WEBVTT

00:00:21.126 --> 00:00:21.806 A:middle
&gt;&gt; Hello everyone.

00:00:22.516 --> 00:00:26.546 A:middle
[ Applause ]

00:00:27.046 --> 00:00:28.206 A:middle
I hope you're have a great time

00:00:28.206 --> 00:00:29.006 A:middle
at WWDC so far.

00:00:29.776 --> 00:00:31.216 A:middle
Allow me to introduce myself.

00:00:31.906 --> 00:00:33.646 A:middle
My name is Brett Keating and I'm

00:00:33.646 --> 00:00:34.896 A:middle
here with my colleague Frank

00:00:34.896 --> 00:00:36.386 A:middle
Doepke and we're here to tell

00:00:36.386 --> 00:00:38.256 A:middle
you about Apple's new Vision

00:00:38.256 --> 00:00:39.836 A:middle
framework, so let's get started.

00:00:39.836 --> 00:00:42.506 A:middle
We're going to begin by showing

00:00:42.506 --> 00:00:43.716 A:middle
you what Vision can do for your

00:00:43.716 --> 00:00:44.266 A:middle
apps.

00:00:44.746 --> 00:00:45.686 A:middle
We're going to go through a few

00:00:45.686 --> 00:00:47.126 A:middle
visual examples of the

00:00:47.126 --> 00:00:48.106 A:middle
algorithms that are going to be

00:00:48.106 --> 00:00:49.016 A:middle
made available in the Vision

00:00:49.016 --> 00:00:49.766 A:middle
framework this year.

00:00:50.936 --> 00:00:51.976 A:middle
At which point I'll hand it off

00:00:51.976 --> 00:00:54.636 A:middle
to Frank to talk about the

00:00:54.636 --> 00:00:56.116 A:middle
concepts behind the Vision

00:00:56.116 --> 00:00:57.566 A:middle
framework, why we designed

00:00:57.566 --> 00:00:58.836 A:middle
things the way we did, what the

00:00:58.836 --> 00:01:00.696 A:middle
mental model behind our API is.

00:01:00.796 --> 00:01:02.516 A:middle
And then we'll go a little

00:01:02.516 --> 00:01:04.906 A:middle
deeper and go through a code

00:01:04.906 --> 00:01:05.446 A:middle
example.

00:01:06.006 --> 00:01:08.796 A:middle
This code example brings

00:01:08.796 --> 00:01:09.716 A:middle
together a few different

00:01:09.716 --> 00:01:11.386 A:middle
technologies in our SDK,

00:01:11.496 --> 00:01:14.566 A:middle
including Core Image, as well as

00:01:14.566 --> 00:01:16.406 A:middle
the brand-new Core ML framework

00:01:16.656 --> 00:01:17.516 A:middle
that we're offering this year

00:01:18.386 --> 00:01:19.926 A:middle
which enables you to put in your

00:01:19.926 --> 00:01:21.226 A:middle
own custom models and have them

00:01:21.276 --> 00:01:23.746 A:middle
be accelerated using our

00:01:24.896 --> 00:01:26.106 A:middle
hardware.

00:01:26.896 --> 00:01:28.716 A:middle
So, let's begin with what you

00:01:28.716 --> 00:01:29.326 A:middle
can do with Vision.

00:01:30.596 --> 00:01:32.986 A:middle
Let's start off with face

00:01:32.986 --> 00:01:33.466 A:middle
detection.

00:01:33.466 --> 00:01:35.676 A:middle
Now face detection is something

00:01:35.676 --> 00:01:37.136 A:middle
we already have in our SDK, but

00:01:37.866 --> 00:01:39.126 A:middle
we're offering in the Vision

00:01:39.126 --> 00:01:40.536 A:middle
framework new this year a face

00:01:40.536 --> 00:01:41.646 A:middle
detection that's based on deep

00:01:41.646 --> 00:01:42.036 A:middle
learning.

00:01:43.246 --> 00:01:44.776 A:middle
And you may already know that

00:01:44.986 --> 00:01:46.006 A:middle
deep learning has made

00:01:46.496 --> 00:01:47.786 A:middle
groundbreaking changes in the

00:01:47.786 --> 00:01:49.916 A:middle
accuracy in what we can do with

00:01:49.986 --> 00:01:51.296 A:middle
Vision technologies and face

00:01:51.296 --> 00:01:53.386 A:middle
detection is no exception.

00:01:54.136 --> 00:01:54.886 A:middle
We're going to have higher

00:01:54.886 --> 00:01:56.086 A:middle
precision which means fewer

00:01:56.086 --> 00:01:57.686 A:middle
false positives, but we are also

00:01:57.686 --> 00:01:58.906 A:middle
going to have dramatically

00:01:59.326 --> 00:02:01.806 A:middle
higher recall which means we'll

00:02:01.806 --> 00:02:02.796 A:middle
miss less faces.

00:02:03.286 --> 00:02:04.156 A:middle
So, let's look at some of the

00:02:04.156 --> 00:02:05.986 A:middle
examples of faces that we will

00:02:05.986 --> 00:02:07.446 A:middle
now be able to detect with the

00:02:07.446 --> 00:02:08.106 A:middle
Vision framework.

00:02:08.936 --> 00:02:10.516 A:middle
For one thing, we'll be able to

00:02:10.516 --> 00:02:11.756 A:middle
detect smaller faces.

00:02:13.936 --> 00:02:15.536 A:middle
We'll also be doing a better job

00:02:15.536 --> 00:02:17.066 A:middle
of detecting strong profiles.

00:02:19.516 --> 00:02:21.386 A:middle
We'll also do a better job

00:02:21.846 --> 00:02:23.036 A:middle
detecting more partially

00:02:23.036 --> 00:02:25.616 A:middle
occluded faces and that includes

00:02:25.826 --> 00:02:27.276 A:middle
things like hats and glasses.

00:02:27.276 --> 00:02:30.506 A:middle
Sticking with the faces theme

00:02:30.506 --> 00:02:33.496 A:middle
for a little longer, we now are

00:02:33.496 --> 00:02:34.786 A:middle
offering in the Vision framework

00:02:34.786 --> 00:02:37.006 A:middle
new this year face landmarks,

00:02:37.656 --> 00:02:38.596 A:middle
what are face landmarks?

00:02:39.496 --> 00:02:41.026 A:middle
This is a constellation of

00:02:41.026 --> 00:02:42.006 A:middle
points that we detect on the

00:02:42.006 --> 00:02:43.696 A:middle
facer, things like the corners

00:02:43.696 --> 00:02:45.036 A:middle
of the eyes, the outline of the

00:02:45.036 --> 00:02:47.036 A:middle
mouth, the contour of the chin.

00:02:48.316 --> 00:02:50.876 A:middle
Here's an example, here's

00:02:50.876 --> 00:02:53.766 A:middle
another example, and one more

00:02:53.766 --> 00:02:54.266 A:middle
example.

00:02:55.396 --> 00:02:56.946 A:middle
We're really excited about this

00:02:56.946 --> 00:02:57.956 A:middle
I think there's going to be some

00:02:57.956 --> 00:02:59.056 A:middle
great apps created with this

00:02:59.056 --> 00:02:59.596 A:middle
technology.

00:03:01.996 --> 00:03:03.696 A:middle
Next, also new this year in the

00:03:03.696 --> 00:03:04.776 A:middle
Vision framework is image

00:03:04.776 --> 00:03:05.426 A:middle
registration.

00:03:06.026 --> 00:03:07.176 A:middle
If you don't know what image

00:03:07.176 --> 00:03:08.546 A:middle
registration is it's basically

00:03:08.876 --> 00:03:11.126 A:middle
aligning two images based on the

00:03:11.126 --> 00:03:12.226 A:middle
features that are present in

00:03:12.226 --> 00:03:12.876 A:middle
those images.

00:03:13.496 --> 00:03:15.826 A:middle
You can use this for stitching

00:03:15.826 --> 00:03:17.166 A:middle
together used for panorama kind

00:03:17.286 --> 00:03:18.686 A:middle
of like this example or image

00:03:18.686 --> 00:03:19.726 A:middle
stacking applications.

00:03:20.536 --> 00:03:22.406 A:middle
We have two different kinds, one

00:03:22.406 --> 00:03:24.126 A:middle
that's translation only and one

00:03:24.126 --> 00:03:24.756 A:middle
that gives you for full

00:03:24.756 --> 00:03:27.176 A:middle
homography for greater accuracy.

00:03:28.656 --> 00:03:31.136 A:middle
We're also offering a few

00:03:31.136 --> 00:03:32.276 A:middle
technologies that are already in

00:03:32.276 --> 00:03:33.566 A:middle
our SDK through CIDetector

00:03:33.566 --> 00:03:34.406 A:middle
interface.

00:03:34.796 --> 00:03:35.706 A:middle
We're making them available in

00:03:35.706 --> 00:03:36.776 A:middle
the Vision API as well.

00:03:36.896 --> 00:03:38.766 A:middle
That includes rectangle

00:03:38.766 --> 00:03:40.516 A:middle
detection as you can see, we

00:03:40.516 --> 00:03:42.296 A:middle
detect the sign in the picture.

00:03:43.816 --> 00:03:45.566 A:middle
We're also doing barcode

00:03:45.566 --> 00:03:46.776 A:middle
detection and recognition in the

00:03:46.776 --> 00:03:50.726 A:middle
Vision API and text detection as

00:03:52.256 --> 00:03:52.376 A:middle
well.

00:03:53.766 --> 00:03:54.866 A:middle
Another new technology,

00:03:55.116 --> 00:03:55.976 A:middle
brand-new in the Vision

00:03:55.976 --> 00:03:56.986 A:middle
framework this year is object

00:03:56.986 --> 00:03:57.366 A:middle
tracking.

00:03:58.186 --> 00:04:00.576 A:middle
You can use this to track a face

00:04:00.576 --> 00:04:01.726 A:middle
if you've detected a face.

00:04:01.726 --> 00:04:03.246 A:middle
You can use that face rectangle

00:04:03.246 --> 00:04:05.186 A:middle
as an initial condition to the

00:04:05.186 --> 00:04:06.436 A:middle
tracking and then the Vision

00:04:06.436 --> 00:04:07.756 A:middle
framework will track that square

00:04:08.196 --> 00:04:09.056 A:middle
throughout the rest of your

00:04:09.056 --> 00:04:09.446 A:middle
video.

00:04:10.246 --> 00:04:12.486 A:middle
Will also track rectangles and

00:04:12.486 --> 00:04:14.036 A:middle
you can also define the initial

00:04:14.036 --> 00:04:15.036 A:middle
condition yourself.

00:04:15.846 --> 00:04:17.426 A:middle
So that's what I mean by general

00:04:17.426 --> 00:04:19.456 A:middle
templates, if you decide to for

00:04:19.456 --> 00:04:21.306 A:middle
example, put a square around

00:04:21.306 --> 00:04:24.656 A:middle
this wakeboarder as I have, you

00:04:24.656 --> 00:04:27.116 A:middle
can then go ahead and track

00:04:27.116 --> 00:04:27.376 A:middle
that.

00:04:29.336 --> 00:04:30.556 A:middle
You can see that we handle

00:04:30.556 --> 00:04:32.666 A:middle
pretty large changes in scale,

00:04:32.756 --> 00:04:34.396 A:middle
pretty large deformations fairly

00:04:34.396 --> 00:04:35.746 A:middle
robustly with this technology.

00:04:39.096 --> 00:04:40.266 A:middle
Another really exciting

00:04:41.296 --> 00:04:42.956 A:middle
technology that's new in Apple's

00:04:42.956 --> 00:04:45.086 A:middle
SDK this year Core ML and you

00:04:45.086 --> 00:04:46.126 A:middle
can integrate your Core ML

00:04:46.126 --> 00:04:47.576 A:middle
models directly into Vision.

00:04:48.236 --> 00:04:50.916 A:middle
As I've mentioned, machine

00:04:50.916 --> 00:04:52.496 A:middle
learning does great things for

00:04:52.496 --> 00:04:55.336 A:middle
Computer Vision and you can use

00:04:55.336 --> 00:04:57.066 A:middle
Core ML if you want to create

00:04:57.066 --> 00:04:58.166 A:middle
your own models, do your own

00:04:58.166 --> 00:04:58.716 A:middle
solution.

00:04:59.416 --> 00:05:01.246 A:middle
Perhaps for example, you want to

00:05:01.246 --> 00:05:02.476 A:middle
create a wedding application

00:05:02.986 --> 00:05:06.316 A:middle
where you're able to detect this

00:05:06.316 --> 00:05:08.006 A:middle
part of the wedding is the

00:05:08.006 --> 00:05:08.956 A:middle
reception, this part of the

00:05:08.956 --> 00:05:09.816 A:middle
wedding is where the bride is

00:05:09.816 --> 00:05:10.686 A:middle
walking down the aisle.

00:05:11.416 --> 00:05:12.456 A:middle
If you want to train your own

00:05:12.456 --> 00:05:14.706 A:middle
model and you have the data to

00:05:14.706 --> 00:05:17.196 A:middle
train your own model you can do

00:05:17.196 --> 00:05:17.476 A:middle
that.

00:05:18.556 --> 00:05:20.766 A:middle
Core ML as I mentioned, provides

00:05:20.766 --> 00:05:22.116 A:middle
native acceleration for custom

00:05:22.116 --> 00:05:23.206 A:middle
models so they'll run really

00:05:23.206 --> 00:05:25.706 A:middle
fast and Vision provides the

00:05:25.706 --> 00:05:26.876 A:middle
imaging pipeline to support

00:05:26.876 --> 00:05:28.776 A:middle
these models, so you won't have

00:05:28.776 --> 00:05:30.276 A:middle
to do any rescaling or anything

00:05:30.276 --> 00:05:31.156 A:middle
like that we'll take care of all

00:05:31.156 --> 00:05:31.586 A:middle
that for you.

00:05:31.586 --> 00:05:33.106 A:middle
We know what your model is

00:05:33.106 --> 00:05:34.476 A:middle
expecting and we'll put the

00:05:34.476 --> 00:05:35.626 A:middle
image in the right format.

00:05:37.596 --> 00:05:38.826 A:middle
If you're interested in Core ML

00:05:38.826 --> 00:05:40.396 A:middle
there's some sessions that you

00:05:40.396 --> 00:05:42.576 A:middle
can go to, we've listed the labs

00:05:42.576 --> 00:05:43.306 A:middle
down here for you.

00:05:43.866 --> 00:05:45.346 A:middle
One of them will be tomorrow

00:05:45.346 --> 00:05:47.356 A:middle
morning and then another one on

00:05:47.356 --> 00:05:47.986 A:middle
Friday afternoon.

00:05:49.446 --> 00:05:51.386 A:middle
So that's basically the features

00:05:51.386 --> 00:05:52.346 A:middle
that are in the Vision

00:05:52.346 --> 00:05:52.796 A:middle
framework.

00:05:54.236 --> 00:05:56.526 A:middle
Overall, what Apple's new Vision

00:05:56.526 --> 00:05:58.306 A:middle
framework provides are

00:05:58.766 --> 00:06:00.776 A:middle
high-level on-device solutions

00:06:01.306 --> 00:06:02.586 A:middle
to Computer Vision problems

00:06:02.706 --> 00:06:03.756 A:middle
through one simple API.

00:06:03.756 --> 00:06:06.576 A:middle
Now let me break this statement

00:06:06.576 --> 00:06:08.266 A:middle
down just a little bit.

00:06:09.276 --> 00:06:10.586 A:middle
What do I mean by high-level

00:06:10.586 --> 00:06:11.186 A:middle
solutions?

00:06:11.896 --> 00:06:14.336 A:middle
Well we don't want you to have

00:06:14.336 --> 00:06:15.556 A:middle
to be a Computer Vision expert

00:06:15.556 --> 00:06:16.876 A:middle
to put the magic of Computer

00:06:16.876 --> 00:06:18.066 A:middle
Vision into your applications.

00:06:18.656 --> 00:06:20.706 A:middle
You don't want to necessarily

00:06:20.706 --> 00:06:22.216 A:middle
have to know which feature

00:06:22.216 --> 00:06:23.636 A:middle
detector you want to use in

00:06:23.636 --> 00:06:25.086 A:middle
combination with what classifier

00:06:25.086 --> 00:06:26.966 A:middle
or set of classifiers, we're

00:06:26.966 --> 00:06:28.366 A:middle
going to handle that for you or

00:06:28.366 --> 00:06:29.196 A:middle
whether or not you want to use

00:06:29.196 --> 00:06:30.216 A:middle
machine learning for example.

00:06:30.976 --> 00:06:31.946 A:middle
If you're a developer you're

00:06:32.326 --> 00:06:33.426 A:middle
probably thinking I just want to

00:06:33.426 --> 00:06:34.246 A:middle
know where the faces are.

00:06:35.626 --> 00:06:36.506 A:middle
And so, we're going to handle

00:06:36.506 --> 00:06:37.666 A:middle
all that complexity for you.

00:06:38.926 --> 00:06:42.166 A:middle
Depending on your use case we'll

00:06:42.166 --> 00:06:43.896 A:middle
be doing either traditional

00:06:43.896 --> 00:06:45.206 A:middle
approach if that's what's needed

00:06:45.206 --> 00:06:46.846 A:middle
for maybe real-time applications

00:06:46.846 --> 00:06:49.166 A:middle
or deep learning algorithms for

00:06:49.416 --> 00:06:50.176 A:middle
higher accuracy.

00:06:50.846 --> 00:06:54.186 A:middle
Now I also mentioned that we're

00:06:54.186 --> 00:06:55.666 A:middle
doing all these algorithms on

00:06:55.666 --> 00:06:58.116 A:middle
the device, let's talk a little

00:06:58.116 --> 00:07:00.436 A:middle
bit about why we'd want to do

00:07:00.436 --> 00:07:01.916 A:middle
things on device versus provided

00:07:01.916 --> 00:07:02.906 A:middle
a cloud-based solution.

00:07:03.396 --> 00:07:05.766 A:middle
First of all, it's privacy.

00:07:06.866 --> 00:07:08.836 A:middle
As you know, Apple cares a lot

00:07:08.836 --> 00:07:11.006 A:middle
about privacy, I care a lot

00:07:11.006 --> 00:07:12.476 A:middle
about privacy working at Apple,

00:07:12.796 --> 00:07:14.136 A:middle
sometimes it makes my job a

00:07:14.136 --> 00:07:16.446 A:middle
little harder, but nonetheless

00:07:17.026 --> 00:07:18.056 A:middle
keeping all your data on the

00:07:18.056 --> 00:07:20.156 A:middle
device is the best way to

00:07:20.156 --> 00:07:21.736 A:middle
protect your user's data

00:07:21.736 --> 00:07:22.176 A:middle
privacy.

00:07:24.456 --> 00:07:26.276 A:middle
Furthermore, with certain

00:07:26.276 --> 00:07:28.036 A:middle
cloud-based solutions there's a

00:07:28.036 --> 00:07:29.106 A:middle
cost associated with it.

00:07:29.306 --> 00:07:31.616 A:middle
If you're a developer maybe

00:07:31.616 --> 00:07:32.796 A:middle
you're paying usage fees to use

00:07:32.796 --> 00:07:33.976 A:middle
a cloud-based solution.

00:07:35.316 --> 00:07:37.146 A:middle
Your users will have to transfer

00:07:37.146 --> 00:07:38.066 A:middle
the data to that cloud.

00:07:39.516 --> 00:07:41.306 A:middle
All these costs they can add up

00:07:41.306 --> 00:07:42.296 A:middle
for both the developers and the

00:07:42.296 --> 00:07:42.726 A:middle
users.

00:07:42.956 --> 00:07:44.506 A:middle
So, when everything's on the

00:07:44.506 --> 00:07:45.586 A:middle
device it's free.

00:07:45.816 --> 00:07:50.566 A:middle
And you can support real-time

00:07:50.566 --> 00:07:51.966 A:middle
use cases like the tracking

00:07:51.966 --> 00:07:52.756 A:middle
example I showed you.

00:07:53.566 --> 00:07:54.616 A:middle
Imagine trying to track

00:07:54.616 --> 00:07:55.536 A:middle
something through a video by

00:07:55.536 --> 00:07:56.416 A:middle
sending every frame to the

00:07:56.416 --> 00:07:57.926 A:middle
cloud, I don't think that's

00:07:57.926 --> 00:07:58.556 A:middle
going to work too well.

00:07:59.226 --> 00:08:01.456 A:middle
So, no latency, fast execution

00:08:01.926 --> 00:08:02.946 A:middle
that's what we're offering with

00:08:03.226 --> 00:08:03.896 A:middle
the Vision framework.

00:08:04.786 --> 00:08:07.696 A:middle
So, I hope you enjoyed that

00:08:08.076 --> 00:08:09.186 A:middle
introduction, now we're going to

00:08:09.186 --> 00:08:12.226 A:middle
go a little deeper and talk

00:08:12.226 --> 00:08:13.446 A:middle
about the Vision concepts.

00:08:13.446 --> 00:08:13.996 A:middle
For this part of the

00:08:13.996 --> 00:08:15.356 A:middle
presentation I'm going to hand

00:08:15.356 --> 00:08:15.976 A:middle
it off to Frank.

00:08:16.516 --> 00:08:19.566 A:middle
[ Applause ]

00:08:20.066 --> 00:08:20.556 A:middle
&gt;&gt; Thank you Brett.

00:08:22.956 --> 00:08:24.406 A:middle
Hi, good afternoon, my name is

00:08:24.406 --> 00:08:25.466 A:middle
Frank Doepke and I'm going to

00:08:25.466 --> 00:08:26.996 A:middle
talk about more of the technical

00:08:26.996 --> 00:08:28.876 A:middle
details what is part of our

00:08:28.876 --> 00:08:29.496 A:middle
Vision framework.

00:08:29.796 --> 00:08:33.916 A:middle
So, what do we want to do, when

00:08:33.916 --> 00:08:35.726 A:middle
we want to analyze an image we

00:08:35.916 --> 00:08:37.836 A:middle
have three major tasks that we

00:08:37.836 --> 00:08:39.816 A:middle
actually want to perform.

00:08:40.276 --> 00:08:41.416 A:middle
So, we [inaudible] finding out

00:08:41.416 --> 00:08:42.576 A:middle
what is in the image and what do

00:08:42.576 --> 00:08:43.456 A:middle
I want to know about it.

00:08:44.316 --> 00:08:45.356 A:middle
There's the machinery,

00:08:46.076 --> 00:08:47.166 A:middle
somebody's got to do the work

00:08:47.676 --> 00:08:48.956 A:middle
and we get some results out of

00:08:48.956 --> 00:08:50.316 A:middle
it, at least we hope that's

00:08:50.316 --> 00:08:51.206 A:middle
what's going to happen.

00:08:52.106 --> 00:08:54.036 A:middle
So, in terminology for Vision

00:08:54.036 --> 00:08:56.046 A:middle
that means the asks these are

00:08:56.046 --> 00:08:56.836 A:middle
requests.

00:08:57.476 --> 00:08:59.166 A:middle
And I just did a few examples

00:08:59.166 --> 00:09:01.016 A:middle
here like the barcode detection

00:09:01.016 --> 00:09:03.936 A:middle
or face detection and we feed

00:09:03.936 --> 00:09:07.016 A:middle
them into our request handler.

00:09:07.926 --> 00:09:08.996 A:middle
That's the one in this case to

00:09:08.996 --> 00:09:10.106 A:middle
be an image request and

00:09:10.176 --> 00:09:11.136 A:middle
[inaudible] hold on to the image

00:09:11.446 --> 00:09:12.576 A:middle
and it's going to do all the

00:09:12.576 --> 00:09:13.416 A:middle
work for us.

00:09:14.066 --> 00:09:16.486 A:middle
And as a result, we get back

00:09:16.526 --> 00:09:18.086 A:middle
what we call observations, what

00:09:18.086 --> 00:09:19.446 A:middle
did we observe in this image.

00:09:20.046 --> 00:09:21.666 A:middle
And these observations depend on

00:09:21.666 --> 00:09:22.726 A:middle
what you asked us to do.

00:09:23.006 --> 00:09:24.516 A:middle
So, we have classification

00:09:24.516 --> 00:09:26.956 A:middle
observation or detected objects.

00:09:27.786 --> 00:09:28.986 A:middle
Now when you want to track

00:09:28.986 --> 00:09:30.076 A:middle
something in the sequence like

00:09:30.076 --> 00:09:32.656 A:middle
the wakeboarder it's basically

00:09:32.656 --> 00:09:33.466 A:middle
the same concept.

00:09:33.566 --> 00:09:34.796 A:middle
We have some asks, we have the

00:09:34.796 --> 00:09:36.376 A:middle
machinery, and we get some

00:09:36.376 --> 00:09:39.096 A:middle
results out of it in the end.

00:09:39.096 --> 00:09:40.826 A:middle
Again, the asks are requests.

00:09:41.426 --> 00:09:42.936 A:middle
Now since this changes with

00:09:42.936 --> 00:09:44.686 A:middle
every frame the image actually

00:09:44.686 --> 00:09:45.926 A:middle
travels with the request.

00:09:47.736 --> 00:09:48.936 A:middle
Our machinery is again

00:09:48.936 --> 00:09:49.826 A:middle
[inaudible] request handler it's

00:09:49.826 --> 00:09:52.506 A:middle
the sequence request handler and

00:09:52.506 --> 00:09:54.046 A:middle
we get results which are

00:09:54.046 --> 00:09:55.906 A:middle
observations that go with our

00:09:55.976 --> 00:09:56.546 A:middle
requests.

00:09:58.086 --> 00:10:00.866 A:middle
So, let me talk a little bit

00:10:00.866 --> 00:10:02.066 A:middle
more about these two image

00:10:02.066 --> 00:10:02.966 A:middle
request handlers that I

00:10:02.966 --> 00:10:03.806 A:middle
mentioned so far.

00:10:04.476 --> 00:10:05.606 A:middle
So, we have the image request

00:10:05.606 --> 00:10:07.666 A:middle
handler that is mostly if you

00:10:07.666 --> 00:10:09.026 A:middle
want to do something interactive

00:10:09.026 --> 00:10:09.736 A:middle
with the image.

00:10:10.166 --> 00:10:11.386 A:middle
You want to do multiple Vision

00:10:11.386 --> 00:10:13.466 A:middle
tasks on an image, sometimes you

00:10:13.466 --> 00:10:15.116 A:middle
actually do one and then based

00:10:15.116 --> 00:10:16.566 A:middle
on the results you then kick off

00:10:16.566 --> 00:10:17.926 A:middle
the next one and that's what you

00:10:17.926 --> 00:10:19.016 A:middle
want to use the image request

00:10:19.016 --> 00:10:19.486 A:middle
handler for.

00:10:19.966 --> 00:10:21.296 A:middle
It'll hold on to the image that

00:10:21.296 --> 00:10:22.446 A:middle
it's set up with for its

00:10:22.446 --> 00:10:25.366 A:middle
lifecycle and that allows us

00:10:25.396 --> 00:10:26.856 A:middle
under the cover to do

00:10:26.856 --> 00:10:28.856 A:middle
performance optimizations by

00:10:28.856 --> 00:10:30.996 A:middle
holding on to intermediates to

00:10:31.146 --> 00:10:32.866 A:middle
make these requests perform

00:10:32.866 --> 00:10:33.276 A:middle
faster.

00:10:34.016 --> 00:10:36.466 A:middle
On the flipside, if I want to

00:10:36.466 --> 00:10:37.726 A:middle
track something we use the

00:10:37.726 --> 00:10:38.816 A:middle
sequence request handler.

00:10:39.276 --> 00:10:40.516 A:middle
The sequence request handler

00:10:40.516 --> 00:10:42.086 A:middle
allows us to keep tracking

00:10:42.186 --> 00:10:42.996 A:middle
[inaudible] in the sequence

00:10:42.996 --> 00:10:43.666 A:middle
request handler.

00:10:44.316 --> 00:10:46.136 A:middle
And it will not hold on to all

00:10:46.136 --> 00:10:47.466 A:middle
the images that gets fed into it

00:10:47.466 --> 00:10:48.626 A:middle
over its lifecycle so they get

00:10:48.626 --> 00:10:49.326 A:middle
released earlier.

00:10:50.056 --> 00:10:51.536 A:middle
But that means on the flipside,

00:10:51.776 --> 00:10:53.486 A:middle
you cannot do the same

00:10:53.486 --> 00:10:54.866 A:middle
optimizations if you want to do

00:10:54.866 --> 00:10:56.146 A:middle
multiple requests on the same

00:10:56.146 --> 00:10:56.486 A:middle
image.

00:10:57.716 --> 00:10:59.836 A:middle
So how does this look in the

00:10:59.836 --> 00:11:01.596 A:middle
code, we are developers that's

00:11:01.596 --> 00:11:02.526 A:middle
what we want to see.

00:11:04.116 --> 00:11:05.606 A:middle
So, we start as a blank slate

00:11:05.606 --> 00:11:07.316 A:middle
that's always good and then we

00:11:07.316 --> 00:11:08.446 A:middle
create a request.

00:11:08.886 --> 00:11:10.466 A:middle
In this case, it's a face

00:11:10.466 --> 00:11:12.746 A:middle
detection request.

00:11:13.346 --> 00:11:14.496 A:middle
Now we create the request

00:11:14.496 --> 00:11:16.546 A:middle
handler, what I'm choosing here

00:11:16.546 --> 00:11:17.816 A:middle
is a request handler based on

00:11:17.816 --> 00:11:19.216 A:middle
the files so I have a file on

00:11:19.216 --> 00:11:22.556 A:middle
disk that I want to use.

00:11:22.556 --> 00:11:24.026 A:middle
Now I ask myRequestHandler to

00:11:24.026 --> 00:11:25.646 A:middle
perform my request and this in

00:11:25.646 --> 00:11:27.566 A:middle
this case [inaudible] it's just

00:11:27.566 --> 00:11:29.716 A:middle
one request I have my array, but

00:11:29.716 --> 00:11:32.746 A:middle
it could be many and I get my

00:11:32.906 --> 00:11:33.836 A:middle
observations back.

00:11:34.996 --> 00:11:36.606 A:middle
And this can be many faces that

00:11:36.606 --> 00:11:37.266 A:middle
I detected.

00:11:37.836 --> 00:11:39.216 A:middle
Now the one thing I would like

00:11:39.216 --> 00:11:42.746 A:middle
to highlight here is the results

00:11:43.006 --> 00:11:45.036 A:middle
come back as part of the request

00:11:45.156 --> 00:11:46.076 A:middle
that we actually set up

00:11:46.076 --> 00:11:46.526 A:middle
initially.

00:11:46.526 --> 00:11:49.916 A:middle
How does it look when we want to

00:11:51.076 --> 00:11:52.506 A:middle
track something?

00:11:52.616 --> 00:11:53.946 A:middle
We create a sequence request

00:11:54.966 --> 00:11:55.776 A:middle
handler [inaudible] of course

00:11:55.776 --> 00:11:57.026 A:middle
not set up as an image because

00:11:57.216 --> 00:11:58.236 A:middle
we have to [inaudible] all the

00:11:58.236 --> 00:11:59.656 A:middle
frames of the sequence.

00:12:01.476 --> 00:12:02.326 A:middle
So, I started with an

00:12:02.326 --> 00:12:03.906 A:middle
observation that I got from the

00:12:03.906 --> 00:12:05.906 A:middle
previous detection or I mark

00:12:05.956 --> 00:12:07.596 A:middle
something up and I create my

00:12:07.596 --> 00:12:09.276 A:middle
tracking request.

00:12:09.826 --> 00:12:12.026 A:middle
And I simply have to run the

00:12:12.026 --> 00:12:12.596 A:middle
request.

00:12:13.246 --> 00:12:15.036 A:middle
And I feed in in this case as a

00:12:15.036 --> 00:12:17.026 A:middle
pixel buffer the frame that is

00:12:17.026 --> 00:12:17.996 A:middle
currently being dragged.

00:12:19.406 --> 00:12:21.176 A:middle
And out of it again I get some

00:12:21.176 --> 00:12:21.616 A:middle
results.

00:12:22.246 --> 00:12:25.246 A:middle
So, now that we have talked

00:12:25.246 --> 00:12:26.816 A:middle
about how this API is kind of

00:12:26.816 --> 00:12:28.426 A:middle
structured I would like to guide

00:12:28.426 --> 00:12:30.066 A:middle
you through some best practices

00:12:30.066 --> 00:12:31.616 A:middle
so that you get, you know, the

00:12:31.616 --> 00:12:33.006 A:middle
best experience out of Vision.

00:12:33.666 --> 00:12:37.456 A:middle
So, when we want to put together

00:12:37.456 --> 00:12:38.936 A:middle
a Computer Vision task you have

00:12:38.936 --> 00:12:39.886 A:middle
to think about a few things.

00:12:41.476 --> 00:12:43.216 A:middle
Number one, what is the right

00:12:43.216 --> 00:12:44.586 A:middle
image type that I want to use.

00:12:45.826 --> 00:12:47.876 A:middle
Number two, what am I going to

00:12:47.876 --> 00:12:48.746 A:middle
do with the image.

00:12:50.396 --> 00:12:52.196 A:middle
And number three, what

00:12:52.226 --> 00:12:53.496 A:middle
performance do I need or want.

00:12:53.496 --> 00:12:54.346 A:middle
Of course, you always want

00:12:54.346 --> 00:12:55.346 A:middle
fastest, but there are some

00:12:55.346 --> 00:12:56.356 A:middle
tradeoffs that you have to think

00:12:56.356 --> 00:12:56.636 A:middle
about.

00:12:57.026 --> 00:12:59.136 A:middle
So, let's talk about the image

00:13:00.526 --> 00:13:00.636 A:middle
type.

00:13:00.846 --> 00:13:02.346 A:middle
Vision supports a number of

00:13:02.346 --> 00:13:04.196 A:middle
image types and they range from

00:13:04.196 --> 00:13:06.836 A:middle
CVPixelBuffer, CGIImage or even

00:13:06.836 --> 00:13:09.276 A:middle
as we saw in the previous

00:13:09.276 --> 00:13:11.446 A:middle
example just from data that I

00:13:11.446 --> 00:13:12.606 A:middle
use in NSURL.

00:13:13.216 --> 00:13:15.776 A:middle
And we go over all these types

00:13:15.886 --> 00:13:17.076 A:middle
in the following slides so that

00:13:17.076 --> 00:13:18.396 A:middle
you know what to choose when.

00:13:20.556 --> 00:13:22.756 A:middle
Which to choose depends a lot of

00:13:22.756 --> 00:13:23.916 A:middle
like what you want to do.

00:13:23.916 --> 00:13:25.836 A:middle
If you run from a camera stream

00:13:25.836 --> 00:13:27.596 A:middle
or if you run from files on disk

00:13:28.346 --> 00:13:29.996 A:middle
you have to look at that

00:13:30.096 --> 00:13:31.396 A:middle
[inaudible] kind of which type

00:13:31.396 --> 00:13:32.856 A:middle
of image you want to use.

00:13:33.246 --> 00:13:34.536 A:middle
Now two important things to

00:13:34.536 --> 00:13:37.576 A:middle
remember is we already have an

00:13:37.666 --> 00:13:39.206 A:middle
imaging pipeline in the Vision

00:13:39.206 --> 00:13:41.076 A:middle
framework you don't need to

00:13:41.076 --> 00:13:42.006 A:middle
scale the images.

00:13:42.406 --> 00:13:43.616 A:middle
So, unless you already have a

00:13:43.616 --> 00:13:44.926 A:middle
very small representation that

00:13:44.926 --> 00:13:45.806 A:middle
you absolutely want to use,

00:13:45.856 --> 00:13:47.136 A:middle
please don't pre-scale because

00:13:47.246 --> 00:13:50.476 A:middle
we'll just do the work twice.

00:13:50.666 --> 00:13:52.356 A:middle
And mind the orientation.

00:13:52.526 --> 00:13:54.086 A:middle
Computer Vision algorithms are

00:13:54.086 --> 00:13:57.056 A:middle
mostly not, you know, sensitive

00:13:57.056 --> 00:13:59.226 A:middle
to orientation or sorry, they

00:13:59.356 --> 00:14:01.176 A:middle
are sensitive to orientation so

00:14:01.236 --> 00:14:02.576 A:middle
you have to pass that in.

00:14:03.166 --> 00:14:04.586 A:middle
And that is an important part

00:14:04.586 --> 00:14:05.676 A:middle
because if you pass in a

00:14:05.816 --> 00:14:07.206 A:middle
portrait image that's actually

00:14:07.206 --> 00:14:08.166 A:middle
lying on its side we will not

00:14:08.166 --> 00:14:09.616 A:middle
find the faces and that's one of

00:14:09.616 --> 00:14:10.996 A:middle
the common mistakes that usually

00:14:10.996 --> 00:14:11.386 A:middle
happens.

00:14:12.906 --> 00:14:14.396 A:middle
So, I promised to go over the

00:14:14.396 --> 00:14:14.846 A:middle
types.

00:14:15.796 --> 00:14:16.696 A:middle
When you want to do something

00:14:16.696 --> 00:14:17.866 A:middle
streaming we want to use the

00:14:17.866 --> 00:14:18.746 A:middle
CVPixelBuffer.

00:14:19.906 --> 00:14:21.956 A:middle
When you create a VideoDataOut

00:14:21.956 --> 00:14:23.206 A:middle
[inaudible] capture you will get

00:14:23.286 --> 00:14:24.776 A:middle
CMSampleBuffers and through

00:14:24.916 --> 00:14:25.806 A:middle
those we get your

00:14:25.866 --> 00:14:26.686 A:middle
CVPixelBuffers.

00:14:27.856 --> 00:14:29.456 A:middle
It's also a pretty good format

00:14:29.456 --> 00:14:30.886 A:middle
if you already have something

00:14:30.886 --> 00:14:32.806 A:middle
where you keep your image data

00:14:32.806 --> 00:14:34.376 A:middle
raw in memory like it's LGB

00:14:34.376 --> 00:14:35.936 A:middle
pixels and wrap them into a

00:14:35.936 --> 00:14:37.276 A:middle
CVPixelBuffer this is a great

00:14:37.276 --> 00:14:38.496 A:middle
format to pass into Vision.

00:14:40.666 --> 00:14:41.976 A:middle
When you get files from disk

00:14:42.146 --> 00:14:44.046 A:middle
please use the URL or if it

00:14:44.046 --> 00:14:44.996 A:middle
comes from the web use the

00:14:44.996 --> 00:14:46.926 A:middle
NSData path.

00:14:47.126 --> 00:14:48.886 A:middle
The great thing about that is it

00:14:48.886 --> 00:14:50.796 A:middle
really allows us to reduce the

00:14:50.796 --> 00:14:51.936 A:middle
memory for print in your

00:14:51.936 --> 00:14:52.616 A:middle
application.

00:14:53.086 --> 00:14:54.566 A:middle
Vision will only read what it

00:14:54.566 --> 00:14:56.236 A:middle
needs to perform the task.

00:14:57.156 --> 00:14:58.256 A:middle
If you think about you want to

00:14:58.256 --> 00:14:59.226 A:middle
do face detection on a

00:14:59.226 --> 00:15:02.376 A:middle
64-megapixel panorama Vision

00:15:02.376 --> 00:15:03.526 A:middle
will actually reduce your memory

00:15:03.526 --> 00:15:04.936 A:middle
for it, but not reading the full

00:15:04.936 --> 00:15:06.436 A:middle
file actually into the memory

00:15:06.436 --> 00:15:07.466 A:middle
and that is an important thing

00:15:07.466 --> 00:15:08.136 A:middle
to keep in mind.

00:15:10.396 --> 00:15:12.006 A:middle
We will read in this case the

00:15:12.006 --> 00:15:13.336 A:middle
EXIF Orientation out of the

00:15:13.336 --> 00:15:15.336 A:middle
file, but you can override it if

00:15:15.336 --> 00:15:17.266 A:middle
you have to for those formats

00:15:17.266 --> 00:15:18.706 A:middle
that don't support it.

00:15:20.666 --> 00:15:22.126 A:middle
If you're already using Core

00:15:22.166 --> 00:15:24.076 A:middle
Image in your application by all

00:15:24.076 --> 00:15:25.286 A:middle
means process the CI image.

00:15:25.286 --> 00:15:27.366 A:middle
This is also important when you

00:15:27.366 --> 00:15:28.096 A:middle
want to actually do some

00:15:28.096 --> 00:15:28.806 A:middle
preprocessing.

00:15:28.806 --> 00:15:29.786 A:middle
If you have some domain

00:15:29.786 --> 00:15:30.946 A:middle
knowledge of what you want to do

00:15:30.946 --> 00:15:33.286 A:middle
in your Computer Vision task you

00:15:33.286 --> 00:15:34.506 A:middle
can do some preprocessing and

00:15:34.506 --> 00:15:35.766 A:middle
try and enhance the image and,

00:15:35.806 --> 00:15:37.186 A:middle
therefore, enhance the Vision

00:15:37.186 --> 00:15:37.716 A:middle
results.

00:15:39.346 --> 00:15:40.316 A:middle
If you want to learn a bit more

00:15:40.316 --> 00:15:42.706 A:middle
about Core Image, there's a

00:15:42.706 --> 00:15:45.006 A:middle
session on Thursday at 1:50 and

00:15:45.396 --> 00:15:46.146 A:middle
they will also show the

00:15:46.146 --> 00:15:47.836 A:middle
integration with our Vision

00:15:47.836 --> 00:15:48.286 A:middle
framework.

00:15:48.756 --> 00:15:52.276 A:middle
Last but not least, if you have

00:15:52.276 --> 00:15:54.246 A:middle
all the images in your UI you

00:15:54.426 --> 00:15:56.346 A:middle
can use the CG image [inaudible]

00:15:56.716 --> 00:15:59.116 A:middle
out of the NS image or the UI

00:15:59.226 --> 00:16:01.196 A:middle
images let's say it comes from

00:16:01.196 --> 00:16:02.906 A:middle
the UI image picker and pass

00:16:02.976 --> 00:16:03.686 A:middle
those into Vision.

00:16:03.806 --> 00:16:07.006 A:middle
Now what am I going to do with

00:16:07.096 --> 00:16:08.496 A:middle
the image and that's where we

00:16:08.496 --> 00:16:10.236 A:middle
have to decide if I want to do

00:16:10.236 --> 00:16:11.346 A:middle
something interactive with the

00:16:11.426 --> 00:16:13.206 A:middle
image in that case I use my

00:16:13.206 --> 00:16:14.336 A:middle
ImageRequestHandler.

00:16:14.606 --> 00:16:16.226 A:middle
It will hold on to the image for

00:16:16.226 --> 00:16:17.926 A:middle
the time and I can do multiple

00:16:17.926 --> 00:16:19.656 A:middle
passes on that image and get the

00:16:19.656 --> 00:16:20.866 A:middle
best results out of that.

00:16:22.126 --> 00:16:23.426 A:middle
Now the CVPixelBuffer

00:16:23.426 --> 00:16:24.926 A:middle
technically will allow you that

00:16:24.926 --> 00:16:26.826 A:middle
you could change the pixels

00:16:27.226 --> 00:16:28.216 A:middle
[inaudible], but we see them as

00:16:28.216 --> 00:16:29.756 A:middle
immutable so don't do that

00:16:29.756 --> 00:16:30.776 A:middle
because we'll get some strange

00:16:30.776 --> 00:16:31.246 A:middle
results.

00:16:31.546 --> 00:16:35.406 A:middle
Next, if you want to track

00:16:35.606 --> 00:16:36.816 A:middle
something we use the

00:16:36.816 --> 00:16:38.156 A:middle
SequenceRequestHandler.

00:16:39.636 --> 00:16:40.506 A:middle
It allows us to keep the

00:16:40.506 --> 00:16:42.946 A:middle
tracking state and lifecycle of

00:16:42.946 --> 00:16:44.676 A:middle
my image is not tied to those

00:16:44.736 --> 00:16:46.256 A:middle
requests handler anymore, but

00:16:46.296 --> 00:16:47.576 A:middle
just how long it needs it for

00:16:47.576 --> 00:16:47.976 A:middle
the tracking.

00:16:52.176 --> 00:16:53.976 A:middle
Performance, so these Vision

00:16:53.976 --> 00:16:55.796 A:middle
tasks are computationally

00:16:55.796 --> 00:16:57.726 A:middle
intensive very often and they do

00:16:57.726 --> 00:16:59.056 A:middle
take time, so you have to think

00:16:59.056 --> 00:17:01.486 A:middle
about that you want to actually

00:17:01.486 --> 00:17:03.376 A:middle
run your task on a different

00:17:03.856 --> 00:17:05.466 A:middle
queue not your main queue.

00:17:06.616 --> 00:17:08.296 A:middle
And think about if you want to

00:17:08.296 --> 00:17:09.376 A:middle
do it in the background, which

00:17:09.376 --> 00:17:11.086 A:middle
is a bit slower or if you need

00:17:11.086 --> 00:17:12.356 A:middle
it very quickly use a more

00:17:12.356 --> 00:17:13.916 A:middle
interactive quality of service

00:17:14.366 --> 00:17:15.516 A:middle
to get the performance.

00:17:16.596 --> 00:17:19.276 A:middle
A good practice is to use the

00:17:19.276 --> 00:17:22.026 A:middle
completion handler to get the

00:17:22.056 --> 00:17:23.606 A:middle
results back, this is part of

00:17:23.606 --> 00:17:24.026 A:middle
our API.

00:17:24.026 --> 00:17:26.166 A:middle
But keep in mind that this

00:17:26.216 --> 00:17:27.866 A:middle
completion handler gets called

00:17:27.916 --> 00:17:29.236 A:middle
on that queue in which you

00:17:29.236 --> 00:17:30.686 A:middle
actually set it off.

00:17:30.686 --> 00:17:32.576 A:middle
So, if you need to update your

00:17:32.576 --> 00:17:33.936 A:middle
UI you have to dispatch that

00:17:33.936 --> 00:17:34.746 A:middle
back to the main queue.

00:17:35.426 --> 00:17:38.796 A:middle
So as Brett already highlighted,

00:17:38.796 --> 00:17:40.036 A:middle
we have a new face detection and

00:17:40.036 --> 00:17:41.206 A:middle
you might say oh God, yet

00:17:41.206 --> 00:17:41.706 A:middle
another one.

00:17:43.946 --> 00:17:45.156 A:middle
But we have good reasons for

00:17:45.156 --> 00:17:45.446 A:middle
this.

00:17:45.706 --> 00:17:47.546 A:middle
Vision uses deep learning and

00:17:47.546 --> 00:17:48.976 A:middle
this gives us really a lot

00:17:49.186 --> 00:17:50.516 A:middle
better precision and recall,

00:17:50.926 --> 00:17:52.366 A:middle
therefore, much better results.

00:17:52.916 --> 00:17:55.826 A:middle
The downside of it, on older

00:17:55.826 --> 00:17:56.976 A:middle
hardware it will run a bit

00:17:56.976 --> 00:17:57.356 A:middle
slower.

00:17:57.436 --> 00:17:58.946 A:middle
So, let's look a little bit at

00:17:58.946 --> 00:18:01.006 A:middle
our overall landscape of face

00:18:01.006 --> 00:18:01.926 A:middle
detectors that we have

00:18:01.926 --> 00:18:02.476 A:middle
available.

00:18:03.236 --> 00:18:04.876 A:middle
So, we have Vision which really

00:18:04.876 --> 00:18:06.346 A:middle
gives us the best results and

00:18:06.346 --> 00:18:08.736 A:middle
it's pretty fast and also pretty

00:18:08.736 --> 00:18:09.966 A:middle
good in its power use as it is

00:18:09.966 --> 00:18:10.926 A:middle
optimized for that.

00:18:11.246 --> 00:18:12.766 A:middle
And we have it available on all

00:18:12.766 --> 00:18:14.376 A:middle
platforms except the watchOS.

00:18:15.446 --> 00:18:16.886 A:middle
And this is the same in terms of

00:18:16.886 --> 00:18:18.566 A:middle
availability for Core Image and

00:18:18.566 --> 00:18:19.686 A:middle
it's a bit faster, but the

00:18:19.686 --> 00:18:21.106 A:middle
results are not quite as good.

00:18:21.736 --> 00:18:24.266 A:middle
In the AV capture session which

00:18:24.266 --> 00:18:25.536 A:middle
is only happening during the

00:18:25.536 --> 00:18:27.016 A:middle
capture side we can actually use

00:18:27.016 --> 00:18:28.436 A:middle
hardware so it's really fast in

00:18:28.436 --> 00:18:30.176 A:middle
performance, but the results

00:18:30.176 --> 00:18:31.666 A:middle
again are not as good as we get

00:18:31.666 --> 00:18:31.976 A:middle
out of Vision.

00:18:32.466 --> 00:18:34.006 A:middle
So, you have to choose depending

00:18:34.006 --> 00:18:35.286 A:middle
on your application what you

00:18:35.286 --> 00:18:36.996 A:middle
want to do choose the right

00:18:36.996 --> 00:18:38.146 A:middle
technology for the face

00:18:38.146 --> 00:18:38.566 A:middle
detection.

00:18:40.406 --> 00:18:41.446 A:middle
Now I did mention that our

00:18:41.446 --> 00:18:43.056 A:middle
quality is better, so let me try

00:18:43.056 --> 00:18:44.096 A:middle
to prove that a little bit.

00:18:44.576 --> 00:18:46.796 A:middle
So, I have here an image and I

00:18:46.796 --> 00:18:47.896 A:middle
ran the face detection through

00:18:47.896 --> 00:18:48.506 A:middle
Core Image.

00:18:48.976 --> 00:18:50.956 A:middle
And we find two faces and we see

00:18:50.956 --> 00:18:53.056 A:middle
roughly where the eyes and where

00:18:53.656 --> 00:18:55.126 A:middle
the mouth are.

00:18:55.396 --> 00:18:56.986 A:middle
Now in Vision we find all four

00:18:56.986 --> 00:18:58.496 A:middle
faces even the occluded ones and

00:18:58.496 --> 00:18:59.986 A:middle
we get a whole lot more details

00:19:00.036 --> 00:19:03.196 A:middle
with the visual landmarks.

00:19:04.356 --> 00:19:05.486 A:middle
Speaking of Core Image, I would

00:19:05.486 --> 00:19:06.426 A:middle
like to highlight a little bit

00:19:06.426 --> 00:19:07.306 A:middle
what's happening with the

00:19:07.386 --> 00:19:08.046 A:middle
CIDetectors.

00:19:08.076 --> 00:19:11.456 A:middle
So, whoever uses it already can

00:19:11.456 --> 00:19:12.536 A:middle
keep on using them they are

00:19:12.536 --> 00:19:15.596 A:middle
still in Core Image, but all new

00:19:15.596 --> 00:19:17.136 A:middle
parts and all the improvements

00:19:17.136 --> 00:19:18.296 A:middle
in terms of algorithms for

00:19:18.296 --> 00:19:20.216 A:middle
computer moving forward will be

00:19:20.216 --> 00:19:22.046 A:middle
in Vision that's the new home

00:19:22.046 --> 00:19:22.946 A:middle
for Computer Vision.

00:19:23.546 --> 00:19:28.126 A:middle
So, an awful lot of sides, how

00:19:28.126 --> 00:19:28.656 A:middle
about a demo.

00:19:29.606 --> 00:19:30.826 A:middle
So, what I'm going to show you

00:19:30.826 --> 00:19:33.756 A:middle
is an application that runs an

00:19:33.756 --> 00:19:35.726 A:middle
AV capture session on the device

00:19:35.996 --> 00:19:37.256 A:middle
if the demo Gods are with us.

00:19:37.896 --> 00:19:39.936 A:middle
And we will do a very simple

00:19:39.936 --> 00:19:41.296 A:middle
rectangle detection request.

00:19:42.376 --> 00:19:43.916 A:middle
So, what do I have to do to set

00:19:43.916 --> 00:19:44.296 A:middle
this up?

00:19:46.156 --> 00:19:48.386 A:middle
What you see here is I create my

00:19:48.386 --> 00:19:52.136 A:middle
request, that's my simple

00:19:52.136 --> 00:19:54.516 A:middle
rectangle detection request in

00:19:55.886 --> 00:19:56.816 A:middle
this case.

00:19:56.996 --> 00:19:58.376 A:middle
I'm actually in the wrong sample

00:19:58.376 --> 00:19:59.416 A:middle
that's why I'm getting confused

00:19:59.416 --> 00:19:59.826 A:middle
here, my apologies.

00:20:00.356 --> 00:20:02.516 A:middle
Here we go.

00:20:02.546 --> 00:20:03.826 A:middle
Okay we have our rectangle

00:20:03.826 --> 00:20:05.956 A:middle
detection request and I'm

00:20:05.956 --> 00:20:07.406 A:middle
setting some parameters just as

00:20:07.406 --> 00:20:08.856 A:middle
an example here, I only want

00:20:08.856 --> 00:20:10.626 A:middle
them this minimum size in our

00:20:10.626 --> 00:20:11.946 A:middle
coordinates are normalized so I

00:20:11.946 --> 00:20:13.796 A:middle
only want a 10% minimize size of

00:20:13.796 --> 00:20:16.666 A:middle
the image and I just want 20

00:20:16.666 --> 00:20:17.206 A:middle
rectangles.

00:20:17.436 --> 00:20:19.036 A:middle
I could get more, but I want 20,

00:20:19.036 --> 00:20:20.156 A:middle
I just picked a number.

00:20:21.386 --> 00:20:23.086 A:middle
I set up my area of the request

00:20:23.116 --> 00:20:25.986 A:middle
that I want to perform and the

00:20:26.236 --> 00:20:28.506 A:middle
right here this is our

00:20:28.676 --> 00:20:30.616 A:middle
completion handler and all that

00:20:30.616 --> 00:20:32.326 A:middle
I'm going to do is I'm going to

00:20:32.326 --> 00:20:34.406 A:middle
draw my rectangles, but as you

00:20:34.406 --> 00:20:35.816 A:middle
notice I'm just patching it to

00:20:35.816 --> 00:20:37.826 A:middle
the main queue to update our UI.

00:20:39.176 --> 00:20:40.216 A:middle
Where do our images come from?

00:20:40.216 --> 00:20:41.736 A:middle
So, we look at the capture

00:20:41.736 --> 00:20:45.526 A:middle
output here and as I promised,

00:20:45.666 --> 00:20:47.006 A:middle
in the capture output we get our

00:20:47.006 --> 00:20:48.566 A:middle
pixelBuffer from the

00:20:48.566 --> 00:20:49.606 A:middle
CMSampleBuffer.

00:20:50.376 --> 00:20:54.276 A:middle
Right here I'm getting the

00:20:54.276 --> 00:20:55.166 A:middle
cameraIntrinsics.

00:20:55.166 --> 00:20:56.496 A:middle
Now this is something that is

00:20:56.596 --> 00:20:57.606 A:middle
important in some of these

00:20:57.656 --> 00:20:58.816 A:middle
Computer Vision paths where we

00:20:58.816 --> 00:21:00.126 A:middle
actually know what the camera is

00:21:00.126 --> 00:21:00.866 A:middle
kind of looking at.

00:21:02.406 --> 00:21:04.206 A:middle
As I mentioned, we don't forget

00:21:04.206 --> 00:21:06.446 A:middle
the acts of orientation and I

00:21:06.446 --> 00:21:07.876 A:middle
create an image request handler

00:21:08.026 --> 00:21:09.696 A:middle
and perform our tasks.

00:21:09.696 --> 00:21:10.636 A:middle
So, how does this look when we

00:21:10.636 --> 00:21:11.886 A:middle
actually run it?

00:21:12.156 --> 00:21:13.006 A:middle
All right, so what we're going

00:21:13.006 --> 00:21:14.296 A:middle
to see here is that now we

00:21:14.586 --> 00:21:16.516 A:middle
tracked this rectangle and

00:21:16.516 --> 00:21:17.906 A:middle
that's as simple as it is, we

00:21:17.906 --> 00:21:19.386 A:middle
can find other rectangles.

00:21:20.896 --> 00:21:22.036 A:middle
If the cable is long enough we

00:21:22.036 --> 00:21:23.076 A:middle
can actually look oh, there we

00:21:23.076 --> 00:21:24.406 A:middle
find a computer with various

00:21:24.406 --> 00:21:24.906 A:middle
rectangles.

00:21:25.516 --> 00:21:27.976 A:middle
Now I chose the yellow kind of

00:21:27.976 --> 00:21:29.666 A:middle
on purpose because it's the same

00:21:29.666 --> 00:21:31.456 A:middle
color as you saw in the demo

00:21:31.726 --> 00:21:33.246 A:middle
during the keynote for the new

00:21:33.246 --> 00:21:34.516 A:middle
document camera on notes.

00:21:34.576 --> 00:21:36.536 A:middle
And I borrowed their color

00:21:36.536 --> 00:21:37.706 A:middle
because they borrowed our code

00:21:37.706 --> 00:21:38.686 A:middle
to do actually the rectangle

00:21:38.686 --> 00:21:38.976 A:middle
detection.

00:21:39.516 --> 00:21:44.636 A:middle
[ Applause ]

00:21:45.136 --> 00:21:45.876 A:middle
Thank you.

00:21:46.016 --> 00:21:48.000 A:middle
[ Applause ]

00:21:51.046 --> 00:21:52.516 A:middle
Now that was simple, let's do a

00:21:52.516 --> 00:21:52.916 A:middle
bit more.

00:21:56.396 --> 00:21:58.746 A:middle
So, how about we throw some

00:21:58.746 --> 00:22:00.096 A:middle
machine learning at this as well

00:22:00.096 --> 00:22:01.286 A:middle
just for the fun of it.

00:22:01.956 --> 00:22:03.776 A:middle
So, what I have to do is I have

00:22:03.776 --> 00:22:06.136 A:middle
a little model that I just

00:22:06.196 --> 00:22:07.566 A:middle
dragged into my project here.

00:22:14.156 --> 00:22:16.456 A:middle
And that is a classifier that

00:22:16.456 --> 00:22:17.576 A:middle
will tell us a bit something

00:22:17.576 --> 00:22:18.276 A:middle
about the image.

00:22:19.456 --> 00:22:21.726 A:middle
And we see when we look at this

00:22:21.726 --> 00:22:25.536 A:middle
part here that we need to feed

00:22:25.536 --> 00:22:27.116 A:middle
it an image of a very strange

00:22:27.116 --> 00:22:30.556 A:middle
size and get out of it some

00:22:30.556 --> 00:22:31.416 A:middle
classification.

00:22:32.496 --> 00:22:33.596 A:middle
Now you don't need to worry

00:22:33.596 --> 00:22:35.886 A:middle
about that size because Vision

00:22:35.886 --> 00:22:37.006 A:middle
will do the work for you.

00:22:37.006 --> 00:22:43.026 A:middle
So, what do I need to do?

00:22:43.626 --> 00:22:46.076 A:middle
I first need to create a Vision

00:22:46.076 --> 00:22:48.226 A:middle
model and my request with that.

00:22:48.286 --> 00:22:50.326 A:middle
And that is the part that we

00:22:50.326 --> 00:22:52.736 A:middle
have here, so I'm simply loading

00:22:52.736 --> 00:22:56.166 A:middle
the inception model and I create

00:22:56.166 --> 00:22:57.456 A:middle
my classification request.

00:22:58.726 --> 00:22:59.476 A:middle
Now it tells me there's

00:22:59.476 --> 00:23:00.696 A:middle
something missing and I will get

00:23:00.696 --> 00:23:01.706 A:middle
to that in just a moment.

00:23:01.996 --> 00:23:03.256 A:middle
The last thing I want to

00:23:03.256 --> 00:23:05.006 A:middle
highlight here is it says that

00:23:05.366 --> 00:23:06.956 A:middle
it was okay square image, but

00:23:06.956 --> 00:23:09.446 A:middle
our cameras don't see squares so

00:23:09.446 --> 00:23:10.786 A:middle
I need to tell it actually how

00:23:10.786 --> 00:23:12.586 A:middle
to handle just, you know, the

00:23:12.586 --> 00:23:14.136 A:middle
aspect ratio that I want to use.

00:23:14.136 --> 00:23:15.636 A:middle
And I say okay I want to just

00:23:15.636 --> 00:23:15.976 A:middle
send a crop.

00:23:20.276 --> 00:23:22.636 A:middle
So, I need a completion handler

00:23:22.636 --> 00:23:26.246 A:middle
for my task and I have that

00:23:26.246 --> 00:23:28.336 A:middle
already pre canned here as well.

00:23:30.496 --> 00:23:31.806 A:middle
So, in this completion handler I

00:23:31.806 --> 00:23:33.296 A:middle
simply look at my observation

00:23:33.296 --> 00:23:34.656 A:middle
and I will get so this

00:23:34.696 --> 00:23:36.216 A:middle
classifier can see a thousand

00:23:36.216 --> 00:23:37.876 A:middle
different things and I don't

00:23:37.876 --> 00:23:39.206 A:middle
want to show all of them I only

00:23:39.376 --> 00:23:40.816 A:middle
show the ones that I care about.

00:23:40.816 --> 00:23:42.576 A:middle
So, what I'm doing is a little

00:23:42.576 --> 00:23:43.516 A:middle
bit of filtering, I only take

00:23:43.516 --> 00:23:46.216 A:middle
the top four and I only look at

00:23:46.216 --> 00:23:47.706 A:middle
the ones that have a confidence

00:23:47.706 --> 00:23:49.676 A:middle
of at least 30%, it just works

00:23:49.676 --> 00:23:50.946 A:middle
well for my demo here, but you

00:23:50.946 --> 00:23:52.126 A:middle
know you will figure out what

00:23:52.126 --> 00:23:53.356 A:middle
kind of works well for your

00:23:53.356 --> 00:23:53.696 A:middle
model.

00:23:54.036 --> 00:23:57.286 A:middle
And all I have to do next is add

00:23:58.016 --> 00:24:01.136 A:middle
my classification request into

00:24:01.136 --> 00:24:02.516 A:middle
my area of request and now I

00:24:02.516 --> 00:24:05.346 A:middle
will actually run two requests.

00:24:06.026 --> 00:24:07.416 A:middle
So, I have this already loaded

00:24:07.416 --> 00:24:09.886 A:middle
on my device, let's see how this

00:24:09.886 --> 00:24:11.196 A:middle
actually looks.

00:24:12.156 --> 00:24:13.526 A:middle
Of course, you will see it when

00:24:13.526 --> 00:24:14.826 A:middle
I switch to the correct machine,

00:24:15.386 --> 00:24:15.686 A:middle
there we go.

00:24:22.046 --> 00:24:25.056 A:middle
Okay, so we have a coffee mug

00:24:25.456 --> 00:24:27.016 A:middle
which is empty, somebody better

00:24:27.016 --> 00:24:27.966 A:middle
fill that for me.

00:24:27.966 --> 00:24:33.066 A:middle
We have a ballpoint pen, we have

00:24:33.066 --> 00:24:37.616 A:middle
a padlock and look an iPod.

00:24:38.396 --> 00:24:44.076 A:middle
Who has stolen those empty cards

00:24:44.076 --> 00:24:45.436 A:middle
away and didn't realize it was

00:24:45.436 --> 00:24:45.976 A:middle
an iPod?

00:24:46.516 --> 00:24:49.500 A:middle
[ Applause ]

00:24:53.056 --> 00:24:54.676 A:middle
All right, let's go back to the

00:24:54.676 --> 00:24:58.096 A:middle
slides before we get to the next

00:24:58.096 --> 00:24:59.406 A:middle
show-and-tell.

00:25:00.456 --> 00:25:01.846 A:middle
For my next demo, I want to do

00:25:01.846 --> 00:25:02.976 A:middle
something a little bit more

00:25:02.976 --> 00:25:06.516 A:middle
elaborate and with that I chose

00:25:06.516 --> 00:25:07.246 A:middle
something that's called

00:25:07.246 --> 00:25:08.006 A:middle
MNISTVision.

00:25:09.486 --> 00:25:10.876 A:middle
People in the machine learning

00:25:10.876 --> 00:25:12.296 A:middle
community have already looked at

00:25:12.296 --> 00:25:13.376 A:middle
that a little bit more.

00:25:13.566 --> 00:25:15.766 A:middle
MNIST is a dataset where a bunch

00:25:15.766 --> 00:25:17.076 A:middle
of government employees and high

00:25:17.076 --> 00:25:18.536 A:middle
school students wrote numbers

00:25:18.596 --> 00:25:21.086 A:middle
down and this was marked up and

00:25:21.146 --> 00:25:22.106 A:middle
people were trained in our

00:25:22.106 --> 00:25:23.166 A:middle
classifier on that.

00:25:23.796 --> 00:25:25.156 A:middle
Note this is basically like

00:25:25.156 --> 00:25:26.326 A:middle
white numbers on black

00:25:26.396 --> 00:25:28.336 A:middle
background, so I guess they've

00:25:28.336 --> 00:25:30.626 A:middle
written it with chalk on an old

00:25:30.666 --> 00:25:31.136 A:middle
blackboard.

00:25:32.516 --> 00:25:34.346 A:middle
So, in this sample code I'm

00:25:34.346 --> 00:25:35.846 A:middle
going to show you I want to show

00:25:35.846 --> 00:25:37.356 A:middle
a few concepts that are kind of

00:25:37.356 --> 00:25:38.646 A:middle
important like making something

00:25:38.646 --> 00:25:40.606 A:middle
a bit more elaborate with

00:25:41.276 --> 00:25:41.456 A:middle
Vision.

00:25:41.606 --> 00:25:43.646 A:middle
First, we'll spin off model

00:25:43.646 --> 00:25:45.006 A:middle
requests based on top of each

00:25:45.006 --> 00:25:47.516 A:middle
other then we use Core Image in

00:25:47.516 --> 00:25:49.566 A:middle
between to do some image process

00:25:49.566 --> 00:25:51.666 A:middle
and last but not least, we use

00:25:51.666 --> 00:25:53.246 A:middle
Core ML again for the machine

00:25:53.246 --> 00:25:53.716 A:middle
learning part.

00:25:56.666 --> 00:25:57.686 A:middle
So, how is this going to work?

00:25:58.926 --> 00:26:00.596 A:middle
We have here an image on which

00:26:00.596 --> 00:26:01.506 A:middle
we find a sticky note.

00:26:02.106 --> 00:26:04.846 A:middle
Well we find it by using the

00:26:04.846 --> 00:26:06.796 A:middle
rectangle detector, there's our

00:26:06.796 --> 00:26:07.326 A:middle
sticky note.

00:26:07.896 --> 00:26:09.226 A:middle
Now that is prospectively

00:26:09.226 --> 00:26:10.866 A:middle
distorted and it's clearly not

00:26:10.926 --> 00:26:12.306 A:middle
white text on black background.

00:26:13.456 --> 00:26:14.846 A:middle
So, we use Core Image in the

00:26:14.846 --> 00:26:16.686 A:middle
next step and we'll actually do

00:26:16.686 --> 00:26:18.046 A:middle
the perspective correction of it

00:26:18.686 --> 00:26:20.666 A:middle
and invert the color and enhance

00:26:20.666 --> 00:26:22.086 A:middle
also the contrast so that we get

00:26:22.086 --> 00:26:23.356 A:middle
rid this black-and-white image.

00:26:24.896 --> 00:26:26.076 A:middle
And last but not least, I need

00:26:26.076 --> 00:26:28.826 A:middle
to run my MNIST classifier on it

00:26:29.016 --> 00:26:30.476 A:middle
and it should tell me that this

00:26:30.476 --> 00:26:32.256 A:middle
is the number four and this has

00:26:32.256 --> 00:26:35.096 A:middle
80% confidence that this is the

00:26:35.096 --> 00:26:35.636 A:middle
number four.

00:26:35.636 --> 00:26:38.666 A:middle
Again, let's see how this looks

00:26:38.666 --> 00:26:39.066 A:middle
in the app.

00:26:41.496 --> 00:26:43.426 A:middle
So again, I start off as a

00:26:43.426 --> 00:26:45.236 A:middle
rectangle detector request, it's

00:26:45.236 --> 00:26:46.316 A:middle
my favorite I know.

00:26:47.886 --> 00:26:48.946 A:middle
But it's more interesting what

00:26:48.946 --> 00:26:50.246 A:middle
I'm going to do in the

00:26:50.246 --> 00:26:51.206 A:middle
completion handler.

00:26:52.426 --> 00:26:53.746 A:middle
So, I do some validation just to

00:26:53.746 --> 00:26:54.876 A:middle
make sure that the rectangles

00:26:54.876 --> 00:26:55.746 A:middle
I'm getting out of it are

00:26:55.746 --> 00:26:56.456 A:middle
actually okay.

00:26:56.456 --> 00:26:58.656 A:middle
But the interesting part happens

00:26:58.736 --> 00:26:58.926 A:middle
here.

00:26:59.596 --> 00:27:01.256 A:middle
I get the coordinates of the

00:27:01.256 --> 00:27:04.126 A:middle
corners and feed them into CI to

00:27:04.126 --> 00:27:05.786 A:middle
use the CIPerspectiveCorrection.

00:27:06.476 --> 00:27:07.636 A:middle
That allows me to take this

00:27:07.636 --> 00:27:09.226 A:middle
prospectively distorted image

00:27:09.226 --> 00:27:10.916 A:middle
and actually bring it upright as

00:27:10.916 --> 00:27:11.966 A:middle
if I would have the camera

00:27:11.966 --> 00:27:12.506 A:middle
straight on.

00:27:14.076 --> 00:27:15.936 A:middle
I use the CIColorControls to

00:27:16.186 --> 00:27:17.456 A:middle
really bring out the contrast of

00:27:17.506 --> 00:27:19.066 A:middle
the image to make it kind of

00:27:19.066 --> 00:27:19.546 A:middle
binarized.

00:27:20.896 --> 00:27:22.246 A:middle
And as I said, I have to color

00:27:22.246 --> 00:27:23.306 A:middle
invert it.

00:27:24.976 --> 00:27:26.776 A:middle
Now the resulting image of that

00:27:26.776 --> 00:27:28.116 A:middle
I feed into a new request in

00:27:28.116 --> 00:27:28.936 A:middle
there because we have a new

00:27:28.936 --> 00:27:31.146 A:middle
image on which I'll run the

00:27:31.146 --> 00:27:32.086 A:middle
classification.

00:27:32.296 --> 00:27:34.066 A:middle
So, how does the classification

00:27:34.066 --> 00:27:34.416 A:middle
look like?

00:27:35.906 --> 00:27:37.446 A:middle
The classification for that I

00:27:37.446 --> 00:27:39.446 A:middle
use my endless model which I

00:27:39.446 --> 00:27:41.776 A:middle
actually have ready and this is

00:27:41.776 --> 00:27:43.046 A:middle
a small model that I've really

00:27:43.046 --> 00:27:44.866 A:middle
trained actually on this laptop

00:27:44.866 --> 00:27:45.996 A:middle
very easily give us a few lines

00:27:45.996 --> 00:27:47.576 A:middle
of code script and then thanks

00:27:47.576 --> 00:27:49.386 A:middle
to Core ML I can just drag that

00:27:49.386 --> 00:27:50.706 A:middle
in and use this very easily.

00:27:51.106 --> 00:27:52.316 A:middle
So, I have my model here.

00:27:53.766 --> 00:27:55.046 A:middle
Now again, this one part I would

00:27:55.046 --> 00:27:57.636 A:middle
like to highlight this, so that

00:27:57.636 --> 00:27:59.436 A:middle
takes in this case a very small

00:27:59.436 --> 00:28:00.166 A:middle
grayscale image.

00:28:00.166 --> 00:28:02.636 A:middle
So, an image 28 by 28 pixels it

00:28:02.636 --> 00:28:03.636 A:middle
should be able to read these

00:28:03.636 --> 00:28:03.976 A:middle
numbers.

00:28:12.056 --> 00:28:12.526 A:middle
So that's where my

00:28:12.526 --> 00:28:14.716 A:middle
classification is coming from

00:28:15.326 --> 00:28:16.906 A:middle
and now I need to feed in the

00:28:16.906 --> 00:28:17.216 A:middle
image.

00:28:17.216 --> 00:28:19.056 A:middle
So, this sample code has been

00:28:19.056 --> 00:28:20.046 A:middle
made available also for the

00:28:20.046 --> 00:28:21.506 A:middle
session to make it easy also to

00:28:21.506 --> 00:28:22.716 A:middle
run a simulator not running it

00:28:22.716 --> 00:28:24.266 A:middle
live off of the camera I'm just

00:28:24.266 --> 00:28:25.196 A:middle
going to use actually the

00:28:25.196 --> 00:28:29.046 A:middle
UIImagePicker and feed it into

00:28:29.086 --> 00:28:32.306 A:middle
my VMImageRequestHandler and let

00:28:32.306 --> 00:28:33.526 A:middle
it just perform the rectangle

00:28:33.526 --> 00:28:33.986 A:middle
request.

00:28:33.986 --> 00:28:37.136 A:middle
Now notice I buried the request

00:28:37.136 --> 00:28:38.906 A:middle
for the classification into the

00:28:38.906 --> 00:28:40.396 A:middle
completion handler of my

00:28:40.396 --> 00:28:42.146 A:middle
rectangle detection and that

00:28:42.146 --> 00:28:43.496 A:middle
allows us to basically cascade

00:28:43.496 --> 00:28:44.966 A:middle
multiple requests on top of each

00:28:44.966 --> 00:28:45.146 A:middle
other.

00:28:46.096 --> 00:28:47.546 A:middle
So, let's try the demo for this.

00:28:50.896 --> 00:28:55.016 A:middle
Okay, so I have my app here and

00:28:55.196 --> 00:28:56.656 A:middle
well [inaudible] giveaway.

00:28:59.076 --> 00:29:00.696 A:middle
Okay, so what I see here is

00:29:00.696 --> 00:29:01.976 A:middle
again I have my image on the

00:29:01.976 --> 00:29:03.436 A:middle
top, this was actually the photo

00:29:03.436 --> 00:29:04.346 A:middle
that I took earlier.

00:29:04.926 --> 00:29:07.476 A:middle
We see its correctly classifying

00:29:07.476 --> 00:29:10.366 A:middle
as a number one, it was a really

00:29:10.366 --> 00:29:11.556 A:middle
high confidence in this case.

00:29:11.556 --> 00:29:12.646 A:middle
And what you see on the bottom

00:29:12.646 --> 00:29:14.816 A:middle
is just basically just to

00:29:14.816 --> 00:29:16.126 A:middle
visualize that I took this

00:29:16.126 --> 00:29:17.296 A:middle
intermediate image that we

00:29:17.296 --> 00:29:19.676 A:middle
created in CI and show this as

00:29:19.676 --> 00:29:19.946 A:middle
well.

00:29:19.946 --> 00:29:21.706 A:middle
Let's choose another number.

00:29:23.066 --> 00:29:24.316 A:middle
Yes, this is the number three.

00:29:26.466 --> 00:29:27.756 A:middle
Can we guess what this number

00:29:27.846 --> 00:29:28.826 A:middle
is, it's the number four?

00:29:29.626 --> 00:29:30.706 A:middle
It works correctly.

00:29:32.576 --> 00:29:33.806 A:middle
All right, thank you.

00:29:34.516 --> 00:29:37.556 A:middle
[ Applause ]

00:29:38.056 --> 00:29:39.176 A:middle
Let me go back to our slides.

00:29:41.486 --> 00:29:42.936 A:middle
So that is our Vision framework.

00:29:43.986 --> 00:29:45.316 A:middle
Let's capitalize a little bit on

00:29:45.316 --> 00:29:46.466 A:middle
what we really have seen here.

00:29:47.486 --> 00:29:49.426 A:middle
So, Vision is a high-level

00:29:49.426 --> 00:29:50.696 A:middle
framework for Computer Vision

00:29:50.756 --> 00:29:51.816 A:middle
and it should really make it

00:29:51.816 --> 00:29:53.756 A:middle
easy for you to use this in your

00:29:53.756 --> 00:29:55.356 A:middle
applications even if you're not

00:29:55.356 --> 00:29:56.576 A:middle
a Computer Vision expert.

00:29:57.276 --> 00:29:58.756 A:middle
We have various detectors and

00:29:58.756 --> 00:30:00.166 A:middle
there's a whole variety of that

00:30:00.166 --> 00:30:01.946 A:middle
and they all run through one

00:30:01.946 --> 00:30:03.296 A:middle
consistent interface which would

00:30:03.336 --> 00:30:04.896 A:middle
make it very easy to learn that

00:30:04.896 --> 00:30:05.446 A:middle
set of APIs.

00:30:06.826 --> 00:30:08.596 A:middle
And last but not least, the

00:30:08.596 --> 00:30:09.886 A:middle
integration with Core ML.

00:30:10.376 --> 00:30:11.736 A:middle
By bringing your own custom

00:30:11.736 --> 00:30:13.696 A:middle
models you can do a lot in your

00:30:13.696 --> 00:30:15.586 A:middle
application, you can find

00:30:15.586 --> 00:30:17.426 A:middle
hotdogs and see if they are

00:30:17.426 --> 00:30:18.076 A:middle
really hotdogs.

00:30:19.416 --> 00:30:20.336 A:middle
I had to make that joke.

00:30:23.576 --> 00:30:24.606 A:middle
So, if you want to learn more

00:30:24.606 --> 00:30:26.816 A:middle
about our session, please go to

00:30:26.816 --> 00:30:28.626 A:middle
our website and I would

00:30:28.626 --> 00:30:29.746 A:middle
definitely highlight there are

00:30:29.796 --> 00:30:31.576 A:middle
some related sessions that you

00:30:31.576 --> 00:30:33.266 A:middle
should have watched perhaps in

00:30:33.266 --> 00:30:33.706 A:middle
the past.

00:30:33.706 --> 00:30:34.786 A:middle
I'll read you the Core ML one,

00:30:34.786 --> 00:30:35.876 A:middle
but you can find it on our

00:30:35.876 --> 00:30:36.106 A:middle
website.

00:30:36.106 --> 00:30:39.616 A:middle
Please come for our get-together

00:30:39.616 --> 00:30:42.146 A:middle
that we have at 6:30 today, chat

00:30:42.146 --> 00:30:43.416 A:middle
about what we can do.

00:30:43.896 --> 00:30:45.536 A:middle
And for the little bit more

00:30:45.536 --> 00:30:46.776 A:middle
advanced part of Core ML there's

00:30:46.826 --> 00:30:48.886 A:middle
a session on Thursday, as well

00:30:48.886 --> 00:30:50.256 A:middle
as we have a session with Core

00:30:50.256 --> 00:30:51.486 A:middle
Image where they will also do

00:30:51.486 --> 00:30:53.556 A:middle
some very fancy stuff with Core

00:30:53.556 --> 00:30:54.246 A:middle
Image and Vision.

00:30:55.826 --> 00:30:57.126 A:middle
And with that I'd like to thank

00:30:57.126 --> 00:30:58.646 A:middle
you for coming today and enjoy

00:30:58.646 --> 00:30:59.276 A:middle
the rest of WWDC.

00:30:59.276 --> 00:30:59.456 A:middle
Thank you.

00:31:00.516 --> 00:31:06.770 A:middle
[ Applause ]