WEBVTT

00:00:28.596 --> 00:00:29.576 A:middle
&gt;&gt;大家下午好

00:00:30.076 --> 00:00:32.006 A:middle
欢迎参加“Metal 2

00:00:32.006 --> 00:00:32.946 A:middle
的计算功能”会议

00:00:33.886 --> 00:00:35.296 A:middle
我叫 Anna Tikhonova

00:00:35.296 --> 00:00:36.686 A:middle
是 GPU 软件团队的

00:00:36.686 --> 00:00:37.976 A:middle
工程师 现在就开始吧

00:00:42.156 --> 00:00:44.046 A:middle
Metal 2 回波系统的功能

00:00:44.046 --> 00:00:45.836 A:middle
比 Metal API 和语言要

00:00:45.836 --> 00:00:46.356 A:middle
多得多

00:00:46.796 --> 00:00:48.946 A:middle
我们还拥有 GPU 工具

00:00:48.946 --> 00:00:50.336 A:middle
以及 MetalKit 和

00:00:50.336 --> 00:00:51.586 A:middle
Metal Performance Shader 框架

00:00:53.006 --> 00:00:54.146 A:middle
你可能会认为 Metal 是

00:00:54.496 --> 00:00:56.376 A:middle
开发高端游戏和图像

00:00:56.376 --> 00:00:57.566 A:middle
的优秀技术

00:00:58.396 --> 00:00:59.616 A:middle
但它同时也用于

00:00:59.616 --> 00:01:00.506 A:middle
计算处理

00:00:59.616 --> 00:01:00.506 A:middle
计算处理

00:01:01.626 --> 00:01:02.806 A:middle
事实上 Metal 在计算方面

00:01:02.806 --> 00:01:04.616 A:middle
非常强大和灵活

00:01:04.616 --> 00:01:06.526 A:middle
以至于 Metal

00:01:06.526 --> 00:01:08.196 A:middle
Performance Shader 框架

00:01:08.196 --> 00:01:09.326 A:middle
完全建立在

00:01:09.406 --> 00:01:09.756 A:middle
计算之上

00:01:11.026 --> 00:01:12.486 A:middle
在本次会议中 我们将介绍

00:01:12.486 --> 00:01:14.076 A:middle
Metal Performance Shader 框架

00:01:14.076 --> 00:01:15.176 A:middle
的新功能

00:01:17.956 --> 00:01:19.596 A:middle
我们在 2015 年推出了

00:01:19.596 --> 00:01:21.026 A:middle
Metal Performers Shader 框架

00:01:21.026 --> 00:01:22.756 A:middle
简称 MPS

00:01:23.486 --> 00:01:24.546 A:middle
之前的会议视频

00:01:24.546 --> 00:01:25.916 A:middle
可以在我们的开发者

00:01:25.916 --> 00:01:28.906 A:middle
网站上找到

00:01:29.266 --> 00:01:30.686 A:middle
MPS 利用 GPU 的

00:01:30.686 --> 00:01:33.446 A:middle
计算功能为 GPU 提供

00:01:33.446 --> 00:01:33.816 A:middle
加速图元

00:01:34.286 --> 00:01:35.886 A:middle
用于图像处理

00:01:35.926 --> 00:01:37.416 A:middle
线性代数和机器学习

00:01:39.146 --> 00:01:40.416 A:middle
这个框架针对 iOS

00:01:40.416 --> 00:01:42.336 A:middle
进行了优化 我们很高兴地宣布

00:01:42.336 --> 00:01:44.096 A:middle
今年 MPS 也将在

00:01:44.096 --> 00:01:44.836 A:middle
Mac 上应用

00:01:45.516 --> 00:01:49.786 A:middle
[掌声]

00:01:50.286 --> 00:01:50.716 A:middle
谢谢

00:01:51.926 --> 00:01:53.366 A:middle
整个功能集都

00:01:53.366 --> 00:01:55.616 A:middle
可以在 iOS 和 macOS 系统中使用

00:01:55.616 --> 00:01:58.476 A:middle
所以我们先来快速地

00:01:58.476 --> 00:02:00.336 A:middle
看一下图像处理支持的

00:01:58.476 --> 00:02:00.336 A:middle
看一下图像处理支持的

00:02:00.336 --> 00:02:00.686 A:middle
新进展

00:02:02.046 --> 00:02:03.866 A:middle
这里列出了

00:02:03.866 --> 00:02:05.576 A:middle
在 iOS 10 中可以使用的

00:02:05.696 --> 00:02:07.486 A:middle
所有图像处理图元

00:02:08.106 --> 00:02:09.675 A:middle
有 Convolution Gaussian Blur

00:02:09.675 --> 00:02:11.586 A:middle
Lanczos Resampling

00:02:11.586 --> 00:02:12.196 A:middle
就举几个例子

00:02:13.126 --> 00:02:14.726 A:middle
这些现在都可以在 macOS 系统中

00:02:14.726 --> 00:02:14.996 A:middle
使用了

00:02:16.146 --> 00:02:17.656 A:middle
今年我们为大家带来

00:02:17.656 --> 00:02:18.926 A:middle
四种新的图像处理

00:02:18.926 --> 00:02:19.336 A:middle
图元

00:02:20.466 --> 00:02:21.816 A:middle
Image Keypoint

00:02:22.206 --> 00:02:24.316 A:middle
图元可以用于 通常用于

00:02:24.316 --> 00:02:26.256 A:middle
计算机视觉算法 例如

00:02:26.256 --> 00:02:28.596 A:middle
稳像和

00:02:28.596 --> 00:02:29.926 A:middle
双线性缩放

00:02:29.926 --> 00:02:31.726 A:middle
图像统计

00:02:31.726 --> 00:02:33.246 A:middle
元素级算术运算符

00:02:33.326 --> 00:02:34.826 A:middle
通常用于图像

00:02:34.826 --> 00:02:35.156 A:middle
预处理

00:02:35.466 --> 00:02:36.386 A:middle
例如在机器

00:02:36.386 --> 00:02:36.656 A:middle
学习中

00:02:37.556 --> 00:02:38.926 A:middle
算术递增滤色镜也

00:02:38.926 --> 00:02:40.446 A:middle
支持广播操作

00:02:41.256 --> 00:02:42.716 A:middle
例如 允许

00:02:42.716 --> 00:02:44.766 A:middle
添加 2D 图像或 1D 图像

00:02:46.176 --> 00:02:48.406 A:middle
这就是我们对图像处理

00:02:48.406 --> 00:02:49.606 A:middle
新进展的快速介绍

00:02:49.986 --> 00:02:51.286 A:middle
现在我们来谈谈新的

00:02:51.286 --> 00:02:52.386 A:middle
线性代数运算

00:02:54.286 --> 00:02:55.686 A:middle
没有矩阵乘法

00:02:55.686 --> 00:02:57.436 A:middle
矩阵向量

00:02:57.436 --> 00:02:59.736 A:middle
乘法 三角

00:03:00.076 --> 00:03:01.866 A:middle
矩阵因式分解和

00:03:01.866 --> 00:03:02.306 A:middle
线性求解器的支持

00:03:05.356 --> 00:03:06.376 A:middle
为了支持线性代数

00:03:06.376 --> 00:03:09.256 A:middle
运算 我们现在有了很多

00:03:09.256 --> 00:03:10.356 A:middle
新的数据表示

00:03:11.066 --> 00:03:13.076 A:middle
首先是 MPSVector 对象

00:03:13.076 --> 00:03:15.186 A:middle
它可以将 Metal

00:03:15.186 --> 00:03:16.496 A:middle
缓冲区中的数据解释为

00:03:16.496 --> 00:03:17.416 A:middle
一维数组

00:03:19.106 --> 00:03:21.506 A:middle
然后是 MPSMatrix 对象

00:03:22.076 --> 00:03:23.276 A:middle
它可以将 Metal 缓冲区中的

00:03:23.276 --> 00:03:24.886 A:middle
数据解释为矩形

00:03:24.886 --> 00:03:25.156 A:middle
数组

00:03:25.886 --> 00:03:27.656 A:middle
而 MPS 矩阵以行序为

00:03:27.656 --> 00:03:28.176 A:middle
主序

00:03:28.956 --> 00:03:30.166 A:middle
你可以将

00:03:30.166 --> 00:03:32.956 A:middle
MPSVector 和 MPSMatrice 都看作是

00:03:33.456 --> 00:03:34.736 A:middle
用户数据缓冲区周围的

00:03:34.736 --> 00:03:35.096 A:middle
封装

00:03:37.436 --> 00:03:39.296 A:middle
而且我们也支持 MPSMatrix 的

00:03:39.296 --> 00:03:40.926 A:middle
临时变化

00:03:42.296 --> 00:03:45.196 A:middle
MPS 图像 临时图像

00:03:45.196 --> 00:03:47.056 A:middle
和 MPS 临时矩阵从

00:03:47.056 --> 00:03:48.666 A:middle
与命令缓冲区相关联的

00:03:48.906 --> 00:03:49.956 A:middle
Metal 堆中分配

00:03:49.956 --> 00:03:50.216 A:middle
出来

00:03:50.766 --> 00:03:51.856 A:middle
之所以称为临时的

00:03:52.226 --> 00:03:54.066 A:middle
是因为它们的寿命

00:03:54.216 --> 00:03:55.996 A:middle
受限于命令缓冲区的

00:03:55.996 --> 00:03:56.516 A:middle
使用寿命

00:03:57.546 --> 00:03:58.866 A:middle
我们建议

00:03:58.896 --> 00:04:00.176 A:middle
在大多数中间存储器中

00:03:58.896 --> 00:04:00.176 A:middle
在大多数中间存储器中

00:04:00.636 --> 00:04:02.526 A:middle
使用临时映像和

00:04:03.006 --> 00:04:03.206 A:middle
矩阵

00:04:04.316 --> 00:04:07.416 A:middle
MPSVector 和 MPSMatrix 都

00:04:07.576 --> 00:04:09.116 A:middle
支持多种输入类型

00:04:09.646 --> 00:04:11.596 A:middle
我们支持单精度

00:04:11.596 --> 00:04:14.236 A:middle
半精度输入类型以及

00:04:14.236 --> 00:04:15.266 A:middle
浮点输入类型

00:04:15.756 --> 00:04:17.696 A:middle
还有 16 位和 8 位带符号

00:04:17.986 --> 00:04:19.125 A:middle
整数输入类型

00:04:21.016 --> 00:04:22.136 A:middle
现在我们来看看怎样

00:04:22.136 --> 00:04:24.446 A:middle
创建大小为 N 的

00:04:24.536 --> 00:04:24.886 A:middle
MPS 向量

00:04:24.886 --> 00:04:26.856 A:middle
如果你还没有

00:04:26.856 --> 00:04:28.346 A:middle
Metal 缓冲区 那就需要先

00:04:28.346 --> 00:04:28.606 A:middle
创建一个

00:04:29.666 --> 00:04:30.666 A:middle
然后再为你的向量

00:04:30.666 --> 00:04:31.686 A:middle
创建一个描述符

00:04:32.526 --> 00:04:34.546 A:middle
请注意 你需要指定

00:04:34.726 --> 00:04:36.086 A:middle
向量的长度

00:04:36.666 --> 00:04:38.146 A:middle
因为向量可以

00:04:38.146 --> 00:04:39.946 A:middle
由原来 Metal 缓冲区的

00:04:39.946 --> 00:04:40.926 A:middle
一部分形成

00:04:41.716 --> 00:04:43.236 A:middle
并且可以在使用该向量

00:04:43.236 --> 00:04:44.556 A:middle
的内核中设置其他相关的

00:04:44.556 --> 00:04:45.016 A:middle
偏移量

00:04:45.996 --> 00:04:47.406 A:middle
最后使用

00:04:47.466 --> 00:04:49.586 A:middle
描述符从缓冲区

00:04:49.586 --> 00:04:50.906 A:middle
创建一个向量

00:04:52.966 --> 00:04:53.976 A:middle
现在我们来看看

00:04:53.976 --> 00:04:56.256 A:middle
如何创建一个 M 行

00:04:56.326 --> 00:04:57.906 A:middle
N 列的 MPS 矩阵

00:04:59.516 --> 00:05:00.906 A:middle
这和创建 MPS 向量

00:04:59.516 --> 00:05:00.906 A:middle
这和创建 MPS 向量

00:05:00.906 --> 00:05:02.916 A:middle
的方式非常类似

00:05:02.916 --> 00:05:04.006 A:middle
但有几点

00:05:04.006 --> 00:05:04.726 A:middle
需要注意

00:05:06.176 --> 00:05:08.256 A:middle
我们提供了一个方便的 API

00:05:08.256 --> 00:05:09.606 A:middle
你可以用它来查找

00:05:09.606 --> 00:05:11.966 A:middle
每个行值的推荐字节数

00:05:12.556 --> 00:05:13.756 A:middle
用于调整 Metal 缓冲区的大小

00:05:14.666 --> 00:05:15.716 A:middle
如果你选择使用 API

00:05:15.796 --> 00:05:17.246 A:middle
那么这就是

00:05:17.246 --> 00:05:18.816 A:middle
使用这个推荐值创建 Metal 缓冲区

00:05:18.816 --> 00:05:19.596 A:middle
的方法

00:05:20.596 --> 00:05:22.106 A:middle
并且这个 API 是完全

00:05:22.106 --> 00:05:24.416 A:middle
可以选择性使用的 但我们推荐使用

00:05:24.416 --> 00:05:25.136 A:middle
因为它的性能更好

00:05:25.986 --> 00:05:27.156 A:middle
其余的就简单了

00:05:28.256 --> 00:05:29.356 A:middle
你先为矩阵创建一个

00:05:29.356 --> 00:05:30.886 A:middle
描述符 然后创建一个

00:05:30.886 --> 00:05:32.346 A:middle
带有描述符的矩阵

00:05:34.936 --> 00:05:36.506 A:middle
既然刚刚我们讲过了

00:05:36.506 --> 00:05:37.806 A:middle
数据表示 那么现在

00:05:37.806 --> 00:05:39.046 A:middle
我们来看一下图元

00:05:39.896 --> 00:05:41.176 A:middle
对于矩阵-矩阵和

00:05:41.176 --> 00:05:43.136 A:middle
矩阵-向量的乘法 我们的

00:05:43.136 --> 00:05:44.586 A:middle
API 以

00:05:44.586 --> 00:05:46.036 A:middle
标准的 BLAS GEMM 和 GEMV

00:05:46.036 --> 00:05:46.766 A:middle
界面为模型

00:05:47.646 --> 00:05:48.846 A:middle
对于三角矩阵

00:05:48.846 --> 00:05:50.196 A:middle
矢量化和线性

00:05:50.196 --> 00:05:52.216 A:middle
求解器 我们的 API 以

00:05:52.216 --> 00:05:53.246 A:middle
标准的 LAPACK

00:05:53.246 --> 00:05:54.916 A:middle
分解和求解

00:05:54.916 --> 00:05:55.486 A:middle
界面为模型

00:05:55.846 --> 00:05:57.036 A:middle
所以如果你熟悉这些

00:05:57.036 --> 00:05:59.106 A:middle
界面 那对我们的 API

00:05:59.106 --> 00:06:00.526 A:middle
你也不会陌生

00:06:02.576 --> 00:06:04.216 A:middle
现在我们来看一个

00:06:04.216 --> 00:06:05.546 A:middle
非常简单的代码示例

00:06:05.836 --> 00:06:07.536 A:middle
我们要做矩阵的

00:06:07.536 --> 00:06:08.996 A:middle
乘法和计算

00:06:08.996 --> 00:06:10.426 A:middle
C = A 乘以 B

00:06:10.426 --> 00:06:12.716 A:middle
所以首先我们需要创建

00:06:12.716 --> 00:06:14.476 A:middle
矩阵 A B 和 C

00:06:14.706 --> 00:06:15.646 A:middle
但我知道大家已经知道怎么

00:06:15.646 --> 00:06:16.786 A:middle
操作了 因为在前一张幻灯片里我已经

00:06:16.836 --> 00:06:18.306 A:middle
讲过 所以我们继续往下看

00:06:19.336 --> 00:06:21.116 A:middle
现在我们要在 GPU 上

00:06:21.116 --> 00:06:22.596 A:middle
运行矩阵的乘法

00:06:23.886 --> 00:06:25.386 A:middle
首先像往常一样进行 Metal

00:06:25.466 --> 00:06:27.446 A:middle
设置来获取设备

00:06:27.446 --> 00:06:29.076 A:middle
命令队列和命令

00:06:29.076 --> 00:06:29.356 A:middle
缓冲区

00:06:29.356 --> 00:06:31.766 A:middle
然后我们需要创建

00:06:31.846 --> 00:06:33.186 A:middle
矩阵乘法内核

00:06:33.766 --> 00:06:35.196 A:middle
注意 你这里需要

00:06:35.196 --> 00:06:36.296 A:middle
指定结果的大小

00:06:36.826 --> 00:06:38.216 A:middle
因为这个内核可以

00:06:38.216 --> 00:06:39.896 A:middle
在矩阵的子区域上

00:06:39.896 --> 00:06:40.436 A:middle
运行

00:06:41.066 --> 00:06:45.576 A:middle
然后将这个内核编码

00:06:45.656 --> 00:06:47.056 A:middle
到 GPU 上 并让它开始

00:06:47.056 --> 00:06:47.476 A:middle
工作

00:06:47.476 --> 00:06:51.036 A:middle
我们已经在

00:06:51.036 --> 00:06:52.346 A:middle
开发者网站上提供了

00:06:52.586 --> 00:06:53.906 A:middle
矩阵乘法的示例代码

00:06:53.906 --> 00:06:56.096 A:middle
以及三角矩阵

00:06:56.096 --> 00:06:57.896 A:middle
向量化的代码

00:06:58.206 --> 00:06:59.556 A:middle
求解线性方程组的示例代码

00:06:59.556 --> 00:07:00.986 A:middle
很快也要发布

00:06:59.556 --> 00:07:00.986 A:middle
很快也要发布

00:07:03.026 --> 00:07:05.526 A:middle
这就是我们关于

00:07:05.756 --> 00:07:07.026 A:middle
线性代数运算的内容

00:07:07.386 --> 00:07:08.996 A:middle
现在我们来看下一个

00:07:08.996 --> 00:07:10.756 A:middle
主题 也就是

00:07:10.756 --> 00:07:12.156 A:middle
在 GPU 上加速机器

00:07:12.156 --> 00:07:12.636 A:middle
学习图元

00:07:14.116 --> 00:07:16.246 A:middle
在今年的 WWDC

00:07:16.246 --> 00:07:17.906 A:middle
大会上有很多关于

00:07:17.906 --> 00:07:19.156 A:middle
机器学习的会议

00:07:19.456 --> 00:07:20.346 A:middle
而我们就是机器学习

00:07:20.346 --> 00:07:21.416 A:middle
团体的一部分

00:07:22.306 --> 00:07:23.586 A:middle
这一页展示了

00:07:23.586 --> 00:07:24.206 A:middle
整体的架构

00:07:25.086 --> 00:07:26.606 A:middle
作为一名应用程序开发人员

00:07:26.816 --> 00:07:27.876 A:middle
你可以通过使用

00:07:27.876 --> 00:07:28.816 A:middle
高级域

00:07:28.816 --> 00:07:30.956 A:middle
特定框架

00:07:30.996 --> 00:07:32.856 A:middle
比如分区框架

00:07:32.856 --> 00:07:34.456 A:middle
和依赖于 Core ML 框架的

00:07:34.456 --> 00:07:35.566 A:middle
自然语言处理框架

00:07:35.616 --> 00:07:37.496 A:middle
为应用程序添加

00:07:37.496 --> 00:07:38.366 A:middle
机器学习功能

00:07:39.216 --> 00:07:40.376 A:middle
Core ML 框架由

00:07:40.446 --> 00:07:42.316 A:middle
CPU 上的

00:07:42.316 --> 00:07:44.076 A:middle
加速框架 BNNS

00:07:44.076 --> 00:07:44.606 A:middle
原语

00:07:45.066 --> 00:07:46.176 A:middle
以及 GPU 上的

00:07:47.066 --> 00:07:49.046 A:middle
机器学习和

00:07:49.046 --> 00:07:51.946 A:middle
MPS 框架驱动构成

00:07:51.946 --> 00:07:52.706 A:middle
但是如果你正在编写一个

00:07:52.706 --> 00:07:54.556 A:middle
使用 Metal 的应用程序

00:07:54.906 --> 00:07:56.046 A:middle
那么你可以直接使用

00:07:56.046 --> 00:07:58.176 A:middle
MPS框架 我稍后

00:07:58.176 --> 00:07:59.386 A:middle
将在这个会议中向你展示如何操作

00:08:01.666 --> 00:08:02.676 A:middle
让我们从正在讲的

00:08:02.736 --> 00:08:03.486 A:middle
这个部分开始

00:08:04.246 --> 00:08:05.116 A:middle
什么是深度学习

00:08:05.366 --> 00:08:06.236 A:middle
什么是机器学习

00:08:07.686 --> 00:08:08.766 A:middle
想象一下这是你

00:08:08.766 --> 00:08:11.436 A:middle
当你看到一个图像

00:08:11.436 --> 00:08:13.076 A:middle
你立刻就能知道上面描绘的

00:08:13.076 --> 00:08:13.316 A:middle
是什么

00:08:13.416 --> 00:08:13.956 A:middle
这是一只熊猫

00:08:14.936 --> 00:08:16.686 A:middle
现在想一想你的

00:08:16.686 --> 00:08:18.006 A:middle
iPhone 上所有的图像

00:08:18.596 --> 00:08:20.206 A:middle
或者你家庭相册中的

00:08:20.206 --> 00:08:20.996 A:middle
所有照片

00:08:21.606 --> 00:08:22.646 A:middle
或者互联网上的

00:08:22.646 --> 00:08:22.966 A:middle
所有图像

00:08:23.816 --> 00:08:27.096 A:middle
没有人可以

00:08:27.096 --> 00:08:28.816 A:middle
将这么多的图像分类

00:08:29.086 --> 00:08:30.506 A:middle
但深度学习算法就是

00:08:30.506 --> 00:08:32.056 A:middle
专门为此而

00:08:32.056 --> 00:08:32.196 A:middle
设计的

00:08:33.186 --> 00:08:34.416 A:middle
它们可以用于筛选

00:08:34.416 --> 00:08:35.576 A:middle
大量数据

00:08:36.015 --> 00:08:37.866 A:middle
并回答诸如

00:08:37.996 --> 00:08:41.676 A:middle
图像的内容是什么 等一系列问题

00:08:42.236 --> 00:08:43.306 A:middle
深度学习算法有

00:08:43.405 --> 00:08:43.905 A:middle
两个阶段

00:08:44.206 --> 00:08:45.156 A:middle
训练和推理

00:08:45.426 --> 00:08:46.426 A:middle
让我们先来讲一下

00:08:46.426 --> 00:08:46.736 A:middle
训练

00:08:47.946 --> 00:08:49.246 A:middle
让我们用一个

00:08:49.246 --> 00:08:49.676 A:middle
例子

00:08:49.676 --> 00:08:51.326 A:middle
我们训练一个系统来进行

00:08:51.326 --> 00:08:51.716 A:middle
图像分类

00:08:52.586 --> 00:08:53.536 A:middle
这个系统训练可以

00:08:53.536 --> 00:08:56.696 A:middle
进行图像分类 例如

00:08:56.696 --> 00:08:58.066 A:middle
你想让系统识别

00:08:58.126 --> 00:08:58.536 A:middle
动物

00:08:58.966 --> 00:09:00.516 A:middle
要让它识别猫

00:09:00.516 --> 00:09:02.126 A:middle
那么你就需要为这个系统输入

00:08:58.966 --> 00:09:00.516 A:middle
要让它识别猫

00:09:00.516 --> 00:09:02.126 A:middle
那么你就需要为这个系统输入

00:09:02.556 --> 00:09:04.196 A:middle
大量的包含

00:09:04.196 --> 00:09:06.126 A:middle
猫 兔子和

00:09:06.126 --> 00:09:07.336 A:middle
所有其他你希望

00:09:07.336 --> 00:09:08.406 A:middle
系统能识别动物的

00:09:08.406 --> 00:09:08.866 A:middle
标签的图像

00:09:10.546 --> 00:09:12.316 A:middle
而这个训练步骤是

00:09:12.316 --> 00:09:13.916 A:middle
一次性的

00:09:13.916 --> 00:09:16.476 A:middle
它消耗计算能力且劳动

00:09:16.566 --> 00:09:16.786 A:middle
强度大

00:09:17.896 --> 00:09:19.076 A:middle
它通常是离线完成的

00:09:19.696 --> 00:09:20.896 A:middle
但是训练阶段的结果

00:09:20.896 --> 00:09:22.336 A:middle
是下一阶段

00:09:23.306 --> 00:09:24.656 A:middle
也就是推理阶段

00:09:24.656 --> 00:09:25.856 A:middle
所需要的训练参数

00:09:26.906 --> 00:09:28.096 A:middle
这时候可以将一个从未见过的

00:09:28.186 --> 00:09:30.156 A:middle
新图像呈现在

00:09:30.156 --> 00:09:31.736 A:middle
你的系统中

00:09:31.736 --> 00:09:33.186 A:middle
并对其进行分类

00:09:33.186 --> 00:09:33.396 A:middle
这是一个帽子

00:09:35.126 --> 00:09:37.016 A:middle
我们为第二阶段

00:09:37.016 --> 00:09:38.306 A:middle
也就是推理阶段提供视图

00:09:38.306 --> 00:09:38.526 A:middle
加速

00:09:39.096 --> 00:09:40.966 A:middle
具体来说 去年我们

00:09:40.966 --> 00:09:42.936 A:middle
讨论了在 GPU 上

00:09:43.056 --> 00:09:44.296 A:middle
构建卷积神经网络的

00:09:44.296 --> 00:09:45.716 A:middle
构建块 用于

00:09:45.716 --> 00:09:46.146 A:middle
推理

00:09:48.466 --> 00:09:50.176 A:middle
所以在继续介绍

00:09:50.176 --> 00:09:51.966 A:middle
今年推出的

00:09:51.966 --> 00:09:52.826 A:middle
机器学习的新功能

00:09:52.856 --> 00:09:53.936 A:middle
之前 我们将

00:09:53.936 --> 00:09:55.136 A:middle
回顾一下

00:09:55.136 --> 00:09:56.886 A:middle
去年演讲中介绍的

00:09:56.886 --> 00:09:58.146 A:middle
一些核心信息

00:09:58.736 --> 00:10:00.416 A:middle
比如 什么是卷积

00:09:58.736 --> 00:10:00.416 A:middle
比如 什么是卷积

00:10:00.416 --> 00:10:00.966 A:middle
神经网络

00:10:02.396 --> 00:10:04.326 A:middle
在这之后 我们才会

00:10:04.326 --> 00:10:06.056 A:middle
谈到今年为

00:10:06.106 --> 00:10:06.836 A:middle
卷积神经网络添加的

00:10:06.836 --> 00:10:07.906 A:middle
新原语

00:10:07.966 --> 00:10:09.426 A:middle
然后我们将

00:10:09.426 --> 00:10:11.146 A:middle
介绍一种新的 易用的

00:10:11.516 --> 00:10:12.636 A:middle
神经网络图像 API

00:10:13.166 --> 00:10:14.746 A:middle
而我们最后一个话题是

00:10:14.746 --> 00:10:15.726 A:middle
循环神经网络

00:10:18.606 --> 00:10:20.976 A:middle
让我们按照刚才的概述开始讲

00:10:21.106 --> 00:10:22.066 A:middle
那么 什么是卷积神经

00:10:22.066 --> 00:10:22.366 A:middle
网络

00:10:24.446 --> 00:10:25.576 A:middle
卷积神经网络

00:10:25.576 --> 00:10:27.426 A:middle
受生物学启发而设计出来

00:10:27.426 --> 00:10:28.836 A:middle
用于近似

00:10:28.836 --> 00:10:29.246 A:middle
视觉皮质

00:10:29.796 --> 00:10:31.406 A:middle
所以让我们想一下

00:10:31.406 --> 00:10:33.076 A:middle
大脑是如何处理视觉输入的

00:10:34.256 --> 00:10:35.636 A:middle
在视觉皮质中

00:10:35.736 --> 00:10:37.056 A:middle
接收信息的第一层

00:10:37.056 --> 00:10:39.396 A:middle
神经元对

00:10:39.396 --> 00:10:40.786 A:middle
特定的边缘和色块很

00:10:40.886 --> 00:10:41.196 A:middle
敏感

00:10:42.366 --> 00:10:43.466 A:middle
而大脑区域进一步的

00:10:43.466 --> 00:10:45.966 A:middle
视觉传递会对

00:10:45.966 --> 00:10:47.596 A:middle
更复杂的结构做出反应

00:10:47.596 --> 00:10:49.366 A:middle
比如朋友的面孔或者

00:10:49.366 --> 00:10:50.166 A:middle
动物 比如猫

00:10:50.996 --> 00:10:53.646 A:middle
所以类似的 卷积神经网络

00:10:53.646 --> 00:10:55.836 A:middle
是多层次结构

00:10:55.836 --> 00:10:58.176 A:middle
其中高级特征

00:10:58.296 --> 00:10:59.836 A:middle
源于低级

00:10:59.836 --> 00:11:00.246 A:middle
特征

00:10:59.836 --> 00:11:00.246 A:middle
特征

00:11:01.156 --> 00:11:02.516 A:middle
因此你的网络中的前几个

00:11:02.516 --> 00:11:04.566 A:middle
层次会对低级特征

00:11:04.566 --> 00:11:06.766 A:middle
比如边缘和色块做出

00:11:06.826 --> 00:11:07.196 A:middle
响应

00:11:07.886 --> 00:11:10.646 A:middle
而随后的层次

00:11:10.766 --> 00:11:12.516 A:middle
对逐渐复杂的特征

00:11:12.616 --> 00:11:14.886 A:middle
比如面孔 做出响应

00:11:16.106 --> 00:11:17.406 A:middle
我一直在说特征

00:11:17.846 --> 00:11:19.556 A:middle
你可以将特征视为

00:11:19.556 --> 00:11:21.176 A:middle
一个过滤器 可以过滤输入的

00:11:21.176 --> 00:11:22.706 A:middle
数据 就是那个特征

00:11:25.316 --> 00:11:26.906 A:middle
这里列出了我们在

00:11:26.976 --> 00:11:28.076 A:middle
iOS 10 中提供的

00:11:28.076 --> 00:11:29.356 A:middle
所有卷积神经网络原语

00:11:29.756 --> 00:11:31.806 A:middle
在这个概述中我将

00:11:31.806 --> 00:11:33.686 A:middle
只讲核心

00:11:34.176 --> 00:11:35.146 A:middle
卷积层

00:11:35.216 --> 00:11:36.426 A:middle
CNN 的核心

00:11:36.546 --> 00:11:36.756 A:middle
构建块

00:11:36.756 --> 00:11:39.046 A:middle
这些原语的其余部分

00:11:39.106 --> 00:11:40.906 A:middle
在我们的演讲文档中

00:11:40.906 --> 00:11:42.266 A:middle
有很详细的

00:11:42.266 --> 00:11:43.076 A:middle
介绍

00:11:43.196 --> 00:11:44.566 A:middle
Pooling Fully-Connected 和

00:11:44.616 --> 00:11:45.156 A:middle
SoftMax.

00:11:45.746 --> 00:11:46.856 A:middle
你可以找到和这些相关的

00:11:46.856 --> 00:11:47.056 A:middle
信息

00:11:48.626 --> 00:11:50.386 A:middle
所以让我们来谈谈

00:11:50.386 --> 00:11:51.186 A:middle
核心构建块

00:11:52.596 --> 00:11:54.216 A:middle
这个核心卷积层的功能

00:11:54.216 --> 00:11:56.196 A:middle
是识别输入

00:11:56.196 --> 00:11:57.766 A:middle
数据中的特征

00:11:57.766 --> 00:11:58.906 A:middle
它之所以被称为

00:11:58.906 --> 00:12:01.076 A:middle
卷积层是因为

00:11:58.906 --> 00:12:01.076 A:middle
卷积层是因为

00:12:01.126 --> 00:12:02.576 A:middle
它对输入进行

00:12:02.576 --> 00:12:02.846 A:middle
卷积操作

00:12:03.916 --> 00:12:05.246 A:middle
我们回想一下常规的

00:12:05.246 --> 00:12:06.076 A:middle
卷积如何进行

00:12:06.906 --> 00:12:08.146 A:middle
你有输入

00:12:08.186 --> 00:12:09.366 A:middle
输出和过滤器

00:12:10.366 --> 00:12:12.386 A:middle
使用输入数据来

00:12:12.386 --> 00:12:14.506 A:middle
调用过滤器 你需要将

00:12:14.756 --> 00:12:16.626 A:middle
过滤器中的

00:12:16.626 --> 00:12:18.446 A:middle
每个值与输入数据中的值相乘

00:12:18.446 --> 00:12:19.686 A:middle
并将该信息组合

00:12:19.686 --> 00:12:21.106 A:middle
从而计算出单个输出值

00:12:22.046 --> 00:12:23.536 A:middle
对于其余的输出像素

00:12:23.636 --> 00:12:25.166 A:middle
你也进行同样的操作

00:12:27.596 --> 00:12:29.856 A:middle
而现在卷积层则是

00:12:29.856 --> 00:12:31.606 A:middle
常规卷积的

00:12:31.606 --> 00:12:32.226 A:middle
一般化

00:12:32.396 --> 00:12:34.666 A:middle
它允许你拥有多个

00:12:34.666 --> 00:12:35.136 A:middle
过滤器

00:12:35.526 --> 00:12:37.536 A:middle
所以你可以拥有和输出通道

00:12:37.536 --> 00:12:38.916 A:middle
一样多的过滤器

00:12:38.916 --> 00:12:39.816 A:middle
这种情况下是 16 个

00:12:41.666 --> 00:12:43.046 A:middle
这些过滤器将

00:12:43.046 --> 00:12:44.656 A:middle
过滤具有特定

00:12:44.656 --> 00:12:46.006 A:middle
特征的输入数据

00:12:47.726 --> 00:12:49.016 A:middle
现在想象一下你正在

00:12:49.016 --> 00:12:50.266 A:middle
使用 RGB 数据

00:12:50.356 --> 00:12:52.186 A:middle
那么你的输入实际上

00:12:52.186 --> 00:12:53.266 A:middle
有三个通道

00:12:54.156 --> 00:12:56.276 A:middle
鉴于 CNN 的工作原理

00:12:56.476 --> 00:12:58.816 A:middle
这意味着你需要三组过滤器

00:12:58.886 --> 00:13:00.156 A:middle
每组 16 个

00:12:58.886 --> 00:13:00.156 A:middle
每组 16 个

00:13:00.866 --> 00:13:02.576 A:middle
每个输入通道一组

00:13:03.856 --> 00:13:05.916 A:middle
然后将这些滤波器

00:13:05.916 --> 00:13:07.296 A:middle
分别应用于

00:13:08.486 --> 00:13:09.036 A:middle
输入数据

00:13:09.036 --> 00:13:10.816 A:middle
然后最后一步将

00:13:10.816 --> 00:13:12.386 A:middle
所有这些信息合并

00:13:12.386 --> 00:13:13.796 A:middle
计算出单个输出像素

00:13:15.516 --> 00:13:17.156 A:middle
这就是我们对

00:13:17.156 --> 00:13:18.006 A:middle
卷积层的概述

00:13:18.536 --> 00:13:19.526 A:middle
现在我们来谈谈

00:13:19.576 --> 00:13:20.846 A:middle
为卷积神经网络

00:13:20.846 --> 00:13:22.026 A:middle
添加的新原语

00:13:22.116 --> 00:13:25.176 A:middle
如你所见 我们添加了

00:13:25.176 --> 00:13:25.686 A:middle
不少原语

00:13:27.736 --> 00:13:29.096 A:middle
但我接下来只讲一下

00:13:29.096 --> 00:13:31.476 A:middle
黄色的部分

00:13:31.476 --> 00:13:33.206 A:middle
其他的比如 L2Norm

00:13:33.256 --> 00:13:34.686 A:middle
Pooling Resampling

00:13:34.686 --> 00:13:36.086 A:middle
和 Up-sampling 这些都将

00:13:36.086 --> 00:13:37.396 A:middle
在我们的文档中介绍

00:13:39.286 --> 00:13:40.986 A:middle
那让我们来看看对核心

00:13:40.986 --> 00:13:42.786 A:middle
卷积层进行的更新

00:13:43.916 --> 00:13:45.146 A:middle
我们过去只支持

00:13:45.186 --> 00:13:46.716 A:middle
单精度浮点权重

00:13:46.716 --> 00:13:47.026 A:middle
类型

00:13:47.466 --> 00:13:49.076 A:middle
现在为了帮你减少

00:13:49.076 --> 00:13:51.126 A:middle
内存占用并

00:13:51.126 --> 00:13:51.966 A:middle
提高网络

00:13:51.966 --> 00:13:52.326 A:middle
性能

00:13:52.876 --> 00:13:54.546 A:middle
我们还支持半精度

00:13:54.546 --> 00:13:56.466 A:middle
浮点 8 位整数

00:13:56.806 --> 00:13:58.076 A:middle
和二进制权重类型

00:13:59.496 --> 00:14:01.006 A:middle
我们过去只支持标准

00:13:59.496 --> 00:14:01.006 A:middle
我们过去只支持标准

00:14:01.006 --> 00:14:02.676 A:middle
卷积 现在

00:14:02.736 --> 00:14:03.926 A:middle
我们也支持二进制和

00:14:03.926 --> 00:14:04.646 A:middle
XNOR 卷积

00:14:04.986 --> 00:14:06.096 A:middle
扩张卷积

00:14:06.096 --> 00:14:08.406 A:middle
子像素卷积和

00:14:08.406 --> 00:14:09.366 A:middle
卷积转置

00:14:09.366 --> 00:14:09.996 A:middle
操作

00:14:11.056 --> 00:14:12.156 A:middle
其中许多是

00:14:12.156 --> 00:14:13.716 A:middle
正交的 所以如果你愿意的话

00:14:14.006 --> 00:14:15.946 A:middle
甚至可以进行

00:14:15.946 --> 00:14:16.276 A:middle
扩大子像素卷积

00:14:17.706 --> 00:14:18.486 A:middle
让我们一个一个地

00:14:18.486 --> 00:14:19.046 A:middle
看一下

00:14:20.806 --> 00:14:22.216 A:middle
二进制和 XNOR 卷积

00:14:22.256 --> 00:14:24.276 A:middle
与常规卷积执行

00:14:24.306 --> 00:14:26.336 A:middle
相同的精确操作 但它们具有

00:14:26.336 --> 00:14:28.016 A:middle
更好的性能 而且能够

00:14:28.476 --> 00:14:29.566 A:middle
节省极大的空间

00:14:30.016 --> 00:14:31.726 A:middle
所以在常规卷积中

00:14:31.726 --> 00:14:33.546 A:middle
你可能有浮点输入

00:14:33.846 --> 00:14:35.166 A:middle
和浮点权重

00:14:36.036 --> 00:14:37.446 A:middle
而二进制卷积能够

00:14:37.516 --> 00:14:39.236 A:middle
允许你

00:14:39.236 --> 00:14:41.266 A:middle
使用二进制权重的全尺寸

00:14:41.266 --> 00:14:41.486 A:middle
输入

00:14:42.416 --> 00:14:44.776 A:middle
而对于 XNOR 卷积

00:14:44.776 --> 00:14:46.706 A:middle
首先

00:14:47.226 --> 00:14:48.626 A:middle
你的输入会被转换为

00:14:48.626 --> 00:14:50.826 A:middle
二进制的 从而使输入

00:14:51.176 --> 00:14:52.396 A:middle
和权重都是二进制的

00:14:53.476 --> 00:14:55.286 A:middle
在常规卷积中

00:14:55.286 --> 00:14:57.066 A:middle
输入必须与权重

00:14:57.106 --> 00:14:57.446 A:middle
相乘

00:14:57.886 --> 00:14:59.876 A:middle
而对于 XNOR 卷积

00:14:59.876 --> 00:15:01.806 A:middle
分离变成了一个简单的 XNOR

00:14:59.876 --> 00:15:01.806 A:middle
分离变成了一个简单的 XNOR

00:15:01.806 --> 00:15:02.336 A:middle
操作

00:15:04.746 --> 00:15:06.066 A:middle
现在我们来谈谈扩张

00:15:06.066 --> 00:15:06.656 A:middle
卷积

00:15:07.626 --> 00:15:08.996 A:middle
我们已经知道常规

00:15:08.996 --> 00:15:09.786 A:middle
卷积如何工作

00:15:10.486 --> 00:15:12.396 A:middle
你需要用过滤器对

00:15:12.396 --> 00:15:13.656 A:middle
输入数据进行计算

00:15:13.656 --> 00:15:14.706 A:middle
来得到单个输出值

00:15:17.526 --> 00:15:18.786 A:middle
但如果你正在研究一种

00:15:18.786 --> 00:15:21.736 A:middle
需要将更广泛的

00:15:21.736 --> 00:15:24.846 A:middle
输入数据进行

00:15:25.216 --> 00:15:26.166 A:middle
全局集成的算法

00:15:26.816 --> 00:15:28.466 A:middle
那么你就不能用 3 乘 3 的内核

00:15:28.536 --> 00:15:30.496 A:middle
而应该用一个 5 乘 5 的内核

00:15:31.736 --> 00:15:32.476 A:middle
来进一步研究

00:15:33.026 --> 00:15:33.666 A:middle
但是这样的话就要进行

00:15:33.666 --> 00:15:34.756 A:middle
更加大量的计算

00:15:35.256 --> 00:15:37.266 A:middle
另外一种方法是使用

00:15:37.266 --> 00:15:39.046 A:middle
扩展卷积这样

00:15:39.046 --> 00:15:43.206 A:middle
你就可以使用

00:15:43.206 --> 00:15:45.256 A:middle
扩展因子在卷积

00:15:45.256 --> 00:15:46.836 A:middle
内核里引入间隔

00:15:46.836 --> 00:15:48.836 A:middle
从而可以

00:15:48.836 --> 00:15:50.576 A:middle
只使用 3 乘 3 的内核

00:15:50.576 --> 00:15:52.676 A:middle
就能够进行进一步的

00:15:52.676 --> 00:15:53.016 A:middle
研究

00:15:54.996 --> 00:15:55.876 A:middle
现在我们来谈谈

00:15:55.946 --> 00:15:57.266 A:middle
亚光圈卷积和

00:15:57.266 --> 00:15:58.846 A:middle
卷积转置原语

00:15:59.766 --> 00:16:01.266 A:middle
常用于图像

00:16:01.266 --> 00:16:01.836 A:middle
放大

00:16:03.066 --> 00:16:04.126 A:middle
让我们想一下图象放大

00:16:04.176 --> 00:16:05.366 A:middle
通常是如何进行的

00:16:05.456 --> 00:16:07.456 A:middle
现在你有输入数据

00:16:07.516 --> 00:16:09.196 A:middle
并想用因子 2

00:16:09.196 --> 00:16:09.956 A:middle
将其放大

00:16:12.336 --> 00:16:13.376 A:middle
所以你将有一些

00:16:13.376 --> 00:16:14.566 A:middle
缺失的像素需要计算

00:16:15.216 --> 00:16:16.536 A:middle
并且通常扩大是

00:16:16.536 --> 00:16:18.156 A:middle
用恒定过滤器进行的

00:16:18.156 --> 00:16:18.606 A:middle
固定操作

00:16:18.766 --> 00:16:20.336 A:middle
例如 盒式

00:16:20.336 --> 00:16:22.336 A:middle
过滤器如何帮助你进行图像

00:16:22.386 --> 00:16:22.756 A:middle
扩大

00:16:23.416 --> 00:16:25.146 A:middle
盒式过滤器获取

00:16:25.316 --> 00:16:28.006 A:middle
已知像素 并将

00:16:28.006 --> 00:16:29.326 A:middle
已知的数据复制到缺失的

00:16:29.326 --> 00:16:30.786 A:middle
位置从而获得

00:16:30.786 --> 00:16:31.216 A:middle
扩大的结果

00:16:33.326 --> 00:16:35.196 A:middle
对于子像素卷积

00:16:35.196 --> 00:16:36.646 A:middle
你的过滤器不是常数

00:16:36.976 --> 00:16:38.226 A:middle
过滤器会从数据中

00:16:38.226 --> 00:16:38.626 A:middle
学习

00:16:38.766 --> 00:16:40.286 A:middle
它们是经过训练的参数

00:16:40.716 --> 00:16:41.786 A:middle
你可以从训练阶段

00:16:41.786 --> 00:16:42.906 A:middle
获得这些参数 系统接受

00:16:42.986 --> 00:16:45.106 A:middle
训练从而完成这个任务

00:16:45.106 --> 00:16:45.946 A:middle
完成图像扩大

00:16:47.086 --> 00:16:49.176 A:middle
所以对于 2 倍放大有 4 个

00:16:49.236 --> 00:16:49.686 A:middle
过滤器

00:16:49.806 --> 00:16:51.656 A:middle
对于 4 倍放大有 16 个

00:16:51.656 --> 00:16:52.656 A:middle
过滤器等等

00:16:53.566 --> 00:16:55.446 A:middle
所以对于 2 倍放大

00:16:55.446 --> 00:16:57.456 A:middle
我们需要用 4 个过滤器

00:16:57.456 --> 00:16:58.166 A:middle
并把它应用在输入数据上

00:16:58.166 --> 00:17:00.216 A:middle
然后对刚才的操作输出

00:16:58.166 --> 00:17:00.216 A:middle
然后对刚才的操作输出

00:17:00.216 --> 00:17:02.076 A:middle
进行重新调整 从而获得

00:17:02.076 --> 00:17:03.476 A:middle
最终的全分辨率

00:17:03.476 --> 00:17:03.856 A:middle
图像

00:17:04.925 --> 00:17:06.445 A:middle
现在让我们来谈谈

00:17:06.445 --> 00:17:08.076 A:middle
如何使用卷积转置原语

00:17:08.156 --> 00:17:09.536 A:middle
来放大图像

00:17:10.435 --> 00:17:12.026 A:middle
我们有输入

00:17:12.026 --> 00:17:13.466 A:middle
但还需要计算

00:17:13.465 --> 00:17:14.146 A:middle
缺失的数据

00:17:14.945 --> 00:17:16.665 A:middle
所以这个原语计算

00:17:17.156 --> 00:17:18.616 A:middle
缺失数据的方法是

00:17:18.616 --> 00:17:19.586 A:middle
它使用一种

00:17:19.586 --> 00:17:21.296 A:middle
卷积传递给

00:17:21.296 --> 00:17:23.165 A:middle
有间隙的中间结果

00:17:23.166 --> 00:17:24.596 A:middle
然后计算每个输出像素

00:17:25.185 --> 00:17:27.316 A:middle
这就是如何得到

00:17:27.356 --> 00:17:28.256 A:middle
放大的结果

00:17:31.136 --> 00:17:32.216 A:middle
现在我们将向你展示

00:17:32.216 --> 00:17:33.556 A:middle
如何使用这些新的

00:17:33.556 --> 00:17:35.046 A:middle
卷积原语在

00:17:35.046 --> 00:17:36.626 A:middle
真实世界的网络中如何操作

00:17:37.096 --> 00:17:38.606 A:middle
我们选用了这个着色

00:17:38.606 --> 00:17:41.486 A:middle
网络 它可以输入黑白

00:17:41.486 --> 00:17:42.886 A:middle
图像 然后输出

00:17:42.886 --> 00:17:44.356 A:middle
彩色图像

00:17:44.356 --> 00:17:47.156 A:middle
而这个特定的网络能够

00:17:47.236 --> 00:17:48.426 A:middle
使用扩张卷积原语

00:17:48.426 --> 00:17:50.396 A:middle
更快地整合更广泛

00:17:50.396 --> 00:17:52.296 A:middle
全局环境

00:17:52.926 --> 00:17:54.756 A:middle
并且它使用卷积

00:17:54.756 --> 00:17:56.726 A:middle
转置原语来提高

00:17:56.726 --> 00:17:57.776 A:middle
网络的结果

00:18:00.166 --> 00:18:01.276 A:middle
现在我们来看看这个

00:18:01.666 --> 00:18:03.966 A:middle
着色网络怎样运行

00:18:10.226 --> 00:18:11.466 A:middle
在这个演示中 我们

00:18:11.466 --> 00:18:12.886 A:middle
收集了一些黑白

00:18:12.886 --> 00:18:14.046 A:middle
图像 比如这个

00:18:14.046 --> 00:18:14.406 A:middle
狮子

00:18:15.046 --> 00:18:16.416 A:middle
一旦我点击这个

00:18:16.416 --> 00:18:17.796 A:middle
图像 着色网络

00:18:17.796 --> 00:18:20.046 A:middle
将在这个设备上

00:18:20.046 --> 00:18:21.126 A:middle
运行 然后我们将看到一个

00:18:21.126 --> 00:18:21.946 A:middle
彩色的图像

00:18:23.906 --> 00:18:25.456 A:middle
让我们再试试另外一个例子

00:18:25.456 --> 00:18:27.046 A:middle
这是一座美丽的雪山

00:18:27.046 --> 00:18:27.616 A:middle
图像

00:18:28.836 --> 00:18:30.036 A:middle
我们看到现在它是彩色的了

00:18:31.586 --> 00:18:33.756 A:middle
还有这个美丽可爱的图像

00:18:33.756 --> 00:18:35.016 A:middle
一位爸爸和女儿在弹

00:18:35.016 --> 00:18:35.366 A:middle
吉他

00:18:35.366 --> 00:18:37.386 A:middle
你可以看到现在图像

00:18:37.386 --> 00:18:38.026 A:middle
是彩色的了

00:18:39.516 --> 00:18:40.896 A:middle
还有这个图像我真的很喜欢

00:18:40.896 --> 00:18:42.306 A:middlee
一只棕熊在森林里

00:18:42.356 --> 00:18:42.696 A:middle
散步

00:18:42.696 --> 00:18:43.756 A:middle
所以我觉得这个网络

00:18:43.786 --> 00:18:45.146 A:middle
效果非常不错

00:18:46.886 --> 00:18:48.726 A:middle
好了 这就是现场

00:18:48.726 --> 00:18:48.916 A:middle
演示

00:18:49.516 --> 00:18:54.686 A:middle
[掌声]

00:18:55.186 --> 00:18:55.796 A:middle
谢谢

00:18:57.766 --> 00:18:59.216 A:middle
所以我们添加了所有这些新的

00:18:59.216 --> 00:19:01.456 A:middle
卷积 CNN 原语 但

00:18:59.216 --> 00:19:01.456 A:middle
卷积 CNN 原语 但

00:19:01.456 --> 00:19:02.056 A:middle
这并不是全部

00:19:02.976 --> 00:19:04.666 A:middle
我们还返回并改进了

00:19:04.666 --> 00:19:06.046 A:middle
iOS 10 中可用的

00:19:06.206 --> 00:19:07.936 A:middle
一些核心 CNN 内核

00:19:07.936 --> 00:19:09.646 A:middle
的性能

00:19:10.406 --> 00:19:11.776 A:middle
这个图像会显示

00:19:11.806 --> 00:19:13.846 A:middle
Inception-v3 网络的

00:19:13.846 --> 00:19:15.386 A:middle
性能 这是一种常用的

00:19:15.386 --> 00:19:16.936 A:middle
图像识别

00:19:17.056 --> 00:19:17.546 A:middle
网络

00:19:18.756 --> 00:19:20.396 A:middle
它显示了这个网络

00:19:20.396 --> 00:19:22.196 A:middle
在 iOS 11 中的性能

00:19:22.196 --> 00:19:23.786 A:middle
正如你所看到的 我们

00:19:23.786 --> 00:19:25.866 A:middle
在不同的 iOS 硬件上

00:19:25.866 --> 00:19:27.546 A:middle
为你带来了至少 20％

00:19:27.756 --> 00:19:28.696 A:middle
的性能提升

00:19:30.406 --> 00:19:33.786 A:middle
现在我们来谈谈新的

00:19:33.786 --> 00:19:37.096 A:middle
神经网络图像 API

00:19:37.716 --> 00:19:40.036 A:middle
神经网络通常

00:19:40.036 --> 00:19:41.416 A:middle
使用图像抽象化来

00:19:41.416 --> 00:19:42.476 A:middle
描述 就像这个

00:19:42.476 --> 00:19:43.506 A:middle
Inception-v3 网络的

00:19:43.506 --> 00:19:44.616 A:middle
可视化一样

00:19:44.616 --> 00:19:46.696 A:middle
我们现在可以使用

00:19:46.696 --> 00:19:48.706 A:middle
新的图像 API 来做到

00:19:48.706 --> 00:19:48.966 A:middle
这一点

00:19:50.446 --> 00:19:51.556 A:middle
所以让我们将这些初始模块中的一个

00:19:51.556 --> 00:19:53.186 A:middle
放大一下

00:19:54.676 --> 00:19:56.496 A:middle
你有过滤节点可以

00:19:56.496 --> 00:19:58.176 A:middle
描述对数据

00:19:58.176 --> 00:19:59.216 A:middle
执行的操作

00:19:59.526 --> 00:20:01.146 A:middle
比如卷积

00:19:59.526 --> 00:20:01.146 A:middle
比如卷积

00:20:01.146 --> 00:20:01.566 A:middle
池化等

00:20:02.556 --> 00:20:04.316 A:middle
同时你有图像节点

00:20:04.316 --> 00:20:05.736 A:middle
可以描述数据如何在

00:20:05.786 --> 00:20:06.546 A:middle
这些不同操作之间

00:20:06.546 --> 00:20:07.096 A:middle
流动

00:20:07.826 --> 00:20:11.306 A:middle
那么我们为什么要添加这个新的图像

00:20:11.306 --> 00:20:11.556 A:middle
API 呢

00:20:11.926 --> 00:20:13.156 A:middle
因为它很好使用

00:20:13.686 --> 00:20:14.656 A:middle
你可以获得整个

00:20:14.656 --> 00:20:16.116 A:middle
网络的紧凑

00:20:16.116 --> 00:20:18.326 A:middle
表示 并将其保存到

00:20:18.326 --> 00:20:20.356 A:middle
磁盘里 还可以将其还原

00:20:20.466 --> 00:20:21.546 A:middle
它可以在平台间运行

00:20:23.166 --> 00:20:24.426 A:middle
你只需要将图形

00:20:24.426 --> 00:20:26.366 A:middle
进行一次初始化 然后就可以

00:20:26.366 --> 00:20:27.716 A:middle
重新用在多个输入

00:20:27.716 --> 00:20:28.106 A:middle
图像里了

00:20:29.516 --> 00:20:31.476 A:middle
仅仅通过一次调用

00:20:31.476 --> 00:20:34.056 A:middle
你就可以在 GPU 上对整个图形

00:20:34.056 --> 00:20:34.346 A:middle
进行操作

00:20:36.276 --> 00:20:37.536 A:middle
没有中间的图像

00:20:37.536 --> 00:20:39.196 A:middle
需要管理 你只需要

00:20:39.196 --> 00:20:40.756 A:middle
做好输入和

00:20:40.756 --> 00:20:41.036 A:middle
输出

00:20:42.146 --> 00:20:45.016 A:middle
在内部我们使用 Metal 堆

00:20:45.016 --> 00:20:46.796 A:middle
来确保所有

00:20:46.796 --> 00:20:47.916 A:middle
中间图像的

00:20:47.916 --> 00:20:49.506 A:middle
内存占用

00:20:49.506 --> 00:20:50.126 A:middle
尽可能小

00:20:50.606 --> 00:20:51.296 A:middle
例如 对于

00:20:51.296 --> 00:20:53.376 A:middle
Inception-v3 网络来说

00:20:53.826 --> 00:20:56.856 A:middle
这意味着能节省 5 倍的内存空间

00:20:56.856 --> 00:20:58.496 A:middle
和 10 倍的检查器分配

00:20:58.556 --> 00:20:59.256 A:middle
我觉得这是相当令人惊叹的

00:21:00.836 --> 00:21:02.926 A:middle
正如我所说 图像为你

00:21:02.926 --> 00:21:03.956 A:middle
做了所有的基础工作

00:21:04.316 --> 00:21:05.646 A:middle
它会创建

00:21:05.846 --> 00:21:06.846 A:middle
中间图像

00:21:06.996 --> 00:21:08.706 A:middle
并管理图像的大小

00:21:09.296 --> 00:21:11.086 A:middle
它甚至会管理

00:21:11.086 --> 00:21:11.366 A:middle
输出的大小

00:21:11.786 --> 00:21:12.766 A:middle
它负责处理

00:21:12.766 --> 00:21:13.406 A:middle
填充策略

00:21:13.796 --> 00:21:15.016 A:middle
它也会进行审查

00:21:15.426 --> 00:21:17.516 A:middle
简而言之 它能让你

00:21:17.566 --> 00:21:19.406 A:middle
少写很多代码

00:21:19.486 --> 00:21:20.746 A:middle
也就能避免产生很多

00:21:20.746 --> 00:21:20.956 A:middle
错误

00:21:21.956 --> 00:21:24.066 A:middle
当我说较少的代码时

00:21:24.596 --> 00:21:25.376 A:middle
我是说少了非常多的代码

00:21:26.206 --> 00:21:27.906 A:middle
所以去年我们发布了

00:21:27.996 --> 00:21:30.726 A:middle
使用 Inception-v3 网络

00:21:30.726 --> 00:21:32.036 A:middle
进行图像识别的 Metal

00:21:32.036 --> 00:21:33.286 A:middle
识别样本

00:21:34.326 --> 00:21:36.026 A:middle
我们把这个样本

00:21:36.026 --> 00:21:37.576 A:middle
转换了一下 从而能够使用

00:21:37.806 --> 00:21:40.036 A:middle
新的图像 API 然后发现我们

00:21:40.036 --> 00:21:41.956 A:middle
可以少编写四倍的代码

00:21:42.356 --> 00:21:43.956 A:middle
少写的代码行数与为了

00:21:43.956 --> 00:21:45.846 A:middle
执行相同的网络

00:21:46.226 --> 00:21:47.916 A:middle
需要在开源传感器

00:21:47.916 --> 00:21:48.886 A:middle
流程框架中编写的

00:21:48.886 --> 00:21:50.436 A:middle
Python 代码行数

00:21:50.436 --> 00:21:50.846 A:middle
一样多

00:21:51.476 --> 00:21:52.956 A:middle
我们只是想提一下

00:21:52.956 --> 00:21:54.046 A:middle
我们将发布这个升级的

00:21:54.086 --> 00:21:57.196 A:middle
示例代码 升级的示例作为

00:21:57.196 --> 00:21:58.346 A:middle
示例代码

00:21:59.026 --> 00:22:01.796 A:middle
拥有关于你的整个网络的

00:21:59.026 --> 00:22:01.796 A:middle
拥有关于你的整个网络的

00:22:01.796 --> 00:22:03.276 A:middle
所有信息 使我们能够

00:22:03.276 --> 00:22:06.116 A:middle
在不同的视图中

00:22:06.116 --> 00:22:07.956 A:middle
提供最佳

00:22:08.106 --> 00:22:08.866 A:middle
性能

00:22:09.336 --> 00:22:10.946 A:middle
让你可以轻松地在

00:22:10.946 --> 00:22:12.766 A:middle
CPU 和 GPU 之间进行

00:22:12.766 --> 00:22:13.206 A:middle
并行处理

00:22:13.976 --> 00:22:15.876 A:middle
当图像正在执行

00:22:16.326 --> 00:22:18.076 A:middle
当 GPU 执行一个

00:22:18.076 --> 00:22:19.986 A:middle
输入图像的图形时

00:22:19.986 --> 00:22:21.686 A:middle
CPU 已经准备好执行

00:22:21.686 --> 00:22:22.776 A:middle
不同的输入

00:22:22.776 --> 00:22:23.716 A:middle
图像图形了

00:22:25.176 --> 00:22:26.606 A:middle
我们还可以将图形节点

00:22:26.676 --> 00:22:28.446 A:middle
融合在一起 比如卷积和

00:22:28.856 --> 00:22:29.966 A:middle
神经元节点

00:22:31.856 --> 00:22:33.746 A:middle
我们可以同时操作

00:22:33.746 --> 00:22:34.386 A:middle
这些图形节点

00:22:34.386 --> 00:22:36.256 A:middle
所以如果我们再看一下

00:22:36.256 --> 00:22:38.056 A:middle
这个初始模块的话

00:22:38.056 --> 00:22:39.886 A:middle
你就可以看到很多行

00:22:39.886 --> 00:22:41.386 A:middle
节点可以

00:22:41.456 --> 00:22:43.036 A:middle
完全彼此独立的

00:22:43.036 --> 00:22:43.236 A:middle
操作

00:22:44.176 --> 00:22:45.486 A:middle
当然 这些独立执行的

00:22:45.486 --> 00:22:47.326 A:middle
输出需要通过

00:22:47.926 --> 00:22:49.216 A:middle
相关节点进行

00:22:49.216 --> 00:22:50.216 A:middle
连接

00:22:51.206 --> 00:22:52.656 A:middle
而且这个图像也足够智能

00:22:52.656 --> 00:22:54.276 A:middle
可以将这些进行优化处理

00:22:54.886 --> 00:22:57.706 A:middle
现在我们来看看如何使用

00:22:57.706 --> 00:22:59.586 A:middle
新的图形 API

00:23:00.296 --> 00:23:02.176 A:middle
所以这是使用

00:23:02.176 --> 00:23:04.126 A:middle
图形 API 创建

00:23:04.126 --> 00:23:04.646 A:middle
卷积节点的代码

00:23:05.826 --> 00:23:07.256 A:middle
它需要一个图像作为源

00:23:08.226 --> 00:23:09.486 A:middle
而且它也有权重

00:23:09.486 --> 00:23:10.926 A:middle
所以让我们谈一下

00:23:10.926 --> 00:23:11.176 A:middle
权重

00:23:13.056 --> 00:23:14.256 A:middle
神经网络规模

00:23:14.256 --> 00:23:15.396 A:middle
变得越来越大

00:23:16.136 --> 00:23:17.736 A:middle
如果你的网络中有

00:23:17.736 --> 00:23:19.346 A:middle
很多卷积节点

00:23:19.346 --> 00:23:21.436 A:middle
那就意味着

00:23:21.496 --> 00:23:22.466 A:middle
你的整个网络的

00:23:22.466 --> 00:23:23.616 A:middle
总体权重可能

00:23:23.616 --> 00:23:24.246 A:middle
相当大

00:23:25.216 --> 00:23:27.016 A:middle
为了解决这个问题

00:23:27.016 --> 00:23:30.126 A:middle
我们添加了一个

00:23:30.186 --> 00:23:31.296 A:middle
可以执行的卷积数据源协议

00:23:31.656 --> 00:23:33.186 A:middle
它能够及时

00:23:33.606 --> 00:23:35.036 A:middle
加载和清除

00:23:35.076 --> 00:23:35.276 A:middle
权重数据

00:23:36.296 --> 00:23:40.046 A:middle
所以我们的想法是

00:23:40.046 --> 00:23:41.546 A:middle
你的整个网络的

00:23:41.546 --> 00:23:43.196 A:middle
权重就不用同时

00:23:43.196 --> 00:23:44.086 A:middle
全部加载到内存中

00:23:44.626 --> 00:23:45.956 A:middle
它们也不必

00:23:45.956 --> 00:23:46.886 A:middle
提前加载

00:23:48.396 --> 00:23:49.656 A:middle
为了帮助将内存空间

00:23:49.656 --> 00:23:51.556 A:middle
占用降到最小 当我们初始化

00:23:51.556 --> 00:23:53.136 A:middle
图形并处理

00:23:53.136 --> 00:23:54.516 A:middle
一个特定的卷积层时

00:23:55.096 --> 00:23:56.126 A:middle
我们将为这个卷积层

00:23:56.126 --> 00:23:57.726 A:middle
加载权重 然后

00:23:57.856 --> 00:23:59.486 A:middle
将它们清除之后

00:23:59.486 --> 00:24:00.726 A:middle
再进入下一个卷积层

00:23:59.486 --> 00:24:00.726 A:middle
再进入下一个卷积层

00:24:02.226 --> 00:24:03.586 A:middle
你要做的就是使用

00:24:03.586 --> 00:24:05.146 A:middle
这个初始化方法

00:24:05.146 --> 00:24:06.916 A:middle
它知道数据的

00:24:06.916 --> 00:24:08.376 A:middle
位置 但实际上并不会

00:24:08.376 --> 00:24:09.086 A:middle
加载数据

00:24:10.096 --> 00:24:11.256 A:middle
然后当图像调用

00:24:11.256 --> 00:24:13.266 A:middle
加载功能的时候

00:24:13.266 --> 00:24:14.846 A:middle
会提醒你需要

00:24:14.846 --> 00:24:15.236 A:middle
加载权重

00:24:15.366 --> 00:24:16.546 A:middle
然后当图像调用

00:24:16.546 --> 00:24:18.166 A:middle
清除函数功能时

00:24:18.166 --> 00:24:19.316 A:middle
你可以释放权重

00:24:21.586 --> 00:24:22.526 A:middle
现在我们来构建一个图像

00:24:23.446 --> 00:24:24.926 A:middle
这里我们正在使用

00:24:24.926 --> 00:24:26.116 A:middle
这个 makeGraph 函数

00:24:26.596 --> 00:24:28.366 A:middle
而在左边 你可以看到

00:24:28.366 --> 00:24:29.636 A:middle
构建网络所需的

00:24:29.636 --> 00:24:30.826 A:middle
所有节点

00:24:31.256 --> 00:24:32.926 A:middle
然后我们创建节点

00:24:33.226 --> 00:24:34.446 A:middle
创建卷积

00:24:34.446 --> 00:24:34.836 A:middle
节点

00:24:35.016 --> 00:24:35.616 A:middle
池化节点

00:24:35.616 --> 00:24:37.456 A:middle
和剩下的节点

00:24:37.756 --> 00:24:38.606 A:middle
现在节点有了

00:24:38.606 --> 00:24:40.226 A:middle
那我们如何将节点

00:24:40.226 --> 00:24:40.446 A:middle
连接成图像呢

00:24:41.646 --> 00:24:43.186 A:middle
我们只需把一个节点的

00:24:43.186 --> 00:24:44.986 A:middle
结果图像作为

00:24:45.066 --> 00:24:46.516 A:middle
源图像传递给下一个节点

00:24:46.516 --> 00:24:48.106 A:middle
就形成了图像

00:24:49.736 --> 00:24:51.236 A:middle
现在让我们在 GPU 上运行这个图表

00:24:51.906 --> 00:24:54.066 A:middle
首先像往常一样进行 Metal

00:24:54.066 --> 00:24:54.456 A:middle
设置

00:24:54.886 --> 00:24:56.016 A:middle
我们初始化这个图像

00:24:56.676 --> 00:24:58.166 A:middle
要管理好输入数据

00:24:58.866 --> 00:25:01.066 A:middle
然后将图像编码到

00:24:58.866 --> 00:25:01.066 A:middle
然后将图像编码到

00:25:01.066 --> 00:25:01.506 A:middle
GPU 上

00:25:02.276 --> 00:25:04.026 A:middle
输出图像中的数据

00:25:04.556 --> 00:25:06.546 A:middle
将会在命令缓冲区

00:25:06.546 --> 00:25:08.466 A:middle
完成时 将数据填充到

00:25:08.466 --> 00:25:09.576 A:middle
输出图像中

00:25:10.086 --> 00:25:11.526 A:middle
然后我们可以选择

00:25:11.526 --> 00:25:12.996 A:middle
等待 GPU 完成

00:25:13.406 --> 00:25:14.686 A:middle
但我们并不推荐

00:25:14.686 --> 00:25:14.956 A:middle
这样做

00:25:15.886 --> 00:25:17.506 A:middle
因为如果这样做的话

00:25:17.506 --> 00:25:19.246 A:middle
CPU 就会等 GPU 完成之后

00:25:19.836 --> 00:25:21.486 A:middle
才能开始对下一轮

00:25:21.486 --> 00:25:22.846 A:middle
图像进行编码

00:25:23.486 --> 00:25:25.256 A:middle
而这样会将气泡引入你的

00:25:25.256 --> 00:25:26.266 A:middle
传输途径 并对

00:25:26.526 --> 00:25:28.036 A:middle
性能产生不利影响

00:25:29.816 --> 00:25:30.686 A:middle
所以我们推荐

00:25:30.686 --> 00:25:32.606 A:middle
使用新的

00:25:32.606 --> 00:25:34.596 A:middle
异步执行的 API

00:25:35.426 --> 00:25:37.896 A:middle
使用这个 API 能让你的 Metal

00:25:37.966 --> 00:25:39.436 A:middle
设置甚至变得更小

00:25:39.626 --> 00:25:41.076 A:middle
这样你只需要准备好

00:25:41.076 --> 00:25:41.736 A:middle
Metal 设备

00:25:42.136 --> 00:25:43.096 A:middle
然后需要

00:25:43.096 --> 00:25:44.016 A:middle
初始化图像

00:25:44.056 --> 00:25:46.426 A:middle
准备好输入数据 然后

00:25:46.426 --> 00:25:47.856 A:middle
执行异步调用

00:25:49.586 --> 00:25:52.376 A:middle
它会立即返回

00:25:52.376 --> 00:25:54.216 A:middle
然后当这个代码

00:25:55.196 --> 00:25:56.236 A:middle
闭包执行时 输出图像

00:25:56.236 --> 00:25:57.086 A:middle
就已经准备好了

00:25:57.796 --> 00:25:59.056 A:middle
但在此期间 你不需要

00:25:59.056 --> 00:26:00.136 A:middle
等待 GPU 完成

00:25:59.056 --> 00:26:00.136 A:middle
等待 GPU 完成

00:26:00.306 --> 00:26:02.056 A:middle
就可以继续进行

00:26:02.056 --> 00:26:03.676 A:middle
编码和新的 GPU 任务。

00:26:04.396 --> 00:26:07.236 A:middle
这样 CPU 和 GPU 就

00:26:07.236 --> 00:26:08.846 A:middle
可以同时工作

00:26:09.406 --> 00:26:10.316 A:middle
并且你的传输途经中

00:26:10.316 --> 00:26:12.756 A:middle
没有气泡 两者都

00:26:12.756 --> 00:26:14.376 A:middle
被充分地利用了起来

00:26:16.756 --> 00:26:18.996 A:middle
好了 现在我来做一次

00:26:18.996 --> 00:26:21.106 A:middle
现场演示 演示

00:26:21.146 --> 00:26:22.846 A:middle
同步和异步 API

00:26:22.966 --> 00:26:24.526 A:middle
之间的

00:26:24.526 --> 00:26:24.786 A:middle
性能差异

00:26:24.786 --> 00:26:27.576 A:middle
这个演示将使用

00:26:27.576 --> 00:26:29.576 A:middle
Inception-v3 网络

00:26:29.576 --> 00:26:30.116 A:middle
进行图像识别

00:26:30.516 --> 00:26:30.806 A:middle
好的

00:26:31.136 --> 00:26:32.726 A:middle
我将从同步

00:26:32.726 --> 00:26:34.416 A:middle
API 开始 在这里我们正在

00:26:34.416 --> 00:26:35.706 A:middle
检测一个水瓶

00:26:35.706 --> 00:26:38.276 A:middle
平均每个

00:26:38.276 --> 00:26:41.756 A:middle
图像大约有 50

00:26:41.756 --> 00:26:42.596 A:middle
毫秒

00:26:42.826 --> 00:26:44.066 A:middle
现在我将切换到

00:26:44.066 --> 00:26:44.956 A:middle
异步 API

00:26:44.956 --> 00:26:47.586 A:middle
现在平均每个图像的

00:26:47.586 --> 00:26:49.546 A:middle
时间约为 36

00:26:49.546 --> 00:26:49.936 A:middle
毫秒

00:26:49.936 --> 00:26:51.656 A:middle
所以性能

00:26:51.686 --> 00:26:52.666 A:middle
有了很大提升

00:26:54.776 --> 00:26:55.066 A:middle
好的

00:26:55.196 --> 00:26:56.436 A:middle
这就是现场演示

00:26:58.516 --> 00:27:04.016 A:middle
[掌声]

00:26:58.516 --> 00:27:04.016 A:middle
[掌声]

00:27:04.516 --> 00:27:04.876 A:middle
谢谢你们

00:27:06.566 --> 00:27:07.656 A:middle
好的 既然我们已经谈过了

00:27:07.656 --> 00:27:08.626 A:middle
新的神经网络图像

00:27:08.626 --> 00:27:10.926 A:middle
API 并且向你展示了

00:27:10.956 --> 00:27:12.716 A:middle
它使用起来多么简单

00:27:12.716 --> 00:27:14.016 A:middle
性能多么强大

00:27:14.016 --> 00:27:16.086 A:middle
现在让我们来换个话题

00:27:16.086 --> 00:27:17.166 A:middle
谈谈循环神经

00:27:17.166 --> 00:27:17.566 A:middle
网络

00:27:19.416 --> 00:27:20.386 A:middle
什么是循环神经

00:27:20.386 --> 00:27:20.786 A:middle
网络呢

00:27:23.406 --> 00:27:25.456 A:middle
CNN 的一个缺点是

00:27:25.456 --> 00:27:27.276 A:middle
无法记住过去

00:27:27.306 --> 00:27:28.326 A:middle
发生的

00:27:28.326 --> 00:27:28.466 A:middle
事情

00:27:29.456 --> 00:27:31.226 A:middle
它们可以将一个图像

00:27:31.896 --> 00:27:33.926 A:middle
作为输入 并生成单个输出

00:27:34.446 --> 00:27:36.316 A:middle
例如图像中所描绘

00:27:36.356 --> 00:27:37.396 A:middle
内容的一组

00:27:37.396 --> 00:27:37.836 A:middle
可能性

00:27:39.056 --> 00:27:41.016 A:middle
但 RNN 是有

00:27:41.016 --> 00:27:41.446 A:middle
记忆的

00:27:42.346 --> 00:27:43.466 A:middle
而且它们擅长按顺序

00:27:43.546 --> 00:27:44.066 A:middle
进行操作

00:27:44.536 --> 00:27:48.256 A:middle
所以它们可以通过一个输入

00:27:48.256 --> 00:27:49.576 A:middle
比如图像中所

00:27:49.636 --> 00:27:51.016 A:middle
描绘内容的一组

00:27:51.616 --> 00:27:52.966 A:middle
可能性 然后产生一个

00:27:53.036 --> 00:27:53.366 A:middle
输出序列

00:27:53.366 --> 00:27:56.196 A:middle
一组有逻辑顺序的单词

00:27:56.196 --> 00:27:57.586 A:middle
成为这个图像的标题

00:27:59.416 --> 00:28:01.716 A:middle
它们还可以通过一个

00:27:59.416 --> 00:28:01.716 A:middle
它们还可以通过一个

00:28:01.806 --> 00:28:03.506 A:middle
序列输入 比如英语句子

00:28:03.506 --> 00:28:06.626 A:middle
产生多个序列

00:28:06.626 --> 00:28:08.506 A:middle
输出 比如同一个句子翻译成

00:28:08.666 --> 00:28:09.946 A:middle
不同的语言

00:28:09.946 --> 00:28:12.376 A:middle
比如俄语

00:28:12.466 --> 00:28:13.056 A:middle
或芬兰语

00:28:13.366 --> 00:28:16.356 A:middle
而且我们还支持许多

00:28:16.356 --> 00:28:17.756 A:middle
不同的 RNN 变体

00:28:18.586 --> 00:28:20.146 A:middle
单门限 RNN

00:28:20.146 --> 00:28:22.156 A:middle
长短期记忆 RNN 或者说 LSTM

00:28:22.596 --> 00:28:24.586 A:middle
以及 LSTM 的多种变体

00:28:24.866 --> 00:28:26.336 A:middle
GRU 和 MGU

00:28:27.766 --> 00:28:29.336 A:middle
那么让我们来谈谈最简单的

00:28:29.366 --> 00:28:31.326 A:middle
RNN 类型 单门限

00:28:31.326 --> 00:28:31.526 A:middle
RNN

00:28:33.666 --> 00:28:34.966 A:middle
单门限 RNN 具有

00:28:34.966 --> 00:28:37.006 A:middle
循环单元 这使得

00:28:37.066 --> 00:28:38.676 A:middle
RNN 之前的输出

00:28:38.996 --> 00:28:40.346 A:middle
能够影响同一个

00:28:40.406 --> 00:28:41.846 A:middle
RNN 的后续

00:28:41.846 --> 00:28:42.406 A:middle
迭代输出

00:28:43.606 --> 00:28:45.496 A:middle
但是单门限 RNN 的功能

00:28:45.546 --> 00:28:47.466 A:middle
还不够强大 不能将

00:28:47.466 --> 00:28:48.746 A:middle
重要信息对多次

00:28:48.746 --> 00:28:49.286 A:middle
迭代输出构成影响

00:28:50.136 --> 00:28:51.676 A:middle
因为单门限 RNN 的

00:28:51.786 --> 00:28:53.976 A:middle
当前输出也是

00:28:53.976 --> 00:28:54.996 A:middle
它的当前状态

00:28:54.996 --> 00:28:55.976 A:middle
没有别的东西

00:28:57.146 --> 00:28:59.426 A:middle
解决这个问题的方法是

00:28:59.476 --> 00:29:01.596 A:middle
长短期记忆 RNN 或简称 LSTM

00:28:59.476 --> 00:29:01.596 A:middle
长短期记忆 RNN 或简称 LSTM

00:29:02.376 --> 00:29:03.906 A:middle
它由单门限 RNN 构成

00:29:03.906 --> 00:29:06.246 A:middle
并具有内部存储

00:29:06.246 --> 00:29:06.506 A:middle
单元

00:29:07.436 --> 00:29:08.856 A:middle
一个特定的

00:29:08.956 --> 00:29:10.596 A:middle
门限组合可以控制

00:29:10.596 --> 00:29:13.106 A:middle
信息在 LSTM 内如何流动

00:29:13.436 --> 00:29:15.016 A:middle
并有选择的让信息

00:29:15.136 --> 00:29:16.266 A:middle
存入存储单元

00:29:16.846 --> 00:29:19.656 A:middle
让我们更详细地

00:29:19.656 --> 00:29:21.316 A:middle
看一下 LSTM 的

00:29:21.316 --> 00:29:21.776 A:middle
架构

00:29:22.206 --> 00:29:25.246 A:middle
正如我所说 LSTM 中

00:29:25.356 --> 00:29:27.846 A:middle
最重要的实体是存储

00:29:27.886 --> 00:29:30.406 A:middle
单元 它在 LSTM 的每个循环期内

00:29:30.476 --> 00:29:31.536 A:middle
都会进行更新

00:29:31.536 --> 00:29:33.426 A:middle
所以你可以想到

00:29:33.846 --> 00:29:35.246 A:middle
LSTM 的每一次迭代

00:29:35.306 --> 00:29:37.456 A:middle
都是这种新旧

00:29:37.456 --> 00:29:38.016 A:middle
内存之间的转换

00:29:38.676 --> 00:29:40.786 A:middle
现在让我们谈谈

00:29:40.816 --> 00:29:41.036 A:middle
门限

00:29:41.566 --> 00:29:43.376 A:middle
首先是遗忘门限

00:29:44.216 --> 00:29:45.876 A:middle
它决定旧的内存中

00:29:45.876 --> 00:29:47.206 A:middle
哪些能够保留

00:29:47.206 --> 00:29:47.566 A:middle
哪些不能保留

00:29:48.966 --> 00:29:50.456 A:middle
然后是输入和

00:29:50.456 --> 00:29:51.836 A:middle
单元门限

00:29:51.836 --> 00:29:53.996 A:middle
它们的相互组合决定了

00:29:54.066 --> 00:29:55.786 A:middle
当前输入的什么信息

00:29:55.786 --> 00:29:56.936 A:middle
将影响新的内存

00:29:56.936 --> 00:29:59.136 A:middle
然后这三个门限

00:29:59.136 --> 00:30:00.866 A:middle
组合在一起来

00:29:59.136 --> 00:30:00.866 A:middle
组合在一起来

00:30:01.226 --> 00:30:04.596 A:middle
更新存储单元

00:30:05.696 --> 00:30:07.576 A:middle
最后是输出门限

00:30:07.626 --> 00:30:09.656 A:middle
它决定了

00:30:09.656 --> 00:30:11.976 A:middle
以前的输入

00:30:12.476 --> 00:30:14.076 A:middle
输出 当前的

00:30:14.076 --> 00:30:16.126 A:middle
输入和新的内存中

00:30:16.126 --> 00:30:17.936 A:middle
哪些信息将会影响 LSTM 的输出

00:30:19.196 --> 00:30:20.626 A:middle
所以现在你知道 LSTM

00:30:20.626 --> 00:30:22.206 A:middle
是由什么组成的了 让我们来看看

00:30:22.206 --> 00:30:24.006 A:middle
你如何使用我们的框架

00:30:24.006 --> 00:30:24.576 A:middle
来创建一个 LSTM

00:30:25.616 --> 00:30:27.536 A:middle
首先创建一个 LSTM 的

00:30:27.756 --> 00:30:28.576 A:middle
描述符

00:30:29.146 --> 00:30:31.306 A:middle
然后你需要将门限

00:30:31.526 --> 00:30:31.876 A:middle
初始化

00:30:32.436 --> 00:30:33.676 A:middle
那么门限由什么控制呢

00:30:33.676 --> 00:30:35.146 A:middle
什么能够控制门限

00:30:35.306 --> 00:30:36.156 A:middle
控制门限

00:30:36.156 --> 00:30:37.756 A:middle
如何操作的是经过

00:30:37.756 --> 00:30:38.386 A:middle
训练的参数

00:30:39.146 --> 00:30:40.156 A:middle
这些参数来自

00:30:40.156 --> 00:30:41.726 A:middle
为使系统执行一项特定任务

00:30:41.726 --> 00:30:43.526 A:middle
而对其进行训练的步骤

00:30:45.566 --> 00:30:47.496 A:middle
而且你可以看到

00:30:47.496 --> 00:30:48.586 A:middle
这里有很多门限

00:30:48.646 --> 00:30:49.856 A:middle
供你进行初始化

00:30:49.856 --> 00:30:52.356 A:middle
但为了简要说明

00:30:52.356 --> 00:30:52.726 A:middle
我们只展示两个初始化

00:30:53.206 --> 00:30:54.336 A:middle
正如你所看到的 我们也

00:30:54.336 --> 00:30:56.046 A:middle
在使用一个数据源供应程序

00:30:56.046 --> 00:30:57.446 A:middle
和之前给你看过的一样

00:30:57.556 --> 00:30:58.606 A:middle
它用来初始化权重

00:30:59.656 --> 00:31:01.536 A:middle
下一步是创建

00:30:59.656 --> 00:31:01.536 A:middle
下一步是创建

00:31:01.536 --> 00:31:03.606 A:middle
我们的 LSTM 层 现在我们

00:31:03.606 --> 00:31:04.876 A:middle
把它放在 GPU 上运行

00:31:06.586 --> 00:31:08.646 A:middle
我们需要创建数组

00:31:08.646 --> 00:31:10.976 A:middle
保存 LSTM

00:31:10.976 --> 00:31:13.236 A:middle
执行序列的

00:31:13.236 --> 00:31:14.266 A:middle
输入和输出

00:31:14.886 --> 00:31:16.076 A:middle
然后将序列编码到

00:31:16.076 --> 00:31:16.716 A:middle
GPU 上

00:31:17.416 --> 00:31:19.446 A:middle
在这里 我们向你展示

00:31:19.666 --> 00:31:21.546 A:middle
一种基于矩阵的 RNN 但我们

00:31:21.546 --> 00:31:22.646 A:middle
想提一下 我们

00:31:22.686 --> 00:31:25.726 A:middle
也支持通过卷积在

00:31:25.726 --> 00:31:27.636 A:middle
MPS 图像上操作的 RNN

00:31:30.176 --> 00:31:31.216 A:middle
现在我们来看一个

00:31:31.216 --> 00:31:32.016 A:middle
实际的例子

00:31:32.596 --> 00:31:34.366 A:middle
我们将使用图片字幕

00:31:34.366 --> 00:31:35.706 A:middle
作为使用 LSTM 的例子

00:31:36.726 --> 00:31:38.566 A:middle
你应该记得 我跟你讲过

00:31:38.896 --> 00:31:40.646 A:middle
深度学习算法

00:31:40.646 --> 00:31:42.076 A:middle
有两个阶段

00:31:42.346 --> 00:31:43.316 A:middle
训练阶段和

00:31:43.316 --> 00:31:44.026 A:middle
推理阶段

00:31:44.816 --> 00:31:46.816 A:middle
所以要想训练一个系统

00:31:46.816 --> 00:31:49.196 A:middle
为图像添加说明文字

00:31:49.196 --> 00:31:51.056 A:middle
你需要给它输入大量的带有

00:31:51.056 --> 00:31:52.356 A:middle
人为添加说明文字的图像

00:31:53.836 --> 00:31:56.606 A:middle
那么这个系统有什么呢

00:31:56.656 --> 00:31:57.686 A:middle
它是由什么构成的

00:31:58.536 --> 00:32:02.016 A:middle
这个系统有一个 CNN 和一个

00:31:58.536 --> 00:32:02.016 A:middle
这个系统有一个 CNN 和一个

00:32:02.016 --> 00:32:03.906 A:middle
RNN 一起工作来生成

00:32:03.906 --> 00:32:04.346 A:middle
说明文字

00:32:04.746 --> 00:32:07.316 A:middle
CNN 用于确定

00:32:07.316 --> 00:32:09.316 A:middle
图像中描述的内容

00:32:09.316 --> 00:32:10.886 A:middle
然后经 RNN 生成

00:32:10.956 --> 00:32:11.806 A:middle
实际的说明文字

00:32:13.256 --> 00:32:15.076 A:middle
而该过程的输出

00:32:15.156 --> 00:32:17.006 A:middle
是经过训练的参数

00:32:17.006 --> 00:32:19.036 A:middle
它们是下一步也就是

00:32:20.186 --> 00:32:20.886 A:middle
推理阶段需要的

00:32:21.676 --> 00:32:25.606 A:middle
因此 在推理阶段

00:32:25.656 --> 00:32:27.766 A:middle
经过训练的参数控制

00:32:27.766 --> 00:32:29.826 A:middle
CNN 层

00:32:29.826 --> 00:32:31.866 A:middle
和 RNN

00:32:31.866 --> 00:32:32.146 A:middle.
门限的运行

00:32:33.206 --> 00:32:37.276 A:middle
然后每个图像

00:32:37.336 --> 00:32:39.166 A:middle
都由 CNN 和 RNN 进行处理

00:32:39.446 --> 00:32:41.326 A:middle
从而生成说明文字

00:32:42.216 --> 00:32:43.246 A:middle
我们已经知道有一个很好的

00:32:43.246 --> 00:32:44.636 A:middle
网络可以确定

00:32:44.706 --> 00:32:45.816 A:middle
图像中描绘的内容

00:32:46.086 --> 00:32:47.506 A:middle
就是 Inception-v3 网络

00:32:47.876 --> 00:32:48.626 A:middle
所以我们将使用它

00:32:49.186 --> 00:32:50.456 A:middle
而且我们刚刚谈到了 LSTM

00:32:50.456 --> 00:32:52.236 A:middle
所以让我们用它来生成

00:32:52.446 --> 00:32:53.036 A:middle
说明文字

00:32:53.996 --> 00:32:56.456 A:middle
说明文字生成阶段

00:32:57.266 --> 00:32:58.176 A:middle
说明文字生成过程

00:32:58.176 --> 00:32:59.726 A:middle
也分为两个阶段

00:33:00.006 --> 00:33:02.206 A:middle
首先我们有 LSTM

00:33:02.486 --> 00:33:03.646 A:middle
初始化阶段

00:33:04.846 --> 00:33:06.126 A:middle
然后我们运行 Inception-v3

00:33:06.126 --> 00:33:08.616 A:middle
网络 实际上我们运行了所有的

00:33:08.616 --> 00:33:10.496 A:middle
层 除了最后一个

00:33:10.496 --> 00:33:11.986 A:middle
SoftMax 层

00:33:12.236 --> 00:33:13.386 A:middle
而输出是一个

00:33:13.386 --> 00:33:15.016 A:middle
特征向量 它含有

00:33:15.016 --> 00:33:16.196 A:middle
关于图像描绘

00:33:16.196 --> 00:33:17.226 A:middle
内容的信息

00:33:17.906 --> 00:33:19.016 A:middle
然后我们将该

00:33:19.016 --> 00:33:20.566 A:middle
特征向量转换为

00:33:20.566 --> 00:33:23.246 A:middle
LSTM 所需的

00:33:23.246 --> 00:33:24.286 A:middle
紧凑表示

00:33:24.286 --> 00:33:26.596 A:middle
然后通过 LSTM 运行

00:33:26.946 --> 00:33:27.746 A:middle
将其初始化

00:33:28.736 --> 00:33:30.466 A:middle
然后一旦我们有了

00:33:30.466 --> 00:33:32.436 A:middle
初始化的 LSTM 那就

00:33:32.436 --> 00:33:33.586 A:middle
准备好可以进入下一个阶段了

00:33:34.606 --> 00:33:36.066 A:middle
即实际说明文字

00:33:36.066 --> 00:33:36.376 A:middle
生成阶段

00:33:38.116 --> 00:33:39.676 A:middle
我们通过向 LSTM 传递

00:33:39.676 --> 00:33:41.366 A:middle
一个特殊的句子开始令牌 ID

00:33:41.436 --> 00:33:44.026 A:middle
来启动这个过程

00:33:44.236 --> 00:33:45.046 A:middle
并且该操作的输出

00:33:45.046 --> 00:33:46.756 A:middle
是一个单词序列

00:33:46.756 --> 00:33:50.006 A:middle
你知道的 就是

00:33:50.006 --> 00:33:51.276 A:middle
和图像中所描绘的

00:33:51.276 --> 00:33:52.666 A:middle
内容相关的单词

00:33:53.526 --> 00:33:55.806 A:middle
然后我们将这些单词传递给

00:33:55.806 --> 00:33:57.226 A:middle
一个 SoftMax 层 该层可以计算

00:33:57.226 --> 00:33:58.796 A:middle
这些单词的概率

00:33:59.326 --> 00:34:01.176 A:middle
我们选择三个概率最高的

00:33:59.326 --> 00:34:01.176 A:middle
我们选择三个概率最高的

00:34:01.326 --> 00:34:03.276 A:middle
这三个概率最高的单词也是

00:34:03.276 --> 00:34:05.816 A:middle
我们对于特定图像的

00:34:05.816 --> 00:34:07.546 A:middle
说明文字中的单字部分

00:34:08.126 --> 00:34:09.726 A:middle
所以我们将这些单词拿出来

00:34:09.806 --> 00:34:11.856 A:middle
并传递给下一个状态的

00:34:11.946 --> 00:34:15.045 A:middle
LSTM 它的功能是

00:34:15.096 --> 00:34:16.886 A:middle
为图像算出三组

00:34:16.916 --> 00:34:19.216 A:middle
最好的双字组合

00:34:19.216 --> 00:34:19.386 A:middle
说明文字

00:34:19.466 --> 00:34:21.416 A:middle
我们执行 N 次迭代

00:34:21.886 --> 00:34:23.076 A:middle
直到达到停止的

00:34:23.076 --> 00:34:25.596 A:middle
条件 也就是当

00:34:25.626 --> 00:34:27.116 A:middle
达到我们想要的说明文字

00:34:27.116 --> 00:34:28.966 A:middle
字数上限的时候

00:34:28.966 --> 00:34:30.856 A:middle
或者当

00:34:30.856 --> 00:34:32.136 A:middle
新生成的说明文字

00:34:32.136 --> 00:34:33.906 A:middle
概率下降到 0 的时候

00:34:34.985 --> 00:34:35.996 A:middle
我知道这仍然

00:34:35.996 --> 00:34:36.505 A:middle
很抽象

00:34:36.846 --> 00:34:39.005 A:middle
所以让我们来看看

00:34:39.386 --> 00:34:42.266 A:middle
LSTM 的输出 也就是

00:34:42.326 --> 00:34:44.556 A:middle
LSTM 为了一个特定图像

00:34:44.556 --> 00:34:45.545 A:middle
进行多次迭代之后的实际输出

00:34:46.216 --> 00:34:49.786 A:middle
在这个图像中 你看到

00:34:49.786 --> 00:34:51.636 A:middle
有冲浪者驾驭在一个波浪上

00:34:51.636 --> 00:34:53.146 A:middle
我们想计算出匹配这张图像的

00:34:53.146 --> 00:34:54.666 A:middle
三句最好的说明文字

00:34:55.696 --> 00:34:57.286 A:middle
在 LSTM 的第一次迭代中

00:34:57.366 --> 00:34:59.936 A:middle
生成了三个最好的

00:34:59.936 --> 00:35:00.306 A:middle
单词

00:34:59.936 --> 00:35:00.306 A:middle
单词

00:35:02.336 --> 00:35:04.446 A:middle
所以 这是匹配

00:35:04.446 --> 00:35:05.686 A:middle
这张图像的最好的

00:35:05.686 --> 00:35:05.996 A:middle
文字说明

00:35:06.506 --> 00:35:07.596 A:middle
“man”“a”和“the”

00:35:08.316 --> 00:35:10.596 A:middle
“a”一词的概率

00:35:10.596 --> 00:35:11.186 A:middle
最高

00:35:11.936 --> 00:35:13.546 A:middle
然后我们把这三个字

00:35:13.546 --> 00:35:15.196 A:middle
传递给下一个

00:35:15.196 --> 00:35:16.436 A:middle
LSTM 的迭代

00:35:17.166 --> 00:35:19.356 A:middle
在这个迭代中

00:35:19.356 --> 00:35:21.416 A:middle
对于这三个起始单词中的

00:35:22.436 --> 00:35:24.416 A:middle
每一个 LSTM 都生成了三个新词

00:35:24.416 --> 00:35:26.026 A:middle
它们有和这些

00:35:26.026 --> 00:35:28.496 A:middle
起始单词组合的

00:35:28.496 --> 00:35:29.606 A:middle
最高概率

00:35:30.666 --> 00:35:31.966 A:middle
对吧 所以我们有三个

00:35:31.966 --> 00:35:33.556 A:middle
新词可以和“man”组合

00:35:33.946 --> 00:35:35.256 A:middle
三个新词和“a”

00:35:35.256 --> 00:35:37.766 A:middle
组合 还有三个新词

00:35:37.826 --> 00:35:38.976 A:middle
和“the”组合

00:35:40.686 --> 00:35:42.296 A:middle
现在你可以看到

00:35:42.296 --> 00:35:44.486 A:middle
每一个双字组合说明

00:35:44.486 --> 00:35:45.486 A:middle
也都有概率

00:35:46.026 --> 00:35:47.866 A:middle
而且由于“a”

00:35:47.936 --> 00:35:49.286 A:middle
在第一次迭代中具有

00:35:49.286 --> 00:35:53.366 A:middle
如此高的概率 所以

00:35:53.366 --> 00:35:54.646 A:middle
在第二次迭代中

00:35:54.646 --> 00:35:56.426 A:middle
以“a”开头的双字组合

00:35:56.476 --> 00:35:58.156 A:middle
最后也具有最高的

00:35:58.156 --> 00:35:58.796 A:middle
概率

00:35:58.896 --> 00:36:00.916 A:middle
这是为什么 因为双字

00:35:58.896 --> 00:36:00.916 A:middle
这是为什么 因为双字

00:36:00.916 --> 00:36:02.506 A:middle
说明的概率

00:36:02.536 --> 00:36:04.516 A:middle
只是其中两个单词

00:36:04.516 --> 00:36:05.706 A:middle
概率的

00:36:05.706 --> 00:36:06.006 A:middle
乘积

00:36:07.116 --> 00:36:08.886 A:middle
这就是我们如何获得这三个的最好

00:36:08.886 --> 00:36:09.396 A:middle
方法

00:36:09.696 --> 00:36:11.226 A:middle
然后我们留下它们并

00:36:11.226 --> 00:36:12.836 A:middle.
继续下一个迭代

00:36:13.186 --> 00:36:14.406 A:middle
而在下一次迭代中

00:36:14.406 --> 00:36:15.936 A:middle
我们只需为已有说明文字

00:36:15.936 --> 00:36:17.536 A:middle
再添加一个单词

00:36:17.846 --> 00:36:18.806 A:middle
这样就有了三字说明

00:36:19.206 --> 00:36:19.996 A:middle
然后我们计算这些

00:36:19.996 --> 00:36:21.836 A:middle
说明文字的概率

00:36:21.836 --> 00:36:22.886 A:middle
并挑选三个概率最高的

00:36:23.936 --> 00:36:25.106 A:middle
我们继续进行下一次

00:36:25.106 --> 00:36:27.026 A:middle
迭代 只需再添加

00:36:27.026 --> 00:36:28.746 A:middle
一个词到

00:36:28.746 --> 00:36:29.186 A:middle
文字说明中

00:36:29.186 --> 00:36:30.566 A:middle
然后我们有了四字文字说明

00:36:30.976 --> 00:36:31.876 A:middle
然后我们计算

00:36:31.926 --> 00:36:33.186 A:middle
所有这些文字说明的

00:36:33.236 --> 00:36:34.546 A:middle
概率 并挑选概率

00:36:34.606 --> 00:36:34.816 A:middle
最高的三个

00:36:36.176 --> 00:36:37.306 A:middle
等等 我觉得你已经

00:36:37.306 --> 00:36:37.646 A:middle
了解这个方法了

00:36:37.866 --> 00:36:38.936 A:middle
那就让我们跳到最后吧

00:36:39.296 --> 00:36:41.416 A:middle
所以最后 我们得到了三个

00:36:41.416 --> 00:36:43.506 A:middle
最好的文字说明来匹配

00:36:43.506 --> 00:36:43.936 A:middle
这个特定的图象

00:36:43.936 --> 00:36:45.906 A:middle
而其中最好的是一个男人

00:36:45.906 --> 00:36:47.426 A:middle
踏着冲浪板冲浪

00:36:47.656 --> 00:36:48.616 A:middle
我觉得意思已经非常接近了

00:36:50.966 --> 00:36:52.346 A:middle
所以现在我们来

00:36:52.346 --> 00:36:52.726 A:middle
演示一下

00:36:53.508 --> 00:36:55.508 A:middle
[掌声]

00:36:58.476 --> 00:37:00.116 A:middle
所以现在我们来做一个

00:36:58.476 --> 00:37:00.116 A:middle
所以现在我们来做一个

00:37:00.606 --> 00:37:02.206 A:middle
这个字幕网络的演示

00:37:03.346 --> 00:37:04.856 A:middle
我们在这里收集了

00:37:04.856 --> 00:37:07.156 A:middle
一些图像 一旦我点击

00:37:07.156 --> 00:37:09.036 A:middle
一张图像 CNN

00:37:09.136 --> 00:37:10.826 A:middle
就会运行并确定

00:37:10.826 --> 00:37:12.526 A:middle
图像中描绘的内容

00:37:12.526 --> 00:37:14.046 A:middle
然后 RNN 将运行

00:37:14.046 --> 00:37:15.226 A:middle
并生成实际的说明文字

00:37:15.356 --> 00:37:16.036 A:middle
所以让我们试试吧

00:37:17.826 --> 00:37:19.446 A:middle
&gt;&gt;一个男人踏着

00:37:19.446 --> 00:37:19.766 A:middle
冲浪板冲浪

00:37:19.766 --> 00:37:22.356 A:middle
&gt;&gt;这个我们已经知道了

00:37:23.526 --> 00:37:24.566 A:middle
现在让我们试试另一张

00:37:24.996 --> 00:37:26.536 A:middle
&gt;&gt;一辆旧卡车停放在

00:37:26.536 --> 00:37:27.106 A:middle
野外

00:37:27.626 --> 00:37:28.936 A:middle
&gt;&gt;所以网络实际上知道

00:37:28.976 --> 00:37:30.356 A:middle
这是一辆旧卡车

00:37:30.356 --> 00:37:31.786 A:middle
它是停放着的 不动的

00:37:31.966 --> 00:37:33.336 A:middle
我觉得这非常

00:37:33.556 --> 00:37:34.156 A:middle
令人惊叹

00:37:34.786 --> 00:37:35.656 A:middle
再试一次

00:37:37.026 --> 00:37:38.496 A:middle
&gt;&gt;一只黑白花纹的狗

00:37:38.496 --> 00:37:39.086 A:middle
躺在草地上

00:37:39.796 --> 00:37:40.896 A:middle
&gt;&gt;所以网络知道

00:37:40.896 --> 00:37:42.176 A:middle
这是一只黑白色的狗

00:37:42.176 --> 00:37:43.636 A:middle
它躺在草地上

00:37:44.326 --> 00:37:45.106 A:middle
并没有跑

00:37:45.236 --> 00:37:46.356 A:middle
没有走路

00:37:46.726 --> 00:37:47.876 A:middle
也没有坐着

00:37:48.336 --> 00:37:50.266 A:middle
而是躺在草地上

00:37:50.766 --> 00:37:52.796 A:middle
太酷了

00:37:53.516 --> 00:37:57.786 A:middle
[掌声]

00:37:58.286 --> 00:37:58.726 A:middle
谢谢

00:37:59.306 --> 00:38:01.166 A:middle
借着这个说明 我们来

00:37:59.306 --> 00:38:01.166 A:middle
借着这个说明 我们来

00:38:01.236 --> 00:38:01.586 A:middle
总结一下

00:38:02.066 --> 00:38:03.536 A:middle
所以在本次会议中

00:38:03.536 --> 00:38:05.246 A:middle
我们讨论了今年在

00:38:05.276 --> 00:38:07.006 A:middle
MPS 框架中

00:38:07.336 --> 00:38:08.206 A:middle
添加的所有新原语。

00:38:08.586 --> 00:38:10.236 A:middle
我们扩大了对

00:38:10.236 --> 00:38:12.386 A:middle
图像处理原语和

00:38:12.786 --> 00:38:13.736 A:middle
卷积神经网络的

00:38:13.736 --> 00:38:14.136 A:middle
支持

00:38:15.006 --> 00:38:16.596 A:middle
我们还增加了对

00:38:16.596 --> 00:38:18.886 A:middle
线性代数和循环

00:38:18.886 --> 00:38:22.226 A:middle
神经网络的支持

00:38:23.096 --> 00:38:24.666 A:middle
该框架针对针对

00:38:24.666 --> 00:38:26.146 A:middle
iOS 进行了优化 正如我所说的那样

00:38:26.596 --> 00:38:29.226 A:middle
现在这些原语也都在

00:38:29.226 --> 00:38:30.016 A:middle
Mac 上可用

00:38:31.116 --> 00:38:32.416 A:middle
我们还讨论了新的

00:38:32.416 --> 00:38:34.676 A:middle
神经网络图像 API

00:38:34.676 --> 00:38:36.406 A:middle
并向你展示了如何

00:38:36.406 --> 00:38:38.336 A:middle
在 GPU 上构建和运行

00:38:38.336 --> 00:38:39.666 A:middle
你的网络

00:38:40.426 --> 00:38:42.186 A:middle
而且 这使我们有可能

00:38:42.186 --> 00:38:43.586 A:middle
在不同的 GPU 上

00:38:43.666 --> 00:38:45.346 A:middle
为你的网络提供

00:38:45.346 --> 00:38:46.336 A:middle
最佳性能

00:38:46.336 --> 00:38:49.776 A:middle
我们希望大家能够

00:38:49.776 --> 00:38:51.976 A:middle
使用所有这些新功能

00:38:51.976 --> 00:38:53.526 A:middle
来创建非常好的应用程序

00:38:53.526 --> 00:38:55.836 A:middle
并告诉我们

00:38:56.116 --> 00:38:57.296 A:middle
所以 请查看 Metal 2 相关的

00:38:57.296 --> 00:38:58.856 A:middle
会议和有关

00:38:58.856 --> 00:39:01.186 A:middle
核心 ML

00:38:58.856 --> 00:39:01.186 A:middle
核心 ML

00:39:01.676 --> 00:39:03.006 A:middle
Accelerate 和 Vision

00:39:03.006 --> 00:39:03.486 A:middle
框架的会议

00:39:04.716 --> 00:39:06.036 A:middle
有关此会议的更多信息

00:39:06.096 --> 00:39:07.636 A:middle
以及示例代码的链接

00:39:07.706 --> 00:39:09.936 A:middle
请登陆我们的

00:39:09.986 --> 00:39:11.426 A:middle
开发者网站查看这个链接

00:39:11.426 --> 00:39:14.276 A:middle
非常感谢大家的

00:39:14.276 --> 00:39:15.636 A:middle
出席 祝大家在

00:39:15.636 --> 00:39:15.846 A:middle
WWDC 大会期间有更多收获

00:39:16.516 --> 00:39:20.500 A:middle
[掌声]
