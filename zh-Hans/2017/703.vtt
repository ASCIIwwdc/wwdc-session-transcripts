WEBVTT

00:00:06.516 --> 00:00:16.500 A:middle
[ 人群讲话声 ]

00:00:23.516 --> 00:00:27.046 A:middle
[ 掌声 ]

00:00:27.546 --> 00:00:30.546 A:middle
&gt;&gt; 哇哦 非常激动能够来到

00:00:30.546 --> 00:00:30.676 A:middle
这里

00:00:31.606 --> 00:00:32.786 A:middle
我叫 Gaurav

00:00:32.786 --> 00:00:35.046 A:middle
今天我们将会

00:00:35.776 --> 00:00:37.466 A:middle
探讨一下机器学习

00:00:37.466 --> 00:00:38.686 A:middle
机器学习是一项非常

00:00:38.686 --> 00:00:39.866 A:middle
强大的技术

00:00:40.516 --> 00:00:42.066 A:middle
再结合我们设备的性能

00:00:42.066 --> 00:00:44.656 A:middle
你们能够创造出许多

00:00:44.656 --> 00:00:46.556 A:middle
令人惊叹的体验

00:00:47.896 --> 00:00:49.946 A:middle
比如说 你可以

00:00:49.946 --> 00:00:51.746 A:middle
进行实时图像识别

00:00:52.346 --> 00:00:53.846 A:middle
和内容创建

00:00:54.926 --> 00:00:56.366 A:middle
在接下来的40分钟里 我们

00:00:56.366 --> 00:00:57.576 A:middle
将会向大家讲述

00:00:57.576 --> 00:01:00.126 A:middle
那些体验以及 Apple 如何

00:00:57.576 --> 00:01:00.126 A:middle
那些体验以及 Apple 如何

00:01:00.126 --> 00:01:01.866 A:middle
方便快捷地

00:01:02.076 --> 00:01:03.846 A:middle
将机器学习融入

00:01:03.846 --> 00:01:04.965 A:middle
你们的 App 中

00:01:06.156 --> 00:01:07.916 A:middle
具体来说 我们将

00:01:07.916 --> 00:01:10.366 A:middle
专注于讨论 Core ML 和我们的机器

00:01:10.366 --> 00:01:11.066 A:middle
学习框架

00:01:14.946 --> 00:01:17.026 A:middle
在 Apple 中 我们正在广泛地使用

00:01:17.026 --> 00:01:18.786 A:middle
机器学习

00:01:19.796 --> 00:01:22.586 A:middle
在我们的照片 App 中 我们使用它来做

00:01:22.586 --> 00:01:24.096 A:middle
人物识别

00:01:24.096 --> 00:01:24.886 A:middle
场景识别

00:01:28.796 --> 00:01:31.106 A:middle
在我们的键盘 App 中 我们使用它

00:01:31.106 --> 00:01:32.496 A:middle
来做输入预测

00:01:33.006 --> 00:01:34.146 A:middle
和智能回复

00:01:35.236 --> 00:01:37.006 A:middle
我们甚至在 Apple Watch 中使用它

00:01:37.006 --> 00:01:38.366 A:middle
来做智能回复

00:01:38.366 --> 00:01:39.736 A:middle
和手写输入识别

00:01:40.926 --> 00:01:43.466 A:middle
我很确信你们也同样希望

00:01:43.466 --> 00:01:45.966 A:middle
创造出类似的体验

00:01:45.966 --> 00:01:47.306 A:middle
在你们自己的 App 中

00:01:48.206 --> 00:01:51.346 A:middle
比如说 你们中的一些人可能

00:01:51.346 --> 00:01:52.646 A:middle
想要做实时图像

00:01:52.646 --> 00:01:53.446 A:middle
识别

00:01:53.996 --> 00:01:56.856 A:middle
这样的话 你们可以告诉用户

00:01:56.856 --> 00:01:59.046 A:middle
为他们提供

00:01:59.046 --> 00:02:00.636 A:middle
他们所看到的 与场景更加相关的信息

00:01:59.046 --> 00:02:00.636 A:middle
他们所看到的 与场景更加相关的信息

00:02:00.636 --> 00:02:02.246 A:middle
比如说

00:02:02.246 --> 00:02:03.536 A:middle
他们是不是

00:02:03.536 --> 00:02:03.956 A:middle
在吃热狗

00:02:04.516 --> 00:02:07.816 A:middle
[ 笑声 ]

00:02:08.316 --> 00:02:11.656 A:middle
我们希望你们能够启用

00:02:11.656 --> 00:02:13.956 A:middle
这些非常棒的功能

00:02:13.956 --> 00:02:14.236 A:middle
在你们的 App 里

00:02:15.076 --> 00:02:17.176 A:middle
因此 我们推出

00:02:17.266 --> 00:02:18.996 A:middle
机器学习框架

00:02:18.996 --> 00:02:20.476 A:middle
让你们能够启用所有这些

00:02:20.476 --> 00:02:21.116 A:middle
酷炫的东西

00:02:21.536 --> 00:02:22.586 A:middle
你们该鼓掌了

00:02:23.516 --> 00:02:27.916 A:middle
[ 掌声 ]

00:02:28.416 --> 00:02:30.276 A:middle
但是在我们鼓掌之前 我们应该

00:02:30.276 --> 00:02:31.686 A:middle
首先了解我们需要

00:02:31.686 --> 00:02:32.816 A:middle
机器学习

00:02:32.816 --> 00:02:33.096 A:middle
的原因是什么

00:02:33.616 --> 00:02:38.826 A:middle
以及你们什么时候会用到

00:02:38.886 --> 00:02:39.036 A:middle
机器学习

00:02:39.036 --> 00:02:42.486 A:middle
假设我是一名花匠

00:02:42.986 --> 00:02:44.926 A:middle
我想展示的全都是

00:02:44.926 --> 00:02:46.416 A:middle
玫瑰的图片

00:02:46.416 --> 00:02:47.886 A:middle
在用户照片图库当中

00:02:48.596 --> 00:02:50.386 A:middle
这看起来是一件挺简单的事

00:02:50.386 --> 00:02:51.876 A:middle
那么我要来编程

00:02:53.196 --> 00:02:56.006 A:middle
可能我会从

00:02:56.006 --> 00:02:56.756 A:middle
颜色入手

00:02:57.346 --> 00:02:59.406 A:middle
如果照片里的主色调

00:02:59.406 --> 00:03:00.766 A:middle
是红色 那这可能是一朵

00:02:59.406 --> 00:03:00.766 A:middle
是红色 那这可能是一朵

00:03:00.766 --> 00:03:01.026 A:middle
玫瑰

00:03:02.576 --> 00:03:03.966 A:middle
问题在于 事实上

00:03:03.966 --> 00:03:05.386 A:middle
有许多玫瑰是白色的

00:03:05.386 --> 00:03:07.876 A:middle
或者是

00:03:09.076 --> 00:03:09.216 A:middle
黄色的

00:03:09.456 --> 00:03:11.916 A:middle
所以事实上我要更深入一些

00:03:11.916 --> 00:03:13.996 A:middle
描述外形

00:03:13.996 --> 00:03:17.716 A:middle
很快我就意识到

00:03:17.716 --> 00:03:20.016 A:middle
这是非常困难的

00:03:20.356 --> 00:03:23.866 A:middle
就算去写一个如此简单的程序

00:03:25.656 --> 00:03:27.016 A:middle
通过编程的方式

00:03:27.016 --> 00:03:28.276 A:middle
因此 我们需要机器学习

00:03:28.276 --> 00:03:29.216 A:middle
来帮助我们

00:03:30.546 --> 00:03:32.116 A:middle
与其去以编程的形式来描述

00:03:32.116 --> 00:03:33.336 A:middle
玫瑰是什么样的

00:03:33.376 --> 00:03:34.966 A:middle
我们会

00:03:34.966 --> 00:03:37.816 A:middle
通过我们的经验来描述一朵玫瑰

00:03:38.176 --> 00:03:39.026 A:middle
我们会去了解

00:03:39.026 --> 00:03:40.466 A:middle
玫瑰所代表的东西

00:03:40.726 --> 00:03:41.386 A:middle
通过以观察经验为主的方式

00:03:42.036 --> 00:03:43.896 A:middle
事实上机器学习

00:03:43.896 --> 00:03:44.416 A:middle
有两步

00:03:45.146 --> 00:03:46.406 A:middle
第一步 训练

00:03:48.116 --> 00:03:50.096 A:middle
那么在这一情况下你们要做什么

00:03:50.096 --> 00:03:51.376 A:middle
你们要在离线情况下收集

00:03:51.376 --> 00:03:53.056 A:middle
玫瑰 百合 向日葵的图片

00:03:53.666 --> 00:03:56.086 A:middle
并标记它们

00:03:56.086 --> 00:03:59.036 A:middle
然后你们要在一个

00:03:59.096 --> 00:04:01.156 A:middle
学习算法中运行它们

00:03:59.096 --> 00:04:01.156 A:middle
学习算法中运行它们

00:04:01.156 --> 00:04:05.506 A:middle
之后你们会得到一个我们称之为

00:04:05.546 --> 00:04:06.036 A:middle
模型的东西

00:04:07.416 --> 00:04:10.396 A:middle
这个模型

00:04:10.396 --> 00:04:12.616 A:middle
代表着一朵玫瑰

00:04:13.286 --> 00:04:14.896 A:middle
是什么样子的

00:04:15.116 --> 00:04:17.055 A:middle
几乎所有这些事情

00:04:17.156 --> 00:04:17.656 A:middle
都是在离线状态下完成的

00:04:18.446 --> 00:04:21.196 A:middle
有一个巨大的 [未听清]

00:04:21.196 --> 00:04:23.426 A:middle
在互联网上 围绕着训练这个步骤

00:04:23.906 --> 00:04:25.346 A:middle
训练这一步骤算是一个复杂的问题

00:04:27.236 --> 00:04:28.846 A:middle
那么一旦你们有了这个模型

00:04:28.846 --> 00:04:30.026 A:middle
你们就要使用这个模型

00:04:30.026 --> 00:04:33.976 A:middle
那么你们要怎样做

00:04:33.976 --> 00:04:36.236 A:middle
拍一张玫瑰花的照片

00:04:36.286 --> 00:04:38.056 A:middle
将这个模型嵌入你们的 App

00:04:38.136 --> 00:04:41.706 A:middle
将照片在模型中运行

00:04:42.376 --> 00:04:44.546 A:middle
你们就会得到标签

00:04:44.546 --> 00:04:44.996 A:middle
以及可信度

00:04:45.806 --> 00:04:48.436 A:middle
这一步被称为推断

00:04:49.726 --> 00:04:52.036 A:middle
训练这一步是非常复杂的

00:04:52.336 --> 00:04:53.886 A:middle
但在今天 推断也在变得

00:04:53.886 --> 00:04:55.636 A:middle
非常非常具有挑战性

00:04:58.686 --> 00:05:00.526 A:middle
比如说 如果你们想

00:04:58.686 --> 00:05:00.526 A:middle
比如说 如果你们想

00:05:00.526 --> 00:05:02.516 A:middle
以编程的方式描述出一个全新的

00:05:02.516 --> 00:05:05.336 A:middle
Deep Neural Network （深度神经网络） 在你们的代码中

00:05:05.336 --> 00:05:06.336 A:middle
那你们将要写出

00:05:06.336 --> 00:05:07.726 A:middle
上千行的代码

00:05:07.726 --> 00:05:08.686 A:middle
仅仅为了描述出这个网络

00:05:09.336 --> 00:05:12.146 A:middle
这会是 [未听清] 很单调乏味的

00:05:12.146 --> 00:05:15.866 A:middle
很有可能你们会面临你们

00:05:15.866 --> 00:05:17.946 A:middle
最大的挑战 就是当你们想证明

00:05:17.946 --> 00:05:21.436 A:middle
这样一个程序的正确性的时候

00:05:21.436 --> 00:05:23.826 A:middle
一旦你们确定

00:05:23.826 --> 00:05:26.636 A:middle
这程序完全正确 你们还需要

00:05:26.636 --> 00:05:28.656 A:middle
确认这一程序

00:05:28.656 --> 00:05:30.176 A:middle
尽可能有着最好的性能表现

00:05:31.996 --> 00:05:33.886 A:middle
最后 你还必须得确认

00:05:33.886 --> 00:05:35.496 A:middle
高能效

00:05:35.496 --> 00:05:36.686 A:middle
也包括在内

00:05:37.216 --> 00:05:40.116 A:middle
这些工作是

00:05:40.116 --> 00:05:43.216 A:middle
非常非常具有挑战性的

00:05:43.596 --> 00:05:44.246 A:middle
同时也可以让你完全深陷其中

00:05:44.816 --> 00:05:48.046 A:middle
在 Apple 中 我们使用设备端的

00:05:48.046 --> 00:05:49.306 A:middle
机器学习

00:05:49.306 --> 00:05:49.996 A:middle
已经有很多年了

00:05:50.536 --> 00:05:53.536 A:middle
并且我们已经完成了

00:05:53.536 --> 00:05:54.046 A:middle
这些挑战

00:05:54.126 --> 00:05:55.386 A:middle
我们已经面对过这些挑战

00:05:56.016 --> 00:05:56.716 A:middle
并且成功完成了它们

00:05:57.286 --> 00:05:58.466 A:middle
我们真的不希望

00:05:58.466 --> 00:05:59.096 A:middle
由你们来面对这些难题

00:05:59.096 --> 00:06:00.066 A:middle
我们会替你们搞定

00:05:59.096 --> 00:06:00.066 A:middle
我们会替你们搞定

00:06:00.306 --> 00:06:01.746 A:middle
我们希望你们只用专注于

00:06:01.746 --> 00:06:02.596 A:middle
体验即可

00:06:02.596 --> 00:06:03.166 A:middle
我们会直接给你们编译器

00:06:03.166 --> 00:06:04.476 A:middle
尽可能是

00:06:04.476 --> 00:06:05.776 A:middle
最好的编译器

00:06:06.536 --> 00:06:09.136 A:middle
因此 我们为你们推出

00:06:09.536 --> 00:06:11.216 A:middle
机器学习框架

00:06:11.216 --> 00:06:13.706 A:middle
这样我们就可以来解决

00:06:13.706 --> 00:06:15.516 A:middle
所有的技术难题 由你们

00:06:15.586 --> 00:06:17.016 A:middle
来负责所有体验方面的问题

00:06:17.296 --> 00:06:17.656 A:middle
在你们的 App 里

00:06:18.786 --> 00:06:21.426 A:middle
这样做的话 我们要

00:06:21.426 --> 00:06:22.686 A:middle
遵从一种分层的形式

00:06:23.376 --> 00:06:26.966 A:middle
最上层的是你们的 App

00:06:29.256 --> 00:06:31.016 A:middle
我们推出全新的

00:06:31.016 --> 00:06:32.746 A:middle
Domain Specific Framework （特定领域框架）

00:06:32.746 --> 00:06:33.686 A:middle
具体来说是

00:06:34.876 --> 00:06:36.496 A:middle
Vision Framework （视觉框架）

00:06:36.496 --> 00:06:38.846 A:middle
使得你们能够做所有

00:06:38.846 --> 00:06:40.266 A:middle
与计算机视觉

00:06:40.266 --> 00:06:40.716 A:middle
相关的工作

00:06:41.506 --> 00:06:42.976 A:middle
计算机视觉在 Vision Framework （视觉框架）中

00:06:42.976 --> 00:06:44.626 A:middle
最棒的部分

00:06:44.626 --> 00:06:46.406 A:middle
就是你不需要是一名

00:06:46.406 --> 00:06:49.616 A:middle
视觉构造专家

00:06:49.616 --> 00:06:50.406 A:middle
就可以使用 Vision Framework （视觉框架）

00:06:50.906 --> 00:06:53.816 A:middle
我们也在不断强化我们的

00:06:53.816 --> 00:06:56.966 A:middle
NLP API （自然语言处理接口） 来容纳更多的语言

00:06:57.466 --> 00:06:58.606 A:middle
和更多的功能

00:06:59.196 --> 00:07:02.486 A:middle
我们推出一个全新的

00:06:59.196 --> 00:07:02.486 A:middle
我们推出一个全新的

00:07:02.486 --> 00:07:04.106 A:middle
框架 它叫做 Core ML

00:07:05.076 --> 00:07:06.676 A:middle
这一框架

00:07:06.756 --> 00:07:08.366 A:middle
对机器学习算法有着全面的支持

00:07:08.366 --> 00:07:10.286 A:middle
更有深度的学习机制

00:07:10.586 --> 00:07:11.656 A:middle
以及标准

00:07:12.276 --> 00:07:16.266 A:middle
那么最终 所有这些

00:07:16.266 --> 00:07:18.496 A:middle
框架都是建立在

00:07:18.496 --> 00:07:20.596 A:middle
Accelerate and Metal Performance

00:07:20.596 --> 00:07:20.826 A:middle
Shaders 上的

00:07:21.396 --> 00:07:28.086 A:middle
我们可以通过 Vision Framework （视觉框架）

00:07:28.306 --> 00:07:29.506 A:middle
让大家先睹为快

00:07:31.206 --> 00:07:33.526 A:middle
Vision 是我们的一站式商店

00:07:33.526 --> 00:07:34.656 A:middle
在其中可以做所有与

00:07:34.656 --> 00:07:36.006 A:middle
计算机视觉和图像有关的事

00:07:37.056 --> 00:07:38.966 A:middle
你们可以用它来做像

00:07:39.026 --> 00:07:43.316 A:middle
物体追踪或者

00:07:43.316 --> 00:07:44.506 A:middle
基于深度学习的

00:07:44.506 --> 00:07:45.006 A:middle
面部识别

00:07:45.006 --> 00:07:47.266 A:middle
Vision Framework （视觉框架）

00:07:47.266 --> 00:07:47.736 A:middle
能做的还有很多

00:07:47.736 --> 00:07:50.306 A:middle
我们会更加细化地讨论 Vision

00:07:50.576 --> 00:07:52.066 A:middle
在明天下午的时候

00:07:52.626 --> 00:07:59.566 A:middle
NLP 这是我们另一个一站式商店

00:07:59.566 --> 00:08:00.836 A:middle
用来进行文字处理

00:07:59.566 --> 00:08:00.836 A:middle
用来进行文字处理

00:08:01.366 --> 00:08:04.686 A:middle
你们可以使用它来做

00:08:04.686 --> 00:08:05.916 A:middle
诸如语言鉴别之类的事

00:08:07.126 --> 00:08:09.416 A:middle
那么我们也会推出

00:08:09.416 --> 00:08:10.886 A:middle
Named Entity Recognition API （命名实体识别接口）

00:08:11.956 --> 00:08:14.986 A:middle
这些 API 可以告诉你

00:08:14.986 --> 00:08:17.116 A:middle
在你的文字中这是否是一个

00:08:17.116 --> 00:08:18.916 A:middle
地名 人名

00:08:18.916 --> 00:08:19.626 A:middle
或是组织机构名

00:08:20.146 --> 00:08:21.246 A:middle
我们相信这对于许多 App 开发者而言

00:08:21.246 --> 00:08:22.856 A:middle
是非常强大的功能

00:08:23.256 --> 00:08:24.276 A:middle
所以请各位去更多的了解它

00:08:24.656 --> 00:08:26.086 A:middle
在明天早上的

00:08:26.156 --> 00:08:27.946 A:middle
有关 NLP 的研讨会中

00:08:29.876 --> 00:08:33.606 A:middle
Core ML 直到现在

00:08:33.606 --> 00:08:35.476 A:middle
我们一直在讨论

00:08:35.566 --> 00:08:35.936 A:middle
Domain Specific Framework（特定领域框架）

00:08:36.395 --> 00:08:37.916 A:middle
Core ML 是我们的

00:08:37.916 --> 00:08:39.806 A:middle
机器学习框架

00:08:39.806 --> 00:08:40.525 A:middle
并且它是对领域不敏感的

00:08:41.756 --> 00:08:44.316 A:middle
它支持许多种

00:08:44.316 --> 00:08:47.136 A:middle
输入形式 例如图像 文字

00:08:48.256 --> 00:08:50.636 A:middle
字典 原始数据

00:08:51.566 --> 00:08:53.156 A:middle
所以你可以做例如

00:08:53.196 --> 00:08:53.566 A:middle
标记音乐之类的事

00:08:55.876 --> 00:08:57.346 A:middle
Core ML 还有一个有趣的地方

00:08:57.346 --> 00:08:59.006 A:middle
就是

00:08:59.006 --> 00:09:01.116 A:middle
他有处理混合

00:08:59.006 --> 00:09:01.116 A:middle
他有处理混合

00:09:01.116 --> 00:09:02.136 A:middle
输入输出类型的能力

00:09:02.446 --> 00:09:04.396 A:middle
你可以拍一张照片

00:09:04.396 --> 00:09:06.286 A:middle
然后得到一段文字

00:09:09.116 --> 00:09:10.916 A:middle
这些框架最棒的部分

00:09:11.026 --> 00:09:13.386 A:middle
在于它们可以一起

00:09:13.386 --> 00:09:13.776 A:middle
工作

00:09:15.086 --> 00:09:17.316 A:middle
你可以写一段文字 然后使它

00:09:17.316 --> 00:09:18.866 A:middle
通过你的 NLP 之后你得到一个输出值

00:09:18.866 --> 00:09:20.476 A:middle
接着你运行使它通过

00:09:20.476 --> 00:09:22.356 A:middle
Core ML 来做出如

00:09:22.436 --> 00:09:23.376 A:middle
情感分析之类的事

00:09:23.376 --> 00:09:25.336 A:middle
我们将会在关于 Core ML 的研讨会上

00:09:25.336 --> 00:09:27.666 A:middle
更细化地探讨这些

00:09:27.746 --> 00:09:29.706 A:middle
如何进行操作

00:09:30.166 --> 00:09:32.876 A:middle
上述研讨会将会在周四时举行

00:09:33.026 --> 00:09:34.556 A:middle
所有这些框架

00:09:34.556 --> 00:09:36.546 A:middle
都是由 Accelerate and MPS

00:09:36.856 --> 00:09:37.106 A:middle
所驱动的

00:09:38.316 --> 00:09:39.276 A:middle
这些就是我们的引擎

00:09:40.746 --> 00:09:42.946 A:middle
无论何时当你们需要某些

00:09:43.566 --> 00:09:45.246 A:middle
与数学相关的功能的时候

00:09:45.246 --> 00:09:46.566 A:middle
你们可以使用 Accelerate and MPS

00:09:46.566 --> 00:09:47.876 A:middle
所以它不一定必须

00:09:48.056 --> 00:09:49.436 A:middle
与机器学习

00:09:49.436 --> 00:09:49.706 A:middle
相关联

00:09:50.116 --> 00:09:53.576 A:middle
你们也可以

00:09:53.956 --> 00:09:57.766 A:middle
在创造定制化的 ML 模型时

00:09:57.766 --> 00:10:00.876 A:middle
使用 Accelerate and MPS

00:09:57.766 --> 00:10:00.876 A:middle
使用 Accelerate and MPS

00:10:00.876 --> 00:10:02.156 A:middle
所以当你们在使用

00:10:02.156 --> 00:10:03.746 A:middle
机器学习模型时

00:10:03.746 --> 00:10:05.776 A:middle
你会想要用到 Accelerate and MPS

00:10:08.076 --> 00:10:10.836 A:middle
所有这些 API

00:10:10.836 --> 00:10:11.196 A:middle
都是在用户设备上运行的

00:10:11.266 --> 00:10:12.486 A:middle
并且它们都有非常

00:10:12.486 --> 00:10:13.036 A:middle
优秀的性能表现

00:10:13.146 --> 00:10:14.656 A:middle
我们十分努力地钻研

00:10:14.656 --> 00:10:15.846 A:middle
以确保你们能够得到最好的

00:10:15.846 --> 00:10:16.856 A:middle
性能表现

00:10:18.346 --> 00:10:19.576 A:middle
因为它们是在用户设备上进行学习的

00:10:19.576 --> 00:10:21.786 A:middle
所以具有以下优势

00:10:22.366 --> 00:10:24.456 A:middle
首先 用户个人隐私

00:10:24.626 --> 00:10:27.676 A:middle
用户非常乐意知道

00:10:27.676 --> 00:10:28.716 A:middle
你并没有

00:10:28.716 --> 00:10:30.896 A:middle
发送他们的个人短信 文字

00:10:30.896 --> 00:10:34.456 A:middle
和图像到服务器上

00:10:34.456 --> 00:10:35.866 A:middle
你们的用户不需要花费额外的

00:10:35.866 --> 00:10:38.956 A:middle
数据流量 来接收这些

00:10:38.956 --> 00:10:40.556 A:middle
不 来发送这些

00:10:40.556 --> 00:10:42.686 A:middle
到服务器端以获得

00:10:44.176 --> 00:10:44.566 A:middle
预测功能

00:10:44.566 --> 00:10:46.496 A:middle
你们同样不用支付

00:10:46.706 --> 00:10:48.136 A:middle
一大笔钱

00:10:48.136 --> 00:10:49.516 A:middle
给服务器公司 就为了

00:10:49.516 --> 00:10:50.586 A:middle
建立服务器来获得

00:10:50.586 --> 00:10:51.176 A:middle
预测的功能

00:10:51.726 --> 00:10:53.136 A:middle
我们设备的

00:10:53.136 --> 00:10:53.486 A:middle
性能非常非常的强大

00:10:53.486 --> 00:10:54.696 A:middle
你们可以在设备上做许多事

00:10:55.306 --> 00:11:00.206 A:middle
最后 你的 App 会保持

00:10:55.306 --> 00:11:00.206 A:middle
最后 你的 App 会保持

00:11:00.206 --> 00:11:00.646 A:middle
可使用的状态

00:11:01.866 --> 00:11:03.856 A:middle
让我们假设你们的用户去了

00:11:03.936 --> 00:11:06.896 A:middle
约塞米蒂国家公园里的荒野

00:11:06.896 --> 00:11:08.246 A:middle
到了一个没有

00:11:08.246 --> 00:11:08.966 A:middle
网络的地方

00:11:10.076 --> 00:11:11.186 A:middle
他们还是能够使用你们的 App

00:11:11.186 --> 00:11:13.186 A:middle
这是非常强大的

00:11:14.476 --> 00:11:17.366 A:middle
然而 也许你们能做的最棒的事之一

00:11:17.436 --> 00:11:19.686 A:middle
就是

00:11:19.686 --> 00:11:20.396 A:middle
实时机器学习

00:11:21.706 --> 00:11:23.396 A:middle
我们的设备性能非常强大

00:11:23.396 --> 00:11:25.136 A:middle
它们可以运行 Modern Deep Neural Network（现代深度神经网络）

00:11:25.136 --> 00:11:28.356 A:middle
例如 ResNet 15

00:11:28.356 --> 00:11:29.656 A:middle
[未听清 ]

00:11:29.656 --> 00:11:32.966 A:middle
你们可以使用我们的设备来做

00:11:32.966 --> 00:11:34.426 A:middle
实时图像识别

00:11:34.816 --> 00:11:37.176 A:middle
在这些场景下 你不会有

00:11:37.226 --> 00:11:39.306 A:middle
任何延迟就能够获得

00:11:40.076 --> 00:11:42.146 A:middle
实际应用

00:11:43.516 --> 00:11:51.296 A:middle
[ 掌声 ]

00:11:51.796 --> 00:11:53.336 A:middle
所以对于任何具有潜在敏感性的事物

00:11:53.396 --> 00:11:54.716 A:middle
你可能会使用

00:11:54.896 --> 00:11:56.326 A:middle
实时图像识别

00:11:56.326 --> 00:12:01.276 A:middle
那么我在这里简要重述一下

00:11:56.326 --> 00:12:01.276 A:middle
那么我在这里简要重述一下

00:12:01.276 --> 00:12:02.556 A:middle
我们将会推出一系列的机器学习

00:12:02.556 --> 00:12:03.286 A:middle
框架

00:12:03.816 --> 00:12:05.606 A:middle
如果你的 App 是以视觉显示为主的

00:12:05.786 --> 00:12:07.066 A:middle
请务必使用

00:12:07.066 --> 00:12:07.516 A:middle
Vision Framework （视觉框架）

00:12:08.166 --> 00:12:10.326 A:middle
如果你的 App 是基于文字的

00:12:10.386 --> 00:12:11.486 A:middle
请使用 NLP

00:12:12.226 --> 00:12:14.426 A:middle
那么如果你觉得 NLP 和 Vision Framework（视觉框架）

00:12:14.426 --> 00:12:16.286 A:middle
都没有提供

00:12:16.776 --> 00:12:18.896 A:middle
你所需要的 API

00:12:18.896 --> 00:12:19.956 A:middle
就直接去到 Core ML 层面

00:12:20.266 --> 00:12:21.996 A:middle
Core ML 可对

00:12:22.666 --> 00:12:24.366 A:middle
标准机器学习

00:12:24.366 --> 00:12:26.076 A:middle
和深度学习算法

00:12:27.046 --> 00:12:27.586 A:middle
提供全面支持

00:12:27.586 --> 00:12:28.816 A:middle
假设你

00:12:28.956 --> 00:12:30.736 A:middle
[未听清] 你的 API 机器

00:12:30.736 --> 00:12:31.906 A:middle
学习算法 那么你

00:12:31.906 --> 00:12:34.346 A:middle
应该去使用 Accelerate and MPS.

00:12:34.996 --> 00:12:36.806 A:middle
在接下来的几天里 我们将会深入地探讨

00:12:36.806 --> 00:12:39.116 A:middle
这些框架

00:12:39.116 --> 00:12:41.366 A:middle
所以你们

00:12:41.896 --> 00:12:43.796 A:middle
[未听清] 但是今天

00:12:43.796 --> 00:12:44.956 A:middle
让我们只关注于 Core ML.

00:12:44.956 --> 00:12:46.806 A:middle
接下来 我将邀请

00:12:46.866 --> 00:12:50.586 A:middle
我的朋友和同事 Micheal 上场

00:12:51.696 --> 00:12:53.356 A:middle
&gt;&gt; 谢了 Gaurav

00:12:53.486 --> 00:12:54.186 A:middle
大家好

00:12:54.186 --> 00:12:56.056 A:middle
我非常激动能够在这里介绍

00:12:56.056 --> 00:12:58.066 A:middle
Core ML 以及它在帮助你们

00:12:58.066 --> 00:13:00.066 A:middle
创造一款优秀的 App 时所扮演的角色

00:12:58.066 --> 00:13:00.066 A:middle
创造一款优秀的 App 时所扮演的角色

00:13:00.996 --> 00:13:02.246 A:middle
我们的讨论将从

00:13:02.246 --> 00:13:04.146 A:middle
高级别 Core ML 的主要目的概览

00:13:04.146 --> 00:13:04.976 A:middle
开始

00:13:06.056 --> 00:13:07.106 A:middle
之后我们会讨论一些

00:13:07.106 --> 00:13:08.286 A:middle
关于模型的事项以及它们

00:13:08.286 --> 00:13:08.976 A:middle
是如果被表现出来的

00:13:09.016 --> 00:13:11.666 A:middle
随后我们会带大家了解一下

00:13:11.666 --> 00:13:13.196 A:middle
使用 Core ML 的

00:13:13.196 --> 00:13:16.766 A:middle
典型的开发过程

00:13:17.006 --> 00:13:18.766 A:middle
Core ML 框架

00:13:18.766 --> 00:13:20.956 A:middle
适用于 macOS iOS

00:13:22.186 --> 00:13:23.716 A:middle
watchOS 和 tvOS

00:13:25.046 --> 00:13:26.676 A:middle
但 Core ML 不仅仅是

00:13:26.676 --> 00:13:28.946 A:middle
一个框架和一大堆的 API

00:13:29.436 --> 00:13:30.946 A:middle
它实际上是一套开发工具

00:13:30.946 --> 00:13:33.016 A:middle
被设计用于

00:13:33.016 --> 00:13:35.046 A:middle
尽可能地简化

00:13:35.046 --> 00:13:36.506 A:middle
机器学习模型的创造

00:13:36.506 --> 00:13:38.826 A:middle
并将其融入你们的 App

00:13:39.556 --> 00:13:41.366 A:middle
这会让你们专注于

00:13:41.366 --> 00:13:42.826 A:middle
你们希望实现的用户体验

00:13:42.826 --> 00:13:44.216 A:middle
而不是

00:13:44.216 --> 00:13:45.546 A:middle
代码编译的细节方面

00:13:47.876 --> 00:13:51.446 A:middle
Core ML 使用非常简单

00:13:51.446 --> 00:13:52.476 A:middle
它会提供给你所需要的性能表现

00:13:52.476 --> 00:13:55.166 A:middle
同时兼容

00:13:55.166 --> 00:13:56.316 A:middle
多种

00:13:56.316 --> 00:14:00.066 A:middle
机器学习工具

00:13:56.316 --> 00:14:00.066 A:middle
机器学习工具

00:14:00.266 --> 00:14:02.516 A:middle
它的简约之处来自于

00:14:02.516 --> 00:14:04.196 A:middle
它统一标准的推断 API

00:14:04.196 --> 00:14:05.226 A:middle
涵盖了所有类型的模型

00:14:06.276 --> 00:14:08.066 A:middle
与 Xcode 相融合让你们能够

00:14:08.066 --> 00:14:09.166 A:middle
与机器学习模型互动

00:14:09.166 --> 00:14:10.626 A:middle
通过

00:14:10.626 --> 00:14:12.046 A:middle
你们早就非常熟练的

00:14:12.166 --> 00:14:13.556 A:middle
软件开发应用

00:14:15.626 --> 00:14:18.616 A:middle
Apple 已经把

00:14:18.746 --> 00:14:20.066 A:middle
它使用的推断引擎销售给了

00:14:20.066 --> 00:14:21.526 A:middle
上百万顾客

00:14:21.526 --> 00:14:23.136 A:middle
的 App 和系统服务中

00:14:23.136 --> 00:14:24.766 A:middle
现在你们也可以使用它了

00:14:24.766 --> 00:14:25.286 A:middle
通过 Core ML

00:14:25.946 --> 00:14:27.316 A:middle
如之前所说 它们

00:14:27.316 --> 00:14:28.466 A:middle
是建立在 Metal and

00:14:28.466 --> 00:14:29.836 A:middle
Accelerate 的上层

00:14:29.836 --> 00:14:31.076 A:middle
以求最大化得提升你的 App

00:14:31.076 --> 00:14:32.396 A:middle
所依附的硬件的性能

00:14:35.096 --> 00:14:36.986 A:middle
Core ML 也同样被设计工作于

00:14:36.986 --> 00:14:39.266 A:middle
这快速更迭的

00:14:39.266 --> 00:14:40.126 A:middle
机器学习生态系统中

00:14:40.746 --> 00:14:43.086 A:middle
它定义了一个全新的公共格式

00:14:43.086 --> 00:14:45.196 A:middle
以描述模型

00:14:45.196 --> 00:14:46.856 A:middle
同时还有一套工具

00:14:46.856 --> 00:14:48.056 A:middle
使你能够将

00:14:48.056 --> 00:14:50.316 A:middle
Popular Training Libraries （普通训练库）的输出值转换

00:14:50.316 --> 00:14:51.506 A:middle
为这一格式

00:14:53.156 --> 00:14:55.056 A:middle
简言之 这就是 Core ML

00:14:55.476 --> 00:14:56.656 A:middle
能够让

00:14:56.656 --> 00:14:58.836 A:middle
你的 App 中融入学习模型的过程

00:14:59.056 --> 00:15:00.566 A:middle
变得极其简单

00:14:59.056 --> 00:15:00.566 A:middle
变得极其简单

00:15:00.756 --> 00:15:02.416 A:middle
让我们再多讨论一下

00:15:02.416 --> 00:15:03.316 A:middle
这些模型

00:15:03.816 --> 00:15:07.726 A:middle
因为 Core ML

00:15:07.726 --> 00:15:08.256 A:middle
一个模型就基本上是一项功能

00:15:08.976 --> 00:15:10.836 A:middle
那么这项功能的逻辑

00:15:10.966 --> 00:15:12.386 A:middle
恰好是从数据中学习而来

00:15:12.696 --> 00:15:13.666 A:middle
但就像其他任何功能一样

00:15:13.666 --> 00:15:15.086 A:middle
它接受一系列输入值

00:15:15.086 --> 00:15:16.756 A:middle
然后产出一系列

00:15:16.756 --> 00:15:17.356 A:middle
输出值

00:15:17.956 --> 00:15:19.046 A:middle
在这个情况下 如幻灯片所示

00:15:19.046 --> 00:15:20.756 A:middle
我们有一个单一的图像输入

00:15:20.756 --> 00:15:22.766 A:middle
和一个输出值

00:15:22.766 --> 00:15:24.006 A:middle
可能会告诉你什么种类的花

00:15:24.116 --> 00:15:26.196 A:middle
包含在其中

00:15:26.456 --> 00:15:28.966 A:middle
在许多使用场景中

00:15:28.966 --> 00:15:30.066 A:middle
你也许想应用

00:15:30.066 --> 00:15:31.976 A:middle
在核心中有关键功能的

00:15:32.206 --> 00:15:33.806 A:middle
机器学习模型

00:15:34.996 --> 00:15:36.876 A:middle
一项常见的功能就是

00:15:36.876 --> 00:15:37.766 A:middle
做出一种

00:15:37.766 --> 00:15:38.636 A:middle
分类

00:15:39.576 --> 00:15:41.636 A:middle
它接受一系列的输入值

00:15:41.636 --> 00:15:42.946 A:middle
并给它们指定

00:15:42.946 --> 00:15:43.316 A:middle
一些分类标签

00:15:43.846 --> 00:15:46.466 A:middle
比如说

00:15:46.466 --> 00:15:47.066 A:middle
拿情感分析举例

00:15:47.706 --> 00:15:49.206 A:middle
你输入一句英文语句

00:15:49.206 --> 00:15:51.196 A:middle
并输出

00:15:51.196 --> 00:15:52.566 A:middle
这句话是积极的还是消极的

00:15:52.566 --> 00:15:55.506 A:middle
然后这里

00:15:56.836 --> 00:15:57.026 A:middle
由一个 emoji 代表

00:15:57.116 --> 00:15:58.736 A:middle
那么为了编写

00:15:59.106 --> 00:16:01.606 A:middle
这种类型的功能 Core ML

00:15:59.106 --> 00:16:01.606 A:middle
这种类型的功能 Core ML

00:16:01.606 --> 00:16:02.836 A:middle
支持种类繁多的

00:16:02.836 --> 00:16:03.366 A:middle
模型

00:16:03.906 --> 00:16:08.866 A:middle
它对于神经网络有广泛的支持

00:16:08.866 --> 00:16:10.886 A:middle
包括前惯性

00:16:10.886 --> 00:16:11.946 A:middle
和周期性神经网络两种

00:16:11.946 --> 00:16:13.246 A:middle
以及超过三十种不同的层级

00:16:13.246 --> 00:16:13.706 A:middle
类型

00:16:14.956 --> 00:16:17.076 A:middle
它同样支持 Tree Ensembles （树集）

00:16:17.076 --> 00:16:18.546 A:middle
支持向量机

00:16:18.546 --> 00:16:19.886 A:middle
和广义线性模型

00:16:21.176 --> 00:16:22.516 A:middle
每一个类型的模型

00:16:22.516 --> 00:16:23.996 A:middle
事实上都是

00:16:23.996 --> 00:16:24.536 A:middle
模型的大集合

00:16:24.766 --> 00:16:26.046 A:middle
我们可以利用这场研讨会

00:16:26.046 --> 00:16:27.696 A:middle
以及整场大会所剩余的时间

00:16:27.696 --> 00:16:28.956 A:middle
来讨论

00:16:28.956 --> 00:16:31.696 A:middle
它们其中的一个

00:16:31.696 --> 00:16:32.826 A:middle
但是请不要被吓到了

00:16:33.106 --> 00:16:34.536 A:middle
你不需要成为一个

00:16:34.536 --> 00:16:36.036 A:middle
机器学习专家才能使用

00:16:36.036 --> 00:16:36.796 A:middle
这些模型

00:16:37.296 --> 00:16:39.446 A:middle
你只要继续专注于

00:16:39.446 --> 00:16:41.246 A:middle
这些你尽力想实现的使用场景

00:16:41.246 --> 00:16:42.936 A:middle
让 Core ML 去处理那些

00:16:42.936 --> 00:16:43.966 A:middle
低级的细节即可

00:16:44.546 --> 00:16:45.896 A:middle
Core ML 代表一个模型

00:16:45.896 --> 00:16:46.776 A:middle
在一个文件中

00:16:47.316 --> 00:16:48.946 A:middle
也就是说 分享一个模型就像

00:16:48.946 --> 00:16:50.196 A:middle
分享一个文件

00:16:50.806 --> 00:16:52.686 A:middle
这个文件有着高级信息

00:16:52.686 --> 00:16:53.976 A:middle
是作为开发者的你

00:16:53.976 --> 00:16:54.886 A:middle
需要编程完成的

00:16:54.886 --> 00:16:55.656 A:middle
这就是功能

00:16:55.656 --> 00:16:57.276 A:middle
描述 它的输入 类型

00:16:57.276 --> 00:16:59.566 A:middle
输出 以及那些

00:16:59.566 --> 00:17:00.846 A:middle
Core ML 为了执行功能

00:16:59.566 --> 00:17:00.846 A:middle
Core ML 为了执行功能

00:17:00.846 --> 00:17:02.106 A:middle
所需要的细节部分

00:17:02.446 --> 00:17:03.656 A:middle
对于神经网络而言 这应该就是

00:17:03.656 --> 00:17:04.685 A:middle
神经网络的结构

00:17:04.685 --> 00:17:06.486 A:middle
加上它的

00:17:06.486 --> 00:17:06.915 A:middle
训练参数

00:17:07.006 --> 00:17:08.616 A:middle
我们鼓励大家去

00:17:08.616 --> 00:17:10.036 A:middle
我们周四的研讨会来了解更多

00:17:10.036 --> 00:17:11.665 A:middle
关于这个格式

00:17:11.665 --> 00:17:15.695 A:middle
和一系列它可以编码的模型

00:17:15.695 --> 00:17:16.856 A:middle
但是可能现在

00:17:16.856 --> 00:17:17.715 A:middle
你们会想

00:17:17.715 --> 00:17:20.066 A:middle
我到哪里才能弄到这些

00:17:20.066 --> 00:17:20.616 A:middle
模型

00:17:21.116 --> 00:17:24.175 A:middle
模型是哪里来的

00:17:24.175 --> 00:17:25.965 A:middle
那么 建议大家从这里开始

00:17:25.965 --> 00:17:27.326 A:middle
查看我们的机器学习

00:17:27.326 --> 00:17:28.156 A:middle
登场介绍页面

00:17:28.156 --> 00:17:29.386 A:middle
在 developer.apple.com.

00:17:30.816 --> 00:17:32.286 A:middle
接着你们会找到一些

00:17:32.286 --> 00:17:34.276 A:middle
执行特定任务

00:17:34.766 --> 00:17:36.966 A:middle
立即可用的模型

00:17:36.966 --> 00:17:37.916 A:middle
已经是 Core ML 格式的了

00:17:38.976 --> 00:17:40.186 A:middle
我们会扩充这一套模型

00:17:40.186 --> 00:17:40.746 A:middle
随着时间的推移

00:17:40.746 --> 00:17:42.586 A:middle
同时我们鼓励大家不断探索

00:17:42.826 --> 00:17:43.556 A:middle
尝试一下

00:17:43.556 --> 00:17:44.586 A:middle
这是一个很棒的途径

00:17:44.586 --> 00:17:45.656 A:middle
去总体了解一下机器学习

00:17:45.656 --> 00:17:47.406 A:middle
和 Core ML 以及

00:17:47.406 --> 00:17:49.126 A:middle
它们可以怎样被应用到你的 App 中

00:17:51.076 --> 00:17:52.586 A:middle
但是我们可能没有

00:17:52.586 --> 00:17:53.366 A:middle
所有你们需要的模型

00:17:53.516 --> 00:17:54.886 A:middle
为了让你们能够应用

00:17:54.886 --> 00:17:55.586 A:middle
你们可能需要基于现有的模型做一些

00:17:55.586 --> 00:17:56.956 A:middle
定制

00:17:56.956 --> 00:17:58.376 A:middle
或者从头开始

00:17:58.376 --> 00:17:59.086 A:middle
制作一个全新的模型

00:18:00.016 --> 00:18:01.856 A:middle
因此我们鼓励你

00:18:01.856 --> 00:18:03.986 A:middle
和你的同事们利用好

00:18:03.986 --> 00:18:05.256 A:middle
机器学习社区

00:18:05.776 --> 00:18:07.526 A:middle
这是一个非常活跃

00:18:07.526 --> 00:18:08.016 A:middle
的社区

00:18:09.396 --> 00:18:11.026 A:middle
那里有无数的库和现成的

00:18:11.026 --> 00:18:12.486 A:middle
模型可供你们

00:18:12.486 --> 00:18:13.326 A:middle
使用

00:18:14.096 --> 00:18:15.686 A:middle
另外 每周都会有非常棒的

00:18:15.686 --> 00:18:17.426 A:middle
线上教程和全新的课程

00:18:17.426 --> 00:18:18.806 A:middle
上线

00:18:19.966 --> 00:18:20.586 A:middle
你们可以做到的

00:18:20.796 --> 00:18:22.106 A:middle
那里有非常棒的资源

00:18:22.106 --> 00:18:22.606 A:middle
可供学习

00:18:22.606 --> 00:18:24.036 A:middle
我有信心

00:18:24.036 --> 00:18:24.906 A:middle
你们都可以成功起步的

00:18:24.906 --> 00:18:26.776 A:middle
这是个美好的时代

00:18:28.316 --> 00:18:30.066 A:middle
但你们会发现

00:18:30.066 --> 00:18:32.096 A:middle
大部分的库都是专注于

00:18:32.096 --> 00:18:33.266 A:middle
训练的

00:18:33.986 --> 00:18:35.266 A:middle
因为 这是非常重要的一步

00:18:35.266 --> 00:18:36.986 A:middle
他们会花大量的

00:18:36.986 --> 00:18:38.146 A:middle
时间确保你们可以

00:18:38.146 --> 00:18:39.046 A:middle
训练出一个很棒的模型

00:18:39.046 --> 00:18:40.866 A:middle
我们希望你们做的是

00:18:40.926 --> 00:18:42.776 A:middle
让 Core ML 代替你们

00:18:42.776 --> 00:18:44.686 A:middle
去获得那些机器学习模型

00:18:44.686 --> 00:18:45.916 A:middle
并切实部署到

00:18:45.916 --> 00:18:46.986 A:middle
你们的 App 上

00:18:47.736 --> 00:18:49.416 A:middle
所以我们推出 Core ML 工具

00:18:49.416 --> 00:18:51.206 A:middle
来做这些

00:18:51.206 --> 00:18:52.166 A:middle
Python package

00:18:52.696 --> 00:18:54.546 A:middle
这是一个 Python package

00:18:54.546 --> 00:18:55.686 A:middle
它完全集中于

00:18:55.686 --> 00:18:57.826 A:middle
接受这些来自于机器学习库的

00:18:57.826 --> 00:18:59.536 A:middle
输出值

00:18:59.536 --> 00:19:01.126 A:middle
并将它们转化为

00:18:59.536 --> 00:19:01.126 A:middle
并将它们转化为

00:19:01.126 --> 00:19:01.576 A:middle
Core ML 格式

00:19:02.646 --> 00:19:04.096 A:middle
随后我们会不断扩充这些工具

00:19:04.096 --> 00:19:06.606 A:middle
但同时

00:19:06.606 --> 00:19:07.976 A:middle
它们也是开源的

00:19:08.516 --> 00:19:15.046 A:middle
[ 掌声 ]

00:19:15.546 --> 00:19:16.706 A:middle
所以这意味着 就算你没有

00:19:16.706 --> 00:19:17.626 A:middle
找到你需要的转换器

00:19:17.626 --> 00:19:19.466 A:middle
我们非常相信

00:19:19.466 --> 00:19:20.606 A:middle
你也已经可以自己写出一个了

00:19:21.136 --> 00:19:22.576 A:middle
所有这些原始数据

00:19:22.576 --> 00:19:23.606 A:middle
都可以随时为你所用

00:19:24.086 --> 00:19:25.316 A:middle
我再次鼓励大家

00:19:25.316 --> 00:19:27.306 A:middle
来参加我们周四的研讨会

00:19:27.306 --> 00:19:28.836 A:middle
了解更多关于 Python package 的信息

00:19:28.836 --> 00:19:30.116 A:middle
以及你可以怎样简单地转换

00:19:30.116 --> 00:19:30.516 A:middle
模型

00:19:30.516 --> 00:19:34.946 A:middle
好的 现在我们有了这个模型

00:19:35.396 --> 00:19:36.626 A:middle
让我们来讨论一下如果

00:19:36.626 --> 00:19:37.156 A:middle
在我们的 App 中使用它

00:19:37.156 --> 00:19:40.256 A:middle
那么你需要从

00:19:40.256 --> 00:19:41.626 A:middle
以 Core ML 为格式的

00:19:41.626 --> 00:19:42.616 A:middle
机器学习模型入手

00:19:43.986 --> 00:19:45.666 A:middle
你只需要将它加入到

00:19:45.666 --> 00:19:46.656 A:middle
你的 Xcode 的项目里

00:19:47.416 --> 00:19:49.036 A:middle
然后 Xcode 就会自动

00:19:49.176 --> 00:19:50.636 A:middle
将这个模型识别为

00:19:50.636 --> 00:19:51.626 A:middle
机器学习模型

00:19:51.626 --> 00:19:53.366 A:middle
然后它会为你生成一个

00:19:53.366 --> 00:19:53.566 A:middle
交互界面

00:19:54.116 --> 00:19:55.036 A:middle
它会给你一个

00:19:55.036 --> 00:19:56.326 A:middle
这个模型的编程界面

00:19:56.326 --> 00:19:58.746 A:middle
使用的数据类型和

00:19:58.746 --> 00:19:59.646 A:middle
结构都是

00:19:59.646 --> 00:20:00.906 A:middle
你们编程时很熟悉的

00:19:59.646 --> 00:20:00.906 A:middle
你们编程时很熟悉的

00:20:01.386 --> 00:20:03.536 A:middle
你们将会使用

00:20:03.686 --> 00:20:05.346 A:middle
这一交互界面并将它编译进

00:20:05.346 --> 00:20:06.446 A:middle
你们的 App

00:20:07.376 --> 00:20:09.086 A:middle
但除此之外 模型本身

00:20:09.086 --> 00:20:10.866 A:middle
也会被编译

00:20:10.936 --> 00:20:12.496 A:middle
并归入到你们的 App 中

00:20:12.856 --> 00:20:14.636 A:middle
也就是说 我们使用的这一格式

00:20:14.636 --> 00:20:15.636 A:middle
是已被优化过的

00:20:15.636 --> 00:20:17.856 A:middle
变得更加开放及兼容

00:20:17.856 --> 00:20:19.176 A:middle
并且使它成为

00:20:19.176 --> 00:20:20.886 A:middle
为了在设备上运行

00:20:20.886 --> 00:20:21.456 A:middle
而优化的格式

00:20:22.996 --> 00:20:24.556 A:middle
为了给你们展示这一操作

00:20:24.656 --> 00:20:25.866 A:middle
我要邀请我的朋友

00:20:25.866 --> 00:20:27.156 A:middle
兼同事 Lizi 到台上来

00:20:28.516 --> 00:20:34.406 A:middle
[ 掌声 ]

00:20:34.906 --> 00:20:36.436 A:middle
我是 Core ML 团队

00:20:36.436 --> 00:20:36.946 A:middle
的工程师

00:20:37.926 --> 00:20:40.316 A:middle
今天 让我们来看一下

00:20:40.316 --> 00:20:42.216 A:middle
你们该如何使用 Core ML 将

00:20:42.216 --> 00:20:43.576 A:middle
机器学习融入你们的

00:20:43.576 --> 00:20:44.106 A:middle
App

00:20:45.156 --> 00:20:46.976 A:middle
首先设定一个背景

00:20:47.796 --> 00:20:49.016 A:middle
就像我喜爱机器

00:20:49.016 --> 00:20:51.076 A:middle
学习一样 我同样喜欢园艺

00:20:51.076 --> 00:20:53.096 A:middle
如果你是像我一样的人

00:20:53.546 --> 00:20:54.796 A:middle
每当你见到

00:20:54.796 --> 00:20:56.436 A:middle
新品种的花时

00:20:56.436 --> 00:20:58.336 A:middle
相信你会非常激动并会马上

00:20:58.336 --> 00:20:59.276 A:middle
就想认出它的种类

00:21:00.366 --> 00:21:01.706 A:middle
所以我们希望打造一款 App

00:21:02.296 --> 00:21:03.866 A:middle
可以获取

00:21:03.866 --> 00:21:05.476 A:middle
不同种类的花的图像

00:21:05.516 --> 00:21:07.426 A:middle
并把它们按类型分类

00:21:08.346 --> 00:21:09.886 A:middle
但首先 要做到这一点

00:21:10.466 --> 00:21:11.296 A:middle
我们需要一个模型

00:21:12.866 --> 00:21:14.166 A:middle
所以我们进一步

00:21:14.166 --> 00:21:15.766 A:middle
收集了许多

00:21:15.896 --> 00:21:17.116 A:middle
不同类型的花的图片

00:21:17.486 --> 00:21:18.686 A:middle
并给每一个都做了标记

00:21:20.286 --> 00:21:21.656 A:middle
之后我训练了一个神经网络分类器

00:21:21.756 --> 00:21:23.686 A:middle
通过使用一个开源的

00:21:23.756 --> 00:21:25.296 A:middle
机器学习工具

00:21:25.296 --> 00:21:27.326 A:middle
将其转换成了我们的 Core ML

00:21:27.416 --> 00:21:27.666 A:middle
格式

00:21:29.256 --> 00:21:31.896 A:middle
有了这个训练出的模型

00:21:31.896 --> 00:21:33.086 A:middle
和这个花朵分类器的 App Shell （程序外壳）

00:21:33.086 --> 00:21:35.006 A:middle
我们来看一下

00:21:35.006 --> 00:21:36.906 A:middle
如果将这两者

00:21:36.906 --> 00:21:37.276 A:middle
合二为一

00:21:38.946 --> 00:21:40.746 A:middle
在 Xcode 里 你可以看到

00:21:40.746 --> 00:21:42.736 A:middle
我正在运行花朵分类器

00:21:42.736 --> 00:21:44.616 A:middle
这个 App

00:21:44.616 --> 00:21:45.626 A:middle
就在我设备屏幕的边上

00:21:46.686 --> 00:21:48.606 A:middle
我可以做的就是

00:21:48.606 --> 00:21:50.346 A:middle
进入到照片图库中

00:21:50.346 --> 00:21:52.626 A:middle
选择一张图片 但现在

00:21:52.736 --> 00:21:53.906 A:middle
它还不能为输出结果

00:21:53.906 --> 00:21:54.906 A:middle
做任何预测

00:21:55.396 --> 00:21:57.246 A:middle
它只显示出这一行而已

00:21:58.796 --> 00:22:00.086 A:middle
那么如果我去看

00:21:58.796 --> 00:22:00.086 A:middle
那么如果我去看

00:22:00.086 --> 00:22:02.606 A:middle
视频控制器 我们能看到的是

00:22:02.606 --> 00:22:04.836 A:middle
它有这样一个 Caption Method （说明方式）

00:22:05.046 --> 00:22:06.226 A:middle
目前只会返回

00:22:06.256 --> 00:22:06.856 A:middle
空白行

00:22:07.426 --> 00:22:10.746 A:middle
它实际上并没有做什么

00:22:10.836 --> 00:22:12.636 A:middle
在这里面 我有

00:22:12.636 --> 00:22:14.176 A:middle
花朵分类器

00:22:14.236 --> 00:22:14.506 A:middle
是以 ML 模型为格式的

00:22:15.186 --> 00:22:16.656 A:middle
我需要做的就是选中它

00:22:17.306 --> 00:22:18.696 A:middle
并将它拖拽到

00:22:18.696 --> 00:22:19.066 A:middle
项目中

00:22:19.786 --> 00:22:22.936 A:middle
我们可以看到 我一把它加入进去

00:22:23.066 --> 00:22:24.796 A:middle
Xcode 就自动

00:22:24.796 --> 00:22:26.546 A:middle
识别了这个文件格式

00:22:27.406 --> 00:22:28.716 A:middle
显示出了模型的名字

00:22:28.716 --> 00:22:30.816 A:middle
以及它的类型

00:22:30.816 --> 00:22:31.346 A:middle
在这下面

00:22:31.926 --> 00:22:33.666 A:middle
我们可以看到文件大小是

00:22:33.666 --> 00:22:35.226 A:middle
41 兆字节 以及其它

00:22:35.226 --> 00:22:36.616 A:middle
信息例如作者

00:22:36.866 --> 00:22:38.296 A:middle
许可或者描述

00:22:38.296 --> 00:22:39.226 A:middle
都一起显示出来

00:22:40.446 --> 00:22:41.876 A:middle
在底部 我们可以看到

00:22:41.916 --> 00:22:43.266 A:middle
这个模型所承接的

00:22:43.266 --> 00:22:45.736 A:middle
输入和输出 首先就是

00:22:46.126 --> 00:22:48.136 A:middle
花朵图像 它的类型是图像

00:22:48.476 --> 00:22:49.966 A:middle
被划分为红色 绿色 蓝色

00:22:50.086 --> 00:22:51.096 A:middle
以及宽度和高度

00:22:52.406 --> 00:22:53.816 A:middle
我们同样可以看到

00:22:53.816 --> 00:22:55.506 A:middle
它将花朵类型输出为一行

00:22:56.166 --> 00:22:57.756 A:middle
所以如果给它

00:22:57.756 --> 00:22:59.576 A:middle
一张玫瑰的图片 我会想要花朵类型

00:22:59.646 --> 00:23:00.526 A:middle
显示玫瑰

00:22:59.646 --> 00:23:00.526 A:middle
显示玫瑰

00:23:01.896 --> 00:23:03.466 A:middle
这里同样存在一个词典

00:23:03.466 --> 00:23:05.016 A:middle
包含许多不同类型花朵

00:23:05.016 --> 00:23:05.736 A:middle
的可能性

00:23:06.306 --> 00:23:08.796 A:middle
我要做的第一件事

00:23:10.206 --> 00:23:11.236 A:middle
就是我要确保

00:23:11.436 --> 00:23:12.966 A:middle
我把它加入到了我的 App

00:23:13.586 --> 00:23:15.876 A:middle
之后你们会看到

00:23:16.396 --> 00:23:18.406 A:middle
这中间的窗口会显示

00:23:18.406 --> 00:23:20.086 A:middle
Swift Generated Source （生成源）

00:23:20.366 --> 00:23:21.896 A:middle
已经加入到了 App 中

00:23:22.896 --> 00:23:23.966 A:middle
这意味着我们可以

00:23:23.966 --> 00:23:25.866 A:middle
真正地使用这生成的代码

00:23:26.176 --> 00:23:27.536 A:middle
来加载这一模型

00:23:27.536 --> 00:23:28.046 A:middle
并靠它来做出预测

00:23:28.846 --> 00:23:30.576 A:middle
为了给你们展示 我们看一下

00:23:30.576 --> 00:23:31.206 A:middle
视频控制器

00:23:31.816 --> 00:23:36.156 A:middle
我要做的第一件事是

00:23:36.156 --> 00:23:37.526 A:middle
定义这些花朵模型

00:23:38.766 --> 00:23:40.216 A:middle
为了将它实例化 我需要

00:23:40.216 --> 00:23:42.086 A:middle
做的就是使用

00:23:42.206 --> 00:23:45.656 A:middle
模型类本身的名字

00:23:45.806 --> 00:23:47.346 A:middle
我们会看到它被高亮的颜色标出

00:23:47.506 --> 00:23:48.456 A:middle
因为它已经存在于

00:23:48.456 --> 00:23:48.866 A:middle
这个项目中

00:23:49.906 --> 00:23:51.516 A:middle
在下一个 Caption Method （说明方式） 中

00:23:51.766 --> 00:23:52.866 A:middle
我们来定义一个预测

00:23:53.446 --> 00:23:56.886 A:middle
我们会使用

00:23:56.936 --> 00:24:00.206 A:middle
这个花朵模型并查看它

00:23:56.936 --> 00:24:00.206 A:middle
这个花朵模型并查看它

00:24:01.076 --> 00:24:02.546 A:middle
我们会看到使用自动完成

00:24:02.696 --> 00:24:03.896 A:middle
这个预测方式是

00:24:03.896 --> 00:24:05.156 A:middle
可用的 并且它将

00:24:05.156 --> 00:24:07.056 A:middle
CVPixelBuffer 作为输入值

00:24:07.906 --> 00:24:09.666 A:middle
我们要使用它并将

00:24:09.666 --> 00:24:12.786 A:middle
图像直接传输给它

00:24:13.286 --> 00:24:14.726 A:middle
现在 我们可以取代

00:24:14.866 --> 00:24:16.776 A:middle
这一预先设定的行 我们可以使用

00:24:16.776 --> 00:24:18.716 A:middle
预测物 同时取代之前的

00:24:19.236 --> 00:24:20.966 A:middle
并返回出花朵类型

00:24:21.676 --> 00:24:24.166 A:middle
现在如果我保存 我们就可以创建

00:24:24.166 --> 00:24:25.266 A:middle
并运行这个 App

00:24:26.026 --> 00:24:27.586 A:middle
我在做这件事的时候

00:24:27.586 --> 00:24:29.916 A:middle
这个模型本身

00:24:29.916 --> 00:24:31.306 A:middle
正在被编译

00:24:31.306 --> 00:24:32.566 A:middle
并归入到 App 中

00:24:33.706 --> 00:24:34.936 A:middle
那么我们回到设备上看

00:24:35.476 --> 00:24:37.196 A:middle
打开我的照片图库

00:24:37.506 --> 00:24:39.136 A:middle
选择一朵

00:24:39.136 --> 00:24:39.366 A:middle
在第二排的玫瑰图片

00:24:40.216 --> 00:24:41.536 A:middle
我们可以看到

00:24:41.536 --> 00:24:42.696 A:middle
它能够显示出 玫瑰

00:24:43.516 --> 00:24:49.356 A:middle
[ 掌声 ]

00:24:49.856 --> 00:24:51.106 A:middle
我们再选一张

00:24:51.106 --> 00:24:52.356 A:middle
比如第三排的向日葵

00:24:53.406 --> 00:24:54.746 A:middle
它同样能够显示出来

00:24:55.736 --> 00:24:56.846 A:middle
或者识别起来

00:24:56.846 --> 00:24:58.216 A:middle
更加困难的 比如下面的

00:24:58.216 --> 00:24:59.646 A:middle
西番莲

00:24:59.646 --> 00:25:00.196 A:middle
它还是可以识别出来

00:24:59.646 --> 00:25:00.196 A:middle
它还是可以识别出来

00:25:01.296 --> 00:25:04.346 A:middle
那么简要重述一下 我们可以

00:25:04.576 --> 00:25:06.876 A:middle
将一个训练好的机器学习模型

00:25:07.146 --> 00:25:09.236 A:middle
拖拽到 Xcode 中  并将它十分简单地添加到

00:25:09.236 --> 00:25:10.906 A:middle
App 中 只需要三行

00:25:10.946 --> 00:25:11.346 A:middle
代码

00:25:12.006 --> 00:25:13.696 A:middle
现在我们有一个完整的神经

00:25:13.696 --> 00:25:15.186 A:middle
网络分类器

00:25:15.186 --> 00:25:15.616 A:middle
在设备上运行

00:25:16.576 --> 00:25:19.096 A:middle
但我还有一些其他的模型

00:25:19.096 --> 00:25:20.576 A:middle
可能也想要尝试一下

00:25:21.006 --> 00:25:21.896 A:middle
那么让我们再做一次

00:25:22.376 --> 00:25:25.016 A:middle
你们可能注意到了

00:25:25.016 --> 00:25:26.506 A:middle
这也有一个叫 FlowerSqueeze 的模型

00:25:27.356 --> 00:25:28.996 A:middle
那么首先我要做的

00:25:28.996 --> 00:25:31.346 A:middle
就是再一次地拖拽它

00:25:32.066 --> 00:25:35.476 A:middle
然后我也要将它加入到

00:25:35.596 --> 00:25:37.246 A:middle
花朵分类器中

00:25:37.386 --> 00:25:39.416 A:middle
这个叫 Hello Flowers （你好花朵）的目标项目中

00:25:39.566 --> 00:25:40.686 A:middle
然后在后台

00:25:40.816 --> 00:25:41.786 A:middle
开始生成 Swift 源

00:25:42.566 --> 00:25:43.956 A:middle
我们会看到 如果我们再放大一些

00:25:44.036 --> 00:25:46.016 A:middle
这个模型的名字

00:25:46.056 --> 00:25:46.456 A:middle
是不同的

00:25:46.606 --> 00:25:48.606 A:middle
它叫做 FlowerSqueeze 但是在

00:25:48.606 --> 00:25:50.186 A:middle
底部 输入和

00:25:50.186 --> 00:25:51.706 A:middle
输出是完全一样的

00:25:53.086 --> 00:25:54.626 A:middle
这意味着如果

00:25:54.626 --> 00:25:55.886 A:middle
我回到视频控制器中

00:25:57.786 --> 00:25:59.016 A:middle
取代了花朵 干脆

00:25:59.476 --> 00:26:00.906 A:middle
我们直接删除花朵分类器

00:25:59.476 --> 00:26:00.906 A:middle
我们直接删除花朵分类器

00:26:01.076 --> 00:26:02.006 A:middle
我们不再需要

00:26:02.006 --> 00:26:02.336 A:middle
那个模型了

00:26:02.926 --> 00:26:05.656 A:middle
在视频控制器中

00:26:06.216 --> 00:26:07.436 A:middle
不再将这个实例化

00:26:07.436 --> 00:26:10.146 A:middle
我们来使用 FlowerSqueeze

00:26:10.786 --> 00:26:13.336 A:middle
这个模型非常干净整洁的地方在于

00:26:13.386 --> 00:26:15.276 A:middle
它的大小

00:26:16.136 --> 00:26:19.106 A:middle
我们返回 它的大小

00:26:19.106 --> 00:26:21.146 A:middle
只有 5.4 兆字节

00:26:21.146 --> 00:26:21.806 A:middle
这是一个非常大的不同之处

00:26:22.266 --> 00:26:27.086 A:middle
回到设备上 我们进入到

00:26:27.086 --> 00:26:28.756 A:middle
照片图库中并选择

00:26:28.756 --> 00:26:29.906 A:middle
另一个 比如这朵雾中之爱

00:26:29.906 --> 00:26:32.256 A:middle
可以看到这个 App

00:26:32.256 --> 00:26:34.966 A:middle
同样可以

00:26:35.556 --> 00:26:35.676 A:middle
将它分类

00:26:35.886 --> 00:26:38.856 A:middle
试一下另一朵西番莲或者

00:26:38.856 --> 00:26:40.376 A:middle
一张更难识别的

00:26:40.376 --> 00:26:42.696 A:middle
边上这朵玫瑰的照片

00:26:42.696 --> 00:26:43.966 A:middle
它仍然能够正确地预测出来

00:26:44.586 --> 00:26:48.716 A:middle
再扼要重述一下 我们刚看到

00:26:48.856 --> 00:26:50.126 A:middle
我们可以在设备上运行这个

00:26:50.126 --> 00:26:51.676 A:middle
神经网络分类器

00:26:51.896 --> 00:26:54.086 A:middle
通过使用 Core ML 这一切

00:26:54.176 --> 00:26:55.886 A:middle
都只用了仅仅几行代码而已

00:26:56.516 --> 00:27:04.086 A:middle
[ 掌声 ]

00:26:56.516 --> 00:27:04.086 A:middle
[ 掌声 ]

00:27:04.586 --> 00:27:06.396 A:middle
现在我们来回顾一下

00:27:06.396 --> 00:27:08.616 A:middle
我们刚才都看到了什么

00:27:08.856 --> 00:27:11.556 A:middle
我们看到在 Xcode 中  一旦

00:27:11.746 --> 00:27:13.586 A:middle
你将一个训练过的机器学习模型拖拽进

00:27:13.586 --> 00:27:15.106 A:middle
你的 App 中

00:27:15.376 --> 00:27:16.446 A:middle
你会得到这个

00:27:16.446 --> 00:27:17.956 A:middle
生成的界面 在下方提供给你

00:27:17.956 --> 00:27:19.616 A:middle
例如模型名称

00:27:19.616 --> 00:27:21.836 A:middle
和类型的信息

00:27:21.836 --> 00:27:23.316 A:middle
以及其他信息

00:27:23.316 --> 00:27:25.806 A:middle
例如模型大小

00:27:25.806 --> 00:27:27.526 A:middle
或者任何其他

00:27:27.526 --> 00:27:27.676 A:middle
作者加入进去的信息

00:27:28.276 --> 00:27:29.996 A:middle
在底部

00:27:30.086 --> 00:27:31.816 A:middle
你们可以看到 例如这一模型的

00:27:31.816 --> 00:27:33.096 A:middle
输入和输出的信息

00:27:33.096 --> 00:27:34.946 A:middle
这是非常有帮助的

00:27:34.946 --> 00:27:35.946 A:middle
当你想要

00:27:35.946 --> 00:27:36.106 A:middle
使用它的时候

00:27:36.106 --> 00:27:38.276 A:middle
一旦你将它加入到你的

00:27:38.276 --> 00:27:40.166 A:middle
App 中  你就会得到生成的代码

00:27:40.166 --> 00:27:42.106 A:middle
你可以用来加载并使用

00:27:42.106 --> 00:27:45.366 A:middle
这一模型来做出预测

00:27:45.436 --> 00:27:47.076 A:middle
我们也在 App 中看到

00:27:47.076 --> 00:27:48.706 A:middle
使用它

00:27:48.706 --> 00:27:49.106 A:middle
是多么的简单

00:27:49.956 --> 00:27:51.826 A:middle
再说一次 即便模型是

00:27:51.826 --> 00:27:53.746 A:middle
一个神经网络分类器

00:27:53.746 --> 00:27:55.266 A:middle
我们将它实例化所需要做的

00:27:55.266 --> 00:27:56.626 A:middle
就是访问

00:27:56.626 --> 00:27:57.066 A:middle
文件的名称

00:27:57.736 --> 00:27:58.856 A:middle
这意味着模型类型

00:27:58.856 --> 00:28:00.686 A:middle
是完全抽象的

00:27:58.856 --> 00:28:00.686 A:middle
是完全抽象的

00:28:00.686 --> 00:28:01.856 A:middle
不论它是一个向量机

00:28:01.856 --> 00:28:03.536 A:middle
一个一般线性模型

00:28:03.536 --> 00:28:05.686 A:middle
或者一个神经网络

00:28:05.916 --> 00:28:07.906 A:middle
你都可以以同样的方式加载它

00:28:07.906 --> 00:28:09.206 A:middle
我们还注意到

00:28:09.206 --> 00:28:11.036 A:middle
预测方式使用到了一个

00:28:11.136 --> 00:28:12.106 A:middle
CVPixelBuffer

00:28:12.776 --> 00:28:14.346 A:middle
它是一个强类型 所以你很清楚

00:28:14.346 --> 00:28:15.406 A:middle
你要在

00:28:15.536 --> 00:28:17.496 A:middle
编辑的时候就检查输入错误

00:28:17.646 --> 00:28:18.616 A:middle
而不是在运行的时候

00:28:20.026 --> 00:28:22.766 A:middle
现在让我们来更深入的看一下

00:28:23.126 --> 00:28:24.486 A:middle
由 Xcode 创建的

00:28:24.536 --> 00:28:27.416 A:middle
Generated Source （生成源）

00:28:27.476 --> 00:28:29.706 A:middle
在这里 我们看到它定义了三个

00:28:29.706 --> 00:28:31.696 A:middle
层级 第一级是输入

00:28:31.696 --> 00:28:33.966 A:middle
将花朵图片

00:28:33.966 --> 00:28:35.456 A:middle
定义为一个 CVPixelBuffer

00:28:36.456 --> 00:28:38.306 A:middle
之后我们看到输出值

00:28:38.306 --> 00:28:40.836 A:middle
和两种相同的类型被列在

00:28:40.836 --> 00:28:41.976 A:middle
生成的交互界面中

00:28:43.176 --> 00:28:44.936 A:middle
接下来 在模型层级中

00:28:44.936 --> 00:28:46.586 A:middle
我们能看到

00:28:46.586 --> 00:28:48.116 A:middle
我们用来创造模型的

00:28:48.116 --> 00:28:50.346 A:middle
便利构造器

00:28:50.346 --> 00:28:53.336 A:middle
以及预测方式

00:28:53.536 --> 00:28:55.486 A:middle
同时在 Generated Source （生成源）内

00:28:55.486 --> 00:28:57.326 A:middle
你可以接入

00:28:57.386 --> 00:28:58.376 A:middle
底层模型

00:28:58.986 --> 00:29:00.676 A:middle
那么在更高级的使用场景中

00:28:58.986 --> 00:29:00.676 A:middle
那么在更高级的使用场景中

00:29:01.006 --> 00:29:02.656 A:middle
你可以使用它

00:29:02.656 --> 00:29:04.096 A:middle
也可以以编程的形式

00:29:04.096 --> 00:29:04.226 A:middle
与它互动

00:29:05.556 --> 00:29:06.816 A:middle
我们来看一下

00:29:06.886 --> 00:29:08.966 A:middle
机器学习模型层级的内部 我们可以看到

00:29:08.966 --> 00:29:10.186 A:middle
有一个模型描述

00:29:10.896 --> 00:29:12.626 A:middle
使你可以访问

00:29:12.626 --> 00:29:14.946 A:middle
任何你在 Xcode

00:29:15.136 --> 00:29:16.066 A:middle
元数据中看到的东西

00:29:16.636 --> 00:29:18.196 A:middle
还有一个额外的

00:29:18.196 --> 00:29:19.726 A:middle
预测方式 它接受

00:29:19.816 --> 00:29:21.726 A:middle
符合协议的输入

00:29:21.726 --> 00:29:23.206 A:middle
并返回符合协议的输出

00:29:23.206 --> 00:29:24.606 A:middle
这给你

00:29:24.676 --> 00:29:26.456 A:middle
提供输入的方式

00:29:26.456 --> 00:29:26.956 A:middle
以更多的弹性空间

00:29:27.836 --> 00:29:29.366 A:middle
我们看过了

00:29:29.366 --> 00:29:31.016 A:middle
这一开发流程的上半部分

00:29:31.446 --> 00:29:32.946 A:middle
并看到了

00:29:32.946 --> 00:29:34.826 A:middle
当你将一个训练过的模型拖拽进 Xcode 会发生什么

00:29:35.486 --> 00:29:36.766 A:middle
它可以生成 Swift 源

00:29:36.856 --> 00:29:38.806 A:middle
你可以在你的 App 里使用

00:29:39.486 --> 00:29:41.436 A:middle
在你的 App 里

00:29:41.526 --> 00:29:42.006 A:middle
使用这一模型

00:29:44.096 --> 00:29:46.156 A:middle
如我们所见 这一模型本身

00:29:46.156 --> 00:29:47.926 A:middle
同样也被编译并归入

00:29:47.926 --> 00:29:49.066 A:middle
到你的 App 中

00:29:51.816 --> 00:29:53.506 A:middle
在这一步做一个更详细的说明

00:29:53.506 --> 00:29:55.986 A:middle
我们要做什么 首先

00:29:55.986 --> 00:29:58.646 A:middle
我们从模型的 JSON 形式中得到它

00:29:58.836 --> 00:29:59.756 A:middle
这是优化过的

00:29:59.846 --> 00:30:01.056 A:middle
为了更加便携和易于转化

00:29:59.846 --> 00:30:01.056 A:middle
为了更加便携和易于转化

00:30:01.056 --> 00:30:02.886 A:middle
并编译它

00:30:03.166 --> 00:30:04.606 A:middle
使它能在设备上快速加载

00:30:04.606 --> 00:30:06.826 A:middle
当你启动它的时候

00:30:08.036 --> 00:30:09.886 A:middle
我们还需要确认模型

00:30:09.886 --> 00:30:11.376 A:middle
与底层推断引擎

00:30:11.376 --> 00:30:12.716 A:middle
相连接

00:30:12.716 --> 00:30:14.276 A:middle
最终在你的设备上做出评估

00:30:14.276 --> 00:30:15.916 A:middle
并给你一个优化的预测结果

00:30:16.026 --> 00:30:17.426 A:middle
当你需要的时候

00:30:17.426 --> 00:30:20.576 A:middle
我们在演示中看到的最后一样东西

00:30:20.576 --> 00:30:22.806 A:middle
就是我们换掉了模型

00:30:23.646 --> 00:30:25.586 A:middle
大多数时候都是为了缩减体积

00:30:26.426 --> 00:30:28.196 A:middle
但是还有其他的原因

00:30:28.196 --> 00:30:29.226 A:middle
为什么你可能会需要

00:30:29.226 --> 00:30:29.936 A:middle
使用别的模型

00:30:30.346 --> 00:30:32.406 A:middle
比如说 为了精确性或者仅仅是

00:30:32.406 --> 00:30:34.266 A:middle
为了测试出不同的类型

00:30:34.266 --> 00:30:35.096 A:middle
看它们表现如何

00:30:35.696 --> 00:30:40.636 A:middle
总的来说 今天我们了解了

00:30:40.636 --> 00:30:41.966 A:middle
我们可用的一些

00:30:41.966 --> 00:30:43.206 A:middle
机器学习模型框架

00:30:43.206 --> 00:30:43.746 A:middle
的概览

00:30:44.686 --> 00:30:46.736 A:middle
我们还推出了 Core ML

00:30:46.736 --> 00:30:48.166 A:middle
一个全新的框架

00:30:48.276 --> 00:30:48.746 A:middle
用于设备端的推断

00:30:49.956 --> 00:30:51.176 A:middle
我们也实际向你们展示了

00:30:51.176 --> 00:30:52.456 A:middle
开发流程

00:30:54.536 --> 00:30:55.946 A:middle
需要更多信息的话

00:30:55.946 --> 00:30:56.786 A:middle
请到

00:30:56.786 --> 00:30:58.376 A:middle
developer.apple.com 查看

00:30:58.376 --> 00:30:59.816 A:middle
我们的研讨会序号是 703

00:31:00.696 --> 00:31:02.096 A:middle
同时 周四可以参加一些

00:31:02.096 --> 00:31:03.976 A:middle
的相关研讨会进行深入了解 例如 Vision

00:31:03.976 --> 00:31:06.536 A:middle
和 NLP 以及 Core ML

00:31:06.596 --> 00:31:08.076 A:middle
如果你们想了解

00:31:08.076 --> 00:31:09.606 A:middle
更多 Core ML 的使用场景

00:31:09.606 --> 00:31:11.366 A:middle
或者如何

00:31:11.366 --> 00:31:12.946 A:middle
将模型转换为 Core ML

00:31:13.006 --> 00:31:13.266 A:middle
格式

00:31:14.276 --> 00:31:15.666 A:middle
感谢各位

00:31:15.666 --> 00:31:16.206 A:middle
并请期待大会接下来的日程
