WEBVTT

00:00:17.551 --> 00:00:20.420 align:middle line:10%
（关于iPhone摄影中的
深度捕捉）

00:00:23.924 --> 00:00:26.627 align:middle line:90%,end
欢迎来到演讲507
我叫布莱德·福德

00:00:26.693 --> 00:00:30.264 align:middle line:90%,end
我来自相机软件团队
我很激动

00:00:30.330 --> 00:00:32.466 align:middle line:90%,end
能在今天下午和你们
分享一些深入的看法

00:00:33.834 --> 00:00:36.570 align:middle line:90%,end
看到我要做什么了吗？好了

00:00:38.572 --> 00:00:39.406 align:middle line:90%,end
本次演讲

00:00:39.473 --> 00:00:41.341 align:middle line:90%,end
是两个演讲的第一部分

00:00:41.408 --> 00:00:43.477 align:middle line:90%,end
这两个演讲会介绍Apple
今年发布的一个非常重要的新功能

00:00:43.544 --> 00:00:46.380 align:middle line:90%,end
那就是包含深度信息的多媒体内容

00:00:47.014 --> 00:00:49.183 align:middle line:90%,end
我会从概念层面上介绍一下景深

00:00:49.249 --> 00:00:51.485 align:middle line:90%,end
我会带着你们熟悉一些关键的术语

00:00:51.852 --> 00:00:55.722 align:middle line:90%,end
我会教你们如何在iPhone上
捕捉深度数据 就像是这张照片

00:00:55.789 --> 00:00:58.192 align:middle line:90%,end
你会在本次演讲中看到
许多幽灵般的图片

00:00:59.593 --> 00:01:00.594 align:middle line:90%,end
我们的计划是这样的

00:00:59.593 --> 00:01:00.594 align:middle line:90%,end
我们的计划是这样的

00:01:01.929 --> 00:01:03.430 align:middle line:90%,end
首先我们会介绍深度和视差

00:01:03.497 --> 00:01:06.233 align:middle line:90%,end
它们出现在iPhone 7 Plus上
我会从大体上介绍一下

00:01:07.100 --> 00:01:09.937 align:middle line:90%,end
接着我们会介绍下如何从
相机获取流式的深度数据

00:01:11.004 --> 00:01:12.673 align:middle line:90%,end
拍摄带有深度数据的照片

00:01:13.507 --> 00:01:16.143 align:middle line:90%,end
最后我们会介绍一个有点离题的主题

00:01:16.210 --> 00:01:18.779 align:middle line:90%,end
也就是双照片拍摄
这是请求最多的

00:01:18.846 --> 00:01:21.181 align:middle line:90%,end
关于双摄像头的功能

00:01:21.381 --> 00:01:22.883 align:middle line:90%,end
我很激动能介绍一下它

00:01:23.450 --> 00:01:28.355 align:middle line:90%,end
你要做的就是听一下所有这些
很糟糕的深度双关语

00:01:28.422 --> 00:01:30.524 align:middle line:90%,end
我会不断在本次演讲中
介绍关于深度的内容

00:01:30.958 --> 00:01:32.793 align:middle line:90%,end
让我们一起做个游戏吧
好吗？

00:01:33.126 --> 00:01:35.929 align:middle line:90%,end
每当你听到一个关于深度的双关语时
就给我点抱怨声

00:01:36.163 --> 00:01:37.664 align:middle line:90%,end
这样我就知道你们在专心听了
好吗？

00:01:37.965 --> 00:01:41.401 align:middle line:90%,end
让我们试一下
大家准备好深潜了吗？

00:01:43.237 --> 00:01:45.138 align:middle line:90%,end
谢谢
我从心底感谢大家

00:01:46.740 --> 00:01:47.808 align:middle line:90%,end
好了

00:01:48.976 --> 00:01:51.778 align:middle line:90%,end
你们今天之所以来这里都是因为它

00:01:51.945 --> 00:01:53.614 align:middle line:90%,end
这就是iPhone 7 Plus

00:01:53.981 --> 00:01:56.216 align:middle line:90%,end
这个产品卖得

00:01:56.650 --> 00:01:58.719 align:middle line:90%,end
甚至比上代plus更好

00:01:59.286 --> 00:02:02.789 align:middle line:90%,end
这在很大程度上要归功于
高质量的双摄像头系统

00:01:59.286 --> 00:02:02.789 align:middle line:90%,end
这在很大程度上要归功于
高质量的双摄像头系统

00:02:04.291 --> 00:02:06.660 align:middle line:90%,end
它是一个双主镜头系统

00:02:06.727 --> 00:02:10.163 align:middle line:90%,end
由一个28毫米的广角摄像头

00:02:10.497 --> 00:02:13.300 align:middle line:90%,end
和一个56毫米的
长焦摄像头组成

00:02:13.800 --> 00:02:15.669 align:middle line:90%,end
它们都是1200万像素的

00:02:16.003 --> 00:02:18.605 align:middle line:90%,end
它们共享同样的功能项
和相同的格式

00:02:19.039 --> 00:02:21.241 align:middle line:90%,end
你可以独立运行其中的一个摄像头

00:02:21.675 --> 00:02:26.079 align:middle line:90%,end
或是利用一个虚拟的第三个摄像头
来一起使用这两个摄像头

00:02:26.146 --> 00:02:28.182 align:middle line:90%,end
这是我们首次将这项技术
运用在iOS上

00:02:28.248 --> 00:02:30.017 align:middle line:90%,end
我们把它叫作双摄像头

00:02:30.551 --> 00:02:33.954 align:middle line:90%,end
它以同步的方式
以及相同的帧率运行双摄像头

00:02:34.388 --> 00:02:37.291 align:middle line:90%,end
并且通过共同运行双摄像头
来实现两个选框功能

00:02:38.292 --> 00:02:40.160 align:middle line:90%,end
第一个功能是双摄像头变焦

00:02:41.128 --> 00:02:43.797 align:middle line:90%,end
它会在广角和长焦之间进行自动切换

00:02:43.864 --> 00:02:45.098 align:middle line:90%,end
当你在变焦的时候

00:02:45.632 --> 00:02:49.403 align:middle line:90%,end
它会适配曝光 对焦 还有帧率
这挺神奇的

00:02:49.469 --> 00:02:51.605 align:middle line:90%,end
你甚至意识不到我们切换了摄像头

00:02:51.872 --> 00:02:53.640 align:middle line:90%,end
但所有这些事件都无缝地发生了

00:02:54.007 --> 00:02:56.176 align:middle line:90%,end
我们还会视差偏移进行了补偿

00:02:56.243 --> 00:02:59.313 align:middle line:90%,end
使其能够平滑地过渡
当你来回在

00:02:59.379 --> 00:03:00.714 align:middle line:90%,end
广角和长焦之间进行切换时

00:02:59.379 --> 00:03:00.714 align:middle line:90%,end
广角和长焦之间进行切换时

00:03:01.915 --> 00:03:04.785 align:middle line:90%,end
第二个选框功能
当然就是人像模式了

00:03:05.152 --> 00:03:10.123 align:middle line:90%,end
也就是双摄像头系统锁定在
长焦摄像头的窄视野上

00:03:11.258 --> 00:03:14.494 align:middle line:90%,end
但会同时使用广角和长焦的图像

00:03:14.862 --> 00:03:17.664 align:middle line:90%,end
来生成一幅漂亮的浅景深效果的图像

00:03:17.898 --> 00:03:20.100 align:middle line:90%,end
通常你要用一个贵得多的照相机

00:03:20.167 --> 00:03:22.169 align:middle line:90%,end
带有快速 广角的镜头
才能实现如此效果

00:03:23.403 --> 00:03:25.305 align:middle line:90%,end
前景在聚焦时看起来很锐利

00:03:25.372 --> 00:03:27.774 align:middle line:90%,end
而背景会逐渐变得模糊

00:03:27.941 --> 00:03:30.043 align:middle line:90%,end
像是这些好看的小花束圈

00:03:31.578 --> 00:03:34.781 align:middle line:90%,end
景深效果甚至在iOS 11中
变得更棒

00:03:35.148 --> 00:03:38.418 align:middle line:90%,end
我们还针对渲染失焦的区域进行了改进

00:03:38.886 --> 00:03:42.489 align:middle line:90%,end
这样可以更准确地表现一个
高度自由的快速镜头

00:03:42.789 --> 00:03:45.425 align:middle line:90%,end
还带有锐利清晰可辨的花束圈

00:03:45.959 --> 00:03:48.662 align:middle line:90%,end
我们还改进了对边缘进行渲染的方法

00:03:48.729 --> 00:03:52.266 align:middle line:90%,end
也就是前景和背景之间的边缘
如果你不清楚的话请去看一下

00:03:52.332 --> 00:03:55.169 align:middle line:90%,end
我估计你会很惊讶地发现
这是多么棒的

00:03:55.402 --> 00:03:57.905 align:middle line:90%,end
浅景深效果
被呈现于iOS 11

00:03:59.473 --> 00:04:00.307 align:middle line:90%,end
要生成

00:03:59.473 --> 00:04:00.307 align:middle line:90%,end
要生成

00:04:00.374 --> 00:04:04.077 align:middle line:90%,end
这样的效果你需要区分
前景和背景

00:04:04.144 --> 00:04:06.046 align:middle line:90%,end
换句话说 你需要用到深度

00:04:06.547 --> 00:04:09.483 align:middle line:90%,end
截至目前 深度信息
只包含于

00:04:09.550 --> 00:04:11.618 align:middle line:90%,end
Apple相机应用的人像模式中

00:04:13.086 --> 00:04:17.391 align:middle line:90%,end
不过现在iOS 11中
我们向第三方应用开放了深度信息

00:04:18.625 --> 00:04:20.994 align:middle line:90%,end
这里是一个灰度可视化的深度图

00:04:21.060 --> 00:04:22.930 align:middle line:90%,end
它被嵌入到这个图片文件里

00:04:24.698 --> 00:04:28.769 align:middle line:90%,end
有了深度信息就拥有了
更多编辑图像的可能性

00:04:29.036 --> 00:04:32.739 align:middle line:90%,end
像是将不同的滤镜应用到背景和前景中

00:04:32.806 --> 00:04:33.807 align:middle line:90%,end
就像是这样

00:04:35.442 --> 00:04:39.112 align:middle line:90%,end
这里我将一个黑白滤镜应用到背景

00:04:39.179 --> 00:04:40.981 align:middle line:90%,end
还将一个淡入淡出滤镜应用到前景

00:04:41.448 --> 00:04:43.550 align:middle line:90%,end
你就能发现 这小女孩
的裤子还是粉色的

00:04:43.617 --> 00:04:45.586 align:middle line:90%,end
但是裤子后面的物体都是黑白的了

00:04:46.119 --> 00:04:48.488 align:middle line:90%,end
了解了深度的渐变 我就能

00:04:48.555 --> 00:04:51.491 align:middle line:90%,end
实现更加复杂的功能 将转换点

00:04:51.558 --> 00:04:53.427 align:middle line:90%,end
像这样前后移动

00:04:53.594 --> 00:04:54.995 align:middle line:90%,end
这样就能让你的注意力集中在花上面

00:04:56.663 --> 00:04:59.233 align:middle line:90%,end
注意下
只有她的手还有手中的花是有颜色的

00:04:59.299 --> 00:05:00.934 align:middle line:90%,end
而其他的物体都是黑白的

00:04:59.299 --> 00:05:00.934 align:middle line:90%,end
而其他的物体都是黑白的

00:05:02.436 --> 00:05:05.639 align:middle line:90%,end
你甚至可以对前景和背景的曝光
进行不同地控制

00:05:05.706 --> 00:05:06.707 align:middle line:90%,end
像是这样

00:05:08.308 --> 00:05:11.478 align:middle line:90%,end
她现在看起来就像是被
photoshop到了她自己的照片上

00:05:12.179 --> 00:05:14.748 align:middle line:90%,end
我不是说你非得这么做
我的意思是你可以这么做

00:05:16.583 --> 00:05:18.519 align:middle line:90%,end
好了 闲话少叙
让我们讲点技术性东西

00:05:18.785 --> 00:05:20.454 align:middle line:90%,end
我想把这部分叫作

00:05:20.821 --> 00:05:22.256 align:middle line:90%,end
深度学习

00:05:22.322 --> 00:05:23.490 align:middle line:90%,end
（深度学习）

00:05:23.557 --> 00:05:24.591 align:middle line:90%,end
谢谢你们

00:05:24.658 --> 00:05:27.027 align:middle line:90%,end
首先我们需要定义一下什么是深度图

00:05:27.594 --> 00:05:32.666 align:middle line:90%,end
在现实世界中 深度指的是
你与被观察对象之间的距离

00:05:33.300 --> 00:05:36.637 align:middle line:90%,end
而深度图就是将一个三维场景转换

00:05:36.803 --> 00:05:39.039 align:middle line:90%,end
成二维场景的表现形式

00:05:39.373 --> 00:05:42.376 align:middle line:90%,end
你可以通过将深度设定为一个
恒定距离来实现

00:05:43.010 --> 00:05:44.111 align:middle line:90%,end
我来解释下我说的是什么意思

00:05:44.678 --> 00:05:46.980 align:middle line:90%,end
我会用到一个针孔相机的图

00:05:47.214 --> 00:05:48.782 align:middle line:90%,end
它被用来说明此类问题

00:05:49.383 --> 00:05:50.817 align:middle line:10%
如果你研究过计算机视觉

00:05:50.884 --> 00:05:52.920 align:middle line:10%
你就会对针孔相机非常熟悉

00:05:53.120 --> 00:05:56.857 align:middle line:10%
针孔照相机其实就是
一个没有镜头的简易遮光盒

00:05:56.924 --> 00:05:58.792 align:middle line:10%
它只有一个小的孔洞

00:05:59.126 --> 00:06:02.663 align:middle line:10%
一个能让光进入的小孔

00:05:59.126 --> 00:06:02.663 align:middle line:10%
一个能让光进入的小孔

00:06:03.096 --> 00:06:05.399 align:middle line:10%
并将自己以一个倒转的图像投射到

00:06:05.632 --> 00:06:09.236 align:middle line:10%
像平面的另一边或者是传感器上

00:06:09.303 --> 00:06:10.737 align:middle line:10%
（深度图）

00:06:11.171 --> 00:06:13.907 align:middle line:10%
另一边也叫作像平面或是传感器

00:06:14.942 --> 00:06:16.677 align:middle line:90%,end
而这个光线所通过的孔

00:06:16.743 --> 00:06:18.345 align:middle line:90%,end
被称为焦点

00:06:18.879 --> 00:06:20.848 align:middle line:90%,end
而所拍摄图像的视野

00:06:20.914 --> 00:06:23.483 align:middle line:90%,end
取决于焦距

00:06:23.851 --> 00:06:27.654 align:middle line:90%,end
焦距就是从焦点到像平面的距离

00:06:28.388 --> 00:06:31.391 align:middle line:90%,end
较短的焦距就意味着更宽的视野

00:06:32.092 --> 00:06:35.629 align:middle line:90%,end
而较长的焦距 还有较长的盒子
就意味着更窄的视野

00:06:36.396 --> 00:06:39.132 align:middle line:90%,end
焦距就是一个恒定距离

00:06:39.199 --> 00:06:42.769 align:middle line:90%,end
它将现实世界的距离扁平化
成一个2D图像

00:06:43.437 --> 00:06:47.207 align:middle line:90%,end
简单来说 深度图就是
将一幅3D深度图像转换为

00:06:47.374 --> 00:06:49.843 align:middle line:90%,end
2D的单通道图像

00:06:50.043 --> 00:06:52.045 align:middle line:90%,end
其中每个像素值都有不同的深度

00:06:52.112 --> 00:06:54.815 align:middle line:90%,end
像是5米 4米 3米

00:06:56.517 --> 00:07:00.821 align:middle line:90%,end
为了测量深度
你需要一个专用的摄像头

00:06:56.517 --> 00:07:00.821 align:middle line:90%,end
为了测量深度
你需要一个专用的摄像头

00:07:00.888 --> 00:07:02.723 align:middle line:90%,end
就像是一个渡越时间摄像头

00:07:02.923 --> 00:07:03.757 align:middle line:90%,end
例如

00:07:03.824 --> 00:07:07.427 align:middle line:90%,end
有一个从物体反射光信号系统

00:07:07.494 --> 00:07:10.664 align:middle line:90%,end
接着它能测量其返回传感器的时间

00:07:11.565 --> 00:07:15.335 align:middle line:90%,end
iPhone 7的双摄像头不是
渡越时间摄像头

00:07:16.103 --> 00:07:18.906 align:middle line:90%,end
它是一个基于视差的系统

00:07:19.339 --> 00:07:20.607 align:middle line:90%,end
视差是一种用来测量

00:07:20.674 --> 00:07:23.844 align:middle line:90%,end
物体偏移量的量度

00:07:23.911 --> 00:07:26.580 align:middle line:90%,end
当你从两个不同镜头观察物体时
像是从你的眼球观察

00:07:27.080 --> 00:07:28.982 align:middle line:90%,end
Disparity就是视差的别称

00:07:29.883 --> 00:07:32.753 align:middle line:90%,end
你只要稳定住头
就可以观察到这个效果

00:07:33.187 --> 00:07:36.356 align:middle line:90%,end
将你的目光固定在近处的某个物体上

00:07:36.690 --> 00:07:40.093 align:middle line:90%,end
然后就不要再移动头了
先闭上一只眼 然后再闭上另一只

00:07:40.160 --> 00:07:43.230 align:middle line:90%,end
比方说 就是
左眼 右眼

00:07:44.164 --> 00:07:46.300 align:middle line:90%,end
左眼 右眼

00:07:46.900 --> 00:07:49.837 align:middle line:90%,end
这时候你就可以发现
有颜色的铅笔看起来偏移得

00:07:49.903 --> 00:07:52.139 align:middle line:90%,end
比后面的记号笔要多
因为它们离得更近

00:07:52.206 --> 00:07:54.208 align:middle line:90%,end
这就是视差效果
或者disparity

00:07:55.776 --> 00:07:57.344 align:middle line:90%,end
现在接着回来介绍针孔相机模型

00:07:57.945 --> 00:07:59.713 align:middle line:90%,end
我拍摄一幅鸟瞰图

00:07:59.880 --> 00:08:03.817 align:middle line:90%,end
是由两个立体纠正相机所拍摄的

00:07:59.880 --> 00:08:03.817 align:middle line:90%,end
是由两个立体纠正相机所拍摄的

00:08:04.251 --> 00:08:07.254 align:middle line:90%,end
也就是说 第一
它们是彼此平行的

00:08:07.321 --> 00:08:08.822 align:middle line:90%,end
它们指向同一个方向

00:08:09.456 --> 00:08:13.193 align:middle line:10%
第二 它们有相同的焦距
这是非常重要的

00:08:13.894 --> 00:08:16.997 align:middle line:10%
那就是从焦点到像平面或是
传感器的距离

00:08:17.598 --> 00:08:21.869 align:middle line:10%
每个摄像头都有一个测量好的
光学中心或者说主要点

00:08:22.603 --> 00:08:26.773 align:middle line:10%
如果你画一条从针孔到像平面的垂直线

00:08:27.474 --> 00:08:30.410 align:middle line:10%
那么光学中心就是它

00:08:30.477 --> 00:08:31.478 align:middle line:10%
与像平面相交的点

00:08:31.945 --> 00:08:33.780 align:middle line:10%
另外还有一个你应该熟悉的术语

00:08:33.847 --> 00:08:35.115 align:middle line:10%
那就是基线

00:08:35.682 --> 00:08:37.351 align:middle line:10%
基线指的是

00:08:37.417 --> 00:08:40.020 align:middle line:10%
两个镜头的光学中心之间的距离

00:08:40.087 --> 00:08:41.655 align:middle line:10%
是在立体纠正系统里的两个镜头

00:08:42.322 --> 00:08:43.323 align:middle line:10%
它是这么工作的

00:08:43.690 --> 00:08:48.829 align:middle line:10%
来自一个被观察对象的光线
穿过光学中心

00:08:49.596 --> 00:08:51.865 align:middle line:10%
或是通过孔径

00:08:52.299 --> 00:08:56.170 align:middle line:10%
并且落在两个摄像头
像平面的不同点上

00:08:57.371 --> 00:09:00.340 align:middle line:10%
我想要给你们讲的第四个术语是Z

00:08:57.371 --> 00:09:00.340 align:middle line:10%
我想要给你们讲的第四个术语是Z

00:09:00.407 --> 00:09:04.278 align:middle line:10%
Z是用于深度
或者说现实世界深度的规范术语

00:09:06.213 --> 00:09:09.016 align:middle line:90%,end
现在看看像平面上的点会怎么样吧

00:09:09.216 --> 00:09:11.785 align:middle line:90%,end
随着被观察的点距离变得更远

00:09:14.121 --> 00:09:15.322 align:middle line:90%,end
像平面上的点离得更近了

00:09:15.389 --> 00:09:16.857 align:middle line:90%,end
我会给你们再展示一次

00:09:17.858 --> 00:09:20.093 align:middle line:90%,end
随着现实点离得更远

00:09:20.994 --> 00:09:23.096 align:middle line:90%,end
它们在像平面上离得更近了

00:09:23.864 --> 00:09:26.466 align:middle line:90%,end
而随着对象离得更近

00:09:26.667 --> 00:09:28.502 align:middle line:90%,end
像平面上的点会互相离得更远

00:09:29.036 --> 00:09:33.507 align:middle line:90%,end
所以当使用立体纠正摄像头的时候
这些偏移只会朝着一个方向移动

00:09:34.007 --> 00:09:36.877 align:middle line:90%,end
它们要么互相离得更近 要么离得更远

00:09:36.944 --> 00:09:40.180 align:middle line:90%,end
但它们都位于一条线
或是极线上

00:09:41.782 --> 00:09:44.318 align:middle line:90%,end
在了解了基线后你就
可以排列你的相机

00:09:44.384 --> 00:09:46.320 align:middle line:90%,end
像是这样沿着它们的光学中心

00:09:46.687 --> 00:09:49.623 align:middle line:90%,end
接着减去像平面上被观察点之间的距离

00:09:49.890 --> 00:09:52.793 align:middle line:90%,end
就可以获得视差

00:09:53.227 --> 00:09:54.361 align:middle line:90%,end
这就是视差

00:09:55.028 --> 00:09:57.130 align:middle line:90%,end
你可以将这个距离以任何单位表示

00:09:57.197 --> 00:09:58.832 align:middle line:90%,end
只要对你的处理过程有帮助就行

00:09:58.899 --> 00:10:01.502 align:middle line:90%,end
它可以是像素 米 微米

00:09:58.899 --> 00:10:01.502 align:middle line:90%,end
它可以是像素 米 微米

00:10:02.069 --> 00:10:05.672 align:middle line:90%,end
通常我们会以像素为单位保存它

00:10:05.739 --> 00:10:07.441 align:middle line:90%,end
因为RGB图像是以像素表示的

00:10:08.242 --> 00:10:09.943 align:middle line:90%,end
我们就可以正常保存像素偏移了

00:10:10.010 --> 00:10:12.980 align:middle line:90%,end
只要它们对应的图像没有改变

00:10:13.046 --> 00:10:14.047 align:middle line:90%,end
大小就可以

00:10:14.982 --> 00:10:17.618 align:middle line:90%,end
你最好不要编辑这个图像

00:10:17.784 --> 00:10:19.753 align:middle line:90%,end
因为如果你缩小了这个图像

00:10:20.020 --> 00:10:22.422 align:middle line:90%,end
你就会同时改变像素的大小

00:10:22.689 --> 00:10:24.191 align:middle line:90%,end
你就得检查整个图

00:10:24.258 --> 00:10:27.227 align:middle line:90%,end
然后缩放深度图中的每个值

00:10:27.561 --> 00:10:29.296 align:middle line:90%,end
这是一个非常不友好的实现方式

00:10:30.597 --> 00:10:32.032 align:middle line:90%,end
我们Apple

00:10:32.099 --> 00:10:36.036 align:middle line:90%,end
选择使用标准化的值来表达视差

00:10:36.103 --> 00:10:39.339 align:middle line:90%,end
这些值对于缩放操作是有弹性的
我们是这么实现的

00:10:40.174 --> 00:10:42.009 align:middle line:90%,end
再回到我们的被观察点

00:10:42.442 --> 00:10:45.846 align:middle line:90%,end
你就会发现两个相似三角形

00:10:46.113 --> 00:10:47.214 align:middle line:90%,end
我来给你们着重标出

00:10:47.281 --> 00:10:49.583 align:middle line:90%,end
（消除视差）

00:10:49.650 --> 00:10:53.153 align:middle line:90%,end
这些三角形具有
相同比例的边和定理

00:10:54.221 --> 00:10:56.423 align:middle line:90%,end
如果我抹掉相机
只给你们显示这些三角形

00:10:56.857 --> 00:11:00.694 align:middle line:90%,end
现实世界三角形的边就是Z
或是米

00:10:56.857 --> 00:11:00.694 align:middle line:90%,end
现实世界三角形的边就是Z
或是米

00:11:00.894 --> 00:11:03.697 align:middle line:90%,end
以及基线 也就是两个
光学中心之间的距离

00:11:04.932 --> 00:11:07.501 align:middle line:90%,end
在这个光盒
或者说遮光盒里

00:11:08.769 --> 00:11:12.706 align:middle line:90%,end
同一个三角形会被表示为
以像素为单位的焦距

00:11:12.773 --> 00:11:14.975 align:middle line:90%,end
和以像素为单位的视差

00:11:15.909 --> 00:11:18.011 align:middle line:90%,end
你们感觉要开始讲数学了吗？
我感觉到了

00:11:18.612 --> 00:11:20.614 align:middle line:90%,end
请听我接着说
这没什么可头疼的

00:11:21.415 --> 00:11:22.249 align:middle line:90%,end
基线

00:11:22.716 --> 00:11:25.719 align:middle line:90%,end
比上以像素为单位的Z

00:11:28.722 --> 00:11:29.590 align:middle line:90%,end
就等于

00:11:30.524 --> 00:11:33.060 align:middle line:90%,end
视差比上焦距的长度

00:11:33.560 --> 00:11:37.497 align:middle line:90%,end
如果我们将两边都除以基线的话

00:11:38.198 --> 00:11:44.338 align:middle line:90%,end
左边的b就会被消去
而左边留下的就是1比上z

00:11:45.239 --> 00:11:48.976 align:middle line:90%,end
这很不错
1比z就是深度的倒数

00:11:49.643 --> 00:11:51.445 align:middle line:90%,end
视差差不多就是这个意思

00:11:51.879 --> 00:11:55.148 align:middle line:90%,end
当某个物体向远处移动的时候
视差会缩小

00:11:55.749 --> 00:11:59.686 align:middle line:90%,end
而当它向近处移动时 视差就会增长
所以说它就是深度的反函数

00:12:01.355 --> 00:12:04.958 align:middle line:90%,end
而我们把右边所剩下的部分
称为规范化视差

00:12:05.025 --> 00:12:11.064 align:middle line:90%,end
它不再是像素偏移了
而是d比上焦点距离乘以基线

00:12:11.498 --> 00:12:12.833 align:middle line:90%,end
基线就被内置了

00:12:12.900 --> 00:12:15.202 align:middle line:90%,end
所以你不需要再单独携带此信息了

00:12:15.269 --> 00:12:16.570 align:middle line:90%,end
当你

00:12:16.637 --> 00:12:17.838 align:middle line:90%,end
处理深度图的时候

00:12:18.205 --> 00:12:21.408 align:middle line:90%,end
视差的单位是1/米
就像是1比上z

00:12:21.742 --> 00:12:24.077 align:middle line:90%,end
它可以处理缩放操作

00:12:24.411 --> 00:12:28.315 align:middle line:90%,end
如你所见
将深度转换为视差是很简单的

00:12:28.382 --> 00:12:30.184 align:middle line:90%,end
因为它只用1除以什么
这样的操作就能完成

00:12:31.985 --> 00:12:34.688 align:middle line:90%,end
有人觉得超出接受范围了么？

00:12:35.856 --> 00:12:36.823 align:middle line:90%,end
（视差对比深度）

00:12:36.890 --> 00:12:40.327 align:middle line:90%,end
它听起来挺麻烦的
不过总结起来很简单

00:12:41.929 --> 00:12:45.265 align:middle line:90%,end
我们有一个基于视差的系统
而不是一个真正的渡越时间相机

00:12:45.899 --> 00:12:48.268 align:middle line:90%,end
不过视差是个不错的深度代理

00:12:48.836 --> 00:12:52.472 align:middle line:90%,end
而且规范化的视差就是深度的倒数

00:12:54.274 --> 00:12:55.242 align:middle line:90%,end
（沉思）

00:12:55.309 --> 00:12:58.812 align:middle line:90%,end
提到规范化视差
也就是深度的倒数

00:12:59.012 --> 00:13:00.080 align:middle line:90%,end
这里我们好好想一下

00:12:59.012 --> 00:13:00.080 align:middle line:90%,end
这里我们好好想一下

00:13:03.250 --> 00:13:05.385 align:middle line:90%,end
这幅图片有一个视差图

00:13:06.920 --> 00:13:10.490 align:middle line:90%,end
我觉得这就是一个反深度的跳跃

00:13:13.026 --> 00:13:14.795 align:middle line:90%,end
谢谢你们
可以了

00:13:15.062 --> 00:13:19.266 align:middle line:90%,end
我们在深度API集中使用了
深度数据这个术语

00:13:19.700 --> 00:13:22.236 align:middle line:90%,end
这是个用来表示任何
有深度物体的专业术语

00:13:23.170 --> 00:13:26.807 align:middle line:90%,end
它可以指代一个真正的深度图
或者是一个视差图

00:13:26.874 --> 00:13:29.243 align:middle line:90%,end
它们都是与深度相关的
它们都是有深度的

00:13:29.309 --> 00:13:31.044 align:middle line:90%,end
因此它们都是深度数据

00:13:32.446 --> 00:13:35.315 align:middle line:90%,end
而且我们专门给它创建了一个对象

00:13:35.382 --> 00:13:37.818 align:middle line:90%,end
根据我们平台上对于深度的定义
其权威表示

00:13:37.885 --> 00:13:40.053 align:middle line:90%,end
被称为AVDepthData

00:13:40.454 --> 00:13:43.490 align:middle line:90%,end
它能被用于iOS macOS
以及tvOS上

00:13:43.957 --> 00:13:45.993 align:middle line:90%,end
这是AVFoundation框架上的一个类

00:13:46.326 --> 00:13:49.062 align:middle line:90%,end
它可以表示深度图
或是视差图

00:13:49.463 --> 00:13:53.734 align:middle line:90%,end
它还提供一些不错的功能来转化
深度和视差

00:13:54.668 --> 00:13:57.404 align:middle line:90%,end
让我们来看看
深度图的细节吧

00:13:58.071 --> 00:14:00.941 align:middle line:90%,end
深度图就是一些图像
如果你现在还没看明白的话

00:13:58.071 --> 00:14:00.941 align:middle line:90%,end
深度图就是一些图像
如果你现在还没看明白的话

00:14:01.008 --> 00:14:04.111 align:middle line:90%,end
它们有点像RGB图像
但它们是单通道的

00:14:04.578 --> 00:14:07.080 align:middle line:90%,end
不过它们仍然能被表示成
CV像素缓冲区

00:14:07.614 --> 00:14:10.484 align:middle line:90%,end
而现在CoreVideo定义了
四种新的像素格式

00:14:11.051 --> 00:14:13.487 align:middle line:90%,end
给那些我们在前面的幻灯片
看到过的类型使用

00:14:13.554 --> 00:14:14.955 align:middle line:90%,end
它们都是浮点型的

00:14:15.656 --> 00:14:20.794 align:middle line:90%,end
头两种格式是用于规范化视差的
它被表示成1/米的形式

00:14:20.861 --> 00:14:24.198 align:middle line:90%,end
注意下有16位
和32位两种形式可选

00:14:24.898 --> 00:14:28.235 align:middle line:90%,end
后两种格式是用于深度的
它们用米来表示

00:14:29.136 --> 00:14:31.471 align:middle line:90%,end
它们也是有16位或者32位可选的

00:14:31.538 --> 00:14:32.539 align:middle line:90%,end
我们为何要这么做？

00:14:33.173 --> 00:14:35.676 align:middle line:90%,end
如果你想要在GPU上对深度进行处理

00:14:35.742 --> 00:14:38.312 align:middle line:90%,end
你就应该请求16位

00:14:38.378 --> 00:14:40.380 align:middle line:90%,end
或者说半浮点的深度值

00:14:40.681 --> 00:14:42.149 align:middle line:90%,end
如果你是在CPU上进行处理

00:14:42.416 --> 00:14:46.019 align:middle line:90%,end
你就应该使用全32位的浮点变量

00:14:46.086 --> 00:14:47.087 align:middle line:90%,end
它们更加合适

00:14:48.488 --> 00:14:50.557 align:middle line:90%,end
我们会在后面介绍下
AVDepthData对象

00:14:50.624 --> 00:14:54.328 align:middle line:90%,end
是从何而来的 不过现在让我们
只关注一下它的核心属性就好

00:14:55.095 --> 00:14:58.799 align:middle line:90%,end
有了AVDepthData对象
你就可以查询它的深度数据类型

00:14:59.166 --> 00:15:01.168 align:middle line:90%,end
也就是四种像素格式之一

00:14:59.166 --> 00:15:01.168 align:middle line:90%,end
也就是四种像素格式之一

00:15:01.869 --> 00:15:04.571 align:middle line:90%,end
你可以访问
depthDataMap本身

00:15:04.638 --> 00:15:07.674 align:middle line:90%,end
它是个CV像素缓存
你能以

00:15:07.741 --> 00:15:11.044 align:middle line:90%,end
行和列来遍历它
利用标准CV像素缓存API

00:15:11.111 --> 00:15:12.279 align:middle line:90%,end
（引入AVDEPTHDATA）

00:15:12.346 --> 00:15:14.548 align:middle line:90%,end
而最后两种我想在这里着重说明

00:15:14.615 --> 00:15:18.151 align:middle line:90%,end
它们跟捕捉深度数据的内在问题有关

00:15:18.785 --> 00:15:21.121 align:middle line:90%,end
我们会一个个地说明这些问题

00:15:21.188 --> 00:15:22.623 align:middle line:90%,end
并且讨论下解决办法

00:15:24.091 --> 00:15:27.427 align:middle line:90%,end
第一个问题是洞
深度数据上的洞

00:15:28.228 --> 00:15:32.332 align:middle line:90%,end
为了计算视差 两个相机都需要观察
同一个点

00:15:32.399 --> 00:15:33.734 align:middle line:90%,end
不过是从两个不同的角度

00:15:34.134 --> 00:15:36.803 align:middle line:90%,end
如果它们观测不到这个点
就不会有视差

00:15:37.204 --> 00:15:38.906 align:middle line:90%,end
为什么它们可能看不到这个点呢？

00:15:40.073 --> 00:15:43.410 align:middle line:90%,end
首先可能是堵塞问题
比如说 有根手指伸了进来

00:15:43.477 --> 00:15:45.812 align:middle line:90%,end
突然挡住了你的其中一个相机

00:15:46.513 --> 00:15:48.682 align:middle line:90%,end
如果它变得有点模糊了
或者完全模糊了

00:15:48.749 --> 00:15:53.921 align:middle line:90%,end
你就不能再看到两个点了
因此你就没有视差了

00:15:55.022 --> 00:15:58.659 align:middle line:90%,end
另一个更常见的原因就是
很难找到特征

00:15:59.493 --> 00:16:02.496 align:middle line:90%,end
当相机一和相机二
的图像被比较时

00:15:59.493 --> 00:16:02.496 align:middle line:90%,end
当相机一和相机二
的图像被比较时

00:16:02.563 --> 00:16:06.300 align:middle line:90%,end
你应该记得 两个相机通过光学中心
将它们进行排列 并且寻找某些特征

00:16:07.134 --> 00:16:08.435 align:middle line:90%,end
这些特征是匹配关键点的

00:16:08.969 --> 00:16:09.970 align:middle line:90%,end
假如说变暗了

00:16:10.571 --> 00:16:14.007 align:middle line:90%,end
那么被观察点可能就没有
清晰可辨的特征了

00:16:14.741 --> 00:16:18.145 align:middle line:90%,end
颜色变得有点嘈杂
并且很难发现边缘

00:16:18.745 --> 00:16:19.847 align:middle line:90%,end
另一个例子就是

00:16:19.913 --> 00:16:24.318 align:middle line:90%,end
如果你将照相机指向一面
平的没有纹理的白墙

00:16:24.785 --> 00:16:29.323 align:middle line:90%,end
墙上基本上没有特征 因此就很难找到
用来匹配的不同之处

00:16:29.823 --> 00:16:32.459 align:middle line:90%,end
无论是以上哪一个原因
你的图像中都可能有某些区域

00:16:32.860 --> 00:16:36.129 align:middle line:90%,end
是根本找不到视差的
而这就被称为洞

00:16:37.798 --> 00:16:41.835 align:middle line:90%,end
洞在深度数据图中被表示为非数字

00:16:42.236 --> 00:16:45.772 align:middle line:90%,end
标准的浮点表示形式
要么是16位 要么是32位的

00:16:46.473 --> 00:16:50.043 align:middle line:90%,end
深度图可能也会被处理来填补这些洞

00:16:50.477 --> 00:16:54.815 align:middle line:90%,end
我们可以通过基于周围深度数据的
内插来实现 这么做很不错

00:16:55.249 --> 00:16:58.151 align:middle line:90%,end
或是通过使用RGB图像中
的元数据来实现

00:16:58.819 --> 00:17:02.122 align:middle line:90%,end
isDepthDataFiltered属性
是AVDepthData里面的属性

00:16:58.819 --> 00:17:02.122 align:middle line:90%,end
isDepthDataFiltered属性
是AVDepthData里面的属性

00:17:02.189 --> 00:17:05.358 align:middle line:90%,end
它会告诉你是不是用这种方式
来处理图的

00:17:06.292 --> 00:17:08.896 align:middle line:90%,end
若你接收到了一个未过滤的
AVDepthData

00:17:08.962 --> 00:17:12.199 align:middle line:90%,end
你在这个图中应该只能找到非数字的值

00:17:13.267 --> 00:17:17.671 align:middle line:90%,end
我们一会儿再介绍如何请求过滤的内容

00:17:19.006 --> 00:17:22.542 align:middle line:90%,end
第二个牵涉到准确视差生成的问题就是

00:17:22.608 --> 00:17:24.077 align:middle line:90%,end
校准错误

00:17:24.511 --> 00:17:26.680 align:middle line:90%,end
有许多校准错误

00:17:26.747 --> 00:17:30.450 align:middle line:90%,end
是我们可以修正的
不过有一种是我们不能修正的

00:17:30.884 --> 00:17:34.021 align:middle line:90%,end
那就是计算错误的光学中心

00:17:34.087 --> 00:17:36.323 align:middle line:90%,end
不管是两个摄像头中的哪一个出了问题

00:17:36.957 --> 00:17:40.294 align:middle line:90%,end
这里我是将针孔相机

00:17:40.360 --> 00:17:41.962 align:middle line:90%,end
向下偏移了90度

00:17:42.029 --> 00:17:43.697 align:middle line:90%,end
这样就可以在顶部留下更多的空间

00:17:44.331 --> 00:17:46.533 align:middle line:90%,end
在一个理想的立体纠正系统中

00:17:46.834 --> 00:17:50.571 align:middle line:90%,end
远景只会在一个方向上偏移
向左或是向右

00:17:51.171 --> 00:17:52.673 align:middle line:90%,end
随着这些相同的线

00:17:53.073 --> 00:17:55.943 align:middle line:90%,end
如果有条光线是从相机一观察到的

00:17:56.810 --> 00:18:01.181 align:middle line:90%,end
它就可以被看成是

00:17:56.810 --> 00:18:01.181 align:middle line:90%,end
它就可以被看成是

00:18:01.248 --> 00:18:02.850 align:middle line:90%,end
一条来自相机二线上的
一系列相交点

00:18:02.916 --> 00:18:04.051 align:middle line:90%,end
（校准错误）

00:18:04.117 --> 00:18:05.786 align:middle line:90%,end
（相机1
相机2）

00:18:05.853 --> 00:18:08.055 align:middle line:90%,end
要精确地测量视差

00:18:09.022 --> 00:18:11.225 align:middle line:90%,end
你必须要有一条精确的基线

00:18:11.758 --> 00:18:14.528 align:middle line:90%,end
基线也就是两个光学中心之间的距离

00:18:15.028 --> 00:18:16.830 align:middle line:90%,end
如果你没有精确的基线

00:18:16.897 --> 00:18:19.600 align:middle line:90%,end
你就不能对齐两个相机的光学中心

00:18:19.666 --> 00:18:22.069 align:middle line:90%,end
那么你就不能知道有多少的视差了

00:18:23.303 --> 00:18:28.242 align:middle line:90%,end
那如果光学中心被算错了或者
报错了会怎么样呢？

00:18:28.876 --> 00:18:31.545 align:middle line:90%,end
假如说真正的光学中心在这

00:18:32.112 --> 00:18:36.149 align:middle line:90%,end
但是因为某些原因
它被错误地报告成这里

00:18:36.884 --> 00:18:40.354 align:middle line:90%,end
突然间我们相机二像平面上的
所有视差点

00:18:40.420 --> 00:18:44.258 align:middle line:90%,end
都向左偏移了相同的固定数值

00:18:44.858 --> 00:18:49.129 align:middle line:10%
现在所有的对象
都会被比它们的真实位置报告得更远些

00:18:50.063 --> 00:18:51.732 align:middle line:10%
如果错误是发生在反方向的话

00:18:51.798 --> 00:18:54.301 align:middle line:10%
这些物体
就会被错误地报告为离得太近了

00:18:54.968 --> 00:18:57.271 align:middle line:10%
我们可以探测到并修复许多问题

00:18:57.337 --> 00:18:59.873 align:middle line:10%
但这个问题是我们不能探测并且修复的

00:18:59.940 --> 00:19:03.110 align:middle line:10%
因为所有这些点看上去
是在同一条正确的线上

00:18:59.940 --> 00:19:03.110 align:middle line:10%
因为所有这些点看上去
是在同一条正确的线上

00:19:03.377 --> 00:19:05.646 align:middle line:10%
我们区分不出来是基线有问题

00:19:06.013 --> 00:19:08.949 align:middle line:10%
还是人移动得更远或是更近了

00:19:10.117 --> 00:19:12.019 align:middle line:10%
这是怎么发生的呢
为什么

00:19:12.085 --> 00:19:15.088 align:middle line:10%
光学中心的计算会出问题呢？

00:19:16.056 --> 00:19:18.625 align:middle line:90%,end
因为iPhone的摄像头
用的不是针孔

00:19:18.692 --> 00:19:23.730 align:middle line:90%,end
它们用的是透镜
而且iPhone上的透镜不是固定不动的

00:19:24.331 --> 00:19:25.799 align:middle line:90%,end
如果使用了OIS

00:19:26.233 --> 00:19:29.970 align:middle line:90%,end
那么透镜可能会横向移动
来抵消手的抖动

00:19:31.004 --> 00:19:34.208 align:middle line:90%,end
重力也会发挥作用
因为它会导致镜头下垂

00:19:35.075 --> 00:19:39.646 align:middle line:90%,end
聚焦致动器实际上
就是施加了电流的弹簧

00:19:40.113 --> 00:19:44.017 align:middle line:90%,end
所有这些原因都可能会
导致它横向移动一小点

00:19:44.418 --> 00:19:46.620 align:middle line:90%,end
而这些光学中心位置的细微的错误

00:19:46.687 --> 00:19:49.690 align:middle line:90%,end
会导致视差的巨大错误

00:19:50.457 --> 00:19:54.261 align:middle line:90%,end
当发生这种情况时
结果就是一个恒定量的错误会出现在

00:19:54.661 --> 00:19:56.129 align:middle line:90%,end
图中的每个像素点上

00:19:57.297 --> 00:20:01.335 align:middle line:90%,end
视差值相对于彼此仍然是可用的

00:19:57.297 --> 00:20:01.335 align:middle line:90%,end
视差值相对于彼此仍然是可用的

00:20:01.735 --> 00:20:05.873 align:middle line:90%,end
但是它们不能再反映现实世界的距离了

00:20:07.474 --> 00:20:12.079 align:middle line:90%,end
出于这个原因 AVDepthData对象
必须有一个精确的概念

00:20:12.880 --> 00:20:16.416 align:middle line:90%,end
绝对的精度值意味着单位

00:20:16.483 --> 00:20:20.120 align:middle line:90%,end
确实能反映现实世界的距离
并没有校准的问题

00:20:20.721 --> 00:20:24.424 align:middle line:90%,end
相对精度意味着
Z排列仍然被保留着

00:20:25.092 --> 00:20:27.528 align:middle line:90%,end
但是现实世界的比例已经丢失了

00:20:28.395 --> 00:20:30.998 align:middle line:90%,end
对于从第三方相机捕捉的深度数据

00:20:31.064 --> 00:20:34.334 align:middle line:90%,end
它可以被报告为绝对或是相对的

00:20:34.768 --> 00:20:38.939 align:middle line:90%,end
但是iPhone 7 Plus
总是会报告相对精度

00:20:39.173 --> 00:20:41.608 align:middle line:90%,end
这是因为我刚才提到过的校准错误

00:20:41.875 --> 00:20:43.810 align:middle line:90%,end
但是我不想让你们被它吓到

00:20:43.877 --> 00:20:47.447 align:middle line:90%,end
相对精度其实并不糟糕

00:20:47.948 --> 00:20:52.319 align:middle line:90%,end
双摄像头的深度其实是完全够用的
让我来给你展示下为什么这么说

00:20:53.587 --> 00:20:55.055 align:middle line:90%,end
棒极了
幻灯片上有些公式

00:20:55.889 --> 00:20:57.357 align:middle line:90%,end
这里又有一些数学的问题

00:20:57.424 --> 00:21:01.461 align:middle line:90%,end
比如
在左边我们有个相对精度的视差值

00:20:57.424 --> 00:21:01.461 align:middle line:90%,end
比如
在左边我们有个相对精度的视差值

00:21:01.828 --> 00:21:04.565 align:middle line:90%,end
也就是那个上面带有一个小帽子符号的
字母d

00:21:04.998 --> 00:21:09.670 align:middle line:90%,end
因为它不是很好 它等同于
一个绝对视差d

00:21:09.736 --> 00:21:11.872 align:middle line:90%,end
加上一个固定量的错误

00:21:12.406 --> 00:21:14.908 align:middle line:90%,end
我们不知道固定量的错误是多少
但是它就在那

00:21:15.943 --> 00:21:19.446 align:middle line:90%,end
现在让我们进行一个常见的操作
比如寻找

00:21:19.513 --> 00:21:22.149 align:middle line:90%,end
同一个图中两个视差的不同之处

00:21:22.816 --> 00:21:24.718 align:middle line:90%,end
这就像是减去不同的部分

00:21:24.785 --> 00:21:28.021 align:middle line:90%,end
比方说
等式看起来是这样的

00:21:28.755 --> 00:21:33.961 align:middle line:90%,end
这里你有两个不好的数据
你要减去两个不好的视差

00:21:34.194 --> 00:21:35.829 align:middle line:90%,end
这就如同两个好的视差有着

00:21:35.896 --> 00:21:37.264 align:middle line:90%,end
同样的固定错误

00:21:37.431 --> 00:21:38.765 align:middle line:90%,end
如果我们把它们重新排列

00:21:38.832 --> 00:21:41.969 align:middle line:90%,end
就会发现
我们实际上解决了这些错误

00:21:42.035 --> 00:21:44.338 align:middle line:90%,end
因为它们相互抵消了

00:21:45.172 --> 00:21:48.008 align:middle line:90%,end
而我们剩下的
就是一个令人开心的巧合

00:21:49.676 --> 00:21:52.513 align:middle line:90%,end
这个令人开心的发现就是
不同处是一样的

00:21:53.046 --> 00:21:56.283 align:middle line:90%,end
不管你的视差是
绝对的还是相对的

00:21:56.850 --> 00:21:59.620 align:middle line:90%,end
这个公式在某种程度上证明了
相对就像绝对的一样好

00:21:59.686 --> 00:22:03.257 align:middle line:90%,end
如果你要实现的效果只依赖于

00:21:59.686 --> 00:22:03.257 align:middle line:90%,end
如果你要实现的效果只依赖于

00:22:03.323 --> 00:22:04.992 align:middle line:90%,end
相同图中的不同之处的话

00:22:05.058 --> 00:22:08.662 align:middle line:90%,end
这就是为什么
通过相对精度深度所生成的效果

00:22:08.729 --> 00:22:09.963 align:middle line:90%,end
看起来仍然很棒

00:22:12.299 --> 00:22:15.369 align:middle line:90%,end
介绍完这个我觉得我们已经讲完了
AVDepthData的有关内容

00:22:15.435 --> 00:22:17.571 align:middle line:90%,end
或者说我们已经差不多结束了

00:22:19.239 --> 00:22:21.441 align:middle line:90%,end
是时候接着讲我们
的第一个拍摄专题了

00:22:21.508 --> 00:22:23.076 align:middle line:90%,end
也就是流式深度

00:22:23.610 --> 00:22:25.612 align:middle line:90%,end
我觉得这时候应该做个演示

00:22:31.718 --> 00:22:35.656 align:middle line:90%,end
我们要做的演示叫
AVCamPhotoFilter

00:22:36.423 --> 00:22:40.227 align:middle line:90%,end
这个应用是我们去年
作为示例代码所发布的

00:22:40.394 --> 00:22:43.931 align:middle line:90%,end
它会为你们展示如何将一个效果
如何实时地将一个效果应用到预览中

00:22:44.464 --> 00:22:48.635 align:middle line:90%,end
并且将同样的效果渲染到照片上

00:22:48.969 --> 00:22:50.938 align:middle line:90%,end
去年它只有顶部的一个按钮

00:22:51.004 --> 00:22:53.340 align:middle line:90%,end
它是用来过滤视频的
它会将一个

00:22:53.407 --> 00:22:56.743 align:middle line:90%,end
有些劣质的玫瑰色
显示效果应用到这个视频上

00:22:56.810 --> 00:22:59.179 align:middle line:90%,end
不过它还是实时为你呈现了预览

00:22:59.246 --> 00:23:02.449 align:middle line:90%,end
并且它还在你拍照的时候
将其渲染到了照片上

00:22:59.246 --> 00:23:02.449 align:middle line:90%,end
并且它还在你拍照的时候
将其渲染到了照片上

00:23:02.883 --> 00:23:06.486 align:middle line:90%,end
今年我们将一些深度加到了这个示例中

00:23:07.054 --> 00:23:12.059 align:middle line:90%,end
借以向你们展示下
如何以流的方式来预览深度

00:23:12.559 --> 00:23:15.495 align:middle line:90%,end
现在我们要做的就是
打开深度

00:23:15.729 --> 00:23:22.069 align:middle line:90%,end
并且通过混合
完全RGB和完全深度来预览

00:23:22.302 --> 00:23:23.270 align:middle line:90%,end
（深度）

00:23:24.204 --> 00:23:26.340 align:middle line:90%,end
我要把我可爱的助手凡娜叫上来

00:23:26.406 --> 00:23:28.075 align:middle line:90%,end
其实他叫埃瑞克
谢谢你 埃瑞克

00:23:28.242 --> 00:23:29.843 align:middle line:90%,end
他会上来给我们展示

00:23:30.477 --> 00:23:32.913 align:middle line:90%,end
一些动态的东西
像是一个棒球手套

00:23:32.980 --> 00:23:33.847 align:middle line:90%,end
我很喜欢它

00:23:34.014 --> 00:23:37.551 align:middle line:90%,end
需要注意的是
还有很多的跳动

00:23:37.618 --> 00:23:40.220 align:middle line:90%,end
你肯定是能看到镜头里是什么
不过这样并不是很完美

00:23:40.287 --> 00:23:42.756 align:middle line:90%,end
有许多临时的问题

00:23:42.823 --> 00:23:47.060 align:middle line:90%,end
不过我可以点击下Smooth按钮
我们马上就过滤了

00:23:47.127 --> 00:23:49.997 align:middle line:90%,end
深度 填补了洞
暂时使它们变得平滑了

00:23:50.063 --> 00:23:52.466 align:middle line:90%,end
现在 这就是个看起来不错的视差了

00:23:52.533 --> 00:23:54.535 align:middle line:90%,end
我要拍一张照片

00:23:56.570 --> 00:23:59.239 align:middle line:90%,end
如果我现在回到照片应用中

00:23:59.907 --> 00:24:03.243 align:middle line:90%,end
就能找到我们刚刚拍摄这张

00:23:59.907 --> 00:24:03.243 align:middle line:90%,end
就能找到我们刚刚拍摄这张

00:24:03.710 --> 00:24:05.479 align:middle line:90%,end
非常不错的深度展示

00:24:05.812 --> 00:24:07.915 align:middle line:90%,end
现在这就是个有启发性的应用了

00:24:08.182 --> 00:24:12.019 align:middle line:90%,end
因为我们终于能回答这个问题了：
你的手套

00:24:12.386 --> 00:24:13.820 align:middle line:90%,end
你的手套有多深呢？

00:24:14.321 --> 00:24:15.656 align:middle line:90%,end
你们真的要学会啊

00:24:16.557 --> 00:24:18.125 align:middle line:90%,end
好的 让我们回到幻灯片上

00:24:18.525 --> 00:24:19.760 align:middle line:90%,end
（关于AVCAMPHOTOFILTER
的演示）

00:24:20.861 --> 00:24:23.230 align:middle line:90%,end
我知道已经很晚了
我想让你们保持清醒

00:24:24.631 --> 00:24:26.266 align:middle line:90%,end
我们是如何实现的呢

00:24:27.601 --> 00:24:29.803 align:middle line:90%,end
AVFoundation框架的
相机捕捉类

00:24:29.870 --> 00:24:32.372 align:middle line:90%,end
分为三个主要部分

00:24:32.706 --> 00:24:35.976 align:middle line:90%,end
第一个是AVCaptureSession
它就是一个控制对象

00:24:36.476 --> 00:24:38.979 align:middle line:90%,end
你可以让它开始或停止运行
但是它不能实现其他功能了

00:24:39.046 --> 00:24:43.450 align:middle line:90%,end
除非你给它某些输入
这里我们有一些AV捕捉输入

00:24:43.717 --> 00:24:45.686 align:middle line:90%,end
例如AVCaptureDeviceInput

00:24:45.953 --> 00:24:48.956 align:middle line:90%,end
这里我已经创建了一个
跟双摄像头相关的了

00:24:49.289 --> 00:24:51.191 align:middle line:90%,end
它会给这个会话提供输入

00:24:51.491 --> 00:24:53.894 align:middle line:90%,end
不过现在你需要将其
作为输出导出到某个地方

00:24:54.328 --> 00:24:58.398 align:middle line:90%,end
现在我们就有了一种新的输出 叫作
AVCaptureDepthDataOutput

00:24:59.166 --> 00:25:03.370 align:middle line:90%,end
它在我们的团队中
被简称为DDO

00:24:59.166 --> 00:25:03.370 align:middle line:90%,end
它在我们的团队中
被简称为DDO

00:25:03.971 --> 00:25:06.707 align:middle line:90%,end
它的功能类似于
VideoDataOutput

00:25:06.773 --> 00:25:09.910 align:middle line:90%,end
除了VideoDataOutput是向
CoreMedia提供示例缓冲区

00:25:10.277 --> 00:25:13.347 align:middle line:90%,end
而它提供的是
AVDepthData对象

00:25:13.714 --> 00:25:16.383 align:middle line:90%,end
也就是我刚才讲过的
那个权威的表示形式

00:25:16.450 --> 00:25:18.519 align:middle line:90%,end
它以流的形式将它们送达

00:25:18.585 --> 00:25:20.454 align:middle line:10%
（引入AVCAPTUREDEPTHDATAOUTPUT）

00:25:22.956 --> 00:25:26.059 align:middle line:90%,end
AVCaptureDepthDataOutput
都支持什么呢？

00:25:26.126 --> 00:25:28.962 align:middle line:90%,end
你当然可以将它添加到
任何会话的任意位置

00:25:29.029 --> 00:25:32.266 align:middle line:90%,end
不过这样你得不到深度
除非你是在双摄像头模式下

00:25:32.332 --> 00:25:35.669 align:middle line:90%,end
因为这是唯一的双系统
或者说立体系统

00:25:35.736 --> 00:25:38.005 align:middle line:90%,end
是我们用来计算视差的

00:25:39.106 --> 00:25:42.109 align:middle line:90%,end
当你将一个DepthDataOutput
附到你的会话中时

00:25:42.442 --> 00:25:43.310 align:middle line:90%,end
会发生一些事情

00:25:43.677 --> 00:25:46.747 align:middle line:90%,end
双摄像头会自动地放大到2倍

00:25:46.947 --> 00:25:49.683 align:middle line:90%,end
也就是长焦的全部视野

00:25:50.017 --> 00:25:52.452 align:middle line:90%,end
这是因为为了计算视差

00:25:52.519 --> 00:25:56.156 align:middle line:90%,end
焦距必须相同
而在2倍变焦下

00:25:56.223 --> 00:25:59.259 align:middle line:90%,end
广角与长焦摄像头的焦距是一致的

00:26:00.527 --> 00:26:03.764 align:middle line:90%,end
与此同时 当你计算深度的时候
缩放是被禁用的

00:26:04.631 --> 00:26:05.632 align:middle line:90%,end
我们添加了

00:26:05.699 --> 00:26:08.268 align:middle line:90%,end
一些新的访问器
到AVCaptureDevice中

00:26:08.902 --> 00:26:13.340 align:middle line:90%,end
在双摄像头系统中
你可以查到哪些视频格式是支持深度的

00:26:13.407 --> 00:26:16.043 align:middle line:90%,end
通过查询supported
DepthDataFormats就可以找到

00:26:17.144 --> 00:26:20.614 align:middle line:90%,end
还有一个新的属性叫作
activeDepthDataFormat

00:26:20.681 --> 00:26:23.584 align:middle line:90%,end
它可以让你明白
activeDepthDataFormat是什么

00:26:23.650 --> 00:26:26.753 align:middle line:90%,end
或是选择一个新的
DepthDataFormat

00:26:28.288 --> 00:26:29.723 align:middle line:90%,end
目前我们支持

00:26:29.790 --> 00:26:33.627 align:middle line:90%,end
三种深度的视频分辨率
或者说深度的预设

00:26:33.694 --> 00:26:35.729 align:middle line:90%,end
让我来一个个介绍下

00:26:35.796 --> 00:26:38.031 align:middle line:90%,end
第一个是广受欢迎的
照片预设

00:26:38.665 --> 00:26:42.703 align:middle line:90%,end
在照片预设中 你可以获得一个
屏幕尺寸的预览

00:26:42.769 --> 00:26:46.640 align:middle line:90%,end
该预览来自于VideoDataOutput
你还能获得一张1200万像素的完整图像

00:26:46.840 --> 00:26:48.408 align:middle line:90%,end
其来自于photoOutput

00:26:48.909 --> 00:26:52.212 align:middle line:90%,end
这里你可以发现VideoDataOutput
提供的是1440x1080分辨率

00:26:52.279 --> 00:26:53.413 align:middle line:90%,end
也就是屏幕尺寸的图像

00:26:53.847 --> 00:26:56.283 align:middle line:90%,end
除此之外 如果你使用了
DepthDataOutput

00:26:56.450 --> 00:27:00.387 align:middle line:90%,end
你就可以得到一个320x240
最大帧率为24fps的深度数据

00:26:56.450 --> 00:27:00.387 align:middle line:90%,end
你就可以得到一个320x240
最大帧率为24fps的深度数据

00:27:00.454 --> 00:27:01.488 align:middle line:90%,end
为什么这么小呢？

00:27:01.688 --> 00:27:06.226 align:middle line:90%,end
因为你需要消耗很多性能
才能处理每秒24帧的视差图

00:27:06.827 --> 00:27:09.930 align:middle line:90%,end
如果你愿意的话
你可以获得一个较低分辨率

00:27:09.997 --> 00:27:11.365 align:middle line:90%,end
只有160x120的视差图

00:27:11.665 --> 00:27:15.469 align:middle line:90%,end
第二个是16x9格式
这是今年的一个新格式

00:27:16.003 --> 00:27:20.107 align:middle line:90%,end
去年我们引入了一个720p
帧率高达60fps的16x9格式

00:27:20.340 --> 00:27:23.610 align:middle line:90%,end
该新格式最高能支持30fps的帧率
但是它支持深度

00:27:23.810 --> 00:27:26.813 align:middle line:90%,end
它也支持
DepthDataOutput

00:27:26.880 --> 00:27:29.449 align:middle line:90%,end
以320x180或是
160x90的分辨率

00:27:29.950 --> 00:27:34.555 align:middle line:90%,end
最后 我们有个非常小的
VGA大小的预设 或者说活动格式

00:27:34.621 --> 00:27:37.858 align:middle line:90%,end
如果你想要个非常小而且快的视差图
就可以使用它

00:27:41.361 --> 00:27:42.696 align:middle line:90%,end
让我们来谈下帧率

00:27:42.763 --> 00:27:47.000 align:middle line:90%,end
AVCaptureDevice能让你设置
最小和最大视频帧率

00:27:47.067 --> 00:27:50.103 align:middle line:90%,end
但是它不允许你
设定深度帧率

00:27:50.170 --> 00:27:51.738 align:middle line:90%,end
独立于视频的帧率

00:27:52.206 --> 00:27:56.043 align:middle line:90%,end
这是因为深度需要
与视频帧率保持一致

00:27:56.109 --> 00:28:01.648 align:middle line:90%,end
或者说保持在同等分割的
视频帧率上

00:27:56.109 --> 00:28:01.648 align:middle line:90%,end
或者说保持在同等分割的
视频帧率上

00:28:02.316 --> 00:28:07.054 align:middle line:90%,end
比如说
如果你选择的最大视频帧率为24

00:28:07.821 --> 00:28:11.225 align:middle line:90%,end
深度能跟得上视频的最大帧率
那么你就可以得到24fps的深度

00:28:11.658 --> 00:28:14.561 align:middle line:90%,end
但是如果你选择的是30fps的视频

00:28:15.095 --> 00:28:18.932 align:middle line:90%,end
深度就跟不上了
所以它就不会选择24 而是15

00:28:18.999 --> 00:28:20.868 align:middle line:90%,end
这样就能得到
更容易被划分的部分了

00:28:21.869 --> 00:28:23.403 align:middle line:90%,end
（AVCaptureDepthDataOutput
的深度过滤）

00:28:23.470 --> 00:28:25.973 align:middle line:90%,end
DepthDataOutput支持
过滤深度数据

00:28:26.039 --> 00:28:28.375 align:middle line:90%,end
就像是我刚才在
AVCamPhotoFilter演示中所说的那样

00:28:28.742 --> 00:28:31.912 align:middle line:90%,end
这样就可以填满洞
还可以使其变得更为平滑

00:28:31.979 --> 00:28:36.149 align:middle line:90%,end
随着你的移动 这样你就看不到
帧与帧之间短暂的跳跃了

00:28:38.185 --> 00:28:41.188 align:middle line:90%,end
好了
让我们来看下目前的

00:28:41.255 --> 00:28:43.790 align:middle line:90%,end
四种数据输出

00:28:43.857 --> 00:28:46.793 align:middle line:90%,end
我们现有四种了
第一种是VideoDataOutput

00:28:46.860 --> 00:28:48.595 align:middle line:90%,end
它在iOS 4中就已经出现了

00:28:49.029 --> 00:28:52.432 align:middle line:90%,end
它会一个接一个地将视频帧

00:28:52.499 --> 00:28:56.403 align:middle line:90%,end
以30fps或是60fps的流媒体方式
根据你所设定的数值送达给你

00:28:57.070 --> 00:28:58.939 align:middle line:90%,end
还有一种是
AudioDataOutput

00:28:59.239 --> 00:29:05.412 align:middle line:90%,end
它通常一次会以44.1的速度
向你推送1024个PCM帧

00:28:59.239 --> 00:29:05.412 align:middle line:90%,end
它通常一次会以44.1的速度
向你推送1024个PCM帧

00:29:06.580 --> 00:29:09.082 align:middle line:90%,end
我们还有MetadataOutput
它可以提供

00:29:09.249 --> 00:29:13.720 align:middle line:90%,end
面部 检测到的面部 或是条形码
这些都会偶尔出现

00:29:14.121 --> 00:29:17.758 align:middle line:90%,end
它们在寻找面部信息的时候
可能会有最高4帧的延迟

00:29:18.458 --> 00:29:20.727 align:middle line:90%,end
我们新添加了
DepthDataOutput

00:29:20.794 --> 00:29:23.597 align:middle line:90%,end
也就是我刚刚提过的
它会以视频的帧率送达

00:29:23.664 --> 00:29:28.168 align:middle line:90%,end
或是以视频可整除的帧率来送达

00:29:28.535 --> 00:29:30.871 align:middle line:90%,end
这样就变得有点荒谬了

00:29:31.338 --> 00:29:33.173 align:middle line:90%,end
要处理所有这些数据输出

00:29:33.240 --> 00:29:36.376 align:middle line:90%,end
你必须要有一个非常成熟的缓冲机制

00:29:36.710 --> 00:29:38.812 align:middle line:90%,end
来追踪所有进来的对象

00:29:38.879 --> 00:29:41.748 align:middle line:90%,end
如果你要同时处理所有这些数据

00:29:41.982 --> 00:29:44.718 align:middle line:90%,end
或是一并处理某个特定的表现时间

00:29:45.485 --> 00:29:51.925 align:middle line:90%,end
我们发现这个问题已经有一阵子了
但是DepthDataOutput

00:29:51.992 --> 00:29:54.928 align:middle line:90%,end
证明它就是解决问题的桥梁

00:29:57.164 --> 00:29:59.800 align:middle line:90%,end
掌声不是很响亮呀
下次请拍得更响一点

00:30:00.000 --> 00:30:03.303 align:middle line:90%,end
在iOS 11中 我们添加了一个
新的同步对象

00:30:03.370 --> 00:30:06.807 align:middle line:90%,end
叫作
AVCaptureDataOutputSynchronizer

00:30:07.341 --> 00:30:10.777 align:middle line:90%,end
它可以在给定的呈现时间内
送达所有的可用数据

00:30:10.944 --> 00:30:13.280 align:middle line:90%,end
在单个统一的回调函数中

00:30:13.547 --> 00:30:16.183 align:middle line:10%
它会提供一个集合对象叫作

00:30:16.250 --> 00:30:18.819 align:middle line:10%
AVCaptureSynchronized
DataCollection

00:30:19.353 --> 00:30:22.089 align:middle line:10%
它能让你指定一个主输出

00:30:22.356 --> 00:30:24.992 align:middle line:10%
也就是对你来说最重要的输出
你想将所有其他东西

00:30:25.058 --> 00:30:26.426 align:middle line:10%
都同步到主输出上

00:30:26.660 --> 00:30:29.296 align:middle line:10%
然后它就会保留所有多媒体信息

00:30:29.363 --> 00:30:32.165 align:middle line:10%
只要你需要的话
以确保所有的数据

00:30:32.232 --> 00:30:35.035 align:middle line:90%,end
在给定的呈现时间内都是可用的
在它给出单个统一

00:30:35.102 --> 00:30:36.637 align:middle line:90%,end
回调函数之前

00:30:37.604 --> 00:30:40.474 align:middle line:90%,end
它要么会给你所有输出的数据

00:30:40.541 --> 00:30:43.610 align:middle line:90%,end
要么就是能确保
如果没有特定输出的数据的话

00:30:43.677 --> 00:30:46.547 align:middle line:90%,end
它就会给你提供一个与它有关的集合

00:30:47.681 --> 00:30:49.049 align:middle line:90%,end
这里有一个代码段

00:30:49.116 --> 00:30:52.519 align:middle line:90%,end
它给你们展示了数据输出同步器的
统一代理回调函数是如何工作的

00:30:52.786 --> 00:30:55.989 align:middle line:90%,end
该回调函数会传给你一个
SynchronizedDataCollection

00:30:56.456 --> 00:30:58.892 align:middle line:90%,end
这很酷
你可以像使用数组一样来使用它

00:30:58.959 --> 00:31:01.895 align:middle line:90%,end
或者是像词典那样使用
取决于你想用它实现什么功能

00:30:58.959 --> 00:31:01.895 align:middle line:90%,end
或者是像词典那样使用
取决于你想用它实现什么功能

00:31:01.962 --> 00:31:05.232 align:middle line:90%,end
你可以像是遍历数组一样遍历它

00:31:05.299 --> 00:31:08.135 align:middle line:90%,end
你可以使用快速枚举来获取

00:31:08.202 --> 00:31:09.536 align:middle line:90%,end
当前集合中所有对象的列表

00:31:10.437 --> 00:31:14.942 align:middle line:90%,end
或者说如果你想将它
当成词典那样使用的话

00:31:15.275 --> 00:31:18.812 align:middle line:90%,end
你就可以通过索引数据输出的下标

00:31:18.879 --> 00:31:20.214 align:middle line:90%,end
来得到你想要的结果

00:31:20.280 --> 00:31:22.850 align:middle line:90%,end
例如
我这里只想查找某个特定的结果

00:31:22.916 --> 00:31:25.652 align:middle line:90%,end
该结果来自于DepthDataOutput
要是结果存在的话

00:31:25.953 --> 00:31:26.854 align:middle line:90%,end
它就会把结果给你

00:31:27.087 --> 00:31:29.957 align:middle line:90%,end
你需要在代码中
用到guard语句来查找nil

00:31:30.023 --> 00:31:32.693 align:middle line:90%,end
因为你可能在给定的呈现时间内
找不到任何深度数据

00:31:34.494 --> 00:31:35.329 align:middle line:90%,end
好了

00:31:35.395 --> 00:31:38.599 align:middle line:90%,end
这里举个如何使用AVCaptureData
OutputSynchronizer的例子

00:31:38.665 --> 00:31:42.703 align:middle line:90%,end
这里又用到了AVCamPhotoFilter
该示例代码已经可以供你们查阅了

00:31:42.769 --> 00:31:45.239 align:middle line:90%,end
它被关联到这个演讲中了
你现在就可以下载它

00:31:47.140 --> 00:31:49.276 align:middle line:90%,end
在iOS 11中
有另一个新的流式功能

00:31:49.343 --> 00:31:50.844 align:middle line:90%,end
它有点偏离今天的主题

00:31:51.278 --> 00:31:56.350 align:middle line:90%,end
那就是对于每个视频帧的
相机内在功能送达的支持

00:31:56.650 --> 00:31:58.151 align:middle line:90%,end
当你在使用
VideoDataOutput的时候

00:31:58.719 --> 00:32:00.754 align:middle line:90%,end
回忆下我们前面讲到的针孔相机

00:31:58.719 --> 00:32:00.754 align:middle line:90%,end
回忆下我们前面讲到的针孔相机

00:32:01.455 --> 00:32:04.491 align:middle line:90%,end
它可以将3D空间中的点
转换成2D空间的

00:32:04.558 --> 00:32:08.228 align:middle line:90%,end
我们需要两种信息
我们需要光学中心

00:32:08.562 --> 00:32:11.665 align:middle line:90%,end
或者说主点
我们还需要焦距

00:32:12.065 --> 00:32:14.568 align:middle line:90%,end
在计算机视觉中
你可以使用这些属性

00:32:14.835 --> 00:32:18.305 align:middle line:90%,end
来将2D图像重新投影回3D空间

00:32:18.505 --> 00:32:20.974 align:middle line:90%,end
通过使用逆转换

00:32:21.208 --> 00:32:24.344 align:middle line:90%,end
这也是新的ARKit的重点

00:32:25.212 --> 00:32:30.450 align:middle line:90%,end
作为iOS 11中的新功能
你可以选择接收一组内在函数

00:32:30.884 --> 00:32:33.720 align:middle line:90%,end
此函数适用于你所送达的每个视频帧

00:32:33.921 --> 00:32:36.757 align:middle line:90%,end
并且你可以通过调用
AVCaptureConnection的

00:32:37.157 --> 00:32:40.360 align:middle line:90%,end
isCameraIntrinsicMatrixDelivery
Enabled方法来选择

00:32:41.094 --> 00:32:45.465 align:middle line:90%,end
当你这么做的时候就可以
在每个缓冲区都获得一个附件

00:32:45.532 --> 00:32:46.533 align:middle line:90%,end
该附件包含内在功能

00:32:47.000 --> 00:32:48.702 align:middle line:90%,end
让我展示矩阵本身是什么样子的

00:32:48.769 --> 00:32:52.239 align:middle line:90%,end
它可能看上去挺复杂的
其实相当简单

00:32:52.973 --> 00:32:55.576 align:middle line:90%,end
相机内在函数是一个3x3的矩阵

00:32:55.642 --> 00:32:59.246 align:middle line:90%,end
它描述了相机的几何属性

00:32:59.813 --> 00:33:02.983 align:middle line:90%,end
fx和fy是以像素表示的焦距

00:32:59.813 --> 00:33:02.983 align:middle line:90%,end
fx和fy是以像素表示的焦距

00:33:03.617 --> 00:33:06.486 align:middle line:90%,end
它们是单独的x和y值
因为有时候相机

00:33:06.553 --> 00:33:09.756 align:middle line:90%,end
具有变形镜头或者变形像素

00:33:10.324 --> 00:33:14.027 align:middle line:90%,end
在iOS设备上 我们的相机
一直都使用方形的像素

00:33:14.094 --> 00:33:16.697 align:middle line:90%,end
所以fx和fy总是相等的

00:33:17.764 --> 00:33:21.802 align:middle line:90%,end
x0和y0是两个像素坐标

00:33:21.869 --> 00:33:24.571 align:middle line:90%,end
它们是镜头主点
或者说光学中心的坐标

00:33:25.172 --> 00:33:28.308 align:middle line:90%,end
它们都是以像素为单位表示的数值
而且它们都是根据

00:33:28.375 --> 00:33:30.711 align:middle line:90%,end
提供它们的视频缓冲区的
分辨率所给出的

00:33:31.345 --> 00:33:34.615 align:middle line:10%
所以一旦你选择了
就能以流的方式获得样本缓冲区

00:33:34.681 --> 00:33:37.784 align:middle line:10%
而且你会从它们那得到这个附件

00:33:38.285 --> 00:33:43.023 align:middle line:10%
其有效载荷是一个C/F数据
它包含了一个3x3的浮点数矩阵

00:33:43.357 --> 00:33:44.691 align:middle line:10%
也就是SIMD数据类型

00:33:45.225 --> 00:33:48.996 align:middle line:90%,end
如果你在做计算机视觉相关的工作
你就会对这个新功能非常感兴趣

00:33:50.531 --> 00:33:54.434 align:middle line:90%,end
好了
我们已经正式讲完了关于流的专题

00:33:55.802 --> 00:33:56.970 align:middle line:90%,end
这次不错

00:33:57.037 --> 00:33:59.339 align:middle line:90%,end
接下来让我们介绍下照片的拍摄

00:33:59.806 --> 00:34:01.008 align:middle line:90%,end
让我们从演示开始吧

00:33:59.806 --> 00:34:01.008 align:middle line:90%,end
让我们从演示开始吧

00:34:01.074 --> 00:34:02.843 align:middle line:90%,end
AVCam
和WIGGLE ME

00:34:07.714 --> 00:34:10.551 align:middle line:90%,end
这里有两个内容要讲
我们这里要介绍两个应用

00:34:11.118 --> 00:34:13.587 align:middle line:90%,end
AVCam是示例代码的重要部分

00:34:13.654 --> 00:34:14.855 align:middle line:90%,end
它会展示如何

00:34:15.054 --> 00:34:18.425 align:middle line:90%,end
使用AVFoundation
来拍摄照片和影片

00:34:19.826 --> 00:34:22.696 align:middle line:90%,end
这里要注意的是 尽管我们已经
对其添加了深度的支持

00:34:22.763 --> 00:34:24.764 align:middle line:90%,end
你还是看不到任何与深度有关的东西

00:34:25.165 --> 00:34:29.870 align:middle line:90%,end
这是因为当我拍摄这里的铅笔时

00:34:29.937 --> 00:34:33.739 align:middle line:90%,end
你实际上是看不到深度的表现的

00:34:34.541 --> 00:34:37.744 align:middle line:90%,end
但是它已经被保存在照片中了
所以当我进入相机应用后

00:34:38.745 --> 00:34:42.081 align:middle line:90%,end
让我来看一下 比方说
我进入了编辑菜单

00:34:42.748 --> 00:34:44.851 align:middle line:90%,end
上面弹出了什么
顶端出现了一个Depth按钮

00:34:44.918 --> 00:34:48.789 align:middle line:90%,end
现在如果我点击Depth按钮
它马上将会将一个模糊特效

00:34:48.856 --> 00:34:50.858 align:middle line:90%,end
应用到背景当中
这真的很酷

00:34:51.225 --> 00:34:55.629 align:middle line:90%,end
所以现在你在应用中
拍摄的照片

00:34:55.696 --> 00:35:00.033 align:middle line:90%,end
也可以使用这个浅深度域的效果了

00:34:55.696 --> 00:35:00.033 align:middle line:90%,end
也可以使用这个浅深度域的效果了

00:35:00.367 --> 00:35:01.502 align:middle line:90%,end
这真的很酷

00:35:01.969 --> 00:35:05.272 align:middle line:90%,end
我们还可以利用深度
实现更多有意思的功能

00:35:05.506 --> 00:35:07.941 align:middle line:90%,end
既然现在所有的照片都有深度数据了

00:35:08.008 --> 00:35:11.311 align:middle line:90%,end
另外 在iOS 11中
所有你以

00:35:11.378 --> 00:35:15.449 align:middle line:90%,end
人像模式拍摄的照片现在
都保存了深度信息

00:35:15.516 --> 00:35:18.752 align:middle line:90%,end
它们就是你
新的创意应用的素材

00:35:19.520 --> 00:35:21.722 align:middle line:90%,end
我要用这个叫作
Wiggle Me的应用

00:35:22.089 --> 00:35:24.992 align:middle line:90%,end
来展示一些
你可以利用深度实现的创新功能

00:35:26.894 --> 00:35:30.631 align:middle line:90%,end
我挑个简单的开始讲

00:35:31.098 --> 00:35:33.233 align:middle line:90%,end
此功能实现的是将一些平面的东西

00:35:33.867 --> 00:35:37.337 align:middle line:90%,end
重新投影到3D空间

00:35:37.771 --> 00:35:42.576 align:middle line:90%,end
使其看起来有点滚动的效果
我可以让它停止滚动

00:35:42.643 --> 00:35:45.746 align:middle line:90%,end
我还可以使用陀螺仪来移动我的手机

00:35:46.813 --> 00:35:48.015 align:middle line:90%,end
这难道不是精妙的效果吗？

00:35:48.081 --> 00:35:49.449 align:middle line:90%,end
它看起来栩栩如生的

00:35:50.017 --> 00:35:51.652 align:middle line:90%,end
我想再挑个功能来讲讲

00:35:52.953 --> 00:35:54.221 align:middle line:90%,end
我真的很喜欢这只狗

00:35:55.055 --> 00:35:56.089 align:middle line:90%,end
这只狗看上去很不错

00:35:56.156 --> 00:35:59.960 align:middle line:90%,end
现在他看上去就在

00:36:00.027 --> 00:36:02.429 align:middle line:90%,end
左右地移动了
你还可以

00:36:02.496 --> 00:36:05.832 align:middle line:90%,end
强制让透视发生变化
在知道了

00:36:05.899 --> 00:36:09.803 align:middle line:90%,end
深度数据在哪里之后
你就可以利用深度实现这样的功能了

00:36:10.804 --> 00:36:11.705 align:middle line:90%,end
放大吧多利

00:36:13.140 --> 00:36:14.808 align:middle line:90%,end
放大吧多利 挑衅吧狗狗

00:36:15.008 --> 00:36:17.711 align:middle line:90%,end
我希望在多利放大的时候
将其进行旋转

00:36:17.978 --> 00:36:19.980 align:middle line:90%,end
因为它有点像是条黑帮狗

00:36:22.182 --> 00:36:23.951 align:middle line:90%,end
我觉得最适合这里的音乐

00:36:24.017 --> 00:36:26.253 align:middle line:90%,end
应该就是“Rolling in the Deep”了
不是吗？

00:36:28.488 --> 00:36:30.824 align:middle line:90%,end
你们做得很好 我很感谢

00:36:30.891 --> 00:36:31.959 align:middle line:90%,end
我真的很感谢

00:36:37.030 --> 00:36:39.433 align:middle line:90%,end
在拍摄带有深度的照片时

00:36:39.600 --> 00:36:42.269 align:middle line:90%,end
我们提供了很多的拍摄选项

00:36:43.103 --> 00:36:45.305 align:middle line:90%,end
你可以使用深度进行带闪光灯的拍摄

00:36:45.372 --> 00:36:47.975 align:middle line:90%,end
你可以使用深度进行静态图像防抖

00:36:48.442 --> 00:36:53.280 align:middle line:90%,end
你甚至可以实现自动包围曝光
比如a+2 -2 0 EV

00:36:53.881 --> 00:36:58.619 align:middle line:90%,end
你可以利用保存在照片中的深度数据
来制作Live Photos

00:37:00.687 --> 00:37:05.225 align:middle line:90%,end
你可以使用AVCapturePhotoOutput
来获取带有深度的照片

00:37:05.659 --> 00:37:08.629 align:middle line:90%,end
这个类是我们去年引入的
将其作为

00:37:08.695 --> 00:37:10.130 align:middle line:90%,end
AVCaptureStillImageOutput
的继承者

00:37:10.898 --> 00:37:14.368 align:middle line:90%,end
它可以非常出色地处理复杂的照片请求

00:37:14.735 --> 00:37:18.071 align:middle line:90%,end
我所说的是可以获得多个资源的请求

00:37:18.605 --> 00:37:23.243 align:middle line:90%,end
而这些资源是必须被追踪和送达
比如说你想获得一个raw图片

00:37:23.710 --> 00:37:27.581 align:middle line:90%,end
JPEG图片
或者live photo影片 等等

00:37:27.648 --> 00:37:30.651 align:middle line:90%,end
你会在不同的时间点得到很多东西

00:37:30.717 --> 00:37:33.220 align:middle line:90%,end
这里的编程模型要你填写一个请求

00:37:33.787 --> 00:37:35.923 align:middle line:90%,end
该请求叫作
AVCapturePhotoSettings

00:37:36.156 --> 00:37:38.792 align:middle line:90%,end
你通过传递请求来开始照片的拍摄

00:37:39.092 --> 00:37:40.794 align:middle line:90%,end
你还要传递稍后会被调用的代理

00:37:41.562 --> 00:37:43.330 align:middle line:90%,end
因为你的photoOutput是

00:37:43.397 --> 00:37:48.669 align:middle line:90%,end
唯一用来拍摄Live Photo

00:37:49.436 --> 00:37:53.440 align:middle line:90%,end
裸RAW图像
和Apple P3宽色图像的接口

00:37:54.374 --> 00:37:58.045 align:middle line:90%,end
它还是iOS 11中唯一可以

00:37:58.111 --> 00:38:02.516 align:middle line:90%,end
拍摄HEIF文件格式的方法
这在Keynote演讲中提到过

00:37:58.111 --> 00:38:02.516 align:middle line:90%,end
拍摄HEIF文件格式的方法
这在Keynote演讲中提到过

00:38:04.051 --> 00:38:05.853 align:middle line:90%,end
你需要对

00:38:05.919 --> 00:38:08.789 align:middle line:90%,end
AVCapturePhotoOutput进行许多修改
这样才能支持HEIF

00:38:09.356 --> 00:38:13.594 align:middle line:90%,end
所以在iOS 11中
为了适应如此多的变化

00:38:13.660 --> 00:38:16.163 align:middle line:90%,end
我们添加了一个新的代理回调函数

00:38:17.197 --> 00:38:18.832 align:middle line:90%,end
它很简单

00:38:19.066 --> 00:38:22.002 align:middle line:90%,end
它用来代替

00:38:22.069 --> 00:38:24.371 align:middle line:90%,end
你获取样本缓冲区的回调函数

00:38:24.438 --> 00:38:27.508 align:middle line:90%,end
现在你会得到一个叫作
AVCapturePhoto的新对象

00:38:28.308 --> 00:38:32.212 align:middle line:90%,end
AVCapturePhoto是
深度唯一的传递媒介

00:38:32.479 --> 00:38:35.315 align:middle line:90%,end
因此如果你想用深度的话

00:38:35.482 --> 00:38:37.684 align:middle line:90%,end
就得实现这个新的代理回调函数

00:38:39.553 --> 00:38:42.523 align:middle line:90%,end
另外 你需要

00:38:42.589 --> 00:38:45.492 align:middle line:90%,end
在会话开始前明确选择
DepthDataDelivery

00:38:46.126 --> 00:38:48.862 align:middle line:90%,end
为什么呢？如果你们还记得的话
双摄像头

00:38:48.929 --> 00:38:51.098 align:middle line:90%,end
在处理深度的时候
需要进行某些特殊的操作

00:38:51.164 --> 00:38:54.835 align:middle line:90%,end
它需要放大到2倍
使焦距匹配

00:38:55.335 --> 00:38:58.205 align:middle line:90%,end
它需要锁定变焦功能
这样你就不能再进行缩放了

00:38:59.106 --> 00:39:02.309 align:middle line:90%,end
想要实现这个功能
在开始运行会话之前

00:38:59.106 --> 00:39:02.309 align:middle line:90%,end
想要实现这个功能
在开始运行会话之前

00:39:02.376 --> 00:39:06.146 align:middle line:90%,end
你就需要告诉photoOutput
“我需要DepthDataDeliveryEnabled”

00:39:06.613 --> 00:39:10.551 align:middle line:90%,end
然后根据每张照片的请求
也就是在你

00:39:10.617 --> 00:39:14.087 align:middle line:90%,end
拍照的时候 你就会填写一个设置对象

00:39:14.288 --> 00:39:16.290 align:middle line:90%,end
“我想在这张照片中包含深度”

00:39:17.824 --> 00:39:21.762 align:middle line:90%,end
然后你就可以使用返回的
AVCapturePhoto了

00:39:22.162 --> 00:39:25.199 align:middle line:90%,end
它有一个叫作
AVDepthData的访问器

00:39:25.265 --> 00:39:28.068 align:middle line:90%,end
哇 这个AVDepthData
真的是无处不在啊

00:39:28.535 --> 00:39:31.205 align:middle line:90%,end
它就像是深入集成到了API中

00:39:34.441 --> 00:39:36.310 align:middle line:90%,end
iOS上绝大多数的
AVCaptureDevice

00:39:36.376 --> 00:39:38.111 align:middle line:90%,end
格式都具有

00:39:38.178 --> 00:39:41.849 align:middle line:90%,end
更高的静态分辨率
比起流式方案来说

00:39:42.316 --> 00:39:43.450 align:middle line:90%,end
看下我们

00:39:43.517 --> 00:39:45.752 align:middle line:90%,end
在iPhone 7 Plus上
支持深度的格式

00:39:46.253 --> 00:39:49.690 align:middle line:90%,end
你就可以发现流式视频分辨率

00:39:49.756 --> 00:39:52.426 align:middle line:90%,end
可以和你获得的高分辨率照片相媲美

00:39:52.726 --> 00:39:55.062 align:middle line:90%,end
例如 对于照片来说
如果你使用流的话

00:39:55.128 --> 00:39:58.999 align:middle line:90%,end
你只能得到屏幕大小的缓冲区
但你可得到1200万像素的静态照片

00:39:59.700 --> 00:40:01.368 align:middle line:90%,end
对于深度也是这样

00:39:59.700 --> 00:40:01.368 align:middle line:90%,end
对于深度也是这样

00:40:02.569 --> 00:40:04.471 align:middle line:90%,end
我说过当我们在用流处理深度数据时

00:40:04.538 --> 00:40:09.776 align:middle line:90%,end
有很多需要实时完成的工作
以满足24 fps的要求

00:40:09.843 --> 00:40:12.613 align:middle line:90%,end
但是当处理照片的时候
我们还可以有一点额外的时间

00:40:12.679 --> 00:40:14.915 align:middle line:90%,end
因为它不需要实时送达

00:40:14.982 --> 00:40:17.417 align:middle line:90%,end
所以我们可以就可以给你
提供一个非常高质量

00:40:17.518 --> 00:40:20.687 align:middle line:90%,end
好看的图
它的分辨率是流分辨率的两倍之多

00:40:21.822 --> 00:40:24.825 align:middle line:90%,end
其长宽比总是与视频的长宽比保持一致

00:40:24.892 --> 00:40:27.928 align:middle line:90%,end
如果你处理的是16x9的视频
你就会得到16x9的图

00:40:30.297 --> 00:40:35.369 align:middle line:90%,end
好了
现在是时候谈一下关于失真的话题了

00:40:36.236 --> 00:40:41.175 align:middle line:90%,end
我们捕捉并且嵌入到照片中的深度图
是失真的

00:40:41.942 --> 00:40:45.412 align:middle line:90%,end
我很抱歉给你们带来这个消息
不过这其实是个好事

00:40:45.846 --> 00:40:46.914 align:middle line:90%,end
让我来解释下为什么

00:40:47.781 --> 00:40:52.186 align:middle line:90%,end
所有我给你们展示过的相机图
都是针孔相机的

00:40:52.853 --> 00:40:54.588 align:middle line:90%,end
针孔相机没有镜头

00:40:55.189 --> 00:40:57.524 align:middle line:90%,end
所以图像就是直线的

00:40:58.225 --> 00:41:02.462 align:middle line:90%,end
也就是说 光会以直线形式穿过小孔

00:40:58.225 --> 00:41:02.462 align:middle line:90%,end
也就是说 光会以直线形式穿过小孔

00:41:02.896 --> 00:41:06.500 align:middle line:90%,end
并且呈现一个几何完美的

00:41:06.567 --> 00:41:09.903 align:middle line:90%,end
复制倒置物体在像平面上

00:41:10.671 --> 00:41:13.340 align:middle line:90%,end
如果你有这样一个完美的正方形网格

00:41:13.407 --> 00:41:16.109 align:middle line:90%,end
并且用针孔相机给它拍了张照片的话

00:41:16.176 --> 00:41:18.946 align:middle line:90%,end
它在像平面上看起来就是这样的
不过是上下颠倒的

00:41:19.479 --> 00:41:22.216 align:middle line:90%,end
直线会一直保持直的

00:41:23.884 --> 00:41:26.687 align:middle line:90%,end
不幸的是 在现实世界中
我们需要让更多的光线进入

00:41:26.753 --> 00:41:30.090 align:middle line:90%,end
所以我们需要镜头
而镜头是有径向失真的

00:41:30.824 --> 00:41:33.627 align:middle line:90%,end
这些失真也会存在于所拍摄的图像中

00:41:33.694 --> 00:41:35.762 align:middle line:90%,end
因为它们会以

00:41:35.963 --> 00:41:40.100 align:middle line:90%,end
有点奇怪的方式弯曲
这样它们才能到达图像传感器

00:41:40.400 --> 00:41:41.902 align:middle line:90%,end
在一种极端情况下

00:41:41.969 --> 00:41:45.205 align:middle line:90%,end
由一个坏镜头所捕获的直线
可能看起来是这样的

00:41:45.739 --> 00:41:48.041 align:middle line:90%,end
这样不利于寻找视差

00:41:48.108 --> 00:41:51.144 align:middle line:90%,end
因为两个图像需要匹配得上
才能找到特征

00:41:51.512 --> 00:41:54.348 align:middle line:90%,end
如果相机一有一组失真

00:41:54.448 --> 00:41:56.817 align:middle line:90%,end
而相机二有一组不同的失真

00:41:56.884 --> 00:42:00.687 align:middle line:90%,end
你要如何才能
在这两个图像找到相同的特征

00:41:56.884 --> 00:42:00.687 align:middle line:90%,end
你要如何才能
在这两个图像找到相同的特征

00:42:00.754 --> 00:42:02.356 align:middle line:90%,end
因为它们失真的地方不一样呢？

00:42:04.625 --> 00:42:08.662 align:middle line:90%,end
我在描述如何计算视差的时候
落下了一个重要的步骤

00:42:09.062 --> 00:42:10.564 align:middle line:90%,end
我现在就把它补充一下

00:42:10.964 --> 00:42:13.967 align:middle line:90%,end
在比较长焦和广角图像之前

00:42:14.034 --> 00:42:15.335 align:middle line:90%,end
我们还需要做一件事

00:42:15.969 --> 00:42:19.239 align:middle line:90%,end
我们要让这些失真的图像直线化

00:42:19.573 --> 00:42:24.144 align:middle line:90%,end
也就是说 我们要利用一组校准系数
来使它们不再失真

00:42:24.411 --> 00:42:27.447 align:middle line:90%,end
这些系数代表了镜头的失真标准

00:42:28.549 --> 00:42:30.083 align:middle line:90%,end
在每个图像都被修正后

00:42:30.551 --> 00:42:32.219 align:middle line:90%,end
看起来就是这样的
令人满意的

00:42:32.519 --> 00:42:33.654 align:middle line:90%,end
笔直的直线

00:42:34.421 --> 00:42:37.324 align:middle line:90%,end
我们现在就可以确定地
比较两个图像中的点了

00:42:37.391 --> 00:42:42.763 align:middle line:90%,end
并且能够找到一个完美的 现实世界的
直线的视差图

00:42:43.197 --> 00:42:44.431 align:middle line:90%,end
看起来就像是这样

00:42:45.666 --> 00:42:47.201 align:middle line:90%,end
我们有了一个完全相反的问题

00:42:47.668 --> 00:42:50.037 align:middle line:90%,end
视差图匹配了物理世界

00:42:50.537 --> 00:42:52.973 align:middle line:90%,end
但是它跟我们刚刚拍摄的图像并不匹配

00:42:53.040 --> 00:42:55.142 align:middle line:90%,end
也就是由于镜头而变得失真的图像

00:42:55.475 --> 00:42:57.244 align:middle line:90%,end
所以现在我们要完成另外一个步骤

00:42:57.444 --> 00:43:02.349 align:middle line:90%,end
就是要将视差图通过失真
重新变回图像原有的样子

00:42:57.444 --> 00:43:02.349 align:middle line:90%,end
就是要将视差图通过失真
重新变回图像原有的样子

00:43:02.416 --> 00:43:06.720 align:middle line:90%,end
我们要使用一组
逆透镜系数来实现这一点

00:43:07.020 --> 00:43:10.624 align:middle line:90%,end
这样最终的视差图
就会有相同的几何失真了

00:43:10.691 --> 00:43:12.192 align:middle line:90%,end
跟它对应的图像一样

00:43:13.293 --> 00:43:15.596 align:middle line:90%,end
要我说的话 这是个好事
让我来解释下为什么

00:43:16.129 --> 00:43:17.764 align:middle line:90%,end
这就意味着我们有了开箱即用的

00:43:18.065 --> 00:43:23.604 align:middle line:90%,end
深度图
它的图片 特别适合使用滤镜

00:43:23.670 --> 00:43:24.571 align:middle line:90%,end
和进行特效处理

00:43:24.638 --> 00:43:27.341 align:middle line:90%,end
它们总是与相关的图像匹配

00:43:27.774 --> 00:43:29.443 align:middle line:90%,end
如果你想要实现某种特效

00:43:29.510 --> 00:43:33.213 align:middle line:90%,end
如果你想实现一些
像是Wiggle Me应用那样的效果

00:43:33.280 --> 00:43:36.950 align:middle line:90%,end
或是想让照片实现一些有趣的效果

00:43:37.017 --> 00:43:38.719 align:middle line:90%,end
就像是我最开始时所展示的那样

00:43:38.986 --> 00:43:40.254 align:middle line:90%,end
它们就能完美实现这一点

00:43:40.654 --> 00:43:43.924 align:middle line:90%,end
但它们不适用于重建3D场景

00:43:44.424 --> 00:43:47.194 align:middle line:90%,end
如果你想实现该功能
你应该把它们直线化

00:43:47.995 --> 00:43:48.862 align:middle line:90%,end
你是可以做到的

00:43:48.929 --> 00:43:50.330 align:middle line:90%,end
我马上就会介绍一下

00:43:52.032 --> 00:43:53.667 align:middle line:90%,end
我想要简单地介绍一下

00:43:53.734 --> 00:43:57.938 align:middle line:90%,end
我们图像文件中
深度数据的物理结构

00:43:58.572 --> 00:44:02.509 align:middle line:90%,end
在iOS 11中 我们支持两种
带有深度的图像

00:43:58.572 --> 00:44:02.509 align:middle line:90%,end
在iOS 11中 我们支持两种
带有深度的图像

00:44:02.609 --> 00:44:05.746 align:middle line:90%,end
第一种是HEIF HEVC
这个新格式

00:44:06.146 --> 00:44:08.215 align:middle line:90%,end
也叫作HEIC文件

00:44:08.815 --> 00:44:11.785 align:middle line:90%,end
而它有着对于深度最好的支持

00:44:12.352 --> 00:44:15.589 align:middle line:90%,end
在此文件中有一个区域
叫作辅助图像

00:44:15.656 --> 00:44:19.393 align:middle line:90%,end
它可以保存视差 深度
或是透明度图

00:44:19.860 --> 00:44:21.195 align:middle line:90%,end
我们会把它保存在这里

00:44:21.595 --> 00:44:24.798 align:middle line:90%,end
我们将其编码为单色HEVC

00:44:25.465 --> 00:44:30.470 align:middle line:90%,end
我们还保存了一些
对于深度很重要的元数据

00:44:30.537 --> 00:44:34.508 align:middle line:90%,end
例如关于它是否被过滤的信息

00:44:34.741 --> 00:44:36.476 align:middle line:90%,end
它的精度

00:44:37.211 --> 00:44:39.947 align:middle line:90%,end
诸如镜头失真这样的相机校准信息

00:44:40.214 --> 00:44:42.282 align:middle line:90%,end
以及一些渲染指令

00:44:42.549 --> 00:44:47.154 align:middle line:90%,end
所有这些元数据
都跟辅助图像一起都被编码成XMP

00:44:48.622 --> 00:44:50.591 align:middle line:90%,end
我们支持的第二种格式是JPEG

00:44:51.391 --> 00:44:55.495 align:middle line:90%,end
虽然JPEG不是个很好的方法
但我们还是支持它了

00:44:56.096 --> 00:45:00.200 align:middle line:90%,end
如果是过滤的深度图
那么它就是8位的有损JPEG

00:44:56.096 --> 00:45:00.200 align:middle line:90%,end
如果是过滤的深度图
那么它就是8位的有损JPEG

00:45:00.300 --> 00:45:02.202 align:middle line:90%,end
而如果它里面包含了非数字

00:45:02.369 --> 00:45:07.975 align:middle line:90%,end
我们就使用16位的无损JPEG编码
来保存所有的非数字

00:45:08.041 --> 00:45:11.478 align:middle line:90%,end
我们会将它作为第二个图像
保存到JPEG的底部

00:45:11.545 --> 00:45:14.314 align:middle line:90%,end
它就像是一个多画面对象
如果你熟悉这个概念的话

00:45:15.048 --> 00:45:20.387 align:middle line:90%,end
我们同样将元数据保存为XMP
就像我们处理HEIF HEVC那样

00:45:23.423 --> 00:45:27.194 align:middle line:90%,end
好了 现在让我介绍下
双摄像头系统中呼声最高的开发者功能

00:45:27.261 --> 00:45:29.029 align:middle line:90%,end
它就是双照片拍摄

00:45:30.631 --> 00:45:31.732 align:middle line:90%,end
这是什么意思呢

00:45:32.132 --> 00:45:35.702 align:middle line:90%,end
到目前为止
当你使用双摄像头拍照的时候

00:45:35.769 --> 00:45:37.237 align:middle line:90%,end
你还是只能得到一张照片

00:45:37.304 --> 00:45:39.506 align:middle line:90%,end
它或者是用广角拍摄的
或者是用长焦拍摄的

00:45:39.573 --> 00:45:40.974 align:middle line:90%,end
取决于你缩放的倍数

00:45:41.041 --> 00:45:45.612 align:middle line:90%,end
你是处于1和2X之间的区域
你就会得到两者

00:45:45.679 --> 00:45:48.615 align:middle line:90%,end
的混合
我们会将其混合成一张更好的照片

00:45:48.682 --> 00:45:49.917 align:middle line:90%,end
但你还是只能获得一张照片

00:45:50.517 --> 00:45:54.588 align:middle line:90%,end
你们一直想要两张照片
现在我们就给你们这个功能

00:45:54.721 --> 00:45:58.392 align:middle line:90%,end
通过一个单一请求
你就可以获得广角和长焦的

00:45:58.458 --> 00:46:00.894 align:middle line:90%,end
全幅1200万像素照片

00:45:58.458 --> 00:46:00.894 align:middle line:90%,end
全幅1200万像素照片

00:46:01.094 --> 00:46:02.896 align:middle line:90%,end
你能随心所欲
通过它们实现想要的功能

00:46:08.769 --> 00:46:09.670 align:middle line:90%,end
让我说下它是如何实现的

00:46:09.736 --> 00:46:11.572 align:middle line:90%,end
它和前面讲过的
对于深度的操作十分相似

00:46:12.439 --> 00:46:14.141 align:middle line:90%,end
在开始拍摄会话之前

00:46:14.208 --> 00:46:16.710 align:middle line:90%,end
你需要告诉photoOutput

00:46:17.244 --> 00:46:20.347 align:middle line:90%,end
我需要拍摄双照片
这样就能开启这个功能了

00:46:21.248 --> 00:46:25.552 align:middle line:90%,end
然后当你在拍摄基于
每张照片请求的照片时

00:46:25.619 --> 00:46:27.621 align:middle line:90%,end
你就可以完成你的设定了
比如说

00:46:28.088 --> 00:46:32.626 align:middle line:90%,end
我想将特定的照片拍成是双照片
给我广角和长焦的两张照片

00:46:34.595 --> 00:46:38.599 align:middle line:90%,end
当你这么做的时候
你所获得的照片回调函数的数量会翻倍

00:46:38.899 --> 00:46:40.634 align:middle line:90%,end
这并不是说你会得到两个回调函数

00:46:40.901 --> 00:46:45.739 align:middle line:90%,end
假如说你请求的是RAW
和HEIF的双照片

00:46:45.806 --> 00:46:48.809 align:middle line:90%,end
那么你就会得到四个回调函数
因为你会得到

00:46:48.876 --> 00:46:52.412 align:middle line:90%,end
两张广角和两张长焦的
RAW和HEIF照片

00:46:53.013 --> 00:46:55.182 align:middle line:90%,end
所以不管你之前得到多少个回调函数

00:46:55.249 --> 00:46:56.917 align:middle line:90%,end
现在数量会翻倍

00:46:58.952 --> 00:47:03.891 align:middle line:90%,end
现在我们支持了所有与深度相关的功能

00:46:58.952 --> 00:47:03.891 align:middle line:90%,end
现在我们支持了所有与深度相关的功能

00:47:03.957 --> 00:47:06.693 align:middle line:90%,end
你可以使用闪光灯来拍摄双照片

00:47:06.793 --> 00:47:13.100 align:middle line:90%,end
自动SIS 包围曝光
你还可以根据需要选择深度

00:47:15.269 --> 00:47:16.870 align:middle line:90%,end
我们是如何处理变焦的呢？

00:47:17.070 --> 00:47:21.341 align:middle line:90%,end
这里会出现安全性和信任的问题

00:47:21.742 --> 00:47:25.712 align:middle line:90%,end
假如说你的应用只显示长焦的视野

00:47:26.380 --> 00:47:29.116 align:middle line:90%,end
广角摄像头有更多的信息

00:47:29.183 --> 00:47:30.284 align:middle line:90%,end
所以在你拍照的时候

00:47:30.384 --> 00:47:34.087 align:middle line:90%,end
你实际上会拍到可视区域之外的内容

00:47:34.154 --> 00:47:35.889 align:middle line:90%,end
这就会产生隐私的问题

00:47:36.156 --> 00:47:37.758 align:middle line:90%,end
所以在你变焦的时候

00:47:38.058 --> 00:47:42.129 align:middle line:90%,end
我们会提供双照片
但是外围会变黑

00:47:42.429 --> 00:47:45.332 align:middle line:90%,end
这样它们就与预览中
所看到的视野一致了

00:47:45.766 --> 00:47:47.334 align:middle line:90%,end
如果你想要完整的图片

00:47:47.401 --> 00:47:49.670 align:middle line:90%,end
你可以将变焦设置成1倍

00:47:50.504 --> 00:47:53.774 align:middle line:90%,end
你怎么知道外面是否有变黑的区域呢？

00:47:54.174 --> 00:47:57.411 align:middle line:90%,end
在图片中我们保存了
一个纯净的孔径矩形

00:47:57.477 --> 00:47:59.880 align:middle line:90%,end
该矩形定义了有效像素的区域

00:48:02.115 --> 00:48:05.686 align:middle line:90%,end
双照片也可以通过相机校准数据送达

00:48:06.520 --> 00:48:09.656 align:middle line:90%,end
相机校准数据

00:48:09.723 --> 00:48:14.761 align:middle line:90%,end
可以用来实现
增强现实 虚拟现实

00:48:15.095 --> 00:48:17.097 align:middle line:90%,end
镜头失真修正等等

00:48:17.664 --> 00:48:23.136 align:middle line:90%,end
有了广角镜头 长焦镜头
和相机校准数据

00:48:23.570 --> 00:48:25.405 align:middle line:90%,end
你就可以制作自己的深度图了

00:48:25.806 --> 00:48:28.375 align:middle line:90%,end
我希望你们可以做出一个
比Apple更棒的深度图

00:48:29.576 --> 00:48:32.746 align:middle line:90%,end
你还可以实现增强现实
因为你获得了内在功能

00:48:33.013 --> 00:48:36.650 align:middle line:90%,end
让我来介绍下
相机校准当中的属性吧

00:48:36.717 --> 00:48:38.952 align:middle line:90%,end
这是我今晚要介绍的最后一个东西了

00:48:39.887 --> 00:48:45.292 align:middle line:90%,end
AVCameraCalibrationData
是我们相机校准的模型类

00:48:46.126 --> 00:48:47.094 align:middle line:90%,end
它在哪里出现呢？

00:48:47.160 --> 00:48:50.697 align:middle line:90%,end
如果你请求深度数据的话
你就可以同时得到AVDepthData

00:48:50.797 --> 00:48:52.332 align:middle line:90%,end
它是深度的一个属性

00:48:53.367 --> 00:48:57.504 align:middle line:90%,end
你也可以通过AVCapturePhoto
来获得它

00:48:58.172 --> 00:49:02.042 align:middle line:90%,end
你可以说我想对照片进行相机校准

00:48:58.172 --> 00:49:02.042 align:middle line:90%,end
你可以说我想对照片进行相机校准

00:49:02.376 --> 00:49:03.577 align:middle line:90%,end
就可以使用这个属性了

00:49:03.644 --> 00:49:05.946 align:middle line:90%,end
如果你要进行双照片拍摄
你就可以请求双照片

00:49:06.013 --> 00:49:10.250 align:middle line:90%,end
并且请求相机校准
这样你就可以获得两个照片的回调函数

00:49:10.384 --> 00:49:12.085 align:middle line:90%,end
并且你会获得广角效果的校准

00:49:12.186 --> 00:49:14.655 align:middle line:90%,end
以及长焦效果的校准了

00:49:16.190 --> 00:49:18.025 align:middle line:90%,end
intrinsicMatrix
看起来是什么样的呢？

00:49:18.091 --> 00:49:19.726 align:middle line:90%,end
我希望它能有点相似性

00:49:19.793 --> 00:49:22.029 align:middle line:10%
因为它差不多等同于我们之前见过的

00:49:22.095 --> 00:49:24.097 align:middle line:10%
流式
VideoDataOutput的例子

00:49:24.698 --> 00:49:29.269 align:middle line:10%
它也是一个3x3矩阵 并且包含了
CameraCalibrationData

00:49:30.437 --> 00:49:34.842 align:middle line:10%
它被用来从3D空间

00:49:34.908 --> 00:49:38.011 align:middle line:10%
转换到2D空间
当你要扁平化一个图像的时候

00:49:38.078 --> 00:49:40.848 align:middle line:10%
你可以在想变回3D空间的时候
使用反转

00:49:42.349 --> 00:49:45.352 align:middle line:10%
它具有像素焦距

00:49:45.452 --> 00:49:48.689 align:middle line:90%,end
这又是两个不同的数字

00:49:48.755 --> 00:49:51.325 align:middle line:90%,end
不过因为我们的像素是正方形像素
所以它们的数字是一样的

00:49:53.026 --> 00:49:56.830 align:middle line:90%,end
它也有对应着光学中心的x和y坐标

00:49:58.465 --> 00:50:02.936 align:middle line:90%,end
像素值是按照参考帧的分辨率给定的

00:49:58.465 --> 00:50:02.936 align:middle line:90%,end
像素值是按照参考帧的分辨率给定的

00:50:04.004 --> 00:50:06.406 align:middle line:90%,end
深度数据可能有很低的分辨率

00:50:06.473 --> 00:50:08.642 align:middle line:90%,end
我们不想把这么低分辨率的像素值
给你们

00:50:08.709 --> 00:50:12.112 align:middle line:90%,end
因此我们提供了一个独立的空间集

00:50:12.279 --> 00:50:14.448 align:middle line:90%,end
它们通常是传感器的完整大小

00:50:14.515 --> 00:50:16.783 align:middle line:90%,end
因此你可以获得很高的精度

00:50:16.850 --> 00:50:20.020 align:middle line:90%,end
以及很高的分辨率
在intrinsicMatrix中

00:50:21.822 --> 00:50:24.191 align:middle line:90%,end
接下来是extrinsicMatrix

00:50:24.725 --> 00:50:28.395 align:middle line:90%,end
这个属性描述的是
现实世界中相机拍摄时的姿态

00:50:29.463 --> 00:50:33.066 align:middle line:90%,end
你会在下面的情景要到这个属性
就是你要用从立体矫正相机得到的图像

00:50:33.133 --> 00:50:36.470 align:middle line:90%,end
进行三角测量的时候
需要将其与另一个图像进行比较

00:50:37.004 --> 00:50:41.875 align:middle line:90%,end
我们的外在功能
一个单一的矩阵

00:50:41.942 --> 00:50:44.678 align:middle line:90%,end
不过有点像是把两个矩阵压到了一起

00:50:45.345 --> 00:50:48.749 align:middle line:90%,end
首先左边的那个是旋转矩阵

00:50:49.082 --> 00:50:53.320 align:middle line:90%,end
它是个3x3的矩阵
用来描述相机如何旋转

00:50:53.387 --> 00:50:55.656 align:middle line:90%,end
根据现实世界的初始状态

00:50:55.722 --> 00:50:56.957 align:middle line:90%,end
不管原来到底是什么样的

00:50:57.291 --> 00:51:01.828 align:middle line:90%,end
另外还有一个1x3的矩阵
它用来描述相机的翻转

00:50:57.291 --> 00:51:01.828 align:middle line:90%,end
另外还有一个1x3的矩阵
它用来描述相机的翻转

00:51:01.895 --> 00:51:04.698 align:middle line:90%,end
或者说相对于现实世界初始状态的距离

00:51:05.732 --> 00:51:10.771 align:middle line:90%,end
需要注意的是
长焦镜头就是现实世界的初始状态

00:51:10.838 --> 00:51:13.473 align:middle line:90%,end
当你使用双摄像头时候很容易就能实现

00:51:13.540 --> 00:51:15.175 align:middle line:90%,end
如果你只想要一个长焦图像

00:51:15.943 --> 00:51:19.413 align:middle line:90%,end
那么你会得到一个单位矩阵

00:51:19.947 --> 00:51:22.182 align:middle line:90%,end
如果你要使用广角和长焦的话

00:51:22.482 --> 00:51:25.252 align:middle line:90%,end
广角就不会是单位矩阵

00:51:25.319 --> 00:51:31.558 align:middle line:90%,end
因为它描述了
其与长焦镜头的姿态和距离

00:51:31.725 --> 00:51:33.560 align:middle line:90%,end
但是通过使用外在功能 你就可以

00:51:33.627 --> 00:51:36.096 align:middle line:90%,end
计算广角和长焦之间的基线

00:51:38.465 --> 00:51:40.000 align:middle line:90%,end
还有其他一些属性是用来处理

00:51:40.067 --> 00:51:43.337 align:middle line:90%,end
我们前面介绍过的
镜头的几何失真的

00:51:43.770 --> 00:51:45.539 align:middle line:90%,end
它们适用于你需要

00:51:45.606 --> 00:51:48.809 align:middle line:90%,end
处理一个图像或是
将深度图直线化的情景

00:51:50.677 --> 00:51:52.813 align:middle line:90%,end
有两个你需要注意的属性

00:51:52.880 --> 00:51:55.782 align:middle line:90%,end
第一个是
lensDistortionCenter

00:51:56.650 --> 00:51:58.785 align:middle line:90%,end
它描述了传感器上

00:51:58.852 --> 00:52:02.823 align:middle line:90%,end
与镜头失真中心重合的点

00:51:58.852 --> 00:52:02.823 align:middle line:90%,end
与镜头失真中心重合的点

00:52:03.190 --> 00:52:07.060 align:middle line:90%,end
这通常与镜头的光学中心并不相同

00:52:07.127 --> 00:52:09.496 align:middle line:90%,end
如果你把所有的失真

00:52:09.563 --> 00:52:12.599 align:middle line:90%,end
镜头上的径向失真
看成是树的年轮的话

00:52:12.666 --> 00:52:15.269 align:middle line:90%,end
那么它就是年轮的中心

00:52:16.236 --> 00:52:18.572 align:middle line:90%,end
除了这个失真中心

00:52:18.906 --> 00:52:21.742 align:middle line:10%
我们还有一个叫
lensDistortionLookupTable的属性

00:52:22.176 --> 00:52:26.680 align:middle line:10%
你可以把它想成是多个浮点

00:52:27.214 --> 00:52:30.951 align:middle line:10%
这些浮点会将lensDistortionCenter
连接到最长的半径

00:52:31.185 --> 00:52:34.087 align:middle line:10%
如果你从这些浮点上画一些小的圆圈

00:52:34.321 --> 00:52:36.123 align:middle line:10%
你就可以得到一些
像是年轮的图案

00:52:36.190 --> 00:52:38.458 align:middle line:10%
它会给你展现镜头的径向失真

00:52:39.226 --> 00:52:43.964 align:middle line:10%
lensDistortionLookupTable
是一个包含在数据中的C浮点数组

00:52:45.232 --> 00:52:49.069 align:middle line:10%
如果沿着这些虚线的每个点都是0的话

00:52:49.136 --> 00:52:52.039 align:middle line:10%
你就会得到世界上独一无二的
完美的镜头

00:52:52.172 --> 00:52:54.308 align:middle line:10%
它根本没有径向失真

00:52:54.942 --> 00:52:56.810 align:middle line:90%,end
如果这里是一个正值

00:52:56.910 --> 00:52:59.947 align:middle line:90%,end
就表明半径有延长的地方

00:53:00.514 --> 00:53:04.017 align:middle line:90%,end
如果是负值
就表明半径有收缩的地方

00:53:04.351 --> 00:53:06.854 align:middle line:90%,end
但是如果总体来看整个表格

00:53:06.920 --> 00:53:11.258 align:middle line:90%,end
你就可以发现镜头的颠簸情况

00:53:12.993 --> 00:53:15.262 align:middle line:90%,end
要将失真修正应用到一个图像中

00:53:15.329 --> 00:53:17.931 align:middle line:90%,end
首先你要建立一个空的目标缓冲区

00:53:18.098 --> 00:53:20.300 align:middle line:90%,end
然后对它进行逐行遍历

00:53:20.367 --> 00:53:24.037 align:middle line:90%,end
对于每个点 你都要用
lensDistortionLookupTable

00:53:24.238 --> 00:53:27.174 align:middle line:90%,end
在在失真图像中查找对应的值

00:53:27.474 --> 00:53:30.811 align:middle line:90%,end
将该值写入到输出缓冲区中
的正确位置上

00:53:31.545 --> 00:53:33.847 align:middle line:90%,end
这部分代码很难写

00:53:33.981 --> 00:53:34.848 align:middle line:90%,end
我们也知道

00:53:34.915 --> 00:53:38.151 align:middle line:90%,end
所以我们提供一个参考实现方法

00:53:38.519 --> 00:53:43.223 align:middle line:90%,end
你们可以在
AVCameraCalibrationData.h中找到

00:53:43.557 --> 00:53:45.359 align:middle line:90%,end
我们把代码放到了一个头文件中

00:53:45.893 --> 00:53:48.362 align:middle line:90%,end
它被全部注释掉了
它是一个很大的objective C函数

00:53:49.162 --> 00:53:50.197 align:middle line:90%,end
请你们去看一下

00:53:50.264 --> 00:53:55.636 align:middle line:90%,end
它描述了如何纠正一个图像
或是如何反扭曲一个图像

00:53:55.802 --> 00:53:57.871 align:middle line:90%,end
取决于你传给它的表格是什么

00:53:59.673 --> 00:54:02.943 align:middle line:90%,end
如你所想 此表格的逆实现

00:53:59.673 --> 00:54:02.943 align:middle line:90%,end
如你所想 此表格的逆实现

00:54:03.043 --> 00:54:08.815 align:middle line:90%,end
描述的就是如何从扭曲的图像变回
非扭曲的

00:54:11.084 --> 00:54:13.787 align:middle line:90%,end
用一个演示来给你们解释会容易得多
让我们做个演示吧

00:54:18.725 --> 00:54:22.229 align:middle line:90%,end
这是我们今天的第四个
也是最后一个示例应用

00:54:22.963 --> 00:54:24.331 align:middle line:90%,end
它叫作Straighten Up

00:54:25.065 --> 00:54:26.800 align:middle line:90%,end
我打赌你们能猜出来
它是干什么用的

00:54:28.635 --> 00:54:32.639 align:middle line:90%,end
这个应用使用了
AVCameraCalibrationData

00:54:32.940 --> 00:54:35.742 align:middle line:90%,end
特别是镜头失真特征描述

00:54:35.843 --> 00:54:37.978 align:middle line:90%,end
来让图像直线化

00:54:39.646 --> 00:54:43.650 align:middle line:90%,end
我今天早上在外面的时候
拍了一些双镜头照片

00:54:44.051 --> 00:54:46.920 align:middle line:90%,end
你们应该可以看出来这些是双照片
而且我是放大了两倍

00:54:46.987 --> 00:54:49.523 align:middle line:90%,end
因为它们周围有黑边

00:54:49.923 --> 00:54:53.193 align:middle line:90%,end
这张当然是用长焦镜头拍的

00:54:54.461 --> 00:54:56.363 align:middle line:90%,end
而这张是失真的照片

00:54:57.431 --> 00:54:59.700 align:middle line:90%,end
现在当我点击
Undistort按钮的时候

00:55:00.067 --> 00:55:03.237 align:middle line:90%,end
你就会发现一些细微的变化

00:55:06.907 --> 00:55:08.842 align:middle line:90%,end
你绝对是可以发现的
不过这些变化真的很小

00:55:09.343 --> 00:55:13.146 align:middle line:90%,end
通常长焦镜头具有更小的曲率

00:55:13.213 --> 00:55:19.353 align:middle line:90%,end
这样它们就在边缘上
具有比广角镜头更小的径向失真

00:55:19.520 --> 00:55:22.322 align:middle line:90%,end
我会放大一点
这样你们就能看出差别了

00:55:22.656 --> 00:55:25.359 align:middle line:90%,end
这是直线的
直线是直的

00:55:26.093 --> 00:55:27.461 align:middle line:90%,end
而这条是扭曲的

00:55:27.995 --> 00:55:30.531 align:middle line:90%,end
现在如果我看下广角的照片

00:55:32.799 --> 00:55:34.835 align:middle line:90%,end
虽然我们没有角落的信息

00:55:37.004 --> 00:55:40.107 align:middle line:90%,end
但是你们还是可以看到
在我们已有的图像数据中

00:55:40.274 --> 00:55:42.376 align:middle line:90%,end
失真还是要更明显些

00:55:43.944 --> 00:55:46.547 align:middle line:90%,end
按distorted
按undistorted

00:55:46.780 --> 00:55:48.348 align:middle line:90%,end
按distorted
按undistorted

00:55:48.415 --> 00:55:51.818 align:middle line:90%,end
你绝对可以发现 在边缘附近
图像被向内拉伸得更多

00:55:54.621 --> 00:55:55.622 align:middle line:90%,end
按undistorted

00:55:55.689 --> 00:55:57.090 align:middle line:90%,end
按distorted
按undistorted

00:55:59.092 --> 00:56:00.661 align:middle line:90%,end
好了
回到幻灯片中

00:55:59.092 --> 00:56:00.661 align:middle line:90%,end
好了
回到幻灯片中

00:56:05.999 --> 00:56:07.534 align:middle line:90%,end
（总结）

00:56:07.601 --> 00:56:08.635 align:middle line:90%,end
我们该总结一下了

00:56:09.870 --> 00:56:14.775 align:middle line:90%,end
iPhone 7 Plus的双摄像头
不是渡越时间的相机系统

00:56:14.842 --> 00:56:15.742 align:middle line:90%,end
它是一个？

00:56:16.410 --> 00:56:18.245 align:middle line:90%,end
视差 视差系统

00:56:18.312 --> 00:56:20.414 align:middle line:90%,end
如果你今天只记住一点

00:56:20.480 --> 00:56:23.183 align:middle line:90%,end
那么我希望你们能记住
视差和深度有什么不同之处

00:56:24.685 --> 00:56:29.289 align:middle line:90%,end
另外 我们平台上对于深度的规范表示
应该是AVDepthData

00:56:30.858 --> 00:56:35.395 align:middle line:90%,end
我们还介绍了内在功能 外在功能
镜头失真

00:56:35.462 --> 00:56:38.732 align:middle line:90%,end
这些都是
AVCameraCalibrationData的属性

00:56:40.367 --> 00:56:43.170 align:middle line:90%,end
我们介绍了
AVCaptureDepthDataOutput

00:56:43.237 --> 00:56:47.641 align:middle line:90%,end
它所提供的流式深度
是你可以自己选择是否进行过滤的

00:56:49.576 --> 00:56:54.481 align:middle line:90%,end
我们还介绍了如何使用
AVCapturePhotoOutput来拍照

00:56:54.848 --> 00:56:57.084 align:middle line:90%,end
并且让这些照片带有深度信息

00:56:59.152 --> 00:57:02.189 align:middle line:90%,end
最后我们花了点时间介绍双摄像头

00:56:59.152 --> 00:57:02.189 align:middle line:90%,end
最后我们花了点时间介绍双摄像头

00:57:02.256 --> 00:57:03.757 align:middle line:90%,end
双照片送达

00:57:04.057 --> 00:57:07.060 align:middle line:90%,end
双照片会给单张照片生成广角
和长焦照片

00:57:07.127 --> 00:57:10.797 align:middle line:90%,end
这样就能实现有趣的计算机视觉任务了
我希望你们可以去试试

00:57:12.633 --> 00:57:15.102 align:middle line:90%,end
我们有三个示例代码
现在就已经可供查阅了

00:57:15.169 --> 00:57:19.640 align:middle line:90%,end
它们都跟本次演讲相关联了
分别是AVCam PhotoFilter和Wiggle Me

00:57:21.808 --> 00:57:24.811 align:middle line:90%,end
有关它们的更多信息
请参见这个网址的链接

00:57:26.346 --> 00:57:29.249 align:middle line:90%,end
请再稍等一会儿

00:57:29.850 --> 00:57:33.353 align:middle line:90%,end
紧接着这个演讲的
是一个非正式的开发者聚会

00:57:33.420 --> 00:57:36.590 align:middle line:90%,end
与会者都是对摄影感兴趣的开发者

00:57:37.024 --> 00:57:38.091 align:middle line:90%,end
你们都是其中一员啊

00:57:39.126 --> 00:57:44.198 align:middle line:90%,end
那你们可以来跟Apple
多媒体技术组的成员聊聊天

00:57:45.432 --> 00:57:49.937 align:middle line:90%,end
你可以问些问题
或者我们就是闲聊 社交一下

00:57:50.437 --> 00:57:53.907 align:middle line:90%,end
明天11点有一个本演讲的姊妹演讲

00:57:54.174 --> 00:57:56.777 align:middle line:90%,end
你可以学到如何读取并处理

00:57:56.877 --> 00:57:58.812 align:middle line:90%,end
图像文件中的深度数据

00:57:58.912 --> 00:58:00.581 align:middle line:90%,end
今天我们只是浅显地

00:57:58.912 --> 00:58:00.581 align:middle line:90%,end
今天我们只是浅显地

00:58:00.647 --> 00:58:03.650 align:middle line:90%,end
介绍了一下
你可以利用深度照片实现什么

00:58:04.051 --> 00:58:05.886 align:middle line:90%,end
明天会有很多的演示

00:58:05.953 --> 00:58:08.088 align:middle line:90%,end
我真的希望你们
明天可以抽出时间来听一下

00:58:08.288 --> 00:58:10.824 align:middle line:90%,end
如果你们能来的话
我深感荣幸

00:58:12.292 --> 00:58:15.963 align:middle line:90%,end
最后主讲一个关于

00:58:16.029 --> 00:58:18.899 align:middle line:90%,end
如何处理HEIF的演讲
这个演讲是在周五上午举行

00:58:18.966 --> 00:58:20.200 align:middle line:90%,end
我希望你们也能来

00:58:21.368 --> 00:58:26.373 align:middle line:90%,end
在那个演讲中 我会深入介绍一下
AVCapturePhoto接口

00:58:27.941 --> 00:58:29.843 align:middle line:90%,end
谢谢 希望你们享受大会剩余的演讲
