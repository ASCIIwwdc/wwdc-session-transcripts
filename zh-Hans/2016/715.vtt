WEBVTT

00:00:19.653 --> 00:00:22.055
<c.magenta>神经网络和加速</c>

00:00:23.624 --> 00:00:26.627
<c.magenta>下午好 欢迎来到“加速”演讲</c>

00:00:27.394 --> 00:00:29.363
<c.magenta>我是Eric Bainville...</c>

00:00:29.863 --> 00:00:32.698
<c.magenta>我是核心OS</c>
<c.magenta>向量和数值团队的一员</c>

00:00:34.735 --> 00:00:38.105
<c.magenta>我们组提供对CPU性能优化的库</c>

00:00:38.972 --> 00:00:42.409
<c.magenta>优化性能的库通常意味着</c>
<c.magenta>我们要与底层的东西打交道</c>

00:00:42.476 --> 00:00:46.380
<c.magenta>能提供大计算量的函数</c>
<c.magenta>比如 求矩阵积</c>

00:00:46.647 --> 00:00:48.482
<c.magenta>傅立叶变换 之类的</c>

00:00:49.516 --> 00:00:52.653
<c.magenta>大多数这些函数被包括在</c>
<c.magenta>Accelerate框架里</c>

00:00:52.819 --> 00:00:56.990
<c.magenta>我们有 像vImage</c>
<c.magenta>一个用于图像处理的库</c>

00:00:57.691 --> 00:00:59.893
<c.magenta>它能被用于类型转换</c>

00:00:59.960 --> 00:01:02.930
<c.magenta>也能用于对图像的几何变换</c>

00:00:59.960 --> 00:01:02.930
<c.magenta>也能用于对图像的几何变换</c>

00:01:04.298 --> 00:01:06.300
<c.magenta>挨着vImage</c>
<c.magenta>你们会看到vDSP</c>

00:01:06.366 --> 00:01:09.169
<c.magenta>它主要被用于信号处理</c>
<c.magenta>像傅立叶变换</c>

00:01:09.436 --> 00:01:11.605
<c.magenta>和其它信号处理的用途</c>

00:01:13.340 --> 00:01:18.979
<c.magenta>然后 我们有BLAS</c>
<c.magenta>一个用于线性代数的库</c>

00:01:19.179 --> 00:01:21.381
<c.magenta>它已经很老了</c>
<c.magenta>它创建于70年代</c>

00:01:21.648 --> 00:01:24.484
<c.magenta>几年前</c>
<c.magenta>我们添加了SparseBLAS</c>

00:01:24.551 --> 00:01:27.221
<c.magenta>用于向量和矩阵的稀疏计算</c>

00:01:27.521 --> 00:01:30.390
<c.magenta>我们也在LinearAlgebra里</c>
<c.magenta>提供了LAPACK</c>

00:01:30.457 --> 00:01:33.060
<c.magenta>一个用于线性代数的高级库</c>

00:01:34.127 --> 00:01:38.131
<c.magenta>在Accelerate之外</c>
<c.magenta>我们还有一些库</c>

00:01:38.465 --> 00:01:40.567
<c.magenta>比如simd 它包含了一组标头</c>

00:01:40.901 --> 00:01:45.305
<c.magenta>能让你们对向量指令和类型</c>
<c.magenta>直接进行读写</c>

00:01:45.372 --> 00:01:48.609
<c.magenta>但它们不会操控CPU的向量单元</c>

00:01:48.675 --> 00:01:53.280
<c.magenta>它们介于中层和外层</c>
<c.magenta>不会改写汇编代码</c>

00:01:54.248 --> 00:01:56.783
<c.magenta>我们还在去年添加了</c>
<c.magenta>compression</c>

00:01:56.850 --> 00:01:58.385
<c.magenta>用于无损压缩</c>

00:01:59.419 --> 00:02:03.557
<c.magenta>对所支持的CPU</c>
<c.magenta>我们为所提供的技术进行了优化</c>

00:01:59.419 --> 00:02:03.557
<c.magenta>对所支持的CPU</c>
<c.magenta>我们为所提供的技术进行了优化</c>

00:02:03.690 --> 00:02:06.293
<c.magenta>所以 当你们拿到新手机</c>
<c.magenta>我们为它的代码进行优化</c>

00:02:06.860 --> 00:02:08.294
<c.magenta>这样你们就不用为此担心了</c>

00:02:08.996 --> 00:02:10.264
<c.magenta>好 那今天...</c>

00:02:11.198 --> 00:02:13.834
<c.magenta>首先 我们来简单地回顾下</c>
<c.magenta>compression</c>

00:02:15.302 --> 00:02:18.639
<c.magenta>然后 我们将介绍两个</c>
<c.magenta>在Accelerate里新的库</c>

00:02:19.039 --> 00:02:23.777
<c.magenta>BNNS 它是一组用于神经网络</c>
<c.magenta>低级计算的函数</c>

00:02:25.612 --> 00:02:27.214
<c.magenta>还有Quadrature</c>

00:02:27.381 --> 00:02:31.752
<c.magenta>它是一个用于求</c>
<c.magenta>函数数值积分的小型的库</c>

00:02:32.019 --> 00:02:34.154
<c.magenta>之后 我的同事Steve会上台</c>

00:02:34.221 --> 00:02:36.657
<c.magenta>介绍simd的新添项</c>

00:02:37.658 --> 00:02:39.359
<c.magenta>好 首先 在我们开始之前</c>

00:02:39.493 --> 00:02:42.262
<c.magenta>让我向你们简单介绍下</c>
<c.magenta>Accelerate的使用</c>

00:02:42.896 --> 00:02:45.599
<c.magenta>基于你们对语言的选择</c>

00:02:45.766 --> 00:02:50.003
<c.magenta>你们要用import或</c>
<c.magenta>include导入函数的声明</c>

00:02:50.537 --> 00:02:53.941
<c.magenta>之后 你们要链接</c>
<c.magenta>Accelerate框架</c>

00:02:54.074 --> 00:02:57.644
<c.magenta>那从Xcode的你们的项目设置里</c>
<c.magenta>你们要浏览至</c>

00:02:57.744 --> 00:03:02.049
<c.magenta>target</c>
<c.magenta>然后点击build phases</c>

00:02:57.744 --> 00:03:02.049
<c.magenta>target</c>
<c.magenta>然后点击build phases</c>

00:03:02.816 --> 00:03:04.051
<c.magenta>出现一个窗口</c>

00:03:04.218 --> 00:03:06.753
<c.magenta>点击Link Binary With Libraries</c>

00:03:06.820 --> 00:03:07.821
<c.magenta>打开它</c>

00:03:08.655 --> 00:03:09.489
<c.magenta>好的</c>

00:03:09.756 --> 00:03:12.426
<c.magenta>点开这里有个小加号的地方</c>

00:03:13.427 --> 00:03:16.964
<c.magenta>你们会看到一个</c>
<c.magenta>所有能被链接的库和框架的列表</c>

00:03:17.030 --> 00:03:18.832
<c.magenta>Accelerate在第一个</c>

00:03:24.938 --> 00:03:27.441
<c.magenta>好的</c>

00:03:27.508 --> 00:03:30.444
<c.magenta>那如果它不在第一个</c>
<c.magenta>在上面有个搜索栏</c>

00:03:30.511 --> 00:03:32.779
<c.magenta>若要找compression</c>
<c.magenta>输入compression</c>

00:03:32.846 --> 00:03:34.114
<c.magenta>我知道compression</c>
<c.magenta>一定会在里面</c>

00:03:34.481 --> 00:03:36.683
<c.magenta>好的 现你们就在使用</c>
<c.magenta>Accelerate了</c>

00:03:36.750 --> 00:03:38.886
<c.magenta>好</c>

00:03:39.052 --> 00:03:40.220
<c.magenta>那compression...</c>

00:03:40.287 --> 00:03:43.090
<c.magenta>记得当去年Sebastian</c>

00:03:43.156 --> 00:03:46.493
<c.magenta>在平台详情咨文介绍LZFSE时</c>

00:03:46.560 --> 00:03:48.562
<c.magenta>我们都不知道他们是谁</c>

00:03:48.729 --> 00:03:53.400
<c.magenta>但今天我们要宣布对LZFSE开源</c>

00:03:53.867 --> 00:03:55.669
<c.magenta>你们可以在GitHub上找到它</c>

00:03:55.769 --> 00:03:58.305
<c.magenta>我们以BSD许可的形式发布它</c>

00:03:59.940 --> 00:04:03.277
<c.magenta>让我提一下 你们会想用它的理由</c>

00:03:59.940 --> 00:04:03.277
<c.magenta>让我提一下 你们会想用它的理由</c>

00:04:03.710 --> 00:04:06.947
<c.magenta>这些是平台比较</c>
<c.magenta>在LZFSE</c>

00:04:07.014 --> 00:04:09.616
<c.magenta>和zlib之间 使用相同的选项</c>

00:04:10.284 --> 00:04:14.621
<c.magenta>我们的编码速度要快1.4倍</c>
<c.magenta>解码速度要快2.6倍</c>

00:04:16.023 --> 00:04:17.891
<c.magenta>好的</c>
<c.magenta>这就是我们的compression</c>

00:04:18.257 --> 00:04:19.793
<c.magenta>现在让我们来看下BNNS</c>

00:04:20.194 --> 00:04:22.262
<c.magenta>“基础神经网络子程序”</c>

00:04:22.829 --> 00:04:24.598
<c.magenta>这个名字看起来很像BLAS</c>

00:04:24.665 --> 00:04:26.900
<c.magenta>BLAS是指“基础线性代数子程序”</c>

00:04:27.100 --> 00:04:29.903
<c.magenta>如我之前所提</c>
<c.magenta>它起源于70年代</c>

00:04:30.671 --> 00:04:35.943
<c.magenta>BNNS提供了一组低级计算例程</c>

00:04:36.109 --> 00:04:38.912
<c.magenta>我稍后细说</c>

00:04:40.581 --> 00:04:42.082
<c.magenta>我们只做低级计算</c>

00:04:42.149 --> 00:04:44.718
<c.magenta>像求矩阵积 但针对于神经网络</c>

00:04:45.986 --> 00:04:48.822
<c.magenta>在我细讲它的作用</c>

00:04:49.022 --> 00:04:50.257
<c.magenta>和相关的API之前</c>

00:04:50.324 --> 00:04:54.728
<c.magenta>让我们来回顾下神经网络</c>

00:04:55.395 --> 00:04:57.598
<c.magenta>假设我们有这样一个网络</c>

00:04:57.965 --> 00:05:00.701
<c.magenta>我们训练了它去识别动物</c>

00:04:57.965 --> 00:05:00.701
<c.magenta>我们训练了它去识别动物</c>

00:05:00.767 --> 00:05:02.536
<c.magenta>那作为输入 你们有一个图像</c>

00:05:02.603 --> 00:05:04.571
<c.magenta>然后 你们有这个橘色的大框</c>

00:05:04.805 --> 00:05:08.709
<c.magenta>在橘色的框里</c>
<c.magenta>这个红色的框代表了权值</c>

00:05:09.142 --> 00:05:11.545
<c.magenta>这些是这个网络的参数</c>

00:05:11.612 --> 00:05:14.448
<c.magenta>作为输出 我们有四个值</c>

00:05:14.615 --> 00:05:17.017
<c.magenta>这些是相应的概率</c>
<c.magenta>对于是一只猫 一只狗</c>

00:05:17.084 --> 00:05:18.685
<c.magenta>一只长颈鹿或一条蛇</c>

00:05:19.386 --> 00:05:21.255
<c.magenta>好的　那首先你们要训练它</c>

00:05:21.321 --> 00:05:22.823
<c.magenta>假设你们有个猫的图像</c>

00:05:23.657 --> 00:05:27.761
<c.magenta>你们通过网络处理这猫的图像</c>
<c.magenta>并得到一个答案</c>

00:05:28.428 --> 00:05:30.764
<c.magenta>这是最高的概率</c>
<c.magenta>它说是只狗</c>

00:05:31.465 --> 00:05:33.467
<c.magenta>呵呵 这就是你们需要训练它的原因</c>

00:05:33.800 --> 00:05:37.004
<c.magenta>事实上是只猫 那你们要做的是</c>

00:05:37.471 --> 00:05:39.473
<c.magenta>反向传播正确答案</c>

00:05:39.540 --> 00:05:41.842
<c.magenta>如果我稍许改动下权值 会怎么样</c>

00:05:42.543 --> 00:05:47.314
<c.magenta>那现在这个网络会稍偏向</c>
<c.magenta>猫的方向</c>

00:05:47.781 --> 00:05:53.587
<c.magenta>你们要使用大量的图像</c>
<c.magenta>做这个成千上万次</c>

00:05:53.820 --> 00:05:55.122
<c.magenta>在某一刻</c>

00:05:56.023 --> 00:05:59.159
<c.magenta>你们会有一个训练好的网络</c>
<c.magenta>能正确回答</c>

00:05:59.226 --> 00:06:00.961
<c.magenta>每一个请求</c>

00:05:59.226 --> 00:06:00.961
<c.magenta>每一个请求</c>

00:06:01.028 --> 00:06:03.463
<c.magenta>如果是只长颈鹿</c>

00:06:05.032 --> 00:06:07.334
<c.magenta>它会说是只长颈鹿</c>
<c.magenta>因为你们正确地训练了它</c>

00:06:08.735 --> 00:06:10.938
<c.magenta>好的　这就是神经网络所能做的</c>

00:06:11.004 --> 00:06:13.574
<c.magenta>注意训练和推测的区别</c>

00:06:13.640 --> 00:06:15.843
<c.magenta>在推测时 我们不改变权值</c>

00:06:16.076 --> 00:06:18.312
<c.magenta>那一般来说 假设你们有这样一个应用</c>

00:06:18.912 --> 00:06:21.748
<c.magenta>你们要在线下做这些训练</c>

00:06:21.949 --> 00:06:23.817
<c.magenta>当你们创建应用时</c>
<c.magenta>做你们的训练</c>

00:06:23.884 --> 00:06:26.253
<c.magenta>那当你们改动应用时</c>
<c.magenta>你们要改动权值</c>

00:06:26.320 --> 00:06:28.222
<c.magenta>和网络拓扑</c>

00:06:28.322 --> 00:06:31.592
<c.magenta>最后能让它在设备上进行推测</c>

00:06:32.526 --> 00:06:35.495
<c.magenta>好的</c>
<c.magenta>那在这个橘色的框里有些什么？</c>

00:06:35.562 --> 00:06:36.797
<c.magenta>让我给你们个例子</c>

00:06:36.864 --> 00:06:39.600
<c.magenta>若你们去了“Metal的新特性</c>
<c.magenta>第二部分”演讲</c>

00:06:39.933 --> 00:06:42.936
<c.magenta>一个昨天的讲座</c>
<c.magenta>你们已经见过了个更大型的例子</c>

00:06:43.270 --> 00:06:45.572
<c.magenta>一个场景识别网络</c>

00:06:45.672 --> 00:06:48.008
<c.magenta>和一个对笑脸识别网络的展示</c>

00:06:48.108 --> 00:06:51.011
<c.magenta>这都是些进阶的网络</c>
<c.magenta>它们有成百上千的层面</c>

00:06:51.178 --> 00:06:54.281
<c.magenta>这个是五年前最前沿的技术</c>

00:06:54.348 --> 00:06:58.986
<c.magenta>它描述了一个百数位识别网络</c>

00:06:59.620 --> 00:07:01.288
<c.magenta>那作为输入</c>
<c.magenta>你们有个小型的图像</c>

00:06:59.620 --> 00:07:01.288
<c.magenta>那作为输入</c>
<c.magenta>你们有个小型的图像</c>

00:07:01.455 --> 00:07:04.758
<c.magenta>一个对手写的捕捉</c>

00:07:05.225 --> 00:07:07.127
<c.magenta>然后它被递入各个层面</c>

00:07:07.461 --> 00:07:09.763
<c.magenta>这里你们有个5x5的卷积</c>

00:07:10.063 --> 00:07:12.566
<c.magenta>输出会是一个含五个图像的堆栈</c>

00:07:13.367 --> 00:07:16.703
<c.magenta>这个输出是五个有着不同权值的卷积</c>

00:07:17.104 --> 00:07:19.239
<c.magenta>然后 你们添加另一个层面</c>

00:07:19.773 --> 00:07:23.710
<c.magenta>你们对这五个图像应用更多的卷积</c>

00:07:23.777 --> 00:07:25.779
<c.magenta>你们会得到一个更大的堆栈</c>

00:07:26.146 --> 00:07:29.149
<c.magenta>包含五十个5x5像素的图像</c>

00:07:29.349 --> 00:07:33.854
<c.magenta>那这样 你们从图像空间</c>

00:07:33.921 --> 00:07:37.090
<c.magenta>一层层地来到了特征空间</c>

00:07:37.758 --> 00:07:41.028
<c.magenta>这些小型图像的内容变得</c>
<c.magenta>越来越抽象</c>

00:07:41.094 --> 00:07:43.096
<c.magenta>最后就只有特征</c>

00:07:43.197 --> 00:07:45.399
<c.magenta>那会告诉你们那是个零或那是个一</c>

00:07:45.465 --> 00:07:47.100
<c.magenta>这是你们想要的输出</c>

00:07:47.501 --> 00:07:48.335
<c.magenta>好的</c>

00:07:48.735 --> 00:07:51.104
<c.magenta>那通过使用少量的层面</c>

00:07:51.238 --> 00:07:54.174
<c.magenta>你们可以达到目的</c>
<c.magenta>并且效果还不错</c>

00:07:54.641 --> 00:07:59.079
<c.magenta>那在这些卷积之后</c>
<c.magenta>我们把这些5x5x50的值</c>

00:07:59.880 --> 00:08:01.949
<c.magenta>作为一个大型的向量</c>

00:07:59.880 --> 00:08:01.949
<c.magenta>作为一个大型的向量</c>

00:08:02.449 --> 00:08:05.085
<c.magenta>对其应用一个全面连接层面</c>

00:08:05.152 --> 00:08:07.054
<c.magenta>其实就是求个大型的矩阵积</c>

00:08:07.120 --> 00:08:11.658
<c.magenta>它会将所有值混合</c>
<c.magenta>然后输出一组100个值</c>

00:08:12.392 --> 00:08:15.362
<c.magenta>在这个模型里 被称为隐藏层面</c>

00:08:16.396 --> 00:08:21.635
<c.magenta>之后你们需要最后一步</c>
<c.magenta>使这100个值</c>

00:08:21.935 --> 00:08:24.771
<c.magenta>混合在一起</c>
<c.magenta>然后产生10个你们你们想要的输出</c>

00:08:24.905 --> 00:08:27.040
<c.magenta>这里 你们在计算未来空间</c>

00:08:27.474 --> 00:08:31.211
<c.magenta>这里的每个数值对应着</c>
<c.magenta>成为一个具体数字的概率</c>

00:08:31.945 --> 00:08:32.779
<c.magenta>好的</c>

00:08:32.846 --> 00:08:34.581
<c.magenta>这就是这个网络的结构</c>

00:08:34.648 --> 00:08:38.452
<c.magenta>如你们所见</c>
<c.magenta>我们有两个不同类别的层面</c>

00:08:38.519 --> 00:08:40.153
<c.magenta>这正是我们在BNNS所实现的</c>

00:08:40.220 --> 00:08:42.623
<c.magenta>我们提供对这些层面的计算部分</c>

00:08:44.258 --> 00:08:47.227
<c.magenta>好　在我们开始讨论计算</c>

00:08:47.294 --> 00:08:49.396
<c.magenta>和相关API之前</c>
<c.magenta>让我向你们展示些数字</c>

00:08:49.463 --> 00:08:52.533
<c.magenta>这里我们将用Caffe作对比</c>

00:08:52.933 --> 00:08:56.770
<c.magenta>它是一个知名的</c>
<c.magenta>神经网络计算程序包</c>

00:08:57.337 --> 00:08:59.473
<c.magenta>这是Caffe有关卷积的部分</c>

00:08:59.573 --> 00:09:02.042
<c.magenta>我们有14个不同卷积的大小</c>

00:08:59.573 --> 00:09:02.042
<c.magenta>我们有14个不同卷积的大小</c>

00:09:02.509 --> 00:09:03.810
<c.magenta>在这里 你们可以看下</c>

00:09:04.545 --> 00:09:08.649
<c.magenta>这是Caffe的处理时间...</c>

00:09:09.616 --> 00:09:11.652
<c.magenta>这是速度</c>
<c.magenta>所以值越高越好</c>

00:09:11.718 --> 00:09:13.720
<c.magenta>通过Caffe处理这些卷积</c>

00:09:13.987 --> 00:09:15.923
<c.magenta>这是你们用BNNS所得的结果</c>

00:09:16.790 --> 00:09:18.892
<c.magenta>从平均来看 BNNS要快2.1倍</c>

00:09:18.959 --> 00:09:21.028
<c.magenta>如果你们有更大的卷积</c>

00:09:21.094 --> 00:09:23.397
<c.magenta>你们可以几乎达到快4倍的速度</c>

00:09:25.365 --> 00:09:27.968
<c.magenta>好的　这就是所有的数字</c>

00:09:28.035 --> 00:09:31.038
<c.magenta>现在让我来介绍下BNNS的构架</c>

00:09:32.039 --> 00:09:34.074
<c.magenta>它是一个低级计算函数的集合</c>

00:09:34.141 --> 00:09:37.010
<c.magenta>与BLAS十分相似</c>
<c.magenta>这也是我们将其取名为BNNS的原因</c>

00:09:37.678 --> 00:09:41.048
<c.magenta>它并不知道</c>
<c.magenta>什么是神经网络</c>

00:09:41.248 --> 00:09:43.650
<c.magenta>这意味着</c>
<c.magenta>那是你们要知道的事</c>

00:09:43.784 --> 00:09:46.954
<c.magenta>它只提供计算的部分</c>

00:09:48.689 --> 00:09:51.058
<c.magenta>并且它只执行推测</c>

00:09:51.792 --> 00:09:52.793
<c.magenta>事实上</c>

00:09:52.860 --> 00:09:55.629
<c.magenta>我觉得 在设备上运行训练不合理</c>

00:09:55.696 --> 00:09:56.730
<c.magenta>成本太高</c>

00:09:56.797 --> 00:09:59.333
<c.magenta>你们会要有数以万计的图像和计算</c>

00:09:59.600 --> 00:10:00.701
<c.magenta>这不会合适</c>

00:09:59.600 --> 00:10:00.701
<c.magenta>这不会合适</c>

00:10:00.968 --> 00:10:04.104
<c.magenta>那一般来说 推测会在线下完成</c>
<c.magenta>如我所述</c>

00:10:04.404 --> 00:10:07.774
<c.magenta>你们会在应用上执行推测</c>

00:10:08.041 --> 00:10:10.143
<c.magenta>我们提供三个不同类别的层面</c>

00:10:10.377 --> 00:10:12.212
<c.magenta>卷积层 池化层</c>

00:10:12.279 --> 00:10:14.081
<c.magenta>和全面连接层</c>

00:10:14.348 --> 00:10:15.549
<c.magenta>为什么？ 因为...</c>

00:10:16.116 --> 00:10:20.554
<c.magenta>实际上 在现代的网络</c>
<c.magenta>你们会花费百分之七十五的时间</c>

00:10:20.621 --> 00:10:22.022
<c.magenta>于计算卷积</c>

00:10:22.389 --> 00:10:24.625
<c.magenta>接下来是池化层</c>

00:10:24.691 --> 00:10:26.627
<c.magenta>使用约百分之十五</c>

00:10:27.094 --> 00:10:29.496
<c.magenta>全面连接层也会花费许多时间</c>

00:10:29.563 --> 00:10:32.733
<c.magenta>但你们通常在网络的末端看见它</c>

00:10:33.233 --> 00:10:35.435
<c.magenta>像在例子里见到的 只有两个</c>

00:10:35.802 --> 00:10:37.838
<c.magenta>在末端的全面连接层</c>

00:10:38.205 --> 00:10:40.140
<c.magenta>但这还是要花费许多时间</c>

00:10:40.741 --> 00:10:44.278
<c.magenta>好的　现在我们了解了构架</c>

00:10:44.344 --> 00:10:47.281
<c.magenta>我将细讲这三个不同类别的层面</c>

00:10:47.447 --> 00:10:51.585
<c.magenta>和我们计算些什么</c>
<c.magenta>还有如何通过API来创建它们</c>

00:10:52.252 --> 00:10:54.488
<c.magenta>让我们从卷积层开始</c>

00:10:55.322 --> 00:10:56.523
<c.magenta>这是一个卷积</c>

00:10:56.590 --> 00:10:58.158
<c.magenta>它使用一个输入图像</c>

00:10:58.692 --> 00:11:01.662
<c.magenta>一组权值 中间橘色的矩阵</c>

00:10:58.692 --> 00:11:01.662
<c.magenta>一组权值 中间橘色的矩阵</c>

00:11:01.728 --> 00:11:03.797
<c.magenta>然后输出图像里的每一个像素</c>

00:11:04.531 --> 00:11:08.335
<c.magenta>是通过计算对每一组输入像素</c>

00:11:08.502 --> 00:11:10.470
<c.magenta>与权值的的积</c>

00:11:10.604 --> 00:11:13.373
<c.magenta>之后将结果相加</c>
<c.magenta>得到你们上方的像素</c>

00:11:13.774 --> 00:11:16.510
<c.magenta>你们要对每一个输出像素</c>
<c.magenta>执行上述步骤</c>

00:11:16.877 --> 00:11:19.179
<c.magenta>那如果你数下</c>
<c.magenta>这是个四维的循环</c>

00:11:19.246 --> 00:11:21.181
<c.magenta>因为你们要循环x和y</c>

00:11:21.415 --> 00:11:23.250
<c.magenta>还有内核的维数</c>

00:11:24.084 --> 00:11:26.520
<c.magenta>现实里 要比上述更复杂些</c>

00:11:26.587 --> 00:11:29.323
<c.magenta>因为我们的输入不仅是一个图像</c>

00:11:29.389 --> 00:11:30.858
<c.magenta>我们有一堆图像</c>

00:11:31.191 --> 00:11:33.227
<c.magenta>那我们要复制权值</c>

00:11:33.927 --> 00:11:37.998
<c.magenta>并知道在每一层</c>
<c.magenta>我们在计算此卷积</c>

00:11:38.298 --> 00:11:40.133
<c.magenta>然后再将它们相加</c>

00:11:40.200 --> 00:11:42.336
<c.magenta>获取我们的输出像素</c>

00:11:42.836 --> 00:11:45.239
<c.magenta>那现在循环就是五维的了</c>

00:11:45.706 --> 00:11:48.275
<c.magenta>我在公式里添加了IC参数</c>

00:11:48.909 --> 00:11:51.044
<c.magenta>这其实不是我们要计算的</c>

00:11:51.278 --> 00:11:53.380
<c.magenta>因为我们还要有个输出堆栈</c>

00:11:53.780 --> 00:11:56.550
<c.magenta>那实际上 我们在卷积里是在</c>
<c.magenta>做这样的计算</c>

00:11:56.750 --> 00:12:00.721
<c.magenta>我们重复这个多次</c>
<c.magenta>每一次为一个输出层</c>

00:11:56.750 --> 00:12:00.721
<c.magenta>我们重复这个多次</c>
<c.magenta>每一次为一个输出层</c>

00:12:01.288 --> 00:12:03.557
<c.magenta>那现在我们有个六维的循环</c>

00:12:04.024 --> 00:12:06.827
<c.magenta>这意味着 即使每个维度都很小</c>

00:12:06.894 --> 00:12:10.731
<c.magenta>像在这个例子里</c>
<c.magenta>我们没有大于264的</c>

00:12:11.098 --> 00:12:13.800
<c.magenta>这的确很小 但你们将它们相乘</c>

00:12:13.867 --> 00:12:15.969
<c.magenta>你们会有几十亿的操作</c>

00:12:16.036 --> 00:12:18.672
<c.magenta>这相当于几十毫秒的计算量</c>

00:12:19.373 --> 00:12:21.975
<c.magenta>那对大很多的整个网络来讲</c>

00:12:22.543 --> 00:12:25.245
<c.magenta>你们会有数以兆计的浮点运算操作</c>

00:12:25.312 --> 00:12:27.814
<c.magenta>这相当于几秒的CPU时间</c>

00:12:28.682 --> 00:12:30.851
<c.magenta>好的　一个在卷积层的计算</c>

00:12:30.918 --> 00:12:33.120
<c.magenta>怎样通过BNNS来实现？</c>

00:12:33.320 --> 00:12:36.723
<c.magenta>那首先 你们要描述你们的输入堆栈</c>

00:12:37.591 --> 00:12:41.094
<c.magenta>你们要指定图像的尺寸</c>

00:12:41.361 --> 00:12:42.863
<c.magenta>通道数</c>

00:12:43.096 --> 00:12:46.200
<c.magenta>还有在内存里的分层</c>

00:12:46.300 --> 00:12:51.104
<c.magenta>包括两行之间的增量和</c>
<c.magenta>两层面间的增量</c>

00:12:51.305 --> 00:12:53.273
<c.magenta>还有很重要的是</c>

00:12:53.440 --> 00:12:55.976
<c.magenta>他们的储存类型</c>

00:12:57.444 --> 00:13:01.915
<c.magenta>举例 我们使用32位浮点数</c>
<c.magenta>或甚至64位浮点数</c>

00:12:57.444 --> 00:13:01.915
<c.magenta>举例 我们使用32位浮点数</c>
<c.magenta>或甚至64位浮点数</c>

00:13:02.482 --> 00:13:04.885
<c.magenta>在神经网络里</c>
<c.magenta>我们无需这样的精确度</c>

00:13:04.952 --> 00:13:07.554
<c.magenta>一般人们会用16位浮点数</c>

00:13:08.188 --> 00:13:10.390
<c.magenta>那很好 因为这会削减一半的储存空间</c>

00:13:11.024 --> 00:13:13.493
<c.magenta>那本来20兆字节 我们只需10</c>

00:13:13.660 --> 00:13:16.129
<c.magenta>如果你们能用整数</c>
<c.magenta>8位的整数</c>

00:13:16.196 --> 00:13:17.998
<c.magenta>那你们只需5兆字节</c>

00:13:18.298 --> 00:13:21.502
<c.magenta>同样 一般你们的输出也无需</c>
<c.magenta>任何精确度</c>

00:13:22.836 --> 00:13:26.006
<c.magenta>所以 你们可以使用</c>
<c.magenta>与输入相同的类型</c>

00:13:26.673 --> 00:13:28.675
<c.magenta>你们需要对输出堆栈作相同的设定</c>

00:13:29.076 --> 00:13:31.512
<c.magenta>然后 你们要描述卷积自身</c>

00:13:31.712 --> 00:13:33.313
<c.magenta>这包括内核的尺寸</c>

00:13:33.747 --> 00:13:37.417
<c.magenta>对输入的0填充</c>

00:13:38.185 --> 00:13:41.421
<c.magenta>x和y在循环里的增幅</c>

00:13:42.122 --> 00:13:44.157
<c.magenta>还有 你们要重复</c>

00:13:44.224 --> 00:13:47.794
<c.magenta>输入和输出的通道数</c>
<c.magenta>还有权值</c>

00:13:47.995 --> 00:13:50.731
<c.magenta>那是之前中间橘色的部分</c>

00:13:51.131 --> 00:13:53.667
<c.magenta>列出权值 同样</c>
<c.magenta>你们可以设置不同的</c>

00:13:53.734 --> 00:13:55.602
<c.magenta>储存类型给权值</c>

00:13:55.869 --> 00:14:00.274
<c.magenta>一般你们将其设定为16位或8位</c>

00:13:55.869 --> 00:14:00.274
<c.magenta>一般你们将其设定为16位或8位</c>

00:14:00.741 --> 00:14:06.513
<c.magenta>因为那可以降低内存使用和</c>
<c.magenta>储存空间</c>

00:14:08.348 --> 00:14:09.650
<c.magenta>当你们完成了这些</c>

00:14:09.716 --> 00:14:12.653
<c.magenta>你们能用这个函数来创建</c>
<c.magenta>卷积筛选器</c>

00:14:13.220 --> 00:14:14.988
<c.magenta>你们告诉它 这是我的输入堆栈</c>

00:14:15.055 --> 00:14:17.991
<c.magenta>那是我的输出堆栈</c>
<c.magenta>那是我的卷积 创建一个筛选器</c>

00:14:18.458 --> 00:14:20.894
<c.magenta>你会获取一个筛选器对象</c>
<c.magenta>然后用它</c>

00:14:20.994 --> 00:14:23.263
<c.magenta>对你们的数据应用卷积</c>

00:14:23.864 --> 00:14:25.165
<c.magenta>在你们使用完它之后</c>

00:14:25.232 --> 00:14:26.834
<c.magenta>你们调用销毁筛选器</c>

00:14:27.201 --> 00:14:29.937
<c.magenta>来移除它并释放资源</c>

00:14:30.804 --> 00:14:32.372
<c.magenta>以上就是关于卷积层的内容</c>

00:14:32.439 --> 00:14:35.075
<c.magenta>现在 让我们来看下池化层</c>

00:14:35.342 --> 00:14:37.544
<c.magenta>池化要比卷积简单些</c>

00:14:38.011 --> 00:14:39.646
<c.magenta>要计算一个输出像素</c>

00:14:39.713 --> 00:14:42.783
<c.magenta>你们要使用一组输入像素</c>

00:14:42.983 --> 00:14:45.152
<c.magenta>然后取最大的平均值</c>

00:14:45.385 --> 00:14:46.553
<c.magenta>这就是你们的结果</c>

00:14:46.620 --> 00:14:49.690
<c.magenta>你们要对所有通道的所有像素</c>
<c.magenta>重复这样的计算</c>

00:14:50.724 --> 00:14:52.226
<c.magenta>这就是这公式所形容的</c>

00:14:52.893 --> 00:14:55.929
<c.magenta>同样 为池化层创建一个筛选器</c>

00:14:56.029 --> 00:14:58.932
<c.magenta>你们要描述输入和输出堆栈</c>

00:14:59.600 --> 00:15:02.669
<c.magenta>与之前一样</c>
<c.magenta>你们也要描述</c>

00:14:59.600 --> 00:15:02.669
<c.magenta>与之前一样</c>
<c.magenta>你们也要描述</c>

00:15:03.103 --> 00:15:04.638
<c.magenta>池化层自身</c>

00:15:04.705 --> 00:15:07.508
<c.magenta>同样 包括</c>
<c.magenta>内核尺寸 填充 增幅</c>

00:15:07.574 --> 00:15:09.176
<c.magenta>这里没有权值</c>

00:15:09.243 --> 00:15:12.145
<c.magenta>那要使用哪个函数来计算输出</c>

00:15:12.212 --> 00:15:14.014
<c.magenta>使用最大平均</c>

00:15:15.549 --> 00:15:18.185
<c.magenta>在你们完成这些后</c>
<c.magenta>你们就可以创建筛选器</c>

00:15:18.252 --> 00:15:21.121
<c.magenta>获得一个和之前相似的</c>
<c.magenta>筛选器对象</c>

00:15:21.722 --> 00:15:25.058
<c.magenta>最后我们支持的层面是</c>
<c.magenta>全面连接层</c>

00:15:26.426 --> 00:15:29.997
<c.magenta>它尽管被称为全面连接层</c>
<c.magenta>这里有个隐藏的矩阵积</c>

00:15:30.063 --> 00:15:35.169
<c.magenta>作为输入你们有一个向量</c>
<c.magenta>然后你们要将它与一个矩阵相乘</c>

00:15:35.235 --> 00:15:38.372
<c.magenta>加入向量偏量</c>
<c.magenta>然后获取你们的输出</c>

00:15:39.173 --> 00:15:40.908
<c.magenta>就是求个矩阵的积</c>

00:15:41.842 --> 00:15:44.244
<c.magenta>这里 你们的向量里没有图像</c>

00:15:44.311 --> 00:15:47.381
<c.magenta>所以 你们要描述向量 它的大小</c>

00:15:47.848 --> 00:15:50.083
<c.magenta>与数据对应并且</c>
<c.magenta>你们要指定使用的类型</c>

00:15:50.150 --> 00:15:56.390
<c.magenta>用于储存这些值 你们可以使用</c>
<c.magenta>32或16位浮点数或整数</c>

00:15:59.593 --> 00:16:04.498
<c.magenta>然后你们要通过矩阵的尺寸</c>
<c.magenta>来描述这个层面自身</c>

00:15:59.593 --> 00:16:04.498
<c.magenta>然后你们要通过矩阵的尺寸</c>
<c.magenta>来描述这个层面自身</c>

00:16:04.798 --> 00:16:06.500
<c.magenta>和矩阵的系数</c>

00:16:07.768 --> 00:16:10.771
<c.magenta>偏量不在演示稿里</c>
<c.magenta>但你们有偏量</c>

00:16:11.505 --> 00:16:13.874
<c.magenta>之后 你们可以创建一个卷积筛选器</c>

00:16:15.676 --> 00:16:17.945
<c.magenta>同样与之前的筛选器相似</c>

00:16:18.011 --> 00:16:20.848
<c.magenta>接下来是怎样应用筛选器</c>

00:16:21.281 --> 00:16:23.750
<c.magenta>你们将输入数据当作输出数据</c>

00:16:24.151 --> 00:16:27.788
<c.magenta>和你们的筛选器</c>
<c.magenta>你们有两个应用它们的函数</c>

00:16:29.556 --> 00:16:33.327
<c.magenta>叫作筛选器应用</c>
<c.magenta>如果你们只有一对输入和输出</c>

00:16:33.393 --> 00:16:35.229
<c.magenta>如果你们有很多对</c>

00:16:35.295 --> 00:16:37.431
<c.magenta>你们要调用</c>
<c.magenta>筛选器批量应用</c>

00:16:38.532 --> 00:16:41.568
<c.magenta>你们告诉它对数</c>

00:16:41.635 --> 00:16:43.737
<c.magenta>并且怎样从一对到另一对</c>

00:16:43.804 --> 00:16:45.339
<c.magenta>就是怎样在内存里迈进</c>

00:16:47.107 --> 00:16:50.177
<c.magenta>好的 这些就是关于BNNS的内容</c>
<c.magenta>让我们总结下</c>

00:16:50.677 --> 00:16:55.415
<c.magenta>BNNS是一组针对神经网络计算的</c>
<c.magenta>低级函数</c>

00:16:56.683 --> 00:16:59.219
<c.magenta>很低　我们着重于计算</c>
<c.magenta>我们完善它</c>

00:16:59.286 --> 00:17:00.254
<c.magenta>我们提高它的处理速度</c>

00:16:59.286 --> 00:17:00.254
<c.magenta>我们提高它的处理速度</c>

00:17:00.988 --> 00:17:03.624
<c.magenta>但它不知道什么是神经网络</c>

00:17:03.824 --> 00:17:05.592
<c.magenta>它只针对于计算</c>

00:17:07.661 --> 00:17:10.364
<c.magenta>我们优化它</c>
<c.magenta>让它变得更快 更省能源</c>

00:17:11.898 --> 00:17:15.636
<c.magenta>最主要的是</c>
<c.magenta>他支持各种数据类型</c>

00:17:18.405 --> 00:17:19.839
<c.magenta>以上就是BNNS的内容</c>

00:17:19.940 --> 00:17:21.308
<c.magenta>接下来 Quadrature</c>

00:17:21.441 --> 00:17:23.109
<c.magenta>我们收到请求...</c>

00:17:23.810 --> 00:17:29.183
<c.magenta>许多人要我们开发一个</c>
<c.magenta>用于求数值积分的库</c>

00:17:29.316 --> 00:17:30.417
<c.magenta>那 这就是</c>

00:17:30.817 --> 00:17:33.887
<c.magenta>好 那还记得你们在学校里学的</c>

00:17:34.154 --> 00:17:37.491
<c.magenta>它能计算一个函数在区间a b</c>
<c.magenta>上的积分</c>

00:17:37.858 --> 00:17:40.694
<c.magenta>也就是在曲线和轴之间绿色的部分</c>

00:17:42.496 --> 00:17:45.499
<c.magenta>那要使用这个</c>
<c.magenta>你们首先要描述函数</c>

00:17:45.933 --> 00:17:47.434
<c.magenta>你们要提供一个回调</c>

00:17:47.501 --> 00:17:50.237
<c.magenta>我们做的改动之一</c>
<c.magenta>与之前的</c>

00:17:50.404 --> 00:17:52.139
<c.magenta>旧的库里不一样的是</c>

00:17:52.406 --> 00:17:56.210
<c.magenta>回调接收一组点并求值</c>

00:17:56.910 --> 00:17:58.846
<c.magenta>通常当你们计算积分</c>

00:17:58.912 --> 00:18:01.281
<c.magenta>你们要在许多点上计算函数值</c>

00:17:58.912 --> 00:18:01.281
<c.magenta>你们要在许多点上计算函数值</c>

00:18:01.348 --> 00:18:05.452
<c.magenta>如果你们有一个向量化的回调</c>
<c.magenta>能提高速度 那很好</c>

00:18:05.519 --> 00:18:10.257
<c.magenta>你们可以使其更快</c>
<c.magenta>通过使用这个多x的回调</c>

00:18:10.324 --> 00:18:13.694
<c.magenta>它会通过x递给你们多个值</c>

00:18:13.760 --> 00:18:18.131
<c.magenta>你们填入每一个对应的y的值</c>
<c.magenta>通过计算f(xi)</c>

00:18:19.399 --> 00:18:22.803
<c.magenta>这就是你们的函数</c>
<c.magenta>然后要告诉它如何计算积分</c>

00:18:22.870 --> 00:18:25.639
<c.magenta>那我们提供了三个</c>
<c.magenta>计算积分的方法</c>

00:18:26.173 --> 00:18:28.375
<c.magenta>它们有不同的的复杂度和运行时间</c>

00:18:29.076 --> 00:18:32.045
<c.magenta>有些还可以积分至无限</c>

00:18:32.179 --> 00:18:35.249
<c.magenta>你们可以在Quadrature标头</c>
<c.magenta>找到更多的细节</c>

00:18:36.450 --> 00:18:40.254
<c.magenta>你们也要指定输出的误差</c>

00:18:40.954 --> 00:18:43.223
<c.magenta>和细分区间的最大数量</c>

00:18:43.290 --> 00:18:45.259
<c.magenta>用于计算结果</c>

00:18:45.459 --> 00:18:47.895
<c.magenta>然后你们将它递入</c>
<c.magenta>integrate函数</c>

00:18:49.363 --> 00:18:51.465
<c.magenta>你们还要告诉函数 a和b</c>

00:18:51.532 --> 00:18:54.868
<c.magenta>你们也要递入一个点</c>
<c.magenta>用于接收误差</c>

00:18:55.135 --> 00:18:59.239
<c.magenta>它被称为估计误差</c>

00:18:59.706 --> 00:19:01.942
<c.magenta>它会在结果里返回估计误差</c>

00:18:59.706 --> 00:19:01.942
<c.magenta>它会在结果里返回估计误差</c>

00:19:02.009 --> 00:19:04.745
<c.magenta>和状态</c>
<c.magenta>我们接受计算的状态</c>

00:19:04.811 --> 00:19:07.147
<c.magenta>因为如果你要求一个很低的误差</c>

00:19:07.214 --> 00:19:09.116
<c.magenta>有时无法被转换</c>

00:19:09.183 --> 00:19:11.418
<c.magenta>那我们可以在状态里看到</c>

00:19:11.718 --> 00:19:13.387
<c.magenta>这就是Quadrature所有内容</c>

00:19:14.555 --> 00:19:16.456
<c.magenta>现在让我请Steve上台</c>

00:19:16.557 --> 00:19:18.992
<c.magenta>他会来讲下关于simd的新添项</c>

00:19:19.860 --> 00:19:20.928
<c.magenta>十分感谢 Eric</c>

00:19:21.228 --> 00:19:22.196
<c.magenta>我是Steve Canon</c>

00:19:22.262 --> 00:19:24.431
<c.magenta>我与Eric一起在</c>
<c.magenta>向量与数值团队工作</c>

00:19:24.598 --> 00:19:27.734
<c.magenta>Eric刚才将你们带回了</c>
<c.magenta>学微积分的日子里</c>

00:19:27.801 --> 00:19:29.770
<c.magenta>我现在将带你们前进些</c>

00:19:29.837 --> 00:19:31.505
<c.magenta>来到线性代数</c>

00:19:33.674 --> 00:19:35.309
<c.magenta>我们有这样一个很有用的模块</c>
<c.magenta>叫simd</c>

00:19:35.609 --> 00:19:39.513
<c.magenta>它能提供几何操作和向量操作</c>

00:19:39.980 --> 00:19:43.517
<c.magenta>针对C、Objective-C、</c>
<c.magenta>C++和Swift</c>

00:19:44.518 --> 00:19:47.654
<c.magenta>它很好地对应了Metal着色语言</c>

00:19:48.488 --> 00:19:51.892
<c.magenta>它能与SceneKit和</c>
<c.magenta>Model I/O紧密结合</c>

00:19:51.959 --> 00:19:53.660
<c.magenta>还有各种图形的库</c>

00:19:53.794 --> 00:19:57.130
<c.magenta>如果你们在写向量相关的代码来执行</c>

00:19:57.197 --> 00:20:01.535
<c.magenta>小型的3x3、4x4之类的</c>
<c.magenta>线性代数的操作</c>

00:19:57.197 --> 00:20:01.535
<c.magenta>小型的3x3、4x4之类的</c>
<c.magenta>线性代数的操作</c>

00:20:01.802 --> 00:20:04.538
<c.magenta>这个库就是你们想要的</c>
<c.magenta>你们就不用去自己写了</c>

00:20:04.605 --> 00:20:06.607
<c.magenta>我们有大部分你们想要的</c>

00:20:06.673 --> 00:20:08.742
<c.magenta>如果没有 可以请求我们添加它</c>

00:20:08.809 --> 00:20:10.644
<c.magenta>它十分的快 让我们来细看</c>

00:20:10.777 --> 00:20:11.945
<c.magenta>那有些什么？</c>

00:20:13.080 --> 00:20:14.348
<c.magenta>我们有一大堆类型</c>

00:20:14.515 --> 00:20:17.684
<c.magenta>有浮点数的向量和双精确度的向量</c>

00:20:18.018 --> 00:20:21.054
<c.magenta>有带符号和不带符号的整数</c>
<c.magenta>像2、3和4</c>

00:20:22.222 --> 00:20:25.425
<c.magenta>我们还有相同尺寸的</c>
<c.magenta>浮点数和双精确度的矩阵</c>

00:20:26.560 --> 00:20:29.396
<c.magenta>这些只是在所有语言里都有的</c>

00:20:30.163 --> 00:20:31.899
<c.magenta>在C、C++</c>
<c.magenta>和Objective-C里</c>

00:20:31.965 --> 00:20:33.233
<c.magenta>还有其它许多类型</c>

00:20:33.300 --> 00:20:36.236
<c.magenta>那些会对你们写自己泛型的</c>
<c.magenta>向量代码很有用</c>

00:20:36.303 --> 00:20:39.306
<c.magenta>但我将着重于共有的子集</c>

00:20:39.373 --> 00:20:42.242
<c.magenta>在所有的语言里和平台上</c>
<c.magenta>在今天的讲座里</c>

00:20:43.143 --> 00:20:45.112
<c.magenta>显然 我们还有类型相关的操作</c>

00:20:45.179 --> 00:20:48.815
<c.magenta>有一般的算术操作</c>

00:20:48.882 --> 00:20:50.717
<c.magenta>用于向量和矩阵</c>

00:20:51.585 --> 00:20:54.121
<c.magenta>还有我们所熟悉的</c>
<c.magenta>几何和着色函数</c>

00:20:54.188 --> 00:20:55.756
<c.magenta>若你们有过任何着色编程的经验</c>

00:20:55.822 --> 00:20:58.659
<c.magenta>大多数你们想用的 这里都有</c>

00:20:58.892 --> 00:21:00.861
<c.magenta>我现在来展示个小型的例子</c>

00:20:58.892 --> 00:21:00.861
<c.magenta>我现在来展示个小型的例子</c>

00:21:01.762 --> 00:21:05.732
<c.magenta>这是一个相同的函数</c>
<c.magenta>被用三种语言编写</c>

00:21:06.300 --> 00:21:09.837
<c.magenta>有Objective-C在最上面</c>
<c.magenta>有C++在中间</c>

00:21:09.903 --> 00:21:11.672
<c.magenta>Swift在底部</c>

00:21:12.072 --> 00:21:13.674
<c.magenta>你们可以看到模版</c>

00:21:13.740 --> 00:21:15.409
<c.magenta>在各个语言之间有些不同</c>

00:21:15.475 --> 00:21:18.345
<c.magenta>只是因为函数声明在</c>
<c.magenta>这些语言之间有所不同</c>

00:21:18.512 --> 00:21:21.448
<c.magenta>但如果我们注意</c>
<c.magenta>实际计算的部分</c>

00:21:21.748 --> 00:21:23.851
<c.magenta>在各语言里 基本上都一样</c>

00:21:23.917 --> 00:21:26.386
<c.magenta>同时 它也很对应</c>

00:21:26.587 --> 00:21:29.122
<c.magenta>你们在数学里表达的方式</c>

00:21:29.456 --> 00:21:30.991
<c.magenta>不会有许多奇怪的函数调用</c>

00:21:31.058 --> 00:21:33.427
<c.magenta>你们也不用写for循环之类的</c>

00:21:33.527 --> 00:21:35.963
<c.magenta>你们能自然流畅地写</c>
<c.magenta>你们的代码</c>

00:21:36.230 --> 00:21:38.732
<c.magenta>我们替你们翻译</c>

00:21:38.999 --> 00:21:40.467
<c.magenta>编写变得友好和简单</c>

00:21:40.534 --> 00:21:43.770
<c.magenta>这用Metal代码写</c>
<c.magenta>看起来也一样</c>

00:21:43.837 --> 00:21:46.573
<c.magenta>那这里凑巧已经有了</c>
<c.magenta>reflect函数</c>

00:21:46.640 --> 00:21:47.875
<c.magenta>在库里面</c>

00:21:47.941 --> 00:21:49.743
<c.magenta>那你们就不用自己编写了</c>

00:21:50.811 --> 00:21:54.615
<c.magenta>在各种语言之间调用函数</c>
<c.magenta>像很多在model I/O里的</c>

00:21:54.681 --> 00:21:57.584
<c.magenta>能通过使用接受这些类型的</c>
<c.magenta>Objective-C API</c>

00:21:58.018 --> 00:21:59.553
<c.magenta>很不错</c>

00:21:59.620 --> 00:22:01.788
<c.magenta>向量类型是编译器的扩展</c>

00:21:59.620 --> 00:22:01.788
<c.magenta>向量类型是编译器的扩展</c>

00:22:01.855 --> 00:22:04.291
<c.magenta>在C、Objective-C</c>
<c.magenta>和C++里</c>

00:22:05.125 --> 00:22:07.561
<c.magenta>在Swift里</c>
<c.magenta>它们被定义为structs</c>

00:22:07.628 --> 00:22:10.898
<c.magenta>但编译器知道如何为你们</c>
<c.magenta>映射它们</c>

00:22:11.598 --> 00:22:13.367
<c.magenta>所以 你们根本不用做任何事</c>

00:22:13.834 --> 00:22:15.202
<c.magenta>这里有个简单的例子</c>

00:22:15.302 --> 00:22:16.904
<c.magenta>若我有个Objective-C的函数</c>

00:22:16.970 --> 00:22:19.606
<c.magenta>我在这里调用某个对向量类型</c>
<c.magenta>执行操作的函数</c>

00:22:20.307 --> 00:22:21.808
<c.magenta>并且我想调用那个函数</c>

00:22:21.942 --> 00:22:23.944
<c.magenta>通过Swift</c>
<c.magenta>使用Swift向量类型</c>

00:22:24.011 --> 00:22:25.746
<c.magenta>我可以成功的这么做</c>

00:22:25.812 --> 00:22:27.414
<c.magenta>我无需做任何进阶的事</c>

00:22:27.548 --> 00:22:28.782
<c.magenta>这些类型都有相同的布局</c>

00:22:28.849 --> 00:22:31.418
<c.magenta>所以 没有转换开销之类的</c>

00:22:32.252 --> 00:22:33.987
<c.magenta>相似的 对于矩阵</c>

00:22:34.188 --> 00:22:36.823
<c.magenta>Swift的矩阵类型布局和</c>

00:22:36.890 --> 00:22:39.126
<c.magenta>C、Objective-C</c>
<c.magenta>和C++类型相匹配</c>

00:22:39.660 --> 00:22:42.529
<c.magenta>那如果我要使用它们</c>
<c.magenta>这里我有Swift</c>

00:22:42.796 --> 00:22:45.666
<c.magenta>我来创建一个Swift的类型</c>
<c.magenta>通过C的类型</c>

00:22:46.300 --> 00:22:48.168
<c.magenta>我所要做的就是使用init函数</c>

00:22:48.235 --> 00:22:49.069
<c.magenta>很好用</c>

00:22:49.136 --> 00:22:50.637
<c.magenta>没有任何的计算开销</c>

00:22:50.704 --> 00:22:53.106
<c.magenta>就好像 不知不觉地改变了类型</c>

00:22:53.173 --> 00:22:55.742
<c.magenta>相似的 我可以使用C的</c>
<c.magenta>矩阵属性</c>

00:22:56.109 --> 00:23:00.848
<c.magenta>如果我要通过C的类型调用C或</c>
<c.magenta>Objective-C或C++的函数</c>

00:22:56.109 --> 00:23:00.848
<c.magenta>如果我要通过C的类型调用C或</c>
<c.magenta>Objective-C或C++的函数</c>

00:23:01.415 --> 00:23:04.318
<c.magenta>我们今年有些新的东西</c>
<c.magenta>我想向你们展示</c>

00:23:05.619 --> 00:23:07.020
<c.magenta>我们有三个新的函数</c>

00:23:07.087 --> 00:23:09.656
<c.magenta>simd orient和simd incircle</c>
<c.magenta>还有simd insphere</c>

00:23:09.723 --> 00:23:12.693
<c.magenta>它们已被重载</c>
<c.magenta>为支持许多不一样的类型</c>

00:23:12.759 --> 00:23:14.628
<c.magenta>和不同的长度 之类的</c>

00:23:14.695 --> 00:23:16.797
<c.magenta>基本上所有在simd库里的都这样</c>

00:23:16.864 --> 00:23:18.565
<c.magenta>所以 仅管我们只有三个新函数</c>

00:23:18.632 --> 00:23:20.567
<c.magenta>实际上 有许多新东西</c>

00:23:21.768 --> 00:23:23.103
<c.magenta>我会从orient开始讲</c>

00:23:23.637 --> 00:23:25.672
<c.magenta>orient让我们回答这样的问题：</c>

00:23:25.739 --> 00:23:27.641
<c.magenta>一组向量是否都朝向正面？</c>

00:23:28.108 --> 00:23:31.044
<c.magenta>如果你们不记得线性代数</c>
<c.magenta>意思是</c>

00:23:31.445 --> 00:23:33.046
<c.magenta>它们是否遵循右手螺旋法则？</c>

00:23:33.313 --> 00:23:35.015
<c.magenta>你们可能记得在物理里见过它</c>

00:23:35.082 --> 00:23:37.384
<c.magenta>或 相等同的</c>
<c.magenta>是否有正值的行列式？</c>

00:23:38.018 --> 00:23:40.621
<c.magenta>如果在座的有数学专业的</c>
<c.magenta>你们现在会抗议</c>

00:23:40.687 --> 00:23:43.657
<c.magenta>一组向量是没有行列式的</c>

00:23:43.757 --> 00:23:45.726
<c.magenta>我的意思是你们把它们</c>

00:23:45.792 --> 00:23:47.794
<c.magenta>放到一个矩阵里</c>

00:23:48.095 --> 00:23:49.730
<c.magenta>计算矩阵的行列式</c>

00:23:49.796 --> 00:23:51.098
<c.magenta>是不是正的？</c>

00:23:51.798 --> 00:23:53.567
<c.magenta>那我们为什么关心这个？</c>

00:23:53.667 --> 00:23:55.502
<c.magenta>这很明显</c>

00:23:56.103 --> 00:24:00.240
<c.magenta>你们能用这回答许多</c>
<c.magenta>计算几何的问题</c>

00:23:56.103 --> 00:24:00.240
<c.magenta>你们能用这回答许多</c>
<c.magenta>计算几何的问题</c>

00:24:00.307 --> 00:24:01.308
<c.magenta>会很有用</c>

00:24:01.542 --> 00:24:04.211
<c.magenta>比如 这个三角形是</c>
<c.magenta>面朝我还是背朝我？</c>

00:24:04.278 --> 00:24:06.079
<c.magenta>如果你们想象个四面体</c>

00:24:06.146 --> 00:24:08.515
<c.magenta>有两个面朝着你们</c>

00:24:08.582 --> 00:24:11.251
<c.magenta>也有两个面背着你们</c>

00:24:11.318 --> 00:24:13.020
<c.magenta>如果你们在进行图形操作</c>

00:24:13.086 --> 00:24:15.756
<c.magenta>知道面朝你们的面</c>
<c.magenta>会是很有用的</c>

00:24:15.822 --> 00:24:17.791
<c.magenta>因为那些是你们要处理的面</c>

00:24:18.192 --> 00:24:21.628
<c.magenta>相似的 如果我有一个点和一条线</c>
<c.magenta>我想回答这样个问题</c>

00:24:21.695 --> 00:24:24.965
<c.magenta>点在不在线上</c>
<c.magenta>或 如果不在 那它在线的哪侧？</c>

00:24:25.632 --> 00:24:28.101
<c.magenta>我能用orient判断</c>
<c.magenta>去回答那个问题</c>

00:24:28.335 --> 00:24:31.038
<c.magenta>那 这看起来很简单的样子</c>
<c.magenta>的确很简单</c>

00:24:31.104 --> 00:24:33.941
<c.magenta>除了实际回答这个问题</c>
<c.magenta>可能会很难</c>

00:24:34.007 --> 00:24:37.110
<c.magenta>当点离线很近时</c>
<c.magenta>我们会在下面细说</c>

00:24:38.045 --> 00:24:39.913
<c.magenta>这里有个这样的例子</c>

00:24:40.447 --> 00:24:44.051
<c.magenta>在显示的右侧 我有个平面</c>

00:24:44.117 --> 00:24:46.320
<c.magenta>我会在平面上加些点</c>

00:24:47.020 --> 00:24:50.190
<c.magenta>我有三个点</c>
<c.magenta>a和b还有c</c>

00:24:50.257 --> 00:24:53.861
<c.magenta>我将使用的simd orient</c>
<c.magenta>查询它们的朝向</c>

00:24:54.194 --> 00:24:56.396
<c.magenta>由于我们是通过</c>
<c.magenta>逆时针的方向</c>

00:24:56.663 --> 00:24:59.233
<c.magenta>从a到b到c</c>

00:24:59.766 --> 00:25:01.768
<c.magenta>我们说它们是</c>
<c.magenta>正朝向</c>

00:24:59.766 --> 00:25:01.768
<c.magenta>我们说它们是</c>
<c.magenta>正朝向</c>

00:25:01.835 --> 00:25:04.505
<c.magenta>这是在平面里对</c>
<c.magenta>正朝向的定义</c>

00:25:04.571 --> 00:25:09.142
<c.magenta>如果我们移动其中一点</c>
<c.magenta>变成顺时针方向</c>

00:25:09.343 --> 00:25:11.144
<c.magenta>现在就是负朝向了</c>

00:25:12.412 --> 00:25:16.550
<c.magenta>那如果我移动点c</c>
<c.magenta>让它正好在a和b之间的线上</c>

00:25:16.817 --> 00:25:19.653
<c.magenta>那它们共线 朝向是0</c>

00:25:19.720 --> 00:25:21.355
<c.magenta>或许 你们会说它是虚的</c>

00:25:21.555 --> 00:25:25.492
<c.magenta>判定点是否正好在线上</c>
<c.magenta>一般是件很难的事</c>

00:25:25.559 --> 00:25:27.594
<c.magenta>特别是利用浮点数的坐标</c>

00:25:27.661 --> 00:25:30.931
<c.magenta>因为朝向数值的不稳定性</c>

00:25:31.532 --> 00:25:33.567
<c.magenta>由于浮点数的取舍</c>

00:25:33.634 --> 00:25:36.203
<c.magenta>如果行列式的结果接近0</c>

00:25:36.336 --> 00:25:38.138
<c.magenta>你们很有可能得到一个错误的符号</c>

00:25:38.205 --> 00:25:40.574
<c.magenta>对于一些算法来说</c>
<c.magenta>这无关紧要</c>

00:25:40.641 --> 00:25:43.143
<c.magenta>但对于其它算法</c>
<c.magenta>你们可能会遇到无法收敛的情况</c>

00:25:43.210 --> 00:25:45.779
<c.magenta>或 当使用它时</c>
<c.magenta>你们也许会获得错误的的结果</c>

00:25:45.846 --> 00:25:47.381
<c.magenta>像在碰撞检测之类的情况里</c>

00:25:47.447 --> 00:25:50.017
<c.magenta>能回答这个问题变得很重要</c>

00:25:50.083 --> 00:25:53.420
<c.magenta>还有像使用三角网格建立模型</c>
<c.magenta>之类的</c>

00:25:53.487 --> 00:25:56.123
<c.magenta>这会是个重要的问题</c>
<c.magenta>要求有准确的答案</c>

00:25:57.691 --> 00:26:01.028
<c.magenta>让我们来看个难回答的例子</c>

00:25:57.691 --> 00:26:01.028
<c.magenta>让我们来看个难回答的例子</c>

00:26:02.563 --> 00:26:04.865
<c.magenta>我在平面里建立两个向量</c>
<c.magenta>u和v</c>

00:26:04.932 --> 00:26:07.501
<c.magenta>它们几乎相同</c>

00:26:07.568 --> 00:26:10.771
<c.magenta>它们只有一点点的不同</c>

00:26:11.705 --> 00:26:15.375
<c.magenta>我在右侧将它们放大了很多倍</c>

00:26:15.442 --> 00:26:16.810
<c.magenta>那样你们能看见它们的不同</c>

00:26:16.877 --> 00:26:20.080
<c.magenta>如果我将它们按真实比例来画</c>
<c.magenta>它们会全部重叠</c>

00:26:20.547 --> 00:26:25.219
<c.magenta>如果我们用通常的方式来</c>
<c.magenta>计算朝向</c>

00:26:25.285 --> 00:26:28.021
<c.magenta>我们会得到结果0</c>
<c.magenta>因为浮点数的取舍</c>

00:26:28.088 --> 00:26:30.157
<c.magenta>这是个简单的</c>
<c.magenta>结果为0的例子</c>

00:26:30.324 --> 00:26:32.426
<c.magenta>如果维度大于2x2</c>

00:26:32.559 --> 00:26:34.995
<c.magenta>我们会得到一个完全错误的符号</c>

00:26:35.062 --> 00:26:37.164
<c.magenta>不只是结果为0</c>
<c.magenta>当它不应该是0时</c>

00:26:37.464 --> 00:26:39.333
<c.magenta>但若我们使用</c>
<c.magenta>simd orient函数</c>

00:26:39.600 --> 00:26:41.335
<c.magenta>我们会得到一个很小的正数</c>

00:26:41.401 --> 00:26:44.371
<c.magenta>是正确的结果</c>
<c.magenta>这些是正朝向的</c>

00:26:44.838 --> 00:26:48.442
<c.magenta>我要提醒的是</c>
<c.magenta>不要诠释</c>

00:26:48.509 --> 00:26:50.544
<c.magenta>这个极小的正数</c>
<c.magenta>对任何情况都有意义</c>

00:26:50.611 --> 00:26:52.012
<c.magenta>这不是一个行列式的值</c>

00:26:52.513 --> 00:26:54.948
<c.magenta>有时候是行列式的值</c>

00:26:55.015 --> 00:26:57.251
<c.magenta>但有时只是有个准确的符号</c>

00:26:57.317 --> 00:27:00.187
<c.magenta>所以 我们这里真正关心的是</c>
<c.magenta>这个数字的符号</c>

00:26:57.317 --> 00:27:00.187
<c.magenta>所以 我们这里真正关心的是</c>
<c.magenta>这个数字的符号</c>

00:27:00.387 --> 00:27:01.622
<c.magenta>那我们是怎么做到的？</c>

00:27:01.722 --> 00:27:04.024
<c.magenta>这些我今天像你们展示的</c>
<c.magenta>几何判定</c>

00:27:04.091 --> 00:27:06.059
<c.magenta>都是使用自适应精度</c>

00:27:06.159 --> 00:27:09.263
<c.magenta>我们计算至我们需要的位</c>

00:27:09.363 --> 00:27:10.497
<c.magenta>来获取正确的结果</c>

00:27:10.564 --> 00:27:14.034
<c.magenta>这让我们在大部分的时候</c>
<c.magenta>能很快返回正确的结果</c>

00:27:14.401 --> 00:27:16.403
<c.magenta>但如果我们要进一步</c>

00:27:16.470 --> 00:27:18.739
<c.magenta>进行精确的计算</c>
<c.magenta>为你们取得正确的结果</c>

00:27:18.906 --> 00:27:20.007
<c.magenta>我们也可以这么做</c>

00:27:20.073 --> 00:27:22.209
<c.magenta>你们可以相信这在你们代码里会给出正确答案</c>

00:27:22.276 --> 00:27:24.344
<c.magenta>你们不用担心</c>

00:27:25.445 --> 00:27:27.247
<c.magenta>Incircle很相似</c>

00:27:27.414 --> 00:27:28.916
<c.magenta>我们在平面里取三点</c>

00:27:29.016 --> 00:27:30.150
<c.magenta>那决定一个圆</c>

00:27:30.217 --> 00:27:32.486
<c.magenta>你们会注意到</c>
<c.magenta>它们是 正朝向的</c>

00:27:32.553 --> 00:27:34.555
<c.magenta>围着圆　这很重要</c>

00:27:34.922 --> 00:27:37.257
<c.magenta>如果我在圆里加个点 x</c>

00:27:37.424 --> 00:27:39.826
<c.magenta>然后simd incircle</c>
<c.magenta>能告诉我点是否在圆内</c>

00:27:40.027 --> 00:27:42.162
<c.magenta>如在圆内 我得到个正值</c>

00:27:42.462 --> 00:27:45.032
<c.magenta>如在圆上 我得到0</c>

00:27:45.599 --> 00:27:48.035
<c.magenta>如在圆外 我得到个负值</c>

00:27:48.535 --> 00:27:51.972
<c.magenta>insphere也是相同的</c>

00:27:54.241 --> 00:27:55.576
<c.magenta>只是现在是三维的了</c>

00:27:55.642 --> 00:27:57.444
<c.magenta>我需要四个维度来定义球体</c>

00:27:57.511 --> 00:27:59.246
<c.magenta>我设定点x</c>
<c.magenta>然后得到相应的结果</c>

00:28:00.647 --> 00:28:02.416
<c.magenta>我向你们展示</c>
<c.magenta>一个之前提过的例子</c>

00:28:02.482 --> 00:28:05.519
<c.magenta>判断一个三角形的面是</c>
<c.magenta>正对还是背对着你们</c>

00:28:06.153 --> 00:28:09.456
<c.magenta>这里我有个简单的struct</c>
<c.magenta>用来在Swift里代表三角形</c>

00:28:09.890 --> 00:28:13.660
<c.magenta>三角形由三个点定义</c>
<c.magenta>我把它们放一个集合里</c>

00:28:14.428 --> 00:28:17.464
<c.magenta>我用这个判定</c>
<c.magenta>IsFacing来告诉我</c>

00:28:17.831 --> 00:28:20.501
<c.magenta>三角形是否面对相机</c>

00:28:21.201 --> 00:28:23.237
<c.magenta>那通常你们的计算方式是</c>

00:28:23.303 --> 00:28:26.773
<c.magenta>运用叉乘积来计算</c>
<c.magenta>一个对三角形面的法向量</c>

00:28:27.241 --> 00:28:30.811
<c.magenta>然后计算它与</c>
<c.magenta>对着相机的向量的点积</c>

00:28:30.878 --> 00:28:33.413
<c.magenta>如果值为正</c>
<c.magenta>那三角形正对着相机</c>

00:28:33.480 --> 00:28:36.884
<c.magenta>我们可以简化这些代码</c>
<c.magenta>并准确计算结果</c>

00:28:38.318 --> 00:28:41.121
<c.magenta>通过使用simd orient判定</c>

00:28:41.321 --> 00:28:42.389
<c.magenta>那我的代码变简单了</c>

00:28:42.789 --> 00:28:44.758
<c.magenta>它很快 还能给我正确的答案</c>

00:28:44.825 --> 00:28:46.426
<c.magenta>这都是我想要的</c>

00:28:46.493 --> 00:28:48.829
<c.magenta>这就是我们尝试着</c>
<c.magenta>在Accelerate实现的</c>

00:28:48.896 --> 00:28:50.264
<c.magenta>给予你们简单的东西</c>

00:28:50.330 --> 00:28:52.332
<c.magenta>用于复杂的数学计算</c>

00:28:53.967 --> 00:28:55.969
<c.magenta>那我们今天向你们展示了</c>
<c.magenta>许多新的东西</c>

00:28:58.438 --> 00:29:00.474
<c.magenta>我们有些全新的库</c>

00:28:58.438 --> 00:29:00.474
<c.magenta>我们有些全新的库</c>

00:29:00.607 --> 00:29:02.743
<c.magenta>我们有BNNS用于神经网络</c>

00:29:03.277 --> 00:29:04.678
<c.magenta>我们有Quadrature</c>

00:29:04.745 --> 00:29:06.947
<c.magenta>我们还有些新的功能</c>

00:29:07.614 --> 00:29:09.716
<c.magenta>simd里的</c>
<c.magenta>orientation和incircle</c>

00:29:09.783 --> 00:29:12.286
<c.magenta>这每一个新功能和库</c>

00:29:12.686 --> 00:29:16.757
<c.magenta>都是为回应开发者的需求</c>
<c.magenta>所添加的</c>

00:29:16.857 --> 00:29:19.660
<c.magenta>所以 我们很想知道你们所想要的</c>

00:29:19.927 --> 00:29:22.663
<c.magenta>通过我们能添加的东西</c>
<c.magenta>能简化你们的计算工作</c>

00:29:22.729 --> 00:29:24.498
<c.magenta>我们想给予你们简单的接口</c>

00:29:24.698 --> 00:29:27.067
<c.magenta>它能让你们有效率地</c>
<c.magenta>完成你们要做的事</c>

00:29:27.634 --> 00:29:29.636
<c.magenta>我们今年还做了许多其它的事</c>

00:29:30.137 --> 00:29:33.207
<c.magenta>在vImage里</c>
<c.magenta>Eric在简介里带过的</c>

00:29:33.907 --> 00:29:37.277
<c.magenta>我们有一组全套的几何操作用于</c>
<c.magenta>交叉存取的色度平面</c>

00:29:37.344 --> 00:29:39.613
<c.magenta>这绝对是最频繁的请求</c>

00:29:39.680 --> 00:29:41.114
<c.magenta>我们在近年里所收到的</c>

00:29:41.281 --> 00:29:42.883
<c.magenta>所以 我们很乐意地添加了它</c>

00:29:42.950 --> 00:29:44.685
<c.magenta>如果你们不知道那是什么</c>
<c.magenta>无需担心</c>

00:29:44.751 --> 00:29:47.321
<c.magenta>但如果你们知道</c>
<c.magenta>那你们会明白它的有用之处</c>

00:29:47.588 --> 00:29:49.656
<c.magenta>我们还扩展了</c>

00:29:49.723 --> 00:29:52.025
<c.magenta>vImage里的转换例程</c>
<c.magenta>用于新的格式</c>

00:29:52.092 --> 00:29:54.795
<c.magenta>这为许多你们或许听说过的关于</c>
<c.magenta>深色的东西奠定了基础</c>

00:29:54.862 --> 00:29:57.030
<c.magenta>所以这个对那来说很重要</c>

00:29:58.565 --> 00:30:00.434
<c.magenta>我们提高了性能</c>

00:29:58.565 --> 00:30:00.434
<c.magenta>我们提高了性能</c>

00:30:00.501 --> 00:30:02.536
<c.magenta>针对vDSP里的交织复杂格式</c>

00:30:02.603 --> 00:30:06.707
<c.magenta>通过FFT 我们支持交织和截面布局</c>

00:30:06.773 --> 00:30:08.108
<c.magenta>复杂和虚的部分</c>

00:30:08.175 --> 00:30:09.977
<c.magenta>要么被分开 要么放在一起</c>

00:30:11.745 --> 00:30:14.281
<c.magenta>我们一般使用截面布局</c>
<c.magenta>进行操作</c>

00:30:14.348 --> 00:30:18.218
<c.magenta>我们推荐这么做</c>
<c.magenta>但如果你们只有交织的数据</c>

00:30:18.285 --> 00:30:21.021
<c.magenta>你们现在可以使用FFT</c>
<c.magenta>它们很快</c>

00:30:22.022 --> 00:30:24.858
<c.magenta>我们也提高了所有</c>
<c.magenta>Level II BLAS操作性能</c>

00:30:24.925 --> 00:30:27.861
<c.magenta>有些是由你们所见到的</c>
<c.magenta>BNNS员工发起的</c>

00:30:27.928 --> 00:30:30.497
<c.magenta>有些是我们所预见并跟进的机会</c>

00:30:30.564 --> 00:30:33.133
<c.magenta>Accelerate里</c>
<c.magenta>还有许多新的东西</c>

00:30:33.200 --> 00:30:34.535
<c.magenta>许多改进了的东西</c>

00:30:34.868 --> 00:30:38.205
<c.magenta>每当有新处理器发布</c>
<c.magenta>我们一定会针对它们进行优化</c>

00:30:38.272 --> 00:30:41.508
<c.magenta>我们想解决所有的那些低级计算细节</c>

00:30:41.575 --> 00:30:44.378
<c.magenta>让你们能注重于</c>
<c.magenta>编写高级算法</c>

00:30:44.578 --> 00:30:46.146
<c.magenta>基于低级细节层面</c>

00:30:46.213 --> 00:30:48.081
<c.magenta>让你们能达成你们想做的</c>

00:30:49.183 --> 00:30:52.019
<c.magenta>总结下</c>
<c.magenta>我们想成为你们一站式购物的地方</c>

00:30:52.085 --> 00:30:53.820
<c.magenta>为计算的算法</c>

00:30:54.288 --> 00:30:56.657
<c.magenta>我们能提供给你们的实现是准确</c>

00:30:56.857 --> 00:30:59.193
<c.magenta>快速和节省能源的</c>

00:30:59.493 --> 00:31:01.662
<c.magenta>并且我们会针对新硬件</c>
<c.magenta>进行优化</c>

00:30:59.493 --> 00:31:01.662
<c.magenta>并且我们会针对新硬件</c>
<c.magenta>进行优化</c>

00:31:01.728 --> 00:31:04.097
<c.magenta>当它们发布时</c>
<c.magenta>这样你们就不用为此担心</c>

00:31:04.164 --> 00:31:08.035
<c.magenta>如果你们想自己优化</c>
<c.magenta>那我们有了新的芯片</c>

00:31:08.101 --> 00:31:10.504
<c.magenta>你们就需要对其更新</c>

00:31:10.571 --> 00:31:12.739
<c.magenta>如果你们交给我们来处理</c>

00:31:12.806 --> 00:31:14.274
<c.magenta>那你们就不用担心了</c>

00:31:15.309 --> 00:31:18.212
<c.magenta>继续提交你们的请求</c>
<c.magenta>我们很高兴能收到它们</c>

00:31:18.278 --> 00:31:20.247
<c.magenta>我们今天在实验室和</c>
<c.magenta>你们许多人交谈了</c>

00:31:20.314 --> 00:31:22.549
<c.magenta>我们已经得到了许多将来的请求</c>

00:31:22.616 --> 00:31:24.985
<c.magenta>能将雷达归档</c>
<c.magenta>我们想要这个功能</c>

00:31:25.686 --> 00:31:30.224
<c.magenta>如果你们想见到更多相关信息</c>
<c.magenta>这个讲座的连接在这里</c>

00:31:30.757 --> 00:31:33.493
<c.magenta>我也推荐你们去看下</c>
<c.magenta>前几年的讲座</c>

00:31:33.560 --> 00:31:37.464
<c.magenta>有关于这些库的其它方面</c>
<c.magenta>有用的细节</c>

00:31:38.232 --> 00:31:40.267
<c.magenta>有两个很好的关于</c>
<c.magenta>Metal的演讲</c>

00:31:40.334 --> 00:31:43.437
<c.magenta>我高度推荐你们去看下</c>
<c.magenta>昨天的演讲</c>

00:31:43.504 --> 00:31:45.906
<c.magenta>特别是如果</c>
<c.magenta>你们对这些感兴趣的话</c>

00:31:45.973 --> 00:31:47.808
<c.magenta>十分感谢你们的到来</c>
