WEBVTT

00:00:16.750 --> 00:00:23.757 align:middle line:0
（研究和护理框架进阶）

00:00:30.998 --> 00:00:32.131 align:middle line:-1
感谢大家的到来

00:00:32.299 --> 00:00:36.970 align:middle line:-1
欢迎来听研究和护理框架进阶会议

00:00:37.538 --> 00:00:39.873 align:middle line:-2
我叫Srinath
我是一名软件工程师

00:00:40.541 --> 00:00:43.310 align:middle line:-2
如果你熟悉我们过去的
Dub Dub Talks

00:00:43.610 --> 00:00:47.381 align:middle line:-1
你就会记得我们的会议主要聚焦于

00:00:47.447 --> 00:00:49.683 align:middle line:-1
两个开源健康框架

00:00:50.717 --> 00:00:52.753 align:middle line:-2
ResearchKit
和CareKit

00:00:53.453 --> 00:00:57.124 align:middle line:-2
尽管今年我们仍然会
谈论很多这些框架的内容

00:00:57.491 --> 00:01:02.229 align:middle line:-2
我们还会谈到一些
我们一直在研究的新API和功能

00:00:57.491 --> 00:01:02.229 align:middle line:-2
我们还会谈到一些
我们一直在研究的新API和功能

00:01:02.462 --> 00:01:03.797 align:middle line:-1
在更大的健康领域中

00:01:04.631 --> 00:01:07.534 align:middle line:-1
对于你们中那些对框架感到陌生的人

00:01:07.868 --> 00:01:11.905 align:middle line:-1
我强烈建议你们看看去年的两个演讲

00:01:13.407 --> 00:01:17.077 align:middle line:-2
CareKit和ResearchKit的新内容
是由Sam Mravca主讲的

00:01:17.611 --> 00:01:22.015 align:middle line:-2
她对ResearchKit和
CareKit做了很好的介绍

00:01:22.649 --> 00:01:25.452 align:middle line:-2
另一个演讲
将CareKit连接到云

00:01:25.719 --> 00:01:27.421 align:middle line:-2
由Kelsey Dedoshka
主讲

00:01:27.721 --> 00:01:30.691 align:middle line:-2
在那个演讲中 我们引入了一个
新的CareKit桥API

00:01:30.958 --> 00:01:35.896 align:middle line:-2
它允许程序员在病人和
供应商间同步护理计划

00:01:35.963 --> 00:01:38.232 align:middle line:-1
其中使用了HIPAA适用后台

00:01:38.899 --> 00:01:42.169 align:middle line:-2
在那张幻灯片上
我非常激动地向你们展示

00:01:42.402 --> 00:01:46.240 align:middle line:-2
Penn Medicine取得的
一些很棒的成果

00:01:47.241 --> 00:01:52.312 align:middle line:-2
Penn Life Gained app利用了
CareKit和CareKit桥API

00:01:52.646 --> 00:01:56.884 align:middle line:-1
在肥胖症手术的术前和术后帮助患者

00:01:57.084 --> 00:01:58.085 align:middle line:-1
在Penn Medicine

00:01:59.219 --> 00:02:01.288 align:middle line:-1
这个app权衡了护理计划

00:01:59.219 --> 00:02:01.288 align:middle line:-1
这个app权衡了护理计划

00:02:01.488 --> 00:02:04.691 align:middle line:-1
治疗数据和其他交互式组件

00:02:05.125 --> 00:02:08.495 align:middle line:-1
来帮助病人度过他们的减肥之旅

00:02:09.229 --> 00:02:14.801 align:middle line:-2
数据一直在被同步
在患者使用的iOS app

00:02:15.068 --> 00:02:19.673 align:middle line:-2
与治疗提供商所用的iPad app间
以此来密切监测

00:02:19.840 --> 00:02:22.576 align:middle line:-1
并实时与患者进行互动

00:02:23.143 --> 00:02:26.046 align:middle line:-1
我们的团队已收到了医患双方

00:02:26.246 --> 00:02:28.849 align:middle line:-1
非常积极的反馈

00:02:29.049 --> 00:02:33.921 align:middle line:-2
鉴于这些app对于他们
肥胖症项目的影响

00:02:35.189 --> 00:02:38.258 align:middle line:-1
既然我们已谈到了从去年以来的进展

00:02:38.959 --> 00:02:41.128 align:middle line:-1
我想要快速地

00:02:41.395 --> 00:02:43.597 align:middle line:-1
整体介绍下我们的健康框架

00:02:44.431 --> 00:02:48.235 align:middle line:-1
这些框架的创造来源于我们的初衷

00:02:48.302 --> 00:02:51.205 align:middle line:-1
就是通过科技来改善世界健康水平

00:02:51.839 --> 00:02:55.042 align:middle line:-2
在此过程中 我们真的想让
我们的用户获得更多

00:02:55.309 --> 00:02:58.545 align:middle line:-2
并且为开发者
以及研究者提供更多工具

00:02:58.745 --> 00:03:01.815 align:middle line:-1
最终你和我们

00:02:58.745 --> 00:03:01.815 align:middle line:-1
最终你和我们

00:03:01.982 --> 00:03:05.752 align:middle line:-1
可以帮助改进两个核心领域

00:03:06.053 --> 00:03:07.721 align:middle line:-1
研究和治疗

00:03:08.922 --> 00:03:11.625 align:middle line:-1
今年我很激动地向你们介绍

00:03:11.892 --> 00:03:14.795 align:middle line:-1
一些我们非常关注的主题

00:03:15.028 --> 00:03:16.496 align:middle line:-1
从很多方面来说

00:03:16.864 --> 00:03:18.899 align:middle line:-1
最开始我们聚焦于框架

00:03:19.132 --> 00:03:22.970 align:middle line:-2
我会给你们介绍我们对于
ResearchKit框架所做的一些更新

00:03:23.504 --> 00:03:27.074 align:middle line:-2
然后我们会介绍
一个更关注于状况的方法

00:03:27.441 --> 00:03:31.044 align:middle line:-2
特别是像帕金森症这样的
运动失调疾病

00:03:31.411 --> 00:03:35.716 align:middle line:-2
这里会由Gabriel上台
来给你们介绍下这个新的API

00:03:36.450 --> 00:03:40.787 align:middle line:-2
最后我们会将所有内容
集合起来做一个演示

00:03:41.021 --> 00:03:45.492 align:middle line:-2
看看你们可以如何在代码中
直接使用这些新API和功能

00:03:47.160 --> 00:03:49.196 align:middle line:-1
我们从ResearchKit开始

00:03:50.163 --> 00:03:53.300 align:middle line:-1
从去年开始 我们花了很多精力

00:03:53.700 --> 00:03:57.137 align:middle line:-1
来改善我们社区的开放性和参与性

00:03:58.472 --> 00:04:01.508 align:middle line:-2
一些对于ResearchKit
用户界面和组件的更新

00:03:58.472 --> 00:04:01.508 align:middle line:-2
一些对于ResearchKit
用户界面和组件的更新

00:04:02.142 --> 00:04:07.047 align:middle line:-1
以及当前任务现有库的一些新内容

00:04:08.348 --> 00:04:10.751 align:middle line:-1
现在让我们从社区的更新开始说吧

00:04:11.084 --> 00:04:12.920 align:middle line:-1
我想谈两个主要话题

00:04:13.187 --> 00:04:15.989 align:middle line:-1
仓库特权和计划更新

00:04:17.156 --> 00:04:20.961 align:middle line:-2
过去的几个月
我们一直在扩展我们的访问权限

00:04:21.028 --> 00:04:24.164 align:middle line:-1
并且给我们社区的成员提供写入权限

00:04:24.932 --> 00:04:28.101 align:middle line:-1
事实上 我们选了五个明星贡献者

00:04:28.168 --> 00:04:31.305 align:middle line:-2
给了他们ResearchKit
仓库的直接访问权限

00:04:31.572 --> 00:04:34.308 align:middle line:-1
这能允许他们合并MPR

00:04:34.942 --> 00:04:37.544 align:middle line:-1
非常感谢 并且恭喜你们

00:04:37.778 --> 00:04:41.882 align:middle line:-2
Erin、Fernando、Nino
Ricardo 还有Shannon

00:04:43.083 --> 00:04:46.420 align:middle line:-1
接着我想讲一下我们的计划更新

00:04:46.887 --> 00:04:51.592 align:middle line:-2
之前我们一直在同时推送到
master和stable分支

00:04:52.025 --> 00:04:56.263 align:middle line:-2
我们意识到这样会制约
你们开发者的能力

00:04:56.797 --> 00:05:02.536 align:middle line:-2
为了权衡我们的一些内部功能
像是定位、可用性以及质量保证

00:04:56.797 --> 00:05:02.536 align:middle line:-2
为了权衡我们的一些内部功能
像是定位、可用性以及质量保证

00:05:03.136 --> 00:05:06.073 align:middle line:-2
这也是我们为什么
今年会推送到stable

00:05:06.373 --> 00:05:09.009 align:middle line:-2
比推送到master
要晚两到三个月

00:05:09.843 --> 00:05:11.612 align:middle line:-1
我们希望你们可以利用这段时间

00:05:12.145 --> 00:05:16.984 align:middle line:-2
来用下我们的最新更新
提供反馈并提交评论

00:05:17.651 --> 00:05:18.986 align:middle line:-1
而你们所做的变动

00:05:19.353 --> 00:05:23.657 align:middle line:-2
会使其很快出现在我们的稳定
发布分支

00:05:23.924 --> 00:05:27.594 align:middle line:-1
而不是让你等整个发布周期

00:05:29.162 --> 00:05:31.465 align:middle line:-1
现在我们已经介绍了社区的更新

00:05:31.532 --> 00:05:35.802 align:middle line:-1
我想更深入介绍下我们对于

00:05:36.069 --> 00:05:40.440 align:middle line:-2
ResearchKit框架本身所做的更新
从用户界面更新开始

00:05:41.775 --> 00:05:46.113 align:middle line:-2
作为比较
这是我们的迷你表格步骤

00:05:46.380 --> 00:05:50.784 align:middle line:-2
在ResearchKit 1.5中的样子
它是从ORK测试app中得到的

00:05:51.718 --> 00:05:53.787 align:middle line:-1
而这是相同的迷你表格步骤

00:05:54.354 --> 00:05:57.391 align:middle line:-2
在ResearchKit
2.0中的样子

00:05:58.592 --> 00:06:04.264 align:middle line:-2
如你所见
我们非常努力地在更新整个视图

00:05:58.592 --> 00:06:04.264 align:middle line:-2
如你所见
我们非常努力地在更新整个视图

00:06:04.331 --> 00:06:09.069 align:middle line:-2
让ResearchKit的界面
更接近最新的iOS样式指引

00:06:09.703 --> 00:06:11.104 align:middle line:-1
让我们仔细看一下

00:06:13.574 --> 00:06:16.610 align:middle line:-1
我们将进度标签从导航条的中心

00:06:16.677 --> 00:06:18.612 align:middle line:-1
移到了右边 并且做了一些修饰

00:06:19.313 --> 00:06:23.517 align:middle line:-1
这让我们补充了导航条的大标题功能

00:06:23.784 --> 00:06:26.186 align:middle line:-1
并将其app到我们的所有步骤标题中

00:06:26.987 --> 00:06:31.525 align:middle line:-2
为了保持一致的样式
我们还添加了一个新的卡片视图

00:06:31.992 --> 00:06:34.761 align:middle line:-1
用以改善整体的用户体验

00:06:34.828 --> 00:06:38.365 align:middle line:-1
对那些回答多个问题和调查问卷的人

00:06:38.565 --> 00:06:42.736 align:middle line:-2
因为它提供了一个你想要实现的
清晰的间断

00:06:44.505 --> 00:06:49.409 align:middle line:-2
这个卡片视图被默认app到
我们所有的步骤和表格中

00:06:49.476 --> 00:06:51.912 align:middle line:-1
我们还有一个新的布林属性

00:06:52.179 --> 00:06:54.882 align:middle line:-1
你可以将其设为假来保证向下兼容性

00:06:55.616 --> 00:06:59.119 align:middle line:-1
最后我们还加入了一个页脚容器视图

00:06:59.486 --> 00:07:01.355 align:middle line:-1
来改进导航流

00:06:59.486 --> 00:07:01.355 align:middle line:-1
来改进导航流

00:07:01.822 --> 00:07:04.391 align:middle line:-1
取消按钮现在是页脚视图的一部分了

00:07:04.591 --> 00:07:06.426 align:middle line:-1
它会一直固定在底部

00:07:06.927 --> 00:07:09.029 align:middle line:-1
这就意味着你的用户

00:07:09.229 --> 00:07:12.533 align:middle line:-1
再也不用一直拉动到步骤的底部

00:07:13.066 --> 00:07:15.636 align:middle line:-1
来进入后面的导航选项了

00:07:15.936 --> 00:07:20.607 align:middle line:-2
把所有的控制功能放到一起
使其更为直观了

00:07:22.042 --> 00:07:23.143 align:middle line:-1
而接下来

00:07:23.577 --> 00:07:28.482 align:middle line:-2
在ResearchKit最常用到
的组件之一就是“知情同意”

00:07:29.149 --> 00:07:33.253 align:middle line:-1
它来生成PDF文件并附上用户签名

00:07:33.887 --> 00:07:37.558 align:middle line:-1
我们意识到在你的app中

00:07:37.624 --> 00:07:40.460 align:middle line:-1
向你的用户调查一些机密文件

00:07:40.827 --> 00:07:42.496 align:middle line:-1
是多么重要

00:07:42.763 --> 00:07:46.934 align:middle line:-2
这也是我们为什么加入了
一个新的ORK PDF浏览器步骤

00:07:47.467 --> 00:07:52.105 align:middle line:-2
它构建于去年推出的
PDFKit框架之上

00:07:52.873 --> 00:07:55.876 align:middle line:-1
让我们仔细看一些功能吧

00:07:55.943 --> 00:07:57.211 align:middle line:-1
这个步骤所提供的

00:07:59.546 --> 00:08:02.482 align:middle line:-1
用于轻松在页面间切换的快速导航

00:07:59.546 --> 00:08:02.482 align:middle line:-1
用于轻松在页面间切换的快速导航

00:08:03.617 --> 00:08:07.187 align:middle line:-1
在需要时来标记文档的实时备注功能

00:08:08.055 --> 00:08:09.857 align:middle line:-1
搜索功能 让你的用户

00:08:09.923 --> 00:08:12.960 align:middle line:-1
通过关键词或短语来检索整个文档

00:08:13.427 --> 00:08:16.797 align:middle line:-1
以及分享或保存PDF

00:08:16.964 --> 00:08:19.132 align:middle line:-1
利用标准iOS共享表单

00:08:19.700 --> 00:08:24.271 align:middle line:-1
更棒的是将其放入你的app非常简单

00:08:25.372 --> 00:08:28.275 align:middle line:-2
你需要创建一个
ORKPDFViewerStep实例

00:08:28.342 --> 00:08:29.910 align:middle line:-1
一个唯一的标识符

00:08:30.344 --> 00:08:32.246 align:middle line:-1
然后提供给我们

00:08:32.312 --> 00:08:34.548 align:middle line:-1
你想要显示的PDF文档的文件路径

00:08:36.250 --> 00:08:39.019 align:middle line:-1
现在我想要换个话题

00:08:39.385 --> 00:08:42.856 align:middle line:-2
介绍下ResearchKit的
一个核心组件

00:08:44.291 --> 00:08:45.325 align:middle line:-1
当前任务

00:08:46.159 --> 00:08:51.231 align:middle line:-2
你们当中有人可能不熟悉
当前任务是个预封装的模块

00:08:51.431 --> 00:08:56.170 align:middle line:-1
能让用户执行特定任务或特定测试

00:08:56.436 --> 00:08:57.938 align:middle line:-1
在给定的时间内

00:08:58.505 --> 00:09:01.842 align:middle line:-2
当用户完成这个步骤时
开发者会收到

00:08:58.505 --> 00:09:01.842 align:middle line:-2
当用户完成这个步骤时
开发者会收到

00:09:01.909 --> 00:09:04.945 align:middle line:-2
一个包含了ORKResult对象
的回调函数

00:09:05.646 --> 00:09:07.915 align:middle line:-1
这个对象由一些数据点组成

00:09:07.981 --> 00:09:12.019 align:middle line:-1
包括像是用户响应、定时信息

00:09:12.085 --> 00:09:16.623 align:middle line:-2
以及从不同源录制的数据
像是加速计、陀螺仪

00:09:17.057 --> 00:09:19.193 align:middle line:-1
治疗数据 甚至是你的麦克风

00:09:20.194 --> 00:09:24.031 align:middle line:-2
今年我们还加入了
对于健康记录的支持

00:09:24.898 --> 00:09:28.268 align:middle line:-2
现在让我们看下
在你的app中应该如何使用它

00:09:28.802 --> 00:09:30.871 align:middle line:-1
你的目标是要创建

00:09:30.938 --> 00:09:35.309 align:middle line:-2
一个记录配置
来查询健康诊断数据类型

00:09:35.709 --> 00:09:38.445 align:middle line:-1
你需要向我们提供两个重要参数

00:09:38.745 --> 00:09:40.948 align:middle line:-2
第一个是
HKClinicalType

00:09:41.481 --> 00:09:45.519 align:middle line:-2
第二个是可选的
HKFHIRResourceType

00:09:46.386 --> 00:09:48.956 align:middle line:-1
在你创建了这个记录配置后

00:09:49.156 --> 00:09:50.624 align:middle line:-1
你可以把它加到步骤中

00:09:51.158 --> 00:09:54.461 align:middle line:-1
现在当用户要执行任务的时候

00:09:54.761 --> 00:09:58.532 align:middle line:-2
他们就会看到HealthKit的
新授权用户界面

00:09:59.066 --> 00:10:02.703 align:middle line:-1
他们只有允许访问才能执行查询

00:09:59.066 --> 00:10:02.703 align:middle line:-1
他们只有允许访问才能执行查询

00:10:03.237 --> 00:10:05.038 align:middle line:-1
而在用户完成任务后

00:10:05.272 --> 00:10:08.275 align:middle line:-2
作为你ORKResult对象中
代理回调的一部分

00:10:08.575 --> 00:10:12.813 align:middle line:-2
你还会从健康记录中
得到你请求的信息

00:10:13.614 --> 00:10:17.885 align:middle line:-2
为了更好理解和学习
这些不同的健康记录类型

00:10:18.252 --> 00:10:22.823 align:middle line:0
我强烈建议你们去参加这个演讲

00:10:23.123 --> 00:10:27.394 align:middle line:0
“通过HealthKit访问 健康数据”
该演讲下午三点开始

00:10:27.661 --> 00:10:31.632 align:middle line:0
它会详细介绍健康记录的所有内容

00:10:31.698 --> 00:10:34.301 align:middle line:-1
包括了一些很重要的app

00:10:35.802 --> 00:10:37.104 align:middle line:-1
我们现在已经介绍了

00:10:37.471 --> 00:10:40.207 align:middle line:-1
当前任务模块的整体更新

00:10:41.875 --> 00:10:44.478 align:middle line:-1
让我来介绍下当前任务本身吧

00:10:45.012 --> 00:10:50.017 align:middle line:-2
我们今年添加了聚焦于
健康三个主要领域的新模块

00:10:50.717 --> 00:10:53.320 align:middle line:-1
听力、语言表达以及视力

00:10:54.321 --> 00:10:55.789 align:middle line:-1
让我们从听力开始说

00:10:57.624 --> 00:11:01.828 align:middle line:-2
我们添加了一个新的
dBHL声调测听步骤

00:10:57.624 --> 00:11:01.828 align:middle line:-2
我们添加了一个新的
dBHL声调测听步骤

00:11:02.563 --> 00:11:05.265 align:middle line:-1
其实现了降十升五方法

00:11:05.666 --> 00:11:07.134 align:middle line:-1
并且让你决定

00:11:07.201 --> 00:11:11.205 align:middle line:-1
用户在dBHL量程内的听力阈值

00:11:12.606 --> 00:11:16.877 align:middle line:-2
为了实现这一点
并且确保你得到最精确的结果

00:11:17.211 --> 00:11:20.080 align:middle line:-1
我非常激动地说

00:11:20.547 --> 00:11:24.017 align:middle line:-2
我们首次开源了
AirPods的校准数据

00:11:24.618 --> 00:11:26.887 align:middle line:-1
有三个表格

00:11:27.254 --> 00:11:32.426 align:middle line:-2
第一个是AirPods
在所有iOS设备上的音量曲线

00:11:32.893 --> 00:11:36.129 align:middle line:-1
第二个是每频率的敏感度

00:11:36.196 --> 00:11:39.633 align:middle line:-2
这里的敏感度是以
分贝声压级别来测量的

00:11:40.000 --> 00:11:42.035 align:middle line:-1
最后我们还提供了

00:11:42.269 --> 00:11:47.040 align:middle line:-2
参考同声压级表单
或者叫RETSPL

00:11:48.642 --> 00:11:53.614 align:middle line:-2
需要注意的是
RETSPL表仍在测试中

00:11:54.348 --> 00:11:58.385 align:middle line:-2
这意味着我们在积极地运行
内部校验和测试

00:11:58.652 --> 00:11:59.853 align:middle line:-1
在接下来的数周内

00:11:59.920 --> 00:12:04.491 align:middle line:-2
随着我们集中精确的数据
我们会更新这些表

00:11:59.920 --> 00:12:04.491 align:middle line:-2
随着我们集中精确的数据
我们会更新这些表

00:12:05.926 --> 00:12:09.596 align:middle line:-2
现在让我们看下
当前任务是怎么运作的

00:12:10.764 --> 00:12:13.567 align:middle line:-1
用户需要听声调

00:12:14.067 --> 00:12:18.572 align:middle line:-1
在特定频率不同的分贝值

00:12:19.306 --> 00:12:20.674 align:middle line:-1
当用户听到一个声调时

00:12:20.741 --> 00:12:23.911 align:middle line:-2
他们要按下按钮
来表示他们听到了声音

00:12:24.278 --> 00:12:27.648 align:middle line:-1
这时候我们会开始降低分贝值

00:12:27.915 --> 00:12:30.284 align:middle line:-1
就像是这里的绿点所表示的那样

00:12:30.784 --> 00:12:35.222 align:middle line:-1
当用户没能在给定时间内点击按钮时

00:12:35.289 --> 00:12:39.293 align:middle line:-2
我们会如红点所示那样
开始提高分贝值

00:12:39.593 --> 00:12:41.929 align:middle line:-1
我们会将这些数据点提供给

00:12:41.995 --> 00:12:44.965 align:middle line:-1
降十升五方法来决定

00:12:45.032 --> 00:12:48.535 align:middle line:-1
用户以分贝计的听力阈值

00:12:52.005 --> 00:12:53.774 align:middle line:-1
从开发者的角度

00:12:54.041 --> 00:12:57.845 align:middle line:-1
整个声调的产生发生在三个阶段

00:12:58.445 --> 00:13:00.981 align:middle line:-1
首先第一个是预刺激延迟

00:12:58.445 --> 00:13:00.981 align:middle line:-1
首先第一个是预刺激延迟

00:13:01.381 --> 00:13:04.685 align:middle line:-2
这是个以秒计的开发者定义的
最大数值

00:13:04.952 --> 00:13:09.356 align:middle line:-2
我们用它来生成一个
从1到该值间的随机延迟

00:13:09.423 --> 00:13:11.592 align:middle line:-1
在我们将该声调播放给用户之前

00:13:12.292 --> 00:13:14.895 align:middle line:-1
这是为了确保用户不会欺骗测试

00:13:15.162 --> 00:13:17.030 align:middle line:-1
通过随机点击按钮

00:13:18.599 --> 00:13:22.102 align:middle line:-1
我们还提供了一个声调持续的属性

00:13:22.169 --> 00:13:25.405 align:middle line:-1
其监控了播放声调的实际持续时间

00:13:26.173 --> 00:13:30.244 align:middle line:-1
最后就是后刺激延迟 也就是

00:13:30.310 --> 00:13:34.081 align:middle line:-1
用户响应特定声调的时间

00:13:35.082 --> 00:13:36.817 align:middle line:-1
为了在你的app中实现

00:13:37.684 --> 00:13:41.922 align:middle line:-2
你需要创建一个
ORKdBHLToneAudiometryStep实例

00:13:41.989 --> 00:13:46.560 align:middle line:-2
一个唯一的标识符
并提供我们一些参数值

00:13:46.627 --> 00:13:50.297 align:middle line:-1
包括频率表 也就是一个频率数组

00:13:50.731 --> 00:13:52.766 align:middle line:-1
你想要将其回播给你的用户

00:13:53.367 --> 00:13:55.169 align:middle line:-1
我们还有更多的属性

00:13:55.235 --> 00:13:58.605 align:middle line:-1
你可以定制你特有的用例

00:14:00.541 --> 00:14:04.011 align:middle line:-2
当用户完成这项任务时
作为代理回调的一部分

00:14:04.511 --> 00:14:06.947 align:middle line:-2
ORKResult对象
会被返回给你

00:14:07.414 --> 00:14:11.251 align:middle line:-2
让我们看看
这个任务中的对象是什么样的

00:14:12.085 --> 00:14:13.253 align:middle line:-1
在最上层 你会得到

00:14:13.320 --> 00:14:16.490 align:middle line:-2
很多信息
包括像是输出音量

00:14:16.924 --> 00:14:19.893 align:middle line:-1
还有示例对象的数组

00:14:20.527 --> 00:14:24.731 align:middle line:-1
这些对象会封装像是声道这类东西

00:14:24.798 --> 00:14:28.769 align:middle line:-2
也就是声音是从左还是右声道
播放给用户的

00:14:29.436 --> 00:14:30.871 align:middle line:-1
还有阈值

00:14:30.938 --> 00:14:33.106 align:middle line:-1
其是由降十升五方法决定的

00:14:33.807 --> 00:14:36.643 align:middle line:-1
它也是由单元对象数组组成的

00:14:37.344 --> 00:14:41.348 align:middle line:-2
而单元对象会提供
像是分贝值这样的细节

00:14:41.648 --> 00:14:44.051 align:middle line:-1
在该分贝下 特定的声调被播放

00:14:44.117 --> 00:14:45.752 align:middle line:-1
还有很多的时间戳

00:14:45.819 --> 00:14:49.823 align:middle line:-1
它包含了用户是何时点击按钮的

00:14:51.091 --> 00:14:55.696 align:middle line:-2
接下来让我们介绍听力类的
下一个任务

00:14:56.363 --> 00:14:59.199 align:middle line:-1
我们加入了一个环境SPL测量计

00:15:00.334 --> 00:15:02.903 align:middle line:-1
它实现了一个A级过滤器

00:15:03.136 --> 00:15:07.174 align:middle line:-1
用来以分贝测量环境的声压级别

00:15:07.808 --> 00:15:10.410 align:middle line:-1
换句话说 它告诉你有多吵

00:15:11.011 --> 00:15:14.314 align:middle line:-1
这个步骤现在还接受了阈值

00:15:14.848 --> 00:15:16.483 align:middle line:-1
这让事情变得有趣了

00:15:16.550 --> 00:15:20.187 align:middle line:-2
因为你现在可以将该步骤
作为门户步骤了

00:15:20.754 --> 00:15:24.858 align:middle line:-2
例如 如果你想让你的用户
执行声调测听任务

00:15:25.225 --> 00:15:29.696 align:middle line:-2
你可以在此之前加入这个任务
以确保你的用户不会

00:15:29.763 --> 00:15:33.600 align:middle line:-2
处于一个太吵的环境
以至于影响任务执行的精确性

00:15:36.403 --> 00:15:40.407 align:middle line:-2
要加入这个任务 你需要创建一个
ORKEnvironmentSPLMeterStep实例

00:15:40.474 --> 00:15:43.944 align:middle line:-2
一个唯一的标识符
并向我们提供阈值

00:15:44.845 --> 00:15:48.482 align:middle line:-2
我们还有一些
你可以后面定制用的属性

00:15:50.317 --> 00:15:55.889 align:middle line:-2
现在让我们换个话题
转到下一个分类 讲话

00:15:57.191 --> 00:15:59.960 align:middle line:-1
我们加入了一个语音识别模块

00:16:00.327 --> 00:16:03.797 align:middle line:-1
其利用了iOS上的语音识别框架

00:16:04.064 --> 00:16:08.368 align:middle line:-1
它让我们可直接访问实时语音识别器

00:16:08.435 --> 00:16:11.438 align:middle line:-1
它支持超过50种不同的语言

00:16:12.206 --> 00:16:14.474 align:middle line:-1
作为这个任务的一部分

00:16:14.541 --> 00:16:18.445 align:middle line:-1
用户要重复一个句子或描述一个图像

00:16:19.213 --> 00:16:20.914 align:middle line:-1
在他们说完之后

00:16:21.315 --> 00:16:24.818 align:middle line:-1
用户会自动进入下一步

00:16:25.352 --> 00:16:28.222 align:middle line:-1
他们可以编辑生成的脚本

00:16:28.822 --> 00:16:31.425 align:middle line:-1
例如在本例中 quick和fox

00:16:31.491 --> 00:16:34.027 align:middle line:-1
被错误理解成quiet和box

00:16:34.494 --> 00:16:38.866 align:middle line:-2
你的用户可以点击这些词
如果需要的话还可以编辑

00:16:40.234 --> 00:16:42.669 align:middle line:-2
需要注意的是
作为此项任务的一部分

00:16:42.736 --> 00:16:44.104 align:middle line:-1
我们会返回给你

00:16:44.438 --> 00:16:48.075 align:middle line:-2
一个非常丰富的数据集
包括三个主要内容

00:16:48.976 --> 00:16:51.645 align:middle line:-1
一个用户所说内容的直接录音

00:16:52.412 --> 00:16:55.182 align:middle line:-1
由语音识别引擎生成的脚本

00:16:55.916 --> 00:16:58.585 align:middle line:-1
以及由用户编辑的脚本

00:17:00.387 --> 00:17:01.455 align:middle line:-1
要将其加入你的app

00:17:01.522 --> 00:17:04.758 align:middle line:-2
你需要创建一个
ORKSpeechRecognitionStep实例

00:17:04.825 --> 00:17:07.861 align:middle line:-2
并提供给我们一个用户界面图像
或一个字符串

00:17:08.829 --> 00:17:12.266 align:middle line:-1
你也能为此识别定制本地化

00:17:12.900 --> 00:17:15.903 align:middle line:-1
并且你还可以得到实时脚本

00:17:15.969 --> 00:17:17.237 align:middle line:-1
随着用户讲话

00:17:18.605 --> 00:17:20.406 align:middle line:-1
让我们详细看下

00:17:20.473 --> 00:17:23.343 align:middle line:-1
我们结果对象的一个子集吧

00:17:24.545 --> 00:17:26.780 align:middle line:-1
这是SFTranscription类型

00:17:27.047 --> 00:17:29.416 align:middle line:-1
由语音识别框架所展现的

00:17:29.883 --> 00:17:32.219 align:middle line:-1
该格式化字符串提供了脚本

00:17:32.553 --> 00:17:34.321 align:middle line:-1
以及分段对象数组

00:17:34.555 --> 00:17:37.658 align:middle line:-1
将脚本分成了子字符串

00:17:37.925 --> 00:17:41.028 align:middle line:-2
还为每个子字符串
提供了一个保密等级

00:17:41.595 --> 00:17:45.299 align:middle line:-2
在这之上
它们还提供了一个替代字符串的数组

00:17:45.632 --> 00:17:48.068 align:middle line:-1
在这个解释例子中 你们可以看到

00:17:49.603 --> 00:17:53.907 align:middle line:-1
这些结果可以用来获取句法、文法的

00:17:54.174 --> 00:17:56.944 align:middle line:-1
语言学功能 还有讲话速率

00:17:57.444 --> 00:18:02.082 align:middle line:-1
以评估在不同医疗情况下的说话模式

00:17:57.444 --> 00:18:02.082 align:middle line:-1
以评估在不同医疗情况下的说话模式

00:18:02.149 --> 00:18:04.117 align:middle line:-1
包括认知和情绪

00:18:07.120 --> 00:18:12.526 align:middle line:-2
有趣的是 我们的下一个任务
是说话和听力的结合

00:18:13.861 --> 00:18:15.829 align:middle line:-1
讲话与噪音当前任务

00:18:16.597 --> 00:18:20.400 align:middle line:-1
这能让你实现完全自动化的语音测听

00:18:21.668 --> 00:18:25.639 align:middle line:-1
传统的声音测听使用纯声音

00:18:25.706 --> 00:18:27.541 align:middle line:-1
也就是记号波形

00:18:28.141 --> 00:18:29.843 align:middle line:-1
对于录好的实例

00:18:29.910 --> 00:18:32.946 align:middle line:-1
用户可以清晰地分辨纯语音

00:18:33.013 --> 00:18:35.849 align:middle line:-1
但是要分辨词语非常困难

00:18:36.049 --> 00:18:37.885 align:middle line:-1
当这些词语跟噪音混在一起的时候

00:18:38.919 --> 00:18:40.621 align:middle line:-1
这很接近于

00:18:40.687 --> 00:18:44.525 align:middle line:-1
现实世界中早期听力下降的例子

00:18:44.825 --> 00:18:47.928 align:middle line:-1
例如 在一个吵闹的餐厅里

00:18:47.995 --> 00:18:51.698 align:middle line:-2
当你不能理解
坐在你前面的人在说什么时

00:18:52.966 --> 00:18:54.902 align:middle line:-1
在我详细介绍之前

00:18:54.968 --> 00:18:58.238 align:middle line:-2
让我们来看看
这个任务是如何运作的

00:19:03.877 --> 00:19:05.746 align:middle line:-1
行动器尝试了三张绿色的图片

00:19:08.215 --> 00:19:11.151 align:middle line:-2
正如你所看到的
一个音频文件被播放给用户

00:19:11.318 --> 00:19:12.352 align:middle line:-1
而在完成了之后

00:19:12.419 --> 00:19:15.756 align:middle line:-2
他们会被要求立即
重复他们刚刚听到的内容

00:19:17.858 --> 00:19:23.664 align:middle line:-1
语音和噪音当前任务使用音频文件

00:19:23.730 --> 00:19:28.068 align:middle line:-2
这些音频文件是由一个闭集矩阵的
五个词语组成 它们被内部校验了

00:19:28.135 --> 00:19:32.539 align:middle line:-1
像是词语相似度、一致性、困难度

00:19:32.806 --> 00:19:36.777 align:middle line:-1
还有确保由同步器生成的句子

00:19:37.244 --> 00:19:40.681 align:middle line:-2
发音更平衡
更重要的是 是一致的

00:19:41.982 --> 00:19:44.518 align:middle line:-1
这些文件然后被用程序混合

00:19:44.585 --> 00:19:49.256 align:middle line:-2
与背景噪音一起
在不同的信噪比或SNR之下

00:19:50.157 --> 00:19:51.491 align:middle line:-1
开发者也可以

00:19:51.558 --> 00:19:56.063 align:middle line:-1
为所有的噪音信号设置增益的值

00:19:58.098 --> 00:20:03.270 align:middle line:-2
语音接收阈值
被定义为SNR中的最小值

00:19:58.098 --> 00:20:03.270 align:middle line:-2
语音接收阈值
被定义为SNR中的最小值

00:20:03.470 --> 00:20:07.641 align:middle line:-1
用户只能理解50%的口述词语

00:20:10.077 --> 00:20:13.981 align:middle line:-2
我们这个测试的愿景是
在接下来的几周内

00:20:14.047 --> 00:20:17.784 align:middle line:-1
我们会上传超过175个不同的文件

00:20:18.785 --> 00:20:22.222 align:middle line:-2
对应了25个列表
每个都有7个句子

00:20:22.623 --> 00:20:23.724 align:middle line:-1
而从长远来看

00:20:24.057 --> 00:20:27.661 align:middle line:-1
我们希望这个测试能够支持多种语言

00:20:27.961 --> 00:20:31.865 align:middle line:-2
特别是目前那些言语
和噪音是不能实现的

00:20:32.165 --> 00:20:35.936 align:middle line:-1
由于缺乏语音数据库或其他测试资源

00:20:36.436 --> 00:20:39.306 align:middle line:-1
如果你是这个特定领域的研究者

00:20:39.540 --> 00:20:41.708 align:middle line:-1
并且你对特定的区域设置有需求

00:20:42.309 --> 00:20:44.478 align:middle line:-1
我强烈建议你与我们联系

00:20:44.678 --> 00:20:46.914 align:middle line:-1
我们会尽力达成您的要求

00:20:49.550 --> 00:20:50.651 align:middle line:-1
要将这个功能加入你的app

00:20:50.717 --> 00:20:53.353 align:middle line:-2
你需要创建一个
ORKSpeechInNoiseStep实例

00:20:53.921 --> 00:20:56.290 align:middle line:-1
并将我们指向你想播放的音频文件

00:20:56.723 --> 00:20:59.960 align:middle line:-2
你也可以指定
app于噪声信号的增益

00:21:02.496 --> 00:21:05.098 align:middle line:-1
最后 让我们来介绍下视觉

00:21:06.600 --> 00:21:09.970 align:middle line:-1
Amsler网格是一种工具

00:21:10.270 --> 00:21:13.740 align:middle line:-1
用于检测在用户视野中的问题

00:21:13.807 --> 00:21:19.379 align:middle line:-2
可能是由于像黄斑变性
这种问题造成的

00:21:20.547 --> 00:21:25.586 align:middle line:-1
这个测试通常在医生的办公室进行

00:21:25.819 --> 00:21:27.387 align:middle line:-1
在一张传统的纸上

00:21:27.454 --> 00:21:30.057 align:middle line:-2
显示一个图形
就像你在这里看到的那样

00:21:30.891 --> 00:21:34.127 align:middle line:-2
视力好的用户
会看清楚这个图形

00:21:34.361 --> 00:21:36.730 align:middle line:-1
而受到某些疾病困扰的用户

00:21:36.930 --> 00:21:39.433 align:middle line:-1
会开始在这张图上看到扭曲

00:21:40.167 --> 00:21:43.837 align:middle line:-2
如果你现在看到扭曲
请不要惊慌

00:21:44.271 --> 00:21:47.140 align:middle line:-2
这是故意的
为了添加戏剧效果

00:21:48.075 --> 00:21:51.812 align:middle line:-2
用户只需指向
他们看到的网格上的扭曲

00:21:52.212 --> 00:21:55.549 align:middle line:-2
通过复制这个网格
我们能够将

00:21:55.616 --> 00:21:59.620 align:middle line:-2
这个任务的功能带到
用户家中的设备上

00:21:59.987 --> 00:22:03.891 align:middle line:-2
用户只需在他们看到扭曲的网格上
标注区域

00:21:59.987 --> 00:22:03.891 align:middle line:-2
用户只需在他们看到扭曲的网格上
标注区域

00:22:05.025 --> 00:22:10.330 align:middle line:-2
我们相信开发者可以
利用一些令人兴奋的iOS功能

00:22:10.631 --> 00:22:12.866 align:middle line:-2
像是压力按压
或是深度感测相机

00:22:13.133 --> 00:22:18.005 align:middle line:-1
来增加正在进行这一任务的用户体验

00:22:19.306 --> 00:22:20.908 align:middle line:-1
所有这些当前任务

00:22:20.974 --> 00:22:24.611 align:middle line:-1
用于数据收集和分析真的很棒

00:22:25.345 --> 00:22:30.117 align:middle line:-2
但它们被设计成要在给定时间段
的特定时间执行

00:22:31.251 --> 00:22:35.322 align:middle line:-2
当我们研究具体问题时
我们意识到

00:22:35.389 --> 00:22:39.860 align:middle line:-2
一些更复杂的健康问题
需要不断监测

00:22:40.127 --> 00:22:45.299 align:middle line:-2
因此我们引入了
被动、非侵入性数据收集

00:22:45.999 --> 00:22:47.301 align:middle line:-1
为了介绍更多的相关信息

00:22:47.534 --> 00:22:49.837 align:middle line:-1
我想请Gabriel上台来

00:22:56.577 --> 00:22:57.411 align:middle line:-1
大家好

00:22:57.911 --> 00:23:01.315 align:middle line:-2
我叫Gabriel
我代表Core Motion团队

00:22:57.911 --> 00:23:01.315 align:middle line:-2
我叫Gabriel
我代表Core Motion团队

00:23:01.582 --> 00:23:04.051 align:middle line:-1
来介绍一个新的研究API

00:23:04.585 --> 00:23:05.919 align:middle line:-1
运动障碍API

00:23:09.089 --> 00:23:13.193 align:middle line:-2
正如Srinath所提及的
这是个被动的 全天监测的API

00:23:13.760 --> 00:23:15.329 align:middle line:-1
在Apple Watch上可用

00:23:15.596 --> 00:23:18.765 align:middle line:-2
这将允许你监测
运动障碍的症状

00:23:19.066 --> 00:23:21.602 align:middle line:-1
特别是两种运动障碍

00:23:21.802 --> 00:23:24.738 align:middle line:-1
跟帕金森病的研究有关

00:23:25.672 --> 00:23:29.710 align:middle line:-2
因为现在有针对性的用例
作为研究API

00:23:30.244 --> 00:23:32.579 align:middle line:-2
你需要申请一个
特殊的代码签名权利

00:23:32.880 --> 00:23:34.314 align:middle line:-1
来使用这个API

00:23:35.115 --> 00:23:38.352 align:middle line:-2
这个app将会
在Apple开发者门户网站完成

00:23:38.652 --> 00:23:39.920 align:middle line:-1
从第二波开始

00:23:40.687 --> 00:23:43.323 align:middle line:-2
如果你等不及了
我也不怪你

00:23:44.224 --> 00:23:47.694 align:middle line:-2
将会有样本数据集
以及可用的演示代码

00:23:47.761 --> 00:23:50.864 align:middle line:-2
在ResearchKit
这个演讲的GitHub仓库里

00:23:51.965 --> 00:23:55.936 align:middle line:-2
让我们来谈论下
这两个运动障碍症状

00:23:58.939 --> 00:23:59.840 align:middle line:-1
正如你们有些人可能知道的那样

00:24:00.474 --> 00:24:03.410 align:middle line:-1
帕金森病是一种退行性神经疾病

00:24:03.911 --> 00:24:06.813 align:middle line:-1
这会影响受疾病困扰患者的运动机能

00:24:07.781 --> 00:24:11.752 align:middle line:-2
帕金森病的其中一种可识别症状
是震颤

00:24:12.219 --> 00:24:17.391 align:middle line:-2
此API监测静止时的震颤
其特征在于

00:24:17.691 --> 00:24:23.497 align:middle line:-2
当某人不想移动
而身体产生抖动

00:24:24.665 --> 00:24:28.302 align:middle line:-2
现在 有相应的治疗措施
包括药物治疗

00:24:28.635 --> 00:24:32.206 align:middle line:-2
可以帮助抑制和控制
帕金森症状

00:24:32.673 --> 00:24:36.910 align:middle line:-2
然而 这些非常相似的治疗
往往会产生不良的副作用

00:24:37.644 --> 00:24:40.047 align:middle line:-1
例如运动障碍

00:24:41.682 --> 00:24:45.452 align:middle line:-2
这个API可以监控的
一种运动障碍症状

00:24:45.886 --> 00:24:49.690 align:middle line:-2
就是表现出烦躁以及身体摇摆
被称作舞蹈病样综合征

00:24:50.924 --> 00:24:55.629 align:middle line:-2
那么让我们回顾一下 你有震颤
这种疾病的表现

00:24:55.963 --> 00:24:59.333 align:middle line:-2
以及运动障碍
治疗后产生的副作用

00:25:00.334 --> 00:25:04.571 align:middle line:-2
让我们看下
研究人员和临床医生目前用到的工具

00:25:04.638 --> 00:25:05.873 align:middle line:-1
来评估这些症状

00:25:08.842 --> 00:25:11.845 align:middle line:-2
通常这些类型的评估
是在诊所完成的

00:25:12.479 --> 00:25:15.749 align:middle line:-2
临床医生会要求
帕金森病患者

00:25:16.049 --> 00:25:18.986 align:middle line:-1
进行物理诊断测试

00:25:19.186 --> 00:25:22.389 align:middle line:-2
以评估
他们状况的严重程度

00:25:23.457 --> 00:25:28.195 align:middle line:-2
这些评级提供了量化数据
尽管受到评估者自身

00:25:28.262 --> 00:25:31.431 align:middle line:-2
以及在诊所
测量时的身体状况的影响

00:25:32.566 --> 00:25:34.735 align:middle line:-2
为了得到更广泛的
和更完整的描述

00:25:35.135 --> 00:25:37.371 align:middle line:-1
我们会鼓励患者坚持写日记

00:25:37.738 --> 00:25:39.540 align:middle line:-1
手动记录他们的症状

00:25:40.807 --> 00:25:42.876 align:middle line:-1
但是 这可能对于患者来说很麻烦

00:25:43.110 --> 00:25:45.279 align:middle line:-1
有些人可能会忘记 这很正常

00:25:45.345 --> 00:25:50.984 align:middle line:-1
或无法完整描述他们每天的症状

00:25:52.486 --> 00:25:53.320 align:middle line:-1
这不是很好吗

00:25:54.454 --> 00:25:59.960 align:middle line:-2
若有一种被动的、不引人注目的方式
来监测这些症状

00:26:01.128 --> 00:26:04.097 align:middle line:-1
通过使用运动障碍API

00:26:04.631 --> 00:26:07.301 align:middle line:-1
像你们一样的研究人员和开发人员

00:26:07.534 --> 00:26:11.004 align:middle line:-2
将能够构建app
来持续收集这些类型的数据

00:26:12.272 --> 00:26:16.310 align:middle line:-2
病人戴着Apple Watch时
不断收集

00:26:17.344 --> 00:26:20.614 align:middle line:-2
这不仅会给你一个量化的方式
测量这些症状

00:26:21.081 --> 00:26:24.151 align:middle line:-2
在这里显示
作为观察时间的百分比

00:26:24.685 --> 00:26:27.721 align:middle line:-1
它也会给你一个纵向的分析

00:26:27.921 --> 00:26:30.724 align:middle line:-1
你可以持续跟踪这些症状的变化

00:26:31.658 --> 00:26:35.362 align:middle line:-1
这些算法的设计和试用

00:26:35.629 --> 00:26:39.366 align:middle line:-2
来自于内部临床研究中
收集的帕金森患者的数据

00:26:40.367 --> 00:26:44.171 align:middle line:-2
我们希望你可以使用
这些工具和这些知识

00:26:44.438 --> 00:26:49.476 align:middle line:-2
来建立新的护理体验
用以提高

00:26:49.543 --> 00:26:50.844 align:middle line:-1
帕金森患者的生活质量

00:26:52.513 --> 00:26:54.248 align:middle line:-1
但是在你这么做之前

00:26:54.815 --> 00:26:56.984 align:middle line:-2
你需要知道
如何使用这个API 对吧？

00:26:57.684 --> 00:26:59.820 align:middle line:-1
那么 让我们看下代码

00:27:01.989 --> 00:27:05.526 align:middle line:-1
你首先需要做的是请求

00:27:05.592 --> 00:27:08.729 align:middle line:-2
来自用户的运动授权
以便使用他们的运动障碍数据

00:27:09.930 --> 00:27:14.334 align:middle line:-2
一旦你完成这些 你需要调用
monitorKinesias函数

00:27:14.635 --> 00:27:16.770 align:middle line:-1
以启用症状监测

00:27:17.738 --> 00:27:22.009 align:middle line:-2
现在这个症状监视器会打开
Apple Watch另外传感器

00:27:22.242 --> 00:27:25.479 align:middle line:-2
所以这会对你用户的电池寿命
产生影响

00:27:25.779 --> 00:27:28.549 align:middle line:-1
不过他们仍然可以收集一天的数据

00:27:28.615 --> 00:27:29.550 align:middle line:-1
仅充一次电

00:27:31.518 --> 00:27:34.955 align:middle line:-1
正如你所见 最长的录音时间为七天

00:27:35.589 --> 00:27:37.157 align:middle line:-1
我知道你们中的很多人将要进行

00:27:37.224 --> 00:27:39.259 align:middle line:-1
超过7天的研究

00:27:39.526 --> 00:27:43.530 align:middle line:-2
如果是这样 只要再次调用
monitorKinesias函数

00:27:43.730 --> 00:27:45.799 align:middle line:-1
来扩展你的数据收集间隔

00:27:47.234 --> 00:27:50.871 align:middle line:-2
这将开始在你的授意下
在用户的设备上

00:27:51.038 --> 00:27:53.106 align:middle line:-1
存储震颤和运动障碍结果

00:27:54.408 --> 00:27:56.076 align:middle line:-1
之后的某个时候 你将要

00:27:56.143 --> 00:27:59.146 align:middle line:-2
返回到该app
你也可以查询这些记录

00:27:59.379 --> 00:28:01.515 align:middle line:-2
让我们看下
查询函数是什么样的

00:27:59.379 --> 00:28:01.515 align:middle line:-2
让我们看下
查询函数是什么样的

00:28:04.218 --> 00:28:08.021 align:middle line:-2
如你所见 在这行
我们查询自我们上次查询起

00:28:08.088 --> 00:28:11.391 align:middle line:-1
新的存储在设备上的震颤记录

00:28:13.060 --> 00:28:16.563 align:middle line:-1
这些记录通过API存储在设备上

00:28:17.197 --> 00:28:19.566 align:middle line:-1
但在7天后失效

00:28:20.000 --> 00:28:21.702 align:middle line:-1
所以 在它失效之前

00:28:21.902 --> 00:28:24.605 align:middle line:-1
你需要获得这些数据的所有权

00:28:25.138 --> 00:28:29.276 align:middle line:-2
通过序列化它们
并将它们存储在这个设备上

00:28:29.610 --> 00:28:33.146 align:middle line:-2
或传输到不同的平台
这样你就可以将其可视化并进行分析

00:28:34.414 --> 00:28:38.852 align:middle line:-2
数据将返回给你
作为分钟长的对象的数组

00:28:39.286 --> 00:28:43.223 align:middle line:-2
所以一小时的数据
有60个结果对象

00:28:43.690 --> 00:28:46.660 align:middle line:-2
我们来看一看
其中一个结果对象是什么样的

00:28:52.165 --> 00:28:56.203 align:middle line:-2
正如你所看到的那样 结果对象
返回了时间的百分比

00:28:56.270 --> 00:28:59.806 align:middle line:-2
一分钟的百分比
该算法能够观察到

00:28:59.873 --> 00:29:02.943 align:middle line:-1
存在或不存在的症状

00:28:59.873 --> 00:29:02.943 align:middle line:-1
存在或不存在的症状

00:29:03.777 --> 00:29:07.347 align:middle line:-2
对于运动障碍 在右侧
你可以看到这很简单

00:29:07.981 --> 00:29:09.583 align:middle line:-1
可能或者不太可能

00:29:10.817 --> 00:29:12.419 align:middle line:-1
震颤给你更多的选择

00:29:12.853 --> 00:29:13.687 align:middle line:-1
让我们来看看

00:29:16.690 --> 00:29:20.494 align:middle line:-2
由于这个是在静止时的震颤
任何活动或混乱的动作

00:29:20.561 --> 00:29:23.263 align:middle line:-1
都会简单地返回未知百分比

00:29:23.730 --> 00:29:27.134 align:middle line:-2
这和我们使用微弱信号
是同一类别

00:29:27.201 --> 00:29:28.602 align:middle line:-1
我们无法做出决定

00:29:29.636 --> 00:29:32.573 align:middle line:-1
然而如果这个算法可以做出决定

00:29:32.639 --> 00:29:34.541 align:middle line:-1
它可以返回震颤的严重程度

00:29:34.842 --> 00:29:37.377 align:middle line:-1
范围从轻微到强烈

00:29:38.846 --> 00:29:44.117 align:middle line:-2
现在 为了给你展示
被动监视下的运动障碍API

00:29:44.418 --> 00:29:45.252 align:middle line:-1
能够与ResearchKit

00:29:45.319 --> 00:29:49.223 align:middle line:-2
的当前任务中的
主动监测结合使用

00:29:49.623 --> 00:29:52.025 align:middle line:-1
我想把Akshay请到舞台上

00:29:52.359 --> 00:29:56.163 align:middle line:-2
他将两者整合
成为一个一流的研究程序

00:30:03.470 --> 00:30:04.371 align:middle line:-1
大家好

00:30:04.438 --> 00:30:06.740 align:middle line:-1
欢迎来到护理研究进阶的演示

00:30:07.307 --> 00:30:09.676 align:middle line:-2
在这个演示中 我们会看到一些
ResearchKit更新

00:30:10.043 --> 00:30:12.246 align:middle line:-1
并创建运动障碍API

00:30:13.046 --> 00:30:14.948 align:middle line:-2
作为我们在GitHub仓库上
ResearchKit的一部分

00:30:15.282 --> 00:30:17.818 align:middle line:-2
我们已经添加
ORK帕金森的研究app

00:30:18.552 --> 00:30:20.854 align:middle line:-2
这个app实现了
运动障碍API

00:30:21.455 --> 00:30:24.791 align:middle line:-2
并可视化了
震颤和运动障碍

00:30:24.858 --> 00:30:26.226 align:middle line:-1
以及我们刚刚看到的症状数据点

00:30:26.827 --> 00:30:28.495 align:middle line:-2
我们现在看看
这个app长什么样

00:30:36.904 --> 00:30:37.938 align:middle line:-2
我们有一个
Apple Watch app

00:30:38.605 --> 00:30:40.674 align:middle line:-1
我们实现了运动障碍API

00:30:41.041 --> 00:30:43.277 align:middle line:-2
收集了震颤和运动障碍
症状数据点

00:30:43.510 --> 00:30:44.611 align:middle line:-1
并将它们发送给电话app

00:30:45.312 --> 00:30:48.515 align:middle line:-2
在iPhone app中
我们有一个调查问卷 一些主动任务

00:30:49.016 --> 00:30:51.919 align:middle line:-2
并且可视化了这些震颤
和运动障碍症状数据点

00:30:52.719 --> 00:30:56.023 align:middle line:-2
让我们看看代码是什么样的
对于这个演示 我们将

00:30:56.089 --> 00:30:58.859 align:middle line:-2
从一个基础乏味的平面app开始
并试着重建这个app

00:31:02.896 --> 00:31:05.232 align:middle line:-2
这是我的Xcode工作空间
如你们所见

00:31:05.299 --> 00:31:08.335 align:middle line:-2
在我的ResearchKit中
我有个帕金森研究app

00:31:08.969 --> 00:31:10.404 align:middle line:-2
我们有一个任务列表
viewController

00:31:10.904 --> 00:31:13.340 align:middle line:-2
我们将在那里添加
所有当前任务和问卷

00:31:13.807 --> 00:31:16.310 align:middle line:-2
一个graphviewController
我们将在那里进行可视化

00:31:16.376 --> 00:31:18.212 align:middle line:-2
这些震颤和运动障碍
症状数据点

00:31:18.679 --> 00:31:19.813 align:middle line:0
还有一个评估管理器

00:31:19.880 --> 00:31:22.349 align:middle line:0
我们将在那里实现
运动障碍API

00:31:23.884 --> 00:31:27.154 align:middle line:0
当帕金森病患者
或者说PD患者去看医生

00:31:27.454 --> 00:31:29.189 align:middle line:-1
他们会被问及一些特定的问题

00:31:29.590 --> 00:31:32.526 align:middle line:-1
这些问题包括他们日常生活的活动

00:31:32.593 --> 00:31:34.962 align:middle line:-1
例如从0到10分

00:31:35.028 --> 00:31:36.230 align:middle line:-1
今天你的痛苦程度如何

00:31:36.864 --> 00:31:38.932 align:middle line:-2
或者你有什么非运动症状
的感觉吗

00:31:39.666 --> 00:31:42.302 align:middle line:-2
我们已经在我们的app中
添加了这些问题的一个子集

00:31:42.836 --> 00:31:46.206 align:middle line:-1
这些问卷通常伴随着七次物理测试

00:31:46.273 --> 00:31:48.976 align:middle line:-2
其中一个物理测试
是评估讲话的清晰度

00:31:49.376 --> 00:31:52.246 align:middle line:-2
让我们继续并添加
语音识别当前任务

00:31:53.480 --> 00:31:54.882 align:middle line:-1
在我的任务列表视图控制器中

00:31:55.616 --> 00:31:58.085 align:middle line:-2
我会继续并添加
语音识别当前任务

00:31:58.652 --> 00:31:59.486 align:middle line:-1
如你所见

00:31:59.553 --> 00:32:02.422 align:middle line:-2
我们只加入了一个
ORKOrderedTask类型的语音识别

00:31:59.553 --> 00:32:02.422 align:middle line:-2
我们只加入了一个
ORKOrderedTask类型的语音识别

00:32:03.023 --> 00:32:07.027 align:middle line:-2
如果注意的话 其中一个参数
是语音识别器语言环境

00:32:07.394 --> 00:32:09.630 align:middle line:-2
这是由ResearchKit
提供的项目

00:32:09.897 --> 00:32:12.833 align:middle line:-1
表示所有支持的语言环境

00:32:12.900 --> 00:32:14.034 align:middle line:-1
被语音识别API所支持

00:32:14.401 --> 00:32:17.538 align:middle line:-1
让你作为开发者不必担心

00:32:17.604 --> 00:32:20.307 align:middle line:-2
你的语言环境是否
被这些语音识别API支持

00:32:21.408 --> 00:32:23.577 align:middle line:-2
现在 让我们接着介绍
评估管理器

00:32:24.945 --> 00:32:27.848 align:middle line:-2
正如Gabriel提到的那样
我们有一个叫做管理器的变量

00:32:27.915 --> 00:32:30.517 align:middle line:-2
CMMovementDisorderManager
类型的

00:32:31.218 --> 00:32:33.387 align:middle line:-2
如果你注意的话
我们有一个函数调用

00:32:33.453 --> 00:32:36.757 align:middle line:-2
monitorKinesias
方法来计算七天的最大持续时间

00:32:37.357 --> 00:32:39.226 align:middle line:-1
让我们在初始化程序中调用它

00:32:40.694 --> 00:32:45.399 align:middle line:-2
不管谁创建了一个
AssessmentManager类型的对象

00:32:45.666 --> 00:32:48.035 align:middle line:-2
都能开始震颤
和运动障碍症状查询

00:32:49.069 --> 00:32:50.470 align:middle line:-1
一旦我们收集了这些数据

00:32:50.537 --> 00:32:52.472 align:middle line:-2
我们也需要一个方法来查询
这些数据点

00:32:52.673 --> 00:32:55.509 align:middle line:-2
让我们继续添加一个方法
来查询这些数据

00:32:56.476 --> 00:33:01.215 align:middle line:-2
我添加了一个新的queryNewAssessments方法
我在那里调用queryTremor方法

00:32:56.476 --> 00:33:01.215 align:middle line:-2
我添加了一个新的queryNewAssessments方法
我在那里调用queryTremor方法

00:33:01.281 --> 00:33:05.052 align:middle line:-2
对于给定的开始日期和结束日期
和queryDyskineticSymptom方法

00:33:05.485 --> 00:33:07.087 align:middle line:-1
为相同的开始日期和结束日期

00:33:09.456 --> 00:33:12.693 align:middle line:-2
为了这个演示 我们已经运行了
这个查询并收集震颤

00:33:12.759 --> 00:33:15.596 align:middle line:-2
以及运动障碍症状数据点
并将它们保存为JSON文件的一部分

00:33:16.029 --> 00:33:19.733 align:middle line:-2
让我们接着使用这些JSON文件
来创建ResearchKit图表

00:33:20.868 --> 00:33:22.903 align:middle line:-2
我会转到
我的图形视图控制器

00:33:23.904 --> 00:33:26.507 align:middle line:-2
在这里 如你所见
我有一个createGraph方法

00:33:26.773 --> 00:33:29.710 align:middle line:-2
它可以读取JSON文件
并从它们创建ResearchKit图表

00:33:30.277 --> 00:33:32.045 align:middle line:-2
让我们在viewDidLoad中
调用这些方法

00:33:34.381 --> 00:33:36.950 align:middle line:-1
很好 现在让我们运行它

00:33:38.685 --> 00:33:41.355 align:middle line:-2
如你所见 我们添加了
语音识别当前任务

00:33:41.855 --> 00:33:44.157 align:middle line:-1
并添加了运动障碍API

00:33:44.925 --> 00:33:46.727 align:middle line:-1
这就是我们的帕金森研究app

00:33:47.027 --> 00:33:48.295 align:middle line:-1
我们在顶部有调查问卷

00:33:48.629 --> 00:33:50.397 align:middle line:-1
让我们运行一个问卷吧

00:33:51.765 --> 00:33:55.469 align:middle line:-2
如Srinath提到的 我们拥有
一包含所有调查项目的卡片视图

00:33:56.036 --> 00:34:00.641 align:middle line:-2
所有这些ResearchKit中
的步骤都坚持了iOS规范

00:33:56.036 --> 00:34:00.641 align:middle line:-2
所有这些ResearchKit中
的步骤都坚持了iOS规范

00:34:01.842 --> 00:34:04.411 align:middle line:-2
让我们快速完成这份问卷
这样就完成了

00:34:05.112 --> 00:34:07.614 align:middle line:-2
现在让我们接着看下
语音识别当前任务

00:34:08.382 --> 00:34:11.385 align:middle line:-2
讲述如何使用
语音识别步骤的前两个步骤

00:34:11.985 --> 00:34:13.754 align:middle line:-2
只要我按下
开始录制按钮

00:34:14.054 --> 00:34:15.589 align:middle line:-1
我会重复我看到的文字

00:34:17.791 --> 00:34:20.060 align:middle line:-1
敏捷的棕色狐狸跳过了懒狗

00:34:23.030 --> 00:34:25.799 align:middle line:-2
我跳转到了下一步
这是另一个转录步骤

00:34:26.099 --> 00:34:29.303 align:middle line:-2
如Srinath所说 这一步
是可选的并且可以被替换的

00:34:29.369 --> 00:34:32.773 align:middle line:-2
从任务中通过设置
允许编辑脚本属性为no

00:34:35.175 --> 00:34:38.679 align:middle line:-1
很好 让我们看看创建的这些图表

00:34:38.745 --> 00:34:40.714 align:middle line:-1
消除震颤和运动障碍症状数据点

00:34:40.981 --> 00:34:43.449 align:middle line:-2
由于ResearchKit图表
在水平模式下看起来非常棒

00:34:43.650 --> 00:34:46.687 align:middle line:-2
我会快速横置我的手机
让我们看看图表

00:34:47.454 --> 00:34:51.458 align:middle line:-2
在这里可以看到 我们有所有的震颤
和运动障碍症状数据点

00:34:51.525 --> 00:34:54.194 align:middle line:-2
在特定的一天
从早上7点到下午6点

00:34:54.995 --> 00:34:58.699 align:middle line:-2
我们可以看到轻微
轻度、中度和强烈震颤

00:34:58.966 --> 00:35:00.234 align:middle line:-1
也可能是运动障碍

00:34:58.966 --> 00:35:00.234 align:middle line:-1
也可能是运动障碍

00:35:01.335 --> 00:35:04.404 align:middle line:-2
很好 现在
我想把Srinath叫上台来

00:35:04.805 --> 00:35:05.873 align:middle line:-1
接着进行这个演讲

00:35:06.340 --> 00:35:07.174 align:middle line:-1
谢谢大家

00:35:08.976 --> 00:35:09.810 align:middle line:-1
谢谢 Akshay

00:35:12.946 --> 00:35:14.314 align:middle line:-1
感谢你精彩的演示

00:35:15.249 --> 00:35:19.319 align:middle line:-2
现在让我们回顾下
我们今天都谈了哪些内容

00:35:21.922 --> 00:35:24.992 align:middle line:-2
我们开始谈论了
我们向社区做出的更新

00:35:25.626 --> 00:35:29.096 align:middle line:-2
通过扩展特权
并更新我们的发布时间表

00:35:30.030 --> 00:35:33.000 align:middle line:-2
我们展示了ResearchKit
的新用户界面

00:35:33.567 --> 00:35:37.504 align:middle line:-2
并且我们还添加了一些新的当前任务
重点关注三个主要健康领域

00:35:37.838 --> 00:35:39.306 align:middle line:-1
听觉、言语和视觉

00:35:40.007 --> 00:35:42.910 align:middle line:-2
Gabriel和你们谈论了
新的运动障碍API

00:35:42.976 --> 00:35:46.380 align:middle line:-2
这在Apple Watch的
watchOS 5上可用

00:35:47.781 --> 00:35:52.953 align:middle line:-2
现在 我们期望
社区的现有成员和新成员

00:35:53.220 --> 00:35:55.923 align:middle line:-1
继续与我们互动并提供反馈

00:35:56.690 --> 00:36:00.360 align:middle line:-2
我们也鼓励你充分利用
我们新的发布时间表

00:35:56.690 --> 00:36:00.360 align:middle line:-2
我们也鼓励你充分利用
我们新的发布时间表

00:36:00.961 --> 00:36:04.631 align:middle line:-2
这样你就可以利用
我们的一些内部功能

00:36:04.898 --> 00:36:09.770 align:middle line:-1
比如辅助功能、定位和质量保证

00:36:10.838 --> 00:36:15.843 align:middle line:-2
这样的话 当我们继续
扩展我们的进展中的任务库

00:36:16.109 --> 00:36:20.180 align:middle line:-2
我们期待所有的开发者
研究人员和健康专家

00:36:20.480 --> 00:36:22.349 align:middle line:-1
帮助我们改进这些内容

00:36:22.816 --> 00:36:26.987 align:middle line:-2
这些任务就像是搭建积木
我们希望你可以利用它们

00:36:27.221 --> 00:36:31.992 align:middle line:-2
来创造更大的研究成果
护理计划和治疗机制

00:36:32.292 --> 00:36:36.663 align:middle line:-2
像你做的那样 我们鼓励你
回馈ResearchKit

00:36:36.997 --> 00:36:39.666 align:middle line:-2
这样我们可以继续
改善我们的基础

00:36:40.067 --> 00:36:44.972 align:middle line:-2
并扩展进展项目的广泛性
让每个人都可以去用它

00:36:46.540 --> 00:36:51.678 align:middle line:-2
如果你想获知更多ResearchKit的信息
请前往我们的网站researchkit.org

00:36:52.479 --> 00:36:54.681 align:middle line:0
如果你要想了解
这个演讲的其他信息

00:36:54.748 --> 00:36:56.550 align:middle line:0
也可以访问以下的链接

00:36:57.184 --> 00:37:00.354 align:middle line:0
我也鼓励你前往
我们今天举办的实验室演讲

00:36:57.184 --> 00:37:00.354 align:middle line:0
我也鼓励你前往
我们今天举办的实验室演讲

00:37:00.888 --> 00:37:02.322 align:middle line:0
我们团队会在那里

00:37:02.523 --> 00:37:05.659 align:middle line:0
会很高兴地回答
你提出的任何问题

00:37:05.859 --> 00:37:08.595 align:middle line:0
我们也会讨论
这次系统升级的一些资讯

00:37:09.496 --> 00:37:13.233 align:middle line:0
最后 我们真的很期待
在接下来的日子里看到你们

00:37:13.300 --> 00:37:16.036 align:middle line:0
在接下来的日子能用到这些更新

00:37:16.103 --> 00:37:16.937 align:middle line:-1
谢谢
