WEBVTT

00:00:16.783 --> 00:00:22.089 align:middle line:0
（用Metal框架加速机器学习
演讲609）

00:00:29.830 --> 00:00:31.265 align:middle line:-1
大家下午好

00:00:31.698 --> 00:00:34.668 align:middle line:-2
欢迎来到“Metal框架
加速机器学习”

00:00:35.469 --> 00:00:37.171 align:middle line:-1
我是Anna Tikhonova

00:00:37.237 --> 00:00:39.306 align:middle line:-1
我是GPU软件团队的工程师

00:00:42.943 --> 00:00:44.678 align:middle line:-1
Metal性能着色器框架

00:00:44.745 --> 00:00:45.979 align:middle line:-1
是基于Metal而建立

00:00:46.580 --> 00:00:48.949 align:middle line:-1
为GPU提供更快速的原语

00:00:49.016 --> 00:00:51.785 align:middle line:-1
并已为iOS和macOS优化

00:00:52.819 --> 00:00:55.155 align:middle line:-1
我们提供的原语包括图像处理

00:00:55.455 --> 00:00:57.558 align:middle line:-1
线性代数和机器学习

00:00:58.625 --> 00:01:02.396 align:middle line:-2
我们曾讲过大量有关推理的内容
在往年的WWDC演讲中

00:00:58.625 --> 00:01:02.396 align:middle line:-2
我们曾讲过大量有关推理的内容
在往年的WWDC演讲中

00:01:02.796 --> 00:01:04.364 align:middle line:-1
这里我只是再强调一下

00:01:06.433 --> 00:01:09.369 align:middle line:-1
今年新增的训练支持

00:01:09.570 --> 00:01:11.038 align:middle line:-1
iOS和macOS

00:01:15.909 --> 00:01:16.810 align:middle line:-1
谢谢

00:01:18.612 --> 00:01:21.315 align:middle line:0
还有更快速的光线追踪

00:01:21.381 --> 00:01:22.282 align:middle line:0
添加到了平台

00:01:22.649 --> 00:01:26.353 align:middle line:0
我们为此做过一整场专题演讲
就在本周初

00:01:26.653 --> 00:01:29.122 align:middle line:0
主题是
“Metal框架加速光线追踪”

00:01:30.057 --> 00:01:33.293 align:middle line:-1
演讲的视频很快就会上线

00:01:34.294 --> 00:01:37.331 align:middle line:-1
今天演讲的主要内容是关于机器学习

00:01:37.764 --> 00:01:39.099 align:middle line:-1
特别是训练

00:01:42.102 --> 00:01:43.871 align:middle line:-1
我提过训练和推断

00:01:44.705 --> 00:01:47.307 align:middle line:0
深度学习算法由这两个阶段构成

00:01:47.608 --> 00:01:49.510 align:middle line:0
第一个阶段是训练阶段

00:01:50.511 --> 00:01:53.213 align:middle line:0
举个例子 比如训练一个模型

00:01:53.714 --> 00:01:55.749 align:middle line:0
对图像分类

00:01:56.183 --> 00:01:58.519 align:middle line:0
比如猫、狗、长颈鹿等等

00:01:59.987 --> 00:02:03.156 align:middle line:0
那么为了训练模型能识别猫

00:01:59.987 --> 00:02:03.156 align:middle line:0
那么为了训练模型能识别猫

00:02:03.223 --> 00:02:06.493 align:middle line:0
就要输入大量标签为猫的图片

00:02:07.060 --> 00:02:10.097 align:middle line:0
再以同样的方法
输入兔子和其他动物的图片

00:02:10.163 --> 00:02:11.999 align:middle line:0
让模型去识别

00:02:14.101 --> 00:02:17.337 align:middle line:0
训练的计算量很大而且是很耗时的

00:02:17.404 --> 00:02:18.505 align:middle line:0
迭代进程

00:02:19.339 --> 00:02:21.842 align:middle line:0
训练的结果是已训练的参数

00:02:24.745 --> 00:02:27.080 align:middle line:0
已训练的参数是下一阶段的必备条件

00:02:27.147 --> 00:02:28.048 align:middle line:0
也就是推断阶段

00:02:28.782 --> 00:02:31.618 align:middle line:0
这个阶段中 模型会看到一张新图

00:02:31.685 --> 00:02:33.086 align:middle line:0
之前从未见过

00:02:33.153 --> 00:02:35.822 align:middle line:0
它需要对其分类
以已训练的参数为基础

00:02:36.223 --> 00:02:37.191 align:middle line:-1
这是只猫

00:02:38.292 --> 00:02:40.427 align:middle line:-1
GPU加速现在可以

00:02:40.494 --> 00:02:42.896 align:middle line:-1
同时用于训练阶段和推断阶段

00:02:45.832 --> 00:02:47.334 align:middle line:-1
但在讲训练之前

00:02:47.401 --> 00:02:51.371 align:middle line:-2
我要先谈谈CNN推断优化
这是我们今年添加的内容

00:02:51.939 --> 00:02:55.042 align:middle line:-1
现在FP16计算可以支持

00:02:55.108 --> 00:02:58.111 align:middle line:-1
卷积和卷积转置原语

00:02:58.946 --> 00:03:03.250 align:middle line:-2
Apple A11 Bionic
GPU有此新功能

00:02:58.946 --> 00:03:03.250 align:middle line:-2
Apple A11 Bionic
GPU有此新功能

00:03:04.351 --> 00:03:08.322 align:middle line:-1
我们发现FP16计算推断

00:03:08.655 --> 00:03:10.958 align:middle line:-1
就精度而言完全足够

00:03:11.892 --> 00:03:14.161 align:middle line:-1
适合常用的神经网络

00:03:15.562 --> 00:03:20.534 align:middle line:-1
FP16计算更为精确还十分省电

00:03:20.601 --> 00:03:24.204 align:middle line:-1
所以请一定要把它运用到推断中

00:03:25.572 --> 00:03:29.176 align:middle line:-2
这个例子展示了
如何将FP16计算

00:03:29.243 --> 00:03:30.744 align:middle line:-1
用于卷积原语

00:03:30.811 --> 00:03:34.181 align:middle line:-2
你只需设置
accumulatorPrecisionOption属性

00:03:36.617 --> 00:03:40.854 align:middle line:-2
现在我们开始深入讲解
本场演讲的主题

00:03:41.188 --> 00:03:42.422 align:middle line:-1
神经网络训练

00:03:43.156 --> 00:03:45.792 align:middle line:-1
我们从卷积神经网络讲起

00:03:48.929 --> 00:03:52.332 align:middle line:-2
这里有一个简单的
手写数字识别网络

00:03:53.233 --> 00:03:56.069 align:middle line:-1
以手写数字图像为输入

00:03:56.870 --> 00:03:59.373 align:middle line:-1
放入十个类中的一个

00:03:59.439 --> 00:04:00.507 align:middle line:-1
从0到9

00:03:59.439 --> 00:04:00.507 align:middle line:-1
从0到9

00:04:01.608 --> 00:04:04.711 align:middle line:-2
这个例子中
图片被正确地归类为

00:04:04.778 --> 00:04:06.580 align:middle line:-1
数字7的图片

00:04:09.316 --> 00:04:13.120 align:middle line:0
推断时用已训练的参数
初始化网络

00:04:13.954 --> 00:04:16.557 align:middle line:0
已训练的参数添加权重

00:04:16.623 --> 00:04:19.293 align:middle line:0
到卷积和全连接原语

00:04:20.327 --> 00:04:23.730 align:middle line:0
训练算法的目的
是计算已训练的参数

00:04:23.797 --> 00:04:28.535 align:middle line:0
让网络可以用它们让输入数据
在推断时修正输出

00:04:30.370 --> 00:04:33.407 align:middle line:-2
训练进程开始的时候
没有任何权重

00:04:33.473 --> 00:04:34.608 align:middle line:-1
我们需要计算

00:04:35.075 --> 00:04:36.176 align:middle line:-1
所以第一步

00:04:36.543 --> 00:04:39.479 align:middle line:-2
初始化权重
用较小的随机的数字

00:04:40.013 --> 00:04:41.682 align:middle line:-2
现在可以开始
训练网络了

00:04:42.149 --> 00:04:45.319 align:middle line:-2
这里列出了
训练过程中的所有步骤

00:04:48.121 --> 00:04:49.957 align:middle line:-1
训练是一个迭代进程

00:04:50.023 --> 00:04:53.126 align:middle line:-2
每次训练的迭代
分为四步

00:04:53.994 --> 00:04:55.929 align:middle line:-1
第一步是正向传播

00:04:55.996 --> 00:04:59.166 align:middle line:-2
这时候将输入
传递给网络

00:04:59.233 --> 00:05:00.367 align:middle line:-1
产生输出

00:04:59.233 --> 00:05:00.367 align:middle line:-1
产生输出

00:05:01.068 --> 00:05:02.536 align:middle line:-1
类似推断进程

00:05:04.238 --> 00:05:05.939 align:middle line:-1
然后计算缺失

00:05:06.573 --> 00:05:08.876 align:middle line:-1
损失直观地衡量了

00:05:08.942 --> 00:05:11.245 align:middle line:-2
网络输出值
与标准值之间的误差

00:05:13.313 --> 00:05:16.450 align:middle line:-2
训练算法的目标
是最小化损失

00:05:18.819 --> 00:05:20.854 align:middle line:0
下一步是梯度传播

00:05:21.488 --> 00:05:24.558 align:middle line:0
就是反向传播
网络输出相对

00:05:24.825 --> 00:05:27.361 align:middle line:0
标准值的误差
给神经网络

00:05:27.794 --> 00:05:29.096 align:middle line:0
再更新权重

00:05:29.963 --> 00:05:33.267 align:middle line:0
理念是随着训练不断进行

00:05:33.333 --> 00:05:35.202 align:middle line:0
网络会越来越准确

00:05:35.269 --> 00:05:38.906 align:middle line:0
所以最好能用
输入修正输出

00:05:39.806 --> 00:05:41.675 align:middle line:-1
从而最小化误差

00:05:43.210 --> 00:05:44.478 align:middle line:-1
以上是概述

00:05:44.778 --> 00:05:47.748 align:middle line:-2
下面分别看看
每个步骤的具体内容

00:05:50.350 --> 00:05:53.654 align:middle line:-2
正向传播指
向网络正向传递信息

00:05:54.054 --> 00:05:55.155 align:middle line:0
以计算输出

00:05:56.190 --> 00:05:58.692 align:middle line:0
如你所见
在这个训练场景下

00:05:59.092 --> 00:06:00.627 align:middle line:0
网络的表现不是很好

00:05:59.092 --> 00:06:00.627 align:middle line:0
网络的表现不是很好

00:06:01.795 --> 00:06:03.764 align:middle line:0
结果明显是错误的

00:06:03.830 --> 00:06:05.098 align:middle line:0
为何这么糟糕？

00:06:05.566 --> 00:06:06.767 align:middle line:0
其实也不意外

00:06:06.834 --> 00:06:09.770 align:middle line:0
因为初始权重
只是随机的数字

00:06:09.837 --> 00:06:12.039 align:middle line:0
网络还没有被训练
所以表现不好

00:06:13.941 --> 00:06:16.476 align:middle line:0
现在要用权重来量化

00:06:16.844 --> 00:06:19.646 align:middle line:0
网络表现的好坏程度

00:06:20.247 --> 00:06:21.849 align:middle line:0
我们可以用这个信息

00:06:22.349 --> 00:06:25.552 align:middle line:0
来提高权重
希望经过多次迭代

00:06:25.619 --> 00:06:28.055 align:middle line:0
能训练网络
输出更准确的结果

00:06:30.257 --> 00:06:32.426 align:middle line:0
为了衡量表现如何

00:06:32.492 --> 00:06:34.127 align:middle line:0
我们需要一个正确答案

00:06:34.795 --> 00:06:37.631 align:middle line:0
就是标准值
之后我会叫它标签

00:06:38.098 --> 00:06:41.502 align:middle line:0
它会与图像
一同输入网络

00:06:42.236 --> 00:06:44.505 align:middle line:0
这个例子中
向量为10个值

00:06:44.571 --> 00:06:46.940 align:middle line:0
正确类的值为1
类7

00:06:47.274 --> 00:06:49.009 align:middle line:0
其他类均为0

00:06:51.645 --> 00:06:54.548 align:middle line:0
网络的输出
就是这十个概率值

00:06:54.882 --> 00:06:55.849 align:middle line:0
每类给一个值

00:06:56.517 --> 00:06:59.052 align:middle line:0
在这个训练场景下

00:06:59.119 --> 00:07:02.923 align:middle line:0
网络输出一个很低的值
给正确答案7

00:06:59.119 --> 00:07:02.923 align:middle line:0
网络输出一个很低的值
给正确答案7

00:07:03.490 --> 00:07:06.860 align:middle line:0
而把最高值
分配给了9

00:07:07.394 --> 00:07:09.930 align:middle line:0
因此网络返回的
正确答案是9

00:07:11.465 --> 00:07:13.166 align:middle line:0
现在把所有信息

00:07:13.467 --> 00:07:15.669 align:middle line:0
传递给损失原语

00:07:18.705 --> 00:07:20.374 align:middle line:0
我之前讲过

00:07:21.441 --> 00:07:24.811 align:middle line:0
损失衡量的差值
是网络输出

00:07:25.145 --> 00:07:26.380 align:middle line:0
较之标准值的误差

00:07:27.548 --> 00:07:30.350 align:middle line:0
而训练算法的目标
是最小化误差

00:07:32.352 --> 00:07:34.488 align:middle line:-2
这时就要需要
图形的下半部分

00:07:36.590 --> 00:07:37.724 align:middle line:-1
下半部分图形

00:07:37.858 --> 00:07:40.060 align:middle line:-1
包括梯度原语

00:07:40.527 --> 00:07:42.262 align:middle line:-1
对应每个正向原语

00:07:43.330 --> 00:07:44.431 align:middle line:-1
梯度原语

00:07:45.098 --> 00:07:47.601 align:middle line:-1
计算更新权重所需的梯度

00:07:49.937 --> 00:07:51.038 align:middle line:-1
损失原语

00:07:52.506 --> 00:07:53.941 align:middle line:-1
计算第一梯度

00:07:54.508 --> 00:07:56.510 align:middle line:-2
就是选定的
损失函数的导数

00:07:56.577 --> 00:07:57.845 align:middle line:-1
基于输出

00:07:58.312 --> 00:07:59.646 align:middle line:-1
然后将这个梯度

00:07:59.980 --> 00:08:01.782 align:middle line:-1
反向传播

00:07:59.980 --> 00:08:01.782 align:middle line:-1
反向传播

00:08:02.549 --> 00:08:03.717 align:middle line:-1
通过网络

00:08:04.184 --> 00:08:06.086 align:middle line:-1
通过第一个…

00:08:06.987 --> 00:08:09.489 align:middle line:-1
梯度原语向后传递

00:08:09.556 --> 00:08:12.826 align:middle line:-2
这个例子中
梯度原语为SoftMax

00:08:14.027 --> 00:08:15.495 align:middle line:-1
要用到链式法则

00:08:15.562 --> 00:08:18.065 align:middle line:-1
链式法则允许反向传播梯度

00:08:18.131 --> 00:08:19.333 align:middle line:-1
通过网络向后走

00:08:20.467 --> 00:08:22.302 align:middle line:-1
同时计算梯度

00:08:22.369 --> 00:08:23.737 align:middle line:-1
以更新权重

00:08:24.271 --> 00:08:27.374 align:middle line:-1
因此权重的增量很小

00:08:27.975 --> 00:08:29.276 align:middle line:-1
在每次迭代中

00:08:31.311 --> 00:08:33.480 align:middle line:-1
然后用更新后的权重

00:08:33.547 --> 00:08:35.115 align:middle line:-1
进行下次训练迭代

00:08:35.883 --> 00:08:38.184 align:middle line:-1
希望误差值会变小

00:08:38.251 --> 00:08:39.753 align:middle line:-1
这是我们努力的方向

00:08:43.557 --> 00:08:45.692 align:middle line:0
实际上
在任何训练场景中

00:08:46.326 --> 00:08:48.462 align:middle line:0
不可能只处理一张图像

00:08:49.062 --> 00:08:52.299 align:middle line:0
而是处理
一组或一批图像

00:08:52.366 --> 00:08:55.135 align:middle line:0
比如32或64的批大小

00:08:55.869 --> 00:08:59.439 align:middle line:0
还要有相应的一批标签

00:08:59.506 --> 00:09:00.674 align:middle line:0
用于计算损失

00:08:59.506 --> 00:09:00.674 align:middle line:0
用于计算损失

00:09:00.741 --> 00:09:03.277 align:middle line:0
这个例子里
我们有一批标签

00:09:03.343 --> 00:09:06.780 align:middle line:0
正确类的值为1
其他为0

00:09:09.550 --> 00:09:11.285 align:middle line:0
每个训练场景

00:09:11.351 --> 00:09:13.620 align:middle line:0
会使用不同的批图像

00:09:13.687 --> 00:09:16.056 align:middle line:0
和相应的一批标签

00:09:16.123 --> 00:09:18.859 align:middle line:0
现在就来运行
多次训练迭代

00:09:21.495 --> 00:09:23.630 align:middle line:0
对第一批图像

00:09:23.697 --> 00:09:25.032 align:middle line:0
做正向传播

00:09:25.098 --> 00:09:28.101 align:middle line:0
计算损失
然后梯度传播

00:09:28.936 --> 00:09:30.037 align:middle line:0
再更新权重

00:09:30.604 --> 00:09:32.372 align:middle line:0
那么第二批呢？

00:09:32.439 --> 00:09:34.208 align:middle line:0
完全一样的流程

00:09:34.274 --> 00:09:36.510 align:middle line:0
正向传播
然后计算损失

00:09:36.577 --> 00:09:38.679 align:middle line:0
梯度传播
再更新权重

00:09:40.080 --> 00:09:42.182 align:middle line:0
训练迭代过程中

00:09:43.016 --> 00:09:45.319 align:middle line:0
我们希望网络的损失

00:09:45.385 --> 00:09:46.320 align:middle line:0
能降低

00:09:46.653 --> 00:09:49.323 align:middle line:0
网络准确度能提高

00:09:49.590 --> 00:09:52.292 align:middle line:0
所以继续训练
直到损失降到

00:09:52.359 --> 00:09:53.827 align:middle line:0
某个阈值以下

00:09:54.228 --> 00:09:57.598 align:middle line:0
网络的准确度
就达到了理想水平

00:09:58.765 --> 00:10:00.834 align:middle line:0
这时我们就知道网络已训练

00:09:58.765 --> 00:10:00.834 align:middle line:0
这时我们就知道网络已训练

00:10:00.901 --> 00:10:03.070 align:middle line:0
我们可以用
已训练的参数

00:10:03.403 --> 00:10:04.338 align:middle line:0
去推断了

00:10:04.738 --> 00:10:07.674 align:middle line:-1
现在看几个必要步骤

00:10:07.741 --> 00:10:11.078 align:middle line:-2
Metal性能着色器框架(MPS)
训练神经网络

00:10:12.012 --> 00:10:15.549 align:middle line:-2
神经网络通常会用
图形抽象来表示

00:10:16.116 --> 00:10:19.353 align:middle line:-1
MPS中的神经网络就以图形描述

00:10:20.888 --> 00:10:23.223 align:middle line:-1
第一步就是创建训练图

00:10:24.424 --> 00:10:26.326 align:middle line:-1
我们要准备好输入数据

00:10:26.393 --> 00:10:27.928 align:middle line:-1
确定权重

00:10:27.995 --> 00:10:29.329 align:middle line:-1
然后执行训练图

00:10:29.396 --> 00:10:30.864 align:middle line:-1
运行正向路径

00:10:31.298 --> 00:10:34.768 align:middle line:-2
计算损失、梯度传播
再更新权重

00:10:35.903 --> 00:10:37.704 align:middle line:-1
训练是一个迭代进程

00:10:38.639 --> 00:10:41.108 align:middle line:-1
训练网络需要多次迭代

00:10:41.175 --> 00:10:43.844 align:middle line:-2
因此还要知道
什么时候停止训练

00:10:44.077 --> 00:10:45.979 align:middle line:-1
现在就来研究每个课题的

00:10:46.280 --> 00:10:47.314 align:middle line:-1
具体内容

00:10:47.814 --> 00:10:50.551 align:middle line:-1
首先是创建训练图

00:10:52.719 --> 00:10:55.956 align:middle line:-2
我说过MPS中
神经网络是

00:10:56.023 --> 00:10:58.425 align:middle line:-2
一个图形
通过神经网络图形API

00:10:59.193 --> 00:11:01.161 align:middle line:-1
这是可视化的

00:10:59.193 --> 00:11:01.161 align:middle line:-1
这是可视化的

00:11:01.461 --> 00:11:04.031 align:middle line:-1
手写数字识别网络

00:11:04.665 --> 00:11:06.099 align:middle line:-1
这个图形里

00:11:06.166 --> 00:11:07.901 align:middle line:-1
你能看到图像节点

00:11:07.968 --> 00:11:09.303 align:middle line:-1
就是白色的小节点

00:11:10.904 --> 00:11:13.073 align:middle line:-1
图像节点用于数据

00:11:13.373 --> 00:11:16.677 align:middle line:-1
输入输出和所有中间结果

00:11:18.846 --> 00:11:21.949 align:middle line:-2
它们描述了不同操作时
数据的移动情况

00:11:22.716 --> 00:11:24.585 align:middle line:-1
然后处理数据

00:11:24.651 --> 00:11:26.220 align:middle line:-1
比如卷积或池化

00:11:27.087 --> 00:11:29.957 align:middle line:-1
以过滤节点表示

00:11:30.924 --> 00:11:33.193 align:middle line:-1
我们支持所有必要的节点

00:11:33.260 --> 00:11:35.829 align:middle line:-1
以创建常用的神经网络

00:11:37.231 --> 00:11:39.132 align:middle line:-1
现在看看怎么简单地

00:11:39.199 --> 00:11:40.767 align:middle line:-1
使用神经网络图形API

00:11:41.702 --> 00:11:46.440 align:middle line:0
这个例子就是
如何创建MPSImageNode

00:11:46.507 --> 00:11:48.141 align:middle line:0
通过神经网络图形API

00:11:48.675 --> 00:11:51.011 align:middle line:0
这是如何创建卷积节点

00:11:51.078 --> 00:11:52.346 align:middle line:0
通过图形API

00:11:53.380 --> 00:11:55.916 align:middle line:0
对于每个正向节点

00:11:55.983 --> 00:11:59.386 align:middle line:0
提供相应的训练梯度节点

00:11:59.720 --> 00:12:02.923 align:middle line:0
只要一行代码
就能创建梯度节点

00:11:59.720 --> 00:12:02.923 align:middle line:0
只要一行代码
就能创建梯度节点

00:12:02.990 --> 00:12:04.024 align:middle line:0
对应正向节点

00:12:04.091 --> 00:12:08.362 align:middle line:0
这个例子展示了
如何创建梯度卷积节点

00:12:08.428 --> 00:12:09.663 align:middle line:0
基于卷积节点

00:12:13.100 --> 00:12:14.735 align:middle line:-1
现在创建整个图形

00:12:16.203 --> 00:12:18.372 align:middle line:-1
这里有个很小的网络

00:12:18.438 --> 00:12:21.241 align:middle line:-2
一个卷积节点
接着一个池化节点

00:12:21.308 --> 00:12:22.943 align:middle line:-1
随后是另一个卷积节点

00:12:23.911 --> 00:12:25.679 align:middle line:-1
怎样连接这些节点

00:12:26.813 --> 00:12:27.681 align:middle line:-1
到图形中？

00:12:27.915 --> 00:12:28.949 align:middle line:-1
很简单

00:12:29.616 --> 00:12:31.685 align:middle line:-2
我们将结果节点
不对

00:12:32.352 --> 00:12:34.521 align:middle line:-1
一个节点的输出图像

00:12:34.588 --> 00:12:37.758 align:middle line:-2
以源图片形式
传递到后续节点

00:12:38.859 --> 00:12:41.528 align:middle line:-1
这就形成全连接图形

00:12:42.729 --> 00:12:44.731 align:middle line:-1
现在创建训练图形

00:12:45.766 --> 00:12:48.735 align:middle line:-2
首先在图形中
添加损失节点

00:12:50.037 --> 00:12:52.005 align:middle line:-1
再添加梯度节点

00:12:52.072 --> 00:12:54.274 align:middle line:-1
我说过 只要一行代码

00:12:54.341 --> 00:12:55.943 align:middle line:-1
就能创建梯度节点

00:12:56.210 --> 00:12:57.978 align:middle line:-1
对应正向节点

00:12:58.345 --> 00:13:00.380 align:middle line:-1
然后跟之前一样连接它们

00:12:58.345 --> 00:13:00.380 align:middle line:-1
然后跟之前一样连接它们

00:13:00.447 --> 00:13:02.616 align:middle line:-1
完整的训练图就做好了

00:13:05.752 --> 00:13:07.588 align:middle line:-1
通过这个例子 你能看到

00:13:07.654 --> 00:13:10.524 align:middle line:-1
图形API简单易用

00:13:11.558 --> 00:13:13.393 align:middle line:-1
训练图可以自动做很多事

00:13:13.460 --> 00:13:15.495 align:middle line:-1
它能处理所有中间结果

00:13:16.797 --> 00:13:18.365 align:middle line:-1
甚至输出图像

00:13:19.166 --> 00:13:22.870 align:middle line:-1
它能最小化网络的内存占用

00:13:22.936 --> 00:13:26.607 align:middle line:-1
通过将所有的中间图像折叠

00:13:26.673 --> 00:13:27.808 align:middle line:-1
借助Metal堆

00:13:28.809 --> 00:13:30.410 align:middle line:-1
它还能融合图形节点

00:13:30.477 --> 00:13:34.181 align:middle line:-2
例如它可以融合
批标准化和网络节点

00:13:34.615 --> 00:13:36.416 align:middle line:-1
它还能优化away节点

00:13:36.717 --> 00:13:39.219 align:middle line:-2
比如优化切割
nation节点的方法

00:13:40.387 --> 00:13:43.156 align:middle line:-1
它还可以自动处理填充

00:13:43.223 --> 00:13:44.958 align:middle line:-1
管理状态对象

00:13:45.025 --> 00:13:46.727 align:middle line:-1
这些稍后会讲到

00:13:47.561 --> 00:13:49.930 align:middle line:-1
所以请好好利用图形API

00:13:54.868 --> 00:13:57.104 align:middle line:-1
了解如何创建训练图后

00:13:57.471 --> 00:14:01.308 align:middle line:-2
现在看看
要传递给训练图的输入

00:13:57.471 --> 00:14:01.308 align:middle line:-2
现在看看
要传递给训练图的输入

00:14:02.576 --> 00:14:04.878 align:middle line:-1
这里就要讲到编码命令

00:14:04.945 --> 00:14:07.414 align:middle line:-1
将图形编码到GPU

00:14:09.049 --> 00:14:11.818 align:middle line:0
我说过 我们不会只发送一张图像

00:14:11.885 --> 00:14:13.086 align:middle line:0
给每次训练

00:14:13.153 --> 00:14:16.323 align:middle line:0
我们要处理一组或一批图像

00:14:16.523 --> 00:14:18.192 align:middle line:0
那么输入数据之一

00:14:18.458 --> 00:14:19.760 align:middle line:0
就是一批图像

00:14:20.794 --> 00:14:23.664 align:middle line:0
你一定记得每批图像

00:14:23.730 --> 00:14:27.467 align:middle line:0
都对应一批标签 用于计算损失

00:14:29.770 --> 00:14:33.807 align:middle line:0
计算损失的标签
以状态形式传递给训练图

00:14:34.174 --> 00:14:37.978 align:middle line:0
代码命令也会把一批状态作为输入

00:14:38.779 --> 00:14:41.548 align:middle line:0
现在来讲讲批和状态

00:14:41.882 --> 00:14:43.584 align:middle line:0
是什么意思？
首先是批

00:14:44.484 --> 00:14:48.188 align:middle line:0
批是一组图像或状态

00:14:48.255 --> 00:14:51.091 align:middle line:0
这是我们今年特地为训练增加的支持

00:14:52.092 --> 00:14:56.029 align:middle line:0
现在有两个新的MPS类型可用
MPSImageBatch

00:14:56.096 --> 00:14:57.731 align:middle line:0
和MPSStateBatch

00:14:58.565 --> 00:15:01.568 align:middle line:0
下面这个例子
告诉你如何用我们的API

00:14:58.565 --> 00:15:01.568 align:middle line:0
下面这个例子
告诉你如何用我们的API

00:15:01.635 --> 00:15:02.769 align:middle line:0
创建单张图像

00:15:04.071 --> 00:15:06.773 align:middle line:0
用现有的Metal纹理创建图像

00:15:08.275 --> 00:15:10.277 align:middle line:0
这个例子展示了如何使用

00:15:10.577 --> 00:15:14.781 align:middle line:0
API创建批图像
再附加一张新图像

00:15:14.848 --> 00:15:16.283 align:middle line:0
传给训练图

00:15:18.485 --> 00:15:20.254 align:middle line:-1
状态对象是什么？

00:15:21.255 --> 00:15:24.791 align:middle line:-1
MPS状态是不透明的数据容器

00:15:25.792 --> 00:15:29.096 align:middle line:-1
训练中 常要用它捕捉

00:15:29.162 --> 00:15:30.264 align:middle line:-1
正向节点的状态

00:15:31.565 --> 00:15:32.399 align:middle line:-1
在调用时

00:15:32.766 --> 00:15:36.036 align:middle line:-1
所以它之后可以用作梯度节点

00:15:37.104 --> 00:15:39.706 align:middle line:-1
训练图会处理所有状态对象

00:15:39.773 --> 00:15:40.807 align:middle line:-1
所以作为开发者

00:15:40.908 --> 00:15:42.943 align:middle line:-1
你一般不用担心状态

00:15:43.010 --> 00:15:44.778 align:middle line:-1
但了解下工作原理也不错

00:15:44.845 --> 00:15:46.680 align:middle line:-1
我们用具体例子说明

00:15:49.049 --> 00:15:51.885 align:middle line:-1
回到上个手写数字识别网络

00:15:53.287 --> 00:15:55.722 align:middle line:-1
特别注意下退出

00:15:55.789 --> 00:15:57.391 align:middle line:-1
和退出梯度节点

00:16:00.761 --> 00:16:03.864 align:middle line:-2
正向退出节点
减少或清零

00:16:03.931 --> 00:16:06.533 align:middle line:-1
以某个特定概率输入值

00:16:07.334 --> 00:16:09.236 align:middle line:-1
退出状态对象

00:16:09.603 --> 00:16:12.606 align:middle line:-1
捕捉正向退出处理的信息

00:16:13.574 --> 00:16:16.343 align:middle line:0
之后可用于梯度节点

00:16:17.044 --> 00:16:18.612 align:middle line:0
因为它清零

00:16:19.913 --> 00:16:23.717 align:middle line:0
输出梯度值的位置

00:16:23.784 --> 00:16:25.786 align:middle line:0
与正向清零的位置一样

00:16:28.889 --> 00:16:31.458 align:middle line:-1
所以我说你不用担心状态

00:16:31.525 --> 00:16:32.960 align:middle line:-1
训练图都会帮你处理

00:16:33.794 --> 00:16:35.963 align:middle line:-1
但是由于计算损失的标签

00:16:36.330 --> 00:16:37.965 align:middle line:-1
以状态的形式传递给训练图

00:16:39.066 --> 00:16:40.701 align:middle line:-1
而且需要用户输入数据

00:16:40.767 --> 00:16:43.504 align:middle line:-1
就是标准值或正确结果

00:16:44.004 --> 00:16:47.007 align:middle line:-1
你需要创建一批标签用于计算损失

00:16:47.241 --> 00:16:49.209 align:middle line:-1
再输入给训练图

00:16:50.143 --> 00:16:53.046 align:middle line:-2
下面这个例子
将展示如何创建单个标签

00:16:53.480 --> 00:16:54.882 align:middle line:-1
用于计算损失

00:16:55.249 --> 00:16:57.584 align:middle line:-1
首先要创建损失数据描述符

00:16:57.985 --> 00:17:00.821 align:middle line:-1
描述标签数据在内存里的情况

00:16:57.985 --> 00:17:00.821 align:middle line:-1
描述标签数据在内存里的情况

00:17:01.722 --> 00:17:05.392 align:middle line:-2
然后创建
MPSCNNLossLabel对象

00:17:05.459 --> 00:17:06.593 align:middle line:-1
用这个描述符

00:17:08.161 --> 00:17:10.196 align:middle line:-1
然后创建批对象用于训练

00:17:10.897 --> 00:17:12.965 align:middle line:-1
GPU运行完图形后

00:17:13.467 --> 00:17:17.204 align:middle line:-1
批标签会包含每张图像的损失值

00:17:17.971 --> 00:17:18.839 align:middle line:-1
对这批图像

00:17:19.039 --> 00:17:20.440 align:middle line:-1
你检查这些值

00:17:20.507 --> 00:17:22.943 align:middle line:-1
或计算一个单一值给整个批

00:17:23.010 --> 00:17:24.178 align:middle line:-1
再检查那个值

00:17:27.714 --> 00:17:29.283 align:middle line:-1
那么现在有了训练图

00:17:29.349 --> 00:17:32.586 align:middle line:-1
下面就是如何输入数据

00:17:32.653 --> 00:17:34.755 align:middle line:-1
我们看看如何将权重

00:17:34.821 --> 00:17:36.523 align:middle line:-1
添加到需要权重的图形节点上

00:17:39.026 --> 00:17:42.696 align:middle line:-1
唯一能添加权重给卷积、全连接

00:17:42.763 --> 00:17:46.934 align:middle line:0
批归一化和实例正则化节点

00:17:47.000 --> 00:17:49.303 align:middle line:0
是通过数据源提供器协议

00:17:50.938 --> 00:17:53.841 align:middle line:0
这个例子就是如何创建卷积节点

00:17:53.907 --> 00:17:55.309 align:middle line:0
通过数据源提供器

00:17:56.176 --> 00:18:00.280 align:middle line:0
你需要部署一个符合协议规则的类

00:17:56.176 --> 00:18:00.280 align:middle line:0
你需要部署一个符合协议规则的类

00:18:00.347 --> 00:18:02.216 align:middle line:0
这里就叫做MyWeights

00:18:04.685 --> 00:18:08.155 align:middle line:-1
数据源提供器在许多方面都很好用

00:18:08.589 --> 00:18:09.623 align:middle line:-1
比如

00:18:09.857 --> 00:18:12.593 align:middle line:-1
如果在网络里你有许多卷积节点

00:18:13.260 --> 00:18:16.396 align:middle line:-1
网络的整体权重会相当可观

00:18:16.964 --> 00:18:20.234 align:middle line:-1
但我们并不想让所有卷积节点的权重

00:18:20.300 --> 00:18:22.035 align:middle line:-1
同时存入内存

00:18:22.769 --> 00:18:25.506 align:middle line:-1
我们希望网络的内存占用

00:18:25.572 --> 00:18:26.673 align:middle line:-1
越低越好

00:18:27.407 --> 00:18:29.576 align:middle line:-1
数据源提供器就派上用场了

00:18:30.010 --> 00:18:32.679 align:middle line:-1
因为它们能及时载入

00:18:32.913 --> 00:18:34.681 align:middle line:-1
和清除权重数据

00:18:35.616 --> 00:18:38.118 align:middle line:-1
所以我们加载权重给一个卷积核

00:18:38.752 --> 00:18:39.987 align:middle line:-1
在处理时

00:18:40.053 --> 00:18:43.524 align:middle line:-2
清除它们后
才继续下一次卷积

00:18:46.260 --> 00:18:48.629 align:middle line:-1
MyWeights这样实施

00:18:49.429 --> 00:18:50.531 align:middle line:0
你要提供

00:18:51.198 --> 00:18:53.867 align:middle line:0
初始化方法

00:18:53.934 --> 00:18:56.103 align:middle line:0
拉入内存并做好准备

00:18:56.170 --> 00:18:58.672 align:middle line:-1
然后训练图会调用load函数

00:18:59.139 --> 00:19:01.408 align:middle line:0
当purge函数被调用时

00:18:59.139 --> 00:19:01.408 align:middle line:0
当purge函数被调用时

00:19:01.608 --> 00:19:02.843 align:middle line:0
权重就被释放了

00:19:03.644 --> 00:19:06.580 align:middle line:0
数据源提供器对训练也很重要

00:19:06.647 --> 00:19:08.515 align:middle line:0
这个我们稍后讲

00:19:11.919 --> 00:19:13.654 align:middle line:-1
那么我们有了训练图

00:19:13.720 --> 00:19:16.423 align:middle line:-1
也准备好了输入和具体权重

00:19:16.490 --> 00:19:18.559 align:middle line:-1
就可以在GPU上执行图形了

00:19:20.360 --> 00:19:22.362 align:middle line:-1
要在GPU上执行训练图

00:19:22.429 --> 00:19:24.831 align:middle line:-1
首先要完成Metal设置

00:19:25.432 --> 00:19:27.501 align:middle line:-1
我们要初始化训练图

00:19:27.935 --> 00:19:29.469 align:middle line:-1
准备好输入

00:19:29.736 --> 00:19:32.072 align:middle line:-1
开始在GPU上训练网络吧

00:19:35.209 --> 00:19:36.944 align:middle line:-1
训练是迭代进程

00:19:38.011 --> 00:19:39.780 align:middle line:-1
因此要设置训练回路

00:19:40.581 --> 00:19:44.117 align:middle line:-2
通常我们要执行训练图
经过几个轮次

00:19:44.885 --> 00:19:47.287 align:middle line:-1
轮次次数是总次数…

00:19:48.088 --> 00:19:50.958 align:middle line:-1
是对整个数据集的迭代次数

00:19:51.792 --> 00:19:54.828 align:middle line:-1
每个轮次应该有多个迭代

00:19:54.895 --> 00:19:57.764 align:middle line:-1
所以迭代的次数是图像总数

00:19:57.831 --> 00:20:01.268 align:middle line:-2
在数据集中
除以批大小32或64

00:19:57.831 --> 00:20:01.268 align:middle line:-2
在数据集中
除以批大小32或64

00:20:02.236 --> 00:20:04.805 align:middle line:-1
现在我们来看每次训练迭代

00:20:07.107 --> 00:20:08.609 align:middle line:-1
每次训练迭代中

00:20:09.910 --> 00:20:11.912 align:middle line:-1
我们对一批图像编码用于训练

00:20:13.146 --> 00:20:16.450 align:middle line:-1
但我们不想让CPU等GPU

00:20:16.517 --> 00:20:20.020 align:middle line:-1
跑完一次训练图

00:20:20.087 --> 00:20:21.421 align:middle line:-1
处理一批图像

00:20:21.755 --> 00:20:25.526 align:middle line:-2
然后CPU才开始编码
commandBuffer

00:20:25.592 --> 00:20:26.827 align:middle line:-1
给下一次图形运行

00:20:27.494 --> 00:20:29.830 align:middle line:-1
我们希望CPU和GPU

00:20:29.897 --> 00:20:31.031 align:middle line:-1
同时工作

00:20:31.331 --> 00:20:33.500 align:middle line:-1
为此我们要用到双缓冲

00:20:34.434 --> 00:20:37.070 align:middle line:-2
那么设置中
我们要创建

00:20:37.671 --> 00:20:40.474 align:middle line:-2
计数信号量
初始值为2

00:20:40.541 --> 00:20:44.344 align:middle line:-2
这是因为我们只要
2个编码同时运行

00:20:45.679 --> 00:20:48.715 align:middle line:-2
然后在输入
训练迭代函数时

00:20:48.782 --> 00:20:50.717 align:middle line:-1
就会调用信号量权重

00:20:50.784 --> 00:20:51.952 align:middle line:-1
进行自减

00:20:52.920 --> 00:20:56.323 align:middle line:-1
当计数值减到0

00:20:56.390 --> 00:20:58.225 align:middle line:-2
就等待
否则就继续

00:20:59.593 --> 00:21:00.928 align:middle line:-1
之后对图形编码

00:20:59.593 --> 00:21:00.928 align:middle line:-1
之后对图形编码

00:21:01.361 --> 00:21:03.564 align:middle line:-1
编码命令即刻返回

00:21:04.264 --> 00:21:06.333 align:middle line:-1
用户指定的回调函数会被调用

00:21:06.767 --> 00:21:08.602 align:middle line:-1
在GPU完成图形运行的时候

00:21:09.369 --> 00:21:11.705 align:middle line:-1
这样我们就知道GPU运行完了

00:21:12.105 --> 00:21:16.577 align:middle line:-1
CPU可以继续为GPU工作编码

00:21:17.711 --> 00:21:20.113 align:middle line:-2
就是之前在信号量上
等待处理的部分

00:21:21.315 --> 00:21:22.816 align:middle line:-1
为什么使用双缓冲呢？

00:21:22.883 --> 00:21:27.487 align:middle line:-2
为什么不能同时对GPU的
多次运行进行编码

00:21:28.822 --> 00:21:31.258 align:middle line:-1
因为编码命令用时少

00:21:31.325 --> 00:21:33.360 align:middle line:-1
命令缓冲比运行训练图快

00:21:33.660 --> 00:21:36.363 align:middle line:-2
所以不会编码
多次训练图执行

00:21:36.430 --> 00:21:38.465 align:middle line:-1
为了减少内存占用

00:21:41.268 --> 00:21:43.837 align:middle line:-1
我们讲过了如何执行训练图

00:21:43.904 --> 00:21:46.540 align:middle line:-1
执行图形时 我们做正向传播

00:21:46.607 --> 00:21:49.276 align:middle line:-1
计算损失 再梯度传播

00:21:49.343 --> 00:21:51.211 align:middle line:-1
然后图形会更新权重

00:21:51.545 --> 00:21:53.747 align:middle line:-1
现在说说权重更新

00:21:55.883 --> 00:21:59.353 align:middle line:-1
我说过数据源提供器很重要

00:21:59.987 --> 00:22:00.921 align:middle line:-1
对训练而言

00:21:59.987 --> 00:22:00.921 align:middle line:-1
对训练而言

00:22:01.488 --> 00:22:04.758 align:middle line:-1
所有权重更新都使用可选的更新方法

00:22:04.825 --> 00:22:06.527 align:middle line:0
通过数据源提供器

00:22:07.761 --> 00:22:10.497 align:middle line:0
图形自动调用更新函数

00:22:11.098 --> 00:22:13.567 align:middle line:0
那么更新权重的步骤都有哪些呢？

00:22:13.634 --> 00:22:14.635 align:middle line:0
来看一下

00:22:17.037 --> 00:22:19.940 align:middle line:-1
回想在梯度传播阶段的梯度计算

00:22:20.007 --> 00:22:22.643 align:middle line:-1
在每个训练场景

00:22:22.709 --> 00:22:24.077 align:middle line:-1
添加少许增量给权重

00:22:25.479 --> 00:22:27.481 align:middle line:-1
如何将增量分配给权重

00:22:27.548 --> 00:22:30.017 align:middle line:-1
由优化器决定

00:22:30.584 --> 00:22:33.520 align:middle line:-1
它只是个函数将原来的权重

00:22:33.587 --> 00:22:35.455 align:middle line:-1
和计算过的梯度作为输入

00:22:35.923 --> 00:22:39.193 align:middle line:-1
输出更新后的权重

00:22:41.228 --> 00:22:43.730 align:middle line:-1
优化器要在更新函数中使用

00:22:43.797 --> 00:22:45.032 align:middle line:-1
在数据源提供器内

00:22:45.999 --> 00:22:47.835 align:middle line:-1
我们也支持几种不同的变体

00:22:47.901 --> 00:22:51.371 align:middle line:-2
来更新GPU权重
包括Adam

00:22:51.438 --> 00:22:54.374 align:middle line:-2
StochasticGradientDescent
和RMSProp

00:22:54.842 --> 00:22:59.346 align:middle line:-2
你甚至可以自定义
权重更新步骤

00:22:59.913 --> 00:23:03.650 align:middle line:-2
那么就来看看
如何在MPS中使用优化器

00:22:59.913 --> 00:23:03.650 align:middle line:-2
那么就来看看
如何在MPS中使用优化器

00:23:06.320 --> 00:23:09.289 align:middle line:-2
你记得数据源提供器
有个init函数

00:23:09.656 --> 00:23:11.959 align:middle line:-1
这里就是创建优化器的地方

00:23:12.025 --> 00:23:13.894 align:middle line:-1
因为你只需要创建一次

00:23:15.295 --> 00:23:17.431 align:middle line:-1
现在看看如何执行

00:23:17.497 --> 00:23:18.498 align:middle line:-1
更新函数

00:23:19.533 --> 00:23:20.634 align:middle line:-1
更新函数

00:23:20.901 --> 00:23:24.104 align:middle line:-2
接收源状态
和梯度状态为输入

00:23:26.173 --> 00:23:28.509 align:middle line:-1
源状态包含原始权重

00:23:28.575 --> 00:23:31.078 align:middle line:-2
梯度状态
包含计算过的梯度

00:23:31.678 --> 00:23:34.081 align:middle line:-2
现在就能用这个数据
编码优化器

00:23:34.548 --> 00:23:37.484 align:middle line:-1
最后一步是将源状态返回

00:23:37.551 --> 00:23:39.253 align:middle line:-1
其中是更新后的权重

00:23:39.520 --> 00:23:40.554 align:middle line:-1
很简单吧

00:23:43.657 --> 00:23:45.926 align:middle line:-1
现在还有最后一步

00:23:46.360 --> 00:23:48.395 align:middle line:-1
我说过 训练时迭代进程

00:23:48.462 --> 00:23:51.198 align:middle line:-1
训练网络需要多次迭代

00:23:52.766 --> 00:23:54.701 align:middle line:-1
你要知道何时停止训练

00:23:55.202 --> 00:23:58.438 align:middle line:-2
现在就来讨论下
这个决定应该如何做

00:23:58.505 --> 00:24:00.140 align:middle line:-1
以训练循环为环境

00:23:58.505 --> 00:24:00.140 align:middle line:-1
以训练循环为环境

00:24:03.343 --> 00:24:05.078 align:middle line:-1
这是训练回路

00:24:05.145 --> 00:24:07.681 align:middle line:-2
正在训练神经网络
包含几个轮次

00:24:09.149 --> 00:24:13.253 align:middle line:-2
为确定何时停止训练
需要一个测试图集

00:24:13.320 --> 00:24:18.025 align:middle line:-1
测试图集内的图像不是用于训练

00:24:18.091 --> 00:24:21.595 align:middle line:-2
只用于评估
网络的准确度

00:24:22.362 --> 00:24:26.066 align:middle line:-2
每个轮次后
你可以选择等待图形

00:24:26.133 --> 00:24:29.169 align:middle line:-2
…等待GPU
停止运行图形

00:24:29.803 --> 00:24:33.140 align:middle line:-1
然后使用当前的已训练的参数

00:24:33.740 --> 00:24:35.676 align:middle line:-1
初始化推断网络

00:24:36.877 --> 00:24:39.880 align:middle line:-2
然后在测试图集上
运行推断网络

00:24:40.380 --> 00:24:41.949 align:middle line:-1
你可以选择停止训练

00:24:42.249 --> 00:24:44.852 align:middle line:-2
当测试集显示
网络精确度

00:24:45.185 --> 00:24:46.453 align:middle line:-1
达到某个水平时

00:24:50.023 --> 00:24:52.359 align:middle line:-1
我们已经讨论过所有步骤

00:24:52.659 --> 00:24:55.596 align:middle line:-1
关于在MPS训练神经网络

00:24:56.063 --> 00:24:56.997 align:middle line:-1
是时候展示一下了

00:24:58.632 --> 00:25:01.768 align:middle line:-1
平台状态汇总中提过

00:24:58.632 --> 00:25:01.768 align:middle line:-1
平台状态汇总中提过

00:25:02.736 --> 00:25:05.405 align:middle line:-1
Metal性能着色器框架可以驱动

00:25:06.340 --> 00:25:09.076 align:middle line:-2
Core ML、Create ML
和Turi Create

00:25:10.277 --> 00:25:13.180 align:middle line:-2
Turi Create
是一款简单易用

00:25:13.814 --> 00:25:17.718 align:middle line:-2
灵活且高性能的工具组
用于创建CoreML模型

00:25:18.352 --> 00:25:21.655 align:middle line:-2
以完成一些任务
如图像分类

00:25:21.722 --> 00:25:25.058 align:middle line:-1
对象检测和推荐等等

00:25:25.325 --> 00:25:27.127 align:middle line:-2
有关Turi Create的
更多信息

00:25:27.594 --> 00:25:30.731 align:middle line:-2
请查看“Turi Create
指南”的演讲视频

00:25:32.266 --> 00:25:33.534 align:middle line:-1
我们准备了一个演示

00:25:34.034 --> 00:25:38.505 align:middle line:-2
用一个…
训练一个对象检测网络

00:25:39.006 --> 00:25:41.942 align:middle line:-2
通过MPS驱动的
Turi Create完成

00:25:43.043 --> 00:25:45.479 align:middle line:-1
平台状态汇总中提到过

00:25:46.013 --> 00:25:49.116 align:middle line:-1
用MPS的速度比不用快9倍

00:25:50.117 --> 00:25:51.685 align:middle line:-1
对象检查网络

00:25:52.152 --> 00:25:55.155 align:middle line:-1
在被识别的对象周围绘制边框

00:26:01.328 --> 00:26:02.429 align:middle line:-1
这个演示中

00:26:04.865 --> 00:26:08.235 align:middle line:-2
我用的MacBook Pro
连接了外部GPU

00:26:09.870 --> 00:26:13.006 align:middle line:-2
Turi Create
在MacBook Pro上运行

00:26:13.407 --> 00:26:17.978 align:middle line:-1
外部GPU用MPS训练网络

00:26:18.946 --> 00:26:21.949 align:middle line:-2
这个例子可以很好地演示
如何使用外部GPU

00:26:22.015 --> 00:26:24.585 align:middle line:-2
提高MacBook Pro的
计算能力

00:26:25.285 --> 00:26:28.288 align:middle line:-2
我们使用的外部GPU
是AMD Vega GPU

00:26:29.356 --> 00:26:30.524 align:middle line:-1
在演示配置中

00:26:30.591 --> 00:26:32.526 align:middle line:-2
我已经导入
Turi Create

00:26:32.826 --> 00:26:36.129 align:middle line:-2
并提前加载了
对象检测网络

00:26:36.196 --> 00:26:37.464 align:middle line:-1
还有一个训练数据集

00:26:37.865 --> 00:26:39.066 align:middle line:-1
那么现在开始

00:26:40.501 --> 00:26:42.669 align:middle line:-1
训练网络用十次迭代

00:26:44.872 --> 00:26:46.940 align:middle line:-1
现在整个对象检测网络

00:26:47.007 --> 00:26:50.344 align:middle line:-2
所有的原语
优化器和权重更新方法

00:26:52.379 --> 00:26:54.748 align:middle line:-1
所有的都在外部GPU上运行

00:26:58.185 --> 00:27:00.554 align:middle line:-1
好了 十次训练迭代已完成

00:26:58.185 --> 00:27:00.554 align:middle line:-1
好了 十次训练迭代已完成

00:27:01.288 --> 00:27:03.724 align:middle line:-2
也许十次迭代不足以完成
该网络的训练

00:27:03.790 --> 00:27:05.559 align:middle line:-1
但在此我们就这样吧

00:27:06.059 --> 00:27:07.861 align:middle line:-1
我现在要做的

00:27:07.928 --> 00:27:11.131 align:middle line:-1
是加载一个提前训练过的网络

00:27:11.365 --> 00:27:12.966 align:middle line:-1
用来运行测试图集

00:27:13.033 --> 00:27:14.668 align:middle line:-1
展示部分结果

00:27:14.735 --> 00:27:15.869 align:middle line:-1
看一下

00:27:18.372 --> 00:27:20.274 align:middle line:-1
好了 这是香蕉

00:27:20.340 --> 00:27:22.276 align:middle line:-1
分类十分正确

00:27:22.576 --> 00:27:24.044 align:middle line:-1
而且画上了边框

00:27:24.945 --> 00:27:28.715 align:middle line:-2
这么美好的早餐
一杯咖啡和一个牛角包

00:27:29.216 --> 00:27:31.652 align:middle line:-1
还有一枚不好看的鸡蛋

00:27:34.321 --> 00:27:36.423 align:middle line:-2
以上就是
Turi Create的演示

00:27:43.463 --> 00:27:44.631 align:middle line:-1
谢谢大家

00:27:47.534 --> 00:27:51.371 align:middle line:-2
现在换个话题
谈谈递归神经网络的训练

00:27:52.339 --> 00:27:55.576 align:middle line:-2
首先简单讲讲
什么是递归神经网络

00:27:57.211 --> 00:28:00.247 align:middle line:0
卷积神经网络的一大缺陷

00:27:57.211 --> 00:28:00.247 align:middle line:0
卷积神经网络的一大缺陷

00:28:00.314 --> 00:28:04.384 align:middle line:0
是它们无法记忆之前发生的事情

00:28:05.319 --> 00:28:06.620 align:middle line:0
它们可以接收一个输入

00:28:06.687 --> 00:28:10.324 align:middle line:0
例如图像
然后产生一个输出

00:28:10.390 --> 00:28:13.527 align:middle line:0
例如一组概率值定义图像内容

00:28:16.630 --> 00:28:17.965 align:middle line:0
RNN就不一样

00:28:19.066 --> 00:28:19.900 align:middle line:0
它能记忆

00:28:19.967 --> 00:28:23.804 align:middle line:0
它们善于处理
连续的输入和输出

00:28:24.705 --> 00:28:27.107 align:middle line:0
比如它们可以用一组概率值

00:28:27.174 --> 00:28:28.709 align:middle line:0
也就是图像内容

00:28:29.243 --> 00:28:30.878 align:middle line:0
CNN产生的结果

00:28:31.345 --> 00:28:33.313 align:middle line:0
然后产生一序列输出

00:28:33.580 --> 00:28:36.683 align:middle line:0
就是一序列文字
作图片的说明

00:28:38.418 --> 00:28:40.787 align:middle line:0
它们也可用一组输入

00:28:40.854 --> 00:28:44.224 align:middle line:0
比如文字序列就是一个句子

00:28:44.525 --> 00:28:46.260 align:middle line:0
产生一组输出

00:28:46.860 --> 00:28:51.064 align:middle line:0
句子没变
但被翻译为另一种语言

00:28:51.131 --> 00:28:52.699 align:middle line:0
比如俄语或芬兰语

00:28:54.868 --> 00:28:57.704 align:middle line:-1
我们支持几个不同的RNN

00:28:58.438 --> 00:28:59.973 align:middle line:-1
最常用的一个

00:29:00.040 --> 00:29:02.376 align:middle line:-1
是长短期记忆RNN

00:29:02.442 --> 00:29:03.744 align:middle line:-1
简称LSTM

00:29:04.611 --> 00:29:06.847 align:middle line:-1
去年WWDC演讲中

00:29:06.914 --> 00:29:10.150 align:middle line:-2
我们讲过大量关于
LSTM门结构的内容

00:29:10.284 --> 00:29:13.153 align:middle line:-1
演示过LSTM推断过程

00:29:13.754 --> 00:29:17.991 align:middle line:-2
所以请查看那场演讲
了解更多关于LSTM推断的内容

00:29:19.593 --> 00:29:22.229 align:middle line:-1
今年新增的训练支持

00:29:22.296 --> 00:29:24.231 align:middle line:-1
所有这些RNN

00:29:25.165 --> 00:29:26.433 align:middle line:-1
本场演讲中

00:29:26.600 --> 00:29:29.303 align:middle line:-1
我会讲到LSTM的训练

00:29:32.606 --> 00:29:34.074 align:middle line:-1
看个具体例子

00:29:34.708 --> 00:29:37.110 align:middle line:-1
这是一个活动分类网络

00:29:37.744 --> 00:29:40.480 align:middle line:-1
以动作感官数据为输入

00:29:40.547 --> 00:29:44.985 align:middle line:-2
就是读取传感器数据
比如加速传感器或陀螺仪

00:29:45.619 --> 00:29:47.287 align:middle line:-1
网络然后使用这些数据

00:29:47.721 --> 00:29:50.691 align:middle line:-1
识别用户所做的运动

00:29:51.124 --> 00:29:54.061 align:middle line:-1
比如我们想确定用户是在骑行

00:29:54.361 --> 00:29:55.929 align:middle line:-1
滑雪还是散步

00:29:59.132 --> 00:30:01.201 align:middle line:-1
你看到网络的

00:29:59.132 --> 00:30:01.201 align:middle line:-1
你看到网络的

00:30:02.135 --> 00:30:03.537 align:middle line:-1
配置很有趣

00:30:03.604 --> 00:30:08.175 align:middle line:-1
它含有一系列CNN原语

00:30:08.242 --> 00:30:10.244 align:middle line:-1
随后是LSTM原语

00:30:10.310 --> 00:30:12.312 align:middle line:-1
再后面是更多的CNN原语

00:30:12.579 --> 00:30:14.648 align:middle line:-2
为什么这样设置？
我们来一窥究竟

00:30:16.984 --> 00:30:19.553 align:middle line:-1
尽管输入的是感官数据

00:30:20.487 --> 00:30:23.156 align:middle line:-1
但显示的是一批1D图像

00:30:23.223 --> 00:30:24.291 align:middle line:-1
6个特征通道

00:30:24.358 --> 00:30:28.128 align:middle line:-2
一个特征通道
用于读取加速传感器

00:30:28.195 --> 00:30:29.663 align:middle line:-1
和陀螺仪上的数据

00:30:30.631 --> 00:30:33.967 align:middle line:-1
每张1D图像为2000像素

00:30:34.034 --> 00:30:37.171 align:middle line:-1
你可以将它们当作即时样本

00:30:37.738 --> 00:30:40.474 align:middle line:-1
因为我们要识别的动作

00:30:40.541 --> 00:30:41.775 align:middle line:-1
是随时发生的

00:30:44.645 --> 00:30:48.415 align:middle line:-2
然后通过1D卷积原语
传递这些图像

00:30:49.283 --> 00:30:53.820 align:middle line:-1
它将2000个样本压缩到20个

00:30:56.123 --> 00:30:58.292 align:middle line:-1
但它要占用几个特征通道

00:30:58.358 --> 00:31:01.328 align:middle line:-2
这样就不会丢失
数据中的任何特征

00:30:58.358 --> 00:31:01.328 align:middle line:-2
这样就不会丢失
数据中的任何特征

00:31:03.230 --> 00:31:05.832 align:middle line:-1
然后新的数据图像

00:31:06.133 --> 00:31:09.303 align:middle line:-2
被传递给LSTM原语
是长度为20的序列

00:31:10.404 --> 00:31:12.406 align:middle line:-1
然后运行20个LSTM迭代

00:31:12.906 --> 00:31:15.776 align:middle line:-2
于是LSTM处理的
是长度为20的序列

00:31:15.843 --> 00:31:17.077 align:middle line:-1
而不是2000

00:31:17.144 --> 00:31:20.514 align:middle line:-1
而且是更高级的数据特征表达

00:31:22.549 --> 00:31:24.685 align:middle line:-1
后面还有几个CNN原语

00:31:25.419 --> 00:31:28.355 align:middle line:-1
精细化数据特征

00:31:29.389 --> 00:31:32.893 align:middle line:-2
序列的最后一个原语
是SoftMax

00:31:33.193 --> 00:31:36.263 align:middle line:-1
分配概率值给不同的动作类别

00:31:36.330 --> 00:31:37.731 align:middle line:-1
这就是网络的输出

00:31:38.632 --> 00:31:40.901 align:middle line:-1
现在看看怎样训练它

00:31:42.202 --> 00:31:44.938 align:middle line:-1
我们还是需要一个损失原语

00:31:45.005 --> 00:31:46.507 align:middle line:-1
将网络的输出

00:31:46.573 --> 00:31:48.008 align:middle line:-1
和标签作为输入

00:31:48.542 --> 00:31:50.410 align:middle line:-1
然后是下半部分图形

00:31:51.111 --> 00:31:54.481 align:middle line:-1
在下半部分还是梯度原语

00:31:54.548 --> 00:31:56.350 align:middle line:-1
对应正向原语

00:31:56.416 --> 00:31:58.218 align:middle line:-1
包括LSTM原语

00:31:59.052 --> 00:32:00.287 align:middle line:-1
那么训练

00:31:59.052 --> 00:32:00.287 align:middle line:-1
那么训练

00:32:01.722 --> 00:32:04.224 align:middle line:-1
先是运行网络正向传播

00:32:04.825 --> 00:32:06.527 align:middle line:-1
然后计算损失

00:32:07.594 --> 00:32:09.530 align:middle line:0
然后梯度传播

00:32:09.596 --> 00:32:12.132 align:middle line:0
计算梯度用于更新权重

00:32:12.633 --> 00:32:14.468 align:middle line:-1
这个设置很像

00:32:15.335 --> 00:32:17.037 align:middle line:-1
CNN训练的设置

00:32:17.104 --> 00:32:19.406 align:middle line:-1
最后一步当然也是更新权重

00:32:19.873 --> 00:32:22.176 align:middle line:-1
大家知道LSTM也有权重

00:32:22.242 --> 00:32:23.677 align:middle line:-1
也需要更新

00:32:26.079 --> 00:32:30.617 align:middle line:-2
现在看看在MPS中
如何训练这个网络

00:32:30.684 --> 00:32:33.620 align:middle line:-2
首先来看
如何创建LSTM 层

00:32:33.687 --> 00:32:35.522 align:middle line:-1
用我们的框架

00:32:36.657 --> 00:32:39.493 align:middle line:-1
第一步是创建LSTM层级描述符

00:32:40.594 --> 00:32:44.131 align:middle line:-2
用初始训练参数
初始化描述符

00:32:44.731 --> 00:32:46.066 align:middle line:-1
通过数据源提供器

00:32:46.400 --> 00:32:48.502 align:middle line:-1
初始的训练参数是

00:32:48.569 --> 00:32:51.305 align:middle line:-1
随机的小数字或检查点值

00:32:52.406 --> 00:32:54.208 align:middle line:-1
训练中描述符的设置

00:32:54.274 --> 00:32:56.810 align:middle line:-1
跟推断完全一样

00:32:58.612 --> 00:33:01.615 align:middle line:-1
我们以前讨论过层描述符的设置

00:32:58.612 --> 00:33:01.615 align:middle line:-1
我们以前讨论过层描述符的设置

00:33:01.915 --> 00:33:05.052 align:middle line:-2
在去年的WWDC演讲
内容十分详实

00:33:05.118 --> 00:33:08.255 align:middle line:-1
所以推荐大家去看那场演讲了解更多

00:33:08.322 --> 00:33:10.390 align:middle line:-2
关于LSTM
层描述符的设置

00:33:11.158 --> 00:33:12.626 align:middle line:-1
有了描述符之后

00:33:13.894 --> 00:33:17.798 align:middle line:-1
就要用它来创建LSTM训练层

00:33:19.766 --> 00:33:22.636 align:middle line:-1
MPS会添加训练权重

00:33:22.936 --> 00:33:25.572 align:middle line:-1
使用描述符定义的数据源

00:33:26.206 --> 00:33:28.141 align:middle line:-1
还需要一些矩阵

00:33:28.242 --> 00:33:29.710 align:middle line:-1
实现梯度计算

00:33:30.644 --> 00:33:33.747 align:middle line:-2
你要用
createWeightGradientMatrices

00:33:33.814 --> 00:33:34.648 align:middle line:-1
API

00:33:34.715 --> 00:33:37.217 align:middle line:-2
在训练层上
创建这些矩阵

00:33:37.751 --> 00:33:39.520 align:middle line:-1
然后训练权重

00:33:39.887 --> 00:33:42.389 align:middle line:-1
会被用于正向和梯度传播中

00:33:42.890 --> 00:33:44.658 align:middle line:-1
然后被传递给优化器

00:33:44.725 --> 00:33:47.194 align:middle line:-1
与计算好的梯度一起用于更新权重

00:33:49.396 --> 00:33:53.534 align:middle line:-2
现在要准备一些输入和输出
用于训练LSTM

00:33:54.535 --> 00:33:56.470 align:middle line:-1
这个例子展示了如何创建

00:33:56.937 --> 00:33:59.840 align:middle line:-1
矩阵去管理输入和输出序列

00:33:59.907 --> 00:34:02.276 align:middle line:-1
在正向和梯度传播中

00:33:59.907 --> 00:34:02.276 align:middle line:-1
在正向和梯度传播中

00:34:02.342 --> 00:34:04.678 align:middle line:-1
每个需要20个矩阵

00:34:05.712 --> 00:34:09.149 align:middle line:-1
这是如何初始化矩阵数据

00:34:11.784 --> 00:34:14.855 align:middle line:-1
现在就可以训练活动分类网络了

00:34:15.255 --> 00:34:16.089 align:middle line:-1
用MPS

00:34:16.156 --> 00:34:17.157 align:middle line:-1
这个代码样本中

00:34:17.224 --> 00:34:19.760 align:middle line:-1
我只强调LSTM过滤器

00:34:20.127 --> 00:34:21.395 align:middle line:-1
因为时间有限

00:34:23.563 --> 00:34:26.600 align:middle line:-2
在正向传播中
运行20矩阵的序列

00:34:26.667 --> 00:34:28.835 align:middle line:-1
正向通过LSTM训练层

00:34:29.735 --> 00:34:31.170 align:middle line:-1
然后反向传播

00:34:31.237 --> 00:34:34.440 align:middle line:-2
运行20个矩阵的序列
经过LSTM层

00:34:34.507 --> 00:34:35.641 align:middle line:-1
计算梯度

00:34:36.577 --> 00:34:38.978 align:middle line:0
现在已有训练权重

00:34:39.246 --> 00:34:40.848 align:middle line:0
计算好的梯度

00:34:40.914 --> 00:34:44.016 align:middle line:0
就可以将它们传递到
优化器去更新权重

00:34:45.686 --> 00:34:47.754 align:middle line:0
最后我要补充一点

00:34:49.389 --> 00:34:52.726 align:middle line:-1
卷积神经网络对图像的处理

00:34:52.793 --> 00:34:55.062 align:middle line:-1
和对LSTM的运行是基于矩阵

00:34:56.063 --> 00:34:58.632 align:middle line:-1
我们会提供便利内核给这个框架

00:34:59.199 --> 00:35:02.236 align:middle line:-1
方便来回转换图像和矩阵

00:34:59.199 --> 00:35:02.236 align:middle line:-1
方便来回转换图像和矩阵

00:35:03.136 --> 00:35:04.438 align:middle line:-1
那么要复制

00:35:05.205 --> 00:35:06.607 align:middle line:0
一张图像到矩阵

00:35:06.673 --> 00:35:10.077 align:middle line:0
需要使用
MPSImageCopyToMatrix内核

00:35:10.143 --> 00:35:11.812 align:middle line:0
这是创建方法

00:35:12.145 --> 00:35:15.883 align:middle line:0
以及如何给一批图像编码

00:35:17.084 --> 00:35:21.955 align:middle line:0
目的矩阵的每行都含有一个源图像

00:35:23.056 --> 00:35:25.459 align:middle line:0
要从矩阵复制到图像

00:35:25.926 --> 00:35:29.162 align:middle line:0
需要内核
MPSMatrixCopyToImage

00:35:29.229 --> 00:35:30.697 align:middle line:0
这一部分是创建

00:35:30.998 --> 00:35:33.267 align:middle line:0
这部分是在GPU上编码

00:35:35.302 --> 00:35:40.807 align:middle line:-2
大家已经了解了如何使用MPS
训练CNN和RNN

00:35:41.808 --> 00:35:44.344 align:middle line:-2
也看过了
Turi Create的演示

00:35:44.411 --> 00:35:46.180 align:middle line:-1
现在由MPS驱动

00:35:46.246 --> 00:35:47.881 align:middle line:-1
现在再看一个演示

00:35:49.550 --> 00:35:51.218 align:middle line:-1
我们在与Google合作

00:35:51.285 --> 00:35:53.987 align:middle line:-1
添加Metal性能着色器框架

00:35:54.054 --> 00:35:56.323 align:middle line:-1
给TensorFlow…

00:35:57.090 --> 00:35:59.193 align:middle line:-1
以提升macOS机器学习的速度

00:35:59.259 --> 00:36:01.495 align:middle line:-1
也给大家带来了动态演示

00:35:59.259 --> 00:36:01.495 align:middle line:-1
也给大家带来了动态演示

00:36:01.562 --> 00:36:03.864 align:middle line:-1
具体来说 我们要演示的是

00:36:03.931 --> 00:36:07.034 align:middle line:-2
训练InceptionV3
对象分类网络

00:36:08.135 --> 00:36:10.737 align:middle line:-2
使用TensorFlow
驱动是MPS

00:36:11.638 --> 00:36:12.739 align:middle line:-1
这个演示中

00:36:14.608 --> 00:36:18.545 align:middle line:-2
我还是使用MacBook Pro
外接一个GPU

00:36:19.313 --> 00:36:22.883 align:middle line:-2
TensorFlow
在MacBook Pro上

00:36:23.317 --> 00:36:27.454 align:middle line:-2
外部GPU
用MPS训练网络

00:36:27.921 --> 00:36:29.056 align:middle line:-1
演示设置

00:36:29.623 --> 00:36:31.358 align:middle line:-2
我己安装了
TensorFlow

00:36:31.658 --> 00:36:34.761 align:middle line:-2
也预先加载了
InceptionV3网络

00:36:34.862 --> 00:36:36.196 align:middle line:-1
和训练数据集

00:36:36.263 --> 00:36:39.499 align:middle line:-1
现在训练网络30次迭代

00:36:41.001 --> 00:36:42.970 align:middle line:-1
你看速度多快

00:36:43.437 --> 00:36:44.705 align:middle line:-1
同样 整个网络

00:36:44.838 --> 00:36:47.808 align:middle line:-2
所有原语
优化器和权重更新步骤

00:36:48.075 --> 00:36:50.277 align:middle line:-1
都是在外部GPU上运行

00:36:50.777 --> 00:36:51.912 align:middle line:-1
这就完成了

00:36:52.479 --> 00:36:53.714 align:middle line:-1
大家看到

00:36:53.780 --> 00:36:57.117 align:middle line:-2
训练速度大概是
每秒100张图

00:36:57.784 --> 00:37:00.721 align:middle line:-1
平台状态汇总中说过

00:36:57.784 --> 00:37:00.721 align:middle line:-1
平台状态汇总中说过

00:37:01.188 --> 00:37:03.557 align:middle line:-1
训练InceptionV3网络

00:37:04.157 --> 00:37:06.226 align:middle line:-2
用MPS驱动的
TensorFlow

00:37:06.727 --> 00:37:10.364 align:middle line:-2
要比不用MPS
快20倍

00:37:11.231 --> 00:37:13.367 align:middle line:-1
以上就是TensorFlow演示

00:37:16.203 --> 00:37:17.404 align:middle line:-1
谢谢大家

00:37:22.042 --> 00:37:23.710 align:middle line:-1
现在做个总结

00:37:24.845 --> 00:37:27.648 align:middle line:-2
今年新添加了
FP16计算

00:37:28.081 --> 00:37:30.984 align:middle line:-1
给卷积和卷积转置原语

00:37:31.552 --> 00:37:34.621 align:middle line:-1
提升CNN推断的性能

00:37:35.255 --> 00:37:37.691 align:middle line:-1
我们还添加了GPU加速原语

00:37:37.891 --> 00:37:39.359 align:middle line:-1
用于训练神经网络

00:37:39.426 --> 00:37:43.330 align:middle line:-2
这些原语都已优化
可用于iOS和macOS

00:37:44.765 --> 00:37:47.534 align:middle line:-2
我们还为训练添加了
神经网络图形API

00:37:48.468 --> 00:37:51.538 align:middle line:-1
简化了GPU上对神经网络的训练

00:37:51.839 --> 00:37:53.040 align:middle line:-1
并让我们可以

00:37:53.106 --> 00:37:56.243 align:middle line:-2
让不同的GPU
都达到最佳性能

00:37:58.745 --> 00:38:02.115 align:middle line:0
本场演讲的更多信息
相关资源的链接

00:37:58.745 --> 00:38:02.115 align:middle line:0
本场演讲的更多信息
相关资源的链接

00:38:02.182 --> 00:38:03.984 align:middle line:0
请访问开发者网站

00:38:05.586 --> 00:38:08.689 align:middle line:0
在明早9点的
Metal机器学习实验室

00:38:09.089 --> 00:38:12.092 align:middle line:0
希望能见到你们
欢迎参加

00:38:13.861 --> 00:38:17.965 align:middle line:-2
谢谢大家的到来
愿你们在WWDC中度过美好时光
