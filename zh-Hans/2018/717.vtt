WEBVTT

00:00:16.917 --> 00:00:19.887 align:middle line:0
（Vision与Core ML
简化强大的计算机视觉）

00:00:19.953 --> 00:00:20.988 align:middle line:0
（演讲717）

00:00:25.292 --> 00:00:28.061 align:middle line:-1
下午好 欢迎来到WWDC

00:00:28.328 --> 00:00:30.831 align:middle line:-1
我知道我现正与咖啡和饼干竞争

00:00:30.898 --> 00:00:33.100 align:middle line:-1
但我不知道咖啡是否是无麸质的

00:00:33.166 --> 00:00:34.701 align:middle line:-1
以及饼干是否不含咖啡因

00:00:34.768 --> 00:00:35.869 align:middle line:-1
所以坚持下去

00:00:36.203 --> 00:00:39.373 align:middle line:-2
我叫Frank Doepke
我将谈一些你可使用Core ML

00:00:39.439 --> 00:00:43.310 align:middle line:-2
和Vision框架做的
关于计算机视觉的有趣事情

00:00:44.244 --> 00:00:45.779 align:middle line:-1
那么今天我们要谈什么呢？

00:00:46.580 --> 00:00:49.183 align:middle line:-2
首先 你可能听说过
我们在自定义图像分类方面

00:00:49.249 --> 00:00:52.152 align:middle line:-1
为你准备了一些特别的东西

00:00:53.220 --> 00:00:55.389 align:middle line:-1
然后我们将谈一下对象识别

00:00:56.356 --> 00:00:59.693 align:middle line:-2
最后但同样重要的是
我将通过深入探讨一些基础知识

00:00:59.760 --> 00:01:01.862 align:middle line:-1
来提升你对Vision的理解水平

00:00:59.760 --> 00:01:01.862 align:middle line:-1
来提升你对Vision的理解水平

00:01:04.164 --> 00:01:06.066 align:middle line:-1
现在先看看自定义图像分类

00:01:07.267 --> 00:01:11.638 align:middle line:-2
我们已经在之前的演示中
看到了一些优点

00:01:11.705 --> 00:01:14.141 align:middle line:-2
我们看到比如
我们可以用鲜花和水果做些什么

00:01:14.208 --> 00:01:17.311 align:middle line:-1
我和其他人一样喜欢鲜花和水果

00:01:17.411 --> 00:01:20.214 align:middle line:-2
抱歉 Lizzie
我们会在此做些更有技术性的事

00:01:20.848 --> 00:01:25.352 align:middle line:-2
我的意思是 如果我们创建一个商店
我们可以做什么 我们都是极客

00:01:25.419 --> 00:01:27.421 align:middle line:-2
所以让我们创建一个
可以建造机器人的商店

00:01:27.487 --> 00:01:29.690 align:middle line:-1
因此我们需要识别一些零件

00:01:30.357 --> 00:01:33.727 align:middle line:-2
我认为如果我有一个
可以帮助客户识别

00:01:33.794 --> 00:01:36.797 align:middle line:-1
这些物体是什么的app会很棒

00:01:38.232 --> 00:01:40.901 align:middle line:-2
所以我们必须为此
训练一个自定义分类器

00:01:41.602 --> 00:01:42.436 align:middle line:-1
然后

00:01:43.170 --> 00:01:47.040 align:middle line:-2
一旦我们有了分类器
我们根据它构建一个iOS app

00:01:47.307 --> 00:01:49.309 align:middle line:-1
其可以在我们的设备上运行

00:01:50.110 --> 00:01:54.281 align:middle line:-2
在经历这些过程时
我将介绍一些你在做这类事情时

00:01:54.348 --> 00:01:56.216 align:middle line:-1
遇到的常见陷阱

00:01:56.517 --> 00:01:58.151 align:middle line:-1
并尝试引导你避开它们

00:02:00.854 --> 00:02:02.356 align:middle line:-1
让我们从训练开始吧

00:02:03.323 --> 00:02:05.526 align:middle line:-2
我们如何训练呢？
当然是使用Create ML

00:02:07.060 --> 00:02:10.229 align:middle line:-2
当然 我们要做的第一步是
我们必须拍照

00:02:11.231 --> 00:02:13.567 align:middle line:-1
然后我们将照片放在文件夹中

00:02:13.634 --> 00:02:16.870 align:middle line:-1
我们使用文件夹名称作为分类标签

00:02:18.805 --> 00:02:21.341 align:middle line:-1
现在 每个人都会问的一个问题是

00:02:21.408 --> 00:02:22.743 align:middle line:-1
“我需要多少数据”

00:02:23.977 --> 00:02:29.850 align:middle line:-2
首先 我们每个类别
至少需要10张图片

00:02:29.917 --> 00:02:33.487 align:middle line:-1
但这是偏低的 你肯定想拥有更多

00:02:33.554 --> 00:02:36.657 align:middle line:-2
越多越好
实际上是你的分类器会表现得更好

00:02:38.425 --> 00:02:41.528 align:middle line:-2
需要注意的另一件事是
高度不平衡的数据集

00:02:41.595 --> 00:02:42.629 align:middle line:-1
这是什么意思呢？

00:02:42.930 --> 00:02:46.033 align:middle line:-2
当数据集中的一个类别
包含数千个图像

00:02:46.099 --> 00:02:49.469 align:middle line:-2
而在另一个类别中只有十个时
这个模型的训练效果不会很好

00:02:49.536 --> 00:02:51.905 align:middle line:-1
因此你想在大多数类别之间

00:02:51.972 --> 00:02:53.574 align:middle line:-1
拥有一个更为均匀的分布

00:02:55.609 --> 00:02:59.413 align:middle line:-1
我们引入的另一件事是增强

00:03:00.013 --> 00:03:03.217 align:middle line:-1
增强将帮助你使此模型更加强大

00:03:04.017 --> 00:03:05.919 align:middle line:-1
但它并没有取代多样性

00:03:05.986 --> 00:03:10.691 align:middle line:-2
所以你仍然希望拥有许多
想要分类的对象图像

00:03:11.258 --> 00:03:13.694 align:middle line:0
但通过增强 我们要做的是

00:03:13.760 --> 00:03:15.596 align:middle line:0
我们拍摄一张照片并扰乱它

00:03:15.996 --> 00:03:19.399 align:middle line:0
我们对其添加噪声 模糊它
旋转它 翻转它

00:03:19.466 --> 00:03:22.503 align:middle line:0
所以当我们训练它时
它在分类器看来有所不同

00:03:24.738 --> 00:03:27.474 align:middle line:-1
我们来看一下训练的实际运作方式

00:03:29.343 --> 00:03:32.346 align:middle line:-2
你可能已经听过
“迁移学习”这个术语

00:03:32.412 --> 00:03:35.616 align:middle line:-2
这正是当我们训练分类器时
在Create ML中使用的方法

00:03:36.283 --> 00:03:38.385 align:middle line:-1
我们从一个预训练模型开始

00:03:38.452 --> 00:03:40.554 align:middle line:-1
这是所有繁重过程发生的地方

00:03:40.621 --> 00:03:44.958 align:middle line:-2
这些模型通常训练数周
并且有数百万张图像

00:03:45.158 --> 00:03:48.562 align:middle line:-1
这是你需要实际使用它的第一个起点

00:03:50.364 --> 00:03:53.800 align:middle line:-1
我们可以将该模型当做特征提取器

00:03:53.867 --> 00:03:56.670 align:middle line:-1
这可以给我们一个特征向量

00:03:56.737 --> 00:03:58.305 align:middle line:-1
它是我们图像中物体的数字描述

00:03:59.373 --> 00:04:02.242 align:middle line:-2
现在你引入自己的数据
我们使用你的标签数据训练该集合

00:03:59.373 --> 00:04:02.242 align:middle line:-2
现在你引入自己的数据
我们使用你的标签数据训练该集合

00:04:02.309 --> 00:04:05.078 align:middle line:0
我们称之为最后一层
即真正的分类器

00:04:05.579 --> 00:04:09.183 align:middle line:0
最终输出你的自定义模型

00:04:11.285 --> 00:04:14.588 align:middle line:-1
我提到了这个大型的首次预训练模型

00:04:15.322 --> 00:04:17.257 align:middle line:-2
本次演讲中
带来Vision的新特性

00:04:17.324 --> 00:04:20.127 align:middle line:-2
我们称之为面向场景的
Vision FeaturePrint

00:04:20.961 --> 00:04:22.696 align:middle line:-1
它可在Create ML中使用

00:04:23.363 --> 00:04:25.866 align:middle line:-1
并允许你训练图像分类器

00:04:27.668 --> 00:04:30.304 align:middle line:-2
它已经在一个非常大的
数据集上进行过训练

00:04:31.371 --> 00:04:35.042 align:middle line:-1
它能够分类超过一千个类别

00:04:35.309 --> 00:04:39.046 align:middle line:-2
这是一个你可以使用的
非常好的发行版

00:04:40.681 --> 00:04:41.782 align:middle line:-1
我们已经使用过它了

00:04:41.849 --> 00:04:44.484 align:middle line:-2
在过去三年中
你可能已经在Photos中见过的

00:04:44.551 --> 00:04:48.522 align:middle line:-2
一些面向用户的功能
实际上它们在底层使用了此模型

00:04:49.923 --> 00:04:53.493 align:middle line:-2
我们也将继续改进该模型
但也有一点需要注意

00:04:53.560 --> 00:04:55.329 align:middle line:-1
我想在此强调一下

00:04:56.630 --> 00:04:59.333 align:middle line:-1
当我们推出该模型的新版本时

00:04:59.399 --> 00:05:01.768 align:middle line:-1
你不一定会自动获得它的改进

00:04:59.399 --> 00:05:01.768 align:middle line:-1
你不一定会自动获得它的改进

00:05:01.835 --> 00:05:04.071 align:middle line:-1
除非你使用新模型重新训练

00:05:04.605 --> 00:05:06.840 align:middle line:-1
所以如果你今年开始用它来开发

00:05:06.907 --> 00:05:07.774 align:middle line:-1
并且你想

00:05:07.841 --> 00:05:10.611 align:middle line:-1
利用我们未来几年推出的特性

00:05:10.944 --> 00:05:14.581 align:middle line:-2
保留你的数据集
以便你可以重新进行训练

00:05:16.950 --> 00:05:19.920 align:middle line:-2
再谈一些关于我们的
特征提取器的更多内容

00:05:21.889 --> 00:05:23.357 align:middle line:-1
它已经存在在设备上

00:05:23.423 --> 00:05:25.859 align:middle line:-1
这对我们来说是一个重要的决定

00:05:26.460 --> 00:05:31.265 align:middle line:-2
因为它使你的模型的
磁盘占用空间显著减小

00:05:32.032 --> 00:05:33.500 align:middle line:-1
让我们稍微比较一下

00:05:34.001 --> 00:05:38.505 align:middle line:0
我选择了一些我们今天常用的模型

00:05:38.872 --> 00:05:42.676 align:middle line:0
首先是Resnet
若我在Resnet上训练分类器

00:05:42.743 --> 00:05:45.746 align:middle line:0
我的模型有多大呢？
98兆字节

00:05:47.281 --> 00:05:50.083 align:middle line:0
如果我使用Squeezenet
它是一个小得多的模型

00:05:50.150 --> 00:05:53.086 align:middle line:0
它无法区分很多的类别

00:05:53.754 --> 00:05:55.289 align:middle line:0
它的大小为5兆字节

00:05:55.355 --> 00:05:58.859 align:middle line:0
所以这很不错
但问题是它没那么强大

00:05:59.493 --> 00:06:00.594 align:middle line:0
Vision怎样？

00:05:59.493 --> 00:06:00.594 align:middle line:0
Vision怎样？

00:06:01.728 --> 00:06:03.931 align:middle line:0
在大多数情况下
它不到1兆字节

00:06:06.233 --> 00:06:09.403 align:middle line:-2
我们相信这对你来说
是一个好选择的另一个原因是

00:06:10.070 --> 00:06:11.338 align:middle line:0
它已经经过优化

00:06:11.638 --> 00:06:15.375 align:middle line:0
我们了解我们的硬件
或者说GPU和CPU

00:06:15.442 --> 00:06:17.044 align:middle line:0
我们对该模型进行了大量优化

00:06:17.878 --> 00:06:21.415 align:middle line:0
因此它在我们的设备上表现最佳

00:06:24.318 --> 00:06:25.853 align:middle line:-1
我们如何使用它来训练呢？

00:06:26.954 --> 00:06:31.058 align:middle line:-2
我们从一些带标签的图像开始
并将它们放入Create ML

00:06:31.391 --> 00:06:35.395 align:middle line:-2
而Create ML知道如何从中提取
Vision FeaturePrint

00:06:36.563 --> 00:06:38.198 align:middle line:-1
它训练我们的分类器

00:06:38.465 --> 00:06:42.402 align:middle line:-2
并且该分类器实际上就是最终
将进入Core ML模型中的东西

00:06:42.469 --> 00:06:43.837 align:middle line:-1
这就是它如此之小的原因

00:06:45.372 --> 00:06:48.141 align:middle line:-1
当我真正想要分析图像的时候

00:06:48.809 --> 00:06:53.747 align:middle line:-1
我所要做的就是使用我的图像和模型

00:06:53.814 --> 00:06:57.618 align:middle line:-2
在Vision或Core ML中
它在底层知道如何

00:06:57.885 --> 00:07:01.855 align:middle line:-2
使用我们的
Vision FeaturePrint

00:06:57.885 --> 00:07:01.855 align:middle line:-2
使用我们的
Vision FeaturePrint

00:07:01.922 --> 00:07:04.124 align:middle line:-1
并向我们返回分类

00:07:07.227 --> 00:07:09.997 align:middle line:-2
这就是我们需要了解的
关于训练的东西

00:07:10.864 --> 00:07:14.101 align:middle line:-1
但我说过当我们处理app时

00:07:14.168 --> 00:07:15.636 align:middle line:-1
还有一些注意事项

00:07:16.637 --> 00:07:17.471 align:middle line:-1
所以

00:07:18.605 --> 00:07:20.474 align:middle line:-1
首先 我们只想

00:07:20.541 --> 00:07:22.676 align:middle line:-1
在必要的时候才运行我们的分类器

00:07:24.444 --> 00:07:26.513 align:middle line:-1
分类器是深度卷积网络

00:07:26.580 --> 00:07:28.615 align:middle line:-1
它是计算密集型的

00:07:28.682 --> 00:07:32.219 align:middle line:-2
所以当我们运行它时
它肯定会用掉

00:07:32.452 --> 00:07:35.155 align:middle line:-1
CPU和GPU上运行的一些电子

00:07:35.422 --> 00:07:38.058 align:middle line:-2
所以除非你真的需要
否则你不想使用它

00:07:38.892 --> 00:07:41.862 align:middle line:-1
在我稍后演示的例子中

00:07:42.696 --> 00:07:46.366 align:middle line:-2
我实际上只想在用户
真正看一件物体时才进行分类

00:07:46.433 --> 00:07:48.235 align:middle line:-1
而不是在相机四处移动时

00:07:50.037 --> 00:07:53.073 align:middle line:-2
所以我问的问题是
“我拿稳相机了吗？”

00:07:53.140 --> 00:07:55.075 align:middle line:-1
然后我才运行我的分类器

00:07:56.009 --> 00:07:59.847 align:middle line:-2
我该怎么做？
我可以通过Vision进行配准

00:08:00.080 --> 00:08:03.917 align:middle line:-2
配准意味着我可以拍摄两张图像
并将它们相互对齐

00:08:03.984 --> 00:08:06.954 align:middle line:-2
它会告诉我
“如果你把它移动这些像素

00:08:07.020 --> 00:08:09.022 align:middle line:-1
它们就能完全匹配”

00:08:09.523 --> 00:08:13.460 align:middle line:-2
这是一个非常便宜且快速的算法
它会告诉我

00:08:13.527 --> 00:08:17.164 align:middle line:-2
我是否拿稳了相机
或者相机前面是否有物体在移动

00:08:19.666 --> 00:08:22.536 align:middle line:0
我使用了VNTranslationalImage
RegistrationRequest

00:08:22.603 --> 00:08:27.674 align:middle line:0
我知道这很绕口
但这包含了所有这些信息

00:08:28.108 --> 00:08:31.011 align:middle line:0
为了将其可视化
让我们看一下这个小视频

00:08:31.445 --> 00:08:35.082 align:middle line:0
我在这个视频中所做的是
我显示一条黄线

00:08:35.148 --> 00:08:37.017 align:middle line:0
它会告诉我在过去几帧中

00:08:37.083 --> 00:08:39.919 align:middle line:-1
相机如何移动

00:08:39.986 --> 00:08:41.621 align:middle line:-1
或者说配准请求如何求移动

00:08:41.688 --> 00:08:44.925 align:middle line:0
所以注意看那条黄线
如果它很长 则说明我的相机

00:08:44.992 --> 00:08:47.327 align:middle line:0
移动了很多
如果我拿稳相机

00:08:47.394 --> 00:08:48.962 align:middle line:0
则它应该是一条很短的线

00:08:50.964 --> 00:08:53.734 align:middle line:0
你可以看到相机正在移动
现在我对准这里

00:08:54.434 --> 00:08:55.602 align:middle line:0
它变得很短

00:08:56.937 --> 00:08:59.239 align:middle line:0
这是个好主意
这就像是说“现在我拿稳相机了

00:08:59.306 --> 00:09:01.041 align:middle line:0
现在可以运行我的分类器了”

00:08:59.306 --> 00:09:01.041 align:middle line:0
现在可以运行我的分类器了”

00:09:03.677 --> 00:09:05.312 align:middle line:-1
要记住的下一件事是

00:09:05.946 --> 00:09:07.047 align:middle line:-1
制定备用计划

00:09:07.614 --> 00:09:09.049 align:middle line:-1
有一个备用计划总是好的

00:09:09.750 --> 00:09:11.852 align:middle line:-1
分类可能有误

00:09:13.554 --> 00:09:14.421 align:middle line:-1
这意味着

00:09:14.488 --> 00:09:17.457 align:middle line:-1
即使我的分类具有很高的置信度

00:09:17.524 --> 00:09:21.094 align:middle line:-2
我还是需要为它无法
正常工作而做准备

00:09:22.462 --> 00:09:24.431 align:middle line:-1
我在这个例子中做的一件事是

00:09:24.498 --> 00:09:26.500 align:middle line:-2
正如你稍后将看到的那样
我有一些东西

00:09:26.567 --> 00:09:29.236 align:middle line:-2
其中没有实体对象
那么我该如何解决呢？

00:09:29.603 --> 00:09:31.772 align:middle line:-2
我的例子中
我正使用Vision框架中的

00:09:31.839 --> 00:09:33.507 align:middle line:-1
条形码检测器

00:09:33.574 --> 00:09:36.343 align:middle line:-1
来读取条形码标签以识别它

00:09:37.211 --> 00:09:38.645 align:middle line:-1
我们看的幻灯片足够多了

00:09:39.313 --> 00:09:40.447 align:middle line:-1
谁想看演示

00:09:52.993 --> 00:09:56.997 align:middle line:-1
你在屏幕右侧看到的是我的设备

00:09:57.464 --> 00:10:00.767 align:middle line:-1
我现在启动我的小机器人商店app

00:09:57.464 --> 00:10:00.767 align:middle line:-1
我现在启动我的小机器人商店app

00:10:01.568 --> 00:10:04.438 align:middle line:-2
你可以看到当我四处移动时
什么都没有发生

00:10:04.738 --> 00:10:07.474 align:middle line:-1
当我静止不动并且对准某些东西时

00:10:07.674 --> 00:10:09.877 align:middle line:-2
我可以看到一条黄线
然后 瞧

00:10:09.943 --> 00:10:11.512 align:middle line:-1
没错 这的确是一个步进电机

00:10:12.112 --> 00:10:14.381 align:middle line:-1
让我们看看这张桌子上还有什么

00:10:18.418 --> 00:10:19.953 align:middle line:-1
那是我的微控制器

00:10:23.323 --> 00:10:24.625 align:middle line:-1
这是一个步进电机驱动器

00:10:25.092 --> 00:10:27.661 align:middle line:-2
我们也可以拿起一件东西
然后对准它

00:10:29.596 --> 00:10:31.365 align:middle line:-1
是的 这是一个闭环带

00:10:35.269 --> 00:10:37.137 align:middle line:-2
这是什么
这是一个导螺杆

00:10:37.638 --> 00:10:40.741 align:middle line:-1
如我所说 你也可以查看条形码

00:10:41.408 --> 00:10:43.143 align:middle line:-1
我需要把数据线拉长一点

00:10:46.013 --> 00:10:47.848 align:middle line:-1
这是我的培训课程

00:10:48.382 --> 00:10:49.383 align:middle line:-2
-嘿 Frank
-当然 因为我没有…

00:10:49.750 --> 00:10:50.617 align:middle line:-1
Frank？

00:10:51.685 --> 00:10:52.519 align:middle line:-1
发生了什么事？

00:10:53.420 --> 00:10:54.254 align:middle line:-1
Frank

00:10:56.256 --> 00:10:59.927 align:middle line:-2
我需要你在演示中添加
另一个机器人零件

00:11:00.060 --> 00:11:01.728 align:middle line:-1
这是Brett 他是我的经理

00:11:04.331 --> 00:11:05.165 align:middle line:-1
那样就太好了

00:11:08.468 --> 00:11:11.338 align:middle line:-2
像往常一样 管理层
最后一刻的需求

00:11:12.272 --> 00:11:14.174 align:middle line:-2
我将确保你得到该备忘录的
另一份副本

00:11:15.275 --> 00:11:17.444 align:middle line:-1
我可不打算周六来干这事儿

00:11:18.212 --> 00:11:20.948 align:middle line:-2
好吧 这是什么？
这是一台伺服电机

00:11:21.982 --> 00:11:24.318 align:middle line:-2
好吧 让我们看看
说不定它能成功呢

00:11:25.586 --> 00:11:26.753 align:middle line:-1
让我试一试

00:11:28.088 --> 00:11:32.259 align:middle line:-2
我能搞定它吗？
不 它无法识别这个对象

00:11:32.326 --> 00:11:33.160 align:middle line:-1
这样呢？

00:11:33.827 --> 00:11:36.797 align:middle line:-2
不 它不是步进电机
所以这是一个漏洞

00:11:37.831 --> 00:11:39.132 align:middle line:-1
我想我们需解决这个问题

00:11:39.800 --> 00:11:40.901 align:middle line:-1
谁想解决这个问题

00:11:42.536 --> 00:11:43.403 align:middle line:-1
噢

00:11:44.371 --> 00:11:47.374 align:middle line:-2
谁想解决这个问题
就是这样

00:11:49.376 --> 00:11:52.246 align:middle line:-1
所以我现在要做的就是

00:11:52.312 --> 00:11:54.948 align:middle line:-1
拍摄一些该伺服电机的照片

00:11:55.449 --> 00:11:59.219 align:middle line:-2
我可能需要去工作室
你知道 设置好灯什么的

00:11:59.820 --> 00:12:03.991 align:middle line:-2
或者 我可以使用
我最喜欢的这个相机

00:11:59.820 --> 00:12:03.991 align:middle line:-2
或者 我可以使用
我最喜欢的这个相机

00:12:05.259 --> 00:12:06.827 align:middle line:-1
现在 让我们看看

00:12:06.894 --> 00:12:09.730 align:middle line:-1
我们将拍摄一堆伺服电机的照片

00:12:12.366 --> 00:12:13.700 align:middle line:-1
而且我需要

00:12:13.767 --> 00:12:16.870 align:middle line:-2
从不同角度拍摄它
并且确保画面中没有任何其它东西

00:12:23.110 --> 00:12:26.980 align:middle line:-1
我需要至少十张不同的图像

00:12:27.447 --> 00:12:30.784 align:middle line:-2
很好的选择
我喜欢把它放在不同的背景上

00:12:35.189 --> 00:12:37.391 align:middle line:-1
并确保拍到这些角落

00:12:37.457 --> 00:12:39.960 align:middle line:-1
再把它放在手上

00:12:46.834 --> 00:12:49.503 align:middle line:-1
好的 我们现在有了很多图像

00:12:51.271 --> 00:12:52.472 align:middle line:-1
现在我要打开Mac

00:12:52.539 --> 00:12:55.609 align:middle line:-1
并实际向你展示如何对其进行训练

00:12:57.144 --> 00:12:57.978 align:middle line:-1
好的

00:12:59.546 --> 00:13:02.015 align:middle line:-1
我打开Image Capture app

00:12:59.546 --> 00:13:02.015 align:middle line:-1
我打开Image Capture app

00:13:02.082 --> 00:13:06.253 align:middle line:-2
让我暂时隐藏
我的QuickTime播放器

00:13:09.089 --> 00:13:10.757 align:middle line:-1
如果我现在查看我的Finder

00:13:10.824 --> 00:13:12.693 align:middle line:-1
你可以看到这是我的训练集

00:13:12.759 --> 00:13:15.796 align:middle line:-2
我之前用它们来训练
我的当前app中使用的

00:13:15.863 --> 00:13:17.164 align:middle line:-1
那个模型

00:13:17.764 --> 00:13:19.600 align:middle line:-1
我现在需要创建一个新文件夹

00:13:21.168 --> 00:13:22.736 align:middle line:-1
让我们称之为Servo

00:13:25.772 --> 00:13:30.644 align:middle line:-2
在Image Capture中
我可以简单地将我刚拍摄的所有照片

00:13:34.481 --> 00:13:37.584 align:middle line:-1
拖入我的Servo文件夹

00:13:41.088 --> 00:13:44.191 align:middle line:-1
好的 现在我们已经添加了它们

00:13:44.558 --> 00:13:46.293 align:middle line:-1
现在我需要再次训练我的模型

00:13:46.860 --> 00:13:51.031 align:middle line:-2
因为我的经理刚刚打乱了
我之前所做的事情

00:13:52.165 --> 00:13:55.135 align:middle line:-2
我在这里使用了一个
简单的Playground脚本

00:13:55.536 --> 00:13:57.538 align:middle line:-2
而不是使用用户界面
这是因为

00:13:57.604 --> 00:14:00.040 align:middle line:-1
我稍后想将它作为构建步骤

00:13:57.604 --> 00:14:00.040 align:middle line:-1
我稍后想将它作为构建步骤

00:14:00.107 --> 00:14:01.441 align:middle line:-1
合并到我的app中

00:14:02.342 --> 00:14:06.113 align:middle line:-2
我将其指向我们刚添加到
文件夹中的数据集

00:14:06.613 --> 00:14:08.949 align:middle line:-1
然后只是简单地训练我的分类器

00:14:09.349 --> 00:14:11.318 align:middle line:-1
最后保存我的模型

00:14:12.686 --> 00:14:16.757 align:middle line:0
现在发生的是 你可以看到
我们已经开始训练了

00:14:17.324 --> 00:14:23.263 align:middle line:0
它将遍历我们文件夹中的
所有这些图像

00:14:23.330 --> 00:14:25.432 align:middle line:0
并从中提取场景打印

00:14:25.532 --> 00:14:28.068 align:middle line:-1
它进行了所有必须的缩放操作

00:14:28.335 --> 00:14:32.139 align:middle line:-1
最后将基于此训练出一个模型

00:14:32.339 --> 00:14:35.042 align:middle line:-2
这是一项非常复杂的任务
但你知道 对你来说

00:14:35.108 --> 00:14:38.645 align:middle line:-2
它只需要一行代码
最终就可以得到

00:14:38.712 --> 00:14:41.048 align:middle line:-1
你可以在app中实际使用的模型

00:14:41.648 --> 00:14:43.250 align:middle line:-1
它刚刚结束 我们来看看

00:14:44.751 --> 00:14:46.053 align:middle line:-1
马上就完成了

00:14:47.087 --> 00:14:48.856 align:middle line:-1
瞧 这就是我们的模型

00:14:53.060 --> 00:14:54.127 align:middle line:-1
那个模型

00:14:54.194 --> 00:14:57.531 align:middle line:-2
我已在我的机器人商店app中
引用过它

00:14:57.598 --> 00:14:58.999 align:middle line:-1
这就是我们现在看到的内容

00:15:00.033 --> 00:15:01.768 align:middle line:-1
如你所见 这是我的图像分类器

00:15:01.835 --> 00:15:03.937 align:middle line:-1
它的大小为148千字节

00:15:04.438 --> 00:15:07.741 align:middle line:-1
这实际上比我的小启动画面还要小

00:15:15.849 --> 00:15:17.951 align:middle line:-2
这里有一件我想强调的事
我们稍后再谈

00:15:18.018 --> 00:15:19.786 align:middle line:-1
这个图像

00:15:21.321 --> 00:15:26.593 align:middle line:-2
也就是我需要传给它的图像
须是299x299像素的彩色图像

00:15:26.660 --> 00:15:30.163 align:middle line:-2
奇怪的参数
但实际上很多分类器都这么干

00:15:31.365 --> 00:15:35.602 align:middle line:-2
好的 现在我有了一个
但愿能够理解它的模型

00:15:35.936 --> 00:15:39.039 align:middle line:-1
现在我要打开我复杂的产品数据库

00:15:39.106 --> 00:15:40.741 align:middle line:-1
它只是一个键列表

00:15:42.109 --> 00:15:44.411 align:middle line:-1
我要把我的Servo添加到那里

00:15:48.081 --> 00:15:50.817 align:middle line:-2
我对它进行重命名
这是Servo

00:15:52.686 --> 00:15:56.056 align:middle line:-2
给它一个标签
这将是我们实际看到的东西

00:15:56.390 --> 00:15:59.326 align:middle line:-1
这里该填伺服电机

00:16:00.761 --> 00:16:04.798 align:middle line:-1
对于描述 我们可以这样写

00:16:04.865 --> 00:16:10.604 align:middle line:-1
一个会嗖嗖响的电机

00:16:12.105 --> 00:16:15.843 align:middle line:-2
非常具有技术性
让我们看看这是否奏效

00:16:17.211 --> 00:16:18.712 align:middle line:-1
我现在要运行我的app

00:16:21.481 --> 00:16:22.316 align:middle line:-1
那是…

00:16:28.322 --> 00:16:30.324 align:middle line:0
好的 我们来试试吧

00:16:32.759 --> 00:16:34.027 align:middle line:0
这就是我们的伺服电机

00:16:42.336 --> 00:16:45.239 align:middle line:-2
从另一个角度看
这是你看到的世界第一个

00:16:45.305 --> 00:16:47.474 align:middle line:-1
在舞台上现场训练的分类器

00:16:47.541 --> 00:16:49.943 align:middle line:-2
从照片开始
一直到最终的app

00:16:50.711 --> 00:16:52.079 align:middle line:-1
我对这个演示着实捏了把汗

00:16:55.616 --> 00:16:56.450 align:middle line:-1
谢谢

00:17:01.788 --> 00:17:04.625 align:middle line:-1
现在我们已经看到它是如何工作的

00:17:04.691 --> 00:17:07.160 align:middle line:-1
但我想在查看代码时强调一些事情

00:17:08.862 --> 00:17:10.964 align:middle line:0
我保证我们将在这里现场写一些代码

00:17:12.199 --> 00:17:13.032 align:middle line:0
好的

00:17:14.134 --> 00:17:16.770 align:middle line:0
让我把一切不需要的东西都关掉

00:17:18.704 --> 00:17:19.873 align:middle line:0
并让它更大一些

00:17:22.108 --> 00:17:25.012 align:middle line:-1
好的 我是如何解决这一切的呢？

00:17:25.345 --> 00:17:28.949 align:middle line:-2
一开始 我们创建了一个
序列请求处理程序

00:17:29.016 --> 00:17:31.885 align:middle line:-1
它被用于进行配准

00:17:31.952 --> 00:17:34.821 align:middle line:-2
正如Sergei
在上个演讲中提到的

00:17:35.222 --> 00:17:36.857 align:middle line:-1
它非常擅长跟踪对象

00:17:37.925 --> 00:17:41.528 align:middle line:-2
然后创建我的请求
将它们放入一个数组中

00:17:41.595 --> 00:17:43.197 align:middle line:-1
你在这里看到的是 对于配准

00:17:43.263 --> 00:17:46.433 align:middle line:-1
只保留最近15个配准结果

00:17:46.767 --> 00:17:48.535 align:middle line:-1
然后我会对其做一些分析

00:17:48.602 --> 00:17:50.204 align:middle line:-1
来看看我是否真的拿稳了相机

00:17:51.238 --> 00:17:53.907 align:middle line:-1
当分析它们时 我要保留一个

00:17:53.974 --> 00:17:55.209 align:middle line:-1
用于此目的的缓冲区

00:17:55.275 --> 00:17:57.311 align:middle line:-1
这实际上就是分类所运行的地方

00:17:58.645 --> 00:18:01.315 align:middle line:-1
并且由于这是一个很耗时的任务

00:17:58.645 --> 00:18:01.315 align:middle line:-1
并且由于这是一个很耗时的任务

00:18:01.381 --> 00:18:03.217 align:middle line:-1
我将在一个单独的队列上运行它

00:18:05.853 --> 00:18:08.689 align:middle line:-1
这是我用来打开

00:18:08.755 --> 00:18:11.024 align:middle line:-1
我们刚刚看到的小面板的一些代码

00:18:11.458 --> 00:18:14.494 align:middle line:-2
但最重要的一点是
我该如何设置我的Vision任务

00:18:15.095 --> 00:18:16.530 align:middle line:-1
我要完成两项任务

00:18:16.597 --> 00:18:18.498 align:middle line:-1
首先是条形码请求

00:18:18.632 --> 00:18:20.934 align:middle line:-1
然后是我的分类请求

00:18:21.001 --> 00:18:22.970 align:middle line:-1
我设置了我的条形码请求

00:18:23.904 --> 00:18:25.672 align:middle line:-1
在我的完成处理程序中

00:18:25.739 --> 00:18:28.041 align:middle line:-2
我只是查看
“我得到了任何结果吗？”

00:18:28.909 --> 00:18:32.312 align:middle line:-1
而且因为我只期待一个条形码

00:18:32.379 --> 00:18:34.181 align:middle line:-1
所以我只看第一个

00:18:34.915 --> 00:18:35.983 align:middle line:-1
我能解码它吗

00:18:36.049 --> 00:18:38.519 align:middle line:-2
如果我从中得到一个字符串
我将用它进行查找

00:18:38.585 --> 00:18:40.854 align:middle line:-1
这实际上就是我刚才如何用条码打开

00:18:40.921 --> 00:18:42.589 align:middle line:-1
“哦 没错 那是我的训练课程”

00:18:43.957 --> 00:18:47.027 align:middle line:0
我将其添加为我想要运行的请求之一

00:18:47.294 --> 00:18:49.596 align:middle line:-1
现在我开始设置我的分类

00:18:49.930 --> 00:18:53.200 align:middle line:-1
这里我所做的是 我使用分类器

00:18:53.267 --> 00:18:56.403 align:middle line:-1
我从包中加载它

00:18:57.237 --> 00:18:59.173 align:middle line:-1
并以此创建我的模型

00:18:59.339 --> 00:19:02.176 align:middle line:-2
在这种情况下 我没使用
Core ML的代码完成功能

00:18:59.339 --> 00:19:02.176 align:middle line:-2
在这种情况下 我没使用
Core ML的代码完成功能

00:19:02.242 --> 00:19:05.479 align:middle line:-2
因为这是我的app中使用的
唯一一行Core ML代码

00:19:05.546 --> 00:19:09.249 align:middle line:-1
它允许我进行自定义类型的错误处理

00:19:09.316 --> 00:19:12.619 align:middle line:-2
但你也可以选择使用
Core ML中的代码完成功能

00:19:12.686 --> 00:19:16.857 align:middle line:-2
两者都绝对有效
我由它创建我的Vision模型

00:19:17.124 --> 00:19:20.460 align:middle line:-2
Vision Core ML模型
以及请求

00:19:20.661 --> 00:19:23.697 align:middle line:-1
同样 当请求返回时

00:19:23.764 --> 00:19:26.233 align:middle line:-1
这意味着会执行我的完成处理程序

00:19:26.733 --> 00:19:30.838 align:middle line:-2
我只是检查
我得到的是什么样的分类

00:19:31.705 --> 00:19:33.740 align:middle line:-1
然后我在这里设置此阈值

00:19:34.141 --> 00:19:37.277 align:middle line:-1
这是我凭经验设定的置信度目标

00:19:37.344 --> 00:19:42.316 align:middle line:-2
我使用的是0.98
即有98%的信心它是正确的

00:19:43.383 --> 00:19:44.685 align:middle line:-1
为什么我要这样做？

00:19:45.185 --> 00:19:46.854 align:middle line:-1
这允许我过滤掉

00:19:46.920 --> 00:19:49.256 align:middle line:-2
当我在看某物体时
不太确定那是什么的情况

00:19:49.323 --> 00:19:51.491 align:middle line:-1
我们稍后会看到这是什么意思

00:19:52.893 --> 00:19:54.595 align:middle line:-1
现在我准备好了所有的请求

00:19:55.562 --> 00:19:57.764 align:middle line:-1
当我真正想要执行它们的时候

00:19:57.831 --> 00:19:59.466 align:middle line:-1
我在这里创建了一个小函数

00:19:59.533 --> 00:20:01.902 align:middle line:-1
它的作用是分析当前图像

00:19:59.533 --> 00:20:01.902 align:middle line:-1
它的作用是分析当前图像

00:20:02.503 --> 00:20:07.307 align:middle line:-2
在分析它的时候
我得到了我的设备方向

00:20:07.374 --> 00:20:10.944 align:middle line:-2
这对于了解我正如何拿着手机
非常重要

00:20:11.845 --> 00:20:13.280 align:middle line:-1
我创建了图像请求处理程序

00:20:13.347 --> 00:20:16.717 align:middle line:-1
在我们当前想要处理的缓冲区上

00:20:17.885 --> 00:20:22.022 align:middle line:-1
并且我让它异步地执行它的工作

00:20:24.291 --> 00:20:26.860 align:middle line:-2
这就是为了使用Core ML
进行处理和条码扫描

00:20:26.927 --> 00:20:29.530 align:middle line:-1
我所需要做的所有事情

00:20:30.264 --> 00:20:34.535 align:middle line:-1
我如何实现场景稳定性部分的呢？

00:20:34.601 --> 00:20:36.303 align:middle line:-1
我有一个可以重置的队列

00:20:36.770 --> 00:20:39.139 align:middle line:-1
我可以将我的点添加进去

00:20:39.940 --> 00:20:44.044 align:middle line:-1
然后我创建了一个函数

00:20:44.111 --> 00:20:46.313 align:middle line:-1
它允许我遍历所记录的点队列

00:20:46.480 --> 00:20:49.216 align:middle line:-1
并且设定“如果它们全部加起来

00:20:49.449 --> 00:20:51.418 align:middle line:-1
只有不到20像素的距离”

00:20:51.485 --> 00:20:53.654 align:middle line:-1
同样 这也是我选择的经验值

00:20:53.820 --> 00:20:56.256 align:middle line:-2
然后我就知道场景是稳定的
即我拿稳了手机

00:20:56.323 --> 00:20:58.225 align:middle line:-1
我的相机前面没有东西在移动

00:20:59.826 --> 00:21:01.662 align:middle line:-1
然后是我们捕捉输出的部分

00:20:59.826 --> 00:21:01.662 align:middle line:-1
然后是我们捕捉输出的部分

00:21:01.728 --> 00:21:04.298 align:middle line:-2
这就是
AVFoundation通过

00:21:04.364 --> 00:21:05.832 align:middle line:-1
相机的缓冲区对我们的调用

00:21:06.567 --> 00:21:08.001 align:middle line:-1
我需要确保

00:21:08.068 --> 00:21:10.137 align:middle line:-1
获取到前一个像素缓冲区

00:21:10.204 --> 00:21:13.507 align:middle line:-2
因为这是我为了配准
要进行比较的东西

00:21:13.974 --> 00:21:17.077 align:middle line:-1
并在完成之后将它们换掉

00:21:17.845 --> 00:21:20.347 align:middle line:-1
我使用当前的缓冲区创建了一个

00:21:20.414 --> 00:21:21.648 align:middle line:-2
TranslationalImage
RegistrationRequest对象

00:21:22.616 --> 00:21:24.351 align:middle line:-1
然后我在序列请求处理程序上

00:21:24.418 --> 00:21:26.520 align:middle line:-1
执行我的请求

00:21:27.287 --> 00:21:31.124 align:middle line:-2
现在我得到了我的观察
我可以检查一下它们是否正常

00:21:31.625 --> 00:21:33.227 align:middle line:-1
并将它们添加到我的数组中

00:21:34.428 --> 00:21:37.898 align:middle line:-2
最后但同样重要的是
我还要检查场景是否稳定

00:21:38.498 --> 00:21:43.370 align:middle line:-2
然后我将显示我的小黄框
它是一个检测叠层

00:21:44.404 --> 00:21:46.974 align:middle line:-1
我知道这是我当前分析的缓冲区

00:21:47.708 --> 00:21:52.446 align:middle line:-1
并要求它对此进行分析

00:21:54.581 --> 00:21:59.753 align:middle line:-2
我在当前分析的缓冲区中的
异步调用结束时所做的一件事是

00:21:59.820 --> 00:22:02.322 align:middle line:-1
我释放了该缓冲区

00:21:59.820 --> 00:22:02.322 align:middle line:-1
我释放了该缓冲区

00:22:02.856 --> 00:22:06.560 align:middle line:-2
你在这里可以看到我正在检查
当前是否有一个缓冲区正被使用

00:22:06.860 --> 00:22:10.230 align:middle line:-2
这可以让我确保
我只在一个缓冲区上工作

00:22:10.297 --> 00:22:11.532 align:middle line:-1
并且我不会总是在它们

00:22:11.598 --> 00:22:13.767 align:middle line:-2
还在后台运行时
将越来越多缓冲区放入队列

00:22:13.834 --> 00:22:16.236 align:middle line:-1
因为这会使相机得不到足够的帧

00:22:17.371 --> 00:22:18.739 align:middle line:-1
好的 当我们运行的时候

00:22:18.805 --> 00:22:20.841 align:middle line:-1
我想要强调一些事情

00:22:20.908 --> 00:22:23.210 align:middle line:0
我们先来讨论第一件事

00:22:24.444 --> 00:22:26.480 align:middle line:0
我们看看底部的控制台

00:22:26.680 --> 00:22:30.484 align:middle line:0
你可以看到 当我刚开始运行时

00:22:31.118 --> 00:22:32.886 align:middle line:0
我现在要在这里运行

00:22:35.889 --> 00:22:37.491 align:middle line:0
以便你能看到它

00:22:38.325 --> 00:22:41.261 align:middle line:0
你可以看到置信度得分很低

00:22:41.328 --> 00:22:42.596 align:middle line:0
我只是在拍摄白色背景

00:22:42.663 --> 00:22:45.032 align:middle line:-1
它不确定我正在看的是什么

00:22:45.499 --> 00:22:48.735 align:middle line:-1
而当我对准它应该能识别的东西时

00:22:50.237 --> 00:22:51.905 align:middle line:-1
我们的置信度得分非常高

00:22:51.972 --> 00:22:55.609 align:middle line:-2
这就是我如何确定
这是我想要展示的对象

00:22:56.810 --> 00:22:58.779 align:middle line:-1
我想要演示的另一件事…

00:23:01.782 --> 00:23:04.885 align:middle line:-1
让我们看一下CPU的实际情况

00:23:07.087 --> 00:23:08.655 align:middle line:-1
好的 现在我什么都没做

00:23:08.722 --> 00:23:11.458 align:middle line:-1
我只是在显示我的屏幕

00:23:12.159 --> 00:23:14.795 align:middle line:-1
当我四处移动相机时

00:23:15.629 --> 00:23:19.533 align:middle line:-2
场景不稳定
CPU的使用率大约为22%

00:23:19.900 --> 00:23:22.336 align:middle line:-2
现在如果我保持稳定
这时分类器开始运行

00:23:22.402 --> 00:23:24.037 align:middle line:-1
你可以看到CPU使用率上升

00:23:24.671 --> 00:23:28.675 align:middle line:-2
这就是为什么我总是建议
只在你真正需要时才运行这些任务

00:23:31.044 --> 00:23:33.914 align:middle line:-1
好的 我们刚才讲了很多东西

00:23:34.081 --> 00:23:35.549 align:middle line:-1
让我们回到幻灯片

00:23:35.949 --> 00:23:38.452 align:middle line:-1
并回顾一下我们刚刚看到的内容

00:23:40.254 --> 00:23:41.255 align:middle line:-1
回到幻灯片

00:23:48.161 --> 00:23:52.733 align:middle line:-2
好的 回顾一下
首先是我们如何实现场景稳定性的

00:23:53.867 --> 00:23:55.602 align:middle line:-1
我们使用了序列请求处理程序

00:23:55.669 --> 00:23:58.739 align:middle line:-2
以及VNTranslationalImage
RegistrationRequest

00:24:00.107 --> 00:24:02.075 align:middle line:-1
来与前一帧进行比较

00:24:03.343 --> 00:24:08.282 align:middle line:-2
除此之外 我们从alignmentTransform中
得到了平移方式

00:24:08.348 --> 00:24:11.885 align:middle line:-1
它告诉我前一帧如何移动X和Y

00:24:12.786 --> 00:24:14.221 align:middle line:-1
从而达到当前这帧

00:24:15.923 --> 00:24:19.359 align:middle line:-2
然后我们谈到
我们只想在场景稳定时进行分析

00:24:20.194 --> 00:24:22.262 align:middle line:-1
为此 我们创建了

00:24:22.329 --> 00:24:25.032 align:middle line:-2
当前缓冲区的
VNImageRequestHandler

00:24:25.933 --> 00:24:27.568 align:middle line:-1
并且我们一起传入

00:24:27.701 --> 00:24:31.538 align:middle line:-1
条码检测请求和分类请求

00:24:32.105 --> 00:24:35.142 align:middle line:-1
这允许Vision在底层进行优化

00:24:35.309 --> 00:24:39.079 align:middle line:-1
这比将它们作为单独的请求运行

00:24:39.146 --> 00:24:40.547 align:middle line:-1
要快得多

00:24:43.083 --> 00:24:47.287 align:middle line:-2
下一部分关于我们在运行时
需要多大的缓冲区

00:24:47.588 --> 00:24:49.656 align:middle line:-1
所以说要“管理你的缓冲区”

00:24:50.858 --> 00:24:54.094 align:middle line:-2
有些Vision请求
如这类卷积网络

00:24:54.161 --> 00:24:55.362 align:middle line:-1
可能耗费较长时间

00:24:55.896 --> 00:24:58.465 align:middle line:-1
这些运行时间更长的任务最好

00:24:58.532 --> 00:25:02.803 align:middle line:-2
运行在后台队列上 以便你的UI
或你在相机中做的任何事情

00:24:58.532 --> 00:25:02.803 align:middle line:-2
运行在后台队列上 以便你的UI
或你在相机中做的任何事情

00:25:02.870 --> 00:25:04.471 align:middle line:-1
可以继续运行而不会卡死

00:25:04.972 --> 00:25:06.840 align:middle line:-1
但在做这点时 特别是对于相机

00:25:06.907 --> 00:25:10.143 align:middle line:-2
你不想持续将来自相机的缓冲区
放入队列

00:25:10.210 --> 00:25:14.381 align:middle line:-2
所以你应该放弃繁忙的缓冲区
在这个例子中 我说过我只用了一个

00:25:14.448 --> 00:25:16.950 align:middle line:-2
这实际上在我的用例场景中
效果非常好

00:25:17.184 --> 00:25:20.621 align:middle line:-2
我用的是大小为1的队列
这就是为什么我只检查一个缓冲区

00:25:20.687 --> 00:25:23.624 align:middle line:-2
只要它正在运行
我就不会将新的缓冲区放入队列

00:25:23.891 --> 00:25:28.161 align:middle line:-2
当其处理完成后
我就可以重置并处理下一个缓冲区

00:25:31.131 --> 00:25:32.399 align:middle line:-1
现在你可能会问

00:25:32.699 --> 00:25:35.569 align:middle line:-2
当我能在Core ML中运行
该模型时 为何要用Vision？

00:25:35.636 --> 00:25:36.770 align:middle line:-1
这毕竟是Core ML模型啊

00:25:38.138 --> 00:25:41.842 align:middle line:-2
以下是使用Vision的
一个重要原因

00:25:42.242 --> 00:25:45.279 align:middle line:-1
让我们回过头看看我们的模型

00:25:45.579 --> 00:25:49.149 align:middle line:-1
这是奇怪的299x299像素参数

00:25:49.550 --> 00:25:51.518 align:middle line:-1
这就是这个模型的训练方式

00:25:51.585 --> 00:25:53.253 align:middle line:-1
这就是它想要作为输入的内容

00:25:53.787 --> 00:25:56.790 align:middle line:-2
但是相机给我们的是
640x480的照片

00:25:56.857 --> 00:25:58.825 align:middle line:-2
或更高的分辨率
如果你愿意的话

00:25:59.793 --> 00:26:03.964 align:middle line:-2
而Vision将完成所有这些工作
它获取这些来自相机的YUV缓冲区

00:25:59.793 --> 00:26:03.964 align:middle line:-2
而Vision将完成所有这些工作
它获取这些来自相机的YUV缓冲区

00:26:04.031 --> 00:26:07.234 align:middle line:-1
将其转换为RGB并缩放图像

00:26:07.301 --> 00:26:09.036 align:middle line:0
而你不必为此编写任何代码

00:26:09.436 --> 00:26:12.773 align:middle line:0
这使得用Vision驱动这些
Core ML模型

00:26:12.840 --> 00:26:14.541 align:middle line:0
来处理图像请求变得更加容易

00:26:17.411 --> 00:26:21.682 align:middle line:-2
以上就是图像分类的内容
接下来 我们将讨论对象识别

00:26:24.518 --> 00:26:27.120 align:middle line:-2
一点警告
在这个演示中 一个活羊角面包

00:26:27.187 --> 00:26:28.455 align:middle line:-1
可能会在舞台上受伤

00:26:28.522 --> 00:26:30.424 align:middle line:-2
所以对于那些娇气的人
请把目光移开

00:26:34.528 --> 00:26:38.699 align:middle line:-1
我们用于对象识别的模型

00:26:38.765 --> 00:26:42.703 align:middle line:-2
基于这种YOLO技术
即“你只看一次”

00:26:43.036 --> 00:26:45.072 align:middle line:-1
这是一个运行非常快速的模型

00:26:45.138 --> 00:26:50.310 align:middle line:-2
它允许我们获取对象的边界框
并为其添加标签

00:26:50.844 --> 00:26:52.513 align:middle line:-1
并且它可以在屏幕上找到多个对象

00:26:52.579 --> 00:26:54.014 align:middle line:-1
如这幅截图所示

00:26:57.451 --> 00:27:01.054 align:middle line:-2
它的优势在于我可以得到
比如它们的位置

00:26:57.451 --> 00:27:01.054 align:middle line:-2
它的优势在于我可以得到
比如它们的位置

00:27:01.121 --> 00:27:02.990 align:middle line:-1
但我不会得到整体图像分类器

00:27:03.056 --> 00:27:06.126 align:middle line:-1
能够得到的那么多的分类

00:27:07.361 --> 00:27:10.664 align:middle line:-1
这与训练也有一定关系

00:27:10.731 --> 00:27:14.301 align:middle line:-2
对于这个话题 我推荐你
观看Turi Create演讲

00:27:14.368 --> 00:27:15.469 align:middle line:-1
它是在昨天举办的

00:27:15.903 --> 00:27:18.505 align:middle line:-1
其向你展示了如何训练这类模型

00:27:18.672 --> 00:27:19.973 align:middle line:-1
这些模型也有点大

00:27:21.708 --> 00:27:24.645 align:middle line:-2
那么这看起来效果如何
我们来看看演示

00:27:30.584 --> 00:27:32.152 align:middle line:-1
机器人商店打烊了

00:27:35.422 --> 00:27:36.490 align:middle line:-1
现在是早餐时间

00:27:42.162 --> 00:27:43.030 align:middle line:-1
好的

00:27:43.864 --> 00:27:45.599 align:middle line:-1
打开QuickTime播放器

00:27:45.666 --> 00:27:49.469 align:middle line:-2
这是我的新app
它是一个早餐查找器

00:27:52.239 --> 00:27:54.641 align:middle line:-2
我们看到了什么
哦 这里有一个羊角面包

00:27:55.042 --> 00:27:58.612 align:middle line:-2
我们有一个百吉饼
我们也可以识别香蕉

00:28:00.180 --> 00:28:02.416 align:middle line:-1
现在它们都显示在一个屏幕中

00:28:02.482 --> 00:28:03.750 align:middle line:-1
我来识别它们

00:28:04.785 --> 00:28:07.087 align:middle line:-2
正如我所提到的
在一些烹饪节目中

00:28:07.154 --> 00:28:08.922 align:middle line:-1
它们通常会告诉你如何操作

00:28:09.122 --> 00:28:11.391 align:middle line:-1
但却将预烘烤的东西从烤箱中拿出来

00:28:12.426 --> 00:28:18.031 align:middle line:-2
而这个模型实际上在这个羊角面包
出炉之前早就烤好了

00:28:18.098 --> 00:28:19.233 align:middle line:-1
我可以证明这一点

00:28:21.668 --> 00:28:25.239 align:middle line:-2
它很新鲜
并且它还是一个羊角面包

00:28:34.281 --> 00:28:35.115 align:middle line:-1
好的

00:28:38.385 --> 00:28:40.521 align:middle line:-1
这很新鲜 但我还是要好好咀嚼

00:28:44.525 --> 00:28:47.160 align:middle line:-1
让我们快速看一下代码的样子

00:28:53.133 --> 00:28:54.768 align:middle line:-1
那么我做了哪些不同的事情呢？

00:28:56.069 --> 00:28:59.039 align:middle line:-2
在设置我的请求方面
实际上很少改变

00:28:59.673 --> 00:29:03.277 align:middle line:-2
我所要做的就是
使用我的Core ML模型

00:28:59.673 --> 00:29:03.277 align:middle line:-2
我所要做的就是
使用我的Core ML模型

00:29:03.343 --> 00:29:09.416 align:middle line:-2
就像我在上一个示例中所做的那样
创建我的Core ML请求

00:29:09.483 --> 00:29:12.152 align:middle line:-2
然后这段代码就是简单的
我如何绘制我的结果

00:29:17.357 --> 00:29:21.128 align:middle line:-2
这里有一些新的东西
来让这更容易一些

00:29:21.795 --> 00:29:26.767 align:middle line:-2
当我们看这些代码时
我们发现一个新的对象

00:29:26.834 --> 00:29:30.971 align:middle line:-1
即VNRecognizedObjectObservation

00:29:31.538 --> 00:29:36.877 align:middle line:-2
此外 这是我的边界框
以及观察标签

00:29:37.945 --> 00:29:39.947 align:middle line:-1
我还想向你展示一件事

00:29:40.781 --> 00:29:43.584 align:middle line:-2
让我们从这里运行我们的app
并设置一个断点

00:29:51.291 --> 00:29:52.192 align:middle line:-1
好的

00:29:53.927 --> 00:29:55.662 align:middle line:-1
好的 我们现在正处于断点

00:29:56.129 --> 00:29:58.098 align:middle line:-1
我只查看第一个标签

00:29:58.165 --> 00:30:01.468 align:middle line:-2
当我们实际处理这些结果时
我们正在做什么

00:29:58.165 --> 00:30:01.468 align:middle line:-2
当我们实际处理这些结果时
我们正在做什么

00:30:04.471 --> 00:30:05.606 align:middle line:-1
我们看看这个

00:30:11.612 --> 00:30:14.648 align:middle line:0
查看一下
objectObservation的

00:30:16.416 --> 00:30:17.351 align:middle line:0
labels属性

00:30:19.520 --> 00:30:22.990 align:middle line:0
你可以看到我实际上
得到不止一个结果

00:30:23.290 --> 00:30:26.960 align:middle line:0
这里有百吉饼 香蕉 咖啡
今天我没带咖啡

00:30:27.027 --> 00:30:30.797 align:middle line:0
不好意思
还有羊角面包 鸡蛋和华夫饼干

00:30:30.864 --> 00:30:34.902 align:middle line:0
它们按照置信度进行排序
置信度高的在最上面

00:30:34.968 --> 00:30:37.070 align:middle line:-1
它通常是你所感兴趣的

00:30:37.137 --> 00:30:40.107 align:middle line:-2
这就是为什么我在这里
抄捷径并只查看第一个结果

00:30:40.240 --> 00:30:43.043 align:middle line:-1
但你总是得到所有的分类

00:30:43.110 --> 00:30:46.914 align:middle line:-2
它们保存在一个数组中
其中包含了我们支持的所有类别

00:30:48.515 --> 00:30:51.418 align:middle line:-1
这就是我们的早餐查找器

00:30:51.485 --> 00:30:53.854 align:middle line:-2
让我们回到幻灯片
这次我来按这个按钮

00:30:54.021 --> 00:30:54.855 align:middle line:-1
好

00:30:58.458 --> 00:31:00.360 align:middle line:-1
我们通过使用一个新的API

00:30:58.458 --> 00:31:00.360 align:middle line:-1
我们通过使用一个新的API

00:31:00.661 --> 00:31:05.165 align:middle line:-2
即我们的VNRecognized
ObjectObservation来使这成为可能

00:31:07.234 --> 00:31:11.471 align:middle line:-2
当我们执行
CoreMLModelRequest

00:31:11.538 --> 00:31:17.144 align:middle line:-2
且若该模型实际上基于对象检测器时
我们就会自动得到它

00:31:20.848 --> 00:31:23.851 align:middle line:-2
如该示例一样
它是基于YOLO的模型

00:31:23.917 --> 00:31:27.154 align:middle line:-2
现在你可能会说
“我也可以像去年那样运行YOLO

00:31:27.221 --> 00:31:29.022 align:middle line:-1
我在网上看到了很多相关文章”

00:31:29.756 --> 00:31:32.626 align:middle line:-1
但是看看他们实际需要编写多少代码

00:31:32.693 --> 00:31:34.561 align:middle line:-1
才能获取此模型的输出

00:31:34.628 --> 00:31:36.530 align:middle line:-1
并将它放入你可以使用的东西中

00:31:36.663 --> 00:31:38.899 align:middle line:-1
而我们在这里只用了几行代码

00:31:38.966 --> 00:31:41.401 align:middle line:-2
因此它使YOLO模型变得
非常容易使用

00:31:42.102 --> 00:31:43.837 align:middle line:-1
我们再来看一次这些代码

00:31:44.238 --> 00:31:48.208 align:middle line:-2
我创建了我的模型
根据该模型创建了我的请求

00:31:48.909 --> 00:31:52.913 align:middle line:-2
在我的完成处理程序中
我可以简单地看一下对象的区域

00:31:52.980 --> 00:31:55.449 align:middle line:-2
因为我们看到
我们可以得到多个对象

00:31:55.916 --> 00:31:58.385 align:middle line:-1
我从中获取标签和边界框

00:31:58.452 --> 00:32:00.387 align:middle line:-1
然后就可以将其显示到早餐查找器中

00:31:58.452 --> 00:32:00.387 align:middle line:-1
然后就可以将其显示到早餐查找器中

00:32:04.091 --> 00:32:06.927 align:middle line:-1
我想在这个例子中强调一件事

00:32:08.328 --> 00:32:10.531 align:middle line:-1
你可以看到这些边界框有点抖动

00:32:10.597 --> 00:32:13.634 align:middle line:-1
因为我一帧一帧一帧地运行检测器

00:32:14.935 --> 00:32:17.137 align:middle line:-1
跟踪往往是这里更好的选择

00:32:17.271 --> 00:32:21.508 align:middle line:-1
为什么呢？即使在运行方面

00:32:21.575 --> 00:32:23.310 align:middle line:-1
跟踪也比运行这些模型要快得多

00:32:25.179 --> 00:32:29.750 align:middle line:-2
因此重新检测比运行跟踪请求
需要更多时间

00:32:31.218 --> 00:32:35.689 align:middle line:-2
只要我想在屏幕上跟踪某对象
我就可以使用跟踪器

00:32:37.057 --> 00:32:39.393 align:middle line:-2
因为它是一种更轻量级的算法
它运行得更快

00:32:39.826 --> 00:32:43.030 align:middle line:-1
最重要的是 我们有时间平滑

00:32:43.096 --> 00:32:45.065 align:middle line:-1
这样这些框就不再抖动了

00:32:45.132 --> 00:32:47.534 align:middle line:-1
如果你查看我们的一些跟踪示例

00:32:47.601 --> 00:32:50.237 align:middle line:-1
它们实际上在屏幕上移动得非常顺畅

00:32:50.871 --> 00:32:52.606 align:middle line:-1
如果你想了解有关跟踪的更多信息

00:32:54.074 --> 00:32:56.643 align:middle line:-1
我的同事Sergei的上一次演讲

00:32:56.877 --> 00:32:59.813 align:middle line:-1
讨论了如何实现这一点

00:33:01.982 --> 00:33:04.251 align:middle line:-1
好的 最后但同样重要的

00:33:04.318 --> 00:33:07.721 align:middle line:-2
让我们加强对Vision的掌握
并讨论一些基础知识

00:33:08.889 --> 00:33:11.959 align:middle line:-2
在使用Vision框架时
知道一些事情非常重要

00:33:12.893 --> 00:33:15.963 align:middle line:-1
首先是很多问题的常见根源

00:33:16.997 --> 00:33:18.165 align:middle line:-1
图像方向

00:33:19.933 --> 00:33:23.704 align:middle line:-2
并非所有的Vision算法
都与方向无关

00:33:24.004 --> 00:33:26.139 align:middle line:-2
你可能早些时候听说过
我们有一个新的

00:33:26.206 --> 00:33:28.575 align:middle line:-1
与方向无关的人脸检测器

00:33:29.042 --> 00:33:30.777 align:middle line:-1
但上一个则不是

00:33:32.079 --> 00:33:35.682 align:middle line:-2
这意味着我们需要知道
图像的直立位置是什么样

00:33:36.316 --> 00:33:37.985 align:middle line:-1
这可能有些让人迷惑

00:33:38.051 --> 00:33:40.454 align:middle line:-1
因为如果你看一下它并预览最终结果

00:33:40.687 --> 00:33:44.057 align:middle line:-2
我的图片看起来是直立的
但这不是它存储在磁盘上的方式

00:33:44.925 --> 00:33:48.228 align:middle line:-2
有样东西可以告诉我们
设备的方向是什么样的

00:33:48.295 --> 00:33:49.963 align:middle line:-1
这被称为EXIF方向

00:33:51.198 --> 00:33:55.402 align:middle line:-2
如果捕获了一张图像
它通常是传感器方向

00:33:55.469 --> 00:33:57.771 align:middle line:-2
通过EXIF 我们可以知道
直立是哪个方向

00:33:58.138 --> 00:34:02.276 align:middle line:-2
如果你将URL作为输入
传递给Vision

00:33:58.138 --> 00:34:02.276 align:middle line:-2
如果你将URL作为输入
传递给Vision

00:34:02.643 --> 00:34:05.179 align:middle line:-1
Vision实际上为你做了所有事

00:34:05.245 --> 00:34:07.848 align:middle line:-1
并从文件中读取此EXIF信息

00:34:09.149 --> 00:34:11.685 align:middle line:-1
但正如我们之前在演示中展示的那样

00:34:11.752 --> 00:34:13.620 align:middle line:-1
如果我使用实时捕获源

00:34:13.687 --> 00:34:15.755 align:middle line:-1
我将需要传递此信息

00:34:16.255 --> 00:34:17.491 align:middle line:-1
因此我必须查看

00:34:17.558 --> 00:34:21.161 align:middle line:-1
我的UI设备的当前方向是什么

00:34:21.562 --> 00:34:24.130 align:middle line:0
并将其转换为
CGImagePropertyOrientation

00:34:24.197 --> 00:34:26.900 align:middle line:0
因为我们需要它的
EXIF方向格式

00:34:29.402 --> 00:34:32.072 align:middle line:-1
接下来我们谈谈坐标系

00:34:33.440 --> 00:34:36.443 align:middle line:0
对于Vision
原点始终位于左下角

00:34:37.744 --> 00:34:43.016 align:middle line:0
并且所有处理都会假设
图像处于直立位置

00:34:43.382 --> 00:34:45.185 align:middle line:0
因此方向很重要

00:34:47.254 --> 00:34:50.489 align:middle line:0
我们所有的处理都是在
标准化的坐标空间中完成的

00:34:50.891 --> 00:34:54.360 align:middle line:0
除了配准 我们需要知道它
实际上有多少像素

00:34:54.828 --> 00:34:58.665 align:middle line:0
标准化坐标意味着我们的坐标是
从(0,0)

00:34:58.732 --> 00:35:00.767 align:middle line:0
到右上角的(1,1)

00:34:58.732 --> 00:35:00.767 align:middle line:0
到右上角的(1,1)

00:35:02.336 --> 00:35:03.270 align:middle line:-1
这是一个

00:35:03.337 --> 00:35:07.040 align:middle line:0
执行了面部和特征点检测请求的图片

00:35:07.474 --> 00:35:10.210 align:middle line:0
你可以看到我得到了脸上的边界框

00:35:10.277 --> 00:35:12.379 align:middle line:0
并且特征点以

00:35:12.446 --> 00:35:15.549 align:middle line:0
该边界框的相对坐标进行表示

00:35:17.251 --> 00:35:19.620 align:middle line:0
如果你需要回到图像坐标空间

00:35:19.686 --> 00:35:24.791 align:middle line:0
可以使用在VNUtils中的工具函数
如VNImageRectFromNormalizedRect

00:35:24.858 --> 00:35:27.661 align:middle line:0
来在这些坐标之间转换

00:35:31.331 --> 00:35:33.000 align:middle line:-1
接下来我们谈谈置信度分数

00:35:33.066 --> 00:35:36.703 align:middle line:-2
在我们的机器人商店示例中
我们已经对此有所接触

00:35:38.739 --> 00:35:42.876 align:middle line:-2
我们的许多算法都可以表示
它们对结果的信心

00:35:43.810 --> 00:35:48.982 align:middle line:-2
这在稍后分析我想要从结果中
得到什么时

00:35:49.049 --> 00:35:50.450 align:middle line:-1
是一个很重要的部分

00:35:50.517 --> 00:35:54.354 align:middle line:-2
我是得到一个为0的低置信度呢
还是得到一个为1的高置信度呢？

00:35:58.859 --> 00:35:59.693 align:middle line:-1
遥控器

00:36:02.296 --> 00:36:03.197 align:middle line:-1
好了

00:36:03.463 --> 00:36:07.935 align:middle line:-2
不幸的是 并非所有算法
都使用相同的标准

00:36:08.001 --> 00:36:11.071 align:middle line:-1
来衡量它们的置信度分数

00:36:11.605 --> 00:36:14.274 align:middle line:-2
例如 如果看看我们的文本检测器
它几乎总是

00:36:14.341 --> 00:36:17.878 align:middle line:-2
返回一个值为1的置信度得分
因为如果它不认为这是文字

00:36:17.945 --> 00:36:20.347 align:middle line:-1
它一开始就不会返回边界框

00:36:21.215 --> 00:36:25.219 align:middle line:-2
但正如我们所看到的
分类器的置信度得分

00:36:25.285 --> 00:36:28.856 align:middle line:-2
则是一个较大的范围
我们来看几个例子

00:36:30.624 --> 00:36:31.892 align:middle line:-1
在我的第一个例子中

00:36:32.793 --> 00:36:35.395 align:middle line:-2
我使用了一张
机器人商店示例中的图像

00:36:36.096 --> 00:36:37.698 align:middle line:-1
我在它上面运行了自己的模型

00:36:38.332 --> 00:36:40.767 align:middle line:-1
果然 它有很高的置信度分数

00:36:40.834 --> 00:36:42.169 align:middle line:-1
并认为这是一个步进电机

00:36:43.670 --> 00:36:45.172 align:middle line:-1
在下面这个例子中

00:36:45.839 --> 00:36:48.876 align:middle line:-1
我将使用我们模型库中的一些模型

00:36:49.743 --> 00:36:53.080 align:middle line:-2
不要误会我的意思
我不是想比较模型的质量

00:36:53.146 --> 00:36:55.849 align:middle line:-1
而是关于它们返回的置信度

00:36:55.916 --> 00:36:57.584 align:middle line:-1
以及我们实际想要做的事情

00:36:58.552 --> 00:37:01.955 align:middle line:-2
当我们想要对这张图片进行分类时
它告诉了我们什么

00:36:58.552 --> 00:37:01.955 align:middle line:-2
当我们想要对这张图片进行分类时
它告诉了我们什么

00:37:03.390 --> 00:37:07.794 align:middle line:-2
嗯 它并没有那么糟糕
但它也不是很确定

00:37:08.095 --> 00:37:12.566 align:middle line:-2
只有0.395的置信度得分
不算特别高

00:37:12.633 --> 00:37:14.968 align:middle line:-2
但其中的确有沙滩
这的确是关于海滩的

00:37:15.502 --> 00:37:19.673 align:middle line:-2
所以当我想搜索它时
这结果基本上还算凑合

00:37:19.740 --> 00:37:22.809 align:middle line:-2
但我可以用它来标记图像吗
这可能是值得怀疑的

00:37:24.211 --> 00:37:25.512 align:middle line:-1
让我们看看下一个例子

00:37:26.980 --> 00:37:30.117 align:middle line:-2
摩托车上的女孩
分类器对此做了什么

00:37:31.752 --> 00:37:34.354 align:middle line:-1
嗯 我不确定她是否愿意被称为红薯

00:37:39.426 --> 00:37:43.096 align:middle line:-2
让我们再看一个例子
这是我的代码的屏幕截图

00:37:44.131 --> 00:37:45.799 align:middle line:-1
分类器对此做了什么

00:37:47.334 --> 00:37:49.937 align:middle line:-2
它认为这是一个网站
电脑实在太笨了

00:37:53.507 --> 00:37:56.343 align:middle line:-2
这是关于我们的置信度得分的
一些结论

00:37:58.245 --> 00:38:02.416 align:middle line:-2
1.0总是意味着100%正确吗？
不一定

00:37:58.245 --> 00:38:02.416 align:middle line:-2
1.0总是意味着100%正确吗？
不一定

00:38:02.816 --> 00:38:05.018 align:middle line:-1
它符合算法的标准

00:38:05.252 --> 00:38:09.756 align:middle line:-2
但我们的感知 正如我们看到的红薯
是完全不同的

00:38:11.425 --> 00:38:14.962 align:middle line:-2
所以当你创建一个
想要利用它的app时

00:38:15.028 --> 00:38:18.765 align:middle line:-2
请记住这一点 好好想一想
如果你写了一个医疗app

00:38:18.832 --> 00:38:23.003 align:middle line:-2
并说“哦 你有癌症”
这个观点可能过于绝对

00:38:23.070 --> 00:38:25.272 align:middle line:-1
你可能想要软化一点点

00:38:25.339 --> 00:38:28.041 align:middle line:-1
取决于你对结果的确切程度

00:38:30.577 --> 00:38:32.946 align:middle line:-1
为此你可以使用两种技术

00:38:33.413 --> 00:38:37.417 align:middle line:-2
正如我们在机器人商店示例中所见
我使用了置信度得分的阈值

00:38:37.484 --> 00:38:40.621 align:middle line:-1
因为我已经标记了图像

00:38:40.687 --> 00:38:42.956 align:middle line:-2
并且过滤掉置信度分数较低的
所有内容

00:38:43.590 --> 00:38:45.926 align:middle line:-2
另一方面
如果我想创建一个搜索app

00:38:45.993 --> 00:38:51.198 align:middle line:-2
我可能会使用我拥有的一些图像
并且可能仍将它们显示在

00:38:51.632 --> 00:38:54.368 align:middle line:-2
搜索结果下面
因为也许在搜索结果中

00:38:54.434 --> 00:38:56.069 align:middle line:-1
仍然可能有一个正确的选择

00:39:01.108 --> 00:39:04.611 align:middle line:-2
像往常一样 你可以在我们的网站上
找到更多信息

00:39:04.878 --> 00:39:07.514 align:middle line:-1
并且我们明天下午3点有个实验室

00:39:07.581 --> 00:39:10.651 align:middle line:-2
欢迎到访 咨询你的问题
我们随时为你提供帮助

00:39:11.552 --> 00:39:14.388 align:middle line:-1
接着我首先要感谢你们所有人

00:39:14.454 --> 00:39:16.990 align:middle line:-2
能够使用我们的技术创造出
这些出色的app

00:39:17.057 --> 00:39:19.526 align:middle line:-2
我期待看到你能用这些技术
所做出来的东西

00:39:19.927 --> 00:39:23.363 align:middle line:-2
最后谢谢大家来到WWDC
请享受余下的演讲 谢谢
