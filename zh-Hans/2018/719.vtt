WEBVTT

00:00:17.384 --> 00:00:21.555 align:middle line:0
（Core Image：
性能、原型和Python）

00:00:21.622 --> 00:00:22.623 align:middle line:0
（演讲719）

00:00:23.524 --> 00:00:24.358 align:middle line:-1
好

00:00:24.791 --> 00:00:25.626 align:middle line:-1
谢谢

00:00:27.294 --> 00:00:28.395 align:middle line:-1
大家下午好

00:00:28.462 --> 00:00:31.098 align:middle line:-2
感谢今天参加
Core Image会议

00:00:31.398 --> 00:00:32.533 align:middle line:-1
我叫David Hayward

00:00:32.698 --> 00:00:35.802 align:middle line:-2
我很高兴能够向大家介绍
我们团队在最近一年

00:00:35.869 --> 00:00:39.373 align:middle line:-1
添加到Core Image的

00:00:39.439 --> 00:00:40.541 align:middle line:-1
新性能及原型功能

00:00:41.041 --> 00:00:43.744 align:middle line:-2
我们有很多内容
所以让我们进入议程

00:00:44.511 --> 00:00:46.713 align:middle line:-1
今天要谈的第一件事就是

00:00:46.780 --> 00:00:49.116 align:middle line:-2
我们添加到Core Image的
一些很棒的新API

00:00:49.183 --> 00:00:51.785 align:middle line:-1
用以提高app的性能

00:00:52.319 --> 00:00:55.122 align:middle line:-1
之后 我们将转入另一个话题

00:00:55.189 --> 00:00:56.657 align:middle line:-1
即如何使用Core Image

00:00:56.723 --> 00:00:58.792 align:middle line:-1
以帮助原型新算法的开发

00:00:59.193 --> 00:01:02.362 align:middle line:-2
最后 我们将讨论
如何使用Core Image

00:00:59.193 --> 00:01:02.362 align:middle line:-2
最后 我们将讨论
如何使用Core Image

00:01:02.629 --> 00:01:05.632 align:middle line:-1
配合各种机器学习app

00:01:07.568 --> 00:01:09.803 align:middle line:-1
好 让我们开始

00:01:09.870 --> 00:01:11.505 align:middle line:-1
首先我们来说说性能API

00:01:11.572 --> 00:01:14.241 align:middle line:-1
今年 我们重点在两个领域

00:01:14.775 --> 00:01:15.676 align:middle line:-1
致力于提高性能

00:01:15.742 --> 00:01:18.278 align:middle line:-1
首先 我们新添了一些对插入

00:01:18.512 --> 00:01:19.813 align:middle line:-1
中间缓冲区的控制

00:01:19.980 --> 00:01:21.615 align:middle line:-1
我们将详细讨论这个问题

00:01:21.949 --> 00:01:23.684 align:middle line:-1
第二 我们将谈谈

00:01:23.750 --> 00:01:28.021 align:middle line:-2
你可以利用的
一些新CI内核语言功能

00:01:28.088 --> 00:01:31.358 align:middle line:-1
我们先来谈谈中间缓冲区

00:01:33.227 --> 00:01:35.495 align:middle line:-2
若你曾用过Core Image
那么你知道

00:01:35.562 --> 00:01:39.833 align:middle line:-2
Core Image让你轻松地
将过滤器序列连接在一起

00:01:40.167 --> 00:01:43.770 align:middle line:0
Core Image中每个过滤器
都由一个或多个内核组成

00:01:44.071 --> 00:01:46.173 align:middle line:0
Core Image的一项重要的

00:01:46.240 --> 00:01:49.376 align:middle line:0
提高性能的功能是连接内核

00:01:49.443 --> 00:01:51.979 align:middle line:0
以减少中间缓冲区的数量

00:01:52.145 --> 00:01:54.882 align:middle line:0
许多情况下
要获得你想要的最佳性能

00:01:54.948 --> 00:01:56.550 align:middle line:-1
你需要尽量减少缓冲区数

00:01:57.484 --> 00:01:59.486 align:middle line:-1
但是 有一些情况

00:01:59.786 --> 00:02:03.190 align:middle line:-1
你不希望最大量地连接

00:01:59.786 --> 00:02:03.190 align:middle line:-1
你不希望最大量地连接

00:02:03.857 --> 00:02:06.793 align:middle line:-2
例如 你的app里
可能有一个昂贵的过滤器

00:02:06.860 --> 00:02:08.461 align:middle line:-1
在过滤器链的早期

00:02:09.329 --> 00:02:10.864 align:middle line:-1
你的app的用户

00:02:10.931 --> 00:02:13.333 align:middle line:-1
在某个时刻可能正在调整

00:02:13.400 --> 00:02:14.768 align:middle line:-1
在图中跟随它的过滤器

00:02:15.135 --> 00:02:16.703 align:middle line:-1
这是一个经典的情况

00:02:16.770 --> 00:02:19.173 align:middle line:-1
中间缓冲区是个好主意

00:02:20.007 --> 00:02:22.109 align:middle line:-1
在介于两者之间的位置

00:02:22.809 --> 00:02:25.913 align:middle line:0
通过设这个中间缓冲区

00:02:26.180 --> 00:02:28.182 align:middle line:0
调整辅助过滤器时

00:02:28.415 --> 00:02:30.551 align:middle line:0
无需两次付出

00:02:30.717 --> 00:02:33.554 align:middle line:0
昂贵的过滤器的成本

00:02:34.087 --> 00:02:35.956 align:middle line:0
那么如何在app中操作？

00:02:36.023 --> 00:02:38.325 align:middle line:0
我们有一个新的API 顾名思义

00:02:38.859 --> 00:02:40.027 align:middle line:0
insertingIntermediate

00:02:40.794 --> 00:02:43.664 align:middle line:-1
我们谈谈这会如何影响我们的结果

00:02:43.730 --> 00:02:45.432 align:middle line:-1
我们所做的不是

00:02:45.499 --> 00:02:46.500 align:middle line:-1
尽可能多地连接

00:02:46.667 --> 00:02:49.136 align:middle line:-1
我们会尊重中间缓冲区的位置

00:02:49.369 --> 00:02:51.772 align:middle line:0
并尽可能多地连接它

00:02:53.207 --> 00:02:54.241 align:middle line:-1
这里有几点说明

00:02:54.308 --> 00:02:55.442 align:middle line:-1
要记住一件事

00:02:55.709 --> 00:02:57.244 align:middle line:-1
默认情况下

00:02:57.311 --> 00:02:59.413 align:middle line:-2
Core Image
对所有中间缓冲区作缓存

00:02:59.479 --> 00:03:02.249 align:middle line:-1
为后续生成作准备

00:02:59.479 --> 00:03:02.249 align:middle line:-1
为后续生成作准备

00:03:02.516 --> 00:03:03.717 align:middle line:-1
使之速度会更快

00:03:04.051 --> 00:03:05.986 align:middle line:-1
但是 有些时候

00:03:06.053 --> 00:03:08.856 align:middle line:-1
你会想关闭中间缓冲区的缓存

00:03:09.389 --> 00:03:13.093 align:middle line:-1
例如 如果你的app将要批量导出

00:03:13.160 --> 00:03:14.428 align:middle line:-1
100张图片

00:03:14.928 --> 00:03:17.364 align:middle line:-1
缓存第一个无益

00:03:17.431 --> 00:03:20.601 align:middle line:-1
因为后续生成的图像将完全不同

00:03:20.667 --> 00:03:22.669 align:middle line:-1
所以 你可以在你的app中实现它

00:03:22.736 --> 00:03:25.472 align:middle line:-2
使用上下文选项
cacheIntermediates

00:03:25.539 --> 00:03:27.040 align:middle line:-1
并将该值设置为false

00:03:28.542 --> 00:03:31.311 align:middle line:-1
但如果你也在使用这个我们刚谈到的

00:03:31.378 --> 00:03:32.279 align:middle line:-1
新API

00:03:32.713 --> 00:03:35.582 align:middle line:-1
你仍然可以打开中间缓冲区的缓存

00:03:35.649 --> 00:03:37.951 align:middle line:-1
即使此上下文选项是关闭的

00:03:38.318 --> 00:03:40.787 align:middle line:-1
所以 这可以让你真正确保

00:03:40.854 --> 00:03:42.756 align:middle line:-1
缓存需要的 不缓存任何其它内容

00:03:45.526 --> 00:03:47.461 align:middle line:-1
我想谈的下一个主题

00:03:47.528 --> 00:03:50.797 align:middle line:-1
是我们添加到内核语言的

00:03:51.732 --> 00:03:53.600 align:middle line:-1
一些应用图像处理的新功能

00:03:55.068 --> 00:03:57.304 align:middle line:-1
请记住 我们有两种方法

00:03:57.371 --> 00:03:59.706 align:middle line:-1
在Core Image中编写内核

00:04:00.307 --> 00:04:03.510 align:middle line:-1
传统的方法是CI内核语言

00:04:03.944 --> 00:04:06.813 align:middle line:-2
在这种情况下
源文件中有一个字符串

00:04:06.880 --> 00:04:09.249 align:middle line:-2
你的Swift代码
或你的objective C代码

00:04:09.583 --> 00:04:11.652 align:middle line:-1
在运行时 你调用

00:04:11.718 --> 00:04:13.754 align:middle line:-1
内核及源代码

00:04:14.688 --> 00:04:18.325 align:middle line:-1
稍后 当你基于该内核创建图像时

00:04:18.492 --> 00:04:21.228 align:middle line:-1
你可以生成任何类型的CI上下文

00:04:21.295 --> 00:04:25.566 align:middle line:-2
不论该上下文是由Metal
还是Open GL支持

00:04:26.934 --> 00:04:30.337 align:middle line:-1
然而 当生成时 需要翻译该源

00:04:30.404 --> 00:04:33.240 align:middle line:-2
需要将其翻译为
Metal或GLSL

00:04:33.607 --> 00:04:35.609 align:middle line:-1
并且这个步骤有成本

00:04:36.310 --> 00:04:40.113 align:middle line:0
最后 该代码被编译为GPU指令集

00:04:40.180 --> 00:04:41.181 align:middle line:-1
然后执行

00:04:42.616 --> 00:04:44.785 align:middle line:0
从去年的iOS 11开始

00:04:44.852 --> 00:04:46.987 align:middle line:0
我们添加了一种
编写CI内核的新方法

00:04:47.054 --> 00:04:48.956 align:middle line:0
具有一些显著优势

00:04:49.122 --> 00:04:52.059 align:middle line:0
这就是基于
Metal着色语言的CI内核

00:04:52.593 --> 00:04:55.596 align:middle line:0
这种情况下 你的项目中有源代码

00:04:55.662 --> 00:05:00.367 align:middle line:0
并且此源是在build时
而不是在运行时编译的

00:04:55.662 --> 00:05:00.367 align:middle line:0
并且此源是在build时
而不是在运行时编译的

00:05:01.502 --> 00:05:05.606 align:middle line:0
和以前一样
你可以根据此代码建内核

00:05:06.106 --> 00:05:10.277 align:middle line:0
使用带有Metal函数名
和二进制数据的内核

00:05:12.012 --> 00:05:16.383 align:middle line:0
其优势点是可以应用此数据

00:05:16.450 --> 00:05:18.886 align:middle line:0
而无需耗用额外编译资源

00:05:19.486 --> 00:05:23.690 align:middle line:-2
需要注意的是
它适用Metal支持的CI上下文

00:05:24.258 --> 00:05:26.126 align:middle line:-1
但它带来了巨大的性能优势

00:05:27.928 --> 00:05:29.897 align:middle line:-1
所以 从这个版本开始

00:05:29.963 --> 00:05:33.333 align:middle line:-1
我们将把CI内核语言标为已弃用

00:05:33.700 --> 00:05:36.303 align:middle line:-1
因为 虽然我们会继续支持这种语言

00:05:37.237 --> 00:05:39.706 align:middle line:-2
我们认为编写
Metal内核的新方法

00:05:39.773 --> 00:05:42.142 align:middle line:-1
为作为开发人员的你提供了很多优势

00:05:42.376 --> 00:05:45.479 align:middle line:-2
首先 你获得了
我之前概述的性能优势

00:05:45.546 --> 00:05:50.083 align:middle line:-2
它同时还提供了
build时代码语法着色

00:05:50.150 --> 00:05:52.619 align:middle line:-1
和优秀的调试工具的优势

00:05:52.920 --> 00:05:55.489 align:middle line:-1
如果你使用Metal源的话

00:05:57.958 --> 00:05:59.092 align:middle line:-1
好

00:06:03.630 --> 00:06:06.900 align:middle line:-1
考虑到这一点 我想谈谈其它几个

00:06:06.967 --> 00:06:09.469 align:middle line:-1
我们添加到内核语言中的功能

00:06:09.536 --> 00:06:11.738 align:middle line:-1
首先 我们增加了半浮动支持

00:06:12.139 --> 00:06:14.541 align:middle line:-1
很多情况下

00:06:14.741 --> 00:06:17.778 align:middle line:-1
当你的CI内核可完全

00:06:18.278 --> 00:06:20.547 align:middle line:-1
满足于半浮动带来的精度

00:06:20.781 --> 00:06:22.816 align:middle line:-1
如果你使用RGB颜色值

00:06:22.883 --> 00:06:24.852 align:middle line:-1
半浮点精度绰绰有余

00:06:25.419 --> 00:06:27.421 align:middle line:-1
在内核中使用半浮点数的优点

00:06:27.487 --> 00:06:29.523 align:middle line:-1
是它使操作运行得更快

00:06:29.590 --> 00:06:31.258 align:middle line:-1
尤其是在A11设备上

00:06:31.491 --> 00:06:32.626 align:middle line:-1
如iPhone 10

00:06:33.360 --> 00:06:35.996 align:middle line:-1
在内核中用半浮点数的另一个优点

00:06:36.063 --> 00:06:37.764 align:middle line:-1
它允许更小的寄存器

00:06:37.831 --> 00:06:40.200 align:middle line:-1
增加了GPU的利用率

00:06:40.267 --> 00:06:41.635 align:middle line:-1
这也有助于提高性能

00:06:42.236 --> 00:06:45.038 align:middle line:-2
今年我们在内核语言中
加了另一个精彩的功能

00:06:45.105 --> 00:06:47.040 align:middle line:-1
即对组读取的支持

00:06:47.274 --> 00:06:49.443 align:middle line:-2
只用一条指令
你的着色器能够执行

00:06:49.510 --> 00:06:52.045 align:middle line:-1
来自输入图像的四个

00:06:52.412 --> 00:06:54.114 align:middle line:-1
单通道读取

00:06:54.181 --> 00:06:55.382 align:middle line:-1
这真的有很大帮助

00:06:56.517 --> 00:06:58.252 align:middle line:-1
作为补充

00:06:58.318 --> 00:07:00.721 align:middle line:-1
我们还可以写像素组

00:06:58.318 --> 00:07:00.721 align:middle line:-1
我们还可以写像素组

00:07:01.088 --> 00:07:04.157 align:middle line:0
即只需在着色器中一条指令
你就可以

00:07:04.458 --> 00:07:06.960 align:middle line:0
写入图像的四个像素

00:07:08.428 --> 00:07:10.264 align:middle line:-1
所有这三个功能

00:07:10.330 --> 00:07:15.302 align:middle line:-1
都可以用于着色器中极大地提高性能

00:07:15.369 --> 00:07:18.071 align:middle line:-1
我来谈一谈如何运作的例子

00:07:18.772 --> 00:07:22.976 align:middle line:-2
想象一下你有一个简单的
3乘3卷积内核

00:07:23.710 --> 00:07:26.547 align:middle line:-1
用于一个图像的一个通道

00:07:26.613 --> 00:07:28.315 align:middle line:-1
这是一种相当常见的操作

00:07:28.382 --> 00:07:31.084 align:middle line:-1
例如要锐化图像的亮度

00:07:31.485 --> 00:07:35.522 align:middle line:-2
在这样的内核中
通常每次调用内核时

00:07:35.923 --> 00:07:39.326 align:middle line:-1
它负责产生一个输出像素

00:07:39.860 --> 00:07:42.129 align:middle line:-1
但是因为这是一个三乘三的卷积

00:07:42.629 --> 00:07:45.132 align:middle line:-1
你的内核需要读取9个像素

00:07:45.699 --> 00:07:47.234 align:middle line:0
以达到这个效果

00:07:47.301 --> 00:07:50.103 align:middle line:0
因此 我们每写一个像素
就需读取个像素

00:07:51.371 --> 00:07:52.673 align:middle line:0
但我们通过新的组写功能

00:07:52.739 --> 00:07:55.909 align:middle line:0
改进这一点

00:07:56.310 --> 00:07:57.945 align:middle line:-1
使用新的组写功能

00:07:58.011 --> 00:08:02.950 align:middle line:-2
你的内核可以一次调用
写出二乘二的一组像素

00:07:58.011 --> 00:08:02.950 align:middle line:-2
你的内核可以一次调用
写出二乘二的一组像素

00:08:03.383 --> 00:08:06.053 align:middle line:-1
当然这二乘二小组有点大

00:08:06.119 --> 00:08:07.788 align:middle line:-1
所以不再是三乘三

00:08:08.121 --> 00:08:11.124 align:middle line:-1
而是四乘四像素读取

00:08:11.191 --> 00:08:13.627 align:middle line:-1
以写出这四个像素

00:08:14.394 --> 00:08:15.529 align:middle line:-1
我们算一下

00:08:15.896 --> 00:08:19.700 align:middle line:0
这意味着我们有16像素读取
4像素写入

00:08:19.766 --> 00:08:22.135 align:middle line:-1
所以我们已经看到了这方面的优势

00:08:24.972 --> 00:08:28.642 align:middle line:-1
我们的另一个功能是收集

00:08:29.076 --> 00:08:33.547 align:middle line:-2
在这个例子中
我们读取4乘4或16像素

00:08:33.614 --> 00:08:34.615 align:middle line:-1
有了这个功能

00:08:34.780 --> 00:08:38.818 align:middle line:-2
我们只需要四条指令
即可完成这16个红色像素

00:08:39.753 --> 00:08:41.554 align:middle line:0
如果你计算一下

00:08:41.621 --> 00:08:43.490 align:middle line:0
这意味着我们每写入四个像素

00:08:43.557 --> 00:08:44.925 align:middle line:0
只进行了四次读取

00:08:45.259 --> 00:08:47.628 align:middle line:0
这确实有助于提高性能

00:08:47.794 --> 00:08:50.731 align:middle line:-2
我们通过实际内核代码
了解一下这个过程

00:08:51.932 --> 00:08:55.736 align:middle line:-1
这是一个简单卷积的例子

00:08:55.802 --> 00:08:57.037 align:middle line:-1
就像我刚才描述的

00:08:57.437 --> 00:08:59.673 align:middle line:-1
这里 我们从输入图像

00:08:59.740 --> 00:09:01.241 align:middle line:-1
做九个样本

00:08:59.740 --> 00:09:01.241 align:middle line:-1
做九个样本

00:09:01.441 --> 00:09:03.310 align:middle line:-1
我们只用它的红色通道

00:09:04.144 --> 00:09:05.879 align:middle line:-1
一旦我们得到这九个值

00:09:05.946 --> 00:09:07.514 align:middle line:-1
我们将对这九个值进行平均

00:09:07.581 --> 00:09:09.283 align:middle line:-1
并以传统方式写出来

00:09:09.349 --> 00:09:12.119 align:middle line:-1
返回单个vec4像素值

00:09:14.154 --> 00:09:17.024 align:middle line:-2
加速的第一步
是将其转换为Metal

00:09:17.090 --> 00:09:18.325 align:middle line:-1
这实际上很简单

00:09:18.392 --> 00:09:20.394 align:middle line:-1
我们从像这样的代码开始

00:09:20.460 --> 00:09:22.462 align:middle line:-1
这是我们传统的CI内核语言

00:09:22.529 --> 00:09:24.965 align:middle line:-1
如果在代码中进行一些搜索和替换

00:09:25.032 --> 00:09:29.203 align:middle line:-2
你可以将其更新为
基于Metal的CI内核语言

00:09:29.269 --> 00:09:31.371 align:middle line:-1
这里请注意几件重要的事情

00:09:31.438 --> 00:09:34.908 align:middle line:-1
我们为内核添加了一个目标参数

00:09:34.975 --> 00:09:35.876 align:middle line:-1
这对我们很重要

00:09:35.943 --> 00:09:39.680 align:middle line:-1
如果我们要检查着色器中的目标坐标

00:09:39.746 --> 00:09:42.216 align:middle line:-1
像这样的类似卷积的内核

00:09:42.983 --> 00:09:45.085 align:middle line:-1
我们用新的、更现代的语法

00:09:45.152 --> 00:09:49.990 align:middle line:-2
只需说s.sample和s.transform
即可从输入中进行采样

00:09:51.124 --> 00:09:53.327 align:middle line:-1
我们在更新此代码时做的最后一件事

00:09:53.393 --> 00:09:57.064 align:middle line:-2
是更改传统的vec4
和vec2参数类型

00:09:57.130 --> 00:09:59.233 align:middle line:-1
到float4和float2

00:10:00.701 --> 00:10:02.870 align:middle line:-1
但我们看到 代码的整体架构

00:10:02.936 --> 00:10:04.738 align:middle line:-1
内核的流程是一样的

00:10:06.773 --> 00:10:09.610 align:middle line:-1
好 第二步是使用半浮动

00:10:10.077 --> 00:10:12.579 align:middle line:-1
这个例子我们可以

00:10:12.646 --> 00:10:14.481 align:middle line:-1
只使用半浮点数的精度

00:10:14.548 --> 00:10:16.517 align:middle line:-1
因为我们只是处理颜色值

00:10:16.583 --> 00:10:19.786 align:middle line:-2
我们将再次对代码
进行一些非常简单的更改

00:10:20.220 --> 00:10:25.058 align:middle line:-1
基本上代码中曾使用浮点精度的位置

00:10:25.125 --> 00:10:27.227 align:middle line:-1
我们将使用半浮点精度

00:10:27.294 --> 00:10:30.397 align:middle line:-2
这表示sampler参数
和destination参数

00:10:30.464 --> 00:10:32.666 align:middle line:-1
有一个_h后缀

00:10:33.367 --> 00:10:37.237 align:middle line:-2
以及代码中的float4
全部变为half4

00:10:38.071 --> 00:10:39.973 align:middle line:-1
这很简单易行

00:10:40.040 --> 00:10:43.110 align:middle line:-2
还有一件事要注意
如果你的代码中有常数

00:10:43.177 --> 00:10:45.279 align:middle line:-1
确保在它们的末尾加h

00:10:45.345 --> 00:10:47.014 align:middle line:-1
比如除以9.0

00:10:48.849 --> 00:10:50.617 align:middle line:-1
这也很简单

00:10:51.084 --> 00:10:52.853 align:middle line:-1
为了获得此示例中的最佳性能

00:10:52.920 --> 00:10:55.088 align:middle line:-1
我们要做的最后一件事

00:10:55.155 --> 00:10:57.291 align:middle line:-1
是利用组读取和组写入

00:10:57.357 --> 00:10:59.726 align:middle line:-1
我们看看完成这个的代码

00:11:00.661 --> 00:11:03.897 align:middle line:-1
我们想写一个二乘二的像素组

00:11:03.964 --> 00:11:07.201 align:middle line:-1
并且我们需要从四乘四像素组中读取

00:11:08.101 --> 00:11:11.271 align:middle line:-1
首先我们想要指定一个组目的地

00:11:11.338 --> 00:11:13.807 align:middle line:-1
我们看一下函数声明

00:11:13.874 --> 00:11:15.576 align:middle line:-1
它现在有一个组目的地

00:11:16.143 --> 00:11:17.444 align:middle line:-1
h数据类型

00:11:18.345 --> 00:11:20.914 align:middle line:-1
我们将像以前一样获得目标坐标

00:11:20.981 --> 00:11:22.883 align:middle line:-1
指向像素的中心

00:11:22.950 --> 00:11:25.586 align:middle line:-1
但该坐标实际上代表了

00:11:25.953 --> 00:11:29.590 align:middle line:-1
一组二乘二像素的坐标

00:11:30.657 --> 00:11:32.025 align:middle line:-1
接下来为了填充这组

00:11:32.226 --> 00:11:35.395 align:middle line:-1
二乘二像素 我们要做的是

00:11:35.462 --> 00:11:37.164 align:middle line:-1
从图像中作一堆读取

00:11:37.965 --> 00:11:39.833 align:middle line:-1
所以 第一次收集读取

00:11:40.167 --> 00:11:42.736 align:middle line:-1
将从二乘二像素组中读

00:11:43.170 --> 00:11:46.440 align:middle line:-1
这里 我们16像素的左下角

00:11:47.074 --> 00:11:53.714 align:middle line:-2
它将以half4数组
返回红色通道的值

00:11:54.848 --> 00:11:57.618 align:middle line:-1
这四个参数将按此顺序存储

00:11:57.684 --> 00:12:02.456 align:middle line:-2
即x、y、z、w
以逆时针方向运行

00:11:57.684 --> 00:12:02.456 align:middle line:-2
即x、y、z、w
以逆时针方向运行

00:12:02.623 --> 00:12:04.758 align:middle line:-1
如果你熟悉Metal中的收集操作

00:12:04.825 --> 00:12:08.896 align:middle line:-1
这与Metal中使用的方向相同

00:12:10.364 --> 00:12:11.832 align:middle line:-1
所以用一条指令

00:12:11.899 --> 00:12:14.668 align:middle line:-2
我们完成了四次读取
我们将为其它四像素组

00:12:14.735 --> 00:12:16.036 align:middle line:-1
重复此过程

00:12:16.103 --> 00:12:20.307 align:middle line:-2
我们可以得到第二
第三和第四组

00:12:20.774 --> 00:12:22.609 align:middle line:-1
现在我们完成了所有16次读取

00:12:22.676 --> 00:12:25.846 align:middle line:-1
我们需要弄清楚哪些值在哪些位置

00:12:26.146 --> 00:12:27.648 align:middle line:-1
所以我们首先要做的是

00:12:27.714 --> 00:12:31.685 align:middle line:-1
得到这个三乘三子组的适当通道

00:12:32.553 --> 00:12:34.121 align:middle line:-1
并将它们平均在一起

00:12:34.354 --> 00:12:36.456 align:middle line:-1
然后我们把这些频道

00:12:36.890 --> 00:12:38.792 align:middle line:-1
存入r1变量

00:12:39.526 --> 00:12:40.994 align:middle line:-1
我们将重复这一过程

00:12:41.061 --> 00:12:46.700 align:middle line:-2
写入其它四个结果像素：
r1、r2、r3和r4

00:12:47.501 --> 00:12:50.637 align:middle line:-1
我们要做的最后一件事就是目标写入

00:12:51.004 --> 00:12:53.740 align:middle line:-1
在一次操作中写入四个像素

00:12:54.274 --> 00:12:57.177 align:middle line:-1
注意 这与传统的CI内核略有不同

00:12:57.244 --> 00:13:00.147 align:middle line:-1
过去我们从内核返回一个值

00:12:57.244 --> 00:13:00.147 align:middle line:-1
过去我们从内核返回一个值

00:13:00.214 --> 00:13:03.750 align:middle line:-1
而现在我们将调用目标写入

00:13:05.552 --> 00:13:08.422 align:middle line:-1
好 这一切的精彩之处是

00:13:08.722 --> 00:13:10.224 align:middle line:-1
只需很少的努力

00:13:10.290 --> 00:13:13.794 align:middle line:-2
我们可以在同样的着色器中
获得两倍的性能

00:13:13.861 --> 00:13:14.828 align:middle line:-1
这是一个非常简单的着色器

00:13:14.895 --> 00:13:16.797 align:middle line:-1
你可获得类似的结果

00:13:16.864 --> 00:13:18.065 align:middle line:-1
可在许多其它类型的着色器中实现

00:13:18.131 --> 00:13:20.200 align:middle line:-1
尤其是作卷积的那些

00:13:20.634 --> 00:13:24.304 align:middle line:-1
这是为内核提高性能的好方法

00:13:25.172 --> 00:13:27.441 align:middle line:0
我想告诉大家

00:13:27.508 --> 00:13:31.345 align:middle line:0
来看看这个很棒的内核语言新文档

00:13:31.645 --> 00:13:33.347 align:middle line:0
不论是传统的CI内核语言

00:13:33.413 --> 00:13:36.450 align:middle line:0
还是基于Metal的CI内核语言

00:13:36.517 --> 00:13:39.052 align:middle line:0
我强烈建议你阅读本文档

00:13:39.419 --> 00:13:41.655 align:middle line:0
现在我们讲过了为内核运行

00:13:41.722 --> 00:13:42.956 align:middle line:-1
提高性能的问题

00:13:43.490 --> 00:13:46.960 align:middle line:-1
我想请Emmanuel上台

00:13:47.027 --> 00:13:49.796 align:middle line:-1
来讲如何使你的新算法的

00:13:49.863 --> 00:13:50.864 align:middle line:-1
开发过程更快

00:13:55.702 --> 00:13:56.537 align:middle line:-1
谢谢 David

00:13:59.139 --> 00:14:00.307 align:middle line:-1
大家下午好

00:13:59.139 --> 00:14:00.307 align:middle line:-1
大家下午好

00:14:00.774 --> 00:14:01.775 align:middle line:-1
很高兴来到这里

00:14:01.842 --> 00:14:04.344 align:middle line:-2
我叫Emmanuel
Core Image团队的工程师

00:14:05.412 --> 00:14:07.447 align:middle line:-1
本场会议的下半场时间

00:14:07.648 --> 00:14:10.217 align:middle line:-2
我们将把注意力
从Core Image引擎移开

00:14:10.284 --> 00:14:14.154 align:middle line:-2
转而探索用Core Image
作原型设计的新方法

00:14:14.788 --> 00:14:16.657 align:middle line:-1
我们还会看看

00:14:16.723 --> 00:14:19.860 align:middle line:-2
如何在机器学习app中
利用Core Image

00:14:19.927 --> 00:14:20.894 align:middle line:-1
我们开始吧

00:14:22.329 --> 00:14:24.064 align:middle line:-1
既然我们谈到原型设计

00:14:24.131 --> 00:14:27.868 align:middle line:-2
我们先看看图像处理过滤器的
生命周期

00:14:30.137 --> 00:14:33.440 align:middle line:-1
比如我们想做

00:14:33.507 --> 00:14:35.742 align:middle line:-1
前景背景分割

00:14:35.809 --> 00:14:39.980 align:middle line:-1
这意味着我们想得到一个掩码

00:14:40.047 --> 00:14:43.717 align:middle line:-2
前景为1.0
背景为0.0

00:14:43.784 --> 00:14:45.485 align:middle line:-1
二者之间有连续值

00:14:46.753 --> 00:14:48.989 align:middle line:-1
实现此类过滤器的难度

00:14:49.056 --> 00:14:51.592 align:middle line:-1
很大程度上取决于数据的特性

00:14:51.658 --> 00:14:56.129 align:middle line:-2
例如 如果你有一个
额外的深度缓冲区

00:14:56.296 --> 00:14:58.298 align:middle line:-1
与你的RGB图像一起

00:14:58.565 --> 00:15:00.267 align:middle line:-1
事情可以变得更容易

00:14:58.565 --> 00:15:00.267 align:middle line:-1
事情可以变得更容易

00:15:00.534 --> 00:15:04.338 align:middle line:-2
如果你有兴趣将RGB图像
与深度信息相结合

00:15:04.872 --> 00:15:07.241 align:middle line:0
我强烈建议你查看

00:15:07.307 --> 00:15:09.243 align:middle line:0
用深度创建照片和视频效果的演讲

00:15:10.444 --> 00:15:14.114 align:middle line:-1
今天我不想专注于这些其它信息来源

00:15:14.181 --> 00:15:16.450 align:middle line:-1
我想专注于一般的原型设计

00:15:18.852 --> 00:15:23.290 align:middle line:-1
假设我们已经完成了这个过滤器

00:15:23.357 --> 00:15:25.559 align:middle line:-1
我们知道我们想要达到的效果

00:15:25.626 --> 00:15:28.395 align:middle line:-1
在这种特殊情况下 前景和背景掩码

00:15:28.462 --> 00:15:31.298 align:middle line:-1
下一步我们自然而然想实现它

00:15:31.465 --> 00:15:33.667 align:middle line:-1
选择你最喜欢的原型

00:15:33.934 --> 00:15:35.135 align:middle line:-1
然后就开始尝试了

00:15:35.736 --> 00:15:38.906 align:middle line:-1
并将不同的过滤器组合在一起并显示

00:15:38.972 --> 00:15:42.409 align:middle line:-1
以达到你寻找的过滤效果

00:15:43.877 --> 00:15:45.345 align:middle line:-1
假设你这么做了

00:15:45.412 --> 00:15:50.551 align:middle line:-2
这里我们有一个
前景到背景掩码的例子

00:15:51.552 --> 00:15:53.754 align:middle line:-1
如你在iOS或macOS环境中

00:15:54.054 --> 00:15:57.591 align:middle line:-1
下一个步骤自然而然是实施该算法

00:15:57.658 --> 00:16:01.295 align:middle line:-1
你可以使用各种生成后端

00:15:57.658 --> 00:16:01.295 align:middle line:-1
你可以使用各种生成后端

00:16:01.361 --> 00:16:02.196 align:middle line:-1
如Core Image

00:16:04.631 --> 00:16:06.466 align:middle line:-1
Metal及Metal性能着色器

00:16:06.700 --> 00:16:09.236 align:middle line:-2
及vImage
如果你想留在CPU上

00:16:10.337 --> 00:16:14.408 align:middle line:-2
从原型到产品的初始转换
可能非常耗时

00:16:14.474 --> 00:16:18.512 align:middle line:-2
第一次生成可能看起来
不像你期望的那样

00:16:19.313 --> 00:16:21.648 align:middle line:-1
有各种各样的原因

00:16:21.715 --> 00:16:23.584 align:middle line:-1
可能导致这些像素差异

00:16:23.650 --> 00:16:25.452 align:middle line:-1
其中一个就是

00:16:25.519 --> 00:16:28.021 align:middle line:-1
过滤器在不同框架的实现方式

00:16:28.088 --> 00:16:29.122 align:middle line:-1
可能完全不同

00:16:29.590 --> 00:16:31.458 align:middle line:-1
我们看左边这个例子

00:16:31.525 --> 00:16:34.328 align:middle line:-2
我们有一个恒定的模糊
适用于这个漂亮的羽化

00:16:34.595 --> 00:16:36.029 align:middle line:-1
从前台到背景

00:16:36.530 --> 00:16:39.733 align:middle line:-1
这个过滤器的示例

00:16:39.800 --> 00:16:42.336 align:middle line:-1
可以显示各种性能优化

00:16:42.402 --> 00:16:43.570 align:middle line:-1
使其加速

00:16:44.338 --> 00:16:47.508 align:middle line:-1
这些优化会引入数字误差

00:16:47.574 --> 00:16:49.476 align:middle line:-1
而在过滤器堆栈中传播

00:16:50.077 --> 00:16:53.981 align:middle line:-2
从而可能会对过滤器输出
产生重大变化

00:16:55.649 --> 00:16:58.785 align:middle line:-2
当你写代码时
通常会出现的另一个问题

00:16:58.852 --> 00:17:00.654 align:middle line:-1
是在原型环境中

00:16:58.852 --> 00:17:00.654 align:middle line:-1
是在原型环境中

00:17:00.721 --> 00:17:02.489 align:middle line:-1
很多内存管理都是自动发生的

00:17:02.556 --> 00:17:05.526 align:middle line:-1
因此你不会经常遇到内存压力

00:17:05.592 --> 00:17:08.161 align:middle line:-1
直到开发的后期

00:17:10.297 --> 00:17:15.736 align:middle line:-1
当然 另一个需要考虑的主题是性能

00:17:16.369 --> 00:17:18.972 align:middle line:-1
通常 原型已经在使用CPU代码

00:17:19.205 --> 00:17:23.143 align:middle line:-1
我们经常高估

00:17:23.210 --> 00:17:25.512 align:middle line:-1
将CP代码指向GP代码的性能提高

00:17:25.579 --> 00:17:27.681 align:middle line:-1
以为一切都会变得实时

00:17:28.482 --> 00:17:31.685 align:middle line:-1
如果我们能够尽早抓住这些问题呢？

00:17:31.752 --> 00:17:34.221 align:middle line:-1
早到原型设计和工作流程中？

00:17:35.522 --> 00:17:37.424 align:middle line:-1
我们相信有这个办法

00:17:37.491 --> 00:17:39.426 align:middle line:-1
它叫PyCoreImage

00:17:39.593 --> 00:17:41.228 align:middle line:-2
Core Image的
Python绑定

00:17:42.262 --> 00:17:46.366 align:middle line:-2
这是结合Core Image的
高性能生成

00:17:46.800 --> 00:17:50.270 align:middle line:-1
和Python编程语言的灵活性

00:17:51.038 --> 00:17:52.239 align:middle line:-1
用Core Image时

00:17:52.306 --> 00:17:55.676 align:middle line:-2
你还继承了对iOS
和macOS的支持

00:17:55.976 --> 00:17:58.245 align:middle line:-1
以及200多个内置过滤器

00:17:58.912 --> 00:18:02.282 align:middle line:-2
我们来看看
PyCoreImage的细节

00:17:58.912 --> 00:18:02.282 align:middle line:-2
我们来看看
PyCoreImage的细节

00:18:04.184 --> 00:18:06.653 align:middle line:-2
PyCoreImage
由三个主要部分组成

00:18:07.754 --> 00:18:10.224 align:middle line:-2
它用Core Image
作为生成后端

00:18:10.891 --> 00:18:13.794 align:middle line:-1
用Python作为编程接口

00:18:14.862 --> 00:18:18.799 align:middle line:-1
它还有一层薄薄NumPy连接代码

00:18:18.866 --> 00:18:21.602 align:middle line:-1
以期与现有代码库互操作

00:18:23.170 --> 00:18:25.706 align:middle line:-2
我们相信
PyCoreImage可以减少

00:18:25.772 --> 00:18:28.375 align:middle line:-1
你的原型设计和产品代码之间的摩擦

00:18:29.209 --> 00:18:31.211 align:middle line:0
如你想留在
以Swift为中心的环境中

00:18:31.278 --> 00:18:33.780 align:middle line:0
使用Swift Playground
也可以做很多事情

00:18:33.847 --> 00:18:35.449 align:middle line:0
我们鼓励你查看

00:18:35.516 --> 00:18:38.919 align:middle line:0
创建自己的
Swift Playground订阅的演讲

00:18:41.822 --> 00:18:45.425 align:middle line:-2
我们来看看
PyCoreImage的主要组件

00:18:46.159 --> 00:18:50.297 align:middle line:-2
因此 PyCoreImage利用Python
绑定objective C和PyObjC

00:18:50.731 --> 00:18:51.865 align:middle line:-1
而且有趣的是

00:18:52.232 --> 00:18:55.202 align:middle line:-2
我们自macOS 10.5
Leopard以来一直在发行PyObjC

00:18:56.670 --> 00:18:58.972 align:middle line:-2
它最初是作为Python
和Objective C之间的

00:18:59.039 --> 00:19:00.440 align:middle line:-1
双向桥实现的

00:18:59.039 --> 00:19:00.440 align:middle line:-1
双向桥实现的

00:19:00.741 --> 00:19:03.310 align:middle line:-2
特别是在Coco app
开发的环境下

00:19:03.377 --> 00:19:06.847 align:middle line:-2
但从那以后扩展到
支持大多数Apple框架

00:19:09.383 --> 00:19:12.085 align:middle line:-1
PyObjC的调用语法非常简单

00:19:12.152 --> 00:19:15.489 align:middle line:-2
获取现有Objective C代码
并用_代替:

00:19:15.789 --> 00:19:17.157 align:middle line:-1
还有一些细节

00:19:17.224 --> 00:19:20.227 align:middle line:-2
如果你想了解更多
建议查看API

00:19:20.994 --> 00:19:23.830 align:middle line:-1
我们以CIVector类为例

00:19:24.331 --> 00:19:25.832 align:middle line:-2
这里有一些
Objective C代码

00:19:25.899 --> 00:19:27.534 align:middle line:-1
我们创建CIVector的实例

00:19:27.601 --> 00:19:28.735 align:middle line:-1
调用CIVector

00:19:29.703 --> 00:19:31.905 align:middle line:-1
带X、Y、Z、W的向量

00:19:32.840 --> 00:19:34.374 align:middle line:-1
我们来看看PyObjC代码

00:19:34.675 --> 00:19:36.577 align:middle line:0
这非常相似
我们从Quartz伞包

00:19:36.643 --> 00:19:38.178 align:middle line:0
导入CIVector

00:19:39.046 --> 00:19:42.349 align:middle line:0
我们可以直接调用带X、Y、Z、W
的向量和CIVector类

00:19:44.218 --> 00:19:45.786 align:middle line:0
你要注意的是这些代码

00:19:45.853 --> 00:19:47.454 align:middle line:0
并不完全像Python一样

00:19:47.921 --> 00:19:50.324 align:middle line:0
我们将在几分钟内谈这个问题

00:19:53.227 --> 00:19:55.896 align:middle line:-2
现在我们来看看
PyCoreImage的类图

00:19:56.230 --> 00:19:58.365 align:middle line:-1
生成后端用Core Image

00:19:58.432 --> 00:20:00.400 align:middle line:-1
Core Image非常接近硬件

00:19:58.432 --> 00:20:00.400 align:middle line:-1
Core Image非常接近硬件

00:20:00.667 --> 00:20:02.436 align:middle line:-1
因此可以重定向过滤的方程

00:20:02.503 --> 00:20:04.505 align:middle line:-1
到最合适的生成后端

00:20:04.571 --> 00:20:06.607 align:middle line:-1
为你提供尽可能高的性能

00:20:07.374 --> 00:20:09.343 align:middle line:0
PyObjC存在于
Core Image上层

00:20:09.409 --> 00:20:12.880 align:middle line:0
它可以通过Core Image的
Python绑定与它通信

00:20:13.180 --> 00:20:15.082 align:middle line:0
由Quartz伞包提供

00:20:15.649 --> 00:20:18.819 align:middle line:0
Quartz伞包同时包含

00:20:18.886 --> 00:20:21.788 align:middle line:0
各种其它图像处理框架
如Core Graphics

00:20:21.855 --> 00:20:23.991 align:middle line:0
以及使用
Core Image的所有类

00:20:24.057 --> 00:20:26.627 align:middle line:0
例如CIVector、CIImages
和CIContext

00:20:28.662 --> 00:20:35.235 align:middle line:-2
PyCoreImage位于PyObjC之上
它本质上利用PyObjC

00:20:35.669 --> 00:20:37.504 align:middle line:-1
与Core Image通信

00:20:37.571 --> 00:20:40.307 align:middle line:-1
并为你做了很多简化

00:20:40.741 --> 00:20:44.144 align:middle line:-2
以便你在用Core Image时
没有那么多设置代码

00:20:44.211 --> 00:20:46.046 align:middle line:-1
我们稍后会看一下这个

00:20:47.014 --> 00:20:49.349 align:middle line:-1
这里很多都是通过CIMG类完成的

00:20:49.416 --> 00:20:53.153 align:middle line:-2
你用它通过供应商方程
与NumPy解释

00:20:53.787 --> 00:20:56.223 align:middle line:-1
你也可以包装NumPy缓冲区

00:20:56.456 --> 00:20:58.325 align:middle line:-1
直接使用类构造函数

00:21:00.260 --> 00:21:01.895 align:middle line:-1
让我们举一个例子

00:21:01.962 --> 00:21:03.797 align:middle line:-2
看如何用
PyCoreImage应用过滤器

00:21:03.864 --> 00:21:06.567 align:middle line:-1
你会看到这个框架多么简单和强大

00:21:07.134 --> 00:21:08.402 align:middle line:-1
你首先要做的是

00:21:08.468 --> 00:21:11.271 align:middle line:-2
从PyCoreImage包
导入你的CIMG类

00:21:12.072 --> 00:21:14.208 align:middle line:0
我们可以用它从文件加载图像

00:21:15.409 --> 00:21:18.679 align:middle line:0
注意 此时我们没有像素缓冲区

00:21:19.012 --> 00:21:20.647 align:middle line:0
Core Image
为图片创建配方

00:21:20.714 --> 00:21:22.516 align:middle line:0
在这种特殊情况下

00:21:22.583 --> 00:21:26.320 align:middle line:0
这个配方只是提供
从文件加载图像的指令

00:21:27.754 --> 00:21:29.356 align:middle line:0
你可以用过滤器

00:21:29.423 --> 00:21:30.657 align:middle line:0
创建更复杂的图表

00:21:30.724 --> 00:21:32.960 align:middle line:0
只需在其上调用CI过滤器名称

00:21:33.026 --> 00:21:35.529 align:middle line:0
并传递输入原色
在本例中为标准差

00:21:35.696 --> 00:21:38.131 align:middle line:0
可看到我们正组装一个更复杂的图形

00:21:38.198 --> 00:21:39.299 align:middle line:0
如果我们放大它

00:21:39.533 --> 00:21:41.235 align:middle line:0
我们可以看到模糊处理器

00:21:41.301 --> 00:21:42.202 align:middle line:0
就在中间

00:21:43.670 --> 00:21:45.739 align:middle line:0
如果你想获得像素缓冲区表示

00:21:45.806 --> 00:21:47.608 align:middle line:0
你可以在CIMG实例上

00:21:47.674 --> 00:21:48.909 align:middle line:0
调用生成

00:21:48.976 --> 00:21:52.012 align:middle line:0
你会得到一个合适的
NumPy缓冲区

00:21:55.782 --> 00:21:56.984 align:middle line:-1
为了做到这一点

00:21:57.050 --> 00:22:00.120 align:middle line:-2
我们需要对Core Image的
调用方式进行简化

00:21:57.050 --> 00:22:00.120 align:middle line:-2
我们需要对Core Image的
调用方式进行简化

00:22:00.187 --> 00:22:01.922 align:middle line:-1
或为你做一些设置代码

00:22:02.489 --> 00:22:05.993 align:middle line:-2
对于已经熟悉
Core Image的人

00:22:06.727 --> 00:22:08.762 align:middle line:-1
这不会让人感到意外

00:22:08.829 --> 00:22:10.631 align:middle line:-1
但对于不熟悉它的人

00:22:10.964 --> 00:22:12.432 align:middle line:-1
我们一起看看步骤

00:22:12.499 --> 00:22:17.237 align:middle line:-2
你将看到我们作的一些简化
以更清楚地说明问题

00:22:18.805 --> 00:22:22.242 align:middle line:-2
Core Image是一个
高性能的GPU图像处理框架

00:22:22.309 --> 00:22:24.378 align:middle line:-1
同时支持iOS和macOS

00:22:24.444 --> 00:22:26.713 align:middle line:-1
以及各种生成后端

00:22:27.881 --> 00:22:29.583 align:middle line:-1
支持大多数像素格式

00:22:30.417 --> 00:22:32.319 align:middle line:-1
这当然意味着位图数据

00:22:32.386 --> 00:22:35.122 align:middle line:-1
以及来自各供应商的原始文件

00:22:36.590 --> 00:22:39.359 align:middle line:-1
支持大多数文件格式

00:22:40.694 --> 00:22:44.898 align:middle line:-2
就像刚才说的 来自各种供应商的
位图数据和原始数据

00:22:44.965 --> 00:22:46.400 align:middle line:-1
支持大多数像素格式

00:22:46.466 --> 00:22:49.903 align:middle line:-1
例如 你可以用无符号8位加载图像

00:22:50.237 --> 00:22:52.172 align:middle line:-1
通过计算和半浮动

00:22:52.339 --> 00:22:54.908 align:middle line:-2
并在最终生成期间
完全呈现32位浮点数

00:22:56.343 --> 00:22:58.879 align:middle line:-2
Core Image可以为你
提取图像元数据

00:22:58.946 --> 00:23:03.917 align:middle line:-2
例如 捕获时间
EXIF标记以及嵌入的元数据

00:22:58.946 --> 00:23:03.917 align:middle line:-2
例如 捕获时间
EXIF标记以及嵌入的元数据

00:23:03.984 --> 00:23:07.020 align:middle line:-1
例如人像地图和人像深度信息

00:23:09.356 --> 00:23:11.692 align:middle line:-2
Core Image
可以很好地处理色彩管理

00:23:11.758 --> 00:23:15.262 align:middle line:-2
这是一个高难度的问题
很多框架都不作处理

00:23:16.263 --> 00:23:18.498 align:middle line:-2
Core Image
支持许多电池状况

00:23:18.832 --> 00:23:20.100 align:middle line:-1
无限图像

00:23:20.334 --> 00:23:22.769 align:middle line:-1
并且有200多个内置过滤器供使用

00:23:22.836 --> 00:23:24.471 align:middle line:-1
你可以拿来即用

00:23:25.272 --> 00:23:26.773 align:middle line:-1
好 我不需要说服你

00:23:26.840 --> 00:23:28.275 align:middle line:-1
那是很多信息

00:23:28.342 --> 00:23:30.143 align:middle line:-2
并且如果你尝试
在原型和工作流程中

00:23:30.444 --> 00:23:32.079 align:middle line:-1
使用Core Image

00:23:33.614 --> 00:23:35.148 align:middle line:-1
学习曲线可能相当陡峭

00:23:35.215 --> 00:23:37.684 align:middle line:-2
所以我们所做的就是
在新功能列表中选出最好的一些

00:23:38.051 --> 00:23:39.453 align:middle line:-1
进行了一些简化

00:23:39.653 --> 00:23:41.221 align:middle line:-1
请记住 这些简化

00:23:41.288 --> 00:23:42.956 align:middle line:-1
都可以随时被覆盖

00:23:43.123 --> 00:23:44.925 align:middle line:-1
因为我们会给你加权代码

00:23:44.992 --> 00:23:46.693 align:middle line:-1
你其实可以对这些更改进行硬编码

00:23:46.760 --> 00:23:48.495 align:middle line:-1
如果这适合你的原型堆栈

00:23:49.696 --> 00:23:51.465 align:middle line:-1
我们做的第一件事就是我们还有

00:23:51.532 --> 00:23:54.401 align:middle line:-1
Core Image的高性能功能

00:23:54.468 --> 00:23:56.003 align:middle line:-1
我们仍生成到Metal后端

00:23:56.470 --> 00:23:58.639 align:middle line:-1
仍然支持几乎所有输入输出格式

00:23:59.072 --> 00:24:01.108 align:middle line:-1
我们仍然可以提取数据的捕获时间

00:23:59.072 --> 00:24:01.108 align:middle line:-1
我们仍然可以提取数据的捕获时间

00:24:01.175 --> 00:24:04.811 align:middle line:-1
以及纵向深度和褪光信息

00:24:05.512 --> 00:24:08.982 align:middle line:-2
最后一个重点
你可以用200多个内置过滤器

00:24:09.850 --> 00:24:11.952 align:middle line:-1
我们做的第一个更改是 默认情况下

00:24:12.019 --> 00:24:14.988 align:middle line:-2
所有生成都用
完整的32位浮点数完成

00:24:16.890 --> 00:24:20.260 align:middle line:-2
第二个更改
一切都用sRGB颜色空间完成

00:24:21.662 --> 00:24:25.032 align:middle line:-2
第三 所有的边界条件都将
通过钳制和裁剪来处理

00:24:25.098 --> 00:24:28.869 align:middle line:-1
这意味着 如果你正在应用卷积运算

00:24:29.536 --> 00:24:31.672 align:middle line:-1
例如你的图片无限重复

00:24:32.172 --> 00:24:33.340 align:middle line:-1
将应用过滤器

00:24:33.540 --> 00:24:36.376 align:middle line:-1
并将生成的图像裁剪回输入尺寸

00:24:36.977 --> 00:24:40.480 align:middle line:-1
这也是一个可以一次覆盖的设置

00:24:42.282 --> 00:24:44.685 align:middle line:-1
最后 无限的图像变得有限

00:24:44.852 --> 00:24:47.487 align:middle line:-1
这样我们可以获取其像素缓冲区表示

00:24:49.590 --> 00:24:53.026 align:middle line:-2
这就是为何PyCoreImage
在幕后细节里

00:24:54.061 --> 00:24:54.895 align:middle line:-1
所以…

00:24:55.495 --> 00:24:58.932 align:middle line:-2
我们将作精彩演示
在实践中查看所有这些

00:24:58.999 --> 00:25:02.703 align:middle line:-2
在此之前 我想快速过一下
PyCoreImage的备忘单

00:24:58.999 --> 00:25:02.703 align:middle line:-2
在此之前 我想快速过一下
PyCoreImage的备忘单

00:25:02.769 --> 00:25:04.204 align:middle line:-1
我们来看看API

00:25:04.872 --> 00:25:07.875 align:middle line:-2
正如你之前看到的
我们从pycoreimage包

00:25:07.941 --> 00:25:09.309 align:middle line:-1
导入了CIMG类

00:25:10.143 --> 00:25:13.180 align:middle line:-2
我们可以调用fromFile
来用它加载文件中的图像

00:25:14.114 --> 00:25:16.517 align:middle line:-2
你如果想知道的话
这是等同于Swift的

00:25:16.583 --> 00:25:18.585 align:middle line:-2
你可以用
CIImage(contentsOfFile:)

00:25:20.821 --> 00:25:23.857 align:middle line:-2
你可以使用fromFile
直接加载纵向褪光信息

00:25:23.924 --> 00:25:25.259 align:middle line:-1
以及肖像深度

00:25:25.325 --> 00:25:28.762 align:middle line:-2
只需使用可选参数
useDepth和useMatte

00:25:31.298 --> 00:25:35.435 align:middle line:-2
你可以通过把NumPy缓冲区
包裹CIImage于构造函数中

00:25:35.502 --> 00:25:37.037 align:middle line:-1
来解释NumPy

00:25:37.404 --> 00:25:40.007 align:middle line:-2
或直接在CIImage实例下
调用生成

00:25:40.073 --> 00:25:41.241 align:middle line:-1
此为另一个选择

00:25:43.443 --> 00:25:44.344 align:middle line:0
如果你用Swift

00:25:44.411 --> 00:25:45.879 align:middle line:0
还有一些代码要写

00:25:45.946 --> 00:25:48.115 align:middle line:0
你需要先创建一个
CIRenderDestination

00:25:48.549 --> 00:25:50.851 align:middle line:0
确保你预先分配了缓冲区

00:25:51.718 --> 00:25:53.820 align:middle line:0
和提供正确的缓冲区属性

00:25:53.887 --> 00:25:58.292 align:middle line:0
创建CIContext
的实例并提示测试生成

00:25:59.626 --> 00:26:01.728 align:middle line:-1
这些都是在幕后处理的

00:25:59.626 --> 00:26:01.728 align:middle line:-1
这些都是在幕后处理的

00:26:02.829 --> 00:26:05.165 align:middle line:-2
Core Image
也支持过程图像

00:26:05.232 --> 00:26:07.201 align:middle line:-1
例如从颜色创建图像

00:26:07.768 --> 00:26:09.469 align:middle line:-1
或从生成器创建图像

00:26:11.805 --> 00:26:13.774 align:middle line:-1
现在我们看一下如何应用过滤器

00:26:14.942 --> 00:26:16.677 align:middle line:-1
应用过滤器再简单不过了

00:26:16.743 --> 00:26:18.078 align:middle line:-1
拿一个CIImage实例

00:26:18.345 --> 00:26:22.282 align:middle line:-2
直接在上调用过滤器名
称并传递输入原色列表

00:26:22.916 --> 00:26:27.721 align:middle line:-2
每个CIImage实例都增加了
200多个lambda表达式

00:26:28.121 --> 00:26:30.991 align:middle line:-2
直接映射到
Core Image过滤器

00:26:31.925 --> 00:26:32.826 align:middle line:-1
如果你用Swift

00:26:32.893 --> 00:26:34.962 align:middle line:-1
这是你之前看到的语法

00:26:35.028 --> 00:26:39.499 align:middle line:-2
应用过滤器
传入过滤器名称以及输入参数列表

00:26:39.566 --> 00:26:41.568 align:middle line:-1
以键值对的字典方式

00:26:43.604 --> 00:26:47.441 align:middle line:-2
要应用内核 可以在CIMG实例中
使用applyKernel

00:26:47.908 --> 00:26:50.677 align:middle line:-1
传入包含内核代码的源字符串

00:26:51.345 --> 00:26:53.847 align:middle line:-1
以及输入参数列表到该内核

00:26:53.914 --> 00:26:55.949 align:middle line:-1
我们等会儿再看一看

00:26:57.417 --> 00:26:59.820 align:middle line:-1
然后你只需指定应用该内核的范围

00:26:59.887 --> 00:27:03.957 align:middle line:-1
以及你在缓冲区中采样的感兴趣区域

00:26:59.887 --> 00:27:03.957 align:middle line:-1
以及你在缓冲区中采样的感兴趣区域

00:27:04.024 --> 00:27:05.292 align:middle line:-1
采样源

00:27:07.160 --> 00:27:11.031 align:middle line:-2
PyCoreImage
提供了一些有用的API

00:27:11.098 --> 00:27:12.666 align:middle line:-1
如复合操作

00:27:12.733 --> 00:27:13.867 align:middle line:-1
这是一个来源…

00:27:14.368 --> 00:27:17.271 align:middle line:-1
以及翻译等几何操作

00:27:17.604 --> 00:27:19.673 align:middle line:-1
缩放 旋转…

00:27:20.240 --> 00:27:21.074 align:middle line:-1
和裁剪

00:27:23.410 --> 00:27:28.415 align:middle line:-1
我想在GPU内核上再花一点时间

00:27:28.482 --> 00:27:31.652 align:middle line:-2
因为这是一个非常强大的功能
尤其对于原型

00:27:31.718 --> 00:27:33.554 align:middle line:-1
我们这里有一个字符串

00:27:33.620 --> 00:27:36.156 align:middle line:-1
包含GPU片段着色器的代码

00:27:36.690 --> 00:27:39.326 align:middle line:0
我们所拥有的基本上是一种方式

00:27:39.393 --> 00:27:41.995 align:middle line:0
让你实时原型化那种效果

00:27:43.664 --> 00:27:45.599 align:middle line:0
这是5抽头拉普拉斯算子的一个例子

00:27:45.832 --> 00:27:48.135 align:middle line:0
我们将使用它进行锐化

00:27:48.502 --> 00:27:51.305 align:middle line:0
我们在每个像素的邻域中
制作五个样本

00:27:51.772 --> 00:27:53.941 align:middle line:0
以计算局部导数的方式组合它们

00:27:54.007 --> 00:27:55.409 align:middle line:0
这将成为我们的细节

00:27:55.475 --> 00:27:58.045 align:middle line:0
我们添加回中心像素的顶部

00:27:58.779 --> 00:28:01.782 align:middle line:0
我不想太过关注过滤器本身
而是集中在如何调用它

00:27:58.779 --> 00:28:01.782 align:middle line:0
我不想太过关注过滤器本身
而是集中在如何调用它

00:28:02.149 --> 00:28:05.719 align:middle line:0
所以 我们称之为
CIMG实例上的黑色内核

00:28:06.520 --> 00:28:08.021 align:middle line:0
低音源代码

00:28:08.088 --> 00:28:11.091 align:middle line:0
只是在那里的
用三引号python字符串

00:28:12.459 --> 00:28:15.262 align:middle line:0
传递我们将要应用内核的范围

00:28:17.164 --> 00:28:18.565 align:middle line:0
并定义感兴趣的区域

00:28:18.632 --> 00:28:21.335 align:middle line:0
和我们将要采样的表达式

00:28:21.802 --> 00:28:24.972 align:middle line:-1
如果你不熟悉目标域的概念

00:28:25.038 --> 00:28:26.607 align:middle line:-1
以及感兴趣的地区

00:28:26.840 --> 00:28:29.476 align:middle line:-2
我建议你查看
Core Image在线文档

00:28:29.543 --> 00:28:31.612 align:middle line:-1
以及之前的WWDC演讲

00:28:32.112 --> 00:28:34.181 align:middle line:-1
但这是卷积内核

00:28:34.348 --> 00:28:36.250 align:middle line:-1
我们正在距离边界一个像素读取

00:28:36.316 --> 00:28:39.253 align:middle line:-2
我们需要指示Core Image
我们是否要这样做

00:28:39.319 --> 00:28:41.655 align:middle line:-1
以便它可以正确处理边界条件

00:28:43.023 --> 00:28:43.857 align:middle line:-1
好

00:28:43.924 --> 00:28:45.125 align:middle line:-1
这里有很多信息

00:28:45.192 --> 00:28:48.495 align:middle line:-1
并且看API总是有点枯燥

00:28:48.562 --> 00:28:51.765 align:middle line:-2
所以我们来看一个演示
把所有这些付诸实践

00:29:01.808 --> 00:29:02.876 align:middle line:-1
好 在演示期间

00:29:02.943 --> 00:29:04.811 align:middle line:-2
我将用
Jupiter Notebook

00:29:05.112 --> 00:29:08.682 align:middle line:-2
这是一个基于浏览器的
实时Python解释器

00:29:09.449 --> 00:29:11.585 align:middle line:-1
你将看到的所有结果

00:29:11.652 --> 00:29:14.755 align:middle line:-2
都是用后端的
Core Image实时生成的

00:29:14.821 --> 00:29:16.356 align:middle line:-1
而不是预先计算过

00:29:16.423 --> 00:29:17.658 align:middle line:-1
这一切都是现场完成的

00:29:18.292 --> 00:29:19.927 align:middle line:-1
我想在这里做的第一件事

00:29:19.993 --> 00:29:23.530 align:middle line:-1
导入我们将要用的实用程序类

00:29:23.730 --> 00:29:25.632 align:middle line:-1
这里最重要的是CIMG类

00:29:25.699 --> 00:29:27.034 align:middle line:-1
用于我的PyCoreImage包

00:29:27.968 --> 00:29:29.336 align:middle line:-1
然后我们只需一些设置代码

00:29:29.403 --> 00:29:32.306 align:middle line:-1
以便我们可视化该笔记本中的图像

00:29:32.906 --> 00:29:33.774 align:middle line:-1
我们开始

00:29:35.342 --> 00:29:37.911 align:middle line:-1
第一是如何加载图像

00:29:38.512 --> 00:29:39.813 align:middle line:-1
在此用fromFile

00:29:40.214 --> 00:29:45.619 align:middle line:-2
我们看到我的对象类型是
PyCoreImage CIMG

00:29:46.053 --> 00:29:47.387 align:middle line:-1
我们可以看到它后面的支持

00:29:47.454 --> 00:29:50.691 align:middle line:-2
是一个正确的
Core Image对象

00:29:51.558 --> 00:29:54.661 align:middle line:-2
我们可以对图像进行生成并
用Matplotlib

00:29:56.697 --> 00:29:59.833 align:middle line:-1
查看实际的像素表示

00:30:00.133 --> 00:30:01.401 align:middle line:-1
这是我们的输入图片

00:30:02.436 --> 00:30:05.405 align:middle line:-1
现在我想在其上应用过滤器

00:30:05.472 --> 00:30:07.741 align:middle line:-2
我们来看看这200多个
Core Image支持的

00:30:07.808 --> 00:30:09.710 align:middle line:-1
过滤器

00:30:13.046 --> 00:30:15.949 align:middle line:-1
比如说我想在这里应用高斯模糊

00:30:16.016 --> 00:30:17.451 align:middle line:-1
我想知道哪些参数

00:30:17.518 --> 00:30:18.685 align:middle line:-1
被该过滤器支持

00:30:18.752 --> 00:30:20.988 align:middle line:-1
所以我在我的CIMG类上调用输入

00:30:21.555 --> 00:30:23.991 align:middle line:-1
我看到它支持输入图像

00:30:24.324 --> 00:30:26.660 align:middle line:-1
不奇怪的是 还有标准差

00:30:27.327 --> 00:30:28.795 align:middle line:-1
所以 我将在这里做

00:30:29.763 --> 00:30:30.864 align:middle line:-1
拍摄输入图像

00:30:31.365 --> 00:30:34.701 align:middle line:-2
在其上应用高斯模糊过滤器
标准差为100像素

00:30:35.135 --> 00:30:36.703 align:middle line:-1
然后并排显示两个图像

00:30:38.739 --> 00:30:41.808 align:middle line:-1
非常简单 对吧？

00:30:42.075 --> 00:30:43.911 align:middle line:-1
好 我们继续吧

00:30:45.112 --> 00:30:47.281 align:middle line:0
如我之前提到 你可以生成过程图像

00:30:47.347 --> 00:30:48.182 align:middle line:0
用Core Image

00:30:48.248 --> 00:30:50.617 align:middle line:0
我们来看看
Core Image生成器

00:30:51.485 --> 00:30:54.621 align:middle line:-2
第一件事是我们调用
fromGenerator

00:30:54.688 --> 00:30:56.256 align:middle line:0
指定生成器的名称

00:30:56.323 --> 00:30:57.691 align:middle line:0
在这里CIQRCode

00:30:58.358 --> 00:31:01.562 align:middle line:0
并在我们尝试编码的消息中传递它们

00:30:58.358 --> 00:31:01.562 align:middle line:0
并在我们尝试编码的消息中传递它们

00:31:02.296 --> 00:31:03.397 align:middle line:0
这是实时的

00:31:03.463 --> 00:31:06.333 align:middle line:0
所以我可以对该消息进行更改

00:31:06.400 --> 00:31:09.570 align:middle line:0
并查看它如何影响正在生成的QR码

00:31:11.605 --> 00:31:13.974 align:middle line:0
Core Image
还支持标记图像

00:31:14.041 --> 00:31:16.210 align:middle line:0
你可以用
CI文本图像生成器来做到

00:31:16.977 --> 00:31:18.345 align:middle line:-1
这里有个例子

00:31:18.912 --> 00:31:21.849 align:middle line:0
WWDC并使用SFLO字体

00:31:23.050 --> 00:31:24.518 align:middle line:0
好 我们继续

00:31:25.385 --> 00:31:29.356 align:middle line:-2
刚才提到过
我们支持与NumPy间的互操作性

00:31:29.423 --> 00:31:31.525 align:middle line:-1
这是我们要做的第一件事

00:31:32.159 --> 00:31:34.962 align:middle line:-1
我们将从图像开始并应用一些有趣的

00:31:35.028 --> 00:31:36.096 align:middle line:-1
且有明显影响的变化

00:31:36.163 --> 00:31:37.698 align:middle line:-1
这种情况下 是一个涡旋畸变

00:31:39.299 --> 00:31:40.534 align:middle line:0
接下来我们要做的

00:31:40.601 --> 00:31:41.902 align:middle line:0
我们将生成该缓冲区

00:31:44.271 --> 00:31:46.139 align:middle line:0
从中获取NumPy区域

00:31:46.206 --> 00:31:47.441 align:middle line:0
这里我们看到它的类型

00:31:47.808 --> 00:31:48.842 align:middle line:0
和它的形状

00:31:49.443 --> 00:31:50.377 align:middle line:0
它的深度

00:31:51.144 --> 00:31:52.613 align:middle line:0
以及一些统计数据

00:31:52.679 --> 00:31:54.181 align:middle line:0
这是最小值 中值

00:31:54.481 --> 00:31:55.949 align:middle line:0
以及它的最大值

00:31:58.719 --> 00:32:00.254 align:middle line:0
我们也可以走另一条路

00:31:58.719 --> 00:32:00.254 align:middle line:0
我们也可以走另一条路

00:32:00.320 --> 00:32:02.022 align:middle line:0
从NumPy到CoreImage

00:32:03.090 --> 00:32:05.225 align:middle line:-1
让我们从NumPy数组开始

00:32:05.292 --> 00:32:06.260 align:middle line:-1
这不是件小事情

00:32:06.326 --> 00:32:08.829 align:middle line:-1
这里 一个随机缓冲区

00:32:08.896 --> 00:32:11.899 align:middle line:-1
其中75%的值已经渐变为黑色

00:32:13.634 --> 00:32:17.337 align:middle line:0
我首先将我的NuPy数组
包装到我的CIMG构造函数中

00:32:17.671 --> 00:32:20.407 align:middle line:0
可以看到我们又有了
一个CIMG类实例

00:32:20.741 --> 00:32:22.409 align:middle line:-1
和支持它的CIImage

00:32:24.711 --> 00:32:26.113 align:middle line:0
现在我有了CIImage

00:32:26.180 --> 00:32:27.848 align:middle line:0
我可以在其上应用各种过滤器

00:32:28.182 --> 00:32:30.918 align:middle line:0
我首先应用这个模糊化

00:32:31.351 --> 00:32:33.453 align:middle line:0
我将使用电线滤波器
一条光隧道

00:32:34.188 --> 00:32:35.622 align:middle line:0
改变图像的对比度

00:32:35.956 --> 00:32:38.859 align:middle line:0
调整曝光及伽玛值

00:32:39.860 --> 00:32:42.062 align:middle line:0
我们一起看看这些过滤器

00:32:42.896 --> 00:32:46.099 align:middle line:-2
在模糊化、光隧道
曝光调整、伽玛调整后

00:32:46.500 --> 00:32:47.668 align:middle line:-1
这是我们的最终效果

00:32:48.368 --> 00:32:50.137 align:middle line:-1
非常有趣 非常易用

00:32:52.406 --> 00:32:53.674 align:middle line:-1
我们把它们放在一起

00:32:53.740 --> 00:32:55.709 align:middle line:-1
这里我开始一个新的图像

00:32:56.343 --> 00:32:58.946 align:middle line:-1
我在下面这个演示中向你展示的是

00:32:59.012 --> 00:33:00.547 align:middle line:-1
如何做弯曲处理

00:32:59.012 --> 00:33:00.547 align:middle line:-1
如何做弯曲处理

00:33:01.014 --> 00:33:02.950 align:middle line:-1
如果你熟悉Python的切片操作

00:33:03.016 --> 00:33:05.118 align:middle line:-1
这正是我们要做的

00:33:05.185 --> 00:33:08.822 align:middle line:-2
我们将在图像中定义带或切片
水平切片

00:33:09.223 --> 00:33:11.658 align:middle line:-1
我们只对这些切片应用过滤器

00:33:12.492 --> 00:33:14.494 align:middle line:-1
让我们先来看一下代码

00:33:15.429 --> 00:33:16.964 align:middle line:-1
这是我们的添加带功能

00:33:17.531 --> 00:33:19.666 align:middle line:-1
我们可以看到它的最底层

00:33:20.400 --> 00:33:22.102 align:middle line:0
我们用两种复合材料生成图像

00:33:22.169 --> 00:33:23.637 align:middle line:0
这是实际的NumPy缓冲区

00:33:23.704 --> 00:33:25.672 align:middle line:0
但右边是CIImage

00:33:26.507 --> 00:33:27.708 align:middle line:0
通过使用这样的切片

00:33:27.774 --> 00:33:30.577 align:middle line:0
我们强制Core Image
只在该带进行生成

00:33:30.644 --> 00:33:31.778 align:middle line:0
而不是整个图片

00:33:32.045 --> 00:33:35.382 align:middle line:0
因此效率更高

00:33:37.551 --> 00:33:40.721 align:middle line:-2
我们这样做并在我们的图像中
创建五个不同的带

00:33:40.787 --> 00:33:42.222 align:middle line:-1
并显示最终的合成

00:33:45.092 --> 00:33:47.794 align:middle line:-2
非常棒
在顶上还有其它标签

00:33:48.996 --> 00:33:51.298 align:middle line:-1
对应于应用的过滤器

00:33:51.865 --> 00:33:54.101 align:middle line:-2
使用PyCoreImage
真的很简单

00:33:54.434 --> 00:33:56.370 align:middle line:0
好的
我之前提到过性能

00:33:56.436 --> 00:33:58.505 align:middle line:0
所以让我们快速看看这个

00:33:59.306 --> 00:34:00.240 align:middle line:0
我想给你看的第一个是

00:33:59.306 --> 00:34:00.240 align:middle line:0
我想给你看的第一个是

00:34:00.307 --> 00:34:03.377 align:middle line:0
每当你在CIImage实例上
调用生成时

00:34:03.710 --> 00:34:06.547 align:middle line:0
NumPy被预处理并缓存

00:34:07.047 --> 00:34:08.649 align:middle line:0
例如 我们在这里创建一个图像

00:34:08.715 --> 00:34:11.251 align:middle line:0
我们按比例缩小
并应用GaussianBlur

00:34:11.585 --> 00:34:13.520 align:middle line:0
第一次调用历时56毫秒

00:34:13.587 --> 00:34:15.088 align:middle line:0
第二次只需两毫秒

00:34:15.989 --> 00:34:18.725 align:middle line:0
让我们来看看大卷积

00:34:18.792 --> 00:34:20.494 align:middle line:0
Core Image非常快

00:34:20.960 --> 00:34:23.096 align:middle line:0
并且能够处理大型卷积

00:34:23.163 --> 00:34:24.264 align:middle line:0
轻松搞定

00:34:24.531 --> 00:34:26.466 align:middle line:-1
这里我们用CIBlur

00:34:26.766 --> 00:34:32.005 align:middle line:-2
一个CIGaussianBlur
西格玛值为200

00:34:32.072 --> 00:34:32.906 align:middle line:-1
这很大

00:34:33.206 --> 00:34:34.741 align:middle line:-1
这里给大家一个概念

00:34:34.808 --> 00:34:36.643 align:middle line:-1
我向你展示这个图像时

00:34:36.909 --> 00:34:40.179 align:middle line:0
我实际用scikit-image
执行equivalent

00:34:40.480 --> 00:34:42.549 align:middle line:0
我们的运行时间是16秒

00:34:42.949 --> 00:34:45.052 align:middle line:0
但这次使用
CoreImage做同样的事

00:34:45.351 --> 00:34:46.954 align:middle line:0
一百三十毫秒

00:34:47.221 --> 00:34:48.388 align:middle line:0
是的 就是这么快

00:34:48.455 --> 00:34:49.755 align:middle line:-1
200倍 耶

00:34:50.324 --> 00:34:51.158 align:middle line:-1
谢谢

00:34:52.525 --> 00:34:53.560 align:middle line:-1
好吧 我们继续

00:34:53.627 --> 00:34:56.663 align:middle line:-2
PyCoreImage
最强大的功能之一

00:34:56.730 --> 00:35:00.200 align:middle line:-1
是内联创建自定义GP内核的能力

00:34:56.730 --> 00:35:00.200 align:middle line:-1
是内联创建自定义GP内核的能力

00:35:00.267 --> 00:35:01.535 align:middle line:-1
并在动态中执行

00:35:01.602 --> 00:35:02.936 align:middle line:-1
并动态修改

00:35:03.303 --> 00:35:04.571 align:middle line:-1
我们来看看

00:35:08.842 --> 00:35:09.676 align:middle line:-1
好

00:35:10.544 --> 00:35:12.980 align:middle line:-2
我首先想要展示的是
如何使用颜色内核

00:35:13.313 --> 00:35:16.216 align:middle line:-1
因此颜色内核是仅输入一个像素

00:35:16.283 --> 00:35:17.518 align:middle line:-1
并输出一个像素的内核

00:35:17.818 --> 00:35:20.854 align:middle line:-1
并且不围绕该像素制作任何其它样本

00:35:21.455 --> 00:35:23.657 align:middle line:0
这是我们的输入图像
这是我们的内核

00:35:23.724 --> 00:35:27.561 align:middle line:0
所以我们实际得到的是一种颜色
我们将颜色显示

00:35:28.228 --> 00:35:30.998 align:middle line:-1
我们来看看这个效果

00:35:31.064 --> 00:35:33.267 align:middle line:-1
我要把我的红色和蓝色通道

00:35:33.333 --> 00:35:34.835 align:middle line:-1
与我的蓝色和红色频道互换

00:35:34.902 --> 00:35:36.270 align:middle line:-1
我要反转它们

00:35:36.703 --> 00:35:38.172 align:middle line:-1
不是太令人兴奋的效果

00:35:38.238 --> 00:35:40.574 align:middle line:-1
但我要告诉你的是我可以

00:35:42.676 --> 00:35:45.679 align:middle line:-2
开始打字 然后说
也许我想扩展红色频道

00:35:45.746 --> 00:35:46.780 align:middle line:0
用蓝色频道

00:35:47.347 --> 00:35:51.618 align:middle line:-1
我想尝试这里的缩放量

00:35:51.685 --> 00:35:53.320 align:middle line:-1
我们可以从.25开始

00:35:53.921 --> 00:35:56.089 align:middle line:-1
随意提到相当高的值

00:35:56.423 --> 00:35:58.225 align:middle line:-1
并生成有趣的效果

00:35:59.026 --> 00:36:01.395 align:middle line:-2
它非常强大
而这一切都是实时完成的

00:35:59.026 --> 00:36:01.395 align:middle line:-2
它非常强大
而这一切都是实时完成的

00:36:01.461 --> 00:36:03.530 align:middle line:-2
所以你可通过这种方式
对过滤器进行微调

00:36:03.597 --> 00:36:06.300 align:middle line:-1
并确保达到你正在寻找的效果

00:36:08.635 --> 00:36:11.405 align:middle line:0
我们来看一个更复杂的内核

00:36:11.471 --> 00:36:12.873 align:middle line:0
我们来看一下通用内核

00:36:12.940 --> 00:36:15.609 align:middle line:0
这有点像我之前展示的
拉普拉斯锐化

00:36:15.676 --> 00:36:18.979 align:middle line:-2
这是一个在每个像素附近
进行额外点击的内核

00:36:19.446 --> 00:36:21.148 align:middle line:-1
所以从文件中的图像开始

00:36:21.215 --> 00:36:22.916 align:middle line:-1
这是我们之前看到的同一图像

00:36:23.116 --> 00:36:25.219 align:middle line:-1
这里有我们的内核代码

00:36:25.285 --> 00:36:26.386 align:middle line:-1
我们略去细节

00:36:26.453 --> 00:36:27.654 align:middle line:-1
这是一个双边过滤器

00:36:27.721 --> 00:36:29.656 align:middle line:-1
是模糊滤镜的边缘

00:36:30.891 --> 00:36:32.793 align:middle line:-1
我们把代码放进去

00:36:33.193 --> 00:36:35.262 align:middle line:-2
并带有一些参数调用
applyKernel

00:36:36.897 --> 00:36:42.302 align:middle line:-1
可以获得非常好的效果

00:36:42.369 --> 00:36:43.904 align:middle line:-1
我们在这里做的 基本上

00:36:44.137 --> 00:36:48.342 align:middle line:-1
是剪切图像中的无冗余高频

00:36:48.408 --> 00:36:49.409 align:middle line:-1
如果我们看看…

00:36:50.043 --> 00:36:51.945 align:middle line:0
我们更仔细地看一下

00:36:53.213 --> 00:36:54.047 align:middle line:-1
看看这里的剪切

00:36:54.114 --> 00:36:56.650 align:middle line:-1
我们可以看到强边缘还存在

00:36:56.717 --> 00:36:58.919 align:middle line:-1
但是非冗余的精细频率

00:36:58.986 --> 00:37:00.020 align:middle line:-1
被冲走了

00:36:58.986 --> 00:37:00.020 align:middle line:-1
被冲走了

00:37:00.721 --> 00:37:04.258 align:middle line:-1
双边滤波器可用于许多不同目的

00:37:04.324 --> 00:37:06.527 align:middle line:-2
在这种情况下
我们将用它来进行锐化

00:37:06.927 --> 00:37:08.896 align:middle line:-1
并使用此过滤器实现锐化

00:37:09.196 --> 00:37:10.898 align:middle line:-1
我们可以简单地拿左边的图像

00:37:11.164 --> 00:37:12.633 align:middle line:-1
并减去右边的图像

00:37:12.699 --> 00:37:15.669 align:middle line:-2
为我们提供了图像中
高频或细节的地图

00:37:15.736 --> 00:37:16.870 align:middle line:-1
我们这样做

00:37:17.905 --> 00:37:20.073 align:middle line:0
我在这里做的是生成我的图像

00:37:20.307 --> 00:37:21.375 align:middle line:0
它是一个NumPy缓冲区

00:37:21.675 --> 00:37:26.146 align:middle line:0
生成我过滤后的图片

00:37:26.713 --> 00:37:29.716 align:middle line:0
并且用运算符重载将它们一起减去

00:37:29.783 --> 00:37:31.151 align:middle line:0
这是随NumPy提供的操作

00:37:31.718 --> 00:37:33.353 align:middle line:0
让我们来看一下细节层

00:37:34.922 --> 00:37:37.691 align:middle line:-1
如果你的左侧有整个图像的细节

00:37:37.758 --> 00:37:39.626 align:middle line:-1
和图像中心的裁剪

00:37:40.727 --> 00:37:43.730 align:middle line:-1
现在 我们可以做的就是将它添加到

00:37:43.797 --> 00:37:44.932 align:middle line:-1
原始图像的顶部

00:37:45.866 --> 00:37:47.334 align:middle line:0
这正是我们要做的

00:37:47.401 --> 00:37:49.169 align:middle line:0
我们将两次加它

00:37:50.170 --> 00:37:52.206 align:middle line:-1
通过这样做 我们实现了形成锐化

00:37:52.940 --> 00:37:54.041 align:middle line:-1
就是这么简单

00:37:54.408 --> 00:37:57.444 align:middle line:-2
如果我想
我可以回到我的过滤器内核字符串

00:37:58.078 --> 00:38:00.981 align:middle line:-1
并开始任意实时进行更改

00:37:58.078 --> 00:38:00.981 align:middle line:-1
并开始任意实时进行更改

00:38:03.250 --> 00:38:07.221 align:middle line:-1
我还想演示如何从图像中加载元数据

00:38:07.788 --> 00:38:09.456 align:middle line:-1
这里我有一张图片

00:38:09.523 --> 00:38:11.124 align:middle line:0
加载了人像效果褪光

00:38:11.191 --> 00:38:12.893 align:middle line:0
以及纵向深度数据

00:38:14.094 --> 00:38:15.829 align:middle line:-1
以下是并排的l图片

00:38:16.763 --> 00:38:18.665 align:middle line:-1
左侧的图像是RGB图像

00:38:18.732 --> 00:38:20.100 align:middle line:-1
中心是深度数据

00:38:20.167 --> 00:38:22.503 align:middle line:-1
右侧是高质量的人像效果图

00:38:22.569 --> 00:38:24.838 align:middle line:-1
我们今天在另一个演讲上介绍了

00:38:26.006 --> 00:38:27.474 align:middle line:0
我们还可以查看EXIF标记

00:38:27.541 --> 00:38:30.344 align:middle line:0
直接通过查看下层的CIImage

00:38:31.545 --> 00:38:34.081 align:middle line:0
来自相同的G实例和调用属性

00:38:35.215 --> 00:38:38.018 align:middle line:0
这里 我们获得有关捕获本身的信息

00:38:39.953 --> 00:38:42.389 align:middle line:-1
像我说的 我们介绍了人像效果褪光

00:38:42.456 --> 00:38:44.224 align:middle line:-1
在另一个演讲 演讲503

00:38:44.291 --> 00:38:45.993 align:middle line:-1
我强烈建议你去看看那个演讲

00:38:46.293 --> 00:38:48.028 align:middle line:-1
所以这里我们略去细节

00:38:48.662 --> 00:38:50.230 align:middle line:-1
我将要实现这个过滤器

00:38:50.297 --> 00:38:52.833 align:middle line:-1
如果你有兴趣了解如何做到的

00:38:53.333 --> 00:38:55.869 align:middle line:-1
我强烈建议你查看本次演讲

00:38:57.137 --> 00:38:58.138 align:middle line:-1
非常有意思的东西

00:39:00.641 --> 00:39:01.475 align:middle line:-1
谢谢

00:39:05.879 --> 00:39:06.713 align:middle line:-1
好

00:39:07.080 --> 00:39:08.615 align:middle line:-1
让我们回到本次演讲

00:39:08.682 --> 00:39:10.851 align:middle line:-1
我想在这里稍微换档

00:39:11.351 --> 00:39:16.490 align:middle line:-2
谈谈将CoreImage
和CoreML结合在一起

00:39:23.363 --> 00:39:27.968 align:middle line:0
如果你想获得
有关使用人像褪光的更多信息

00:39:28.302 --> 00:39:30.737 align:middle line:-1
和人像深度信息

00:39:30.804 --> 00:39:33.774 align:middle line:-2
我鼓励你仔细查看有关
创建照片和视频效果的演讲

00:39:35.008 --> 00:39:37.744 align:middle line:-2
我们看看将Core Image
和CoreML结合在一起

00:39:38.846 --> 00:39:41.248 align:middle line:-1
今年 我们非常高兴地宣布

00:39:41.315 --> 00:39:43.016 align:middle line:-1
我们推出了一个新的过滤器

00:39:43.584 --> 00:39:45.252 align:middle line:-1
CICoreMLModelFilter

00:39:45.719 --> 00:39:47.988 align:middle line:-2
这是一个非常简单
但非常强大的过滤器

00:39:48.055 --> 00:39:49.089 align:middle line:-1
需要两个输入

00:39:49.957 --> 00:39:53.360 align:middle line:-1
第一个输入是带有滤镜的图像本身

00:39:54.361 --> 00:39:55.729 align:middle line:-1
并输入CoreML模型

00:39:58.465 --> 00:40:00.501 align:middle line:0
并且你获得了一个输出

00:39:58.465 --> 00:40:00.501 align:middle line:0
并且你获得了一个输出

00:40:00.567 --> 00:40:01.735 align:middle line:0
已被潜在神经网络处理的输出

00:40:01.802 --> 00:40:04.037 align:middle line:-1
这真的很简单 很强大

00:40:04.438 --> 00:40:07.708 align:middle line:-2
为了展示代码有多简单
让我们来看看Swift

00:40:09.142 --> 00:40:10.978 align:middle line:0
我们在左侧有一个输入图像

00:40:11.044 --> 00:40:12.913 align:middle line:0
你要做的就是调用过滤器

00:40:13.413 --> 00:40:15.782 align:middle line:0
传入我们今年推出的新过滤器

00:40:16.216 --> 00:40:18.385 align:middle line:0
并提供预编译的ML模型

00:40:18.452 --> 00:40:19.586 align:middle line:0
就是这么简单

00:40:20.053 --> 00:40:21.855 align:middle line:0
如果你想看看其它方式

00:40:21.922 --> 00:40:24.658 align:middle line:0
在图像处理app中利用机器学习

00:40:24.725 --> 00:40:27.594 align:middle line:0
我鼓励你看看其它演讲

00:40:27.661 --> 00:40:30.531 align:middle line:0
关于Turi Create指南
和Visionwith CoreML

00:40:33.000 --> 00:40:34.401 align:middle line:-1
一个相关的话题

00:40:34.735 --> 00:40:37.804 align:middle line:-1
我们在训练数据集中的常见操作之一

00:40:37.871 --> 00:40:39.840 align:middle line:-1
是机器学习中的数据增强

00:40:40.541 --> 00:40:42.109 align:middle line:-1
而数据增强

00:40:42.643 --> 00:40:46.213 align:middle line:-1
可以显着提高神经网络的稳健性

00:40:46.280 --> 00:40:49.716 align:middle line:-2
在这种情况下
假设我们正在进行对象分类

00:40:50.250 --> 00:40:51.818 align:middle line:-1
我们正在努力确定

00:40:51.885 --> 00:40:54.421 align:middle line:-1
该图像是桥还是有水

00:40:56.890 --> 00:41:01.161 align:middle line:-1
对原始趋势数据集进行扩充

00:40:56.890 --> 00:41:01.161 align:middle line:-1
对原始趋势数据集进行扩充

00:41:01.395 --> 00:41:04.064 align:middle line:-1
将增加该数据集中的图像数量

00:41:04.131 --> 00:41:06.767 align:middle line:-1
而无需收集新图片

00:41:07.301 --> 00:41:08.836 align:middle line:-1
你基本上可以免费得到

00:41:09.403 --> 00:41:11.305 align:middle line:-1
所以 你可以携带很多操作

00:41:11.371 --> 00:41:13.073 align:middle line:-1
其中一个只是改变它的外观

00:41:13.140 --> 00:41:14.808 align:middle line:-1
例如 色调 温度

00:41:14.875 --> 00:41:16.343 align:middle line:-1
和图像的白点

00:41:17.110 --> 00:41:19.980 align:middle line:-1
通过添加噪声改变图像的光谱属性

00:41:21.348 --> 00:41:24.151 align:middle line:-2
或通过应用变换
改变图像的几何图形

00:41:24.985 --> 00:41:28.188 align:middle line:-2
事实证明 用Core Image
实现所有这些都是易如反掌

00:41:28.856 --> 00:41:30.290 align:middle line:-1
让我们来看几个过滤器

00:41:30.357 --> 00:41:33.193 align:middle line:-1
以及如何将它们用于数据增强

00:41:34.695 --> 00:41:36.597 align:middle line:-1
我们在左侧有输入图像

00:41:37.798 --> 00:41:39.333 align:middle line:-1
我们可以改变温度和色调

00:41:39.399 --> 00:41:40.901 align:middle line:-1
用CITemperatureAndTint

00:41:41.702 --> 00:41:43.770 align:middle line:-1
我们可以调整亮度 对比度

00:41:43.837 --> 00:41:47.875 align:middle line:-2
及用CIColorControls
调整的图像饱和度

00:41:48.942 --> 00:41:51.578 align:middle line:-1
用CIDither更改图像的频谱

00:41:51.645 --> 00:41:53.046 align:middle line:-1
还有CIGaussianBlur

00:41:54.648 --> 00:41:57.718 align:middle line:-1
还有用仿射变换更改图像的几何图形

00:41:59.186 --> 00:42:00.754 align:middle line:-1
我们来看看实践中的所有这些

00:41:59.186 --> 00:42:00.754 align:middle line:-1
我们来看看实践中的所有这些

00:42:08.996 --> 00:42:11.231 align:middle line:-2
好 我们回到
Jupiter Notebook

00:42:11.298 --> 00:42:13.100 align:middle line:-1
与之前相同的设置

00:42:13.467 --> 00:42:15.502 align:middle line:-2
我想向你展示的是
如何用Core Image

00:42:15.569 --> 00:42:16.436 align:middle line:-1
作批量增强

00:42:17.037 --> 00:42:18.572 align:middle line:-1
我们正在加载图片

00:42:19.239 --> 00:42:21.775 align:middle line:-1
我们将在这里定义我们的增强功能

00:42:21.842 --> 00:42:23.510 align:middle line:-1
我们要做的主要是

00:42:23.577 --> 00:42:24.645 align:middle line:0
来自随机空间的

00:42:24.912 --> 00:42:26.713 align:middle line:0
为我在这里定义的每个过滤器的抽样

00:42:27.181 --> 00:42:30.851 align:middle line:0
我们将用GaussianBlur
缩放旋转

00:42:31.251 --> 00:42:33.287 align:middle line:0
一些调整 曝光调整

00:42:33.554 --> 00:42:35.856 align:middle line:0
纤维以及噪音抖动

00:42:37.758 --> 00:42:39.660 align:middle line:0
好了？让我们缓存该功能

00:42:40.460 --> 00:42:41.328 align:middle line:-1
再来看看

00:42:41.395 --> 00:42:44.531 align:middle line:-1
对该增强的一些实现

00:42:46.567 --> 00:42:47.968 align:middle line:-1
所以我的滑块在这里控制

00:42:48.035 --> 00:42:50.337 align:middle line:-1
我在后端使用的数字生成器种子

00:42:52.673 --> 00:42:53.807 align:middle line:-1
好 非常酷

00:42:53.874 --> 00:42:55.309 align:middle line:0
我不确定效率如何

00:42:55.375 --> 00:42:58.612 align:middle line:0
所以这里我将实时处理
200个这样的增强

00:42:58.979 --> 00:43:01.148 align:middle line:-1
我们将在这里看看它们如何

00:42:58.979 --> 00:43:01.148 align:middle line:-1
我们将在这里看看它们如何

00:43:01.481 --> 00:43:03.183 align:middle line:0
实时保存到硬盘

00:43:03.250 --> 00:43:04.218 align:middle line:0
我们来试试吧

00:43:04.685 --> 00:43:06.453 align:middle line:-1
让你了解它有多快

00:43:10.390 --> 00:43:11.558 align:middle line:-1
这真的很厉害

00:43:15.128 --> 00:43:15.963 align:middle line:-1
好

00:43:16.864 --> 00:43:21.068 align:middle line:-2
下面我想展示的是如何通过
Core Image来使用CoreML

00:43:21.935 --> 00:43:25.072 align:middle line:-1
首先是加载Core ML模型

00:43:25.272 --> 00:43:26.139 align:middle line:-1
我们在这里做的

00:43:27.341 --> 00:43:29.710 align:middle line:0
我们有一个玻璃模型
我们将要用它

00:43:30.277 --> 00:43:32.045 align:middle line:0
产生一个有趣的效果

00:43:32.112 --> 00:43:34.014 align:middle line:-1
让我们从过程图像开始

00:43:34.348 --> 00:43:35.549 align:middle line:-1
我们之前见过这个

00:43:36.850 --> 00:43:38.252 align:middle line:-1
然后让它变得更有趣

00:43:38.318 --> 00:43:39.586 align:middle line:-1
我们为它添加一些纹理

00:43:40.787 --> 00:43:42.956 align:middle line:0
我们在上面添加多频段噪音

00:43:45.425 --> 00:43:46.727 align:middle line:0
以及一些羽化

00:43:47.327 --> 00:43:48.762 align:middle line:0
和一些小插图

00:43:50.631 --> 00:43:51.732 align:middle line:0
好 这是输入图像

00:43:51.798 --> 00:43:53.367 align:middle line:0
我们把它喂给我们的神经网络

00:43:53.433 --> 00:43:57.804 align:middle line:-2
和另一个我们预先训练过的
CoreML模型

00:43:59.106 --> 00:44:00.774 align:middle line:-1
好吗？让我们来运行吧

00:43:59.106 --> 00:44:00.774 align:middle line:-1
好吗？让我们来运行吧

00:44:05.279 --> 00:44:06.113 align:middle line:-1
和…

00:44:09.683 --> 00:44:12.519 align:middle line:0
就这样
2018年WWDC是为你而举办的

00:44:13.720 --> 00:44:15.722 align:middle line:-1
好 说到这儿

00:44:16.323 --> 00:44:19.059 align:middle line:-1
我要感谢大家今天参加这个会议

00:44:19.693 --> 00:44:22.062 align:middle line:-1
我希望你们喜欢这个演讲

00:44:22.129 --> 00:44:23.697 align:middle line:-1
就像我们享受为你准备演讲的过程

00:44:24.431 --> 00:44:26.767 align:middle line:0
我强烈建议你明天来和我们谈谈

00:44:26.834 --> 00:44:28.969 align:middle line:0
下午三点
在Core Image技术实验室

00:44:30.103 --> 00:44:31.672 align:middle line:0
非常感谢
