WEBVTT

00:00:17.017 --> 00:00:23.457 align:middle line:0
（Core ML新特性
第二部分）

00:00:24.858 --> 00:00:25.726 align:middle line:-1
大家好

00:00:31.398 --> 00:00:33.700 align:middle line:-2
欢迎来到Core ML
第二部分演讲

00:00:34.368 --> 00:00:37.971 align:middle line:-2
我是Aseem
Core ML团队的工程师

00:00:40.774 --> 00:00:43.243 align:middle line:-2
众所周知
Core ML是Apple

00:00:43.544 --> 00:00:46.413 align:middle line:-1
用于设备上推理的机器学习框架

00:00:48.348 --> 00:00:50.717 align:middle line:-1
而我最喜欢Core ML的原因

00:00:50.884 --> 00:00:53.754 align:middle line:-2
是它在所有Apple硬件上
都得到了优化

00:00:55.422 --> 00:00:56.657 align:middle line:-1
过去一年中

00:00:57.324 --> 00:01:02.429 align:middle line:-2
我们在所有Apple平台上看到了
许多令人惊叹的app

00:00:57.324 --> 00:01:02.429 align:middle line:-2
我们在所有Apple平台上看到了
许多令人惊叹的app

00:01:03.096 --> 00:01:04.464 align:middle line:-1
所以这真的很令人兴奋

00:01:05.232 --> 00:01:07.034 align:middle line:-1
而我们对今年推出的新功能

00:01:07.601 --> 00:01:09.803 align:middle line:-1
甚至更加兴奋

00:01:10.604 --> 00:01:11.438 align:middle line:-1
现在

00:01:12.039 --> 00:01:15.108 align:middle line:-1
你可以大幅缩减app的大小

00:01:16.577 --> 00:01:21.415 align:middle line:-2
通过使用新的批处理预测API
你可以使你的app运行更快

00:01:23.050 --> 00:01:27.588 align:middle line:-1
并且你可以轻松将最先进的研究成果

00:01:27.754 --> 00:01:29.990 align:middle line:-1
通过自定义机制整合到你的app中

00:01:31.725 --> 00:01:33.961 align:middle line:-1
这些是对第一次演讲的回顾

00:01:34.394 --> 00:01:35.662 align:middle line:-1
如果你错过了那次演讲

00:01:36.163 --> 00:01:38.932 align:middle line:-1
我强烈建议你回去看一下幻灯片

00:01:41.435 --> 00:01:43.837 align:middle line:-1
在这次演讲中 我们将会看到

00:01:44.238 --> 00:01:47.040 align:middle line:-1
如何实际使用这些特性

00:01:47.941 --> 00:01:51.211 align:middle line:-2
更具体地说
我们将通过几个例子向你展示

00:01:51.678 --> 00:01:55.148 align:middle line:-1
你如何通过简单的几步

00:01:55.682 --> 00:01:59.953 align:middle line:-2
使用Core ML Tools
来缩减模型的大小

00:02:00.220 --> 00:02:02.856 align:middle line:-1
以及你如何在模型中使用自定义特性

00:02:04.591 --> 00:02:06.126 align:middle line:-1
这是这次演讲的议程

00:02:07.060 --> 00:02:10.764 align:middle line:-2
我们从Core ML Tools
生态系统的最新进展开始

00:02:11.732 --> 00:02:17.304 align:middle line:-2
然后我们将深入并演示
量化和自定义转换

00:02:18.038 --> 00:02:19.640 align:middle line:-1
让我们先从生态系统开始

00:02:23.277 --> 00:02:25.312 align:middle line:-1
你如何得到一个ML模型呢？

00:02:26.046 --> 00:02:28.048 align:middle line:-1
最简单的是 如果你…

00:02:29.449 --> 00:02:30.384 align:middle line:-1
如果你可以…

00:02:32.286 --> 00:02:35.022 align:middle line:-2
如果你能在网上找到它
只需下载它 对吧？

00:02:36.023 --> 00:02:39.393 align:middle line:-1
一个下载ML模型的好地方

00:02:39.459 --> 00:02:42.362 align:middle line:-1
是Apple机器学习着陆页

00:02:42.696 --> 00:02:44.264 align:middle line:-1
那上面有许多模型

00:02:45.465 --> 00:02:48.468 align:middle line:-2
现在让我们假设你想
在你的数据集上训练一个模型

00:02:49.036 --> 00:02:51.104 align:middle line:-1
在这种情况下 你可以使用

00:02:52.739 --> 00:02:53.774 align:middle line:-1
Create ML

00:02:53.941 --> 00:02:56.977 align:middle line:-1
这是我们今年刚刚发布的一个新框架

00:02:57.845 --> 00:03:00.848 align:middle line:-1
你无需成为机器学习专家即可使用它

00:02:57.845 --> 00:03:00.848 align:middle line:-1
你无需成为机器学习专家即可使用它

00:03:01.315 --> 00:03:03.784 align:middle line:-2
它非常易于使用
它就在Xcode中

00:03:04.451 --> 00:03:06.920 align:middle line:-1
所以去试试吧

00:03:08.488 --> 00:03:13.126 align:middle line:-2
你们中的一些人已经熟悉了
开源社区中的一些

00:03:13.193 --> 00:03:15.529 align:middle line:-1
令人惊叹的机器学习工具

00:03:16.029 --> 00:03:22.002 align:middle line:-2
为此我们去年发布了一个Python包
即Core ML Tools

00:03:22.536 --> 00:03:26.773 align:middle line:-1
此外我们还发布了一些转换器

00:03:28.375 --> 00:03:32.246 align:middle line:-1
去年这个领域有许多活动

00:03:32.946 --> 00:03:34.915 align:middle line:-1
这就是现在的样子

00:03:37.451 --> 00:03:42.422 align:middle line:-1
正如你所看到的 还有更多的转换器

00:03:42.890 --> 00:03:47.160 align:middle line:-2
现在确实有很多不同的
训练框架以供你选择

00:03:48.695 --> 00:03:52.533 align:middle line:-2
所有这些转换器都建立在
Core ML Tools之上

00:03:55.369 --> 00:03:59.072 align:middle line:-2
现在 我想在这里强调
几个不同的转换器

00:04:01.175 --> 00:04:06.346 align:middle line:-2
去年我们与Google合作
发布了TensorFlow转换器

00:04:07.414 --> 00:04:08.715 align:middle line:-1
这很令人兴奋

00:04:10.651 --> 00:04:15.322 align:middle line:-2
如你所知 TensorFlow
在爱尝试新层的研究人员中颇受欢迎

00:04:15.656 --> 00:04:19.625 align:middle line:-2
所以我们最近在转换器中添加了
对自定义层的支持

00:04:21.128 --> 00:04:25.832 align:middle line:-2
最近TensorFlow发布了
对在训练过程中进行量化的支持

00:04:26.200 --> 00:04:28.602 align:middle line:-2
这种支持是通过
Core ML 2实现的

00:04:29.102 --> 00:04:31.438 align:middle line:-1
这个特性很快就会添加到转换器中

00:04:33.173 --> 00:04:37.811 align:middle line:-2
另一个令人兴奋的是
我们与Facebook和Prisma的合作

00:04:38.312 --> 00:04:40.881 align:middle line:-1
这些合作的成果就是ONNX转换器

00:04:42.182 --> 00:04:43.951 align:middle line:-1
ONNX的优势在于

00:04:45.652 --> 00:04:49.857 align:middle line:-1
现在你可以使用许多不同的训练库了

00:04:50.290 --> 00:04:54.361 align:middle line:-2
通过使用新的ONNX转换器
它们都可以被转换为Core ML

00:04:56.230 --> 00:05:00.434 align:middle line:-2
这是对Core ML Tools
生态系统最新进展的快速总结

00:04:56.230 --> 00:05:00.434 align:middle line:-2
这是对Core ML Tools
生态系统最新进展的快速总结

00:05:00.834 --> 00:05:02.569 align:middle line:-1
为了讨论量化

00:05:02.636 --> 00:05:05.472 align:middle line:-2
我想邀请我的朋友
Sohaib到舞台上来

00:05:14.147 --> 00:05:16.116 align:middle line:-2
大家早上好
我叫Sohaib

00:05:16.183 --> 00:05:17.985 align:middle line:-1
我是Core ML团队的工程师

00:05:18.051 --> 00:05:21.321 align:middle line:-2
今天 我们将看看
Core ML Tools 2.0中

00:05:21.388 --> 00:05:22.990 align:middle line:-1
新的量化功能

00:05:28.095 --> 00:05:29.763 align:middle line:-1
Core ML Tools 2.0支持

00:05:29.830 --> 00:05:32.432 align:middle line:-1
最新的Core ML模型格式规范

00:05:32.733 --> 00:05:33.867 align:middle line:-1
它也有一些实用工具

00:05:33.934 --> 00:05:36.904 align:middle line:-2
使你可以轻松地添加
弹性形状和量化功能

00:05:37.204 --> 00:05:39.740 align:middle line:-1
到你的神经网络机器学习模型中

00:05:40.240 --> 00:05:42.309 align:middle line:-2
在Core ML中
使用这些优秀新功能

00:05:42.376 --> 00:05:45.279 align:middle line:-1
你不仅可以缩减模型的大小

00:05:45.546 --> 00:05:48.949 align:middle line:-2
还可以减少app中模型的数量
并且减少app的占用空间

00:05:50.350 --> 00:05:53.320 align:middle line:-1
现在 我们先看一下量化

00:05:54.821 --> 00:05:57.257 align:middle line:-2
Core ML Tools
支持训练后量化

00:05:57.658 --> 00:06:00.194 align:middle line:-2
我们从Core ML
神经网络模型开始

00:05:57.658 --> 00:06:00.194 align:middle line:-2
我们从Core ML
神经网络模型开始

00:06:00.594 --> 00:06:03.330 align:middle line:-1
它具有32位浮点权重参数

00:06:03.730 --> 00:06:07.467 align:middle line:-2
我们用Core ML Tools
来量化这个模型的权重

00:06:08.101 --> 00:06:10.037 align:middle line:-1
生成的模型体积较小

00:06:10.771 --> 00:06:13.340 align:middle line:-1
模型大小的缩减直接依赖于

00:06:13.407 --> 00:06:15.876 align:middle line:-1
我们量化模型的位数

00:06:17.811 --> 00:06:21.048 align:middle line:-2
现在 我们中的很多人可能会想
量化到底是什么？

00:06:21.281 --> 00:06:23.317 align:middle line:-1
它如何缩减模型的大小

00:06:23.984 --> 00:06:26.253 align:middle line:-1
让我们窥视一下幕后所发生的事情

00:06:30.357 --> 00:06:32.426 align:middle line:-1
神经网络由层组成

00:06:32.726 --> 00:06:35.495 align:middle line:-1
这些层可以被视为数学函数

00:06:36.063 --> 00:06:39.233 align:middle line:-1
这些数学函数有参数 称为权重

00:06:39.700 --> 00:06:42.803 align:middle line:-1
这些权重通常存储为32位浮点数

00:06:44.304 --> 00:06:47.074 align:middle line:-2
在我们之前的演讲中
我们谈到了ResNet50

00:06:47.641 --> 00:06:49.142 align:middle line:-1
这是一种流行的机器学习模型

00:06:49.209 --> 00:06:52.045 align:middle line:-1
可以用于图像分类等等

00:06:52.446 --> 00:06:56.283 align:middle line:-2
这个模型拥有
超过2500万个权重参数

00:06:57.050 --> 00:07:00.320 align:middle line:-2
所以你可以想象
如果你能以某种方式以更少的位数

00:06:57.050 --> 00:07:00.320 align:middle line:-2
所以你可以想象
如果你能以某种方式以更少的位数

00:07:00.521 --> 00:07:02.723 align:middle line:-1
来表示这些参数

00:07:03.090 --> 00:07:05.325 align:middle line:-1
我们就可以大大缩减这个模型的大小

00:07:06.927 --> 00:07:09.730 align:middle line:-1
实际上 这个过程被称为量化

00:07:10.464 --> 00:07:13.267 align:middle line:-1
在量化过程中 我们将

00:07:13.600 --> 00:07:16.003 align:middle line:-1
在最小值和最大值之间的层的权重

00:07:16.537 --> 00:07:17.638 align:middle line:-1
映射为

00:07:18.605 --> 00:07:19.773 align:middle line:-1
无符号整数

00:07:20.908 --> 00:07:22.576 align:middle line:-1
对于APIC量化

00:07:22.643 --> 00:07:26.680 align:middle line:-1
我们将这些值映射到0到55的范围

00:07:27.114 --> 00:07:28.382 align:middle line:-1
对于7位量化

00:07:28.448 --> 00:07:32.553 align:middle line:-2
我们将它们映射到0到127
一直到1位

00:07:32.786 --> 00:07:35.489 align:middle line:-1
即将这些权重映射为0或1

00:07:36.223 --> 00:07:37.491 align:middle line:-1
由于我们使用更少的位数

00:07:37.558 --> 00:07:40.594 align:middle line:-2
来表示相同的信息
因此我们缩减了模型的大小

00:07:42.362 --> 00:07:43.197 align:middle line:-1
真棒

00:07:43.530 --> 00:07:47.334 align:middle line:-2
你们中许多人可能已经注意到
我们正在将浮点数映射为整数

00:07:48.202 --> 00:07:51.171 align:middle line:-1
你可能已经得出结论 在这种映射中

00:07:51.638 --> 00:07:53.841 align:middle line:-1
可能会有一些精确度损失 这是对的

00:07:54.675 --> 00:07:55.642 align:middle line:-1
经验法则是

00:07:55.976 --> 00:07:58.278 align:middle line:-1
你用来量化模型的位数越少

00:07:58.545 --> 00:08:00.914 align:middle line:-2
我们的模型在准确性方面
所受到的影响越大

00:07:58.545 --> 00:08:00.914 align:middle line:-2
我们的模型在准确性方面
所受到的影响越大

00:08:01.048 --> 00:08:02.683 align:middle line:-1
我们稍后还会谈到这一点

00:08:03.884 --> 00:08:05.619 align:middle line:-1
以上是对量化的概述

00:08:05.986 --> 00:08:08.755 align:middle line:-2
但问题依然存在
我们如何获得这种映射

00:08:09.489 --> 00:08:11.258 align:middle line:-1
有很多流行的算法

00:08:11.325 --> 00:08:13.694 align:middle line:-1
和技术能帮助你做到这一点

00:08:13.760 --> 00:08:16.530 align:middle line:-2
Core ML支持
其中两种最流行的

00:08:17.130 --> 00:08:19.700 align:middle line:-1
线性量化和查找表量化

00:08:20.634 --> 00:08:22.002 align:middle line:-1
让我们简要介绍一下

00:08:26.273 --> 00:08:28.008 align:middle line:-1
线性量化是一种

00:08:28.075 --> 00:08:31.778 align:middle line:-1
以均匀的方式映射参数的算法

00:08:32.880 --> 00:08:37.150 align:middle line:-2
这种量化是通过比例系数和偏差值
进行参数化的

00:08:37.217 --> 00:08:39.186 align:middle line:-1
这些值是通过计算得到的

00:08:39.553 --> 00:08:42.389 align:middle line:-1
该计算基于我们正在量化的层的参数

00:08:43.023 --> 00:08:46.393 align:middle line:-2
了解这种映射工作原理
的一种非常直观的方式

00:08:46.727 --> 00:08:48.195 align:middle line:-1
是我们退后一步

00:08:48.262 --> 00:08:50.497 align:middle line:-1
看看我们如何从位于底部的量化权重

00:08:50.564 --> 00:08:53.267 align:middle line:-1
恢复到原来的浮点数权重

00:08:53.834 --> 00:08:57.571 align:middle line:-2
在线性量化中
我们只需用量化权重

00:08:57.804 --> 00:08:59.973 align:middle line:-1
乘以比例系数再加上偏差

00:09:02.075 --> 00:09:04.778 align:middle line:-2
Core ML支持的
第二种量化技术

00:09:05.012 --> 00:09:06.513 align:middle line:-1
是查找表量化

00:09:07.147 --> 00:09:09.383 align:middle line:-1
顾名思义

00:09:09.683 --> 00:09:11.018 align:middle line:-1
我们构造一个查找表

00:09:11.952 --> 00:09:14.588 align:middle line:-1
再想象一下我们如何从量化后的权重

00:09:14.655 --> 00:09:17.024 align:middle line:-2
得到原来的权重
会很有帮助

00:09:17.257 --> 00:09:20.294 align:middle line:-1
在这种情况下 量化权重只是

00:09:20.594 --> 00:09:22.763 align:middle line:-1
查找表中的一些索引

00:09:24.031 --> 00:09:26.233 align:middle line:-2
现在 如果你注意到
与线性量化不同

00:09:26.300 --> 00:09:29.603 align:middle line:-2
我们现在可以自由移动
我们的量化权重

00:09:29.670 --> 00:09:32.039 align:middle line:-1
它们不必以线性方式间隔开

00:09:33.874 --> 00:09:37.811 align:middle line:-2
回顾一下
Core ML Tools支持

00:09:38.612 --> 00:09:40.781 align:middle line:-1
线性量化和查找表量化

00:09:40.848 --> 00:09:42.850 align:middle line:-1
我们从一个全精度神经网络模型开始

00:09:42.916 --> 00:09:45.652 align:middle line:-1
并使用这些工具来量化该模型的权重

00:09:46.220 --> 00:09:47.654 align:middle line:-1
现在你可能在想

00:09:47.988 --> 00:09:50.290 align:middle line:-2
太好了
我可以缩减我的模型的大小

00:09:50.824 --> 00:09:53.961 align:middle line:-1
但该如何找出量化的参数呢？

00:09:54.761 --> 00:09:57.965 align:middle line:-2
如果我正进行线性量化
我该如何计算出比例系数和偏差呢？

00:09:58.365 --> 00:10:02.035 align:middle line:-2
如果我正在执行查找表量化
我该如何构建查找表呢？

00:09:58.365 --> 00:10:02.035 align:middle line:-2
如果我正在执行查找表量化
我该如何构建查找表呢？

00:10:03.036 --> 00:10:06.206 align:middle line:-2
我在这里告诉你
你不必关心这其中任何一点

00:10:06.940 --> 00:10:10.611 align:middle line:-2
你所要做的就是决定
你想要量化模型的位数

00:10:10.844 --> 00:10:12.746 align:middle line:-1
并决定要使用的算法

00:10:13.046 --> 00:10:15.215 align:middle line:-2
剩下的工作交给
Core ML Tools来完成

00:10:16.083 --> 00:10:16.984 align:middle line:-1
事实上…

00:10:17.985 --> 00:10:18.819 align:middle line:-1
谢谢大家

00:10:22.656 --> 00:10:26.994 align:middle line:-2
事实上 量化一个
Core ML模型是如此简单

00:10:27.394 --> 00:10:29.796 align:middle line:-2
以至于我们可在几行
Python代码中完成它

00:10:30.397 --> 00:10:33.400 align:middle line:-2
既然我们可以在这里演示
何必继续浪费口舌呢？

00:10:40.507 --> 00:10:42.676 align:middle line:-1
为了演示

00:10:42.743 --> 00:10:46.013 align:middle line:-2
我需要一个
Core ML模型格式的神经网络

00:10:46.580 --> 00:10:48.248 align:middle line:-1
正如我的同事Aseem所说

00:10:48.315 --> 00:10:51.752 align:middle line:-2
Core ML机器学习主页是一个
找到这些模型的好地方

00:10:52.052 --> 00:10:55.189 align:middle line:-2
我已经提前下载了该页面中的
一个模型

00:10:55.522 --> 00:10:58.358 align:middle line:-2
这个模型叫做SqueezeNet
让我们打开它

00:11:00.627 --> 00:11:03.230 align:middle line:-2
正如我们所看到的
这个模型的大小是5兆字节

00:11:03.597 --> 00:11:08.268 align:middle line:-2
它有一个输入
是一个227*227像素的图像

00:11:08.669 --> 00:11:12.105 align:middle line:-2
它有两个输出
其中一个是类标签

00:11:12.639 --> 00:11:16.243 align:middle line:-2
由一个字符串表示
它代表该图片最有可能

00:11:16.610 --> 00:11:17.644 align:middle line:-1
属于的标签

00:11:17.711 --> 00:11:21.215 align:middle line:-1
第二个输出是这些字符串对应的概率

00:11:21.615 --> 00:11:23.951 align:middle line:-1
鉴于此 如果我们传入图像

00:11:24.017 --> 00:11:27.020 align:middle line:-2
我们会得到这个图像
可能是什么的概率列表

00:11:28.789 --> 00:11:30.457 align:middle line:-1
现在让我们开始量化这个模型

00:11:31.458 --> 00:11:34.761 align:middle line:-2
我首先要做的是
进入一个Python环境

00:11:34.928 --> 00:11:35.896 align:middle line:-1
我比较喜欢

00:11:35.963 --> 00:11:37.831 align:middle line:-1
Jupyter Notebook

00:11:38.098 --> 00:11:39.766 align:middle line:-1
现在我们打开它

00:11:46.673 --> 00:11:50.110 align:middle line:-1
让我们打开一个新的笔记本并放大

00:11:51.311 --> 00:11:54.915 align:middle line:-2
我们先导入
Core ML Tools

00:11:58.886 --> 00:12:01.221 align:middle line:-2
让我们来运行它
然后我想做的是

00:11:58.886 --> 00:12:01.221 align:middle line:-2
让我们来运行它
然后我想做的是

00:12:01.288 --> 00:12:03.724 align:middle line:-2
导入所有
在Core ML Tools中的

00:12:03.790 --> 00:12:07.261 align:middle line:-2
新量化工具
我们通过运行这句代码来达到目的

00:12:16.170 --> 00:12:19.106 align:middle line:-1
现在我们需要加载想要量化的模型

00:12:19.173 --> 00:12:21.175 align:middle line:-2
即我们刚看到的
SqueezeNet模型

00:12:21.241 --> 00:12:23.343 align:middle line:-1
我们需要获取该模型的一个实例

00:12:32.786 --> 00:12:34.288 align:middle line:-1
将参数设置为我的桌面

00:12:37.991 --> 00:12:38.825 align:middle line:-1
很好

00:12:39.026 --> 00:12:43.063 align:middle line:-2
现在 为了量化这个模型
我们只需要做一个简单的API调用

00:12:43.463 --> 00:12:47.267 align:middle line:-2
让我们尝试使用线性量化
来量化这个模型

00:12:51.572 --> 00:12:54.408 align:middle line:-2
它的API名称很简单
叫quantize_weights

00:12:54.808 --> 00:12:56.510 align:middle line:-1
我们传入的第一个参数

00:12:56.877 --> 00:12:59.079 align:middle line:-1
是你刚加载的原始模型

00:12:59.546 --> 00:13:02.149 align:middle line:-1
然后是我们想要量化模型的位数

00:12:59.546 --> 00:13:02.149 align:middle line:-1
然后是我们想要量化模型的位数

00:13:02.216 --> 00:13:03.550 align:middle line:-1
这里我们将其设为8

00:13:04.685 --> 00:13:06.887 align:middle line:-1
以及我们想要使用的量化算法

00:13:07.054 --> 00:13:08.689 align:middle line:-1
让我们试试线性量化

00:13:10.157 --> 00:13:11.158 align:middle line:-1
现在所发生的事情是

00:13:11.225 --> 00:13:14.995 align:middle line:-1
这些工具会遍历线性网络的所有层

00:13:15.062 --> 00:13:17.731 align:middle line:-1
并量化这些层中的所有权重

00:13:18.165 --> 00:13:19.099 align:middle line:-1
我们完成了

00:13:20.467 --> 00:13:22.269 align:middle line:-1
如果你还记得

00:13:22.603 --> 00:13:25.272 align:middle line:-1
几分钟前我提到量化我们的模型

00:13:25.339 --> 00:13:27.274 align:middle line:-1
会造成精确度上的损失

00:13:27.941 --> 00:13:31.345 align:middle line:-2
所以我们想知道我们的量化模型
与原始模型相比效果如何

00:13:32.179 --> 00:13:35.883 align:middle line:-2
这样做的最简单方法是
将一些数据传给它

00:13:36.383 --> 00:13:39.953 align:middle line:-1
并使用我们的原始模型推理该数据

00:13:40.554 --> 00:13:42.956 align:middle line:-1
再使用我们的量化模型

00:13:43.023 --> 00:13:46.426 align:middle line:-2
对相同的数据进行相同的推理
并比较这两者的预测

00:13:47.094 --> 00:13:48.595 align:middle line:-1
来看看它们的一致程度

00:13:49.029 --> 00:13:51.465 align:middle line:-2
Core ML Tools
有帮助你做到这一点的工具

00:13:51.532 --> 00:13:55.636 align:middle line:-2
我们可以通过调用这个
称为compare_models函数来达到目的

00:13:56.236 --> 00:13:57.971 align:middle line:-1
我们传入全精度模型

00:13:58.472 --> 00:14:01.141 align:middle line:-1
然后是我们刚刚量化过的模型

00:13:58.472 --> 00:14:01.141 align:middle line:-1
然后是我们刚刚量化过的模型

00:14:01.942 --> 00:14:03.710 align:middle line:-1
由于这个模型是一个简单的

00:14:04.778 --> 00:14:07.381 align:middle line:-1
图像分类器 它只有一个图像输入

00:14:08.081 --> 00:14:09.416 align:middle line:-1
我们有一个方便的工具

00:14:09.483 --> 00:14:12.753 align:middle line:-2
我们只需传入一个
包含样本数据图像的文件夹

00:14:13.120 --> 00:14:14.221 align:middle line:-1
在我的桌面上

00:14:14.288 --> 00:14:17.824 align:middle line:-2
我有一个文件夹
里面有一组与我的app相关的图像

00:14:18.158 --> 00:14:23.063 align:middle line:-2
因此我将这个文件夹的路径
作为临时参数传入

00:14:27.968 --> 00:14:28.836 align:middle line:-1
很好

00:14:28.902 --> 00:14:31.805 align:middle line:-2
现在我们看到我们正在分析
该文件夹中的所有图像

00:14:31.872 --> 00:14:34.174 align:middle line:-1
我们正在推理…

00:14:34.241 --> 00:14:36.577 align:middle line:-1
我们先使用全精度模型

00:14:36.643 --> 00:14:38.512 align:middle line:-1
然后再用量化模型进行推理

00:14:38.579 --> 00:14:40.380 align:middle line:-1
最后比较这两个预测

00:14:41.348 --> 00:14:42.749 align:middle line:-1
我们似乎已经完成了

00:14:43.750 --> 00:14:46.954 align:middle line:-2
你可以看到我们的Top 1
Agreement值是94.8%

00:14:47.721 --> 00:14:51.058 align:middle line:-2
看起来不错 这个Top 1
Agreement是什么意思呢？

00:14:51.558 --> 00:14:53.894 align:middle line:-1
这意味着当我向原始模型输入

00:14:54.494 --> 00:14:56.763 align:middle line:-1
比如一只狗的图像时

00:14:57.297 --> 00:14:59.132 align:middle line:-1
它会预测这张图片是一只狗

00:14:59.199 --> 00:15:00.767 align:middle line:-1
而我的量化模型也作出同样预测

00:14:59.199 --> 00:15:00.767 align:middle line:-1
而我的量化模型也作出同样预测

00:15:01.034 --> 00:15:04.137 align:middle line:-2
这种情况发生在
数据集中94.8%的图片上

00:15:05.839 --> 00:15:08.275 align:middle line:-1
我可以在我的app中使用此模型

00:15:08.675 --> 00:15:09.943 align:middle line:-1
但我想看看

00:15:10.177 --> 00:15:12.779 align:middle line:-2
其他量化技术
是否在这个模型上效果更好

00:15:13.480 --> 00:15:16.917 align:middle line:-2
正如我所提到的
Core ML支持两种量化技术

00:15:17.084 --> 00:15:19.553 align:middle line:-1
线性量化和查找表量化

00:15:19.887 --> 00:15:21.188 align:middle line:-1
所以让我们继续尝试

00:15:21.488 --> 00:15:24.124 align:middle line:-1
使用查找表量化来量化此模型

00:15:30.931 --> 00:15:32.466 align:middle line:-1
我们再次传入原始模型

00:15:32.766 --> 00:15:35.102 align:middle line:-1
和我们想要量化模型的位数

00:15:35.669 --> 00:15:37.404 align:middle line:-1
以及我们的量化技术

00:15:39.306 --> 00:15:40.474 align:middle line:-1
哎呀 这里有个错误

00:15:48.916 --> 00:15:50.217 align:middle line:-1
让我们运行它

00:15:50.651 --> 00:15:53.720 align:middle line:-2
K-means是一种
简单的聚类算法

00:15:53.787 --> 00:15:56.356 align:middle line:-1
能够逼近我们的权重分布

00:15:56.657 --> 00:15:58.192 align:middle line:-1
使用这种分布

00:15:58.392 --> 00:16:02.062 align:middle line:-1
我们可以为我们的权重构建查找表

00:15:58.392 --> 00:16:02.062 align:middle line:-1
我们可以为我们的权重构建查找表

00:16:02.529 --> 00:16:04.097 align:middle line:-1
我们在这里做的是

00:16:04.164 --> 00:16:07.000 align:middle line:-1
我们遍历神经网络中的所有层

00:16:07.267 --> 00:16:09.736 align:middle line:-1
对其执行量化过程

00:16:09.970 --> 00:16:11.438 align:middle line:-1
并为那个特顶层计算查找表

00:16:12.206 --> 00:16:15.409 align:middle line:-2
如果你是一位专家
并且你了解你的模型

00:16:15.576 --> 00:16:16.944 align:middle line:-1
你也知道你的模型架构

00:16:17.211 --> 00:16:19.580 align:middle line:-2
而且你知道K-means
不是最合适你的算法

00:16:19.813 --> 00:16:22.049 align:middle line:-1
你可以灵活地传入

00:16:22.216 --> 00:16:23.483 align:middle line:-1
你自己的自定义函数

00:16:24.585 --> 00:16:26.954 align:middle line:-2
而不是这里的这个算法
这个工具将使用

00:16:27.020 --> 00:16:29.790 align:middle line:-1
你的自定义函数来为你构造查找表

00:16:30.824 --> 00:16:34.661 align:middle line:-2
我们使用查找表方法
再次完成了对这个模型的量化

00:16:35.062 --> 00:16:38.298 align:middle line:-2
现在让我们看看这个模型
与我们的原始模型比较效果如何

00:16:38.632 --> 00:16:41.468 align:middle line:-2
所以我们再次调用
compare_models API

00:16:42.236 --> 00:16:46.373 align:middle line:-2
我们传入原始模型
接着传入查找表模型

00:16:46.974 --> 00:16:48.909 align:middle line:-1
我们再次传入

00:16:50.511 --> 00:16:51.645 align:middle line:-1
示例数据文件夹

00:16:54.681 --> 00:16:58.619 align:middle line:-1
我们再次使用原始模型和量化模型

00:16:59.586 --> 00:17:01.388 align:middle line:-1
对所有图像进行推理

00:16:59.586 --> 00:17:01.388 align:middle line:-1
对所有图像进行推理

00:17:01.688 --> 00:17:02.723 align:middle line:-1
我们看到这一次

00:17:02.789 --> 00:17:05.791 align:middle line:-2
我们得到了一个更好一点的
Top 1 Agreement

00:17:06.193 --> 00:17:07.261 align:middle line:-1
对于这个模型

00:17:07.694 --> 00:17:09.963 align:middle line:-1
我们看到查找表是正确的选择

00:17:10.364 --> 00:17:12.866 align:middle line:-1
但是这与模型有关 对于其他模型

00:17:13.066 --> 00:17:14.067 align:middle line:-1
可能是线性量化效果更好

00:17:14.635 --> 00:17:17.905 align:middle line:-2
现在我们对这个结果感到高兴
并且认为这对我的app来说

00:17:17.971 --> 00:17:20.773 align:middle line:-2
已经够好了
现在让我们保存此模型

00:17:23.410 --> 00:17:25.546 align:middle line:-1
我们通过调用save函数来保存

00:17:30.417 --> 00:17:34.254 align:middle line:-2
再给它起个有创意的名字
就叫QuantizedSqueezeNet

00:17:41.161 --> 00:17:43.263 align:middle line:-2
可以了
现在我们有了一个量化模型

00:17:43.964 --> 00:17:47.634 align:middle line:-2
这是一个原始模型
我们看到它的大小是5兆字节

00:17:48.168 --> 00:17:50.037 align:middle line:-1
让我们打开我们的量化模型

00:17:52.606 --> 00:17:54.274 align:middle line:-1
我们立即注意到的第一件事

00:17:54.341 --> 00:17:57.544 align:middle line:-1
是这个模型的大小只有1.3兆字节

00:18:04.117 --> 00:18:05.285 align:middle line:-1
如果你注意一下会发现

00:18:05.986 --> 00:18:10.858 align:middle line:-2
有关量化模型的所有细节
都与原始模型相同

00:18:11.225 --> 00:18:14.561 align:middle line:-2
它仍然需要一个图像输入
仍然有两个输出

00:18:15.229 --> 00:18:18.131 align:middle line:-2
若我有一个使用此模型的app
我可以做的是

00:18:18.198 --> 00:18:19.633 align:middle line:-1
如我们在演示中看到的那样

00:18:20.000 --> 00:18:22.536 align:middle line:-2
将这个量化模型直接
拖入我们的app

00:18:22.603 --> 00:18:23.937 align:middle line:-1
并开始使用它

00:18:24.137 --> 00:18:26.440 align:middle line:-2
只需这样 我们就缩减了
app的大小

00:18:32.379 --> 00:18:34.915 align:middle line:-2
这就是使用
Core ML Tools量化的过程

00:18:38.652 --> 00:18:43.590 align:middle line:-2
回顾一下 我们看到使用Core ML Tools
来量化我们的模型是多么容易

00:18:44.291 --> 00:18:48.328 align:middle line:-2
使用一个简单的API
传入我们的原始模型

00:18:48.795 --> 00:18:51.231 align:middle line:-1
我们想要量化模型的位数

00:18:51.498 --> 00:18:53.667 align:middle line:-1
和我们想要使用的量化算法

00:18:54.201 --> 00:18:56.436 align:middle line:-2
我们也看到Core ML Tools中
有一些实用工具

00:18:56.703 --> 00:18:59.039 align:middle line:-1
来帮助我们比较量化模型

00:18:59.373 --> 00:19:01.808 align:middle line:-2
从而了解它与我们的
原始模型相比较效果如何

00:18:59.373 --> 00:19:01.808 align:middle line:-2
从而了解它与我们的
原始模型相比较效果如何

00:19:03.510 --> 00:19:05.345 align:middle line:-1
正如我们在演示中看到的那样

00:19:05.712 --> 00:19:08.882 align:middle line:-2
量化我们的模型会导致
相应精度的损失

00:19:09.816 --> 00:19:10.817 align:middle line:-1
这个…

00:19:11.151 --> 00:19:13.754 align:middle line:-1
这种精度损失高度依赖于模型和数据

00:19:14.621 --> 00:19:18.759 align:middle line:-2
一些模型在量化之后
比其它模型表现更好

00:19:19.359 --> 00:19:20.994 align:middle line:-1
作为一般经验法则

00:19:21.161 --> 00:19:23.697 align:middle line:-1
我们量化模型的位数越少

00:19:24.364 --> 00:19:26.033 align:middle line:-1
我们精度所受的影响就越大

00:19:26.567 --> 00:19:28.235 align:middle line:-1
在演示中我们看到

00:19:28.669 --> 00:19:31.705 align:middle line:-2
我们能使用Core ML Tools中的
Top 1 Agreement指标

00:19:31.772 --> 00:19:34.575 align:middle line:-2
来比较我们的量化模型
和原始模型

00:19:35.442 --> 00:19:36.810 align:middle line:-1
但你必须弄清楚

00:19:37.411 --> 00:19:40.147 align:middle line:-2
你的模型和用例的
相关度量标准是什么

00:19:40.214 --> 00:19:42.850 align:middle line:-1
并验证你的量化模型是可接受的

00:19:44.017 --> 00:19:47.421 align:middle line:-2
在之前的演讲中
我们看了一个风格转换演示

00:19:48.155 --> 00:19:50.757 align:middle line:-1
这个网络输入一幅图像

00:19:51.158 --> 00:19:54.494 align:middle line:-1
然后输出一个风格化的图像

00:19:55.329 --> 00:19:57.297 align:middle line:-1
让我们来看看这个模型

00:19:57.364 --> 00:19:59.233 align:middle line:-1
在不同的量化级别下表现如何

00:20:00.133 --> 00:20:04.271 align:middle line:-1
在左上角

00:20:04.771 --> 00:20:10.210 align:middle line:-2
我们看到原始模型是32位
大小为6.7兆字节

00:20:10.677 --> 00:20:14.448 align:middle line:-2
我们的8位线性量化模型
只有1.7兆字节

00:20:14.781 --> 00:20:17.451 align:middle line:-1
而且我们发现 从视觉上来看

00:20:17.518 --> 00:20:19.753 align:middle line:-2
该效果对于我的风格转换演示来说
已经足够了

00:20:20.687 --> 00:20:23.924 align:middle line:-1
我们还可以看到 即使低至4位

00:20:24.024 --> 00:20:26.193 align:middle line:-1
我们也不会在效果方面损失太多

00:20:26.593 --> 00:20:27.961 align:middle line:-1
我甚至可能会说

00:20:28.028 --> 00:20:30.163 align:middle line:-2
对于我的app来说
即使3位也可以正常工作

00:20:30.664 --> 00:20:33.967 align:middle line:-2
从2位开始我们可以看到
这时出现了很多痕迹

00:20:34.401 --> 00:20:36.436 align:middle line:-1
这个模型可能不适合我们

00:20:38.906 --> 00:20:41.175 align:middle line:-2
以上就是如何使用
Core ML Tools进行量化的部分

00:20:41.975 --> 00:20:43.510 align:middle line:-1
接下来我将话筒交回给Aseem

00:20:43.577 --> 00:20:45.612 align:middle line:-1
他将会谈论自定义转换

00:20:45.779 --> 00:20:46.613 align:middle line:-1
谢谢

00:20:52.352 --> 00:20:53.387 align:middle line:-1
谢谢Sohaib

00:20:55.155 --> 00:20:58.659 align:middle line:-1
我想谈一下一个非常重要的特性

00:20:58.725 --> 00:21:01.728 align:middle line:-2
它让我们能够跟上
机器学习领域的发展

00:20:58.725 --> 00:21:01.728 align:middle line:-2
它让我们能够跟上
机器学习领域的发展

00:21:02.329 --> 00:21:03.397 align:middle line:-1
大家都知道

00:21:04.064 --> 00:21:07.134 align:middle line:-1
机器学习领域正在迅速发展

00:21:07.768 --> 00:21:10.304 align:middle line:-2
因此 为你提供必要的软件工具
来解决这个问题

00:21:10.771 --> 00:21:14.374 align:middle line:-2
对于我们Core ML团队来说
非常重要

00:21:15.876 --> 00:21:17.077 align:middle line:-1
现在举一个例子

00:21:17.911 --> 00:21:20.781 align:middle line:-1
假设你正在尝试一个

00:21:20.848 --> 00:21:22.349 align:middle line:-1
Core ML尚不支持的新模型

00:21:22.649 --> 00:21:27.321 align:middle line:-2
或者假设你有一个
运行在Core ML上的神经网络

00:21:27.387 --> 00:21:31.792 align:middle line:-2
但是也许其中有一两层
Core ML暂时无法提供

00:21:32.893 --> 00:21:38.432 align:middle line:-2
在这种情况下 你希望仍然能够使用
Core ML的强大功能 对吗？

00:21:39.333 --> 00:21:41.134 align:middle line:-2
对这个问题的回答是
是的

00:21:41.668 --> 00:21:44.938 align:middle line:-1
自定义机制将帮助你达到这点

00:21:46.173 --> 00:21:47.274 align:middle line:-1
在接下来的几分钟内

00:21:47.474 --> 00:21:50.644 align:middle line:-1
我想重点关注当我们有一个

00:21:50.711 --> 00:21:53.514 align:middle line:-1
新的神经网络层的情况

00:21:53.881 --> 00:21:56.984 align:middle line:-2
然后向你展示
你将如何将它转换为Core ML

00:21:57.284 --> 00:21:59.486 align:middle line:-1
以及如何在你的app中实现它

00:22:00.854 --> 00:22:02.956 align:middle line:-1
让我们先来看看模型转换

00:22:03.957 --> 00:22:07.261 align:middle line:-2
如果你使用过我们的转换器
或者即使你没有

00:22:07.661 --> 00:22:10.697 align:middle line:-2
它是一个非常简单的API
这只是对一个函数的调用

00:22:12.065 --> 00:22:15.068 align:middle line:-1
这是Keras转换器的样子

00:22:15.469 --> 00:22:17.638 align:middle line:-2
它与ONNX转换器
或TensorFlow转换器

00:22:17.704 --> 00:22:20.440 align:middle line:-1
都很相似

00:22:21.742 --> 00:22:25.612 align:middle line:-2
当你调用这个函数时
大多数情况下都是正常的

00:22:25.946 --> 00:22:29.149 align:middle line:0
但有时你可能会得到
类似这样的错误消息

00:22:30.751 --> 00:22:34.354 align:middle line:0
它可能会说
“嘿 不支持的某某操作”

00:22:35.088 --> 00:22:36.957 align:middle line:0
如果这件事发生在你身上

00:22:37.291 --> 00:22:40.894 align:middle line:0
你只需要多做一点事
就可以避开这个错误

00:22:41.628 --> 00:22:42.796 align:middle line:0
更具体地说

00:22:42.963 --> 00:22:47.668 align:middle line:0
这样的错误信息表明
你应该使用自定义层

00:22:48.969 --> 00:22:50.170 align:middle line:0
在我向你展示

00:22:50.237 --> 00:22:53.407 align:middle line:0
你需要做点什么才能成功转换之前

00:22:54.241 --> 00:22:57.778 align:middle line:-2
让我们先看几个
你需要使用到自定义层的例子

00:23:01.315 --> 00:23:05.853 align:middle line:-2
假设你有一个图像分类器
这是它在Xcode中的样子

00:23:06.220 --> 00:23:08.589 align:middle line:-1
这是一些关于该模型的高级描述

00:23:08.889 --> 00:23:12.593 align:middle line:-2
如果你能看到它的内部
很可能这是一个神经网络

00:23:13.026 --> 00:23:16.063 align:middle line:-1
而且很可能是一个卷积神经网络

00:23:16.129 --> 00:23:19.399 align:middle line:-2
所以它会有很多层
卷积层 激活层

00:23:20.367 --> 00:23:21.635 align:middle line:-1
现在可能会发生这种情况

00:23:21.702 --> 00:23:23.971 align:middle line:-1
即有一个新的激活层出现

00:23:24.037 --> 00:23:25.472 align:middle line:-1
而Core ML还不支持它

00:23:25.772 --> 00:23:26.607 align:middle line:-1
并且…

00:23:27.341 --> 00:23:30.277 align:middle line:-1
就像在每次机器学习会议上一样

00:23:30.344 --> 00:23:32.713 align:middle line:-1
研究人员总是在提出新的层

00:23:32.779 --> 00:23:34.214 align:middle line:-1
所以这是一个很常见的情况

00:23:35.048 --> 00:23:36.216 align:middle line:-1
如果发生这种情况

00:23:36.483 --> 00:23:40.888 align:middle line:-1
你只需要使用这个新层的自定义实现

00:23:41.321 --> 00:23:44.258 align:middle line:-2
然后你就准备好了
这就是这个模型的样子

00:23:44.324 --> 00:23:47.327 align:middle line:-1
唯一的区别是在底部的

00:23:47.394 --> 00:23:48.495 align:middle line:-1
这个依赖部分

00:23:49.363 --> 00:23:50.364 align:middle line:-1
其中…

00:23:51.431 --> 00:23:54.601 align:middle line:-2
具有这个模型所包含的
这个自定义层的描述

00:23:55.169 --> 00:23:56.837 align:middle line:-1
我们来看看另一个例子

00:23:57.004 --> 00:23:59.940 align:middle line:-2
假设我们有一个非常简单的
数字分类器

00:24:01.175 --> 00:24:02.342 align:middle line:-1
最近

00:24:02.943 --> 00:24:06.980 align:middle line:-2
我看到了一篇研究论文
它的题目是“空间变换网络”

00:24:07.548 --> 00:24:09.416 align:middle line:-1
它所做的事情是这样的

00:24:10.017 --> 00:24:13.687 align:middle line:-1
它在数字之后插入一个神经网络

00:24:14.154 --> 00:24:16.523 align:middle line:-1
用来定位数字的位置

00:24:17.291 --> 00:24:19.860 align:middle line:-1
然后将其传入一个网格采样器层

00:24:20.260 --> 00:24:22.229 align:middle line:-1
这会重新渲染这个数字

00:24:22.296 --> 00:24:25.265 align:middle line:-1
但这次它已经能够定位在数字本身上

00:24:25.566 --> 00:24:28.068 align:middle line:-1
然后你将它传递给你的旧分类方法

00:24:28.969 --> 00:24:32.339 align:middle line:-1
我们不关心这里的细节

00:24:32.406 --> 00:24:35.008 align:middle line:-1
但要注意的一点是

00:24:35.275 --> 00:24:36.944 align:middle line:-1
绿色部分是Core ML支持的

00:24:37.344 --> 00:24:40.581 align:middle line:-1
而红色部分是新的网格采样器层

00:24:40.948 --> 00:24:43.750 align:middle line:-1
是Core ML不支持的新实验层

00:24:44.418 --> 00:24:46.887 align:middle line:-1
我想通过这个特定模型的例子

00:24:47.354 --> 00:24:51.325 align:middle line:-2
来向你展示如何使用
Core ML Tools对其转换

00:24:51.959 --> 00:24:53.327 align:middle line:-1
现在我们来演示一下

00:25:00.000 --> 00:25:01.768 align:middle line:-1
我希望能够一次成功

00:25:03.504 --> 00:25:05.005 align:middle line:-1
好的

00:25:05.973 --> 00:25:06.974 align:middle line:-1
好

00:25:07.508 --> 00:25:09.977 align:middle line:-1
我先关闭这些窗口

00:25:14.648 --> 00:25:17.584 align:middle line:-1
让我清除这个

00:25:18.085 --> 00:25:22.856 align:middle line:-2
我也将使用
Jupyter Notebook来进行演示

00:25:29.930 --> 00:25:33.300 align:middle line:-1
导航到我的预训练网络的文件夹

00:25:34.334 --> 00:25:39.439 align:middle line:-2
你可以在这里看到我的
spatial_transformer文件

00:25:39.506 --> 00:25:41.441 align:middle line:-1
这是一个预训练的Keras模型

00:25:42.743 --> 00:25:46.380 align:middle line:-2
如果你想知道
我是如何得到这个模型的

00:25:48.182 --> 00:25:49.483 align:middle line:-1
基本上我做的是…

00:25:50.050 --> 00:25:51.418 align:middle line:-1
我可以轻松找到

00:25:51.485 --> 00:25:54.021 align:middle line:-1
空间变换器的开源实现

00:25:54.087 --> 00:25:57.057 align:middle line:-2
我刚在Keras中执行了该脚本
然后我就得到了这个模型

00:25:58.158 --> 00:26:02.429 align:middle line:-2
除此以外 我还有这个
网格采样器层的Python脚本

00:25:58.158 --> 00:26:02.429 align:middle line:-2
除此以外 我还有这个
网格采样器层的Python脚本

00:26:03.197 --> 00:26:05.866 align:middle line:-1
我正在谈论的这个网格采样器层

00:26:06.266 --> 00:26:08.669 align:middle line:-1
在Keras中也没有原生支持

00:26:09.303 --> 00:26:11.805 align:middle line:-1
所以我在网上找到的这个实现

00:26:12.105 --> 00:26:15.676 align:middle line:-1
使用Keras自定义层来实现该层

00:26:16.376 --> 00:26:20.614 align:middle line:-2
正如你所见 自定义概念
并不是Core ML独有的

00:26:20.914 --> 00:26:24.418 align:middle line:-2
实际上 在大多数机器学习框架中
这是非常普遍的

00:26:24.751 --> 00:26:27.087 align:middle line:-1
这就是人们在新层中进行实验的方法

00:26:27.955 --> 00:26:30.624 align:middle line:-2
好的 到目前为止
我只有一个Keras模型

00:26:30.824 --> 00:26:33.660 align:middle line:-2
现在我想专注于
如何获得Core ML模型

00:26:34.361 --> 00:26:36.230 align:middle line:-1
所以我将打开…

00:26:38.131 --> 00:26:39.099 align:middle line:-1
让我们看看…

00:26:40.000 --> 00:26:42.336 align:middle line:-2
在这里 让我启动一个
新的Python笔记本

00:26:44.137 --> 00:26:46.874 align:middle line:-1
我将从在Python环境中

00:26:46.940 --> 00:26:48.242 align:middle line:-1
导入Keras模型开始

00:26:51.879 --> 00:26:54.248 align:middle line:-1
先导入Keras

00:26:55.315 --> 00:26:57.751 align:middle line:-1
再导入我们的Keras自定义层

00:26:58.285 --> 00:27:00.921 align:middle line:-1
现在我将在Keras中加载模型

00:26:58.285 --> 00:27:00.921 align:middle line:-1
现在我将在Keras中加载模型

00:27:02.689 --> 00:27:04.658 align:middle line:-1
这就是你如何加载Keras模型

00:27:05.526 --> 00:27:07.494 align:middle line:-1
你将该部分提供给模型

00:27:07.561 --> 00:27:10.030 align:middle line:-2
如果有一个自定义层
就把它传给这部分

00:27:10.998 --> 00:27:14.468 align:middle line:-2
好的 现在我们有了这个模型
让我们将其转换为Core ML

00:27:15.669 --> 00:27:17.638 align:middle line:-1
我要先导入coremltools

00:27:18.372 --> 00:27:19.373 align:middle line:-1
执行它

00:27:19.907 --> 00:27:22.476 align:middle line:-1
现在 正如我之前展示给你的那样

00:27:22.543 --> 00:27:25.679 align:middle line:-1
只需要调用一个函数来转换它

00:27:26.079 --> 00:27:27.114 align:middle line:-1
我们来试试

00:27:28.415 --> 00:27:32.085 align:middle line:-2
这是我的调用
正如预期的那样 我得到一个错误

00:27:33.520 --> 00:27:35.822 align:middle line:-2
Python喜欢抛出
这些冗长的错误信息

00:27:36.123 --> 00:27:40.027 align:middle line:-1
但是我们真正关心的是最后一行

00:27:40.427 --> 00:27:41.361 align:middle line:-1
让我…

00:27:46.733 --> 00:27:49.002 align:middle line:0
正如我们在这最后一行所看到的那样

00:27:49.269 --> 00:27:51.338 align:middle line:0
采样器层不受支持

00:27:51.839 --> 00:27:55.142 align:middle line:0
现在我们看看怎样才能解决这个问题

00:27:55.742 --> 00:27:57.778 align:middle line:-1
我关掉这些以便你可以看到

00:27:58.445 --> 00:28:00.948 align:middle line:-1
现在我稍微改一下我的转换器调用

00:27:58.445 --> 00:28:00.948 align:middle line:-1
现在我稍微改一下我的转换器调用

00:28:01.181 --> 00:28:03.050 align:middle line:-1
这是我的Core ML模型

00:28:06.019 --> 00:28:08.956 align:middle line:-1
现在我要传递一个额外的参数

00:28:09.223 --> 00:28:15.229 align:middle line:-2
它被称为
custom_convertions_functions

00:28:19.399 --> 00:28:20.801 align:middle line:-1
这是一个字典类型

00:28:21.401 --> 00:28:25.839 align:middle line:-2
它是从层的名称到一个
我稍后会定义的函数的映射

00:28:26.139 --> 00:28:27.774 align:middle line:-2
将其命名为
covert_grid_sampler

00:28:27.841 --> 00:28:30.511 align:middle line:-1
让我退后一步并解释这里发生的事情

00:28:30.577 --> 00:28:34.214 align:middle line:-1
转换器的工作方式是

00:28:34.281 --> 00:28:35.682 align:middle line:-1
它会遍历每个Keras层

00:28:36.817 --> 00:28:38.452 align:middle line:-1
先进入第一层

00:28:38.519 --> 00:28:40.754 align:middle line:-1
将其参数转换为Core ML

00:28:40.821 --> 00:28:43.857 align:middle line:-2
然后转到第二层继续转换它的参数
如此类推

00:28:44.625 --> 00:28:47.427 align:middle line:-2
当它碰到这个自定义层时
它不知道该怎么做

00:28:47.761 --> 00:28:51.398 align:middle line:-2
所以我传入的这个函数
convert_grid_sampler

00:28:51.965 --> 00:28:54.268 align:middle line:-1
将帮助我的转换器做到这一点

00:28:54.868 --> 00:28:57.171 align:middle line:-1
我们来看看这个函数长什么样

00:29:00.974 --> 00:29:01.975 align:middle line:-1
就是这个函数

00:29:02.843 --> 00:29:06.280 align:middle line:-2
这里有几行代码
但它所做的只有三件事

00:29:07.481 --> 00:29:11.318 align:middle line:-1
首先 它给出了一个类的名称

00:29:11.985 --> 00:29:13.353 align:middle line:-1
正如我们注意到的那样

00:29:13.420 --> 00:29:15.556 align:middle line:-1
该层的实现不在这里

00:29:15.889 --> 00:29:18.192 align:middle line:-1
实现将稍后在app中出现

00:29:18.725 --> 00:29:20.861 align:middle line:-1
它将被封装在一个类中

00:29:21.261 --> 00:29:24.431 align:middle line:-1
这是我们稍后将实现的类的名称

00:29:24.498 --> 00:29:27.768 align:middle line:-2
在转换过程中
我们只需要指定这个类名

00:29:28.068 --> 00:29:28.936 align:middle line:-1
就这么简单

00:29:29.136 --> 00:29:30.604 align:middle line:-1
然后设置其描述

00:29:30.804 --> 00:29:32.639 align:middle line:-1
你应该提供它

00:29:32.706 --> 00:29:34.541 align:middle line:-1
如果有其他人…

00:29:34.741 --> 00:29:38.278 align:middle line:-2
以便如果有人正在看你的模型
他们知道它是干什么的

00:29:39.246 --> 00:29:40.347 align:middle line:-1
第三件事基本上就是

00:29:40.414 --> 00:29:44.451 align:middle line:-2
将Keras层的任何参数
转换为Core ML

00:29:45.052 --> 00:29:47.221 align:middle line:-2
对于这个特定的层
它有两个参数

00:29:47.287 --> 00:29:51.091 align:middle line:-2
输出高度和输出权重
我只是把它转换成Core ML

00:29:51.792 --> 00:29:54.161 align:middle line:-1
如果你的自定义层没有任何参数

00:29:54.228 --> 00:29:57.631 align:middle line:-1
那么你不需要这样做

00:29:58.332 --> 00:30:01.401 align:middle line:-2
如果你的层有很多参数
它们都应该在这里

00:29:58.332 --> 00:30:01.401 align:middle line:-2
如果你的层有很多参数
它们都应该在这里

00:30:01.468 --> 00:30:05.072 align:middle line:-1
并且被封装在Core ML模型中

00:30:06.240 --> 00:30:08.509 align:middle line:-2
你可能已经注意到了
我在这里所做的一切

00:30:08.575 --> 00:30:11.478 align:middle line:-1
与你定义类的方式非常相似 对吗？

00:30:11.745 --> 00:30:13.614 align:middle line:-1
你给出一个类名 可能有一个描述

00:30:13.680 --> 00:30:16.817 align:middle line:-2
也许还有些参数
现在让我来执行它

00:30:19.853 --> 00:30:22.923 align:middle line:-1
现在我们看到转换进行得很顺利

00:30:25.692 --> 00:30:28.095 align:middle line:-1
让我……

00:30:28.929 --> 00:30:31.632 align:middle line:-1
不知道为什么 这里有点奇怪

00:30:35.769 --> 00:30:38.672 align:middle line:-1
如果你不介意 我把这些都删了

00:30:40.541 --> 00:30:42.409 align:middle line:-1
现在让我可视化这个模型

00:30:42.676 --> 00:30:47.147 align:middle line:-2
你可以简单的调用
Core ML Tools中的函数来做到这一点

00:30:47.581 --> 00:30:49.082 align:middle line:-2
这个函数叫
visualize_spec

00:30:50.751 --> 00:30:54.254 align:middle line:-1
这里你可以看到该模型的可视化效果

00:30:54.588 --> 00:30:58.458 align:middle line:-2
正如我们所看到的那样
这里是定位网络和一些层

00:30:58.792 --> 00:31:00.494 align:middle line:-1
这是我们的自定义层

00:30:58.792 --> 00:31:00.494 align:middle line:-1
这是我们的自定义层

00:31:00.561 --> 00:31:03.130 align:middle line:-2
如果我点击它
我可以看到它的参数

00:31:03.197 --> 00:31:05.699 align:middle line:-1
这是我给它的类名

00:31:06.700 --> 00:31:09.036 align:middle line:-1
这些是我设置的参数

00:31:10.037 --> 00:31:12.606 align:middle line:-2
可视化你的Core ML模型
总是一个好主意

00:31:13.240 --> 00:31:16.043 align:middle line:-1
在拖放之前 检查一下一切是否正常

00:31:17.277 --> 00:31:18.111 align:middle line:-1
好

00:31:19.613 --> 00:31:23.417 align:middle line:-2
不是这个笔记本
现在我要保存这个模型

00:31:31.158 --> 00:31:32.759 align:middle line:-1
现在我们来看看这个模型

00:31:34.094 --> 00:31:35.829 align:middle line:-1
让我关闭它

00:31:37.297 --> 00:31:38.298 align:middle line:-1
好的

00:31:42.669 --> 00:31:45.372 align:middle line:-1
让我导航到

00:31:46.807 --> 00:31:48.108 align:middle line:-1
这个目录

00:31:51.845 --> 00:31:54.348 align:middle line:-2
我的模型在这里
如果我点击并在Xcode中查看它

00:31:54.414 --> 00:31:58.352 align:middle line:-2
看看它是什么样的
我们可以看到它在这里有

00:31:59.119 --> 00:32:00.487 align:middle line:-1
一个自定义网格描述

00:31:59.119 --> 00:32:00.487 align:middle line:-1
一个自定义网格描述

00:32:01.522 --> 00:32:03.457 align:middle line:-1
让我们回到幻灯片

00:32:10.297 --> 00:32:14.768 align:middle line:-2
我们刚刚看到的是
只用几行简单的代码

00:32:14.835 --> 00:32:17.538 align:middle line:-2
我们就可以轻松将函数
转换为Core ML

00:32:17.804 --> 00:32:19.973 align:middle line:-2
这过程和你用TensorFlow
转换器或ONNX转换器

00:32:20.374 --> 00:32:23.944 align:middle line:-1
的过程几乎是一样的

00:32:25.245 --> 00:32:27.447 align:middle line:-1
左边是我们的模型

00:32:28.248 --> 00:32:30.083 align:middle line:-1
带参数的自定义层模型

00:32:30.484 --> 00:32:32.753 align:middle line:-1
当你将此模型拖放到Xcode中时

00:32:33.453 --> 00:32:36.023 align:middle line:-1
你需要在一个文件中提供该类的实现

00:32:36.423 --> 00:32:39.726 align:middle line:-2
比如gridSampler.swift
这就是这个文件的样子

00:32:40.260 --> 00:32:45.599 align:middle line:-1
这就是你的类 它有一个初始化函数

00:32:46.033 --> 00:32:47.100 align:middle line:-1
它将会

00:32:47.167 --> 00:32:50.103 align:middle line:-1
初始化模型中的任何参数

00:32:50.804 --> 00:32:52.840 align:middle line:-1
这个类的主要函数

00:32:54.741 --> 00:32:55.909 align:middle line:-1
是evaluate函数

00:32:58.111 --> 00:33:01.515 align:middle line:-1
这是该层需要执行的数学运算的

00:32:58.111 --> 00:33:01.515 align:middle line:-1
这是该层需要执行的数学运算的

00:33:01.582 --> 00:33:04.384 align:middle line:-1
真正实现部分

00:33:05.185 --> 00:33:06.320 align:middle line:-1
还有另一个函数也会被调用

00:33:06.386 --> 00:33:08.088 align:middle line:-2
这个outputShapes
(forInputShapes)函数

00:33:08.155 --> 00:33:10.891 align:middle line:-1
它会指定该层产生的

00:33:10.958 --> 00:33:12.159 align:middle line:-1
输出区域的大小

00:33:12.526 --> 00:33:16.296 align:middle line:-2
这有助于Core ML在加载时
分配缓冲区大小

00:33:16.930 --> 00:33:19.633 align:middle line:-1
以便你的app在运行时更高效

00:33:21.969 --> 00:33:26.507 align:middle line:-2
我们刚刚看到你将如何处理
神经网络中的一个新层

00:33:27.174 --> 00:33:30.177 align:middle line:-1
有一个非常类似于自定义层的概念

00:33:30.244 --> 00:33:32.513 align:middle line:-1
它被称为自定义模型

00:33:33.280 --> 00:33:36.750 align:middle line:-1
它们的原理差不多 但它更具通用性

00:33:37.217 --> 00:33:41.555 align:middle line:-2
对于自定义模型
你可以处理任何类型的网络

00:33:41.755 --> 00:33:44.858 align:middle line:-1
它不一定是一个神经网络

00:33:45.292 --> 00:33:48.662 align:middle line:-1
并且在整体上能给你更多的灵活性

00:33:50.564 --> 00:33:53.300 align:middle line:-2
让我总结一下这次演讲
我们看到…

00:33:54.601 --> 00:33:58.939 align:middle line:-2
Core ML Tools的
这个生态系统有多丰富

00:33:59.006 --> 00:34:00.340 align:middle line:-1
这对你们来说很棒

00:33:59.006 --> 00:34:00.340 align:middle line:-1
这对你们来说很棒

00:34:00.407 --> 00:34:03.810 align:middle line:-2
因为现在你有更多的选择
来获得Core ML模型

00:34:04.478 --> 00:34:06.747 align:middle line:-2
我们看到量化Core ML模型
是多么容易

00:34:08.215 --> 00:34:12.485 align:middle line:-1
我们还看到只需几行代码

00:34:13.920 --> 00:34:18.257 align:middle line:-2
我们就可以很轻松地在模型中
集成一个新的自定义层

00:34:20.726 --> 00:34:23.429 align:middle line:-2
你可以在我们的文档页面
找到更多信息

00:34:23.597 --> 00:34:25.632 align:middle line:-1
欢迎来实验室并与我们交谈

00:34:26.166 --> 00:34:27.201 align:middle line:-1
好的 谢谢
