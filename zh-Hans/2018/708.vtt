WEBVTT

00:00:17.017 --> 00:00:22.923 align:middle line:0
（Core ML新特性
第一部分）

00:00:27.261 --> 00:00:28.161 align:middle line:-1
早上好

00:00:28.762 --> 00:00:29.596 align:middle line:-1
欢迎大家

00:00:29.930 --> 00:00:32.131 align:middle line:-2
我是Michael
这次演讲的内容是关于

00:00:32.198 --> 00:00:33.967 align:middle line:-1
Core ML中的新特性

00:00:35.569 --> 00:00:40.707 align:middle line:-2
一年前推出的Core ML
能够大大简化

00:00:40.774 --> 00:00:44.044 align:middle line:-1
将机器学习模型整合到app中的过程

00:00:45.312 --> 00:00:48.415 align:middle line:-2
看到它在过去一年能被广泛使用
真是太棒了

00:00:49.883 --> 00:00:52.152 align:middle line:-1
我们希望它让能所有人思考

00:00:52.219 --> 00:00:57.791 align:middle line:-2
如果你的app有能力做到以下这些
你可以带来什么样的全新的体验

00:00:57.858 --> 00:01:00.894 align:middle line:-1
比如理解图片的内容

00:00:57.858 --> 00:01:00.894 align:middle line:-1
比如理解图片的内容

00:01:02.629 --> 00:01:06.099 align:middle line:-1
或者分析一些文本

00:01:06.166 --> 00:01:08.635 align:middle line:-2
（Cate 你的工作很优秀
继续努力！激励）

00:01:08.702 --> 00:01:13.740 align:middle line:-2
如果你的app可以理解音频或音乐
你可以做什么

00:01:15.242 --> 00:01:18.579 align:middle line:-1
或根据用户的动作解释用户的行为

00:01:19.913 --> 00:01:23.083 align:middle line:-1
甚至可以对其转换或生成新的内容

00:01:24.384 --> 00:01:28.455 align:middle line:-2
所有这些 以及更多其它的功能
现在都很容易实现

00:01:28.989 --> 00:01:31.225 align:middle line:-1
这是因为这种类型的功能

00:01:31.458 --> 00:01:33.460 align:middle line:-1
都可在Core ML模型中编码

00:01:35.095 --> 00:01:37.431 align:middle line:-1
现在 如果我们窥视其内部

00:01:37.998 --> 00:01:39.733 align:middle line:-1
我们可能会找到一个神经网络

00:01:40.067 --> 00:01:42.503 align:middle line:-1
集成树或其他的模型体系结构

00:01:43.637 --> 00:01:45.873 align:middle line:-1
它们可能有数百万个参数

00:01:45.939 --> 00:01:48.809 align:middle line:-1
其值是从大量的数据中学习到的

00:01:50.544 --> 00:01:53.580 align:middle line:-2
但是对于你来说
你可以专注于单个文件

00:01:54.281 --> 00:01:57.317 align:middle line:-1
你可以专注于它提供的功能

00:01:57.384 --> 00:02:01.455 align:middle line:-2
及其带来的体验
而不是那些实现细节

00:01:57.384 --> 00:02:01.455 align:middle line:-2
及其带来的体验
而不是那些实现细节

00:02:04.758 --> 00:02:06.894 align:middle line:0
将Core ML模型添加到
你的app中 非常简单

00:02:06.960 --> 00:02:09.896 align:middle line:0
只需将该文件添加到
你的Xcode项目即可

00:02:11.131 --> 00:02:14.968 align:middle line:0
Xcode会显示一个简单的视图

00:02:15.035 --> 00:02:18.939 align:middle line:0
根据其输入及输出来描述它的功能

00:02:20.073 --> 00:02:23.544 align:middle line:0
Xcode还能更进一步
为你生成一个接口

00:02:24.811 --> 00:02:27.748 align:middle line:-2
这样只需几行代码就可以
与这个模型交互

00:02:28.782 --> 00:02:30.250 align:middle line:-1
一行用来加载模型

00:02:31.318 --> 00:02:32.586 align:middle line:-1
一行进行预测

00:02:33.687 --> 00:02:36.857 align:middle line:-2
有时可以再加一行代码
来提取你感兴趣的特定输出

00:02:37.991 --> 00:02:40.694 align:middle line:-2
注意在某些情况下
你甚至不必编写这些代码

00:02:40.761 --> 00:02:43.764 align:middle line:-2
因为Core ML与我们的一些
更高级的API集成在一起

00:02:43.830 --> 00:02:47.434 align:middle line:-2
若你为它们提供Core ML模型
它会允许你自定义它们的行为

00:02:48.101 --> 00:02:51.839 align:middle line:-2
在Vision中 这通过
VNCoreMLRequest对象完成的

00:02:51.905 --> 00:02:53.574 align:middle line:-1
新Natural Language框架中

00:02:53.640 --> 00:02:56.677 align:middle line:-2
你可以从Core ML模型中
实例化一个MLModel

00:02:59.513 --> 00:03:01.014 align:middle line:-1
这即Core ML的简介

00:02:59.513 --> 00:03:01.014 align:middle line:-1
这即Core ML的简介

00:03:01.615 --> 00:03:03.183 align:middle line:-1
但我们这次要谈论有何新鲜东西

00:03:04.284 --> 00:03:07.788 align:middle line:-2
我们在过去的一年中
收到了很多来自你们的宝贵意见

00:03:07.855 --> 00:03:11.124 align:middle line:-2
并在Core ML 2中
重点关注这些改进

00:03:12.626 --> 00:03:15.028 align:middle line:-1
我们将分两次演讲讨论这些问题

00:03:15.696 --> 00:03:17.965 align:middle line:-2
在第一次演讲中
也就是现在这个演讲

00:03:18.031 --> 00:03:21.001 align:middle line:-2
我们将从你的app的角度
讨论有哪些新特性

00:03:21.835 --> 00:03:24.471 align:middle line:-2
在第二个演讲中
也就是等下经过短暂休息后

00:03:24.538 --> 00:03:26.640 align:middle line:-1
在上午10点开始的那个演讲

00:03:27.674 --> 00:03:29.109 align:middle line:-1
我们将讨论一些工具

00:03:29.176 --> 00:03:31.378 align:middle line:-1
以及如何更新和转换模型

00:03:31.445 --> 00:03:33.747 align:middle line:-2
来充分利用
Core ML 2中的新功能

00:03:36.884 --> 00:03:39.987 align:middle line:-2
当涉及到你的app时
我们将关注三个关键领域

00:03:40.687 --> 00:03:45.726 align:middle line:-2
首先是你如何在
保证获得同样功能的前提下

00:03:45.792 --> 00:03:47.694 align:middle line:-1
减小app中模型的大小和数量

00:03:48.862 --> 00:03:52.533 align:middle line:-2
然后 我们将看看
如何从单个模型中获得更好的性能

00:03:54.101 --> 00:03:56.670 align:middle line:-2
接着我们将总结
为什么使用Core ML

00:03:56.737 --> 00:03:58.906 align:middle line:-1
可以让你跟上发展迅速的

00:03:58.972 --> 00:04:01.341 align:middle line:-1
机器学习领域的最新进展

00:03:58.972 --> 00:04:01.341 align:middle line:-1
机器学习领域的最新进展

00:04:02.276 --> 00:04:04.511 align:middle line:-1
我们首先从讨论模型大小开始

00:04:04.578 --> 00:04:06.146 align:middle line:-2
我将把这个话题
交给Francesco

00:04:10.450 --> 00:04:11.351 align:middle line:-1
谢谢Michael

00:04:12.753 --> 00:04:13.587 align:middle line:-1
大家好

00:04:14.254 --> 00:04:18.091 align:middle line:-2
任何减小Core ML
app大小的方法都非常重要

00:04:18.591 --> 00:04:20.459 align:middle line:-2
我是Francesco
我将要介绍

00:04:20.527 --> 00:04:22.362 align:middle line:-1
量化和弹性形状

00:04:22.963 --> 00:04:26.366 align:middle line:-2
它们是在Core ML 2中
可帮助你减小app大小的两项新功能

00:04:28.235 --> 00:04:29.203 align:middle line:-1
所以…

00:04:29.269 --> 00:04:31.872 align:middle line:-2
Core ML是一种在设备上
运行的机器学习模型

00:04:33.607 --> 00:04:37.144 align:middle line:-2
与在云中运行app相比
它为你的app提供了四大优势

00:04:37.711 --> 00:04:38.545 align:middle line:-1
首先

00:04:38.912 --> 00:04:40.480 align:middle line:-1
用户隐私得到充分尊重

00:04:41.048 --> 00:04:43.116 align:middle line:-1
通过在设备上运行机器学习模型

00:04:43.851 --> 00:04:46.854 align:middle line:-2
我们保证数据
永远不会离开用户的设备

00:04:47.988 --> 00:04:50.824 align:middle line:-1
其次 它可以帮助你实现实时性能

00:04:52.025 --> 00:04:56.196 align:middle line:-2
Apple设备对运行
机器学习工作载荷非常高效

00:04:57.097 --> 00:05:00.434 align:middle line:-2
此外 你不必维护互联网服务器
并为其支付费用

00:04:57.097 --> 00:05:00.434 align:middle line:-2
此外 你不必维护互联网服务器
并为其支付费用

00:05:01.335 --> 00:05:05.005 align:middle line:-2
最后 Core ML的推理过程
随时随地可用

00:05:05.539 --> 00:05:07.241 align:middle line:-1
而不需考虑连接问题

00:05:07.941 --> 00:05:09.843 align:middle line:-1
所有这些好处都伴随着这个事实

00:05:10.077 --> 00:05:13.180 align:middle line:-2
即你现在需要将机器学习模型
存储在设备上

00:05:14.014 --> 00:05:17.751 align:middle line:0
如果机器学习模型很大
那么你可能会担心

00:05:17.818 --> 00:05:19.119 align:middle line:0
你的app的大小

00:05:19.786 --> 00:05:24.024 align:middle line:-2
假设你有一个很棒的app
它具有很多很酷的功能

00:05:24.391 --> 00:05:26.393 align:middle line:-1
你的用户非常喜欢这个app

00:05:26.860 --> 00:05:29.630 align:middle line:-1
现在你想利用设备上的机器学习

00:05:29.696 --> 00:05:31.999 align:middle line:-1
所提供的新机会

00:05:32.065 --> 00:05:34.368 align:middle line:-1
来为你的app添加超酷的新功能

00:05:34.902 --> 00:05:37.437 align:middle line:-2
那么你怎么做呢
你训练了一些Core ML模型

00:05:37.504 --> 00:05:38.772 align:middle line:-1
然后将它们添加到你的app中

00:05:39.773 --> 00:05:42.309 align:middle line:-1
这意味着 你的app变得更棒了

00:05:42.376 --> 00:05:43.977 align:middle line:-1
并且你的用户也更加开心

00:05:45.145 --> 00:05:46.680 align:middle line:-1
但其中一些用户可能会注意到

00:05:47.014 --> 00:05:49.349 align:middle line:-1
你的app大小有所增加

00:05:49.917 --> 00:05:52.152 align:middle line:-1
app在添加机器学习能力之后

00:05:52.219 --> 00:05:54.621 align:middle line:-1
变大数十或数百兆字节

00:05:54.688 --> 00:05:56.290 align:middle line:-1
并不罕见

00:05:57.491 --> 00:06:00.127 align:middle line:-2
随着你不断向app
添加越来越多的功能

00:05:57.491 --> 00:06:00.127 align:middle line:-2
随着你不断向app
添加越来越多的功能

00:06:00.928 --> 00:06:03.363 align:middle line:-1
你的app大小可能会失控

00:06:04.665 --> 00:06:06.667 align:middle line:-1
如果这些机器学习模型

00:06:06.967 --> 00:06:09.069 align:middle line:-1
正在支持你的app的某些附加功能

00:06:09.136 --> 00:06:11.004 align:middle line:-1
你首先可以做的是

00:06:11.638 --> 00:06:14.074 align:middle line:-2
就是将它们保存在
最初的app包之外

00:06:15.242 --> 00:06:17.878 align:middle line:-1
然后当用户使用这些附加功能时

00:06:17.945 --> 00:06:21.114 align:middle line:-2
你可以根据需要下载它们
并在设备上进行编译

00:06:21.782 --> 00:06:24.284 align:middle line:-2
因此在这种情况下
用户在开始时就很高兴

00:06:24.351 --> 00:06:26.887 align:middle line:-1
因为安装大小不变

00:06:27.221 --> 00:06:31.191 align:middle line:-2
但由于用户在你的app中下载
并使用了所有Core ML功能

00:06:31.959 --> 00:06:35.295 align:middle line:-1
最终你的app大小仍然很大

00:06:36.230 --> 00:06:38.732 align:middle line:-1
那么如果我们采用另一种方法

00:06:39.900 --> 00:06:41.368 align:middle line:-2
即缩小模型大小本身
来解决该问题

00:06:42.469 --> 00:06:44.605 align:middle line:-1
这不是更好吗？

00:06:46.306 --> 00:06:50.010 align:middle line:-2
如果我们在app内部自带模型
这会给我们一个更小的安装包

00:06:51.311 --> 00:06:52.980 align:middle line:-1
而如果我们按需下载模型

00:06:53.480 --> 00:06:56.183 align:middle line:-1
这可以带来更快 更小的下载文件

00:06:57.084 --> 00:07:00.587 align:middle line:-2
无论如何 你的app将有
更小的存储足迹

00:06:57.084 --> 00:07:00.587 align:middle line:-2
无论如何 你的app将有
更小的存储足迹

00:07:00.654 --> 00:07:03.891 align:middle line:-2
使用较少的存储空间
使你的app性能更好

00:07:03.957 --> 00:07:05.659 align:middle line:-1
也对整个系统大有所益

00:07:06.927 --> 00:07:09.863 align:middle line:-2
所以让我们看看如何将
Core ML app的大小

00:07:09.930 --> 00:07:11.932 align:middle line:-2
分解成更小的因素
来更好地解决这个问题

00:07:13.367 --> 00:07:14.801 align:middle line:-1
首先是模型的数量

00:07:14.868 --> 00:07:18.672 align:middle line:-2
这取决于你的app
有多少个机器学习功能

00:07:19.139 --> 00:07:20.707 align:middle line:-1
然后是权重的数量

00:07:21.441 --> 00:07:24.411 align:middle line:-2
权重的数量取决于
为了解决你的机器学习问题

00:07:24.478 --> 00:07:25.846 align:middle line:-1
你所选择的体系结构

00:07:26.513 --> 00:07:27.814 align:middle line:-1
如Michael提到的

00:07:28.882 --> 00:07:32.352 align:middle line:-1
权重是机器学习模型存储

00:07:32.719 --> 00:07:35.689 align:middle line:-1
它在训练期间所学习的信息的地方

00:07:36.290 --> 00:07:40.661 align:middle line:-2
因此如果它被训练
去完成一项复杂的任务

00:07:40.727 --> 00:07:43.864 align:middle line:-2
这样的一个模型需要数千万个权重
是很正常的

00:07:45.499 --> 00:07:47.167 align:middle line:-1
最后是每个权重的大小

00:07:47.367 --> 00:07:50.704 align:middle line:-2
我们如何存储我们在训练期间
学习的这些参数呢？

00:07:51.738 --> 00:07:53.240 align:middle line:-1
我们首先关注这个因素

00:07:54.441 --> 00:07:56.510 align:middle line:-1
对于神经网络 我们有几种选择

00:07:56.577 --> 00:07:58.245 align:middle line:-1
来表示和存储权重

00:07:59.947 --> 00:08:02.649 align:middle line:0
在iOS 11的
第一个Core ML版本中

00:07:59.947 --> 00:08:02.649 align:middle line:0
在iOS 11的
第一个Core ML版本中

00:08:03.450 --> 00:08:07.955 align:middle line:0
神经网络使用浮点32位权重存储

00:08:09.923 --> 00:08:12.893 align:middle line:0
在iOS 11.2中
我们采取了你们的建议

00:08:12.960 --> 00:08:16.396 align:middle line:0
并且引入了半精度浮点16位权重

00:08:16.630 --> 00:08:21.735 align:middle line:0
这在为app提供相同准确度的基础上
将存储空间缩减为原来的一半

00:08:22.236 --> 00:08:24.938 align:middle line:0
但今年 我们想更进一步

00:08:25.472 --> 00:08:27.574 align:middle line:0
我们推出了量化权重

00:08:28.575 --> 00:08:30.611 align:middle line:0
通过使用量化权重
我们不再受限于

00:08:30.677 --> 00:08:33.981 align:middle line:0
只能使用浮点32位或浮点16位值

00:08:34.047 --> 00:08:37.951 align:middle line:0
神经网络可以使用8位 4位

00:08:38.452 --> 00:08:40.621 align:middle line:0
一直到1位来进行编码

00:08:42.188 --> 00:08:45.325 align:middle line:-1
现在我们来看看这里的量化是什么

00:08:46.360 --> 00:08:50.097 align:middle line:-2
这里我们想要表示我们的
神经网络权重的一个子集

00:08:50.497 --> 00:08:54.635 align:middle line:-2
正如我们所看到的
这些权重可以在连续范围内取任何值

00:08:55.502 --> 00:08:58.038 align:middle line:-1
这意味着在理论上

00:08:58.105 --> 00:09:00.641 align:middle line:-1
每个权重的取值具有无限可能

00:08:58.105 --> 00:09:00.641 align:middle line:-1
每个权重的取值具有无限可能

00:09:01.041 --> 00:09:07.681 align:middle line:-2
因此在神经网络中
我们使用32位浮点数来存储权重

00:09:08.048 --> 00:09:10.784 align:middle line:-2
这意味着这个权重
可以表达数十亿种数值

00:09:10.851 --> 00:09:14.087 align:middle line:-1
以更好地表现它们的连续性

00:09:14.555 --> 00:09:18.926 align:middle line:-2
但事实上神经网络也可以
以较低精度权重工作

00:09:19.927 --> 00:09:24.064 align:middle line:-2
量化是将不连续值的取值限制在
其可能取值的子集的过程

00:09:24.464 --> 00:09:30.704 align:middle line:-1
这个子集非常小并且离散

00:09:31.171 --> 00:09:35.342 align:middle line:-2
例如 这里的量化过程
使这个连续的权重谱变成了

00:09:36.310 --> 00:09:39.213 align:middle line:-1
只有256个可能取值的子集

00:09:39.546 --> 00:09:43.016 align:middle line:-2
所以在量化之前
权重可以取任何可能的值

00:09:43.350 --> 00:09:46.987 align:middle line:-1
量化后 它们只有256种可能取值

00:09:47.955 --> 00:09:51.692 align:middle line:-2
现在 由于它的权重可以
从这个很小的子集中取得

00:09:52.559 --> 00:09:55.796 align:middle line:-2
因此Core ML现在只需要8位
即可存储权重信息

00:09:56.830 --> 00:10:00.267 align:middle line:-1
但还不止如此 我们可以走得更远

00:09:56.830 --> 00:10:00.267 align:middle line:-1
但还不止如此 我们可以走得更远

00:10:00.767 --> 00:10:04.171 align:middle line:-1
比如我们可以限制网络

00:10:04.238 --> 00:10:08.141 align:middle line:-1
只能取8种值 而不是256种

00:10:09.610 --> 00:10:11.845 align:middle line:-1
既然现在我们只有8种可能

00:10:12.513 --> 00:10:16.350 align:middle line:-2
Core ML中每个权重将需要
用3位值来存储你的模型

00:10:17.518 --> 00:10:18.919 align:middle line:-1
这里有一些细节

00:10:19.353 --> 00:10:21.154 align:middle line:-1
关于我们如何选择这些值

00:10:21.221 --> 00:10:22.489 align:middle line:-1
来表示其权重

00:10:22.756 --> 00:10:26.026 align:middle line:0
它们可以在取值范围内均匀分布

00:10:26.093 --> 00:10:28.295 align:middle line:0
在这种情况下 它是一个线性量化

00:10:29.296 --> 00:10:31.431 align:middle line:0
然而如果是查找表量化

00:10:33.333 --> 00:10:37.204 align:middle line:0
我们可以任意的方式
将这些可能取值分散在这个范围内

00:10:37.738 --> 00:10:42.009 align:middle line:0
现在我们来看看
量化如何帮助我们减小模型的大小

00:10:42.342 --> 00:10:44.912 align:middle line:-2
在这个例子中
我们关注的是Resnet50

00:10:45.212 --> 00:10:47.748 align:middle line:-2
这是许多app用来
执行许多不同的任务的

00:10:47.814 --> 00:10:49.016 align:middle line:-1
常见体系结构

00:10:49.983 --> 00:10:52.853 align:middle line:-1
它包含2500万个训练参数

00:10:53.587 --> 00:10:56.990 align:middle line:-2
这意味着如果你使用
32位浮点数来表示它

00:10:57.925 --> 00:11:00.694 align:middle line:-1
那么总模型大小超过100兆字节

00:10:57.925 --> 00:11:00.694 align:middle line:-1
那么总模型大小超过100兆字节

00:11:02.396 --> 00:11:06.133 align:middle line:-2
如果我们将它量化为8位
而架构没有发生改变

00:11:06.200 --> 00:11:09.002 align:middle line:-1
我们仍然有2500万个参数

00:11:09.503 --> 00:11:11.738 align:middle line:-1
但我们现在只使用一个字节

00:11:12.573 --> 00:11:13.974 align:middle line:-1
来存储单个权重

00:11:14.041 --> 00:11:16.977 align:middle line:-1
这意味着模型大小减少了4倍

00:11:17.277 --> 00:11:20.547 align:middle line:-2
现在只需要26兆字节
来存储这个模型

00:11:20.881 --> 00:11:22.249 align:middle line:-1
我们还可以更进一步

00:11:22.316 --> 00:11:24.051 align:middle line:-1
我们可以在这个模型中使用

00:11:24.117 --> 00:11:26.753 align:middle line:-1
4位来表示每个权重的量化表示

00:11:27.254 --> 00:11:29.223 align:middle line:-1
并最终得到一个更小的模型

00:11:36.463 --> 00:11:40.234 align:middle line:-1
Core ML支持所有的量化模式

00:11:40.300 --> 00:11:42.436 align:middle line:-1
直到只需1位

00:11:44.271 --> 00:11:45.105 align:middle line:-1
现在…

00:11:45.639 --> 00:11:47.508 align:middle line:-1
量化是一项强大的技术

00:11:47.975 --> 00:11:51.044 align:middle line:-2
它可以采取现有的体系结构
却具有更小的大小

00:11:51.345 --> 00:11:52.980 align:middle line:-1
但是你如何获得量化模型呢？

00:11:54.781 --> 00:11:58.151 align:middle line:-2
如果你有Core ML格式的
神经网络

00:11:58.218 --> 00:12:01.622 align:middle line:-2
你可以使用Core ML工具
来获得它的量化表示

00:11:58.218 --> 00:12:01.622 align:middle line:-2
你可以使用Core ML工具
来获得它的量化表示

00:12:01.688 --> 00:12:04.291 align:middle line:-1
Core ML工具会自动替你量化

00:12:05.492 --> 00:12:07.928 align:middle line:0
或者你可以直接训练量化模型

00:12:09.263 --> 00:12:11.732 align:middle line:0
你可以使用量化约束
从零开始进行量化训练

00:12:11.798 --> 00:12:15.402 align:middle line:0
或者用量化约束重新训练现有模型

00:12:16.403 --> 00:12:17.971 align:middle line:-1
在你获得量化模型和训练工具后

00:12:18.038 --> 00:12:19.973 align:middle line:-1
你可以像平常一样

00:12:20.040 --> 00:12:21.608 align:middle line:-1
将其转换为Core ML

00:12:22.209 --> 00:12:25.012 align:middle line:-2
在app中
使用模型的方式不会改变

00:12:25.579 --> 00:12:27.447 align:middle line:-1
在模型中

00:12:27.514 --> 00:12:29.483 align:middle line:-1
数字将以不同的精度进行存储

00:12:29.550 --> 00:12:33.120 align:middle line:-1
但使用该模型的接口完全不会改变

00:12:35.489 --> 00:12:38.559 align:middle line:-2
但我们总是需要考虑到
量化模型

00:12:38.959 --> 00:12:40.727 align:middle line:-1
只是原始浮点模型的

00:12:40.794 --> 00:12:43.597 align:middle line:-1
较低精度的近似

00:12:44.231 --> 00:12:45.933 align:middle line:-1
这意味着量化模型

00:12:45.999 --> 00:12:48.902 align:middle line:-1
具有精确性与模型大小的折衷

00:12:49.703 --> 00:12:53.073 align:middle line:-1
这种折衷取决于模型和用例

00:12:53.740 --> 00:12:55.943 align:middle line:-1
这也是一个非常活跃的研究领域

00:12:56.410 --> 00:12:59.613 align:middle line:-1
因此总是建议检查量化模型的准确性

00:13:00.047 --> 00:13:03.417 align:middle line:-1
并将其与原来的浮点数版本进行比较

00:13:04.017 --> 00:13:07.855 align:middle line:0
你应在检查中使用相关的测试数据
以及适用于你的app和用例的指标

00:13:08.956 --> 00:13:11.792 align:middle line:-1
现在让我们看一个如何采用量化模型

00:13:12.259 --> 00:13:15.062 align:middle line:-1
来减小app大小的演示

00:13:25.172 --> 00:13:27.174 align:middle line:-1
我想向你展示一款风格转换app

00:13:28.075 --> 00:13:32.579 align:middle line:-2
在风格转换app中 有一个训练好的
神经网络被用来渲染用户图像

00:13:32.646 --> 00:13:36.149 align:middle line:-2
该网络使用通过观看绘画或其他图像
学习到的风格来对用户的图像渲染

00:13:36.550 --> 00:13:37.618 align:middle line:-1
首先加载app

00:13:39.186 --> 00:13:40.287 align:middle line:-1
我们可以看到

00:13:40.587 --> 00:13:42.656 align:middle line:-1
我的app中内置了四种风格

00:13:42.723 --> 00:13:45.259 align:middle line:-1
城市 玻璃 油画和波浪

00:13:45.626 --> 00:13:49.296 align:middle line:-2
然后我可以从用户的照片库中
选择图片

00:13:49.863 --> 00:13:53.400 align:middle line:-2
然后通过在设备上
以不同风格渲染来处理它们

00:13:53.934 --> 00:13:57.838 align:middle line:-2
这是原始图像
我将其渲染为城市风格

00:13:59.940 --> 00:14:01.008 align:middle line:-1
玻璃风格

00:13:59.940 --> 00:14:01.008 align:middle line:-1
玻璃风格

00:14:02.309 --> 00:14:03.143 align:middle line:-1
油画风格

00:14:04.845 --> 00:14:05.679 align:middle line:-1
和波浪风格

00:14:07.414 --> 00:14:09.583 align:middle line:-2
看看该app
是如何在Xcode中构建的

00:14:10.951 --> 00:14:15.422 align:middle line:-2
这个app使用Core ML
和Vision API执行这种风格化

00:14:16.223 --> 00:14:19.993 align:middle line:-2
如我们所见 我们在Xcode中
捆绑了四个Core ML模型

00:14:20.360 --> 00:14:23.497 align:middle line:-2
城市、玻璃、油画和波浪
与我们在app中看到的一样

00:14:24.431 --> 00:14:28.335 align:middle line:-2
我们可以检视这个模型
这些仍然是未经量化的模型

00:14:28.402 --> 00:14:31.905 align:middle line:-2
所以这些模型中的每一个
都占用6.7兆字节的磁盘空间

00:14:33.040 --> 00:14:35.843 align:middle line:-2
我们看到模型的输入
是特定分辨率的图像

00:14:36.543 --> 00:14:39.813 align:middle line:-2
并生成一个名为Stylized的
相同分辨率的的图像

00:14:40.981 --> 00:14:45.052 align:middle line:-2
现在我们想知道
我们可以通过切换为量化模型

00:14:45.118 --> 00:14:48.255 align:middle line:-1
节省多少存储空间和内存空间

00:14:48.622 --> 00:14:50.457 align:middle line:-2
我已使用
Core ML Tools

00:14:51.525 --> 00:14:55.395 align:middle line:-1
获得了所有这些模型的量化表示

00:14:56.163 --> 00:14:58.599 align:middle line:-1
有关如何获取这些模型的教程

00:14:58.999 --> 00:15:03.403 align:middle line:-2
参见稍后第二部分 其将详细介绍
Core ML Tools的量化过程细节

00:14:58.999 --> 00:15:03.403 align:middle line:-2
参见稍后第二部分 其将详细介绍
Core ML Tools的量化过程细节

00:15:04.104 --> 00:15:06.173 align:middle line:-1
我想先关注玻璃风格

00:15:06.874 --> 00:15:09.576 align:middle line:-1
并查看不同的量化版本

00:15:09.643 --> 00:15:10.911 align:middle line:-1
对这些风格的效果影响如何

00:15:11.845 --> 00:15:15.782 align:middle line:-2
我所要做的就是
将这些新模型拖入Xcode项目中

00:15:17.951 --> 00:15:20.921 align:middle line:-2
并重新运行该app
然后我们再看看这些模型的表现

00:15:22.523 --> 00:15:25.826 align:middle line:-2
首先我们可以看到app大小
现在大幅缩小了

00:15:25.893 --> 00:15:29.997 align:middle line:-2
例如 8位版本已经
从原来的6.7兆字节

00:15:30.063 --> 00:15:31.665 align:middle line:0
缩小到1.7兆字节

00:15:37.037 --> 00:15:39.306 align:middle line:-1
在4位版本中 我们可以节省更多

00:15:39.373 --> 00:15:41.441 align:middle line:-1
现在模型少于1兆字节

00:15:41.875 --> 00:15:46.046 align:middle line:-2
在3位版本中 它是649千字节
等等

00:15:46.980 --> 00:15:48.749 align:middle line:-1
现在让我们回到app

00:15:51.151 --> 00:15:53.287 align:middle line:-1
让我们选择相同的图像作为参考

00:15:53.520 --> 00:15:56.390 align:middle line:-1
并在原始版本中应用玻璃风格

00:15:57.124 --> 00:15:58.325 align:middle line:-1
仍然像以前一样

00:15:58.959 --> 00:16:01.762 align:middle line:-2
现在我们可以将它
与8位版本进行比较

00:15:58.959 --> 00:16:01.762 align:middle line:-2
现在我们可以将它
与8位版本进行比较

00:16:04.331 --> 00:16:06.366 align:middle line:-1
你可以看到没有任何改变

00:16:06.767 --> 00:16:09.670 align:middle line:-1
这是因为8位量化方法非常稳定

00:16:10.771 --> 00:16:15.375 align:middle line:-2
我们还可以进一步尝试
这种模型的4位版本

00:16:16.944 --> 00:16:18.612 align:middle line:-1
哇 结果仍然很好

00:16:20.180 --> 00:16:21.982 align:middle line:-1
现在让我们试试3位版本

00:16:24.852 --> 00:16:27.621 align:middle line:-1
我们看到第一次颜色偏移

00:16:27.688 --> 00:16:30.190 align:middle line:-1
因此 我们最好去和设计师核对一下

00:16:30.257 --> 00:16:32.526 align:middle line:-1
这种效果是否仍然可以接受

00:16:33.227 --> 00:16:35.128 align:middle line:-1
现在 当我们看到2位版本时

00:16:36.330 --> 00:16:37.865 align:middle line:-1
这不是我们所期待的

00:16:37.931 --> 00:16:39.700 align:middle line:-1
也许我们会将它保存为一恐怖app

00:16:39.766 --> 00:16:41.602 align:middle line:-1
但我不打算向设计师展示这个

00:16:46.473 --> 00:16:48.675 align:middle line:-1
让我们回到4位版本并隐藏这个版本

00:16:49.142 --> 00:16:51.945 align:middle line:-1
这只是在提醒我们

00:16:52.513 --> 00:16:54.515 align:middle line:-1
量化模型是原始模型的一个近似

00:16:55.182 --> 00:16:58.752 align:middle line:-2
因此你最好检查它们
并与原始版本进行比较

00:16:59.052 --> 00:17:01.755 align:middle line:-1
现在 对于每种模型和量化技术

00:16:59.052 --> 00:17:01.755 align:middle line:-1
现在 对于每种模型和量化技术

00:17:01.822 --> 00:17:04.391 align:middle line:-1
事情总会从某点开始变得不太匹配

00:17:06.492 --> 00:17:08.962 align:middle line:-1
在与设计师进行了一些讨论

00:17:09.029 --> 00:17:12.332 align:middle line:-2
并对许多图像进行了广泛的评估之后
我们决定发布

00:17:12.398 --> 00:17:15.702 align:middle line:-2
这个模型的4位版本
这是最好的质量中的最小尺寸

00:17:16.936 --> 00:17:19.406 align:middle line:-1
让我们删除app中占了大量空间的

00:17:19.473 --> 00:17:22.442 align:middle line:-1
所有的浮点版本模型

00:17:23.443 --> 00:17:26.113 align:middle line:-1
并将其替换为4位版本

00:17:31.018 --> 00:17:33.120 align:middle line:-1
现在让我们最后一次运行app

00:17:40.427 --> 00:17:42.095 align:middle line:-1
我们再次选择相同的图像

00:17:45.132 --> 00:17:46.333 align:middle line:-1
并显示所有风格

00:17:48.702 --> 00:17:49.703 align:middle line:-1
这是这个城市风格

00:17:50.838 --> 00:17:51.672 align:middle line:-1
玻璃风格

00:17:53.740 --> 00:17:54.575 align:middle line:-1
油画风格

00:17:56.310 --> 00:17:57.177 align:middle line:-1
和大波浪风格

00:18:00.214 --> 00:18:05.185 align:middle line:-2
在这个演示中
我们从四个庞大的32位模型开始

00:18:05.252 --> 00:18:08.856 align:middle line:-1
其总app大小为27兆字节

00:18:09.389 --> 00:18:12.659 align:middle line:-1
然后我们评估质量并切换到4位模型

00:18:12.993 --> 00:18:16.563 align:middle line:-2
我们app的总大小一路降到
只有3.4兆字节

00:18:17.598 --> 00:18:18.432 align:middle line:-1
现在…

00:18:23.136 --> 00:18:25.639 align:middle line:-1
这在质量方面没有任何缩水

00:18:26.139 --> 00:18:30.110 align:middle line:-2
因为所有这些量化版本
看起来都是一样的

00:18:30.177 --> 00:18:32.145 align:middle line:-1
质量仍然令人满意

00:18:34.481 --> 00:18:37.885 align:middle line:-2
我们看到了量化如何
通过在微观层面减少权重的大小

00:18:37.951 --> 00:18:41.121 align:middle line:-1
来帮助我们缩小app的大小

00:18:42.089 --> 00:18:46.226 align:middle line:-2
现在让我们看看
如何减少app需要的模型数量

00:18:47.728 --> 00:18:49.363 align:middle line:-1
在最简单的情况下

00:18:50.063 --> 00:18:53.233 align:middle line:-1
如果你的app有三种机器学习功能

00:18:53.300 --> 00:18:55.602 align:middle line:-1
那么你需要三种不同的机器学习模型

00:18:56.036 --> 00:19:01.341 align:middle line:-2
但在某些情况下
有可能使用同一个模型

00:18:56.036 --> 00:19:01.341 align:middle line:-2
但在某些情况下
有可能使用同一个模型

00:19:01.408 --> 00:19:03.744 align:middle line:-1
来支持两种不同的功能

00:19:04.378 --> 00:19:07.080 align:middle line:-1
例如 你可以训练一个多任务模型

00:19:07.514 --> 00:19:11.685 align:middle line:-2
多任务模型被训练成
一次执行多项任务

00:19:12.352 --> 00:19:14.121 align:middle line:-2
Turi Create演讲中
有个关于风格转换的例子

00:19:14.188 --> 00:19:16.356 align:middle line:-1
涉及到多任务模型

00:19:16.823 --> 00:19:18.325 align:middle line:-1
或者 在某些情况下

00:19:18.692 --> 00:19:21.061 align:middle line:-1
你可以在Core ML中使用一个

00:19:21.128 --> 00:19:23.063 align:middle line:-1
被称为“弹性形状和尺寸”的新特性

00:19:24.298 --> 00:19:27.801 align:middle line:0
让我们回到风格转换演示

00:19:28.135 --> 00:19:32.339 align:middle line:0
在Xcode中
我们看到输入图像和输出图像的大小

00:19:32.840 --> 00:19:36.076 align:middle line:0
被编码到模型的部分定义中

00:19:36.777 --> 00:19:40.414 align:middle line:0
但如果我们想在不同的图像分辨率下
运行相同的风格呢？

00:19:41.014 --> 00:19:45.385 align:middle line:0
如果我们想在不同的图像尺寸上
运行相同的网络 该怎么办？

00:19:46.787 --> 00:19:47.821 align:middle line:-1
例如

00:19:48.121 --> 00:19:51.258 align:middle line:-2
用户可能希望看到
高清版本的风格转换

00:19:51.792 --> 00:19:55.095 align:middle line:-1
所以他们给我们一个高清图像

00:19:55.596 --> 00:19:59.233 align:middle line:-2
现在如果我们的Core ML模型
仅以较低的分辨率作为输入

00:20:00.000 --> 00:20:05.472 align:middle line:-2
作为开发者我们能做的只有
缩小图片的尺寸 处理它

00:20:06.106 --> 00:20:10.410 align:middle line:-2
然后再将其放大
这实际上并不会让用户感到满意

00:20:11.778 --> 00:20:13.113 align:middle line:-1
即便在过去

00:20:14.014 --> 00:20:16.917 align:middle line:-2
我们也可使用Corel ML Tools
重新安装此模型

00:20:16.984 --> 00:20:18.819 align:middle line:-1
并让它接受任何分辨率的图像

00:20:19.486 --> 00:20:21.889 align:middle line:-1
特别是高分辨率图像

00:20:23.223 --> 00:20:27.027 align:middle line:-2
因此即使在过去
我们也可以实现此功能

00:20:27.094 --> 00:20:29.596 align:middle line:-2
并将高分辨率图像
直接传给Corel ML模型

00:20:29.830 --> 00:20:31.798 align:middle line:-1
然后产生一个高分辨率的结果

00:20:33.534 --> 00:20:37.037 align:middle line:-2
这是因为我们想要在风格化中
引入更精细的细节

00:20:37.104 --> 00:20:41.708 align:middle line:-2
并有更精细的笔触
使得放大时的效果非常好

00:20:41.775 --> 00:20:44.645 align:middle line:-2
因为它们在最终图像中
进行了大量的工作

00:20:46.513 --> 00:20:49.416 align:middle line:-2
过去我们的确可以做到
但我们使用的方式是

00:20:49.483 --> 00:20:52.753 align:middle line:-1
复制模型并创建两个不同的版本

00:20:53.053 --> 00:20:56.089 align:middle line:-2
一个用于标准画质
一个用于高清画质

00:20:56.490 --> 00:21:00.327 align:middle line:-2
这当然意味着我们的app大小
变为原来的两倍

00:20:56.490 --> 00:21:00.327 align:middle line:-2
这当然意味着我们的app大小
变为原来的两倍

00:21:00.394 --> 00:21:01.695 align:middle line:-1
尽管这个网络

00:21:01.762 --> 00:21:03.830 align:middle line:-1
是被训练为处理任何分辨率的

00:21:04.498 --> 00:21:07.401 align:middle line:-2
现在不再是这样了
我们推出了弹性形状

00:21:07.768 --> 00:21:11.505 align:middle line:-2
通过使用弹性形状
你可以用单一的模型

00:21:11.772 --> 00:21:14.508 align:middle line:-1
来处理更多的分辨率种类

00:21:15.609 --> 00:21:16.743 align:middle line:-1
现在在Xcode中…

00:21:21.348 --> 00:21:23.517 align:middle line:-1
在Xcode中 你会看到

00:21:24.284 --> 00:21:26.687 align:middle line:-1
输入仍然是图像

00:21:27.187 --> 00:21:31.959 align:middle line:-2
但除了默认分辨率
模型也接受弹性分辨率

00:21:32.025 --> 00:21:35.362 align:middle line:-2
在这个简单的例子中
它们分别是标清和高清

00:21:36.330 --> 00:21:38.832 align:middle line:0
这意味着现在你只需安装一个模型

00:21:40.400 --> 00:21:42.302 align:middle line:0
你不必写任何冗余代码

00:21:43.270 --> 00:21:46.306 align:middle line:0
如果你需要在标清和高清之间切换

00:21:46.373 --> 00:21:48.408 align:middle line:0
其速度非常快 因为我们不需要

00:21:48.475 --> 00:21:51.044 align:middle line:0
重新加载模型
我们只需要调整它的大小

00:21:52.513 --> 00:21:55.716 align:middle line:-1
你有两种方法来指定模型的弹性

00:21:56.984 --> 00:21:59.286 align:middle line:-1
你可以为其维度定义一个范围

00:21:59.586 --> 00:22:01.722 align:middle line:-1
你可以定义一个最小的宽度和高度

00:21:59.586 --> 00:22:01.722 align:middle line:-1
你可以定义一个最小的宽度和高度

00:22:01.788 --> 00:22:03.156 align:middle line:-1
以及一个最大的宽度和高度

00:22:03.590 --> 00:22:06.193 align:middle line:-2
然后在推理过程中
使用两者之间的任何值

00:22:07.094 --> 00:22:08.295 align:middle line:-1
但也有另一种方法

00:22:08.562 --> 00:22:11.365 align:middle line:-1
你可以枚举你要使用的所有形状

00:22:11.732 --> 00:22:13.934 align:middle line:-1
例如 所有不同的宽高比

00:22:14.001 --> 00:22:17.304 align:middle line:-2
所有不同的分辨率
这样做的性能会更好

00:22:17.704 --> 00:22:20.174 align:middle line:-1
Core ML更早地了解你的用例

00:22:20.541 --> 00:22:24.111 align:middle line:-1
因此它有机会进行更多的优化

00:22:24.978 --> 00:22:27.814 align:middle line:-1
这也为你的app提供了更小的测试面

00:22:29.249 --> 00:22:30.884 align:middle line:-1
那哪些模型是弹性的呢？

00:22:30.951 --> 00:22:34.655 align:middle line:-2
哪些模型能被训练
以支持多种分辨率呢？

00:22:36.223 --> 00:22:40.827 align:middle line:-2
完全卷积神经网络
通常用于图像处理任务

00:22:40.894 --> 00:22:45.499 align:middle line:-2
如风格转换 图像增强
超分辨率等等

00:22:45.999 --> 00:22:47.935 align:middle line:-1
它还被用来实现一些对象检测架构

00:22:48.402 --> 00:22:52.806 align:middle line:-2
Core ML工具可以替
你检查模型是否具备此功能

00:22:54.208 --> 00:22:57.778 align:middle line:-2
我们看到了如何使用弹性大小
来减少模型的数量

00:22:57.845 --> 00:23:00.380 align:middle line:-1
以及权重的大小可以通过量化来缩小

00:22:57.845 --> 00:23:00.380 align:middle line:-1
以及权重的大小可以通过量化来缩小

00:23:00.647 --> 00:23:02.249 align:middle line:-1
那权重的数量呢？

00:23:03.183 --> 00:23:04.017 align:middle line:-1
Core ML

00:23:04.484 --> 00:23:05.886 align:middle line:-1
考虑到它支持

00:23:05.953 --> 00:23:08.422 align:middle line:-1
许多不同的架构和训练框架

00:23:08.922 --> 00:23:12.860 align:middle line:-1
它一直帮助你为你的机器学习问题

00:23:12.926 --> 00:23:14.161 align:middle line:-1
选择合适大小的模型

00:23:14.595 --> 00:23:18.098 align:middle line:-2
因此 Core ML可以同时使用
这三种因素

00:23:18.432 --> 00:23:21.134 align:middle line:-1
来帮助你解决你的app大小的问题

00:23:21.502 --> 00:23:24.204 align:middle line:-2
在任何情况下
推理都将是超高性能的

00:23:24.738 --> 00:23:28.041 align:middle line:-2
为了介绍在性能和定制化中
引入的新功能

00:23:28.108 --> 00:23:30.210 align:middle line:-2
让我们欢迎Bill March
谢谢

00:23:37.951 --> 00:23:38.785 align:middle line:-1
谢谢

00:23:39.786 --> 00:23:43.190 align:middle line:-2
Core ML
最初的基本设计原则之一

00:23:43.257 --> 00:23:46.426 align:middle line:-2
就是它应该为你的app
提供可能的最佳性能

00:23:46.727 --> 00:23:50.163 align:middle line:-2
为了达到这个目标 我想强调一下
Core ML的一个新特性

00:23:50.230 --> 00:23:53.500 align:middle line:-2
以帮助你的app能够
在任何Apple设备上表现耀眼

00:23:54.801 --> 00:23:56.703 align:middle line:-2
我们来看看
Francesco向我们展示的

00:23:56.770 --> 00:23:58.238 align:middle line:-1
风格转换示例

00:23:58.305 --> 00:23:59.606 align:middle line:-1
从你的app的角度来看

00:24:00.040 --> 00:24:03.911 align:middle line:-2
它需要一个输入的图像
并简单地返回风格化的图像

00:24:04.344 --> 00:24:07.047 align:middle line:-1
有两个关键组件可以实现这一点

00:24:07.414 --> 00:24:11.618 align:middle line:-2
第一个是MLModel文件
它存储了

00:24:11.685 --> 00:24:13.053 align:middle line:-1
应用此风格所需的特定参数

00:24:13.453 --> 00:24:15.656 align:middle line:-1
第二个是推理引擎

00:24:15.722 --> 00:24:18.058 align:middle line:-1
它摄入MLModel和图像

00:24:18.125 --> 00:24:21.061 align:middle line:-1
并执行必要的计算以生成结果

00:24:21.862 --> 00:24:24.464 align:middle line:-1
让我们来看看这个推理引擎的底层

00:24:24.531 --> 00:24:28.502 align:middle line:-2
以及我们如何利用Apple
提供的技术高效地执行这种风格转换

00:24:30.170 --> 00:24:32.439 align:middle line:-1
这个模型是一个神经网络的例子

00:24:32.506 --> 00:24:35.976 align:middle line:-1
它由一系列称为层的数学运算组成

00:24:36.376 --> 00:24:39.179 align:middle line:-1
每个层都会对图像进行一些转换

00:24:39.246 --> 00:24:41.748 align:middle line:-1
最终产生风格化输出

00:24:42.616 --> 00:24:45.352 align:middle line:-1
模型存储了每个层的权重

00:24:45.419 --> 00:24:48.622 align:middle line:-2
这些权重决定了特定的转换
以及我们将要应用的风格

00:24:49.523 --> 00:24:51.558 align:middle line:-1
Core ML神经网络推理引擎

00:24:51.625 --> 00:24:54.862 align:middle line:-2
为这些层中的每一层
都进行了高度优化的实现

00:24:55.128 --> 00:24:57.364 align:middle line:-1
在GPU上 我们使用MTL着色器

00:24:57.431 --> 00:25:00.767 align:middle line:-2
在CPU上 我们可以使用
Accelerate进行有效计算

00:24:57.431 --> 00:25:00.767 align:middle line:-2
在CPU上 我们可以使用
Accelerate进行有效计算

00:25:01.301 --> 00:25:03.637 align:middle line:-2
并且我们可以进行调度
以将计算的不同部分

00:25:03.704 --> 00:25:07.074 align:middle line:-1
根据模型 设备状态和其它因素

00:25:07.140 --> 00:25:09.176 align:middle line:-1
动态地分配给不同的硬件

00:25:11.144 --> 00:25:14.281 align:middle line:-2
我们也可以找到
融合网络中的层的机会

00:25:14.348 --> 00:25:17.284 align:middle line:-1
这会减少所需的整体计算

00:25:18.785 --> 00:25:22.122 align:middle line:-2
我们能够在这里进行优化
因为我们知道发生了什么

00:25:22.189 --> 00:25:23.824 align:middle line:-1
我们知道模型的细节

00:25:23.891 --> 00:25:26.760 align:middle line:-2
它们包含在你提供给我们的
MLModel文件中

00:25:26.827 --> 00:25:30.063 align:middle line:-1
我们知道推理引擎和设备的细节

00:25:30.130 --> 00:25:31.231 align:middle line:-1
因为我们设计了它们

00:25:32.299 --> 00:25:35.369 align:middle line:-1
我们可以为你处理所有这些优化

00:25:35.435 --> 00:25:38.872 align:middle line:-2
以使你可以专注于
在你的app中提供最佳的用户体验

00:25:40.274 --> 00:25:41.708 align:middle line:-1
但是你的工作载荷呢？

00:25:42.409 --> 00:25:46.313 align:middle line:-2
特别是 如果你需要进行多重预测
那该怎么办呢？

00:25:47.147 --> 00:25:50.684 align:middle line:-2
如果Core ML不知道它
Core ML就无法对其进行优化

00:25:51.485 --> 00:25:54.288 align:middle line:-2
因此在过去
如果你有这样的工作载荷

00:25:55.455 --> 00:25:57.157 align:middle line:-1
你需要做这样的事情：

00:25:57.224 --> 00:26:01.562 align:middle line:-2
一个简单的for循环 环绕着
对现有Core ML的prediction API的调用

00:25:57.224 --> 00:26:01.562 align:middle line:-2
一个简单的for循环 环绕着
对现有Core ML的prediction API的调用

00:26:01.762 --> 00:26:05.499 align:middle line:-2
你可以遍历一个输入数组
并产生一个输出数组

00:26:06.834 --> 00:26:11.371 align:middle line:-2
让我们仔细看看
我们这样做时底层所发生的情况

00:26:12.139 --> 00:26:15.409 align:middle line:-2
对于每张图片
我们都需要做一些预处理工作

00:26:15.642 --> 00:26:18.378 align:middle line:-2
如果没有别的要做了
我们需要将数据发送到GPU

00:26:19.046 --> 00:26:21.415 align:middle line:-2
一旦我们完成这些
我们就可以进行计算

00:26:21.481 --> 00:26:24.785 align:middle line:-2
并生成输出图像
但接下来有一个后处理步骤

00:26:25.085 --> 00:26:28.555 align:middle line:-2
我们需要从GPU中拿回数据
并将其返回给你的app

00:26:29.823 --> 00:26:31.725 align:middle line:-1
改善这张图片的关键

00:26:31.792 --> 00:26:34.528 align:middle line:0
是消除GPU管道中的气泡

00:26:35.829 --> 00:26:38.866 align:middle line:0
出于两个主要原因
这将导致更高的性能

00:26:38.932 --> 00:26:41.602 align:middle line:0
首先 由于GPU不曾空闲

00:26:41.668 --> 00:26:43.637 align:middle line:0
整体计算时间得到了缩短

00:26:44.037 --> 00:26:47.608 align:middle line:0
第二 由于GPU持续工作

00:26:47.674 --> 00:26:50.310 align:middle line:0
它能够以更高的性能状态运行

00:26:50.377 --> 00:26:54.348 align:middle line:0
并减少计算每个特定输出所需的时间

00:26:55.582 --> 00:26:58.218 align:middle line:0
但Core ML的魅力在于
你不必关心

00:26:58.285 --> 00:27:01.822 align:middle line:0
这其中的任何细节
事实上 在你的app中

00:26:58.285 --> 00:27:01.822 align:middle line:0
这其中的任何细节
事实上 在你的app中

00:27:01.889 --> 00:27:03.524 align:middle line:-1
你需要关心的仅仅是

00:27:03.924 --> 00:27:07.060 align:middle line:-1
用户得到结果的时间变短了

00:27:07.728 --> 00:27:11.198 align:middle line:-2
所以今年我们推出了
一个新的批处理API

00:27:11.265 --> 00:27:13.100 align:middle line:-1
可以让你做到这一点

00:27:14.067 --> 00:27:15.969 align:middle line:-1
之前你需要循环遍历输入

00:27:16.036 --> 00:27:19.273 align:middle line:-2
并调用它们各自的预测
然而新的API非常简单

00:27:20.407 --> 00:27:22.276 align:middle line:-1
单行预测代码

00:27:22.342 --> 00:27:26.847 align:middle line:-2
它会摄入一个输入数组
并产生一个输出数组

00:27:26.914 --> 00:27:28.515 align:middle line:-1
Core ML将负责其余部分

00:27:34.721 --> 00:27:35.889 align:middle line:-1
让我们看看它的实践

00:27:36.423 --> 00:27:39.626 align:middle line:-1
继续我们的风格转换示例

00:27:39.693 --> 00:27:42.095 align:middle line:-1
让我们看看我们想要为整个照片库

00:27:42.162 --> 00:27:44.998 align:middle line:-2
应用风格转换的情况
这里我有一个简单的app

00:27:45.065 --> 00:27:49.169 align:middle line:-2
就是用来做这件事的
我打算将风格应用于200张图片

00:27:49.236 --> 00:27:51.505 align:middle line:-1
在左边 你们的左边

00:27:51.939 --> 00:27:55.809 align:middle line:-2
这是在for循环中
使用去年的API的实现

00:27:55.876 --> 00:27:58.478 align:middle line:-2
在右侧
则是我们新的批处理API

00:27:58.545 --> 00:27:59.513 align:middle line:-1
让我们开始吧

00:28:00.414 --> 00:28:01.315 align:middle line:-1
我们开始了

00:28:03.784 --> 00:28:05.319 align:middle line:-1
我们可以看到新API已完成

00:28:05.719 --> 00:28:07.621 align:middle line:-1
我们等一下去年的技术

00:28:08.589 --> 00:28:09.423 align:middle line:-1
好了

00:28:15.262 --> 00:28:17.698 align:middle line:-2
在这个例子中
我们看到了新的批处理API

00:28:17.764 --> 00:28:19.066 align:middle line:-1
明显的改进

00:28:19.132 --> 00:28:22.803 align:middle line:-2
一般来说 你在app中看到的改进
取决于模型

00:28:22.870 --> 00:28:24.838 align:middle line:-1
以及设备和工作载荷

00:28:24.905 --> 00:28:28.475 align:middle line:-2
但若你有大量prediction
要调用 请使用新的API

00:28:28.542 --> 00:28:31.845 align:middle line:-2
并为Core ML
提供加速计算的机会

00:28:35.649 --> 00:28:39.553 align:middle line:-2
当然 世界上性能最好的app
如果不能提供

00:28:39.620 --> 00:28:42.489 align:middle line:-2
你想为你的用户提供的体验
它也并不特别令人激动

00:28:43.590 --> 00:28:46.460 align:middle line:-1
我们希望确保无论该体验是什么

00:28:46.527 --> 00:28:48.195 align:middle line:-1
或将来是什么样的

00:28:48.262 --> 00:28:51.431 align:middle line:-2
Core ML的性能
和易用性都一如既往

00:28:52.366 --> 00:28:54.835 align:middle line:-1
但机器学习领域正在迅速发展

00:28:55.135 --> 00:28:57.938 align:middle line:-2
我们将如何跟上呢？
而且跟上的速度有多快呢？

00:28:58.005 --> 00:29:00.908 align:middle line:-2
让我告诉你一个跟这个问题有关的
我自己的故事

00:28:58.005 --> 00:29:00.908 align:middle line:-2
让我告诉你一个跟这个问题有关的
我自己的故事

00:29:02.843 --> 00:29:04.945 align:middle line:-2
让我们看一个
可以用机器学习来回答的

00:29:05.012 --> 00:29:06.713 align:middle line:-1
看似简单的问题

00:29:07.648 --> 00:29:11.752 align:middle line:-2
给出一张图片 我想知道
其中有马吗？

00:29:12.519 --> 00:29:14.555 align:middle line:-1
我想我听到一两声笑了

00:29:14.621 --> 00:29:16.723 align:middle line:-1
也许这是一个愚蠢的挑战问题

00:29:16.790 --> 00:29:18.992 align:middle line:-1
顺便说一句 小孩儿都好这口

00:29:19.059 --> 00:29:24.064 align:middle line:-2
很久很久以前
当我刚开始读研究生的时候

00:29:24.131 --> 00:29:27.134 align:middle line:-2
我当时正在考虑这个问题
并首次接触机器学习

00:29:27.501 --> 00:29:29.970 align:middle line:0
我对这个问题的看法像下面这样

00:29:30.904 --> 00:29:34.842 align:middle line:0
“我不知道 似乎很难
我真的没有什么好主意”

00:29:35.876 --> 00:29:40.247 align:middle line:0
几年过去了 我变老了
希望也能变得更聪明一点了

00:29:40.314 --> 00:29:42.749 align:middle line:0
但是这个领域非常迅速地发展

00:29:43.083 --> 00:29:45.052 align:middle line:0
因这时开始出现很多
使用深度神经网络

00:29:45.118 --> 00:29:46.687 align:middle line:0
得到的令人兴奋的新结果

00:29:47.688 --> 00:29:50.023 align:middle line:0
就这样 我对这个问题的看法
就改变了

00:29:50.090 --> 00:29:53.260 align:middle line:0
突然间 哇 原来这些先进的研究
真的可以回答这些问题

00:29:53.327 --> 00:29:55.229 align:middle line:0
电脑现在可以赶上小孩子

00:29:55.295 --> 00:29:58.332 align:middle line:0
和马识别技术了
多么令人兴奋的发展

00:30:00.267 --> 00:30:02.402 align:middle line:0
又经过了几年

00:30:02.469 --> 00:30:05.939 align:middle line:0
现在我在Apple工作
对这个问题的看法又改变了

00:30:06.373 --> 00:30:10.544 align:middle line:0
现在只需要使用Create ML
它的用户界面很漂亮

00:30:10.611 --> 00:30:12.613 align:middle line:0
你将在几分钟内拥有一个马分类器

00:30:13.313 --> 00:30:15.916 align:middle line:0
所以 你知道
如果你是机器学习专家

00:30:15.983 --> 00:30:17.918 align:middle line:0
且正在看这个 你可能会想
“哦 这个人

00:30:17.985 --> 00:30:19.086 align:middle line:0
不知道他在说什么

00:30:19.152 --> 00:30:21.355 align:middle line:0
在2007年我就知道
如何解决这个问题

00:30:21.421 --> 00:30:23.790 align:middle line:0
到2012年我已解决它一百次了”

00:30:24.224 --> 00:30:25.325 align:middle line:0
这不是重点

00:30:25.659 --> 00:30:30.264 align:middle line:0
如果你是一个关心
持久且高质量软件的人

00:30:30.330 --> 00:30:32.599 align:middle line:0
这会让你感到紧张
因为在11年内

00:30:32.666 --> 00:30:35.135 align:middle line:0
我们看到这个问题的环境
发生了天翻地覆的变化

00:30:36.203 --> 00:30:38.472 align:middle line:0
所以我们看看
Core ML中的另一些功能

00:30:38.539 --> 00:30:40.340 align:middle line:-1
来让你将悬着的心放下

00:30:41.542 --> 00:30:44.678 align:middle line:-2
为了做到这一点
我们再次进入底层并窥视

00:30:44.745 --> 00:30:48.982 align:middle line:-2
这个新的马匹识别模型
这又是一个神经网络

00:30:49.750 --> 00:30:51.185 align:middle line:-1
如前所述

00:30:51.251 --> 00:30:54.655 align:middle line:-1
神经网络由一系列层组成

00:30:54.721 --> 00:30:57.824 align:middle line:-1
我们在推理引擎中对其中每一层

00:30:57.891 --> 00:30:59.993 align:middle line:-1
都有高度优化的实现

00:31:00.827 --> 00:31:03.830 align:middle line:-2
我们支持的操作列表很庞大
而且一直在增长

00:31:04.264 --> 00:31:06.633 align:middle line:-1
试图跟上这一领域的新发展

00:31:07.668 --> 00:31:10.737 align:middle line:-2
但是如果在Core ML中
有一层不再得到支持了呢？

00:31:12.272 --> 00:31:13.173 align:middle line:-1
过去

00:31:13.707 --> 00:31:16.643 align:middle line:-2
你要么等待
要么需要一个不同的模型

00:31:17.411 --> 00:31:20.747 align:middle line:-1
但如果这层是关键的马匹识别层呢？

00:31:21.048 --> 00:31:23.684 align:middle line:-2
这是你的马匹识别app
正在等待的突破

00:31:23.984 --> 00:31:24.985 align:middle line:-1
你等得起吗？

00:31:26.687 --> 00:31:29.590 align:middle line:-2
鉴于机器学习的发展速度
这可能是一个严重的障碍

00:31:31.191 --> 00:31:34.695 align:middle line:0
因此 我们为神经网络模型
引入了自定义层

00:31:35.028 --> 00:31:39.499 align:middle line:0
现在 如果缺少某个神经网络层
你可以提供一个实现

00:31:39.566 --> 00:31:43.237 align:middle line:0
它将与Core ML
模型的其余部分无缝衔接

00:31:44.004 --> 00:31:47.941 align:middle line:0
在模型中
自定义层存储了实现类的名称

00:31:48.008 --> 00:31:50.277 align:middle line:0
在这里是
AAPLCustomHorseLayer

00:31:51.078 --> 00:31:54.248 align:middle line:0
实现类在推理引擎中

00:31:54.314 --> 00:31:55.516 align:middle line:0
充当所缺失实现的角色

00:31:55.849 --> 00:31:57.885 align:middle line:0
就像这个层
内置于Core ML一样

00:31:57.951 --> 00:32:01.455 align:middle line:0
这里提供的实现应该是通用的

00:31:57.951 --> 00:32:01.455 align:middle line:0
这里提供的实现应该是通用的

00:32:01.522 --> 00:32:02.956 align:middle line:0
并适用于新层的任何实例

00:32:04.691 --> 00:32:07.394 align:middle line:0
它只需要在运行时
被包含在你的app中

00:32:07.661 --> 00:32:09.963 align:middle line:0
然后这个特定层的参数

00:32:10.030 --> 00:32:12.032 align:middle line:0
和其他有关该模型的信息

00:32:12.099 --> 00:32:14.201 align:middle line:0
将一同被封装在MLModel中

00:32:15.969 --> 00:32:20.240 align:middle line:-2
实现一个自定义层很简单
我们暴露了MLCustomLayer协议

00:32:20.507 --> 00:32:22.809 align:middle line:-2
你只需根据存储在
MLModel中的数据

00:32:22.876 --> 00:32:24.945 align:middle line:-1
提供用来初始化层的方法

00:32:26.046 --> 00:32:28.949 align:middle line:-2
你需要提供一个方法
来告诉我们需要为该层的输出

00:32:29.016 --> 00:32:30.384 align:middle line:-1
分配多少空间

00:32:31.118 --> 00:32:32.853 align:middle line:-1
然后是执行计算的方法

00:32:34.955 --> 00:32:37.124 align:middle line:-1
另外 你可以添加这种灵活性

00:32:37.191 --> 00:32:40.060 align:middle line:-1
而不牺牲整个模型的性能

00:32:41.061 --> 00:32:43.864 align:middle line:-2
该协议包含一个可选的方法
它允许你提供给我们

00:32:43.931 --> 00:32:47.501 align:middle line:-1
一个该层的MTL着色器的实现

00:32:48.302 --> 00:32:50.671 align:middle line:-1
如果你给我们这个 那么它可以在

00:32:50.737 --> 00:32:53.707 align:middle line:-2
与其它Core ML计算所在的
同样命令缓冲区中被编码

00:32:53.774 --> 00:32:56.009 align:middle line:-2
所以这里没额外的开销
无论是来自额外的编码

00:32:56.076 --> 00:32:57.845 align:middle line:-1
还是多次往返GPU产生的开销

00:32:58.412 --> 00:33:00.581 align:middle line:-2
如果你不提供这个
那么我们将简单的

00:32:58.412 --> 00:33:00.581 align:middle line:-2
如果你不提供这个
那么我们将简单的

00:33:00.647 --> 00:33:03.116 align:middle line:-2
在CPU上进行计算
而不会做其他这些工作

00:33:04.952 --> 00:33:08.121 align:middle line:-2
因此 不管神经网络模型的进展
有多快

00:33:08.188 --> 00:33:09.923 align:middle line:-1
你都有办法跟上Core ML

00:33:10.490 --> 00:33:11.892 align:middle line:-1
但有一些限制

00:33:12.826 --> 00:33:15.162 align:middle line:-1
自定义层仅适用于神经网络模型

00:33:15.229 --> 00:33:18.232 align:middle line:-2
他们只能处理
ML MultiArrays的输入和输出

00:33:19.032 --> 00:33:21.368 align:middle line:-1
这是一种与神经网络交互的自然方式

00:33:21.668 --> 00:33:23.871 align:middle line:-1
但机器学习领域几乎不会限制

00:33:23.937 --> 00:33:25.639 align:middle line:-1
只在这个领域前进

00:33:26.607 --> 00:33:28.942 align:middle line:-1
实际上 当我第一次学习图像识别时

00:33:29.009 --> 00:33:32.613 align:middle line:-2
几乎没有人在谈论将神经网络
作为解决这个问题的方法

00:33:32.980 --> 00:33:35.315 align:middle line:-2
今天你可以看到
这绝对是最先进的技术

00:33:37.251 --> 00:33:40.587 align:middle line:-1
并不难想象具有机器学习功能的app

00:33:40.654 --> 00:33:42.556 align:middle line:-1
可能会导致有些自定义层根本不适用

00:33:43.023 --> 00:33:46.627 align:middle line:-2
例如 机器学习app
可能会使用神经网络

00:33:46.693 --> 00:33:50.130 align:middle line:-2
来向某个相似空间中嵌入图像
然后使用使用最近邻法

00:33:50.197 --> 00:33:53.166 align:middle line:-2
或局部敏感哈希法
或其它什么方法

00:33:53.233 --> 00:33:54.735 align:middle line:-1
来查找相似的图像

00:33:56.837 --> 00:33:59.339 align:middle line:-2
模型可能会结合
音频和动作数据来提供鼓励

00:33:59.406 --> 00:34:02.809 align:middle line:-1
给那些并不总能完成跑步目标的人

00:33:59.406 --> 00:34:02.809 align:middle line:-1
给那些并不总能完成跑步目标的人

00:34:04.878 --> 00:34:08.447 align:middle line:-2
甚至是一种我们甚至还没有想到的
能为你的用户提供新颖的体验的

00:34:08.514 --> 00:34:10.583 align:middle line:-1
全新模型类型

00:34:10.984 --> 00:34:12.452 align:middle line:-1
在所有这些情况下

00:34:12.518 --> 00:34:15.222 align:middle line:-2
如果我们可以拥有Core ML的
简单性和可移植性

00:34:15.656 --> 00:34:19.226 align:middle line:-2
而不必牺牲灵活性来跟上领域的发展
将是很棒的一件事

00:34:20.827 --> 00:34:22.529 align:middle line:-1
所以我们推出了自定义模型

00:34:23.496 --> 00:34:26.699 align:middle line:-1
Core ML自定义模型允许你

00:34:26.766 --> 00:34:29.735 align:middle line:0
封装Core ML中缺少的
部分计算实现

00:34:30.404 --> 00:34:31.871 align:middle line:0
就像自定义层一样

00:34:31.938 --> 00:34:34.440 align:middle line:0
该模型存储了实现类的名称

00:34:34.975 --> 00:34:37.244 align:middle line:0
这个类则充当了这类模型的

00:34:37.311 --> 00:34:38.645 align:middle line:0
通用推理引擎的角色

00:34:39.079 --> 00:34:42.748 align:middle line:0
而参数像以前一样
存储在MLModel中

00:34:43.550 --> 00:34:46.219 align:middle line:0
这允许将模型
作为app中的资源进行更新

00:34:46.286 --> 00:34:47.754 align:middle line:0
而无需接触代码

00:34:50.424 --> 00:34:52.659 align:middle line:-1
并且实现自定义模型也很简单

00:34:52.726 --> 00:34:55.094 align:middle line:-2
我们暴露了一个协议
MLCustomModel

00:34:55.429 --> 00:34:59.099 align:middle line:-2
你根据存储在MLModel中
的数据提供初始化的方法

00:35:00.100 --> 00:35:02.736 align:middle line:-2
再提供一个
根据输入计算预测结果的方法

00:35:03.303 --> 00:35:05.973 align:middle line:-2
如果有机会在这个特定的模型类型中
进行一些优化

00:35:06.039 --> 00:35:08.475 align:middle line:-1
我们还有一个可选的方法

00:35:08.542 --> 00:35:10.043 align:middle line:-1
来提供批处理实现

00:35:10.277 --> 00:35:12.679 align:middle line:-2
如果没有
我们将在for循环中调用每个预测

00:35:14.615 --> 00:35:16.316 align:middle line:-1
在你的app中使用自定义模型

00:35:16.383 --> 00:35:19.086 align:middle line:-2
与使用其他任何Core ML模型
在工作流程上基本相同

00:35:19.653 --> 00:35:22.556 align:middle line:-2
在Xcode中
一个带有自定义组件的模型

00:35:22.623 --> 00:35:26.493 align:middle line:-2
将有一个依赖项部分
其将列出所需实现的名称

00:35:26.560 --> 00:35:27.928 align:middle line:-1
以及简短的描述

00:35:28.562 --> 00:35:30.864 align:middle line:-2
只需将其包含在你的app中
就可以开始使用了

00:35:31.665 --> 00:35:35.736 align:middle line:-2
原来的prediction API没有改变
无论是单个还是批处理预测

00:35:38.205 --> 00:35:41.375 align:middle line:-1
因此 自定义层和自定义模型允许你

00:35:41.441 --> 00:35:45.045 align:middle line:-2
使用Core ML的强大能力
和简洁性而不牺牲所需的灵活性

00:35:45.112 --> 00:35:47.648 align:middle line:-2
这种灵活性对跟上
机器学习领域的进展至关重要

00:35:48.582 --> 00:35:52.352 align:middle line:-2
对于新的神经网络层 自定义层
允许你使用Core ML中的

00:35:52.419 --> 00:35:54.188 align:middle line:-1
神经网络推理引擎中

00:35:54.254 --> 00:35:56.523 align:middle line:-1
已经存在的诸多优化

00:35:57.057 --> 00:36:01.461 align:middle line:-1
自定义模型对于类型和功能更加灵活

00:35:57.057 --> 00:36:01.461 align:middle line:-1
自定义模型对于类型和功能更加灵活

00:36:01.528 --> 00:36:04.031 align:middle line:-1
但他们的确需要你做更多的实现工作

00:36:05.766 --> 00:36:09.403 align:middle line:-2
这两种自定义形式都允许你
在MLModel中封装模型参数

00:36:09.469 --> 00:36:13.073 align:middle line:-1
使得模型可移植且代码更简单

00:36:15.976 --> 00:36:19.580 align:middle line:-2
我们只接触到Core ML 2中的
一小部分很棒的新功能

00:36:20.047 --> 00:36:23.116 align:middle line:-1
请下载测试版 自己尝试一下

00:36:27.020 --> 00:36:30.357 align:middle line:-2
Core ML具有许多优秀新特性
可以减少你的app大小

00:36:30.424 --> 00:36:33.760 align:middle line:-1
提高性能 确保灵活性

00:36:33.827 --> 00:36:35.729 align:middle line:-1
并兼容机器学习的最新进展

00:36:36.496 --> 00:36:40.567 align:middle line:-2
我们向你展示了量化如何
缩小模型大小 和新的批处理API

00:36:40.634 --> 00:36:44.872 align:middle line:-2
可以实现更高效的处理
以及自定义层和自定义模型

00:36:44.938 --> 00:36:47.674 align:middle line:-2
如何帮助你将先进机器学习技术
应用到你的app中

00:36:48.275 --> 00:36:51.745 align:middle line:-2
结合我们在Create ML中
训练模型的强大的新工具

00:36:51.812 --> 00:36:55.249 align:middle line:-2
将机器学习功能添加到你的app中
并为你的用户提供全新的体验

00:36:55.315 --> 00:36:57.851 align:middle line:-1
的方式比以往任何时候都多

00:36:59.853 --> 00:37:01.121 align:middle line:0
短暂休息后

00:36:59.853 --> 00:37:01.121 align:middle line:0
短暂休息后

00:37:01.188 --> 00:37:04.791 align:middle line:0
我们会回到这里
并深入了解这些功能

00:37:04.858 --> 00:37:08.395 align:middle line:0
特别是 我们将向你展示如何使用
我们的Core ML工具软件

00:37:08.462 --> 00:37:12.132 align:middle line:0
来缩小模型大小并使用
Core ML自定义你的用户体验

00:37:12.199 --> 00:37:14.268 align:middle line:0
谢谢
