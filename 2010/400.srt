1
00:00:06,500 --> 00:00:09,050
[ Applause ]

2
00:00:09,050 --> 00:00:12,650
>> Thank you for coming.

3
00:00:12,650 --> 00:00:16,690
It's going to be a great week.

4
00:00:16,690 --> 00:00:21,880
Today, in this session, we are going to talk
about all the great technologies that we make

5
00:00:21,880 --> 00:00:25,360
for the graphics and media needs of your applications.

6
00:00:25,360 --> 00:00:33,030
Apple delivers products that give users
incredible immersive, vivid user experiences.

7
00:00:33,030 --> 00:00:37,140
We saw that today with the release of iPhone 4.

8
00:00:37,140 --> 00:00:43,870
iPhone 4 with its new retina display and a
high resolution display is the perfect platform

9
00:00:43,870 --> 00:00:47,290
for really bringing vivid user experiences.

10
00:00:47,290 --> 00:00:57,180
And of course, we see this with the iPad,
the revolutionary iPad, and the Macintosh.

11
00:00:57,180 --> 00:00:57,770
[ Applause ]

12
00:00:57,770 --> 00:01:11,410
>> At the heart of all of this are
the Graphics and Media technologies.

13
00:01:11,410 --> 00:01:19,420
We deliver over twenty frameworks,
over twenty different graphics

14
00:01:19,420 --> 00:01:23,990
and media frameworks for you to
leverage in your application.

15
00:01:23,990 --> 00:01:31,480
These frameworks deliver a huge amount of graphics and
media technology that you can leverage to build this vivid,

16
00:01:31,480 --> 00:01:34,730
immersive, user experiences right at your application.

17
00:01:34,730 --> 00:01:37,530
These are the same frameworks that
we use when we build our products.

18
00:01:37,530 --> 00:01:43,730
They are the same technologies that
you see when we demo on stage, right.

19
00:01:43,730 --> 00:01:46,210
These are really fantastic technologies.

20
00:01:46,210 --> 00:01:51,500
These are technologies you should learn about and use to
their fullest, and you will be able to build applications

21
00:01:51,500 --> 00:01:57,310
that really make your users love your products.

22
00:01:57,310 --> 00:02:03,270
So we deliver these technologies at different levels of API.

23
00:02:03,270 --> 00:02:09,900
At the high level on the iPhone, we have a Cocoa Touch
API which is an Objective-C API that makes it easy for you

24
00:02:09,900 --> 00:02:15,960
to get access to the Graphics and Media technologies
and easy for you to incorporate into your product.

25
00:02:17,230 --> 00:02:22,250
We, of course, have low level technologies
such as Quartz for high-quality 2D rendering,

26
00:02:22,250 --> 00:02:29,490
OpenGL for high performance 3D, and
Core Audio for professional grade audio.

27
00:02:29,490 --> 00:02:35,320
These low level technologies give you
the flexibility to do custom things

28
00:02:35,320 --> 00:02:38,450
to get access to all the capabilities of the platform.

29
00:02:38,450 --> 00:02:46,620
And then we have technologies such as Core Animation that
let you mix and match between the different technologies.

30
00:02:46,620 --> 00:02:53,410
They let you take 2D graphics, 3D
graphics, and video, and blend them together

31
00:02:53,410 --> 00:02:56,750
into really custom-immersive user experiences.

32
00:02:58,090 --> 00:03:06,990
Core Animation is a very powerful technology for you
to build really immersive vivid user experiences.

33
00:03:06,990 --> 00:03:16,320
So what we do at Apple is we build the graphics and media
technology of a common platform across all of our products.

34
00:03:16,320 --> 00:03:26,560
So across the desktop Mac OS and across IOS, it is the
same graphics and media technologies, the same foundation.

35
00:03:26,560 --> 00:03:34,550
This means that we've been able to take years of our
experience and we deliver that across all of the platforms,

36
00:03:34,550 --> 00:03:38,480
giving you that same high-quality
professional grade technology.

37
00:03:38,480 --> 00:03:46,710
So what this also means is that we have
optimized this technology for the hardware.

38
00:03:46,710 --> 00:03:51,630
So whether you are trying to get high performance or
get access to all of the features of the hardware,

39
00:03:51,630 --> 00:04:01,220
whether it be microphones and speakers and cameras, this
technology has been optimized for that hardware device.

40
00:04:01,220 --> 00:04:06,710
And what is really important about
that is that the world is going mobile,

41
00:04:06,710 --> 00:04:14,430
and optimized means that when you use our technologies
right, you also are optimizing for battery life.

42
00:04:14,430 --> 00:04:17,390
And battery life is going to be
something very important for your users.

43
00:04:17,390 --> 00:04:19,420
You want to make sure that when
you are building an application,

44
00:04:19,420 --> 00:04:25,160
you are giving your users a good experience
with battery life when going mobile.

45
00:04:26,970 --> 00:04:34,660
So looking at some of the applications
that you have built, there is BoinxTV.

46
00:04:34,660 --> 00:04:41,620
BoinxTV takes our graphics and media
technologies and incorporates them in a way

47
00:04:41,620 --> 00:04:46,090
that brings a live TV studio right on to the Mac.

48
00:04:46,090 --> 00:04:48,560
It is really cool.

49
00:04:48,560 --> 00:04:58,970
Or Pinball HD uses an intuitive Multi-Touch interface
combined with OpenGL ES to take an arcade classic

50
00:04:58,970 --> 00:05:05,520
and make a really great application for the iPad.

51
00:05:05,520 --> 00:05:07,040
OrFour Track.

52
00:05:07,040 --> 00:05:14,350
FourTrack takes Core Audio and makes a
multi-track recorder right on your iPhone.

53
00:05:14,350 --> 00:05:15,820
That is pretty amazing.

54
00:05:15,820 --> 00:05:22,210
So you have taken all our technologies,
all the graphics and media technologies,

55
00:05:22,210 --> 00:05:28,000
and you have used them to build over 225,000 applications.

56
00:05:28,000 --> 00:05:29,510
That is a huge number.

57
00:05:29,510 --> 00:05:38,380
And of course, I'd like to say thank you because you guys
have built some applications that are absolutely amazing.

58
00:05:38,380 --> 00:05:46,810
So for the rest of the talk, what I want
to focus on is I want to focus on iOS 4.

59
00:05:46,810 --> 00:05:56,280
We are going to talk about some of the new and innovative
features that we are building into iOS 4, specifically,

60
00:05:56,280 --> 00:06:01,600
OpenGL ES and the new extensions we are offering
there, AVFoundation for the audio and video needs

61
00:06:01,600 --> 00:06:08,830
of your application, HTTP Live Streaming, the
best way to stream live video over the internet,

62
00:06:08,830 --> 00:06:12,990
and Game Center for bringing social gaming into your game.

63
00:06:12,990 --> 00:06:18,710
And to start, I am going to bring
Gheoff Stahl up to talk about OpenGL ES.

64
00:06:18,710 --> 00:06:19,160
>> Thank you.

65
00:06:19,160 --> 00:06:21,320
[ Applause ]

66
00:06:21,320 --> 00:06:29,280
>> OpenGL ES, it's the open standard-spaced technology
that allows you to access the power of the GPU.

67
00:06:29,280 --> 00:06:36,410
When we conceived iOS, we chose
OpenGL ES as a graphics foundation,

68
00:06:36,410 --> 00:06:41,880
and John talked about layering OpenGL ES
as a full participant in this layering.

69
00:06:41,880 --> 00:06:45,990
Core Animation, for example, is built on top of OpenGL ES.

70
00:06:45,990 --> 00:06:54,210
So no matter what high level API your application uses,
you get the power of OpenGL ES and the power of the GPU.

71
00:06:54,210 --> 00:07:02,600
So before we go into the new features in iOS 4, lets
first take a review of OpenGL ES and what it is.

72
00:07:02,600 --> 00:07:10,830
OpenGL ES is a low level graphics API that uses vertices,
triangles, and triangular meshes to express geometry.

73
00:07:10,830 --> 00:07:17,860
When that is combined with textures and pixel
data, you can render compelling 3D images

74
00:07:17,860 --> 00:07:22,720
such as this Sergeant Shock [phonetic]
who would look right at home in a 3D game.

75
00:07:22,720 --> 00:07:25,220
But it is more than this.

76
00:07:25,220 --> 00:07:30,960
OpenGL ES can be used for high speed compositing as we see
with Core Animation, and also can be used for image effects.

77
00:07:30,960 --> 00:07:40,560
And when we go to OpenGL ES 2.0 and we add shaders,
OpenGL ES can really unlock the power of the GPU.

78
00:07:40,560 --> 00:07:42,990
So what are shaders?

79
00:07:42,990 --> 00:07:50,190
Shaders are small programs written in
OpenGL shading language that run on the GPU

80
00:07:50,190 --> 00:07:55,530
and can either affect the vertex or
fragment parts of the rendering pipeline,

81
00:07:55,530 --> 00:08:00,080
thus allowing you to really customize your drawing
experience and unlock that full power of the GPU.

82
00:08:00,080 --> 00:08:06,880
In this case, we replied dynamic lighting and shadows to
Sergeant Shock to really immerse him in your application.

83
00:08:06,880 --> 00:08:11,060
I think the best way to show this is to look at a demo.

84
00:08:11,060 --> 00:08:14,820
So I'd like to have David Biterman [phonetic]
help me with this demo called Extreme Ball.

85
00:08:14,820 --> 00:08:15,740
[ Applause ]

86
00:08:15,740 --> 00:08:20,190
>> So this demo is created by Digital
Legends for Imagination Technologies,

87
00:08:20,190 --> 00:08:24,780
and it is a immersive 3D world
here, I made a futuristic arena,

88
00:08:24,780 --> 00:08:28,690
and what it shows is the power of OpenGL ES 2.0 and shaders.

89
00:08:28,690 --> 00:08:32,820
First, we are looking at the triangular mesh
that makes up the world as you would expect.

90
00:08:32,820 --> 00:08:34,760
It makes a structure of the world.

91
00:08:34,760 --> 00:08:38,040
And now, let us look at some of
the fine details in the simulation.

92
00:08:38,040 --> 00:08:45,100
So you have the reflections in the floor, you have the water
with animated normal maps with that specular highlighting,

93
00:08:45,100 --> 00:08:49,570
the character itself, his facial
expressions, a physics-driven hair model,

94
00:08:49,570 --> 00:08:58,470
she is animated on a bone structure with motion capture
and vertex shaders, animated bones and skinning the mesh,

95
00:08:58,470 --> 00:09:01,660
fragment shader provide that lighting detail.

96
00:09:01,660 --> 00:09:09,510
When we look at the character, we can see dynamic lighting,
we see reflections in the floor, and we see shadows cast.

97
00:09:09,510 --> 00:09:15,870
This simulation drives over a million
and a half polygons per second.

98
00:09:15,870 --> 00:09:23,920
The models-- the balls themselves are very simple
geometric meshes covered with textures, normal maps,

99
00:09:23,920 --> 00:09:29,170
specular highlights, create a more-- it looks
like you got more geometry than you would expect.

100
00:09:29,170 --> 00:09:38,400
Really, all in all, this is a great demonstration of the
power of OpenGL ES 2.0, what you can do with shaders,

101
00:09:38,400 --> 00:09:42,830
and all of this is running on a GPU that
you can hold in the palm of your hand.

102
00:09:42,830 --> 00:09:45,100
Absolutely fantastic, amazing technology.

103
00:09:45,100 --> 00:09:53,200
Again, written by Digital Legends
for Imagination Technologies.

104
00:09:53,200 --> 00:09:54,290
>> Thank you, Dave.

105
00:09:54,290 --> 00:09:57,050
[ Applause ]

106
00:09:57,050 --> 00:09:58,690
>> We have reviewed OpenGL ES.

107
00:09:58,690 --> 00:10:02,250
Let us talk about iOS 4.

108
00:10:02,250 --> 00:10:07,980
So last year, we introduced OpenGL ES 2.0 and shaders.

109
00:10:07,980 --> 00:10:13,430
This year we are going to introduce some really
fantastic new features to add on top of them.

110
00:10:13,430 --> 00:10:18,220
>> So let us jump right in, starting off
with low cost full scene anti-aliasing.

111
00:10:18,220 --> 00:10:24,370
We've added a full scene anti-aliasing which
reduces the aliasing artifacts in your scene

112
00:10:24,370 --> 00:10:27,560
for very low cost while maintaining optimum frame rate.

113
00:10:27,560 --> 00:10:30,160
So it markedly improved the rendering quality.

114
00:10:30,160 --> 00:10:33,540
For example, here, you see, if you look
at the ball from the previous simulation,

115
00:10:33,540 --> 00:10:36,380
you will see there is an aliasing
artifacts in the under side of that ball.

116
00:10:36,380 --> 00:10:41,420
If we turn on full scene anti-aliasing, what you can
see is this aliasing artifacts are markedly reduced.

117
00:10:41,420 --> 00:10:47,360
This, and the last demonstration you saw,
was running with full scene anti-aliasing on.

118
00:10:47,360 --> 00:10:49,970
You can see the frame rates and throughput we achieved.

119
00:10:49,970 --> 00:10:54,000
Low cost full scene anti-aliasing, new in iOS 4.

120
00:10:54,000 --> 00:10:55,420
One of the really important things that you saw

121
00:10:55,420 --> 00:11:01,170
on the demonstration is the way your 3D
scene interacts with lighting and shadows.

122
00:11:01,170 --> 00:11:04,100
So what we have done for iOS 4, we have enhanced shadows.

123
00:11:04,100 --> 00:11:09,500
We have added support for two shadowing
techniques, both shadow mapping and shadow volumes.

124
00:11:09,500 --> 00:11:15,010
We have added depth texture support for
shadow mapping, and shadow is a technique.

125
00:11:15,010 --> 00:11:21,050
It is image-based technique where you take the light and
you render the scene from the point of view of the light

126
00:11:21,050 --> 00:11:26,270
into the depth texture, you accumulate these results, and
then when you are rendering the scene from the user's point

127
00:11:26,270 --> 00:11:32,980
of view, the user results, they guide you to
what is in shadow and what is out of shadow.

128
00:11:32,980 --> 00:11:36,650
Shadow volumes are-- use a stencil buffer and show--

129
00:11:36,650 --> 00:11:41,070
and allow pixel accurate shadows,
like you see in this example here.

130
00:11:41,070 --> 00:11:45,430
If you are interested in either of these
techniques, the more advanced rendering techniques,

131
00:11:45,430 --> 00:11:49,920
we are going to be talking about these later this
week, the advanced OpenGL ES rendering sessions,

132
00:11:49,920 --> 00:11:56,880
where we talk about exactly how they created
this demonstration right here, enhanced shadows.

133
00:11:56,880 --> 00:12:00,650
So beyond shadows, a really important
thing in 3D rendering is textures.

134
00:12:00,650 --> 00:12:06,690
And we have a standout example we used
earlier, Pinball HD, fantastic use of textures

135
00:12:06,690 --> 00:12:11,390
to give you that immersive 3D Pinball experience.

136
00:12:11,390 --> 00:12:12,640
So how do they do this?

137
00:12:12,640 --> 00:12:17,380
Well, it is actually fairly simple, and it is a common
and convenient technique that many of you may already use

138
00:12:17,380 --> 00:12:20,940
if you are using OpenGL ES, and it is texture atlas.

139
00:12:20,940 --> 00:12:23,610
So what is a texture atlas?

140
00:12:23,610 --> 00:12:29,030
A texture atlas is a large texture that accumulate--
you store all of your smaller textures into,

141
00:12:29,030 --> 00:12:31,460
and then during your rendering, you reference out of that.

142
00:12:31,460 --> 00:12:36,600
As you can see here, we have textures for the
bumpers, for the flippers, and for the table art,

143
00:12:36,600 --> 00:12:42,700
all of that is contained in one texture and it's-- and
you reference that when you are drawing your scene.

144
00:12:42,700 --> 00:12:50,560
For iOS 4, we have added a new extension texture max level
which allows you even more control over texture filtering,

145
00:12:50,560 --> 00:12:56,830
allows you to have pixel accurate texturing, and
ensures you have the highest quality scenes possible.

146
00:12:56,830 --> 00:13:04,540
And we also added shader texture LOD, which
is level of detail control for shaders.

147
00:13:04,540 --> 00:13:08,300
This means you can write a single shader
that you can control the texture filtering.

148
00:13:08,300 --> 00:13:12,090
So whether an object is near to you or far
to you and far away from you in the scene,

149
00:13:12,090 --> 00:13:17,900
you can ensure smooth alias-free texturing across
your scene, allows a shader to select the texture,

150
00:13:17,900 --> 00:13:21,450
select the mipmap bubble, and it's
interesting when texturing.

151
00:13:21,450 --> 00:13:29,240
That is shader texture LOD, two new advanced
texture management routines now available in iOS 4.

152
00:13:29,240 --> 00:13:34,300
The next thing we have added are
two additional texturing techniques.

153
00:13:34,300 --> 00:13:36,760
The first one is all about integration with media.

154
00:13:36,760 --> 00:13:45,670
YUV 422 textures allow native support
of video on the GPU with OpenGL ES.

155
00:13:45,670 --> 00:13:52,400
This allows you to maintain-- do not have to do costly
format conversions, maintain an optimal memory layout

156
00:13:52,400 --> 00:13:58,610
for video textures, and really allows you
to integrate video with your 3D rendering

157
00:13:58,610 --> 00:14:04,430
in one space, integration with media YUV 422 textures.

158
00:14:04,430 --> 00:14:08,570
The second thing we have added for
texturing is floating point textures.

159
00:14:08,570 --> 00:14:10,670
The floating point texture is a little bit different.

160
00:14:10,670 --> 00:14:17,380
Floating point textures allow some new rendering
techniques you could not do before on a handheld GPU.

161
00:14:17,380 --> 00:14:19,870
In this case, I will talk about two of them.

162
00:14:19,870 --> 00:14:25,700
One case is you-- let's say you have a really complex
calculation that you want to run on a per pixel basis.

163
00:14:25,700 --> 00:14:27,400
So, that-- running in a shader.

164
00:14:27,400 --> 00:14:32,340
What you can do is you can precalculate
your data at a granularity that is set for--

165
00:14:32,340 --> 00:14:39,640
that's right for your application, store that in a floating
point texture, upload it to the GPU, and then during--

166
00:14:39,640 --> 00:14:43,750
when your application is running, that
complex shader calculation collapses

167
00:14:43,750 --> 00:14:48,800
down to a single texture lookup ensuring your
application maintains optimum performance.

168
00:14:48,800 --> 00:14:50,730
Great technique there.

169
00:14:50,730 --> 00:14:55,110
Also, floating point textures, of course, can be
used for uploading high precision numerical data.

170
00:14:55,110 --> 00:15:00,660
Let us say you have hype field that you want to upload to
the GPU, put it in a floating point texture, upload it,

171
00:15:00,660 --> 00:15:03,590
you will be able to reference that
at floating point resolution.

172
00:15:03,590 --> 00:15:06,450
So we have added a number of new things to iOS 4.

173
00:15:06,450 --> 00:15:11,350
We have also ensured that it is optimized for performance.

174
00:15:11,350 --> 00:15:16,110
We think this is the most optimized
release ever for our graphic system.

175
00:15:16,110 --> 00:15:23,000
We have added stencil wrap for high performance,
stencil shadows, we have added vertex array object

176
00:15:23,000 --> 00:15:32,200
that allows improved vertex efficiency, especially for
multiple vertex objects, we have added discard frame buffer

177
00:15:32,200 --> 00:15:36,800
which allows you to-- allows the GPU
to optimize its memory bandwidth use,

178
00:15:36,800 --> 00:15:41,360
and we have paid particular attention to texturing.

179
00:15:41,360 --> 00:15:50,580
We have improved both GL tech subimage, and we have also
improved the overall texture upload speed throughout

180
00:15:50,580 --> 00:15:51,640
the system.

181
00:15:51,640 --> 00:15:56,130
All in all, this is the most optimized
release we have ever had.

182
00:15:56,130 --> 00:15:57,420
So how do we bring this all together?

183
00:15:57,420 --> 00:16:03,870
Well, let us show one more-- let us show another
demo that shows some of the power of OpenGL ES 2.0

184
00:16:03,870 --> 00:16:07,060
and the use of some of the new features of iOS 4.

185
00:16:07,060 --> 00:16:14,580
I'd like to invite up Torsten Reil, the CEO
of NaturalMedia to give the demonstration.

186
00:16:14,580 --> 00:16:16,960
>> I would like to show you something today.

187
00:16:16,960 --> 00:16:18,440
I've been very excited about it.

188
00:16:18,440 --> 00:16:22,460
It is something that we have been working on
at NaturalMotion with our partners at MunkyFun.

189
00:16:22,460 --> 00:16:29,560
We are trying to push the boundaries of what
is possible in terms of interactivity, realism,

190
00:16:29,560 --> 00:16:33,470
and believability of a character on a handheld device.

191
00:16:33,470 --> 00:16:42,830
To do this, we are using advanced OpenGL ES 2.0 features,
as well as our runtime animation engine, Morpheme.

192
00:16:42,830 --> 00:16:46,200
Now, the character that we are working on is a horse.

193
00:16:46,200 --> 00:16:53,450
It is a horse that is much less about my little pony and
much more about creating something that is authentic,

194
00:16:53,450 --> 00:16:57,530
believable, and something you can
interact with in a natural way.

195
00:16:57,530 --> 00:17:01,430
It forms the core component of a game that
we are working on together with MunkyFun,

196
00:17:01,430 --> 00:17:07,900
and I would like to introduce Nick Pavis [phonetic], who's
the CEO of MunkyFun, to show us what this looks like so far.

197
00:17:07,900 --> 00:17:12,700
[ Applause ]

198
00:17:12,700 --> 00:17:20,750
>> So what you see here on this screen
is running live on iPhone 4 on iOS 4.

199
00:17:20,750 --> 00:17:26,240
You see here first of all, starting with the close up of the
horse, we are using high resolution textures for the horse,

200
00:17:26,240 --> 00:17:31,640
as well as advanced OpenGL ES 2.0
shaders to make the coat look natural,

201
00:17:31,640 --> 00:17:36,520
but also for details such as the eyes on the horse.

202
00:17:36,520 --> 00:17:40,050
Now, what you will see in a moment is
that Nick can interact with the horse.

203
00:17:40,050 --> 00:17:42,570
You would not see his fingers here,
but he is stroking the horse,

204
00:17:42,570 --> 00:17:46,080
and the horse is reacting to that
naturally and interactively.

205
00:17:46,080 --> 00:17:52,170
We are using procedural animations for this driven by the
morpheme animation engine rather than canned animation.

206
00:17:52,170 --> 00:17:57,770
Now, what's Nick done here is send the horse on to
the paddock and have it run around on the paddock.

207
00:17:57,770 --> 00:18:03,090
So the scene itself is about 16,000 polygons,
the horse is another 10,000 polygons,

208
00:18:03,090 --> 00:18:08,440
we have got full scene anti-aliasing running on this scene,
and you can see that the horse itself is running naturally,

209
00:18:08,440 --> 00:18:11,980
again, using a morpheme animation engine.

210
00:18:11,980 --> 00:18:17,590
So what we want to show you now is really, how we are
building this scene out starting with the beginning,

211
00:18:17,590 --> 00:18:19,300
with the basic lighting which you see here.

212
00:18:19,300 --> 00:18:24,110
We are now adding textures to this, and the
textures themselves are high resolution.

213
00:18:24,110 --> 00:18:31,340
So for example, the grass alone uses four different high
resolution textures to avoid repetitiveness and tiles.

214
00:18:31,340 --> 00:18:35,630
Next up, we are adding anti-aliasing, as you
have just seen in to the scene, and particularly,

215
00:18:35,630 --> 00:18:41,540
is useful for areas like the fence, for example, especially
when we do the slow camera pans, we get rid of the jaggies.

216
00:18:41,540 --> 00:18:45,100
Again, that is something that is possible now in iOS 4.

217
00:18:45,100 --> 00:18:47,930
And moving on, we are now adding vegetation here.

218
00:18:47,930 --> 00:18:50,000
So you can see the trees have just
been added in the background,

219
00:18:50,000 --> 00:18:52,700
as well as grass in the foregrounds close to the fence.

220
00:18:52,700 --> 00:18:57,100
This is done using Alpha, again on OpenGL ES 2.0 and iOS 4.

221
00:18:57,100 --> 00:19:00,120
And next up, we've added fog.

222
00:19:00,120 --> 00:19:04,830
So the fog is used to make all the scene
components sit together in a natural way.

223
00:19:04,830 --> 00:19:08,860
And we have implemented that again, not
really in the old style, but in a new style.

224
00:19:08,860 --> 00:19:13,060
We are using desaturation shaders for this
again, to give us that extra realistic look.

225
00:19:13,060 --> 00:19:15,990
We are now adding the horse to the scene.

226
00:19:15,990 --> 00:19:18,730
There it is, obviously, right now, without any textures.

227
00:19:18,730 --> 00:19:24,180
But what you see is again, that we are using dynamic
shadows using the shadow buffers in OpenGL ES 2.0.

228
00:19:24,180 --> 00:19:26,710
And also, if you look carefully,
what you can see is that the green

229
00:19:26,710 --> 00:19:30,740
from the grass itself is bleeding into the horse itself.

230
00:19:30,740 --> 00:19:32,950
And the same is true for the sky as well.

231
00:19:32,950 --> 00:19:38,540
That again, gives us an additional level of realism
which is only really possible now with OpenGL ES 2.0.

232
00:19:38,540 --> 00:19:42,260
And Nick is now going to add the texture
on the horse here, as well as the shaders,

233
00:19:42,260 --> 00:19:46,170
again, which gives the coat a realistic look.

234
00:19:46,170 --> 00:19:48,410
Next up, I think Nick is going to send the horse off.

235
00:19:48,410 --> 00:19:50,670
[ Laughter ]

236
00:19:50,670 --> 00:19:52,780
>> Not 100 % realistic yet.

237
00:19:52,780 --> 00:19:56,380
But I think, as a next step, he is
adding the animation engine to it.

238
00:19:56,380 --> 00:19:57,450
And now, the horse is running.

239
00:19:57,450 --> 00:20:00,110
And I think Nick's just actually triggered that jump itself.

240
00:20:00,110 --> 00:20:03,230
You can see we get very smooth
transitions from one gate to the other one,

241
00:20:03,230 --> 00:20:08,330
and we also have sound to the background running as
well, which is triggered off the animation events.

242
00:20:08,330 --> 00:20:10,840
Now, Nick's just called the horse back to the gates,

243
00:20:10,840 --> 00:20:14,190
presumably to give it a few more
strokes for having screwed up the demo.

244
00:20:14,190 --> 00:20:16,710
So this is really where we are right now.

245
00:20:16,710 --> 00:20:23,940
We are amazed at the power that is now available
on the iPhone and in the handheld device.

246
00:20:23,940 --> 00:20:28,740
And we are really excited about the possibilities
that we now have, and that NaturalMotion together

247
00:20:28,740 --> 00:20:31,800
with MunkyFun, for creating just amazing games.

248
00:20:31,800 --> 00:20:33,170
So thank you very much.

249
00:20:33,170 --> 00:20:40,110
[Applause]

250
00:20:40,110 --> 00:20:42,070
>> Thank you, Torsten.

251
00:20:42,070 --> 00:20:53,320
It's absolutely stunning what they can achieve with a
handheld device, OpenGL 2.0-- OpenGL ES 2.0, and iOS 4.

252
00:20:53,320 --> 00:20:55,610
Think about where were three years ago.

253
00:20:55,610 --> 00:20:57,160
Think where we were five years ago.

254
00:20:57,160 --> 00:20:58,030
This is amazing.

255
00:20:58,030 --> 00:21:03,290
This is a device that you hold in your hand, this
fits in your pocket, absolutely amazing power.

256
00:21:03,290 --> 00:21:06,700
So what do we talk about?

257
00:21:06,700 --> 00:21:12,560
OpenGL ES 2.0 and shaders unlock the
fantastic power of the handheld GPU.

258
00:21:12,560 --> 00:21:16,360
Full scene anti-aliasing, very low cost.

259
00:21:16,360 --> 00:21:21,560
Enhance shadows, shadow mapping, shadow
volumes, new texture management techniques,

260
00:21:21,560 --> 00:21:28,970
new texture formats about integration, unlocking new
rendering techniques, and finally, all of these is optimized

261
00:21:28,970 --> 00:21:36,330
for performance, delivering what we think is
the absolute leading handheld graphic system.

262
00:21:36,330 --> 00:21:42,210
I thank you very much, and I will turn the talk
over to Meriko to talk about our media systems.

263
00:21:42,210 --> 00:21:44,030
[ Applause ]

264
00:21:44,030 --> 00:21:44,930
>> This is awesome.

265
00:21:44,930 --> 00:21:46,030
Thank you, guys, for being here.

266
00:21:46,030 --> 00:21:48,760
I know it is a little bit late on a Monday
night, and you all got here early to see Steve.

267
00:21:48,760 --> 00:21:50,380
We are thrilled to see you all here.

268
00:21:50,380 --> 00:21:56,510
And I am incredibly excited to be talking to you
about the media systems on iOS 4 and iPhone 4 today.

269
00:21:56,510 --> 00:21:59,830
I would like to start by talking about AV Foundation.

270
00:21:59,830 --> 00:22:07,540
AV Foundation is a modern Objective-C 2.0 API that is
designed for maximum flexibility, professional grade access

271
00:22:07,540 --> 00:22:15,610
to time-based media-- and professional access
to time-based media with dropping ease of use.

272
00:22:15,610 --> 00:22:19,200
To set the stage, I would like to talk
a little bit about what we had in iOS 3.

273
00:22:19,200 --> 00:22:26,480
In iOS 3, we gave you UIKit API to access the
camera, record data, trim it, and save it off.

274
00:22:26,480 --> 00:22:30,550
We gave you a set of AV Foundation
API for working with audio.

275
00:22:30,550 --> 00:22:35,390
This allows you to record audio, process
audio, and save it off to a file.

276
00:22:35,390 --> 00:22:44,520
You guys responded with fantastic media-based applications,
things like Pro HDR for taking beautiful HDR photography,

277
00:22:44,520 --> 00:22:52,050
Reel Director for recording and editing media,
and Skype for awesome quality audio conferencing.

278
00:22:52,050 --> 00:22:53,440
We said, "Yes, please.

279
00:22:53,440 --> 00:22:54,770
Could we have some more?"

280
00:22:54,770 --> 00:22:58,770
So we spent the last year dramatically
extending AV Foundation.

281
00:22:58,770 --> 00:23:01,470
So first off, we are giving you great access to the camera.

282
00:23:01,470 --> 00:23:04,720
We are giving you control over the
camera and access to its output.

283
00:23:04,720 --> 00:23:13,650
We have fantastic professional grade frame-accurate
editing services, and high-quality performance playback.

284
00:23:13,650 --> 00:23:18,040
And finally, a really easy to use set of export API.

285
00:23:18,040 --> 00:23:26,420
We use this technology to power our applications
inside of iOS 4, from our iPod media playback

286
00:23:26,420 --> 00:23:31,660
to our camera applications to record and trim, and save.

287
00:23:31,660 --> 00:23:34,190
These technologies are at the heart of Face Time.

288
00:23:34,190 --> 00:23:36,520
Did you guys all get to see a Face Time this morning?

289
00:23:36,520 --> 00:23:37,740
We are-- yeah.

290
00:23:37,740 --> 00:23:38,980
[ Applause ]

291
00:23:38,980 --> 00:23:43,530
>> We are really, really, really proud of that feature.

292
00:23:43,530 --> 00:23:44,950
And Randy showed you iMovie.

293
00:23:44,950 --> 00:23:46,920
iMovie for iPhone 4.

294
00:23:46,920 --> 00:23:54,220
iMovie is built entirely on exactly the same public API and
AV Foundation that we are presenting to you in iPhone 4.

295
00:23:54,220 --> 00:23:54,440
[ Applause ]

296
00:23:54,440 --> 00:23:59,880
>> It is pretty cool.

297
00:24:01,400 --> 00:24:06,700
So because we're the graphics and imaging
and media teams, we built AV Foundation hand

298
00:24:06,700 --> 00:24:09,200
in hand with our foundation technologies.

299
00:24:09,200 --> 00:24:14,400
It works beautifully with OpenGL ES, it
sounds great with Core Audio and OpenAL,

300
00:24:14,400 --> 00:24:20,510
it's best friends with core animation, and it is a first
class citizen in our multitasking operating system.

301
00:24:20,510 --> 00:24:23,210
So I am not kidding when I say it is extensive.

302
00:24:23,210 --> 00:24:26,690
We have more than forty new classes
in AV Foundation for you to work with.

303
00:24:26,690 --> 00:24:31,590
I would like to talk to you a little bit about the
media you can access when you are using AV Foundation.

304
00:24:31,590 --> 00:24:36,570
In all of these classes, you can access camera
directly from your-- data directly from the camera,

305
00:24:36,570 --> 00:24:40,800
from your user's camera roll, or from their iPod library.

306
00:24:40,800 --> 00:24:45,200
This means you have direct access to their
media libraries, their asset libraries,

307
00:24:45,200 --> 00:24:48,450
and anything that you save off in your application space.

308
00:24:48,450 --> 00:24:52,480
I would like to take a deeper dive into some of these areas.

309
00:24:52,480 --> 00:24:57,550
We are really proud of the new camera on iPhone 4,
and we are giving you great access and control to it.

310
00:24:57,550 --> 00:25:03,570
We are giving you frame level access, we are
giving you control over the hardware features,

311
00:25:03,570 --> 00:25:06,720
and we are also giving you drop-in recording API.

312
00:25:06,720 --> 00:25:11,950
To talk a little bit about recording, what you
are going to do is open an AV capture session,

313
00:25:11,950 --> 00:25:16,900
and all you need to do is pick which preset you
would like to record for your application's use.

314
00:25:16,900 --> 00:25:22,280
We have high, medium, and low preset that automatically
adjusts to your users' iPhones, so you do not have to query

315
00:25:22,280 --> 00:25:26,590
and figure out what your aspect ratio should
be or what the right bit rate should be.

316
00:25:26,590 --> 00:25:30,180
So on an iPhone 4, we will record
16 by 9 high-definition video.

317
00:25:30,180 --> 00:25:35,510
And on the iPhone 3GS will record
standard definition 640 by 480 video.

318
00:25:35,510 --> 00:25:39,120
We also allow you to record stills
using the AV capture session.

319
00:25:39,120 --> 00:25:43,800
You can record in JPEG format, and we also
allow you to record in-- uncompressed.

320
00:25:43,800 --> 00:25:50,590
We are going to record that in the native format for
your user's iPhone for maximal hardware acceleration.

321
00:25:50,590 --> 00:25:56,680
So in iPhone 4, that is five megapixels of uncompressed
data for you to work with in your photography applications.

322
00:25:56,680 --> 00:26:00,140
We give you excellent device control.

323
00:26:00,140 --> 00:26:05,400
On all iPhones, you can set the point of
interest for exposure and for white balance.

324
00:26:05,400 --> 00:26:10,690
I'm really looking forward to seeing what you guys do with
HDR and various kinds of image processing applications.

325
00:26:10,690 --> 00:26:18,460
We also, on an iPhone 3GS and an iPhone 4, give you access
to set the focal point or the interest point for the focus.

326
00:26:18,460 --> 00:26:24,160
And on iPhone 4, you can choose between your cameras
and whether or not you would like to enable the flash.

327
00:26:24,160 --> 00:26:28,400
All of these functionalities are available
in automatic mode, just like our camera uses,

328
00:26:28,400 --> 00:26:32,390
or in manual mode if you would like to
set that within your own application.

329
00:26:32,390 --> 00:26:36,440
You guys have also shown tremendous access in
working with the data live off of the camera

330
00:26:36,440 --> 00:26:39,990
as a live source of information for your application.

331
00:26:39,990 --> 00:26:43,040
And in iOS 4, you have got it.

332
00:26:43,040 --> 00:26:47,240
What we are doing is giving you direct and
unfettered access to the frame streaming directly off

333
00:26:47,240 --> 00:26:49,700
of the camera to process and work with as you wish.

334
00:26:49,700 --> 00:26:53,770
So this is great for things like object
tracking, it is great for bar code scanners,

335
00:26:53,770 --> 00:26:56,150
and it is really great for augmented reality.

336
00:26:56,150 --> 00:26:56,510
[ Applause ]

337
00:26:56,510 --> 00:27:05,660
>> So we thought we put together a little demo for you.

338
00:27:05,660 --> 00:27:07,600
So what we have got is an iPhone 4.

339
00:27:07,600 --> 00:27:12,890
We are using the capture classes to put up a live
preview of the data streaming off of the camera.

340
00:27:12,890 --> 00:27:16,800
In addition, we are doing image processing
on all of those frames to look for this tag.

341
00:27:16,800 --> 00:27:21,490
And this tag is really just a unique black and white
bar code that we have coded into our application.

342
00:27:21,490 --> 00:27:25,520
You will see that when David moves
it into frame, and you can see it,

343
00:27:25,520 --> 00:27:30,610
we are pegging this OpenGL ES 2.0
tower of blocks onto that tag.

344
00:27:30,610 --> 00:27:35,100
We are using that tag and we are doing image
processing on that tag to see it shape.

345
00:27:35,100 --> 00:27:38,530
So we can see it is tilted and we know where the floor is.

346
00:27:38,530 --> 00:27:45,600
So if David tilts the tag, you can see that the blocks
track, moves around the base, so it sticks there.

347
00:27:45,600 --> 00:27:48,650
Mostly, totally live, high frame
rate, and great performance.

348
00:27:48,650 --> 00:27:49,120
[ Applause ]

349
00:27:49,120 --> 00:27:59,630
>> Because our games team put this together,
they could not help but put a physics model in.

350
00:27:59,630 --> 00:28:01,170
So you can actually knock the blocks over.

351
00:28:01,170 --> 00:28:03,210
[ Laughter ]

352
00:28:03,210 --> 00:28:09,190
>> And they're still sticking to the floor, tilt
it, they'll continues sticking to the floor.

353
00:28:09,190 --> 00:28:10,470
It is pretty cool.

354
00:28:10,470 --> 00:28:14,680
I hope this provided some inspiration
for your applications using the camera.

355
00:28:14,680 --> 00:28:19,670
So in iOS 3, we gave you really basic
access to editing on the iPhone.

356
00:28:19,670 --> 00:28:21,910
We basically gave you trim and save.

357
00:28:21,910 --> 00:28:27,800
We have dramatically expanded this inside of AV
Foundation in iOS 4, and we are really proud of our models.

358
00:28:27,800 --> 00:28:31,840
Again, it is professional grade,
frame accurate, access to editing.

359
00:28:31,840 --> 00:28:35,310
And I would like to take you through
a little bit about how that works.

360
00:28:35,310 --> 00:28:38,770
So the first thing you are going to do is
you are going to open an AV composition.

361
00:28:38,770 --> 00:28:43,670
You are going to pick your clips, and then
you are going to set the areas that you like.

362
00:28:43,670 --> 00:28:48,300
Once you do that, you will sequence them into a composition.

363
00:28:48,300 --> 00:28:53,070
Once they are in a composition, you can start working
with them live within the composition, rendering them out.

364
00:28:53,070 --> 00:29:01,240
We have got easy drop in opacity and affine
transforms for great transitions, super easy to use.

365
00:29:01,240 --> 00:29:02,690
We also love Core Animation.

366
00:29:02,690 --> 00:29:08,650
So if you want to do something a little more custom, titling
your own transition, you can do that too, lay those in.

367
00:29:08,650 --> 00:29:12,770
And again, we really like audio here in this group.

368
00:29:12,770 --> 00:29:14,740
So you can do all kinds of things with audio.

369
00:29:14,740 --> 00:29:20,460
It is professional grade, you can lay in a new track, you
can mix down the existing tracks, you can pass them through,

370
00:29:20,460 --> 00:29:22,630
you can overlay an audio track if you like.

371
00:29:22,630 --> 00:29:24,290
It is pretty cool.

372
00:29:24,290 --> 00:29:30,180
So once you have that composition, you probably
want to be able to play it back in preview.

373
00:29:30,180 --> 00:29:34,880
We have high performance, beautiful
playback engine on iPhone.

374
00:29:34,880 --> 00:29:44,780
Since iPhone 1.0, we have been compositing beautiful,
animated, blended alpha user interface on top of this.

375
00:29:44,780 --> 00:29:49,690
It sticks to your fingers, operates
completely in real time, does not drop frames.

376
00:29:49,690 --> 00:29:53,550
This is really important to us, and we are very
glad in iOS to extend that capability to you.

377
00:29:53,550 --> 00:29:56,180
Now, how do you do that?

378
00:29:56,180 --> 00:29:58,080
You do that by picking up an AV player.

379
00:29:58,080 --> 00:30:04,580
AV player is the way you inspect your media,
understand its structure, and work with your media.

380
00:30:04,580 --> 00:30:10,680
You can observe and control your playback state,
you can enable and disable tracks, you can set in

381
00:30:10,680 --> 00:30:13,790
and out points, you can even control your playback rate.

382
00:30:13,790 --> 00:30:19,110
So now, you have got a whole lot of information
about your media and the ability to control it.

383
00:30:19,110 --> 00:30:23,160
>> The next thing you want to do is
probably lay in a custom control.

384
00:30:23,160 --> 00:30:28,590
Now, the way we do this is that all of our media
plays directly back into a Core Animation layer.

385
00:30:28,590 --> 00:30:31,760
It is a first class citizen in
your Core Animation rendered tree.

386
00:30:31,760 --> 00:30:35,330
So you can draw your own custom controls, track it on in,

387
00:30:35,330 --> 00:30:38,510
and then you can use something
that we call AV Synchronized layer.

388
00:30:38,510 --> 00:30:40,740
We think AV Synchronized layer is super cool.

389
00:30:40,740 --> 00:30:45,780
What this does-- if you will bear with me a minute--
is you can take the time base of your movie and use it

390
00:30:45,780 --> 00:30:50,610
to drive the animation of your core
animation layer tree or subtree.

391
00:30:50,610 --> 00:30:56,010
And what this means is that no matter what is going on,
whether your user is playing back and forward, backward,

392
00:30:56,010 --> 00:31:03,210
scrubbing, you can peg exactly the animation point
you want in your UI to that spot in the movie.

393
00:31:03,210 --> 00:31:04,980
We put together a little bit of demo to show you this.

394
00:31:04,980 --> 00:31:05,900
We call it CoverPlay.

395
00:31:05,900 --> 00:31:08,390
We took the movie that Randy made
this morning in the keynote.

396
00:31:08,390 --> 00:31:10,910
That is 720P full frame rate video.

397
00:31:10,910 --> 00:31:10,970
[ Background Music ]

398
00:31:10,970 --> 00:31:14,960
>> We can start it playing.

399
00:31:14,960 --> 00:31:19,990
So what we have done is we have used the AV Asset Image
Generator to pull out all of the key frames from that movie

400
00:31:19,990 --> 00:31:22,590
and lay each one of them into their own layer.

401
00:31:22,590 --> 00:31:25,400
We are using AV player to play
back the main movie, full frame,

402
00:31:25,400 --> 00:31:29,600
and then we are using Core Animation
to animate those layers of thumbnails.

403
00:31:29,600 --> 00:31:33,460
And those layers of thumbnails are
actually our scrubber bar for this movie.

404
00:31:33,460 --> 00:31:38,400
These thumbnails stick to the same spot in the
movie at all times, and the way that works is

405
00:31:38,400 --> 00:31:42,150
that the user input gesture is
controlling the time base of the movie.

406
00:31:42,150 --> 00:31:47,280
The time base of the movie is then controlling
that animation using an AV Synchronized layer.

407
00:31:47,280 --> 00:31:48,900
I think this is pretty cool.

408
00:31:48,900 --> 00:31:55,430
Our users love to share their media, and we want
to make it really easy for you to help them.

409
00:31:55,430 --> 00:31:58,960
So what we have got is a set of AV export sessions.

410
00:31:58,960 --> 00:32:01,250
Again, just like in recording, we have presets.

411
00:32:01,250 --> 00:32:06,180
You can choose high, medium, and low, and we will
keep track of what kind of phone your user has.

412
00:32:06,180 --> 00:32:08,760
We also will allow you to pass through tracks.

413
00:32:08,760 --> 00:32:13,880
We can set trim on pass through tracks, or
enable or disable any particular track you like.

414
00:32:13,880 --> 00:32:15,860
So it is pretty flexible.

415
00:32:15,860 --> 00:32:19,340
We also have fantastic support from
metadata in our export classes.

416
00:32:19,340 --> 00:32:23,470
We support ID3, iTunes, and Quicktime metadata.

417
00:32:23,470 --> 00:32:30,180
We will propagate your data from source to destination,
we will allow you to add or edit metadata as you like,

418
00:32:30,180 --> 00:32:34,230
you can even do something like take
your core location, get your GPS data,

419
00:32:34,230 --> 00:32:38,900
and lay that into the Quicktime metadata
location inside of a movie track.

420
00:32:38,900 --> 00:32:43,280
I challenged the AV Foundation team to make a
demo that uses many of these classes as we could.

421
00:32:43,280 --> 00:32:45,360
So what they built me was a knock, knock joke generator.

422
00:32:45,360 --> 00:32:47,740
I am not sure if they were trying to tell me something.

423
00:32:47,740 --> 00:32:50,670
But what you have got here is a series of movies.

424
00:32:50,670 --> 00:32:54,260
Each of them has a thumbnail, and a set of themes.

425
00:32:54,260 --> 00:32:57,000
And what we are going to do is [inaudible]--
I have not seen Roger in a couple of days.

426
00:32:57,000 --> 00:32:59,180
Let us get him to tell us a joke.

427
00:32:59,180 --> 00:33:06,630
This is going to use AV composition to edit
these clips together and play them back.

428
00:33:06,630 --> 00:33:08,540
>> Knock, knock.

429
00:33:08,540 --> 00:33:09,950
>> Who's there?

430
00:33:09,950 --> 00:33:10,140
>> Sam.

431
00:33:10,140 --> 00:33:13,550
>> Sam who?

432
00:33:13,550 --> 00:33:16,260
>> Sam Francisco, here I come.

433
00:33:16,260 --> 00:33:16,700
[ Laughter ]

434
00:33:16,700 --> 00:33:18,110
>> You guys like the joke?

435
00:33:18,110 --> 00:33:18,890
[ Cheering ]

436
00:33:18,890 --> 00:33:19,430
>> Okay. Okay.

437
00:33:19,430 --> 00:33:26,860
If we can go back to the beginning, we
will dive into a little more detail.

438
00:33:26,860 --> 00:33:32,670
So what is going on here is when we made these movies, every
engineer read the entire knock, knock joke start to finish.

439
00:33:32,670 --> 00:33:36,240
And then we use the AV Foundation
API to mark the in and out points.

440
00:33:36,240 --> 00:33:39,460
When we use the composition, we are
using the built-in transitions I talked

441
00:33:39,460 --> 00:33:41,310
about to make those cross fades and pushes.

442
00:33:41,310 --> 00:33:43,310
So if you want to do another one,
you guys can watch for that.

443
00:33:43,310 --> 00:33:46,460
>> Knock, knock.

444
00:33:46,460 --> 00:33:47,920
>>> Who's there?

445
00:33:47,920 --> 00:33:49,820
>> Interrupting cow.

446
00:33:49,820 --> 00:33:53,020
>> Interrupting cow moo.

447
00:33:53,020 --> 00:33:54,820
[ Laughter ]

448
00:33:54,820 --> 00:34:00,130
>> That sounds like a thumbs down.

449
00:34:00,130 --> 00:34:00,300
[ Booing ]

450
00:34:00,300 --> 00:34:03,070
>> Finally, they really wanted to
show off the power of Core Animation

451
00:34:03,070 --> 00:34:06,520
and how well it integrates with
all of the AV Foundation classes.

452
00:34:06,520 --> 00:34:10,070
So in this middle reel, what you have
got is a series of clip art and a series

453
00:34:10,070 --> 00:34:12,630
of descriptions of the Core Animation transitions.

454
00:34:12,630 --> 00:34:16,040
When you watch this next movie playback,
you will see the badges dancing.

455
00:34:16,040 --> 00:34:21,760
All of those are rendering live at full frame rate
on top of 720P video that we took on iPhone 4.

456
00:34:21,760 --> 00:34:24,080
One more joke.

457
00:34:24,080 --> 00:34:26,250
>> Knock, knock.

458
00:34:26,250 --> 00:34:27,620
>> Who's there?

459
00:34:27,620 --> 00:34:29,820
>> Candice.

460
00:34:29,820 --> 00:34:31,520
>> Candice who?

461
00:34:31,520 --> 00:34:33,200
>> Candice be the last knock, knock joke?

462
00:34:33,200 --> 00:34:33,260
[ Laughter ]

463
00:34:33,260 --> 00:34:33,400
>> Yeah, okay.

464
00:34:33,400 --> 00:34:33,490
[ Cheering ]

465
00:34:33,490 --> 00:34:42,030
>> So those arms are animated in
and out with Core Animation.

466
00:34:42,030 --> 00:34:44,350
We also created some custom playback controls.

467
00:34:44,350 --> 00:34:48,030
We have got a play button, a rewind button,
a scrubber, and even a share button.

468
00:34:48,030 --> 00:34:53,090
Maybe we will save off the metadata about
whether you like the joke before we send it out.

469
00:34:53,090 --> 00:34:56,140
[ Applause ]

470
00:34:56,140 --> 00:34:59,700
>> So I wanna talk for just a moment about multitasking.

471
00:34:59,700 --> 00:35:01,880
It is one of my favorite features in iOS 4.

472
00:35:01,880 --> 00:35:04,060
I think it is hugely powerful.

473
00:35:04,060 --> 00:35:08,270
We built the AV Foundation classes hand
in hand with the multitasking system,

474
00:35:08,270 --> 00:35:13,570
so that your users will get the behaviors
they expect with the media system.

475
00:35:13,570 --> 00:35:19,690
Just like audio sessions, you can set your multitasking
category directly inside the AV foundation API,

476
00:35:19,690 --> 00:35:25,020
and we will take of starting and stopping
system services for you as your users expect.

477
00:35:25,020 --> 00:35:27,250
So for instance, we do not allow
you to record in the backgrounds,

478
00:35:27,250 --> 00:35:29,840
so we will shut down the camera
preview and bring it back up.

479
00:35:29,840 --> 00:35:33,040
You do not have to keep track of that.

480
00:35:33,040 --> 00:35:38,120
We will maintain a list of what is changed in the state
of your application while your users multitask out,

481
00:35:38,120 --> 00:35:41,600
provide that information back to you
when your user comes back into your app,

482
00:35:41,600 --> 00:35:44,610
so you can update your user interface to match.

483
00:35:44,610 --> 00:35:49,380
We have also enabled export in the
background, which is pretty cool.

484
00:35:49,380 --> 00:35:52,780
So AV Foundation, we have more than forty new classes.

485
00:35:52,780 --> 00:35:58,350
We have great access to the camera and control over
it, we have professional grade editing services

486
00:35:58,350 --> 00:36:02,750
that are frame accurate, we have performed
a playback, and easy to use export.

487
00:36:02,750 --> 00:36:05,570
We are really excited about AV Foundation.

488
00:36:05,570 --> 00:36:11,880
So I would like to change tracks for a
moment and talk about HTTP Live Streaming,

489
00:36:11,880 --> 00:36:15,000
which is something pretty near and dear to my heart.

490
00:36:15,000 --> 00:36:22,490
Last year, we stood up on stage with our friends
from CNN and MLB as we introduced our open standard

491
00:36:22,490 --> 00:36:27,130
for high-quality, internet-based streaming media.

492
00:36:27,130 --> 00:36:32,020
They showed you an introduction to what
they were planning to ship with iOS 3.

493
00:36:32,020 --> 00:36:34,700
And in the last year, your response has been overwhelming.

494
00:36:34,700 --> 00:36:38,940
These are just a few of the folks who have
fantastic applications up in the store.

495
00:36:38,940 --> 00:36:43,370
Our folks-- our friends in the broadcast
industry who have signed up as well, inlet--

496
00:36:43,370 --> 00:36:47,310
has got built-in support for streaming
media and their encoder boxes

497
00:36:47,310 --> 00:36:51,130
and optimized streaming a ton of
data over the network everyday.

498
00:36:51,130 --> 00:36:58,950
So to review how HTTP Live Streaming works, I would
like you take-- take you through a few of the features.

499
00:36:58,950 --> 00:37:00,400
At its heart, it is adaptive.

500
00:37:00,400 --> 00:37:04,350
We are serving you the bits you need
for the feed that matches your speed.

501
00:37:04,350 --> 00:37:07,660
We are continuously analyzing your user's bandwidth

502
00:37:07,660 --> 00:37:11,700
and determining what the highest speed they can
get that is going to match their bandwidths.

503
00:37:11,700 --> 00:37:15,130
So you get full frame video and seamless audio.

504
00:37:15,130 --> 00:37:20,380
If your network pickups or they change state, they might
drop down the 3G, we will move them to a lower stream

505
00:37:20,380 --> 00:37:25,180
without ever interrupting their audio, or
rebuffering video in a way that they can see.

506
00:37:25,180 --> 00:37:27,980
If your network comes back, we will bring it back up.

507
00:37:27,980 --> 00:37:29,440
This is really, really beautiful.

508
00:37:29,440 --> 00:37:35,120
I am hoping some of you guys have played with NetFlix
on an iPad and seen a little bit about how this works.

509
00:37:35,120 --> 00:37:41,590
Streaming is great for live content, things
like live sporting events and concerts.

510
00:37:41,590 --> 00:37:48,210
It is also great for on-demand content, whether you want
to rebroadcast lectures, watch TV shows, watch a movie.

511
00:37:48,210 --> 00:37:55,950
And we are built on the industry's best standard
codecs for beautiful video and crystal clear audio.

512
00:37:55,950 --> 00:38:00,580
It's the H.264 for video and AAC for audio.

513
00:38:00,580 --> 00:38:05,740
We have stream level encryption to keep your
content partners feeling secure and happy.

514
00:38:05,740 --> 00:38:08,050
And on the networking side, we are built on top of the HTTP.

515
00:38:08,050 --> 00:38:11,660
And that sounds pretty simple,
but it's really pretty profound,

516
00:38:11,660 --> 00:38:17,650
because what it gives us is the maximum
compatibility with the existing web infrastructure.

517
00:38:17,650 --> 00:38:19,320
This makes this really firewall-friendly.

518
00:38:19,320 --> 00:38:24,750
If your users can download a webpage, look at a
webpage, they can probably get you stream without having

519
00:38:24,750 --> 00:38:26,240
to reconfigure their router or their Mac.

520
00:38:26,240 --> 00:38:29,250
I think this is pretty cool.

521
00:38:29,250 --> 00:38:32,830
We have some new features in iOS
4 that we think are fantastic.

522
00:38:32,830 --> 00:38:34,950
The first one is Stream Insertion.

523
00:38:34,950 --> 00:38:41,850
And what this is a programmatic way to inject or add content
to the beginning or in the middle of one of your streams.

524
00:38:41,850 --> 00:38:48,490
This allows you to take a series of bumpers or interstitial
content and inject it into a stream live or on-demand

525
00:38:48,490 --> 00:38:54,530
so that you do not have to burn a copy of that content
into every single stream that you stream to each user.

526
00:38:54,530 --> 00:39:01,140
We handle various frame sizes, different aspect ratios with
no problem, just jump in your trailers and we'll stream

527
00:39:01,140 --> 00:39:05,040
to your users and play them back, and we have
added the ability to include a metadata track.

528
00:39:05,040 --> 00:39:08,820
And you can put whatever data is useful
for your application into that track,

529
00:39:08,820 --> 00:39:11,590
and it will stick to the time base of your movie.

530
00:39:11,590 --> 00:39:17,260
You can put GPS data in, you might want to tie some
slides to a lecture, or inject live player data

531
00:39:17,260 --> 00:39:21,430
or stats if something interesting happens in
the baseball game that you are streaming live.

532
00:39:21,430 --> 00:39:24,470
And we have also got some new tools.

533
00:39:24,470 --> 00:39:28,970
We have given you final segmenter so that you can work
with your existing on-demand content without having

534
00:39:28,970 --> 00:39:34,410
to re-encode it, we have given you a file validator so
that you can make sure that your streams are compliant

535
00:39:34,410 --> 00:39:41,790
and adhering to our best practices, we have also given
you a file index generator to help user posting workflow.

536
00:39:41,790 --> 00:39:43,140
So we also have a demo.

537
00:39:43,140 --> 00:39:46,650
I would like to invite up Matt Johnson from Engaged Sports.

538
00:39:46,650 --> 00:39:51,580
He has been working on an application that he plans to
launch next month that uses a bunch of iOS 4 features.

539
00:39:51,580 --> 00:39:56,620
[ Applause ]

540
00:39:56,620 --> 00:39:57,420
>> Thank you.

541
00:39:57,420 --> 00:40:00,840
At Engaged Sports, we are building new applications

542
00:40:00,840 --> 00:40:06,830
so fans can experience live sporting events
in entirely new ways on their iPhone.

543
00:40:06,830 --> 00:40:09,980
We have a really exciting new app that we
want to demonstrate for you today for one

544
00:40:09,980 --> 00:40:13,900
of the world's largest sporting events, the Tour de France.

545
00:40:13,900 --> 00:40:15,790
>> But first, a quick bit of background.

546
00:40:15,790 --> 00:40:18,930
This project started [inaudible] the passion for cycling.

547
00:40:18,930 --> 00:40:24,030
Also, my day job is running one of the teams that's in
the Tour de France, and they'd been killing us for years

548
00:40:24,030 --> 00:40:31,090
so we'd be at the race, and we really had no
ability to follow the action live on our iPhones.

549
00:40:31,090 --> 00:40:34,200
We've been in development for the
last couple of months on a 3.0 version

550
00:40:34,200 --> 00:40:37,510
of the application when the 4.0 beta was released.

551
00:40:37,510 --> 00:40:43,310
We had a number of features that we dreamed
up, but we now realized were possible with 4.0.

552
00:40:43,310 --> 00:40:46,750
We're really excited to demonstrate some
of those features for you here today.

553
00:40:46,750 --> 00:40:51,010
Joining me on stage is Jay Graves from
our development partner, Double Encore.

554
00:40:51,010 --> 00:40:56,070
And Tour de France is very different than
the traditional stadium sporting experience,

555
00:40:56,070 --> 00:40:59,500
because it turns the entire country
of France into its stadium.

556
00:40:59,500 --> 00:41:06,870
It happens over three weeks every month in
July, and it travels almost 4000 kilometers.

557
00:41:06,870 --> 00:41:11,870
One of the first features we developed
with 4.0 was using MapKit.

558
00:41:11,870 --> 00:41:15,400
One of the things that you want to do when you're
looking at the Tour de France is you want to be able

559
00:41:15,400 --> 00:41:18,120
to follow the action along the race course.

560
00:41:18,120 --> 00:41:22,510
We now have live GPS data streaming
to us from the race as it's happening

561
00:41:22,510 --> 00:41:25,350
that we can now show the user on their iPhone.

562
00:41:25,350 --> 00:41:28,290
At the top of the map here, you
see the start town for this stage.

563
00:41:28,290 --> 00:41:31,420
This is the last year's stage 20 of the Tour de France.

564
00:41:31,420 --> 00:41:34,210
The yellow line indicates the progress the stage has made.

565
00:41:34,210 --> 00:41:41,320
With 4.0 and map overlays, we're able to
integrate this data directly into the Map View.

566
00:41:41,320 --> 00:41:48,290
So both the route that the race is following, the
progress the race has made, as well as the position

567
00:41:48,290 --> 00:41:53,130
of the relative leaders on the race all
integrated into a map overlay later.

568
00:41:53,130 --> 00:41:56,970
And with Core Animation framework,
we're able to pan and zoom,

569
00:41:56,970 --> 00:42:00,980
and our map overlays will animate directly with the map.

570
00:42:00,980 --> 00:42:01,890
Now maps are great.

571
00:42:01,890 --> 00:42:07,930
But when you have a sport as visually exciting as
cycling, you really want to be able to see it live.

572
00:42:07,930 --> 00:42:11,270
With HTTP Live Streaming, we can do exactly that.

573
00:42:11,270 --> 00:42:18,480
And what's really exciting about 4.0 is we have an
entirely new level of control over the video layer.

574
00:42:18,480 --> 00:42:22,170
So one of the first things we did, and
something we'd always want to do for cycling,

575
00:42:22,170 --> 00:42:27,010
was overlay the elevation profile of the race course.

576
00:42:27,010 --> 00:42:32,560
So here, you can see on the left is the start
of the race, and the right is the finish.

577
00:42:32,560 --> 00:42:36,360
And in between, you can see the
elevation games or the climbs or mountains

578
00:42:36,360 --> 00:42:40,020
that the racers will go over during the course.

579
00:42:40,020 --> 00:42:42,670
Now, we can make this come to life.

580
00:42:42,670 --> 00:42:49,860
With synchronized metadata, we're embedding the
live GPS data, the distance the race has traveled,

581
00:42:49,860 --> 00:42:53,310
and the individual position of
the leaders on the race directly

582
00:42:53,310 --> 00:42:58,950
into the video while the video is
still playing live in the background.

583
00:42:58,950 --> 00:43:00,440
Now, the Tour de France is a long race.

584
00:43:00,440 --> 00:43:04,090
It's three weeks long, but each day is also six hours a day.

585
00:43:04,090 --> 00:43:08,620
So there are times I need to leave
the app and go do something else.

586
00:43:08,620 --> 00:43:13,210
Now, you may have all seen what multitasking
and the ability to have background audio,

587
00:43:13,210 --> 00:43:16,590
but you've probably never seen it
done with a video-centric application.

588
00:43:16,590 --> 00:43:19,950
So as you can hear, the audio track
from the race is still playing.

589
00:43:19,950 --> 00:43:28,060
If something exciting happens, I can jump right back in,
and the audio-- video is perfectly in sync with the audio.

590
00:43:28,060 --> 00:43:31,780
So the last feature--

591
00:43:31,780 --> 00:43:37,790
[ Applause ]

592
00:43:37,790 --> 00:43:39,510
>> So if you thought that was something,
this is even better.

593
00:43:39,510 --> 00:43:43,590
So the last feature is something
we've always wanted to do for cycling,

594
00:43:43,590 --> 00:43:50,530
and it really completely changes the user
experience of how you go and watch a bike race.

595
00:43:50,530 --> 00:43:55,300
We've converted that elevation
profile into a video scrubber.

596
00:43:55,300 --> 00:44:00,900
So in case you want to-- you missed some action, you know,
you wanted to go back to the start of a climb or you wanted

597
00:44:00,900 --> 00:44:08,680
to make your own highlights and replay the race later, you
can now scrub along the profile, release, and both the video

598
00:44:08,680 --> 00:44:16,610
and the audio will go perfectly in sync with
that geographical location along the race course.

599
00:44:16,610 --> 00:44:17,980
Thank you very much.

600
00:44:17,980 --> 00:44:24,380
[ Applause ]

601
00:44:24,380 --> 00:44:27,790
>> So I guess I shouldn't go too
far because I'm wrapping up.

602
00:44:27,790 --> 00:44:33,260
HTTP Live Streaming, it's our open protocol for
high quality adaptive media over the internet.

603
00:44:33,260 --> 00:44:37,370
In iOS 4, we brought you new tools, stream
insertion, and synchronized metadata.

604
00:44:37,370 --> 00:44:42,590
And if this is any indication of what you guys are
going to do, I'm really excited to see the next year.

605
00:44:42,590 --> 00:44:45,740
With that, I'd like to bring out Mike
to talk about Game Center for a minute

606
00:44:45,740 --> 00:44:51,020
[ Applause ]

607
00:44:51,020 --> 00:44:56,230
>> There are over 50,000 games and
entertainment titles on the App Store today.

608
00:44:56,230 --> 00:45:02,000
There's no doubt that our platform
offers a revolutionary gaming experience.

609
00:45:02,000 --> 00:45:06,360
Games are huge in our platform, and we
want to make them bigger and better.

610
00:45:06,360 --> 00:45:09,660
Therefore, we're introducing Game Center.

611
00:45:09,660 --> 00:45:17,810
At its core, Game Center is a social gaming network that
enables your games to take advantage about social gaming,

612
00:45:17,810 --> 00:45:21,980
structure, and allows the players to enjoy.

613
00:45:21,980 --> 00:45:25,490
Game Center is actually made up of three pieces.

614
00:45:25,490 --> 00:45:28,350
One piece is a Game Center application.

615
00:45:28,350 --> 00:45:35,470
Game Center application is used for people to discover
new Game Center games, to make new Game Center friends,

616
00:45:35,470 --> 00:45:40,800
and to compare their progress versus their friends.

617
00:45:40,800 --> 00:45:46,970
Game Center also includes a powerful
and flexible framework called Game Kit.

618
00:45:46,970 --> 00:45:53,270
Now, Game Kit is what your apps use to take advantage
of the features we're again talk about today.

619
00:45:53,270 --> 00:45:59,240
Game Kit is also tightly coupled
with our Game Center services.

620
00:45:59,240 --> 00:46:05,470
Our Game Center services are a flexible,
scalable set of services that really fast.

621
00:46:05,470 --> 00:46:12,600
And what they do is they bring the people to your
games so that your games can enjoy all the people

622
00:46:12,600 --> 00:46:17,380
in our social gaming network and have great time.

623
00:46:17,380 --> 00:46:19,760
I wan to talk about some of the features in Game Center.

624
00:46:19,760 --> 00:46:21,640
So, one of them is Leaderboards.

625
00:46:21,640 --> 00:46:27,080
Now, Leaderboards are great way for players to
compare how they're doing versus everybody else

626
00:46:27,080 --> 00:46:29,760
in their-- in your game all over the world.

627
00:46:31,050 --> 00:46:38,150
Our servers take care of storing, sorting, and filtering
all the Leaderboard information you send up to us,

628
00:46:38,150 --> 00:46:42,610
and giving it back to you at the appropriate
time and in the appropriate format.

629
00:46:42,610 --> 00:46:49,040
We've made it really easy for you with a few simple lines
of code, to have one or more Leaderboards to your game.

630
00:46:49,040 --> 00:46:54,650
Whether your game is a single-player game or multiplayer
game, you can take advantage of the Leaderboards.

631
00:46:54,650 --> 00:46:57,610
Every Leaderboard comes with a couple of built in filters.

632
00:46:57,610 --> 00:47:01,800
There are filters for friends and
everyone, and there's still just for time

633
00:47:01,800 --> 00:47:06,120
for today, this week, this-- and all time.

634
00:47:07,910 --> 00:47:14,110
We also provide a basic UI, standard UI, you can use to
make it really easy to add Leaderboards to your game,

635
00:47:14,110 --> 00:47:20,510
or you can choose to customize the look of your
Leaderboards to make them fully immersive within your game.

636
00:47:20,510 --> 00:47:24,090
I think it's a great feature that
we've made super easy to use.

637
00:47:24,090 --> 00:47:28,790
I want to talk about the next feature
now, which is Achievements.

638
00:47:28,790 --> 00:47:33,930
Achievements are a way for rewarding a
player for accomplishing a goal in your game.

639
00:47:33,930 --> 00:47:41,190
It adds depth to any game, whether your game is a
racing game, a strategy game, a first person shooter,

640
00:47:41,190 --> 00:47:45,300
it doesn't really matter, Achievements
add a whole another dimension to the game.

641
00:47:45,300 --> 00:47:49,980
The completionist will want to collect
every single one of your achievements,

642
00:47:49,980 --> 00:47:55,960
and everyone will enjoy comparing their
progress in your game versus their friends.

643
00:47:57,580 --> 00:48:02,620
Just like with the Leaderboards, we've provide a standard
UI you can use so that Achievements look the same

644
00:48:02,620 --> 00:48:05,580
within your game as they do in our Game Center app.

645
00:48:05,580 --> 00:48:12,430
Or you can customize the user interface so
that it fit seamlessly within your game.

646
00:48:12,430 --> 00:48:14,200
That's Achievements.

647
00:48:14,200 --> 00:48:20,390
And I want to talk about another feature
I'm really excited about, Multiplayer.

648
00:48:20,390 --> 00:48:26,510
We've taken something that's normally very, very
complicated and difficult to do and made it simple.

649
00:48:26,510 --> 00:48:32,200
So the first part of Multiplayer I want
to talk about are game invitations.

650
00:48:32,200 --> 00:48:39,280
So with iOS 3, we introduced push authentications,
real powerful system to get a message to any device.

651
00:48:39,280 --> 00:48:43,210
We leveraged that with our game invitations.

652
00:48:43,210 --> 00:48:49,020
So now, when a player invites their friend to play
a game, that friend will get a push notification.

653
00:48:49,020 --> 00:48:53,010
Whatever they're doing, wherever they are,
they get a push authentication to play the game

654
00:48:53,010 --> 00:48:57,940
with optional personalized message,
and here, they can accept the game.

655
00:48:57,940 --> 00:49:01,720
They accept it, launches the game,
they play Multiplayer game,

656
00:49:01,720 --> 00:49:06,480
but we also recognize that not everybody has the same games.

657
00:49:06,480 --> 00:49:09,300
So in this case, if I invite one of my friends

658
00:49:09,300 --> 00:49:21,000
and my friend doesn't have the game I'm inviting
him to, they'll still get a push notification--

659
00:49:21,000 --> 00:49:21,060
[ Applause ]

660
00:49:21,060 --> 00:49:24,140
>> -- but in this case, we replace the
Accept button with an App Store button.

661
00:49:24,140 --> 00:49:30,790
So it allows him to go to the App Store, purchase
the game, and then play with the person inviting him.

662
00:49:30,790 --> 00:49:34,860
This is a great way for your game to
leverage our social gaming network

663
00:49:34,860 --> 00:49:39,210
and increase the distribution and visibility of your game.

664
00:49:39,210 --> 00:49:44,970
We have a lot of features like this built
into Game Center, and this is just one.

665
00:49:44,970 --> 00:49:48,300
But this gets us friends inviting friends.

666
00:49:48,300 --> 00:49:53,740
We want to make so that any Game Center players
can play against any other Game Center player.

667
00:49:53,740 --> 00:49:57,810
So we introduced this great feature called Auto-matching.

668
00:49:57,810 --> 00:50:00,140
Let me talk about what Auto-matching is.

669
00:50:00,140 --> 00:50:08,490
What Auto-matching does is players who want to
play your game in an auto-match, they let us know,

670
00:50:08,490 --> 00:50:14,400
and it goes up to our server, our server takes all the
people all over the world asking to be matched to your game,

671
00:50:14,400 --> 00:50:18,570
figures out the best possible groupings
of matches out of all those people,

672
00:50:18,570 --> 00:50:21,100
and returns that information back to your game.

673
00:50:21,100 --> 00:50:31,230
>> It's really fast, it's really simple, our
servers take care of all the complex work here.

674
00:50:31,230 --> 00:50:38,630
So Auto-matching is a great way for anybody to
be matched with anybody, and we also add a way--

675
00:50:38,630 --> 00:50:43,330
we realize that even though we think our logic
is really great for putting people together,

676
00:50:43,330 --> 00:50:45,530
every game has its own set of requirements.

677
00:50:45,530 --> 00:50:48,940
So we've also offered some flexible API's for you

678
00:50:48,940 --> 00:50:53,790
to tell our service exactly how you want
to-- the players to be matched for your game.

679
00:50:53,790 --> 00:50:57,620
That way, we return the exact proper
matching your game requires.

680
00:50:57,620 --> 00:51:00,440
[ Applause ]

681
00:51:00,440 --> 00:51:04,170
>> So, now we found the people for your game.

682
00:51:04,170 --> 00:51:10,130
Another very difficult thing normally in multiplayer games
is connecting the devices so they can talk to each other.

683
00:51:10,130 --> 00:51:13,830
We also offer the peer to peer connectivity.

684
00:51:13,830 --> 00:51:20,300
Now, when we find the players, we will connect
them over Wi-Fi or 3G on a peer to peer network,

685
00:51:20,300 --> 00:51:26,380
we have a real simple API for doing this to make--
take all the complexity out of this process.

686
00:51:26,380 --> 00:51:29,320
So now, we got a game.

687
00:51:29,320 --> 00:51:33,680
We've taken the people, we found them, we've
matched them together, and they're talking.

688
00:51:33,680 --> 00:51:38,480
But if you're like me, when I'm playing a Multiplayer
game, I like to talk to the people I'm playing with.

689
00:51:38,480 --> 00:51:42,960
I like to strategize, I like to trash talk, whatever.

690
00:51:42,960 --> 00:51:45,760
And so, we've introduced in-game voice chat.

691
00:51:45,760 --> 00:51:51,220
[ Applause ]

692
00:51:51,220 --> 00:51:56,520
>> This is tightly coupled to our-- all
of our matching and our peer to peer.

693
00:51:56,520 --> 00:51:58,600
So it works almost seamlessly.

694
00:51:58,600 --> 00:52:03,430
Few simple lines of code, your game can have
everybody in the game, talking to each other.

695
00:52:03,430 --> 00:52:08,310
Or if you want, you can have team A talking amongst
themselves and team B talking amongst themselves.

696
00:52:08,310 --> 00:52:11,920
There's a lot of flexibility in here
for your games to take advantage of.

697
00:52:11,920 --> 00:52:16,410
So I just want to go over, there's-- Game
Center's made up of three main pieces.

698
00:52:16,410 --> 00:52:25,740
Our Game Center application, the Game Kit framework, the
Game Center services, and all those provide these features

699
00:52:25,740 --> 00:52:29,720
and more, Leaderboards, Achievements,
Invites, Auto-matching,

700
00:52:29,720 --> 00:52:32,510
peer to peer connectivity, and in-game voice chat.

701
00:52:32,510 --> 00:52:40,100
Right now, Game Center is available as a developer preview
and will be available to the general public later this year.

702
00:52:40,100 --> 00:52:40,280
Thank you.

703
00:52:40,280 --> 00:52:40,340
[ Applause ]

704
00:52:40,340 --> 00:52:40,620
>> Back to you, John.

705
00:52:40,620 --> 00:52:48,980
>> That's just fantastic stuff, isn't it?

706
00:52:48,980 --> 00:52:52,610
We're really happy about what we've
been able to do in iOS 4.

707
00:52:52,610 --> 00:53:00,000
So we've gone over a little bit of OpenGL ES, AV
foundation, HTTP Live Streaming, and Game Center,

708
00:53:00,000 --> 00:53:04,150
and the new features and innovations
we're bringing to iOS 4.

709
00:53:04,150 --> 00:53:07,740
And to bring that together, we want to do something fun.

710
00:53:07,740 --> 00:53:09,700
We, at Apple, built a technology demo.

711
00:53:09,700 --> 00:53:15,180
It's a game that brings a bunch of these
technologies together into a really interesting demo.

712
00:53:15,180 --> 00:53:19,920
It's a demo that we're gonna be using through
some of the sessions this week, and teaching you

713
00:53:19,920 --> 00:53:25,790
and showing you how we use these technologies,
and how we incorporate them into an application.

714
00:53:25,790 --> 00:53:31,070
So with that, I'm going to bring Graeme Devine up, and we're
going to look at a demo-- a technology demo called Quest.

715
00:53:31,070 --> 00:53:37,490
>> I'm really, really proud to be here today to
give you, well, the world's first preview of Quest.

716
00:53:37,490 --> 00:53:43,740
We spent the last couple of months at Apple writing
a highly performant game prototype that runs on all

717
00:53:43,740 --> 00:53:50,270
of Apple's embedded platforms at 40 to 60 frames
per second using Apple frameworks and technologies.

718
00:53:50,270 --> 00:53:56,070
So let's jump in and take a look.

719
00:53:56,070 --> 00:53:58,960
One of the things we did is integrate Game Center.

720
00:53:58,960 --> 00:54:03,640
But one of the things we also did was on
this iPhone 4, it is made of resolution.

721
00:54:03,640 --> 00:54:08,410
So let's see if we can zoom in and just
take a look at this gorgeous display.

722
00:54:08,410 --> 00:54:15,300
That is full frame OpenGL ES 2.0 on
top of a Cocoa Touch user interface.

723
00:54:15,300 --> 00:54:22,250
It logged in to Game Kit and it uses AV Foundation
to provide a three dimensional sound environment,

724
00:54:22,250 --> 00:54:28,970
because a lot of people play games with the headphones
on, and we wanna be able to provide them environment.

725
00:54:28,970 --> 00:54:31,620
So let's take a look at my Achievements.

726
00:54:32,630 --> 00:54:36,020
You see that is a Core Animation flip.

727
00:54:36,020 --> 00:54:40,630
By using Cocoa Touch to drive all
of my UI, I can easily in--

728
00:54:40,630 --> 00:54:45,830
a few lines of code, just do large flips
like that and flip around the display.

729
00:54:45,830 --> 00:54:50,720
You can see, I've not quite run-- I've not
quite won the demon slayer achievement,

730
00:54:50,720 --> 00:54:52,620
so I think you can see where this demo is going.

731
00:54:52,620 --> 00:54:57,520
So let's sit down and lets dive in.

732
00:54:58,820 --> 00:55:03,080
Now, the Quest environment is lit per pixel.

733
00:55:03,080 --> 00:55:08,790
As the character runs around and runs into areas
and out of areas, the world around him affects him.

734
00:55:08,790 --> 00:55:18,890
The world itself is around 50,000 triangles, putting a
few million triangles per second on each of our platforms.

735
00:55:18,890 --> 00:55:24,920
As he runs through the red area, you can see that
he is getting lit by the environment around him,

736
00:55:24,920 --> 00:55:28,180
and the environment around the character is affecting him.

737
00:55:28,180 --> 00:55:36,400
One of the other things that we did--

738
00:55:36,400 --> 00:55:36,690
[ Applause ]

739
00:55:36,690 --> 00:55:37,860
>> Thank you.

740
00:55:37,860 --> 00:55:43,110
But the other thing that we did was
we are using the GPU on our devices

741
00:55:43,110 --> 00:55:47,170
to animate using skeletal animation and skinning.

742
00:55:47,170 --> 00:55:50,550
He is completely running on the GPU.

743
00:55:50,550 --> 00:55:52,090
A lot of talks this week about how we're doing that.

744
00:55:52,090 --> 00:55:58,940
But one of the other things we wanted to do with Cocoa Touch
was really make our environment interactive touching the

745
00:55:58,940 --> 00:55:59,950
world around you.

746
00:55:59,950 --> 00:56:06,080
So if touch my character, I can make up a contextual menu
and I can do all sorts of things to my contextual menu.

747
00:56:06,080 --> 00:56:11,200
But if I slide to the right, I can call in my pet [noise].

748
00:56:11,200 --> 00:56:18,280
And then if I touch again on top of my contextual menu, the
environment-- that contextual menu has completely changed.

749
00:56:18,280 --> 00:56:20,460
It's changed because of my character.

750
00:56:20,460 --> 00:56:22,900
My character now has his little robot friend.

751
00:56:22,900 --> 00:56:25,190
So the menu is completely changed.

752
00:56:25,190 --> 00:56:27,190
So that's how you dismiss him.

753
00:56:28,580 --> 00:56:35,250
And you can see, I'm still able to run around, I'm
going to [noise]-- I think the demon is pretty hungry.

754
00:56:35,250 --> 00:56:39,120
So maybe we'll have to have a bash on him.

755
00:56:39,120 --> 00:56:43,880
So by interacting with the demon and pressing on top
of the demon, I can actually start the fight [noise],

756
00:56:43,880 --> 00:56:49,890
making the world interactive, I want to interact
with that demon and fight him right now.

757
00:56:49,890 --> 00:56:53,070
The text lying off there is all Cocoa Touch again.

758
00:56:53,070 --> 00:56:58,890
Everything in the user interface is running
on top of OpenGL ES 2.0 using Cocoa Touch.

759
00:56:58,890 --> 00:57:00,320
We didn't write our own UI at all.

760
00:57:00,320 --> 00:57:01,200
[ Applause ]

761
00:57:01,200 --> 00:57:12,150
>> And I got that achievement.

762
00:57:12,150 --> 00:57:13,030
Let's do one more thing.

763
00:57:13,030 --> 00:57:14,850
Let's touch in the character's face.

764
00:57:14,850 --> 00:57:16,710
I used to put him on a drive home.

765
00:57:16,710 --> 00:57:20,280
This Cocoa Touch interface and how
integrated it is to the game environment.

766
00:57:20,280 --> 00:57:24,530
By taking the game and skinning in such a way that
it looks like it's part of the game environment,

767
00:57:24,530 --> 00:57:29,300
I can't tell the difference between
the game and the interface.

768
00:57:29,300 --> 00:57:34,320
But to our game players, it is exactly the
familiar interface they use on the hundreds

769
00:57:34,320 --> 00:57:36,990
of thousands of other iPhone app that are out there.

770
00:57:36,990 --> 00:57:41,410
There is no difference between this
application and the photos application.

771
00:57:41,410 --> 00:57:42,370
We just skinned the UI.

772
00:57:42,370 --> 00:57:48,480
So let's press done and quit on out.

773
00:57:48,480 --> 00:57:49,460
Thank you.

774
00:57:49,460 --> 00:57:52,770
[ Applause ]

775
00:57:52,770 --> 00:57:54,170
>> Thank you, Graeme.

776
00:57:56,970 --> 00:58:01,550
So we talked about just a few technologies
available in the Graphics and Media frameworks.

777
00:58:01,550 --> 00:58:03,960
We have a wealth of technology for you to use.

778
00:58:03,960 --> 00:58:07,720
I encourage you to go learn about all of them.

779
00:58:07,720 --> 00:58:13,600
And we have 26 sessions this week just
on the graphics and media technologies.

780
00:58:13,600 --> 00:58:15,940
And we have 24 labs.

781
00:58:15,940 --> 00:58:21,020
The labs are really useful for you to be able to
go and ask the hard questions to the engineers

782
00:58:21,020 --> 00:58:24,260
who actually wrote these things, these frameworks.

783
00:58:24,260 --> 00:58:28,400
They will be there to answer all your
questions, so we encourage you to go to these.

784
00:58:28,400 --> 00:58:30,280
With that, thank you and enjoy your week.

