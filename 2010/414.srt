1
00:00:06,360 --> 00:00:08,240
>> My name is Dan Omachi.

2
00:00:08,240 --> 00:00:13,440
I work for the Apples GPU Software Team
on the OpenGL Framework for Mac OS X,

3
00:00:13,440 --> 00:00:17,740
as well as the OpenGL ES Framework on iOS 4.

4
00:00:17,740 --> 00:00:21,140
I hope you guys are here today, because you'd really

5
00:00:21,140 --> 00:00:27,560
like to add some stunning visual
effects to your Mac or iOS applications.

6
00:00:27,560 --> 00:00:32,950
Perhaps you thought of adding some shadows,
reflections, or refractions into your app.

7
00:00:32,950 --> 00:00:34,800
Maybe you've heard of some advanced techniques,

8
00:00:34,800 --> 00:00:39,420
such as parallax occlusion mapping,
tone mapping, or deferred shading.

9
00:00:39,420 --> 00:00:45,870
I'm not going to be talking so much about those advanced
techniques today, however, I am going to be talking

10
00:00:45,870 --> 00:00:53,060
about some essential design practices that you'll need
to consider in your applications if you want to add

11
00:00:53,060 --> 00:00:58,590
such advanced techniques, or invent
your own techniques using OpenGL.

12
00:01:00,970 --> 00:01:03,380
So what is OpenGL?

13
00:01:03,380 --> 00:01:07,590
So many of you know OpenGL as a 3D graphics API.

14
00:01:07,590 --> 00:01:11,720
The OpenGL specification, which is
the definitive document on OpenGL,

15
00:01:11,720 --> 00:01:16,960
actually has what I think is a
slightly more accurate definition.

16
00:01:16,960 --> 00:01:21,310
OpenGL is a software interface to graphics hardware.

17
00:01:21,310 --> 00:01:24,680
In other words, it's an interface
with a graphics processing unit.

18
00:01:24,680 --> 00:01:32,350
Every device that ships with iOS 4 and
Mac OS X has a pretty capable GPU on it.

19
00:01:32,350 --> 00:01:35,440
So what does this GPU do?

20
00:01:35,440 --> 00:01:42,300
Well, many people believe that the GPU is
just there to make your graphics look good.

21
00:01:42,300 --> 00:01:47,910
Actually, you can make some pretty high
quality renderers using just the CPU.

22
00:01:47,910 --> 00:01:50,300
Movie studios do this all the time.

23
00:01:50,300 --> 00:01:54,760
They make very high quality renderers,
and you see some great special effects.

24
00:01:54,760 --> 00:02:00,530
However, their renderers take many,
many minutes to render a single frame.

25
00:02:00,530 --> 00:02:03,510
This isn't so good for an interactive application.

26
00:02:03,510 --> 00:02:05,610
So what does the GPU do?

27
00:02:05,610 --> 00:02:07,280
It accelerates your rendering.

28
00:02:07,280 --> 00:02:12,130
And when you're talking about interactive
frame rates, this matters.

29
00:02:12,130 --> 00:02:16,070
Faster rendering equals better image quality.

30
00:02:16,070 --> 00:02:23,540
Drawing efficiently, allows drawing more: more models,
more vertices in those models, more pixels, longer shaders,

31
00:02:23,540 --> 00:02:27,120
better special effects in your application.

32
00:02:27,120 --> 00:02:29,010
All at an interactive frame rate.

33
00:02:29,010 --> 00:02:33,210
All right, so what will you learn today?

34
00:02:33,210 --> 00:02:40,090
So let's say you've got a Formula One car and just because
you've got it you've driven to work every day doesn't mean

35
00:02:40,090 --> 00:02:44,100
that you're going to be winning any Formula
One races or even qualifying for them,

36
00:02:44,100 --> 00:02:48,350
even though you've got this very
advanced, almost 1,000 horsepower machine.

37
00:02:48,350 --> 00:02:51,330
You need to know how to use it effectively.

38
00:02:51,330 --> 00:02:53,290
Same thing with the GPU in OpenGL.

39
00:02:53,290 --> 00:02:55,410
It's a very complex machine.

40
00:02:55,410 --> 00:03:02,220
You need to know how to utilize it and use it
efficiently in order to harness that power.

41
00:03:02,220 --> 00:03:06,670
So I'll tell you a little bit about
how OpenGL works under the hood.

42
00:03:06,670 --> 00:03:13,370
Like any good Formula 1 driver, he knows exactly
the strengths and weaknesses of his machine,

43
00:03:13,370 --> 00:03:16,450
where it excels, where he needs to work at it more.

44
00:03:16,450 --> 00:03:19,550
I'll talk a lot about this process called state validation.

45
00:03:19,550 --> 00:03:25,850
This is where OpenGL translates API calls into GPU commands.

46
00:03:25,850 --> 00:03:30,460
Now this is actually a CPU intensive operation,
and a lot of applications stumble on it.

47
00:03:30,460 --> 00:03:33,930
So you need to be aware of what happens there.

48
00:03:33,930 --> 00:03:45,590
I'll also give you some fundamental OpenGL techniques to
avoid these CPU bottlenecks, and efficiently access the GPU.

49
00:03:45,590 --> 00:03:52,150
Now it's important to note that these
techniques apply equally to iOS 4 and Mac OS X.

50
00:03:52,150 --> 00:03:56,010
So the codes you write on one platform and the knowledge

51
00:03:56,010 --> 00:03:59,690
that you've gained here, you can
leverage on the other platform.

52
00:03:59,690 --> 00:04:07,910
They've got pretty different architectures,
very different GPU's, very different devices.

53
00:04:07,910 --> 00:04:13,710
But the OpenGL software stack is quite similar,
so you can leverage that knowledge pretty easily.

54
00:04:13,710 --> 00:04:20,750
So let me talk a little bit about OpenGL's design.

55
00:04:20,750 --> 00:04:26,620
OpenGL is designed to be a low level API to
allow it direct access to the GPU's capabilities.

56
00:04:26,620 --> 00:04:32,720
Allow you to get in and get out, not interfere, not
have the software stack interfere with your code.

57
00:04:32,720 --> 00:04:34,480
Really lean.

58
00:04:34,480 --> 00:04:39,940
However, it's high enough level
to drive many heterogeneous GPU's.

59
00:04:39,940 --> 00:04:41,810
On the Mac we support many GPU's.

60
00:04:41,810 --> 00:04:45,150
On the iOS we support many as well.

61
00:04:45,150 --> 00:04:51,690
So there is a fair amount of work to
translate from these API calls to GPU commands.

62
00:04:51,690 --> 00:04:56,210
Not the lowest level way to actually get to the GPU.

63
00:04:56,210 --> 00:04:58,670
I mean we could make an API that's to the metal.

64
00:04:58,670 --> 00:05:07,320
However, what this allows, this high level allows for you to
do is write code that's portable, and also write code today

65
00:05:07,320 --> 00:05:13,620
that will run on devices that have changed
drastically underneath your application tomorrow.

66
00:05:13,620 --> 00:05:20,570
So as architecture changes, your code
remains the same and works quite efficiently.

67
00:05:20,570 --> 00:05:22,620
So OpenGL is a state machine.

68
00:05:22,620 --> 00:05:27,120
And this state maps roughly to the GPU pipeline.

69
00:05:27,120 --> 00:05:33,510
If you were to look at Apple's implementation of
OpenGL, what you'd see is this gigantic C Struct.

70
00:05:33,510 --> 00:05:37,800
OK? And what would, be in this struct you could
actually look at the OpenGL specification.

71
00:05:37,800 --> 00:05:41,710
At the back you'd see this pretty
large table that says, OpenGL state.

72
00:05:41,710 --> 00:05:45,190
And it has things like, you know, what stuff is enabled.

73
00:05:45,190 --> 00:05:49,180
The various GL enables in OpenGL, whether it's on and off.

74
00:05:49,180 --> 00:05:53,760
It has things like what's bound at certain points.

75
00:05:53,760 --> 00:05:58,800
And so that's basically what's in this context.

76
00:05:58,800 --> 00:06:00,930
All right?

77
00:06:00,930 --> 00:06:08,370
So much of OpenGL's live time is just
spent tracking state that your app makes.

78
00:06:08,370 --> 00:06:13,150
So your application, there's a certain class
of calls that OpenGL has that just exists

79
00:06:13,150 --> 00:06:16,870
to change this context state, this state becker.

80
00:06:16,870 --> 00:06:20,850
[phonetic] So for instance, you
call glEnable, some state changes.

81
00:06:20,850 --> 00:06:25,710
You call glBindTexter some more state changes.

82
00:06:25,710 --> 00:06:31,680
You call glUseProgram, and again, the
context is updated with new state.

83
00:06:31,680 --> 00:06:36,400
So at this point we're actually
doing nothing that's GPU specific.

84
00:06:36,400 --> 00:06:38,110
It's all GPU agnostic.

85
00:06:38,110 --> 00:06:41,680
There's no hardware specific command getting generated.

86
00:06:41,680 --> 00:06:44,600
The real work happens when you make a draw call.

87
00:06:44,600 --> 00:06:48,130
This is when API calls get translated into GPU commands.

88
00:06:48,130 --> 00:06:52,830
All of that work is deferred until you draw.

89
00:06:52,830 --> 00:06:59,210
So for instance you call glDrawArrays, and look what
happens here is we're munching all of this context state,

90
00:06:59,210 --> 00:07:03,290
taking that draw call, and creating a GPU command.

91
00:07:03,290 --> 00:07:09,580
So one thing to note about this is that this
translation state is a CPU intensive operation.

92
00:07:09,580 --> 00:07:14,640
We need to do a lot of processing on the CPU to
figure out exactly what your application has done,

93
00:07:14,640 --> 00:07:18,590
what it wants, and translate that into a GPU command.

94
00:07:18,590 --> 00:07:21,680
All right, so now we've got this
GPU command, what happens to it?

95
00:07:21,680 --> 00:07:26,760
Well, GPU commands are inserted to a command
buffer that's allocated by the kernel.

96
00:07:26,760 --> 00:07:29,310
So we've put that in there.

97
00:07:29,310 --> 00:07:36,490
And as the command buffer fills up, or your
application calls glFlush, we flush it to the GPU.

98
00:07:36,490 --> 00:07:38,500
The GPU now can process it.

99
00:07:38,500 --> 00:07:41,590
But actually there's one step that needs to happen first.

100
00:07:41,590 --> 00:07:46,370
We need to actually transfer all the
resources that are needed for those commands.

101
00:07:46,370 --> 00:07:49,710
For instance, we need to put textures
that are used for those draw commands.

102
00:07:49,710 --> 00:07:52,700
And we need to download those to the GPU.

103
00:07:52,700 --> 00:07:57,890
And that can make this process a CPU intensive process.

104
00:07:57,890 --> 00:08:03,060
In addition to state validation, this is another
potential bottleneck your application could incur.

105
00:08:03,060 --> 00:08:07,510
Now this is why we recommend not
calling glFlush for really any reason.

106
00:08:07,510 --> 00:08:14,730
There are some very specific reasons where you might want
to call glFlush for multicontext, multithreading rendering.

107
00:08:14,730 --> 00:08:18,750
But for the majority of applications,
you're only talking about a single thread,

108
00:08:18,750 --> 00:08:21,080
and you should never need to call glFlush.

109
00:08:21,080 --> 00:08:23,820
It's an expensive operation.

110
00:08:23,820 --> 00:08:29,880
Now you've got the command buffer on the
GPU, and the GPU can begin processing it.

111
00:08:29,880 --> 00:08:38,600
And it starts by fetching vertices, and
then it pushes that data down the pipeline.

112
00:08:38,600 --> 00:08:46,620
So it's important to note that there are
many potential bottlenecks on the GPU.

113
00:08:46,620 --> 00:08:48,950
Any one of these stages could be a bottleneck.

114
00:08:48,950 --> 00:08:53,860
However, a very common bottleneck is actually the CPU.

115
00:08:53,860 --> 00:08:56,190
All of those stages that I just talked about.

116
00:08:56,190 --> 00:09:00,740
So a key point, the GPU is another
processor that runs in parallel to the CPU.

117
00:09:00,740 --> 00:09:05,840
Like any good multithreaded apps, you don't want
one thread blocking and locking up the other thread.

118
00:09:05,840 --> 00:09:13,320
You want both cords being running at the same
time, really maximizing the use of the CPU.

119
00:09:13,320 --> 00:09:15,410
Well, same thing happens with a GPU.

120
00:09:15,410 --> 00:09:24,230
As OpenGL pushes commands into a command buffer, the GPU
fetches commands that have already been submitted to it.

121
00:09:24,230 --> 00:09:26,100
So, let me show that again.

122
00:09:26,100 --> 00:09:32,720
OpenGL is simultaneously adding commands to one command
buffer while the GPU is fetching commands from another.

123
00:09:32,720 --> 00:09:36,950
So you really don't want to let the GPU wait for the CPU.

124
00:09:36,950 --> 00:09:39,890
That's just wasting the GPU's resources.

125
00:09:39,890 --> 00:09:45,740
You could be rendering 1,000 enemies in your
game, and maybe you could be rendering 3,000

126
00:09:45,740 --> 00:09:50,550
if you're not, if you are utilizing the GPU fully.

127
00:09:50,550 --> 00:09:55,420
If you're stalling it, well, you're
not utilizing the GPU as much,

128
00:09:55,420 --> 00:09:59,410
and you're not rendering its cool effects
or as many effects as you could be.

129
00:09:59,410 --> 00:10:04,810
Also, some applications tend to use
the CPU to do some graphics work.

130
00:10:04,810 --> 00:10:08,450
Well, as I mentioned before, the
CPU is good at a lot of things.

131
00:10:08,450 --> 00:10:11,710
And you can do some high quality
rendering with it, but it's very slow.

132
00:10:11,710 --> 00:10:16,290
And you really want to use the GPU for
this work, really offload the work.

133
00:10:16,290 --> 00:10:24,060
There are certain calls that; so this is what happens
when you let the GPU wait, it just sits there.

134
00:10:24,060 --> 00:10:30,160
There are a certain class of calls where the
CPU may need to wait for the GPU to process.

135
00:10:30,160 --> 00:10:40,440
Anytime the GPU needs to process something for the CPU and
give it to the CPU, the CPU will sit there waiting for it.

136
00:10:40,440 --> 00:10:43,340
These things are like readpixels, queries, and fences.

137
00:10:43,340 --> 00:10:48,790
Here's what happens, CPU sort of just sits there
waiting until it gets the data it needs from the GPU.

138
00:10:48,790 --> 00:10:54,230
Now there are ways you can use readpixels, queries, and
fences efficiently where you're not stalling the CPU,

139
00:10:54,230 --> 00:10:58,840
and I can go into that a little bit later.

140
00:10:58,840 --> 00:11:03,250
So one thing I really want to reiterate
here is that for each draw call,

141
00:11:03,250 --> 00:11:07,300
context state is translated into GPU command.

142
00:11:07,300 --> 00:11:10,070
This is a very CPU intensive operation.

143
00:11:10,070 --> 00:11:11,650
We call this state validation.

144
00:11:11,650 --> 00:11:15,940
Here's what happens you called
glDrawElements, the CPU processing goes way

145
00:11:15,940 --> 00:11:20,960
up and we translate this GPU command here.

146
00:11:20,960 --> 00:11:27,660
If you were to profile your application and
what you would see here is that the draw calls,

147
00:11:27,660 --> 00:11:35,200
in this case glDrawElements takes a substantially
more time than any of the other OpenGL calls.

148
00:11:35,200 --> 00:11:42,530
OK, here you see it takes order of magnitude more
than any of the other OpenGL calls that you see here.

149
00:11:42,530 --> 00:11:47,530
And what's important to note about this, is
that there is some cost in making a draw call.

150
00:11:47,530 --> 00:11:54,710
It's actually not the draw call itself that is very
expensive, or causing this expense, it's state setting calls

151
00:11:54,710 --> 00:11:57,670
that your app has made before the draw call.

152
00:11:57,670 --> 00:12:05,920
So you enable something, you bind something, those look
cheap on a Shark profile, but that cost does show up.

153
00:12:05,920 --> 00:12:10,710
It doesn't show up in that particular call,
but it shows up in the subsequent draw call.

154
00:12:10,710 --> 00:12:16,590
So state sending calls look cheap, they're
not really as cheap as they might appear.

155
00:12:16,590 --> 00:12:23,760
So I'm going to over a couple of techniques,
which you can use to reduce your CPU overhead.

156
00:12:23,760 --> 00:12:30,140
The first of which is to use OpenGL's various objects.

157
00:12:30,140 --> 00:12:34,020
The second is to manage your rendering state.

158
00:12:34,020 --> 00:12:37,100
Sort it, so that you're not making redundant state changes.

159
00:12:37,100 --> 00:12:43,560
State changes that incur more CPU costs,
unnecessary state changes, and batcher state.

160
00:12:43,560 --> 00:12:46,510
Reduce some state by combining objects into one.

161
00:12:46,510 --> 00:12:51,010
[ silence ]

162
00:12:51,010 --> 00:12:52,300
So objects.

163
00:12:52,300 --> 00:12:59,510
Whenever you use an OpenGL objects, some of that
state is cached in that object and pre-validated.

164
00:12:59,510 --> 00:13:03,350
It's not validated at draw time; it's validated up front.

165
00:13:03,350 --> 00:13:07,300
So when it's bound it's easily translated into GPU command.

166
00:13:07,300 --> 00:13:10,370
So let's take texture objects for example.

167
00:13:10,370 --> 00:13:15,780
You call glGenTextures, and you create this texture object.

168
00:13:15,780 --> 00:13:19,350
All right, you call tech image and
you see this object state here.

169
00:13:19,350 --> 00:13:22,800
It's this little state vectors that the object itself has.

170
00:13:22,800 --> 00:13:25,620
And that gets updated and validated.

171
00:13:25,620 --> 00:13:29,080
You call tech parameter and that state
gets validated and updated again.

172
00:13:29,080 --> 00:13:36,790
And finally, when you call bind texture, that
state is merged with the rest of the context state,

173
00:13:36,790 --> 00:13:45,670
and cached much more easy to validate, much more, much
less CPU processing required to create that GPU command.

174
00:13:45,670 --> 00:13:53,480
Now it's important to note that this process of
setting up objects is actually somewhat expensive.

175
00:13:53,480 --> 00:13:57,970
So you really want to do this upfront, when
you're app, your level, your document is loading

176
00:13:57,970 --> 00:14:01,650
when the user isn't expecting some high frame rate.

177
00:14:01,650 --> 00:14:06,060
Don't wait until your middle of your, you're
in the middle of your real time run loop.

178
00:14:06,060 --> 00:14:07,950
Do it up front.

179
00:14:07,950 --> 00:14:13,730
So now I've described one way in
which you can reduce CPU validation.

180
00:14:13,730 --> 00:14:16,850
I'll also describe a few other ways.

181
00:14:16,850 --> 00:14:23,520
And I'll also describe some ways in which not
using objects can be an inefficient use of the API.

182
00:14:23,520 --> 00:14:29,750
The first thing I'll describe is how fixed function,
vertex and fragment pipe, how that fixed function,

183
00:14:29,750 --> 00:14:33,460
vertex and fragment pipe, can be
an inefficient use of the API.

184
00:14:33,460 --> 00:14:41,530
And instead, how using GLSL programmable
objects can be a much more efficient use.

185
00:14:41,530 --> 00:14:49,160
So modern hardware doesn't have any fixed
function vertex or fragment pipeline.

186
00:14:49,160 --> 00:14:58,360
OpenGL needs to convert all of your fixed function
calls, glEnableLight, etc., into a shader internally.

187
00:14:58,360 --> 00:15:00,970
And this can be pretty costly.

188
00:15:00,970 --> 00:15:01,600
Here's what happens.

189
00:15:01,600 --> 00:15:07,010
You call glEnableLight, some context
state changes, as it usually does.

190
00:15:07,010 --> 00:15:10,440
GL text in another fixed function call.

191
00:15:10,440 --> 00:15:13,390
And that state gets updated.

192
00:15:13,390 --> 00:15:15,130
glDrawArrays.

193
00:15:15,130 --> 00:15:19,760
Here's what happened, we generate this large
shader under the hood for your application.

194
00:15:19,760 --> 00:15:22,690
Now you don't have to pay attention
to exactly what's going on.

195
00:15:22,690 --> 00:15:28,390
We're just emulating what you've told us,
what the state that you'd like to use.

196
00:15:28,390 --> 00:15:30,790
And this can be a pretty expensive operation.

197
00:15:30,790 --> 00:15:33,750
We actually cache the shader away,
so we don't generate shader

198
00:15:33,750 --> 00:15:36,950
and complete it every single time that we use fix function.

199
00:15:36,950 --> 00:15:39,120
But we cached it away in the cache table.

200
00:15:39,120 --> 00:15:45,950
And when you use this, you use fixed function, we need
to generate this cache key, which is somewhat expensive.

201
00:15:45,950 --> 00:15:49,710
And then go inside of our cache and
pull out your shader and set it.

202
00:15:49,710 --> 00:15:51,920
This can be pretty expensive.

203
00:15:51,920 --> 00:15:57,110
So instead what we'd rather have you do, and which
could be a much more efficient use of the API,

204
00:15:57,110 --> 00:16:00,230
is to use program object, shader objects.

205
00:16:00,230 --> 00:16:03,110
This is a most efficient way to set up the pipeline.

206
00:16:03,110 --> 00:16:06,110
So you specify shader code, you compile and link it

207
00:16:06,110 --> 00:16:11,600
into a program object while you're document
your level, your document, your app is loading.

208
00:16:11,600 --> 00:16:14,190
Before you venture your real time run loop.

209
00:16:14,190 --> 00:16:21,460
And then when you want to use that pipeline
you set it, and bam, easily set on the GPU.

210
00:16:21,460 --> 00:16:26,200
No looking into some weird hash table
to pull out the fix function shader.

211
00:16:26,200 --> 00:16:27,690
Very efficient use of the API.

212
00:16:27,690 --> 00:16:34,600
So some people would like a little bit more
understanding of how vertex and fragment shaders work.

213
00:16:34,600 --> 00:16:36,080
They are kind of a complex piece.

214
00:16:36,080 --> 00:16:40,100
So I'm just going to go through and
describe a little bit about how they work.

215
00:16:40,100 --> 00:16:44,250
So the vertex shader is the first
part of the programmable pipeline.

216
00:16:44,250 --> 00:16:48,220
A shader is executed every time for every vertex.

217
00:16:48,220 --> 00:16:51,570
So let' say you've got a model with 1,000 vertices.

218
00:16:51,570 --> 00:16:54,350
And you draw that model.

219
00:16:54,350 --> 00:16:57,610
Your vertex shader will run 1,000 times.

220
00:16:57,610 --> 00:17:01,360
OK, now this is great, this is fine, because
the GPU's are very efficient at that.

221
00:17:01,360 --> 00:17:02,560
It's designed for this.

222
00:17:02,560 --> 00:17:08,230
It's a high bandwidth processor specifically
designed to do this sort of professing.

223
00:17:08,230 --> 00:17:10,840
OK, so let's talk about the inputs.

224
00:17:10,840 --> 00:17:14,300
Inputs are per-vertex attributes that
are specified outside the shader.

225
00:17:14,300 --> 00:17:22,680
Things like pre-transformed positions,
pre-transformed normals, untransform texture coordinate.

226
00:17:22,680 --> 00:17:24,420
Specified outside the shader.

227
00:17:24,420 --> 00:17:27,130
Now there are two classes of inputs.

228
00:17:27,130 --> 00:17:30,690
The first is a position in clip space.

229
00:17:30,690 --> 00:17:33,580
OK? This is the glPosition built-invariable.

230
00:17:33,580 --> 00:17:35,640
You've assigned this, glpresent variable.

231
00:17:35,640 --> 00:17:42,190
And this clip space is used for
OpenGL to map, map to the screen.

232
00:17:42,190 --> 00:17:47,260
OK? It's to map your 3D model onto a 2D screen.

233
00:17:47,260 --> 00:17:49,980
So that's one output of the vertex shader.

234
00:17:49,980 --> 00:17:52,940
The second are one or many bearings.

235
00:17:52,940 --> 00:17:59,540
And so the type of data that these bearings usually
consist of are colors, normal, and texture coordinates.

236
00:17:59,540 --> 00:18:04,110
Values that you'd like to read in your fragment shader.

237
00:18:04,110 --> 00:18:08,900
Now these values are interpolated
across any rasterized triangle.

238
00:18:08,900 --> 00:18:14,760
So, let's say this triangle was generated by three vertices.

239
00:18:14,760 --> 00:18:20,080
And on one vertex you signed 0.4 to one of these varying.

240
00:18:20,080 --> 00:18:22,740
One the other you would sign 0.8.

241
00:18:22,740 --> 00:18:25,240
You output that in your vertex here.

242
00:18:25,240 --> 00:18:32,730
OK, so halfway through the pixel generated
on this polygon will have a value of 0.6.

243
00:18:32,730 --> 00:18:35,760
One-quarter of the way down it'll have 0.5.

244
00:18:35,760 --> 00:18:38,210
Three-quarters, 0.7.

245
00:18:38,210 --> 00:18:47,540
So in other words, it's distributed across the polygon from
the two varyings that you output in your vertex shader.

246
00:18:47,540 --> 00:18:54,710
Now it's not it's not linearly output like
it looks here where it's evenly distributed.

247
00:18:54,710 --> 00:18:57,890
In fact, if the polygon is facing you it will be.

248
00:18:57,890 --> 00:19:03,340
But if it's a little bit on edge you'll have
this sort of perspective correct interpolation.

249
00:19:03,340 --> 00:19:09,080
Where values that are closer to you will be
nearer, or actually be a little further apart.

250
00:19:09,080 --> 00:19:12,590
That's to give it this 3D effect that you need.

251
00:19:12,590 --> 00:19:19,500
OK, so let me give you an example
of a pretty simple vertex shader.

252
00:19:19,500 --> 00:19:28,560
So here is a varying that we define,
varTexCoord And this will, this is,

253
00:19:28,560 --> 00:19:33,570
this works just like the variances I just
described that are distributed across the polygon.

254
00:19:33,570 --> 00:19:37,420
And here is the main body where all this work is going on.

255
00:19:37,420 --> 00:19:45,390
On the first line what we're doing is we're multiplying
the incoming glVertex, the pre-transformed position,

256
00:19:45,390 --> 00:19:49,420
and multiply it by the modelViewProjectionMatrix.

257
00:19:49,420 --> 00:19:51,270
And then we output it to glPosition.

258
00:19:51,270 --> 00:19:54,720
So now this position is in clip
space, because we transformed it.

259
00:19:54,720 --> 00:20:05,920
And then the second step here is we take in a texture
coordinate that is specified outside the shader.

260
00:20:05,920 --> 00:20:11,110
We take the two components, S and T
components, and we assign it to this varying.

261
00:20:11,110 --> 00:20:15,750
And this varying, again, it works just
like that diagram I just showed you.

262
00:20:15,750 --> 00:20:19,440
And you can read varTexCoord in the fragment shader.

263
00:20:19,440 --> 00:20:22,290
The second stage of the programmable pipeline.

264
00:20:22,290 --> 00:20:24,680
Now there are a couple of things to note about this shader.

265
00:20:24,680 --> 00:20:30,050
We're using these built in variables here.

266
00:20:30,050 --> 00:20:33,740
Now these are sort of a throw back
to the fixed function days.

267
00:20:33,740 --> 00:20:36,690
And they're only available on the Mac.

268
00:20:36,690 --> 00:20:41,820
They're not available if you use ES 2.0 on iOS 4.

269
00:20:41,820 --> 00:20:45,200
They're based on, sort of, the legacy pipeline.

270
00:20:45,200 --> 00:20:50,390
And actually we would prefer that you
do not use them for a couple of reasons.

271
00:20:50,390 --> 00:20:54,100
There needs to be some mapping
performed in order to use them.

272
00:20:54,100 --> 00:20:55,900
And they're not forward compatible.

273
00:20:55,900 --> 00:20:58,210
OpenGL ES doesn't have them as I decided.

274
00:20:58,210 --> 00:21:01,000
And code without them isn't the future of OpenGL.

275
00:21:01,000 --> 00:21:07,170
In fact, there are a number of extensions that would
ship on Mac OS X where you can't use these variables.

276
00:21:07,170 --> 00:21:08,780
There a whole set of these variables.

277
00:21:08,780 --> 00:21:13,250
In fact, on the right hand side are
varyings and attributes that are, you know,

278
00:21:13,250 --> 00:21:16,830
these legacy fixed function based variables.

279
00:21:16,830 --> 00:21:23,190
And on the left here, so excuse me on the
right those are the varying attributes.

280
00:21:23,190 --> 00:21:26,410
And on the left here we've got uniforms.

281
00:21:26,410 --> 00:21:33,410
ModelViewProjectionMatrix, lighting, points, stuff that
just doesn't exist anymore in the programmable pipeline.

282
00:21:33,410 --> 00:21:37,240
But OpenGL has them for a legacy reason.

283
00:21:37,240 --> 00:21:43,240
So instead of using these variables, you can use generics.

284
00:21:43,240 --> 00:21:48,720
Here's an example of a shader, which does
the exact same thing as the previous shader.

285
00:21:48,720 --> 00:21:52,490
Except instead of using built in variables we use our own.

286
00:21:52,490 --> 00:22:02,270
We define our own, so that we have portable code and OpenGL
can map them to the programmable pipeline much more easily.

287
00:22:02,270 --> 00:22:06,810
So we define an input position
and an input texture coordinate.

288
00:22:06,810 --> 00:22:10,750
Well don't use the built in glVertex or glMultitexture cord.

289
00:22:10,750 --> 00:22:12,920
We use our own.

290
00:22:12,920 --> 00:22:15,500
And we define our own model view projection matrix.

291
00:22:15,500 --> 00:22:17,910
We don't use glView projection matrix.

292
00:22:17,910 --> 00:22:20,800
And we sat that outside the shader.

293
00:22:20,800 --> 00:22:28,090
And just as in our last shader, we have bar,
TexCoord another varying that we output to.

294
00:22:28,090 --> 00:22:36,340
And in the main body we multiply our model view
projection matrix by our input position that we've defined.

295
00:22:36,340 --> 00:22:38,070
And we output it to glPosition.

296
00:22:38,070 --> 00:22:43,340
Now glPosition is a built in variable, but it's
not one of these legacy throwback variables.

297
00:22:43,340 --> 00:22:45,210
You still need to use it.

298
00:22:45,210 --> 00:22:52,550
And then again we take our input text TexCoord
variable and pass it through to varTexCoord.

299
00:22:52,550 --> 00:22:55,460
So that it may now be read in the fragmentator.

300
00:22:55,460 --> 00:22:56,830
The fragmentator.

301
00:22:56,830 --> 00:23:01,500
So this runs once per pixel produced by each polygon.

302
00:23:01,500 --> 00:23:07,880
So let's say you've got a model with 1,000
vertices, and it draws 100,000 pixels.

303
00:23:07,880 --> 00:23:10,910
This shader will be run 100,000 times.

304
00:23:10,910 --> 00:23:14,320
Again, GPU's efficient at processing this, so that's great.

305
00:23:14,320 --> 00:23:19,360
But in general, if you have some processing
that could be done higher up in a pipeline

306
00:23:19,360 --> 00:23:21,800
in the vertex shader, instead of the fragment shader.

307
00:23:21,800 --> 00:23:25,950
You probably want to do it up there,
because that will be run less times.

308
00:23:25,950 --> 00:23:29,350
A little bit less processing, a
little bit less work for the GPU.

309
00:23:29,350 --> 00:23:34,580
The cool thing about this programmable
pipeline is that you can render effects

310
00:23:34,580 --> 00:23:37,570
that aren't possible using the fixed function pipeline.

311
00:23:37,570 --> 00:23:40,270
So here we've got this tune shading effect.

312
00:23:40,270 --> 00:23:43,080
OK? And here's how that works.

313
00:23:43,080 --> 00:23:46,260
Per fragment we calculate this edginess factor.

314
00:23:46,260 --> 00:23:53,380
So if the pixel on the polygon, if the polygon
on which it lies is more on edge to the user,

315
00:23:53,380 --> 00:23:55,970
we'll give it a value that's lower to zero.

316
00:23:55,970 --> 00:23:57,530
That's closer to zero.

317
00:23:57,530 --> 00:24:06,070
OK? However, if the polygon is facing the camera,
the user will give it a value that's closer to 1.

318
00:24:06,070 --> 00:24:10,220
So we now know whether this polygon is on edge or facing.

319
00:24:10,220 --> 00:24:15,400
And then we could use this edginess
factor to give it a color.

320
00:24:15,400 --> 00:24:20,440
So, for instance, if it's on edge, it's probably we
want to give it the sort of tune effect, you know,

321
00:24:20,440 --> 00:24:25,310
as the silhouette of the teapot
hat, so we'll give it a black value.

322
00:24:25,310 --> 00:24:26,850
And otherwise we'll give it a blue value.

323
00:24:26,850 --> 00:24:32,410
And then we assign this color that we've determined
the glFragColor, another built in variable,

324
00:24:32,410 --> 00:24:36,750
which is the ultimate color that
will be rendered for that pixel.

325
00:24:36,750 --> 00:24:40,010
Let's talk about the inputs to the vertex shader.

326
00:24:40,010 --> 00:24:47,140
There's this call, glVertexAttribPointer, which
points to data that can be fed to the vertex shader.

327
00:24:47,140 --> 00:24:52,010
Input position, for instance, or
texture coordinates, things like that.

328
00:24:52,010 --> 00:24:54,210
Here's how it works.

329
00:24:54,210 --> 00:24:58,890
You allocate some memory in your
application; in this case we're using malloc.

330
00:24:58,890 --> 00:25:02,930
And then you load data into this
buffer that you've allocated.

331
00:25:02,930 --> 00:25:08,640
You call glEnableVertexAttrib to let OpenGL
know that hey, I'm going to use a vertex array.

332
00:25:08,640 --> 00:25:15,710
And you give it a position at index, or
some index 0 to 16 that maps to the shader.

333
00:25:15,710 --> 00:25:21,340
And then you call glVertexAttribPointer and you
give it this position data that you've allocated.

334
00:25:21,340 --> 00:25:29,550
OK? Position data is basically tells
OpenGL hey, my vertex data lives here.

335
00:25:29,550 --> 00:25:32,120
So there are some issues with using OpenGL this way.

336
00:25:32,120 --> 00:25:38,870
Because you're allocating the buffer on your end,
you're not telling OpenGL to allocate it itself.

337
00:25:38,870 --> 00:25:43,690
OpenGL has to copy this data into its own stream.

338
00:25:43,690 --> 00:25:50,890
So CPU's cycles will be required to copy that vertex data.

339
00:25:50,890 --> 00:25:51,530
Here's what happens.

340
00:25:51,530 --> 00:25:57,400
You call glVertexAttribPointer, OpenGL now
knows about this buffer that you've allocated,

341
00:25:57,400 --> 00:26:05,800
but then when you call glDrawArrays or draw with this
buffer, OpenGL copies it into the command buffer.

342
00:26:05,800 --> 00:26:08,130
And there's a double whammy here.

343
00:26:08,130 --> 00:26:14,140
Because the CPU's also needing to copy,
there's some CPU cycles being incurred.

344
00:26:14,140 --> 00:26:18,010
But also we're filling up the command
buffer much more quickly.

345
00:26:18,010 --> 00:26:20,670
And then a flush will occur.

346
00:26:20,670 --> 00:26:24,140
Flushes will happen much more often, a second whammy.

347
00:26:24,140 --> 00:26:31,450
So instead of doing this, we'd like you to be
able to just cache that vertex data on the GPU.

348
00:26:31,450 --> 00:26:32,740
And here's how you do it.

349
00:26:32,740 --> 00:26:33,790
You can store it in a VBL.

350
00:26:33,790 --> 00:26:47,340
You call glBufferData and BufferData allocates some space
on the GPU, and then loads your vertex data into the GPU.

351
00:26:47,340 --> 00:26:58,570
Then you'll call glDrawArrays, a command is created and
it simply references this data that's already on the GPU.

352
00:26:58,570 --> 00:27:05,490
You would call BufferData probably when your application
loads before you're in the real time run loop.

353
00:27:05,490 --> 00:27:07,090
There is some cost to it.

354
00:27:07,090 --> 00:27:13,590
But if you do that it'll be cached ready
to be used in a real time run loop.

355
00:27:13,590 --> 00:27:15,260
So here's how it works.

356
00:27:15,260 --> 00:27:18,880
You call glGenBuffers, that creates
this vertex buffer object.

357
00:27:18,880 --> 00:27:21,360
You can call bindBuffer to bind it to the context.

358
00:27:21,360 --> 00:27:24,650
Tell OpenGL, hey I'm going to work with this object now.

359
00:27:24,650 --> 00:27:29,890
And you call glBufferData to allocate and load your data.

360
00:27:29,890 --> 00:27:35,680
Then you call glVertexAttribPointer the same call
that you made before with client side vertex arrays.

361
00:27:35,680 --> 00:27:39,630
But this time instead of giving it
a pointer, you give it an offset

362
00:27:39,630 --> 00:27:43,220
into the vertex buffer object, where your vertex data lives.

363
00:27:43,220 --> 00:27:48,540
So in this case we give it 0, which says, hey my
vertex data is at the beginning of this buffer.

364
00:27:48,540 --> 00:27:53,990
You can actually store many attributes within a single
vertex buffer object, so it doesn't have to be 0.

365
00:27:53,990 --> 00:28:01,920
Let's say you've got color data 50 bytes down, then
you give it a value of 50 for the color attributes.

366
00:28:01,920 --> 00:28:07,120
You may want to modify your data
for animations or some other reason.

367
00:28:07,120 --> 00:28:13,890
If you have a constant number of animations, if you have
few of them, few enough of them, just create multiple VBOs.

368
00:28:13,890 --> 00:28:20,080
Let's say you've got 10 frames, 10 models
that you want to animate for your character.

369
00:28:20,080 --> 00:28:21,720
Just make 10 VBOs.

370
00:28:21,720 --> 00:28:25,120
That way all 10 of them are cached on the GPU.

371
00:28:25,120 --> 00:28:28,480
However, you may generate data on the fly.

372
00:28:28,480 --> 00:28:30,330
Maybe you'll load it from disk.

373
00:28:30,330 --> 00:28:33,400
Someway that OpenGL may not know about it.

374
00:28:33,400 --> 00:28:41,640
In this case you can call glBufferSubData Or
MapBuffer to modify this cached vertex buffer object.

375
00:28:41,640 --> 00:28:43,050
Here's how this works.

376
00:28:43,050 --> 00:28:49,010
You call glBufferData as you normally would,
but instead you give it this glDynamicDrawHint.

377
00:28:49,010 --> 00:28:54,690
And that says to OpenGL, hey, I'm going to modify this
buffer, so put in someplace that's easily accessible

378
00:28:54,690 --> 00:28:59,580
by the GPU, but can be easily modified by the CPU.

379
00:28:59,580 --> 00:29:03,950
Then you modify this data that you want
to update in the vertex buffer object.

380
00:29:03,950 --> 00:29:13,150
And you call BufferSubData with this update data
pointer, and it's loaded into the vertex buffer object.

381
00:29:13,150 --> 00:29:14,160
There are some caveats.

382
00:29:14,160 --> 00:29:19,870
There are some potential problems where if
you're updating buffer a lot, buffers a lot,

383
00:29:19,870 --> 00:29:23,860
you can have some, encounter some problems.

384
00:29:23,860 --> 00:29:26,100
You can force the GPU to sync with the CPU.

385
00:29:26,100 --> 00:29:28,570
So all of a sudden you're running full out in parallel,

386
00:29:28,570 --> 00:29:32,440
and then you call BufferSubData and
then lock, one depends on the other.

387
00:29:32,440 --> 00:29:33,550
And you don't want that.

388
00:29:33,550 --> 00:29:40,840
So instead what you can do, well so, basically
what will happen is this CPU will wait for the GPU

389
00:29:40,840 --> 00:29:44,790
to finish drawing the buffer before it updates the buffer.

390
00:29:44,790 --> 00:29:51,320
OK? Both the CPU and GPU can't read and
write from the buffer at the same time.

391
00:29:51,320 --> 00:29:56,080
So this can happen whenever you use
glSubData or glBufferSubData or MapBuffer.

392
00:29:56,080 --> 00:29:59,580
You can use a double buffering
technique to avoid this problem.

393
00:29:59,580 --> 00:30:02,060
And let me explain how that works.

394
00:30:02,060 --> 00:30:05,970
So, you have two vertex buffer objects.

395
00:30:05,970 --> 00:30:14,740
On an odd frame you'll load, you'll
bind and load an odd buffer.

396
00:30:14,740 --> 00:30:18,890
OK? And you draw with it just as you normally would.

397
00:30:18,890 --> 00:30:23,730
But on an even frame you bind and load this other buffer.

398
00:30:23,730 --> 00:30:29,820
This way the CPU is loading this even buffer, while the
GPU is reading from an odd buffer, a different object.

399
00:30:29,820 --> 00:30:35,500
They don't need to synchronize, because they're
not accessing the same object, the same data.

400
00:30:35,500 --> 00:30:38,550
OK? And then you draw with an even
buffer as you normally would.

401
00:30:38,550 --> 00:30:45,870
And so what you would do is you'd ping-pong between these
two buffers updating one, while the other is being drawn.

402
00:30:45,870 --> 00:30:46,890
Vertex array layout.

403
00:30:46,890 --> 00:30:47,560
So vertex array layout.

404
00:30:47,560 --> 00:30:50,610
So VertexAttribPointers are really important to GL call.

405
00:30:50,610 --> 00:30:58,680
Because not only does it tell you, tell OpenGL where
your vertices live, it tells it the vertex layout.

406
00:30:58,680 --> 00:31:05,330
So you call glVertexAttribPointer and you give
it some data, like what kind of data is it?

407
00:31:05,330 --> 00:31:07,020
It's a floating point in this case.

408
00:31:07,020 --> 00:31:09,220
The size of the data.

409
00:31:09,220 --> 00:31:14,930
It's probably, it's a position,
so maybe it has an X, Y, and Z.

410
00:31:14,930 --> 00:31:16,720
So it needs a value of 3.

411
00:31:16,720 --> 00:31:22,170
Describe the number of bytes from the
one vertex, one attribute to the next.

412
00:31:22,170 --> 00:31:28,090
So in this case there's 16 bytes between
to the next attribute 0, OK, in the array.

413
00:31:28,090 --> 00:31:32,150
And offset, where it lives within the vertex buffer object.

414
00:31:32,150 --> 00:31:38,590
Call glVertexAttribPointer again and some more
data is updated for a different attribute.

415
00:31:38,590 --> 00:31:46,800
OK? So wouldn't be nice to cache this in the GPU so that
you're not always having to call the glVertexAttribPointer.

416
00:31:46,800 --> 00:31:51,550
Well now you can, because now you
have a vertex array object.

417
00:31:51,550 --> 00:31:56,310
And the way this works is you call glGenVertexArrays.

418
00:31:56,310 --> 00:31:59,580
And this creates this vertex array object.

419
00:31:59,580 --> 00:32:07,710
And any subsequent vertexAttribPointer call
actually changes the data within this VAO.

420
00:32:07,710 --> 00:32:10,980
So it's all cached right there.

421
00:32:10,980 --> 00:32:12,050
Let me show you some code.

422
00:32:12,050 --> 00:32:15,180
You call glGenVertexArrays, create the vertex array object.

423
00:32:15,180 --> 00:32:19,730
You bind it to the context, tell OpenGL, hey;
I'm going to work with the vertex array object.

424
00:32:19,730 --> 00:32:25,180
You call glEnableVertexAttrib just as you
normally would, and glVertexAttribPointer.

425
00:32:25,180 --> 00:32:30,530
But instead of this getting set in
the context, it's set in the VAO.

426
00:32:30,530 --> 00:32:36,180
You can set multiple vertex attributes
and it'll all cache within the VAO.

427
00:32:36,180 --> 00:32:42,510
And then you can call glBindVertexArrays
when you want to use this VAO to draw with.

428
00:32:42,510 --> 00:32:49,460
You don't have to call VertexAttribPointer many, many
times to set it up, to set up your model data to be drawn.

429
00:32:49,460 --> 00:32:56,450
You just call BindVertexArray once and it's
already cached ready to go to be drawn.

430
00:32:56,450 --> 00:32:57,980
Framebuffer objects.

431
00:32:57,980 --> 00:33:00,720
These are pretty cool objects.

432
00:33:00,720 --> 00:33:05,820
So with EAGL and OpenGL ES you must
always use an FBO in some form.

433
00:33:05,820 --> 00:33:10,310
The EAGL IT guide requires that you use and FBO

434
00:33:10,310 --> 00:33:15,600
to allocate your backing store your
store from, to which you will render to.

435
00:33:15,600 --> 00:33:21,540
However, you can do some pretty cool effects by
attaching a texture to a frame buffer object.

436
00:33:21,540 --> 00:33:23,850
So, here we've got this little demon character.

437
00:33:23,850 --> 00:33:29,420
And what I've done here is we've rendered
this demon character to a texture.

438
00:33:29,420 --> 00:33:30,160
All right?

439
00:33:30,160 --> 00:33:36,740
And then we bind that texture and textured
this plane that you see here on the bottom.

440
00:33:36,740 --> 00:33:44,420
And this plane is the image that we've rendered
to that we're now mapping to this polygon.

441
00:33:44,420 --> 00:33:47,830
So you can do all sorts of reflections,
refractions, shadows.

442
00:33:47,830 --> 00:33:52,870
Some pretty neat effects with a
renderable texture and framebuffer object.

443
00:33:52,870 --> 00:33:58,640
The way this works you call glGenTextures, create your
texture as you normally would, bind it to the context,

444
00:33:58,640 --> 00:34:03,900
and then you allocate some data by, with glTexImage2D.

445
00:34:03,900 --> 00:34:07,930
In this case we're making a 512 x 512 texture.

446
00:34:07,930 --> 00:34:14,850
OK? And then we can create a frame
buffer object, called glGenFramebuffers.

447
00:34:14,850 --> 00:34:17,660
And bind that to the context.

448
00:34:17,660 --> 00:34:23,610
Later when the texture is no longer bound to the
context, we can attach it to this framebuffer object,

449
00:34:23,610 --> 00:34:29,050
which basically says, any drawing that
you do in OpenGL, draw to this texture.

450
00:34:29,050 --> 00:34:30,740
Don't draw it to the screen.

451
00:34:30,740 --> 00:34:37,010
OK? And then later on you can bind that
texture to the context, and you can read it

452
00:34:37,010 --> 00:34:40,830
and map your rendered image to some other object.

453
00:34:40,830 --> 00:34:43,600
Some notes about objects mutability.

454
00:34:43,600 --> 00:34:47,520
OpenGL objects can be changed at
any time during their lifetime.

455
00:34:47,520 --> 00:34:52,390
So in this case we've created a texture,
and we've given it GL Linear Filtering.

456
00:34:52,390 --> 00:34:59,210
And then later on maybe in a real time run loop when
the user is expecting an interactive frame rate,

457
00:34:59,210 --> 00:35:04,250
we can do something like glLinearMipmapLinear
and change that texture object.

458
00:35:04,250 --> 00:35:06,170
Change the way that it works.

459
00:35:06,170 --> 00:35:13,070
I would really avoid doing this, because this forces
OpenGL to revalidate the object the next time it's used.

460
00:35:13,070 --> 00:35:17,370
If you need an object with 2 different
states, just create 2 different objects.

461
00:35:17,370 --> 00:35:21,030
Set them up at fronts, don't change
them, because then OpenGL needs

462
00:35:21,030 --> 00:35:24,420
to do some revalidation, and that's
going to cause a stutter.

463
00:35:24,420 --> 00:35:29,220
Or it's potentially going to cause
a stutter in your application.

464
00:35:29,220 --> 00:35:33,830
So OpenGL objects aren't actually
pre-validated when they're created.

465
00:35:33,830 --> 00:35:39,010
Instead they're validated when they're first used to draw.

466
00:35:39,010 --> 00:35:40,670
Now there's some reasons for this.

467
00:35:40,670 --> 00:35:47,490
Shader objects can't be compiled until their first use of
draw; because the compiler needs to know some context state

468
00:35:47,490 --> 00:35:50,090
that that shader's going to be used with.

469
00:35:50,090 --> 00:35:55,040
For instance, they may need to know that FBO, VAO, or
textures that are bound, the blend states that is used

470
00:35:55,040 --> 00:36:02,490
in conjunction with that shader in order for it to
do a good job compiling and optimizing your shader.

471
00:36:02,490 --> 00:36:10,550
Texture objects and vertex buffer objects, memory resources
don't get cached in VRAM until they're first used to draw.

472
00:36:10,550 --> 00:36:16,940
Now this lazy validation step that I just spoke
about, can cause some hiccups in your run loop.

473
00:36:16,940 --> 00:36:20,020
And there are some methods to get to avoid this.

474
00:36:20,020 --> 00:36:25,990
So you can avoid this validation, this
hiccup by pre-warming your objects.

475
00:36:25,990 --> 00:36:31,410
And the way this works is, you bind the object
and draw with it to an offscreen buffer.

476
00:36:31,410 --> 00:36:34,320
Maybe the back buffer and you don't
present that to the user.

477
00:36:34,320 --> 00:36:37,850
And you use the state and other objects it's used with.

478
00:36:37,850 --> 00:36:39,660
So let's say you got a shader.

479
00:36:39,660 --> 00:36:45,680
Make sure you use it, you turn on all the blending state
you bind all the textures that that shader is used with,

480
00:36:45,680 --> 00:36:50,570
and draw with it first before you're
in your real time run loop.

481
00:36:50,570 --> 00:36:54,220
Don't wait until you're in your
run loop and cause a stutter.

482
00:36:54,220 --> 00:36:55,590
Hey, here's a little bit of pseudo code.

483
00:36:55,590 --> 00:37:00,990
Oh, so one thing I should note is really only consider
this if your application experiences a hiccup.

484
00:37:00,990 --> 00:37:07,270
If it experiences a hiccup, particularly when you've bound
an object that you've never used to draw with previously.

485
00:37:07,270 --> 00:37:10,100
So here's some pseudo code for how this works.

486
00:37:10,100 --> 00:37:13,890
For every program in your scene bind it to the context.

487
00:37:13,890 --> 00:37:18,480
For every VAO that's used with that program bind that.

488
00:37:18,480 --> 00:37:23,220
And for every texture used with that VAO program, bind that.

489
00:37:23,220 --> 00:37:29,770
And then for every blend state use with all those
other objects, etc., etc. You set that stake.

490
00:37:29,770 --> 00:37:30,680
And then you draw.

491
00:37:30,680 --> 00:37:32,670
Draw to the offscreen buffer.

492
00:37:32,670 --> 00:37:36,580
This isn't to present to the user,
it's just to warm up OpenGL.

493
00:37:36,580 --> 00:37:39,330
Note about object size.

494
00:37:39,330 --> 00:37:43,610
Know how much memory your objects take.

495
00:37:43,610 --> 00:37:47,760
All current graphics resources
need to fit in memory somehow.

496
00:37:47,760 --> 00:37:49,330
And memory is limited.

497
00:37:49,330 --> 00:37:52,920
On iOS 4 there's no virtual memory
system, so this constrains.

498
00:37:52,920 --> 00:37:55,570
On Mac OS X.

499
00:37:55,570 --> 00:37:57,420
Some of the devices have limited VRAM.

500
00:37:57,420 --> 00:38:02,000
So, you know, if you're using too
much memory there's some cost to it.

501
00:38:02,000 --> 00:38:09,710
There's some paging that might need to happen, and
you don't want to have that in a real time run loop.

502
00:38:09,710 --> 00:38:11,580
Try to use compressed textures.

503
00:38:11,580 --> 00:38:13,160
Textures take up a lot of memory.

504
00:38:13,160 --> 00:38:16,020
There are a number of compressed
texture formats that you can use.

505
00:38:16,020 --> 00:38:20,390
Also, don't use the data types like
a 32-bit float for your textures,

506
00:38:20,390 --> 00:38:23,300
when you could be using an unsigned, 8-bit unsigned byte.

507
00:38:23,300 --> 00:38:25,890
An 8-bit unsigned byte.

508
00:38:25,890 --> 00:38:27,640
Use what you need.

509
00:38:27,640 --> 00:38:32,600
Use the smallest state as possible
that you need for your scene.

510
00:38:32,600 --> 00:38:37,990
We see a lot of time, some applications
allocate this humongous texture.

511
00:38:37,990 --> 00:38:45,890
A 2,000 by 2,000 pixel texture for a little tiny model
that's going to fill up maybe only 200 pixels on the screen.

512
00:38:45,890 --> 00:38:49,630
You're never going to see most of that texture.

513
00:38:49,630 --> 00:38:51,230
It's just a waste of resources.

514
00:38:51,230 --> 00:38:55,620
So fit the texture to the size of the model that's rendered.

515
00:38:55,620 --> 00:38:59,130
Use a 256 x 256 texture in that case.

516
00:38:59,130 --> 00:39:07,970
And really to ensure a smooth frame rate, try to fit, the
entire frames resources into VRAM so that we never need

517
00:39:07,970 --> 00:39:10,910
to page out a texture from VRAM in the middle of a frame.

518
00:39:10,910 --> 00:39:15,300
And if possible, fits entire level
or scene's textures into VRAM.

519
00:39:15,300 --> 00:39:20,190
That way we will never need to
page in the middle of your scene.

520
00:39:21,530 --> 00:39:27,050
So, OpenGL's objects are a very
efficient way to use the API.

521
00:39:27,050 --> 00:39:32,220
However, there is still some costs to binding an object.

522
00:39:32,220 --> 00:39:35,960
You really need to determine this
costs through profiling, however.

523
00:39:35,960 --> 00:39:40,530
Batch or draw calls to reduce this
binding of more expensive objects.

524
00:39:40,530 --> 00:39:44,970
OK? Let's say you've got, you've determined that
some texture takes a really long time to bind,

525
00:39:44,970 --> 00:39:47,830
or takes a fair number of CPU cycles to bind.

526
00:39:47,830 --> 00:39:50,120
In two objects that use this texture.

527
00:39:50,120 --> 00:39:54,220
Don't bind it once then draw, bind it again, and then draw.

528
00:39:54,220 --> 00:39:58,620
We said bind it once and draw, and draw the second one.

529
00:39:58,620 --> 00:39:59,960
Visibility.

530
00:39:59,960 --> 00:40:04,090
OpenGL processes every thing sent to it in some form.

531
00:40:04,090 --> 00:40:06,110
Even if it's ultimately not visible.

532
00:40:06,110 --> 00:40:09,550
You know, we're not going to draw something
that's, you know, behind the camera.

533
00:40:09,550 --> 00:40:11,790
But there is some processing that needs to occur.

534
00:40:11,790 --> 00:40:14,600
The CPU needs to process the draw call.

535
00:40:14,600 --> 00:40:22,820
The vertex shader needs to run to determine whether
or not the camera can actually see this object.

536
00:40:22,820 --> 00:40:25,980
So try not to send them to OpenGL.

537
00:40:25,980 --> 00:40:29,680
Imagine this is the scene of your application.

538
00:40:29,680 --> 00:40:32,590
Here's the view point, the user, the camera.

539
00:40:32,590 --> 00:40:35,710
Here's its field of view.

540
00:40:35,710 --> 00:40:39,610
And here is the frustum OK, this
includes the right and left clip planes,

541
00:40:39,610 --> 00:40:43,410
the top and bottom clip planes,
and the Z near and far clip planes.

542
00:40:43,410 --> 00:40:48,210
So now it will iterate through your list of objects
and determine whether or not they're visible.

543
00:40:48,210 --> 00:40:50,850
Anything within this area we'll send to OpenGL.

544
00:40:50,850 --> 00:40:55,170
Anything outside of this frustum we'll
just discard, we won't send it to OpenGL.

545
00:40:55,170 --> 00:40:58,750
And draw this robot; he's clearly behind the camera.

546
00:40:58,750 --> 00:41:00,820
We won't draw him.

547
00:41:00,820 --> 00:41:04,530
We draw this hero character; he's off to the right.

548
00:41:04,530 --> 00:41:06,750
We won't draw him.

549
00:41:06,750 --> 00:41:12,620
We draw this demon, hey, he is definitely
visible, so we'll mark him as object 0.

550
00:41:12,620 --> 00:41:15,300
We draw this other robot, hey, you know, he's visible.

551
00:41:15,300 --> 00:41:17,920
So we'll draw him.

552
00:41:17,920 --> 00:41:21,500
We check this other demon character;
he's not visible way off to the left.

553
00:41:21,500 --> 00:41:23,980
We won't send him to OpenGL.

554
00:41:23,980 --> 00:41:25,770
This hero character, he's definitely visible.

555
00:41:25,770 --> 00:41:27,280
He' also in the frustum.

556
00:41:27,280 --> 00:41:32,330
So we'll send him to OpenGL and then
this demon character also visible.

557
00:41:32,330 --> 00:41:34,030
We'll send him to OpenGL.

558
00:41:34,030 --> 00:41:38,710
OK? So now we have the set of objects
that we want to send to OpenGL.

559
00:41:38,710 --> 00:41:43,100
You can put this inside of a visibility list.

560
00:41:43,100 --> 00:41:47,130
Ok? Now one thing to note about this
is you don't want to draw the objects

561
00:41:47,130 --> 00:41:49,530
in the same order they were determined visible.

562
00:41:49,530 --> 00:41:51,640
Ok? You want to sort it by render state.

563
00:41:51,640 --> 00:41:53,700
What would happen here you'd bind the demon's texture?

564
00:41:53,700 --> 00:41:55,970
Draw him, bind the robot's texture, draw him.

565
00:41:55,970 --> 00:41:57,930
Bind the hero's texture, draw him.

566
00:41:57,930 --> 00:42:02,890
And then we'd rebind the demon sections
that we bound originally and draw the demon.

567
00:42:02,890 --> 00:42:09,000
OK? Instead what you want to do is sort them, so
that now the demons are together, one bind two draw.

568
00:42:09,000 --> 00:42:13,250
All right, so here's an algorithm that
you can use to sort your rendering state.

569
00:42:13,250 --> 00:42:14,270
It's called a state tree.

570
00:42:14,270 --> 00:42:16,950
So let's say you've got these four characters.

571
00:42:16,950 --> 00:42:20,400
You've got these two guys and they're
clearly using the same texture.

572
00:42:20,400 --> 00:42:25,110
And you've got these two guys, and you've got this
human character and he's got some metal armor on him

573
00:42:25,110 --> 00:42:27,210
and you've got this robot clearly all metal.

574
00:42:27,210 --> 00:42:31,570
So you want to have the shader that
does some little shininess effect.

575
00:42:31,570 --> 00:42:34,100
They used the same shader.

576
00:42:34,100 --> 00:42:38,820
You stick them inside of a tree
and you traverse it in order.

577
00:42:38,820 --> 00:42:42,800
So starting from the top, you bind the first shader.

578
00:42:42,800 --> 00:42:45,590
You bind the texture that's used by these two guys.

579
00:42:45,590 --> 00:42:49,740
You bind the VAO, and you render the demon.

580
00:42:49,740 --> 00:42:53,120
You go up and you've already bound
the texture, don't do it again.

581
00:42:53,120 --> 00:42:56,730
You bind the new VAO and you render this guy.

582
00:42:56,730 --> 00:43:02,470
Go up to the top and now we bind this new GLSL program.

583
00:43:02,470 --> 00:43:04,390
This shininess program.

584
00:43:04,390 --> 00:43:12,100
And we bind the texture, bind the
VAO, render this robot, go on up.

585
00:43:12,100 --> 00:43:18,720
You've already bound the GLSL program, so now we just bind
the texture for this human guy, find his VAO and render him.

586
00:43:18,720 --> 00:43:22,800
Now it looks kind of like a binary tree here,
but it would actually be an enary tree.

587
00:43:22,800 --> 00:43:24,170
This is a very simplistic scene.

588
00:43:24,170 --> 00:43:29,090
You probably would have, you know, many, many
shaders, which would make this tree much wider.

589
00:43:29,090 --> 00:43:31,620
Also, you might want to account
for different rendering state.

590
00:43:31,620 --> 00:43:39,850
Like you might want to account for depth, blend, clip
state, etc., which would make this a deeper tree.

591
00:43:39,850 --> 00:43:46,490
OK? In this case I determined that the GLSL program
objects I said, well those are pretty expensive to bind.

592
00:43:46,490 --> 00:43:48,740
So I'm going to put them at the top of the tree.

593
00:43:48,740 --> 00:43:53,690
We're going to set those first, so that
we don't have to rebind them very often.

594
00:43:53,690 --> 00:43:56,440
OK? So the more expensive objects at the top of your tree,

595
00:43:56,440 --> 00:44:01,540
less expensive objects like vertex
arrays towards the bottom.

596
00:44:01,540 --> 00:44:09,190
One way in which you can reduce CPU overhead, the CPU
overhead of draw calls, is to combine the draw calls.

597
00:44:09,190 --> 00:44:11,970
Basically make less draw calls.

598
00:44:11,970 --> 00:44:14,060
And there are two methods that I'll talk about.

599
00:44:14,060 --> 00:44:15,420
One is texture atlasing.

600
00:44:15,420 --> 00:44:19,190
And this is basically combining
multiple textures into a single texture.

601
00:44:19,190 --> 00:44:21,910
And the second one is instancing.

602
00:44:21,910 --> 00:44:25,830
Instancing requires some special hardware
that's only available on Mac OS X.

603
00:44:25,830 --> 00:44:30,550
My colleague Matt Collins will be talking about
that a little bit more tomorrow and how to use that.

604
00:44:30,550 --> 00:44:35,010
I'm actually going to talk about texture atlasing.

605
00:44:35,010 --> 00:44:41,880
Here you have these four characters, and you've
got these four textures to map to these characters.

606
00:44:41,880 --> 00:44:48,400
In order to draw this in a naive way would be to bind this
texture, draw to it, bind the second texture, draw to it,

607
00:44:48,400 --> 00:44:52,270
find the third texture, draw, find the fourth texture, draw.

608
00:44:52,270 --> 00:44:56,880
OK, you're binding four times for four textures.

609
00:44:56,880 --> 00:44:59,360
Instead you can bind it into one uber texture.

610
00:44:59,360 --> 00:45:01,040
A texture atlas.

611
00:45:01,040 --> 00:45:05,680
Then you bind that one texture, draw, draw, draw, draw.

612
00:45:05,680 --> 00:45:07,880
One bind, four draws.

613
00:45:07,880 --> 00:45:11,240
Much more efficient use of OpenGL.

614
00:45:11,240 --> 00:45:14,710
Here's an example of a texture atlas used in the Quest demo.

615
00:45:14,710 --> 00:45:17,170
Here we've got a lot of different
elements in a single texture.

616
00:45:17,170 --> 00:45:19,180
We've got some flags on the upper right.

617
00:45:19,180 --> 00:45:22,140
We've got a stone wall in the upper left.

618
00:45:22,140 --> 00:45:28,860
We've got stairs, we've got doors, we've
got statue, all in one texture, one bind,

619
00:45:28,860 --> 00:45:33,560
and they can draw a ton of different
things of their dungeon.

620
00:45:33,560 --> 00:45:34,870
Multithreading in OpenGL.

621
00:45:34,870 --> 00:45:41,320
So because there is a fair amount of CPU overhead that
OpenGL incurs, there are reasons to multithread it,

622
00:45:41,320 --> 00:45:46,200
so that you can amortize the CPU
costs across multiple cores.

623
00:45:46,200 --> 00:45:51,220
This makes sense on iOS 4 devices as well,
even though they only have a single core.

624
00:45:51,220 --> 00:45:53,180
CPU intensive calls can block.

625
00:45:53,180 --> 00:46:00,610
And that means that while they're blocking, while
you're in your main loop doing some OpenGL processing,

626
00:46:00,610 --> 00:46:06,960
you can't handle UI events, you can't
handle audio, you can't do your app logic.

627
00:46:06,960 --> 00:46:13,290
Additionally, if you're doing a lot of stuff on the main
thread, there is this is watchdog process that looks

628
00:46:13,290 --> 00:46:16,440
at your app and determines whether
you're in some infinite loop,

629
00:46:16,440 --> 00:46:19,510
whether you're behaving badly, and it may kill your app.

630
00:46:19,510 --> 00:46:26,240
So it may mistake you for doing something like
in an infinite loop or a block and some sort

631
00:46:26,240 --> 00:46:28,560
of deadlock and just kill your application.

632
00:46:28,560 --> 00:46:36,780
So you really want, you could put some of this processing
on anther thread and the watchdog won't do this to you.

633
00:46:36,780 --> 00:46:40,950
So here is the simplest multithreading
technique I'll describe.

634
00:46:40,950 --> 00:46:47,940
And basically you load a second, maybe third
thread, both with, or one or two OpenGL contexts.

635
00:46:47,940 --> 00:46:50,480
And you can use these threads to load data.

636
00:46:50,480 --> 00:46:51,700
Load textures.

637
00:46:51,700 --> 00:46:52,660
Load vertex data.

638
00:46:52,660 --> 00:46:53,780
Compile shaders.

639
00:46:53,780 --> 00:46:56,210
A lot of CPU heavy lifting.

640
00:46:56,210 --> 00:47:00,050
Important things to know is once you're done with
all that loading you want to kill your other threads.

641
00:47:00,050 --> 00:47:04,400
You only want to have one thread
running with an OpenGL context.

642
00:47:04,400 --> 00:47:08,330
OK? Because the other thread, two OpenGL
contexts is running at the same time.

643
00:47:08,330 --> 00:47:12,830
There is some CPU over head that might be
incurred, because there's some locking.

644
00:47:12,830 --> 00:47:18,480
And so two threads can block one another;
two OpenGL threads can block one other.

645
00:47:18,480 --> 00:47:22,660
So just have one OpenGL thread running at a time.

646
00:47:22,660 --> 00:47:28,820
Another more advanced technique is
to use a producer consumer paradigm.

647
00:47:28,820 --> 00:47:32,990
So in this case the main thread
produces data, it can produce, you know,

648
00:47:32,990 --> 00:47:36,810
the animation frame, which your characters are in.

649
00:47:36,810 --> 00:47:43,440
To position on the screen or position in the world,
you can compute the visibility of your objects.

650
00:47:43,440 --> 00:47:45,700
Use that frustum culling technique.

651
00:47:45,700 --> 00:47:53,850
On this thread you won't have an OpenGL context, you're
just producing data to render by a second thread.

652
00:47:53,850 --> 00:47:58,290
When the producer thread is done you
send all the render threads to begin.

653
00:47:58,290 --> 00:48:02,990
And then the render threads can take all that
data, consume it, and render with OpenGL.

654
00:48:02,990 --> 00:48:07,150
It has the only OpenGL context on it, that render thread.

655
00:48:07,150 --> 00:48:09,290
You don't have two OpenGL contexts.

656
00:48:09,290 --> 00:48:14,890
The main thread can then process
audio input and other app logic

657
00:48:14,890 --> 00:48:18,150
in parallel while the render thread
is actually drawing stuff.

658
00:48:18,150 --> 00:48:23,350
And let's say you still have some CPU
overhead and it's not well balanced.

659
00:48:23,350 --> 00:48:29,550
You can move some stuff, like maybe the
visibility test to the render thread.

660
00:48:29,550 --> 00:48:31,230
Give it a more even distribution.

661
00:48:31,230 --> 00:48:38,780
So I've talked a lot about using the
CPU, or the CPU and the GPU together.

662
00:48:38,780 --> 00:48:43,540
You need to also consider using the
GPU with the display, the other device.

663
00:48:43,540 --> 00:48:48,740
That is important to consider when coding your OpenGL.

664
00:48:48,740 --> 00:48:53,380
One thing to note is you can only render
as fast as the display can refresh.

665
00:48:53,380 --> 00:49:00,950
It doesn't make sense for you to render at 200 frames
a second if the user can only see 60 frames a second.

666
00:49:00,950 --> 00:49:02,960
OK? It just wastes battery power.

667
00:49:02,960 --> 00:49:07,550
You're doing a lot of processing that the
user will never have any context into.

668
00:49:07,550 --> 00:49:10,460
Will never see the result of.

669
00:49:10,460 --> 00:49:14,690
On iOS 4 you can use a CADisplayLink API.

670
00:49:14,690 --> 00:49:23,340
And we see a lot of apps using this NSTimer
API to initiate their per-frame rendering.

671
00:49:23,340 --> 00:49:31,410
Instead, we use this DisplayLink API, because the NSTime
is arbitrary when it's fired with respect to the display.

672
00:49:31,410 --> 00:49:37,820
What will happen is NSTimer might fire right before
the refresh, and so there's going to be some latency

673
00:49:37,820 --> 00:49:40,460
between the time you draw and then you can see it.

674
00:49:40,460 --> 00:49:44,460
Or it might be fired right after display has refreshed.

675
00:49:44,460 --> 00:49:48,010
So it's not going to be consistent with respect to display.

676
00:49:48,010 --> 00:49:51,940
And in some very pathological cases
it can reduce your frame rate.

677
00:49:51,940 --> 00:49:59,230
On Mac OS X you can use the analogous API CV display link.

678
00:49:59,230 --> 00:50:05,400
Now we see a lot of games trying to control their main loop.

679
00:50:05,400 --> 00:50:09,070
This is a kind of an outdated way of doing it.

680
00:50:09,070 --> 00:50:15,270
Because, again, you don't need to display, or don't
need to render any faster than the user can see.

681
00:50:15,270 --> 00:50:23,530
Looping more than needed wastes power, particularly on
these MacBooks where people want a fairly long battery life.

682
00:50:23,530 --> 00:50:29,710
You could implement some benchmark mode for advanced
users or developers that runs on the main loop.

683
00:50:29,710 --> 00:50:36,590
But under shipping game in a normal loops,
or for a normal running you may just want

684
00:50:36,590 --> 00:50:40,080
to use CVDisplayLink to initiate your rendering.

685
00:50:40,080 --> 00:50:46,510
A note about coding for both platforms.

686
00:50:46,510 --> 00:50:52,760
So OpenGL ES is a subset of OpenGL on the desktop.

687
00:50:52,760 --> 00:51:02,620
So if you code using OpenGL ES 2.0, you can port your code
that you've invested a lot of time on iOS 4 onto the Mac.

688
00:51:02,620 --> 00:51:04,520
And vice versa.

689
00:51:04,520 --> 00:51:14,430
OK? So if you've got this Mac application, and if you
stick to all the calls that OpenGL ES 2.0 provides,

690
00:51:14,430 --> 00:51:18,290
you can pretty easily port it to the iPhone OS 4.

691
00:51:18,290 --> 00:51:20,890
There are some things to be aware of.

692
00:51:20,890 --> 00:51:25,780
Clearly there are more memory and performance
constraints on the embedded iOS 4 devices.

693
00:51:25,780 --> 00:51:27,590
So you need to consider that.

694
00:51:27,590 --> 00:51:30,070
There are different compressed formats.

695
00:51:30,070 --> 00:51:32,310
You will need to translate for that.

696
00:51:32,310 --> 00:51:36,770
And there are for some kind of silly
reason, slightly different function names.

697
00:51:36,770 --> 00:51:40,370
Now the parameters of these functions are exactly the same.

698
00:51:40,370 --> 00:51:47,240
On OpenGL ES we have this BindVertexArray
OES function and it's exact same function

699
00:51:47,240 --> 00:51:50,920
as BindVertexArrayAPPLE, it just
has a slightly different name.

700
00:51:50,920 --> 00:51:53,500
So you just need to rename your functions.

701
00:51:53,500 --> 00:52:01,910
The sample code that I provided for this session that
you can find for the session's site, compiles for both

702
00:52:01,910 --> 00:52:07,140
and you can kind of use it as a template or
maybe a starter for creating your application

703
00:52:07,140 --> 00:52:10,410
that you might want to port and ship on both platforms.

704
00:52:10,410 --> 00:52:13,970
It's this kind of cool little reflection demo.

705
00:52:13,970 --> 00:52:18,690
And it works pretty well on most platforms.

706
00:52:18,690 --> 00:52:23,900
So in summary, there is a fair amount of
CPU overhead that OpenGL needs to incur,

707
00:52:23,900 --> 00:52:28,960
and you can minimize this to efficiently access the GPU.

708
00:52:28,960 --> 00:52:33,410
Validation is where a lot of this CPU overhead occurs.

709
00:52:33,410 --> 00:52:37,330
You can use OpenGL objects to cache this validation

710
00:52:37,330 --> 00:52:42,060
and minimize state changes and draw
calls to reduce the validation.

711
00:52:42,060 --> 00:52:49,450
For more information you can contact our Graphics
and Game Technologies Evangelist, Allan Schaffer.

712
00:52:49,450 --> 00:52:54,380
As well there's a ton of documentation
on OpenGL at the OpenGL Dev Center.

713
00:52:54,380 --> 00:52:59,690
And there are a lot of engineers from Apple at
these Apple Developer Forums, so you can get help

714
00:52:59,690 --> 00:53:04,770
and ask questions throughout the
year at this devforums.apple.com.

715
00:53:04,770 --> 00:53:14,460
Also, I've posted a bunch of code snippets
and the sample code at this link down here.

716
00:53:14,460 --> 00:53:16,950
So you can check that out.

717
00:53:16,950 --> 00:53:25,060
There's a Q&A on the different variables that you shouldn't
use in your GLSL program and some other information.

718
00:53:25,060 --> 00:53:31,390
This is just the first of six OpenGL
sessions at this year's WWDC.

719
00:53:31,390 --> 00:53:37,750
And there's some great information for both
Mac and iPhone developers, or iOS 4 developers.

720
00:53:37,750 --> 00:53:42,840
The first is OpenGL ES an overview on, for the iPhone.

721
00:53:42,840 --> 00:53:46,190
And that's mainly geared for the iOS 4 developers.

722
00:53:46,190 --> 00:53:49,820
And the second is OpenGL ES Shading and Advanced Rendering.

723
00:53:49,820 --> 00:53:51,200
And this is a pretty cool one.

724
00:53:51,200 --> 00:53:53,530
My colleagues have come up with some great demos.

725
00:53:53,530 --> 00:53:59,620
And even if you're a Mac developer, a lot of
these demos are easily portable to the Mac.

726
00:53:59,620 --> 00:54:04,030
So they're going to be talking about some shadows,
some reflections, some really cool techniques

727
00:54:04,030 --> 00:54:07,620
that you should probably check out
even if you're a Mac developer.

728
00:54:07,620 --> 00:54:11,260
There's also an OpenGL ES Tuning and Optimization session.

729
00:54:11,260 --> 00:54:18,820
And this is going to be great for developers
coding for iOS, but also some of the techniques

730
00:54:18,820 --> 00:54:21,970
that they mention you'll be able
to use and leverage on the Mac.

731
00:54:21,970 --> 00:54:27,940
They're going to be describing a tool that's
available on iOS 4 the OpenGL Analyzer.

732
00:54:27,940 --> 00:54:32,090
And even though it works only on iOS 4,
if you're a Mac developer you can use some

733
00:54:32,090 --> 00:54:34,710
of the same techniques to profile your applications.

734
00:54:34,710 --> 00:54:37,640
They're also going to be talking
about some of the GPU bottlenecks.

735
00:54:37,640 --> 00:54:43,830
Now I talked a lot about CPU bottlenecks, but there is a
whole class of bottlenecks on the graphics processing unit

736
00:54:43,830 --> 00:54:51,590
that you should be aware of and potentially could run
into after you've optimized the CPU portion of your app.

737
00:54:51,590 --> 00:54:57,270
And then tomorrow morning at 9 o'clock there's OpenGL
for Mac OS X and my college Matt Collins will be talking

738
00:54:57,270 --> 00:55:03,820
about a number of the newly available features
on Mac OS X instancing, texture arrays.

739
00:55:03,820 --> 00:55:07,920
He's also got some really cool demos
that you might want to take a look at.

740
00:55:07,920 --> 00:55:11,570
And then finally there's this Taking
Advantage of Multiple GPUs session,

741
00:55:11,570 --> 00:55:16,550
and they're going to be talking
about OpenCL the other GPU API.

742
00:55:16,550 --> 00:55:23,680
And it's used in conjunction with OpenGL
and leveraging multiple GPUs on the Mac Pro

743
00:55:23,680 --> 00:55:31,630
to do some really cool processing with OpenCL and really
great rendering with OpenGL on two different devices.

744
00:55:31,630 --> 00:55:33,820
So thanks a lot for coming.

745
00:55:33,820 --> 00:55:34,740
I really appreciate it.

746
00:55:34,740 --> 00:55:40,010
And I'm hoping you guys will be able to take these
techniques and really efficiently use OpenGL.

747
00:55:40,010 --> 00:55:51,290
[ Applause ]

