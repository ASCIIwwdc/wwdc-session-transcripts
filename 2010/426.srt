1
00:00:06,380 --> 00:00:09,140
>> David Hayward: Good afternoon, and
thank you for coming to today's discussion

2
00:00:09,140 --> 00:00:12,210
on "Image Processing and Effects with Core Image".

3
00:00:12,210 --> 00:00:14,360
It's a lot of fun stuff to talk about today.

4
00:00:14,360 --> 00:00:19,440
I'll start off by giving you a brief introduction to Core
Image for those of you who may be new to the technology

5
00:00:19,440 --> 00:00:23,910
and discuss quickly how you can add it to your application.

6
00:00:23,910 --> 00:00:29,010
After that I'll pass the stage over to Daniel, who will
be talking about how to use Core Image most efficiently

7
00:00:29,010 --> 00:00:33,800
in your application to get best performance
and then, finally, Alex will come up on stage

8
00:00:33,800 --> 00:00:37,620
and talk about writing some filters including
one at the end with some really twisted math,

9
00:00:37,620 --> 00:00:41,030
but don't worry it's not on the final exam.

10
00:00:41,030 --> 00:00:43,770
So, first a quick introduction to Core Image.

11
00:00:43,770 --> 00:00:51,070
So, Core Image is used throughout the Mac OS X
Operating System for everything from fun special effects

12
00:00:51,070 --> 00:00:59,540
like our dashboard ripple effect to effects in
iChat and in Photo Booth and in screensavers,

13
00:00:59,540 --> 00:01:02,840
and it's always used for serious
image processing in our applications

14
00:01:02,840 --> 00:01:06,060
like iPhoto Aperture including your applications.

15
00:01:06,060 --> 00:01:08,450
So, how does Core Image work?

16
00:01:08,450 --> 00:01:15,090
Well, it's built on its core on what we call
filter kernels, which are small portions of code,

17
00:01:15,090 --> 00:01:17,920
which are written in architecture-independent language.

18
00:01:17,920 --> 00:01:24,940
That language is C-like with vector extensions and
it's based on an OpenGL shading language subset.

19
00:01:24,940 --> 00:01:32,940
Core Image can then execute those kernels on either as
CPU or on GPU depending on how your application sees fit

20
00:01:32,940 --> 00:01:38,590
and Core Image is built on other key
architectures of Mac OS X such as OpenGL

21
00:01:38,590 --> 00:01:41,880
and OpenCL in order to get its best performance.

22
00:01:41,880 --> 00:01:45,450
So here's the basic concept of Core Image.

23
00:01:45,450 --> 00:01:50,300
The idea is you have filters, which
perform per pixel operations on images.

24
00:01:50,300 --> 00:01:55,430
In this very simple example here, we have an original
image and we're going to apply a Sepia Tone filter

25
00:01:55,430 --> 00:01:58,930
to produce a new image that had effect applied to it.

26
00:01:58,930 --> 00:02:03,140
However, we can start adding additional
filters and create chains of filters.

27
00:02:03,140 --> 00:02:09,190
For example, here we have the Sepia Tone filter and
then we've added to that a hue adjustment filter,

28
00:02:09,190 --> 00:02:11,430
which gives us a little blue tone effect.

29
00:02:11,430 --> 00:02:16,180
So, this allows, as you can see,
far more interesting effects.

30
00:02:16,180 --> 00:02:22,560
One key feature of Core Image, however, is that it can
concatenate multiple filters and the idea behind this is

31
00:02:22,560 --> 00:02:27,140
to reduce the need for intermediate buffers
wherever possible to get best performance.

32
00:02:27,140 --> 00:02:30,420
And it's not just simple chains that are supported.

33
00:02:30,420 --> 00:02:34,930
You can actually have complex graphs of filters
in order to achieve much more interesting effects

34
00:02:34,930 --> 00:02:41,960
such as sharpening effects and gloom effect
like we kind of see here in this example.

35
00:02:41,960 --> 00:02:47,380
So, in addition to the framework for executing filters,
Core Image includes a large set of built-in filters,

36
00:02:47,380 --> 00:02:50,170
which allow you to get started with Core Image right away.

37
00:02:50,170 --> 00:02:55,190
These built-in filters we include include several
filters for doing geometry adjustments

38
00:02:55,190 --> 00:02:59,790
such as affine transforms and cos transforms.

39
00:02:59,790 --> 00:03:08,140
We have distortion effects like this glass distortion;
a wide variety of blurs, Gaussian blurs, motion blurs;

40
00:03:08,140 --> 00:03:16,150
we have sharpening filters; we have color
adjustments like this one, which is an invert filter;

41
00:03:16,150 --> 00:03:21,020
we have color effects like this is a
Sepia Tone filter we mentioned earlier;

42
00:03:21,020 --> 00:03:24,940
we also have a bunch of stylized fun filters
like this one, which is called crystallized,

43
00:03:24,940 --> 00:03:31,860
which turns an image into a crystal; we also
have half-tone effects and also tiling effects,

44
00:03:31,860 --> 00:03:39,540
which will take either a rectangle or a triangle and create
an infinite image out of a portion of your input image;

45
00:03:39,540 --> 00:03:45,870
we have generators, which are for generating starburst
effect and checkerboards, whatever you can imagine;

46
00:03:45,870 --> 00:03:51,960
we have transition effects, which are useful for using Core
Image on video, which allow you to segue from one piece

47
00:03:51,960 --> 00:04:00,440
of image to another image; we have composite operations
like standard Porter-Duff composite operations;

48
00:04:00,440 --> 00:04:06,070
and we also have a set of reduction operations such as
filters, which will take a large image and reduce it

49
00:04:06,070 --> 00:04:11,020
down to the average color of an image or the
histogram of an image and this could be very useful

50
00:04:11,020 --> 00:04:13,300
as foundation for other image processing algorithms.

51
00:04:13,300 --> 00:04:19,170
So, as I alluded to earlier, Core
Image supports large rendering trees

52
00:04:19,170 --> 00:04:24,770
and one of our keys features is we will optimize
that tree for you to get the best performance.

53
00:04:24,770 --> 00:04:29,870
Our Core Image runtime has just-in-time
optimizing compiler and one of its key features is

54
00:04:29,870 --> 00:04:35,470
that it defers its optimization until you
actually draw the image and this allows it

55
00:04:35,470 --> 00:04:38,670
to only evaluate what portion of
your image is needed to draw.

56
00:04:38,670 --> 00:04:45,010
So, if you're zoomed in on a very large image, Core Image
will only apply your filter to the portion that is visible.

57
00:04:45,010 --> 00:04:50,170
Similarly it also supports tiling of large images so if
you have a very large image, it can break it up into pieces

58
00:04:50,170 --> 00:04:54,420
for you without you having to do
all the additional work of tiling.

59
00:04:54,420 --> 00:04:58,880
Core Image also performs optimization
algorithms; the other typical compilers don't.

60
00:04:58,880 --> 00:05:05,260
For example, it will concatenate multiple color matrix
operations if they appear in series or if you have a chain

61
00:05:05,260 --> 00:05:10,910
that involves a premultiply and an unpremultiply
of alpha, it will optimize those away.

62
00:05:10,910 --> 00:05:18,460
It also if you will reorder scale operations so if have
a complex filter that's being applied to a large image

63
00:05:18,460 --> 00:05:24,210
and then it's downsized to the screen, Core Image is
smart enough to move the down sample operation earlier

64
00:05:24,210 --> 00:05:29,590
in the processing tree so that the
complex filter is evaluated on less data.

65
00:05:29,590 --> 00:05:35,340
Another optimization is it only does color management
when it needs to, which is typically on the input image

66
00:05:35,340 --> 00:05:40,240
and then finally rendering to the
display, to the display for a file.

67
00:05:40,240 --> 00:05:44,410
One thing to keep in mind is these optimizations
are not just about improving performance.

68
00:05:44,410 --> 00:05:49,230
By optimizing out to sequential operations like
I've outlined here, we also get better quality

69
00:05:49,230 --> 00:05:54,660
because there's fewer operations which
can introduce quantization artifacts.

70
00:05:54,660 --> 00:05:58,870
So, that's a brief introduction
to the architecture of Core Image.

71
00:05:58,870 --> 00:06:04,110
Let me talk for a few slides about how you
can add it very easily to your application.

72
00:06:04,110 --> 00:06:10,570
So, first off there's a few Core Image objects that are
Cocoa based objects that you want to be familiar with.

73
00:06:10,570 --> 00:06:13,390
First and foremost is the CIFilter object.

74
00:06:13,390 --> 00:06:19,310
This is a mutable object which represents the effect
you want to apply, and it has a set of input parameters,

75
00:06:19,310 --> 00:06:24,740
which can either be numerical parameters or images,
and the results of a filter is an output image,

76
00:06:24,740 --> 00:06:29,410
which then you can do further filtering on.

77
00:06:29,410 --> 00:06:36,720
Another key object type is the CIImage Object, which is an
immutable object that represents the recipe for an image.

78
00:06:36,720 --> 00:06:41,510
This image can either represent a file just
read from disk or it can represent the output

79
00:06:41,510 --> 00:06:44,090
of a filter that I just mentioned earlier.

80
00:06:44,090 --> 00:06:50,290
The other key object to keep in mind is the
CIContext Object and this is the destination

81
00:06:50,290 --> 00:06:58,760
to which Core Image will render your results and the
CIContext Objects can be based on either OpenGL context

82
00:06:58,760 --> 00:07:03,300
or on Core Graphics context depending on
what you see fit best for your application.

83
00:07:03,300 --> 00:07:07,950
So, how do you add Core Image to your application?

84
00:07:07,950 --> 00:07:10,810
Well, you basically can do it in four easy steps.

85
00:07:10,810 --> 00:07:13,170
First is we want to create a CIImage Object.

86
00:07:13,170 --> 00:07:17,470
In this brief example, we're going
to create a CIImage from a URL.

87
00:07:17,470 --> 00:07:19,920
Second, we want to create a filter object.

88
00:07:19,920 --> 00:07:24,140
We create a filter in Core Image by specifying its name.

89
00:07:24,140 --> 00:07:27,070
In this example, the CISepiaTone filter.

90
00:07:27,070 --> 00:07:30,950
We also at this time can specify the
parameters for this filter, the input image

91
00:07:30,950 --> 00:07:33,970
and the amount to the effect we want to apply.

92
00:07:33,970 --> 00:07:37,250
Thirdly, we want to create a CIContext into which to draw.

93
00:07:37,250 --> 00:07:44,050
Here we create a context based on a CGContext and lastly
step four we want to draw the filter into that context.

94
00:07:44,050 --> 00:07:50,160
So, we ask for the output image of the filter and then we
draw that into the context and that's all there is to it.

95
00:07:50,160 --> 00:07:54,170
Here's the same steps written in code-like format.

96
00:07:54,170 --> 00:08:00,990
Here we have a slightly more complicated example and
four lines of code; we're creating an image from an URL;

97
00:08:00,990 --> 00:08:07,270
we're applying the Sepia Tone filter as we did earlier;
then on top of that we're applying a hue-adjustment filter,

98
00:08:07,270 --> 00:08:13,960
which will rotate the hue in the
image by 1.57 degrees by radiance.

99
00:08:13,960 --> 00:08:18,870
Lastly, we get the output image of that
filter, and we draw it into our context.

100
00:08:18,870 --> 00:08:23,870
Now, one of the great things about Core Image
is that in a very few number of lines of code,

101
00:08:23,870 --> 00:08:29,110
you can leverage all of the key technologies that
are below Core Image such as OpenGL and OpenCL.

102
00:08:29,110 --> 00:08:35,250
For example, these four operations here when
Core Image converts that to OpenGL work,

103
00:08:35,250 --> 00:08:39,500
will represent all of this code in
OpenGL for you and this includes tiling,

104
00:08:39,500 --> 00:08:44,450
this includes converting the kernels
to shaders and so forth.

105
00:08:44,450 --> 00:08:49,960
Similarly when Core Image is leverage OpenCL to
do its work, it will also convert that same set

106
00:08:49,960 --> 00:08:54,340
of operations into a healthy amount of OpenCL work.

107
00:08:54,340 --> 00:09:02,580
So, that's our brief introduction to Core Image and
how to add it to your application to talk about how

108
00:09:02,580 --> 00:09:04,700
to get the best performance out of Core Image.

109
00:09:04,700 --> 00:09:09,510
I'm going to pass the stage over to Daniel, who
will be talking about getting the best performance.

110
00:09:09,510 --> 00:09:14,640
[ Applause ]

111
00:09:14,640 --> 00:09:15,830
>> Daniel Eggert: Thank you, David.

112
00:09:15,830 --> 00:09:19,560
So David showed you how easy it is to use Core Image.

113
00:09:19,560 --> 00:09:23,700
So, I want to show you a small demo that does exactly that.

114
00:09:23,700 --> 00:09:26,950
It's a very simple demo that uses Core Image.

115
00:09:26,950 --> 00:09:34,230
Then next I want to take you through five topics
related to Core Image and show you some things

116
00:09:34,230 --> 00:09:40,900
and how to do things efficiently with Core Image,
a few things to be aware of and then, finally,

117
00:09:40,900 --> 00:09:44,530
take you through some debugging tips at the end.

118
00:09:44,530 --> 00:09:46,630
So the demo is a very simple demo.

119
00:09:46,630 --> 00:09:52,460
It opens image and then inside the
NSViews, subclass is draw method,

120
00:09:52,460 --> 00:09:57,750
it applies one of the built-in Core Image
filters to it and draws it to the screen.

121
00:09:57,750 --> 00:10:00,930
So let's take a look at what that looks like.

122
00:10:00,930 --> 00:10:03,940
So, this is the pointilizer demo app.

123
00:10:03,940 --> 00:10:13,700
Let me drag an image onto the app, and it simply
opens that image and here's our custom NSView

124
00:10:13,700 --> 00:10:21,410
and this filter pointilizes and I can change the
radius, which is the input parameter there's a filter

125
00:10:21,410 --> 00:10:26,020
and you can see the dots getting
larger, and I can drag the slider

126
00:10:26,020 --> 00:10:31,230
and they get smaller and that's all there is to that demo.

127
00:10:31,230 --> 00:10:36,920
So this simple demo application is
available on the attendee website.

128
00:10:36,920 --> 00:10:41,360
I suggest to you to download this app check
it out to get started with Core Image.

129
00:10:41,360 --> 00:10:49,080
Also, the next few things I'm going to talk about most
of those are illustrated in this simple application.

130
00:10:49,080 --> 00:10:50,670
So, the five things I want to talk about.

131
00:10:50,670 --> 00:10:58,480
I'll start off with something that most of you
have probably heard about which is NSImage.

132
00:10:58,480 --> 00:11:06,810
This is the Cocoa image object that
most of you know very well probably.

133
00:11:06,810 --> 00:11:12,980
Some things that people are not aware of is that an
NSImage can both be a source and a destination and,

134
00:11:12,980 --> 00:11:17,030
hence, is inherently mutable pixel container.

135
00:11:17,030 --> 00:11:24,320
The content inside an NSImage can
change depending on various situations.

136
00:11:24,320 --> 00:11:31,340
Also an NSImage can contain both bit
map data and things like PDF data.

137
00:11:31,340 --> 00:11:35,880
So the other image type that is available to you

138
00:11:35,880 --> 00:11:43,590
on the system is something called
CGImageRef, which is the quartz image object.

139
00:11:43,590 --> 00:11:48,140
This in contrast to NSImage is an immutable pixel container.

140
00:11:48,140 --> 00:11:54,860
It contains exactly one bitmap-based
image and this is the type you want to use

141
00:11:54,860 --> 00:11:59,130
for best fidelity when you're using image processing.

142
00:11:59,130 --> 00:12:04,520
This is the type you want to read your
data into and if you're saving onto disk,

143
00:12:04,520 --> 00:12:07,900
you want to use the CGImageRef-based APIs.

144
00:12:07,900 --> 00:12:12,190
Again, the sample code will take
you through some of these steps.

145
00:12:12,190 --> 00:12:14,000
Have a look at that.

146
00:12:14,000 --> 00:12:19,820
Next up is I want to talk a bit about CPU and GPU.

147
00:12:19,820 --> 00:12:26,130
You've probably all heard about that a lot of work is
being, like the GPU is the new kid on the block you want

148
00:12:26,130 --> 00:12:34,400
to use the GPU, but you need to be aware that both
the CPU and the GPU each have a unique benefit.

149
00:12:34,400 --> 00:12:42,630
For example, the CPU is still what will give you the best
fidelity whereas the GPU will give you the best performance.

150
00:12:42,630 --> 00:12:44,710
So, it's really a tradeoff there.

151
00:12:44,710 --> 00:12:53,120
Another more subtle detail is that
the CPU is more background friendly.

152
00:12:53,120 --> 00:13:00,050
On the CPU, you have thread scheduling so
if you want something on the background,

153
00:13:00,050 --> 00:13:04,420
you'll probably want to run it in the background on the CPU.

154
00:13:04,420 --> 00:13:09,520
The GPU has the obvious advantage that it
offloads the CPU so if you have a lot of work

155
00:13:09,520 --> 00:13:13,650
on the CPU you might want to use the GPU.

156
00:13:13,650 --> 00:13:16,790
So, it really depends on your application.

157
00:13:16,790 --> 00:13:21,380
You need to think about what is
the right thing to use for you.

158
00:13:21,380 --> 00:13:29,240
Two examples if you're applying an image effect on
image, if you're apply an image effect on image,

159
00:13:29,240 --> 00:13:35,870
if you're apply an effect on image and want to say
it to disk, you're probably going for best fidelity

160
00:13:35,870 --> 00:13:38,980
and in that case you want to use the CPU.

161
00:13:38,980 --> 00:13:46,040
If you're interactively updating the
display, you probably want to use the GPU.

162
00:13:46,040 --> 00:13:51,490
So now that you know which one of the
two you want to use, how do you do it?

163
00:13:51,490 --> 00:13:54,590
David showed you how to create a CIContext.

164
00:13:54,590 --> 00:13:58,910
Well, when you create it, you can
create it with an options dictionary.

165
00:13:58,910 --> 00:14:05,560
Inside that options dictionary, you set
kCIContextUseSoftwareRenderer to yes,

166
00:14:05,560 --> 00:14:10,910
and that will make that context be a CPU context.

167
00:14:10,910 --> 00:14:15,930
If you don't, you pass that option
dictionary in when you create the context;

168
00:14:15,930 --> 00:14:21,120
if you don't specify it, that context will be a GPU context.

169
00:14:21,120 --> 00:14:33,630
The other thing to note as David already mentioned is
that CPU Context will use OpenCL on Snow Leopard and 4.

170
00:14:33,630 --> 00:14:41,780
The next thing is probably the most important thing
to take away from what I will say in this session.

171
00:14:41,780 --> 00:14:44,300
It's about your CIContext.

172
00:14:44,300 --> 00:14:49,810
The CIContext inside Core Image hold on
to a lot of state and a lot of caches.

173
00:14:49,810 --> 00:14:57,550
That is not visible to you, but Core Image does that to
ensure that your application gets the best performance

174
00:14:57,550 --> 00:15:01,170
and you really need to keep your CIContext around

175
00:15:01,170 --> 00:15:10,080
and reuse your CIContext otherwise all
those caches will be thrown away every time.

176
00:15:10,080 --> 00:15:17,600
So, as I've written here, reusing your CIContext
is usually the single change in your application

177
00:15:17,600 --> 00:15:20,420
that leads to the largest performance win.

178
00:15:20,420 --> 00:15:27,540
So check your application if you're using Core Image and
make sure you're doing this and well, how would you do that?

179
00:15:27,540 --> 00:15:33,630
If you're using like in the example app
you're drawing inside an NSview drawRect,

180
00:15:33,630 --> 00:15:38,580
you can simply use NSGraphicsContext
and get the CIContext from there

181
00:15:38,580 --> 00:15:41,080
and that will automatically do the right thing for you.

182
00:15:41,080 --> 00:15:45,150
It will reuse the same CIContext.

183
00:15:45,150 --> 00:15:53,040
If you are creating your own CIContext, you simply
retain it in the beginning or, sorry about that,

184
00:15:53,040 --> 00:15:56,820
you retain it in the beginning, you reuse it and then

185
00:15:56,820 --> 00:16:02,410
in the end before your application
quits, you release the CIContext.

186
00:16:02,410 --> 00:16:03,870
So, remember this.

187
00:16:03,870 --> 00:16:09,690
If you're not doing this, it might
give you a large performance win.

188
00:16:09,690 --> 00:16:17,390
The next thing is color management and the good
story here is that you get color management for free.

189
00:16:17,390 --> 00:16:24,200
Core Image automatically does color management
for you by respecting the input images color space

190
00:16:24,200 --> 00:16:29,190
and respecting the context of output color space.

191
00:16:29,190 --> 00:16:33,110
The filters are applied in the linear working space.

192
00:16:33,110 --> 00:16:39,080
So at the beginning Core Image converts from the
images color space to the linear working space

193
00:16:39,080 --> 00:16:49,680
and on the output side Core Image converts from that
linear space into the context output color space.

194
00:16:49,680 --> 00:16:52,670
Sometimes people want to turn off color management.

195
00:16:52,670 --> 00:16:54,180
You can do that.

196
00:16:54,180 --> 00:17:04,010
Again, in the options dictionary, you can set on
the input side the KCIImage color space to null.

197
00:17:04,010 --> 00:17:11,300
That will turn off color management on the
input side, likewise on the output side,

198
00:17:11,300 --> 00:17:17,070
and you get setKCIContextOutputColorSpace to null.

199
00:17:17,070 --> 00:17:20,840
That will turn off color management on the output side.

200
00:17:20,840 --> 00:17:24,940
When you're entering to the display,
the display has a color profile

201
00:17:24,940 --> 00:17:31,950
and we color manage to match the displays color space.

202
00:17:31,950 --> 00:17:37,690
This color space will change and there
are two reasons why it could change.

203
00:17:37,690 --> 00:17:44,100
One thing is if the user drags the window
of your application turn on the display,

204
00:17:44,100 --> 00:17:48,940
if the user has a multiple display setup,
the other situation is more subtle.

205
00:17:48,940 --> 00:17:56,310
If the user while your application is running goes
into system preferences and changes the color profile,

206
00:17:56,310 --> 00:18:03,250
you want your application to update the display
so that your window still looks correctly.

207
00:18:03,250 --> 00:18:05,690
You would do it like this.

208
00:18:05,690 --> 00:18:16,420
You call set displays when screen profile changes to yes
on your window and then inside your drawRect method, again,

209
00:18:16,420 --> 00:18:20,180
you use NSGraphics context, get your CIContext from there.

210
00:18:20,180 --> 00:18:29,320
That will make sure that your window is redrawn
correctly when it moves from one display to another.

211
00:18:29,320 --> 00:18:37,940
This does not all, however, work when the user
changes the display profile in the system preferences.

212
00:18:37,940 --> 00:18:39,340
Go and check out the sample code.

213
00:18:39,340 --> 00:18:42,880
It shows you exactly how to handle that situation.

214
00:18:42,880 --> 00:18:53,230
Some of your applications might use off screen caches where
you've rendered something to that you are then reusing.

215
00:18:53,230 --> 00:19:00,000
Those off-screen caches need to be
invalidated when the display profile changes.

216
00:19:00,000 --> 00:19:03,500
Again, it's kind of the same scenario,
but slightly different.

217
00:19:03,500 --> 00:19:08,890
You can get notified about the
display profile changing either

218
00:19:08,890 --> 00:19:14,060
in the windows delegate you can
implement the window change screen profile

219
00:19:14,060 --> 00:19:17,730
and implement that method, clear your cache there.

220
00:19:17,730 --> 00:19:20,440
There's a notification you can register for.

221
00:19:20,440 --> 00:19:25,600
It's called NSWindowDidChangeScreenProfileNotification.

222
00:19:25,600 --> 00:19:29,540
You can use that to clear your caches.

223
00:19:29,540 --> 00:19:35,030
The fifth thing is threading and, again, the
good story here is that if you're using the CPU,

224
00:19:35,030 --> 00:19:39,510
Core Image will automatically use
all available cores on the system.

225
00:19:39,510 --> 00:19:45,830
You will get multi-threading for free
with Core Image rendering to the CPU.

226
00:19:45,830 --> 00:19:52,790
There is another side of threading, obviously, if
you are using multiple threads in your application

227
00:19:52,790 --> 00:19:56,630
and there's some things there that you need to be aware of,

228
00:19:56,630 --> 00:20:02,860
calling into Core Image the CIContext
are not thread safe.

229
00:20:02,860 --> 00:20:08,390
Everything else inside Core Image is, but if
you're using background threads for Core Image,

230
00:20:08,390 --> 00:20:17,080
you need to create separate CIContext instances for
each thread that you're calling into Core Image from.

231
00:20:17,080 --> 00:20:25,950
You can use locking, obviously, and just use one shared
context, but we recommend using separate CIContext instances

232
00:20:25,950 --> 00:20:33,080
as that is usually the fastest approach, but it
depends on exactly how your application works--

233
00:20:33,080 --> 00:20:35,580
these two possibilities.

234
00:20:35,580 --> 00:20:40,010
The other thing is if you go down
the road of calling into Core Image

235
00:20:40,010 --> 00:20:43,880
from a background thread, you need to set the stack size.

236
00:20:43,880 --> 00:20:46,420
Core Image actively uses the stack.

237
00:20:46,420 --> 00:20:50,360
We recommend setting the stack size to 64 megabytes.

238
00:20:50,360 --> 00:20:56,400
If you are using Cocoa, this is how you set
the stack size on newly created threads.

239
00:20:56,400 --> 00:20:59,320
That brings us to debugging.

240
00:20:59,320 --> 00:21:05,100
Now you are using Core Image and you want
to know what is going on inside Core Image,

241
00:21:05,100 --> 00:21:10,240
we have something that is called render tree printing.

242
00:21:10,240 --> 00:21:16,330
It allows you to see constantly what Core Image is up to.

243
00:21:16,330 --> 00:21:25,660
We will render to the console for every time
that you tell Core Image to draw an image

244
00:21:25,660 --> 00:21:30,290
into a context to render an image into a context.

245
00:21:30,290 --> 00:21:36,180
There's an environment variable called CI_PRINT_TREE.

246
00:21:36,180 --> 00:21:46,500
When you set that to one, each of these draw calls
will cause the filter tree to be dumped to the console

247
00:21:46,500 --> 00:21:50,740
and this gives you a peek into what Core Image is up to.

248
00:21:50,740 --> 00:21:58,270
One thing to note though is as David already
mentioned Core Image does tiling whenever necessary.

249
00:21:58,270 --> 00:22:06,410
If the output size of the image is very large, one
single draw operation might actually cause multiple draws

250
00:22:06,410 --> 00:22:09,700
and in that case, you will see multiple outputs.

251
00:22:09,700 --> 00:22:16,620
So, in Xcode what you would do you would find
your executable in your Xcode project under Groups

252
00:22:16,620 --> 00:22:19,330
and Files there's a section called Executables.

253
00:22:19,330 --> 00:22:27,490
You find your application there, you Right-click
on it, select "Get Info", out comes a window,

254
00:22:27,490 --> 00:22:32,910
you need to go into the "Arguments Tab",
and in there you hit the little plus

255
00:22:32,910 --> 00:22:36,920
at the bottom and you can add an environment variable.

256
00:22:36,920 --> 00:22:39,370
Again, it's called CI_PRINT_TREE.

257
00:22:39,370 --> 00:22:40,410
You can set that to one.

258
00:22:40,410 --> 00:22:47,300
And there's a nice little checkbox on the
side so you can just leave it in there

259
00:22:47,300 --> 00:22:51,380
and just toggle the checkbox if
you wanted to turn it on or off.

260
00:22:51,380 --> 00:22:57,650
If it's turned on, it will impact
performance because you are logging a lot

261
00:22:57,650 --> 00:23:01,480
so this is an easy way to turn it on and off.

262
00:23:01,480 --> 00:23:06,500
So, now you've turned it on what will
actually happen, what will you see?

263
00:23:06,500 --> 00:23:10,690
You will see something like this and you will see
many of these if you're using Core Image a lot,

264
00:23:10,690 --> 00:23:14,360
and obviously we think you should be using Core Image a lot.

265
00:23:14,360 --> 00:23:21,750
The thing to see here is lines
like these and each line starts

266
00:23:21,750 --> 00:23:26,540
with these two asterisks is a render
operation, is a draw operation.

267
00:23:26,540 --> 00:23:29,670
Let's look closer at the first one of these.

268
00:23:29,670 --> 00:23:34,790
It looks something like this and
these, this is the render operation

269
00:23:34,790 --> 00:23:38,410
and you need to read these from the bottom going up.

270
00:23:38,410 --> 00:23:44,230
The first line we see, which is
the last line, is your input image.

271
00:23:44,230 --> 00:23:53,810
In this case, it's a 292x438 image that is
being put into Core Image into the filter tree.

272
00:23:53,810 --> 00:23:59,900
We go up there's a kernel being applied to it and there's
a fine transform being applied to the result of that

273
00:23:59,900 --> 00:24:04,370
and there's some more kernels being applied
to the result of the affine transform

274
00:24:04,370 --> 00:24:07,690
and finally this is being rendered to a context.

275
00:24:07,690 --> 00:24:17,300
In this case, the context name is fe-context-cl-cpu,
which tells you this is a CPU context using OpenCL.

276
00:24:17,300 --> 00:24:23,230
So let's briefly look at the second one
of the two that I had up on the display.

277
00:24:23,230 --> 00:24:24,820
Again, we read from the bottom.

278
00:24:24,820 --> 00:24:27,430
We start out with a FILL operation.

279
00:24:27,430 --> 00:24:28,640
Here's our input image.

280
00:24:28,640 --> 00:24:33,230
In this case, it's a 1200x900 image.

281
00:24:33,230 --> 00:24:36,710
We go further up there's some kernels applied to it.

282
00:24:36,710 --> 00:24:42,020
There's a source over, some more kernels
and finally we end up at the context.

283
00:24:42,020 --> 00:24:43,950
In this case, the context name is different.

284
00:24:43,950 --> 00:24:52,320
It's an fe-context-gl, which tells you in this
case the context is a GPU context using OpenGL.

285
00:24:52,320 --> 00:24:55,290
So what can you use this for?

286
00:24:55,290 --> 00:24:59,840
You're seeing all these things
and what's the madness behind it.

287
00:24:59,840 --> 00:25:07,950
Well, one easy debugging help that you can gain from this
is you can see how many times a thing is being rendered.

288
00:25:07,950 --> 00:25:11,640
You can find your input images in this output.

289
00:25:11,640 --> 00:25:14,250
One easy thing is just to look at the sizes of the images.

290
00:25:14,250 --> 00:25:20,500
If you know that you're inputting an image
that's 1200x900, you can identify those images

291
00:25:20,500 --> 00:25:27,350
and let's say you're taking an image, applying
some filters to it and saving it to disk,

292
00:25:27,350 --> 00:25:32,380
you would only expect one render
call being done on that image.

293
00:25:32,380 --> 00:25:36,830
If you're seeing 21 render calls,
you should probably go back

294
00:25:36,830 --> 00:25:42,990
and look at your application logic and
see if everything looks sane there.

295
00:25:42,990 --> 00:25:50,300
The thing I mentioned earlier is if you have large appellate
sizes, Core Image might actually call draw multiple times

296
00:25:50,300 --> 00:25:57,570
because of tiling, but still we have seen
shipping apps that had poor performance simply

297
00:25:57,570 --> 00:26:00,140
because they were drawing too many times.

298
00:26:00,140 --> 00:26:04,650
Not only when saving to disk but also updating your display.

299
00:26:04,650 --> 00:26:08,520
This can give you some hints to what is actually happening.

300
00:26:08,520 --> 00:26:15,690
Another thing that you can use this for is to see
are you using the CPU when you expect to use a CPU?

301
00:26:15,690 --> 00:26:19,010
Are you using the GPU when you expect to use the GPU?

302
00:26:19,010 --> 00:26:31,170
You can, again, identify your input images and then
see if the context name matches your expectations.

303
00:26:31,170 --> 00:26:41,430
If you are rendering to the display for interactivity,
you probably want to use a GPU, does that really happen?

304
00:26:41,430 --> 00:26:43,960
The CI_PRINT_TREE stuff is something, again,

305
00:26:43,960 --> 00:26:47,790
you can try with a demo application
that is available on the attendee side.

306
00:26:47,790 --> 00:26:52,670
You can turn it on there and see what
that small sample application does.

307
00:26:52,670 --> 00:26:57,380
That is all I have for you and now I'd
like to ask Alex on stage who is going

308
00:26:57,380 --> 00:27:01,510
to tell you something about writing your own filters.

309
00:27:01,510 --> 00:27:06,040
[ Applause ]

310
00:27:06,040 --> 00:27:07,130
>> Alexandre Naaman: Thank you, Daniel.

311
00:27:07,130 --> 00:27:08,720
My name is Alexandre Naaman.

312
00:27:08,720 --> 00:27:11,440
I'm a software engineer on Core Image and
today I'm going to talk to you a little bit

313
00:27:11,440 --> 00:27:13,640
about writing your own customer CI Filter.

314
00:27:13,640 --> 00:27:18,840
So, so far we've seen today a little bit the cast of
characters and how you go ahead and put those together

315
00:27:18,840 --> 00:27:24,750
into creating your own app in an efficient manner and
what I'm going to show you today is first off two samples;

316
00:27:24,750 --> 00:27:29,480
one very simple sample, which is going to be desaturation
filter, and then a more complex one based an idea

317
00:27:29,480 --> 00:27:33,140
that M.C. Escher had in 1956, and he
actually didn't complete so we're going

318
00:27:33,140 --> 00:27:35,290
to talk about those in a fair amount of detail.

319
00:27:35,290 --> 00:27:37,080
So, first question you're going to ask yourself is,

320
00:27:37,080 --> 00:27:41,370
why would I write a filter instead
of just using what's already there?

321
00:27:41,370 --> 00:27:45,690
And two main reasons why you would want to write your
own filters is because first off the filter doesn't exist

322
00:27:45,690 --> 00:27:49,800
in the existing set that we ship in OS or you
can't create the effect that you're looking

323
00:27:49,800 --> 00:27:52,570
for by daisy chaining these two things together.

324
00:27:52,570 --> 00:27:54,910
So, any number of effects together.

325
00:27:54,910 --> 00:27:57,160
The way we're going to do this
well, there are two main ways.

326
00:27:57,160 --> 00:28:02,090
First off you can try doing it inside of Quartz
Composer and writing a kernel and then porting it over

327
00:28:02,090 --> 00:28:06,850
and writing some objective C code in your
kernel, but for the purpose of our demo today,

328
00:28:06,850 --> 00:28:11,750
we're going to do everything inside of Quartz Composer and
it's really easy once you implemented your algorithm inside

329
00:28:11,750 --> 00:28:16,210
of Quartz Composer to bring it inside of an app.

330
00:28:16,210 --> 00:28:18,710
So, our first sample is going to be relatively simple.

331
00:28:18,710 --> 00:28:23,860
We're just going to desaturate an image and we're going
to have the slider that controls how desaturated it gets.

332
00:28:23,860 --> 00:28:28,100
So, this is what the composition looks like
inside of Quartz Composer so it's fairly simple.

333
00:28:28,100 --> 00:28:35,260
We're going to take an input image and then we're going
to pass it through our kernel that we're going to write

334
00:28:35,260 --> 00:28:38,930
and we're going to go through that step-by-step
and desaturate it to a certain amount until we end

335
00:28:38,930 --> 00:28:45,000
up with a new image and that is the entire composition
and the amount value is going to be a slider that we have

336
00:28:45,000 --> 00:28:48,460
that goes from zero to one and
controls how desaturated the image gets.

337
00:28:48,460 --> 00:28:53,160
So, let's take a look at what the kernel is
going to look like and how Core Image works.

338
00:28:53,160 --> 00:29:00,120
So, here we're looking at a sub part of the initial
input image because Core Image works on tiles

339
00:29:00,120 --> 00:29:03,250
and that's not important right now, but it will be in
a moment when we talk about some of the things you need

340
00:29:03,250 --> 00:29:06,090
to keep in mind when you start writing your own filters .

341
00:29:06,090 --> 00:29:10,180
So, first off Core Image is going to ask us to render,

342
00:29:10,180 --> 00:29:14,790
to provide a new color value at
every single pixel location, XY.

343
00:29:14,790 --> 00:29:19,620
So, if we're asked to render a point here, the
first thing we're going to do is read its value.

344
00:29:19,620 --> 00:29:24,690
So, we're going to get the current coordinate and
then we're going to determine the value of that color

345
00:29:24,690 --> 00:29:29,760
in our input image at that location and
unpre-multiply it because colors that come

346
00:29:29,760 --> 00:29:33,730
into the kernels have alpha pre-multiplied.

347
00:29:33,730 --> 00:29:40,090
The next thing we're going to do is compute
brightness for it, CAP Y, and these values,

348
00:29:40,090 --> 00:29:44,040
the RGV values come from the SRGV color
profile and you can find those by looking

349
00:29:44,040 --> 00:29:46,670
in the color sync utility for that profile.

350
00:29:46,670 --> 00:29:52,530
So, we're going to compute a likeness, CAP Y, and
we're going to create a new color that we're going

351
00:29:52,530 --> 00:29:57,090
to call desaturated color and we're going to assign
the red, green and blue components to be equal

352
00:29:57,090 --> 00:30:00,690
to CAP Y and preserve the original alpha value.

353
00:30:00,690 --> 00:30:06,430
So, now we have two colors unpre-multiply
and, sorry, a RIG and desaturated color,

354
00:30:06,430 --> 00:30:12,370
and what we're going to return is some mixture of those
two and if this looks familiar, this function mix,

355
00:30:12,370 --> 00:30:18,790
it's because the kernel language that you used to write
your own custom filters inside of CI looks a lot like GLSL.

356
00:30:18,790 --> 00:30:20,860
It's a subset of that.

357
00:30:20,860 --> 00:30:28,680
Now, we can vary the value of amount, and we'll have
a more or less desaturated image and so if we do that,

358
00:30:28,680 --> 00:30:33,710
we can see how that affects our output and this is,
again, just looking at a subsection of the image

359
00:30:33,710 --> 00:30:37,060
and this is actually our kernel
running in Real Time inside of Keynote.

360
00:30:37,060 --> 00:30:41,800
So, we took the kernel that we had inside of Quartz
Composer and we just dragged it in there and varied

361
00:30:41,800 --> 00:30:44,620
that value amount and we end up with this.

362
00:30:44,620 --> 00:30:48,810
So, it's pretty simple to prototype
the effects you're trying to generate.

363
00:30:48,810 --> 00:30:54,020
That being said this is a fairly simple sample, but there
are two other things you really need to keep in mind

364
00:30:54,020 --> 00:31:00,010
when you start writing your own kernels and those are
the Domain of Definition, or DOD, and Region of Interest.

365
00:31:00,010 --> 00:31:04,490
So, in the case of the sample that we were
just looking at, if we take our input image

366
00:31:04,490 --> 00:31:08,290
and let's suppose that it was a size 1200x1000.

367
00:31:08,290 --> 00:31:12,760
After we've applied the effect, the image
is going to be of the exact same size.

368
00:31:12,760 --> 00:31:15,050
This is what we call the Domain of Definition,

369
00:31:15,050 --> 00:31:20,010
which is to say given your input image once the
filter is run, what is the size of the input image?

370
00:31:20,010 --> 00:31:23,420
In this case, it doesn't change we don't have
to tell Core Image to do anything special,

371
00:31:23,420 --> 00:31:29,010
but you can imagine that if you did a zoom or a blur that
the image might get either smaller or larger and you need

372
00:31:29,010 --> 00:31:31,900
to tell Core Image what to do in that situation.

373
00:31:31,900 --> 00:31:38,540
Now, as I mentioned earlier when we perform the
rendering, we actually provide you with tiles.

374
00:31:38,540 --> 00:31:43,680
So, we do a tiled approach that is going to be
optimized for the device that you're targeting.

375
00:31:43,680 --> 00:31:50,980
So, if we were trying to render this small section
here, what we need to know is that is the data

376
00:31:50,980 --> 00:31:53,000
that we need from our original input image?

377
00:31:53,000 --> 00:31:58,390
And this is what we call the Region of Interest or
ROI, and so in this case, we have a one-to-one mapping;

378
00:31:58,390 --> 00:32:02,640
for every pixel in, we have another pixel out, and
we're not reading any additional data so we don't have

379
00:32:02,640 --> 00:32:06,170
to specify an ROI, but as soon as you write
anything a little bit more complicated,

380
00:32:06,170 --> 00:32:08,340
you may have to take those things into account.

381
00:32:08,340 --> 00:32:12,780
So, let's look at another sample that's
going to be slightly more tricky,

382
00:32:12,780 --> 00:32:16,420
and this is just going to be involving transposing an image.

383
00:32:16,420 --> 00:32:19,240
So, for every, we're just going to
swap around the x and y coordinates.

384
00:32:19,240 --> 00:32:20,590
Very simple.

385
00:32:20,590 --> 00:32:26,260
And the kernel looks like this so we just sample the
image but instead of sampling the image at dEstCoord.xy,

386
00:32:26,260 --> 00:32:28,240
we're going to sample it at dEstCoord.yx.

387
00:32:28,240 --> 00:32:32,790
So, how does this affect DOD?

388
00:32:32,790 --> 00:32:38,430
Well, if we start off with an image that's
600x400 and we don't tell Core Image otherwise,

389
00:32:38,430 --> 00:32:45,670
it's going to assume that the image that we're trying to
render is of the exact same size, which is to say 600x400.

390
00:32:45,670 --> 00:32:46,620
That's not what we want.

391
00:32:46,620 --> 00:32:51,020
As you can see, I've colored here in blue the
section where Core Image doesn't know what to do.

392
00:32:51,020 --> 00:32:55,620
It doesn't know where to grab the pixels
from so what we want is to tell Core Image

393
00:32:55,620 --> 00:32:59,330
that the DOD for this image is actually 400x600.

394
00:32:59,330 --> 00:33:02,200
So, we want to swap those values around.

395
00:33:02,200 --> 00:33:08,430
The way we're going to do that is by getting the
extent of the input image, creating a new filter shape

396
00:33:08,430 --> 00:33:14,830
and that basically has the origin for the x and y swap and
the width and height swapped and then when we call apply,

397
00:33:14,830 --> 00:33:20,180
and this all happens in your output image for your
filter, we're going to pass in one additional parameter

398
00:33:20,180 --> 00:33:26,360
that is the KCIApplyOptionDefinition and give it the
new shape that we just created and when we do this,

399
00:33:26,360 --> 00:33:29,790
Core Image will know that what we're trying
to render our result from this filter is going

400
00:33:29,790 --> 00:33:33,790
to be a size 400x600 and has a new origin.

401
00:33:33,790 --> 00:33:35,050
So, that takes care of the DOD.

402
00:33:35,050 --> 00:33:38,130
How does this affect the ROI?

403
00:33:38,130 --> 00:33:41,860
Well, this is the result that we're
looking for, and as I mentioned earlier,

404
00:33:41,860 --> 00:33:44,120
when Core Image does its rendering it tiles it.

405
00:33:44,120 --> 00:33:49,250
So, if we were, for example, to render a tile in the
upper corner of the image located at this location

406
00:33:49,250 --> 00:33:54,910
and of that size, if we don't tell Core Image otherwise
the result we're going to get is going to look like this

407
00:33:54,910 --> 00:33:58,700
and this is a really common mistake when
people starting writing their own filters even

408
00:33:58,700 --> 00:34:00,980
if they've been writing them for years actually.

409
00:34:00,980 --> 00:34:05,970
So, we're going to, let's look at what
happens if you didn't specify ROI.

410
00:34:05,970 --> 00:34:12,370
So, let's look at our input image and let's look at
where that rectangle that we tried to render came from.

411
00:34:12,370 --> 00:34:13,360
It's in the middle of nowhere.

412
00:34:13,360 --> 00:34:15,860
There's no data for us to transpose here.

413
00:34:15,860 --> 00:34:21,090
We're reading basically garbage so we're going to
end up with something unknown or basically based

414
00:34:21,090 --> 00:34:23,890
on our rom mode but not the results you want.

415
00:34:23,890 --> 00:34:27,680
So, once again, what we need to do
is tell Core Image that the data

416
00:34:27,680 --> 00:34:29,360
that we're looking for comes from a different place.

417
00:34:29,360 --> 00:34:34,770
So, we're going to swap the origin so the x and y for the
origin and we're going to swap the size and we're going

418
00:34:34,770 --> 00:34:41,260
to do that by creating a region of method inside of our
filter and just swapping those values as I mentioned.

419
00:34:41,260 --> 00:34:46,910
One thing to keep in mind when you write your own filters
is always think about how does it affect the ROI and DOD?

420
00:34:46,910 --> 00:34:53,680
And if you're sampling at locations that aren't equal to the
current dEstCoord, you probably need to write both of those

421
00:34:53,680 --> 00:34:58,900
and if the rendering isn't correct chances are
that you need to tweak that a little bit more.

422
00:34:58,900 --> 00:35:04,170
So, now that we're done with the simple example,
let's talk about a slightly more complicated example.

423
00:35:04,170 --> 00:35:13,860
So, the code for this is available for download right
now on developer.apple.com/mac/library/samplecode/Droste,

424
00:35:13,860 --> 00:35:20,720
and it's based on an idea that M.C. Escher had
in 1956 and a lithograph that he tried to produce

425
00:35:20,720 --> 00:35:24,670
that he actually never finished,
but can now be done in realtime.

426
00:35:24,670 --> 00:35:29,120
So, we're going to take an image
that looks like this and we're going

427
00:35:29,120 --> 00:35:33,170
to create what he called a cyclical annular expansion.

428
00:35:33,170 --> 00:35:42,080
So, basically a recursive image that spins around, and
it caused him to have some almighty headaches and me too.

429
00:35:43,450 --> 00:35:45,860
[Laughter] So, let's look into this one a little bit more.

430
00:35:45,860 --> 00:35:48,190
So, let's forget about the recursion
for a split second here.

431
00:35:48,190 --> 00:35:52,400
Let's look at how we're going to
deform one level of this image,

432
00:35:52,400 --> 00:35:58,230
and if we animate that that's going to look like this.

433
00:35:58,230 --> 00:36:03,830
The basic idea here being that if we perform this repeatedly
so we start off with our first level of deformation

434
00:36:03,830 --> 00:36:10,040
and we just keep applying it over and over and over again to
out input image until the point where the data is too small

435
00:36:10,040 --> 00:36:15,120
to make any visible effect on our final output
image, we're going to get our desired result.

436
00:36:15,120 --> 00:36:19,840
Now, one thing you might have noticed here is that
our image has actually been sheared and shrunk.

437
00:36:19,840 --> 00:36:24,540
So, in order to not end up with this kind of unfinished
painting, we're going to add in one more layer

438
00:36:24,540 --> 00:36:29,330
on the background, and if we do that,
we'll end up with the desired result.

439
00:36:29,330 --> 00:36:33,330
The grid that we're going to use is going to look a
little bit like this, and I'm going to talk about the math

440
00:36:33,330 --> 00:36:38,000
and I promise I only have two slides
on math a little bit later.

441
00:36:38,000 --> 00:36:40,450
[Laughter] So, let's talk about
how we're first going to do this.

442
00:36:40,450 --> 00:36:41,900
We're going to use Source Over.

443
00:36:41,900 --> 00:36:46,430
So, if we start with our input image
A and we apply the effect level zero,

444
00:36:46,430 --> 00:36:50,350
we end up with image B, our first deformation.

445
00:36:50,350 --> 00:36:55,980
We do this again, level one, so the
scaled-down version, we get a new image, C.

446
00:36:55,980 --> 00:37:02,900
And if we do image C over image B, we start getting
what looks like the result that we're looking for.

447
00:37:02,900 --> 00:37:12,440
I mean if we do this repeatedly N times, we're
going to eventually get our final output image.

448
00:37:12,440 --> 00:37:17,590
So, the question that we have to figure out is, and
this is how Core Image works it's going to ask you

449
00:37:17,590 --> 00:37:24,110
for the color value at a given pixel, and you have to
figure out from your source image where does that come from.

450
00:37:24,110 --> 00:37:30,240
So, let's pretend we were trying to render the
dot on the corner, a prime of that little table,

451
00:37:30,240 --> 00:37:36,220
and we need to figure out where that
comes from in the original source image.

452
00:37:36,220 --> 00:37:40,690
And you can see that the rectangle that we're going to be
cutting out for this image where the recursion is going

453
00:37:40,690 --> 00:37:44,660
to happen is in yellow and even this
represents the first level of deformation even

454
00:37:44,660 --> 00:37:48,970
after the very first level the image is going to get
scaled down a little bit and there are going to be areas

455
00:37:48,970 --> 00:37:54,240
that are outside of the bounds of our original image
that are pictured in green, red, sine and blue,

456
00:37:54,240 --> 00:37:57,160
and we're going to have to figure
out what to do with those as well.

457
00:37:57,160 --> 00:38:00,840
So, these are my two math slides.

458
00:38:00,840 --> 00:38:02,900
I'm going to go over them quickly here.

459
00:38:02,900 --> 00:38:07,110
So, what we're going to do is going to
look a lot like a logarithmic spiral.

460
00:38:07,110 --> 00:38:15,270
So here we have an equation for a logarithmic spiral r is
equal to a times e to the b theta and a if you think back

461
00:38:15,270 --> 00:38:24,710
to your math classes, is going to control the number of
strands in the spiral and b controls the periodicity.

462
00:38:24,710 --> 00:38:26,860
So let's take a look at how we're going to deform the image.

463
00:38:26,860 --> 00:38:30,560
With the inner circle here corresponding to
the region that we're going to be cutting out

464
00:38:30,560 --> 00:38:33,760
and the outer circle corresponding
to the bounds of the image.

465
00:38:33,760 --> 00:38:40,370
So, we've got two measurements we've got r1 our
inner radius, and r2, the radius that we're trying

466
00:38:40,370 --> 00:38:41,890
to get to once we perform the deformation.

467
00:38:41,890 --> 00:38:51,460
Now, at theta is equal to zero e raised to the power
of zero is equal to one, therefore, a is equal to r1.

468
00:38:51,460 --> 00:38:56,360
We need to figure out the values for a and b so we
can pass these into our kernel a little bit later.

469
00:38:56,360 --> 00:39:03,940
Then when theta is equal to 2 pi so once we've done one
entire revolution, our two is going to be equal to r1,

470
00:39:03,940 --> 00:39:10,630
our value a that we just figured out, times e raised to
the power of b times 2 pi and if we isolated the value

471
00:39:10,630 --> 00:39:16,300
of b we end up with b is equal to log of r2
divided by r1 and all of that divided by 2 pi.

472
00:39:16,300 --> 00:39:21,040
So, this works, but it's not a conformal map,
which is to say it doesn't preserve angles.

473
00:39:21,040 --> 00:39:24,380
So, if we had a synthetic image with
no people in it, it would look fine,

474
00:39:24,380 --> 00:39:27,510
but if we had any other stuff it wouldn't look correct.

475
00:39:27,510 --> 00:39:28,880
The whole image looks skewed.

476
00:39:28,880 --> 00:39:33,490
So, although we've preserved angles going
radially out we haven't preserved angles

477
00:39:33,490 --> 00:39:35,820
in between the points and this is not going to look correct.

478
00:39:35,820 --> 00:39:40,730
So, we need to do a little bit more tweaking to
our kernel in order to get the desired result.

479
00:39:40,730 --> 00:39:51,200
So let's look again at our image, and the first thing we're
going to do is convert it to a polar log coordinate system.

480
00:39:51,200 --> 00:40:01,010
So, we've unwrapped it and then we're going to rotate it
and scale it and then finally replicate it along the X-axis

481
00:40:01,010 --> 00:40:05,570
and when we do that, we will get a conformal map
and we'll get something that looks like this,

482
00:40:05,570 --> 00:40:07,750
which is going to give us a desired result.

483
00:40:07,750 --> 00:40:08,520
Those are all my map slides.

484
00:40:08,520 --> 00:40:10,040
[Laughter]

485
00:40:10,040 --> 00:40:11,100
So, let's look at the kernel.

486
00:40:11,100 --> 00:40:15,410
Believe it or not this is the entire
kernel for performing a Droste Effect.

487
00:40:15,410 --> 00:40:17,460
So, we're going to pass in a few parameters.

488
00:40:17,460 --> 00:40:24,110
R.x is equal to a or r1; r.y is equal to
log of r2 divided by r1 and divided by 2 pi,

489
00:40:24,110 --> 00:40:29,470
which is b in the equation you looked at earlier, and then a
scaling factor, which initially is going to be equal to 1.0

490
00:40:29,470 --> 00:40:34,270
and then for each subsequent operation is going to
equal to image width divided by inner rectangle width

491
00:40:34,270 --> 00:40:38,520
and then we're just going to keep taking that
to the second power or third power, et cetera,

492
00:40:38,520 --> 00:40:40,910
et cetera, to create each additional iteration.

493
00:40:40,910 --> 00:40:48,640
So, our kernel is going to take a few parameters
as inputs the first one being the input image,

494
00:40:48,640 --> 00:40:53,080
the second one being the location of a center of the
image so the center of the rectangle that we chose to cut

495
00:40:53,080 --> 00:41:01,110
out from our image and the third one being our values a
and b and then the scaling factor that we talked about.

496
00:41:01,110 --> 00:41:04,010
So the first thing we're going to do
is we're going to move our coordinate

497
00:41:04,010 --> 00:41:06,200
that we're currently trying to evaluate to the center.

498
00:41:06,200 --> 00:41:08,950
So everything is relative to the center
of the rectangle that we tried to cut out.

499
00:41:08,950 --> 00:41:16,320
And then we're going to convert that, we will figure out
the angle of that point so we're going to convert that point

500
00:41:16,320 --> 00:41:22,980
into polar coordinates so we've got the
distance squared and then do .5 that.

501
00:41:22,980 --> 00:41:29,260
So, now we've got our polar coordinates and we're going to
perform the rotation and the scaling and then we're going

502
00:41:29,260 --> 00:41:36,370
to convert that point once again back into
Cartesian coordinates and perform the exponentiation,

503
00:41:36,370 --> 00:41:41,630
which is going to give us the logarithmic spiral that
we were looking for and the last step we're going

504
00:41:41,630 --> 00:41:45,840
to do is scale that point if necessary
and then move it back to the center

505
00:41:45,840 --> 00:41:48,960
from where it came from and that is the entire effect.

506
00:41:48,960 --> 00:41:55,270
So this works, but as we saw earlier it
requires a lot of passes over the data

507
00:41:55,270 --> 00:41:56,890
and that means a lot of intermediate buffers.

508
00:41:56,890 --> 00:42:01,450
So, you can imagine if you had multiple levels of
recursion, this is going to end up being quite slow.

509
00:42:01,450 --> 00:42:05,270
So the question we want to ask ourselves
is, can we do this in a single pass?

510
00:42:05,270 --> 00:42:11,680
The key thing to note here is that when b in our equation
is equal to zero, we end up with r is equal to a.

511
00:42:11,680 --> 00:42:12,210
That's it.

512
00:42:12,210 --> 00:42:15,470
So this is going to give us a hall of mirrors effect.

513
00:42:15,470 --> 00:42:19,480
So, if we were to try and cut out
this rectangle here in yellow,

514
00:42:19,480 --> 00:42:26,100
what we really want to do is replicate what's not inside
the yellow inside the yellow and do that repeatedly,

515
00:42:26,100 --> 00:42:30,440
which is where the scaling factor comes from that we
talked about earlier and that's going to look like this.

516
00:42:30,440 --> 00:42:33,200
The question is, can we do this in a single pass?

517
00:42:33,200 --> 00:42:35,270
And I have good news, we can.

518
00:42:35,270 --> 00:42:38,320
So, let's take a look at this in a little bit more detail.

519
00:42:38,320 --> 00:42:42,930
We're going to cut out this section in
yellow and we want to replicate the image in.

520
00:42:42,930 --> 00:42:48,710
So, we're going to move it to the center once again and then
when we're asked to render a point, let's say on the corner

521
00:42:48,710 --> 00:42:53,230
of the arm chair here, what we need to do
is figure out where does that point come

522
00:42:53,230 --> 00:42:56,010
from within the outer section of the image?

523
00:42:56,010 --> 00:42:57,380
Where is the valid data?

524
00:42:57,380 --> 00:43:02,970
And so what we're going to do is we're going to draw a line
from the center out and we're going to scale this point

525
00:43:02,970 --> 00:43:09,780
by that same scaling factor until we reach valid pixel
data and we'll look at the code for this in a second.

526
00:43:09,780 --> 00:43:15,860
And the same way we saw that even on the first iteration
sometimes we'll be asked to render data that falls outside

527
00:43:15,860 --> 00:43:20,530
of the image bounds so sometimes we're going to have
to take points that fall outside and bring them in.

528
00:43:20,530 --> 00:43:23,030
So, we're going to divide the value
of the current coordinate

529
00:43:23,030 --> 00:43:26,270
by the same scaling factor, and
again, we'll do that repeatedly.

530
00:43:26,270 --> 00:43:31,670
In terms of testing for this, we have two points here,
which correspond to the rectangle that we've chosen

531
00:43:31,670 --> 00:43:39,510
and those are simply at the inner rectangle width divided
by two for width and height and minus inner rectangle

532
00:43:39,510 --> 00:43:45,300
within height divided by two, and then we have two
additional points which correspond to the outer bounds

533
00:43:45,300 --> 00:43:55,620
of our image, which are just at center.x, center.y and
minus center.x, minus center.y. So let's look at the code.

534
00:43:55,620 --> 00:43:57,470
So, the code is mostly unchanged.

535
00:43:57,470 --> 00:44:03,660
We're just going to add a few for loops here and we can
unrule these because it's a fixed number of iterations.

536
00:44:03,660 --> 00:44:08,340
So, we're just going to be passing in one
additional parameter, which is the dimensions of half

537
00:44:08,340 --> 00:44:17,950
of the inner rectangle and then the first for loop is going
to take an existing point and scale it continuously based

538
00:44:17,950 --> 00:44:21,950
on whether or not it falls outside of the image
bounds or not and if it's not, it won't change it.

539
00:44:21,950 --> 00:44:28,370
It's just going to do divide by one so it won't affect
the position and then if on the other hand we had a point

540
00:44:28,370 --> 00:44:33,700
that was inside the inner rectangle, we're going to
keep scaling it out for a certain number of iterations

541
00:44:33,700 --> 00:44:38,510
until we get a point that is in the
valid area and the rest is unchanged.

542
00:44:38,510 --> 00:44:44,230
So, we get hall of mirrors plus
the Droste Effect in a single pass.

543
00:44:44,230 --> 00:44:48,640
Now, that doesn't view with alpha blending,
and if we look at our picture of our iMac,

544
00:44:48,640 --> 00:44:53,450
you can see that the sections colored
here in green look horrible.

545
00:44:53,450 --> 00:44:57,490
So, the question is, can we do this in a single pass?

546
00:44:57,490 --> 00:45:00,670
And you see we applied the Droste
Effect it looks kind of bad.

547
00:45:00,670 --> 00:45:05,820
So, we can use the same trick that we used for scaling
points if we realize that alpha is not equal to one.

548
00:45:05,820 --> 00:45:10,120
So, if we're asked to render a point where alpha
isn't equal to one, we're just going to move it in

549
00:45:10,120 --> 00:45:14,040
and keep accumulating values until we have alpha equals one.

550
00:45:14,040 --> 00:45:18,220
So in terms of code, it's going to look like this.

551
00:45:18,220 --> 00:45:20,600
So we're just going to use Porter Duff alpha blending.

552
00:45:20,600 --> 00:45:22,640
We're going to have another for loop.

553
00:45:22,640 --> 00:45:27,970
Truth be told we probably didn't need four iterations
because each new iteration involves a new sampling operation

554
00:45:27,970 --> 00:45:30,870
so that's on the expensive side, but that's the basic idea.

555
00:45:30,870 --> 00:45:36,580
We're just going to compute a new coordinate, look at the
value for that and keep adding it to our current color

556
00:45:36,580 --> 00:45:40,410
if necessary and then if we do
that, we'll get alpha blending.

557
00:45:40,410 --> 00:45:43,410
So we can do everything in a single pass.

558
00:45:43,410 --> 00:45:48,880
So, let's talk a little bit about how
this filter is in terms of performance.

559
00:45:48,880 --> 00:45:55,780
So, first off I talked a little bit about ROI earlier and
this is a perfect example of when it's really important

560
00:45:55,780 --> 00:46:01,430
to specify an ROI because in this case we can't determine
ahead of time when we're trying to render a small subsection

561
00:46:01,430 --> 00:46:03,440
of the image how much of the original image we need.

562
00:46:03,440 --> 00:46:07,440
We might need the entire image to render just a small tile.

563
00:46:07,440 --> 00:46:12,390
So, this is not a tileable operation, which
means that you're going to be limited in terms

564
00:46:12,390 --> 00:46:16,830
of the maximum output size for the image that
you can create to the limits for that device

565
00:46:16,830 --> 00:46:22,270
so the maximum texture size or the sizes in OpenCL.

566
00:46:22,270 --> 00:46:28,030
Also had we gone down the multi-pass approach, we could
have chosen to just simply take our original input image,

567
00:46:28,030 --> 00:46:31,250
scale and rotate it and do the Source Over.

568
00:46:31,250 --> 00:46:32,180
That's another thing.

569
00:46:32,180 --> 00:46:39,790
Also because we're not using the built in affine
transform and rotate methods inside of Core Image,

570
00:46:39,790 --> 00:46:44,010
we're going to end up with some aliasing artifact
so we might want to do some multi-sampling in order

571
00:46:44,010 --> 00:46:46,010
to make our image look a little bit smoother.

572
00:46:46,010 --> 00:46:52,350
And one thing that's really important to note
is given the recursive nature of this algorithm,

573
00:46:52,350 --> 00:46:59,360
the very first thing you want to do is match the aspect
ratio of the image that you're trying to perform this effect

574
00:46:59,360 --> 00:47:04,420
to be identical to the aspect ratio of
the rectangle that you're cutting out.

575
00:47:04,420 --> 00:47:07,460
So, let's take a look at how this works.

576
00:47:07,460 --> 00:47:13,300
So, we've implemented this inside of Quartz Composer
and first thing I'm going to do is click two points

577
00:47:13,300 --> 00:47:21,790
to indicate what portion of the image I want to cut out
and then I'm going to enable the effect and we're done.

578
00:47:21,790 --> 00:47:28,550
So, we can do this on and then we can change the
values of a and b to see how that affects our result,

579
00:47:28,550 --> 00:47:36,200
and we can take a look at some of the
other graphs and how they get affected

580
00:47:36,200 --> 00:47:49,630
by these things including our little spiral here, which
was kind of fun, and we can also do it on live video

581
00:47:49,630 --> 00:47:56,400
and we can go really crazy [applause] and
you can see how I felt before I got on stage.

582
00:48:00,600 --> 00:48:03,230
[Laughter] Okay, and this is available for you right now.

583
00:48:03,230 --> 00:48:05,940
You can download it on the website
via the URL that I showed you earlier.

584
00:48:05,940 --> 00:48:07,950
It's kind of spooky.

585
00:48:07,950 --> 00:48:14,620
I know. Okay, if you're curious and want to learn a
little bit more about the math behind all of this stuff,

586
00:48:14,620 --> 00:48:19,700
there's some people in the Netherlands that
came up, that figured out how this all worked

587
00:48:19,700 --> 00:48:24,450
and without them this would never have been possible, and
they published a paper in the AMS, which you can get at here

588
00:48:24,450 --> 00:48:30,620
as well and Jos Leys, whose name I probably butchered,
also has an interesting web page about the math behind all

589
00:48:30,620 --> 00:48:33,880
of this and one good thing to keep
in mind or a good reference for you

590
00:48:33,880 --> 00:48:38,710
when you start writing your own kernels is the GLSL
quick reference, which is available for download

591
00:48:38,710 --> 00:48:42,450
from the Khronos website, which I've listed here.

592
00:48:42,450 --> 00:48:48,340
In addition when you start writing your own kernels,
there are a few good books you might want look at,

593
00:48:48,340 --> 00:48:54,600
Digital Image Warping by George Wolberg, which has a
lot of information about image resampling; GPU Gems 3,

594
00:48:54,600 --> 00:49:01,400
which has a good object tracking demo
written in Core Image that you can look at;

595
00:49:01,400 --> 00:49:05,080
and then finally Digital Image Processing,
which is a good overview of image processing

596
00:49:05,080 --> 00:49:08,860
in general and has as good chapter on color.

597
00:49:08,860 --> 00:49:16,260
You can contact Allan Schaffer at aschaffer@apple.com
or go to our developer forums at devforums.apple.com.

598
00:49:16,260 --> 00:49:23,200
And on that note I'd like to thank you all for coming,
and I hope you enjoy the rest of the conference.

