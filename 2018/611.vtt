WEBVTT

00:00:07.516 --> 00:00:15.500 A:middle
[ Music ]

00:00:17.516 --> 00:00:23.336 A:middle
[ Applause ]

00:00:23.836 --> 00:00:24.826 A:middle
&gt;&gt; Good morning everyone.

00:00:25.046 --> 00:00:26.676 A:middle
My name is Karol Gasinski, and I

00:00:26.676 --> 00:00:28.296 A:middle
am a member of GPU Software

00:00:28.296 --> 00:00:29.566 A:middle
Architecture Team at Apple.

00:00:29.566 --> 00:00:32.836 A:middle
We will start this session with

00:00:32.836 --> 00:00:35.186 A:middle
a brief summary of what is new

00:00:35.286 --> 00:00:37.456 A:middle
in [inaudible], in terms of VR

00:00:37.456 --> 00:00:38.196 A:middle
adoption.

00:00:38.946 --> 00:00:40.826 A:middle
Then, we will take a deep dive

00:00:41.046 --> 00:00:42.906 A:middle
into a new Metal 2 features,

00:00:43.136 --> 00:00:45.016 A:middle
designs specifically for the VR

00:00:45.016 --> 00:00:45.476 A:middle
this year.

00:00:46.756 --> 00:00:48.576 A:middle
And finally, we will end this

00:00:48.576 --> 00:00:50.466 A:middle
session with advanced techniques

00:00:50.626 --> 00:00:52.236 A:middle
for developing VR applications.

00:00:53.856 --> 00:00:56.026 A:middle
Recently, we introduced new iMac

00:00:56.116 --> 00:00:57.976 A:middle
and iMac Pro that have great

00:00:57.976 --> 00:01:00.776 A:middle
GPUs on board; iMac is now


00:00:57.976 --> 00:01:00.776 A:middle
GPUs on board; iMac is now

00:01:00.776 --> 00:01:01.936 A:middle
equipped with [inaudible] based

00:01:01.936 --> 00:01:05.636 A:middle
GPUs and have up to 80 gigabytes

00:01:05.636 --> 00:01:06.976 A:middle
of video memory on board.

00:01:07.716 --> 00:01:09.946 A:middle
While iMac Pro are equipped with

00:01:09.946 --> 00:01:11.786 A:middle
even more advanced and even

00:01:11.786 --> 00:01:14.286 A:middle
bigger based GPUs, with up to 16

00:01:14.286 --> 00:01:15.586 A:middle
gigabytes of video memory.

00:01:16.546 --> 00:01:18.636 A:middle
That's a lot of power that is

00:01:18.636 --> 00:01:19.536 A:middle
now in your hands.

00:01:20.386 --> 00:01:21.516 A:middle
But we are not limiting our

00:01:21.516 --> 00:01:23.406 A:middle
service to iMac on their own.

00:01:24.166 --> 00:01:25.976 A:middle
With recent announcement of

00:01:25.976 --> 00:01:28.456 A:middle
extended GPU support, you can

00:01:28.456 --> 00:01:30.816 A:middle
now turn any Mac into powerful

00:01:30.936 --> 00:01:34.376 A:middle
workstation that gives you more

00:01:34.376 --> 00:01:35.116 A:middle
than 10 [inaudible] of

00:01:35.176 --> 00:01:36.376 A:middle
processing power.

00:01:37.126 --> 00:01:37.886 A:middle
And that's not all.

00:01:39.106 --> 00:01:40.786 A:middle
Today we are introducing plug

00:01:40.786 --> 00:01:43.276 A:middle
and play support for HTC Vive

00:01:43.406 --> 00:01:44.406 A:middle
head mounted display.

00:01:45.196 --> 00:01:48.966 A:middle
It has two panels with 1,440 by

00:01:48.966 --> 00:01:54.826 A:middle
1,600 and 650 pixels per inch.

00:01:54.956 --> 00:01:58.366 A:middle
That's 78% increase in the

00:01:58.366 --> 00:02:01.516 A:middle
resolution, and 57% increase in


00:01:58.366 --> 00:02:01.516 A:middle
resolution, and 57% increase in

00:02:01.566 --> 00:02:03.616 A:middle
pixel density compared to Vive.

00:02:03.746 --> 00:02:06.676 A:middle
And with support for better

00:02:06.786 --> 00:02:09.086 A:middle
panels comes support for its new

00:02:09.186 --> 00:02:11.266 A:middle
dual-camera front-facing system,

00:02:11.666 --> 00:02:13.526 A:middle
so developers will now be able

00:02:13.526 --> 00:02:14.886 A:middle
to use those cameras to

00:02:14.956 --> 00:02:16.386 A:middle
experiment with pass-through

00:02:16.386 --> 00:02:18.036 A:middle
video on Mac.

00:02:18.236 --> 00:02:19.486 A:middle
And together with Vive Pro

00:02:19.486 --> 00:02:21.446 A:middle
support comes improved tracking

00:02:21.446 --> 00:02:21.966 A:middle
system.

00:02:23.456 --> 00:02:25.186 A:middle
So, you might be wondering how

00:02:25.186 --> 00:02:26.426 A:middle
you can start developing VR

00:02:26.426 --> 00:02:28.036 A:middle
application on Mac OS.

00:02:28.906 --> 00:02:32.506 A:middle
Both HTC Vive and Vive Pro work

00:02:32.506 --> 00:02:34.526 A:middle
in conjunction with Valve

00:02:34.826 --> 00:02:37.456 A:middle
SteamVR runtime, that provides a

00:02:37.456 --> 00:02:39.346 A:middle
number of services including VR

00:02:39.346 --> 00:02:40.226 A:middle
compositor.

00:02:40.676 --> 00:02:43.936 A:middle
Valve is also making open VR

00:02:43.936 --> 00:02:46.016 A:middle
framework that is available on

00:02:46.016 --> 00:02:48.066 A:middle
Mac OS, so that you can do the

00:02:48.066 --> 00:02:49.576 A:middle
map that works with SteamVR.

00:02:50.626 --> 00:02:52.296 A:middle
We've been working very closely

00:02:52.296 --> 00:02:54.876 A:middle
with both Valve and HTC to make

00:02:54.876 --> 00:02:57.516 A:middle
sure that Vive Pro is supported

00:02:57.676 --> 00:03:00.356 A:middle
in SteamVR runtime on Mac OS.


00:02:57.676 --> 00:03:00.356 A:middle
in SteamVR runtime on Mac OS.

00:03:03.006 --> 00:03:04.796 A:middle
So, now let's see how new Metal

00:03:04.796 --> 00:03:06.486 A:middle
features that we're introducing

00:03:06.486 --> 00:03:07.876 A:middle
can develop a [inaudible] Mac OS

00:03:07.876 --> 00:03:09.786 A:middle
Mojave can be used to

00:03:09.786 --> 00:03:11.166 A:middle
fiber-optimize your VR

00:03:11.166 --> 00:03:11.946 A:middle
application.

00:03:12.036 --> 00:03:14.356 A:middle
As a quick refresher, let's

00:03:15.086 --> 00:03:16.736 A:middle
review current interaction

00:03:16.736 --> 00:03:18.096 A:middle
between application and VR

00:03:18.136 --> 00:03:18.786 A:middle
compositor.

00:03:18.896 --> 00:03:21.386 A:middle
Application will start by

00:03:21.386 --> 00:03:23.106 A:middle
rendering image for left and

00:03:23.106 --> 00:03:25.466 A:middle
right eye into 30 multi-sample

00:03:25.516 --> 00:03:26.026 A:middle
textures.

00:03:26.776 --> 00:03:28.306 A:middle
Then it will resolve those

00:03:28.306 --> 00:03:30.556 A:middle
images into iOS surface back

00:03:30.726 --> 00:03:32.456 A:middle
textures that can be further

00:03:32.456 --> 00:03:33.816 A:middle
passed to VR compositor.

00:03:33.816 --> 00:03:37.926 A:middle
VR compositor will perform final

00:03:37.986 --> 00:03:39.476 A:middle
processing step that will

00:03:39.556 --> 00:03:41.256 A:middle
include [inaudible] distortion

00:03:41.256 --> 00:03:42.446 A:middle
correction, chromatic

00:03:42.446 --> 00:03:43.656 A:middle
aberration, and order

00:03:43.656 --> 00:03:44.356 A:middle
operations.

00:03:44.986 --> 00:03:47.026 A:middle
We can call it in short warp.

00:03:48.426 --> 00:03:49.866 A:middle
Once the final image is

00:03:49.956 --> 00:03:52.066 A:middle
produced, it can be sent to the

00:03:52.066 --> 00:03:53.846 A:middle
headset for presentment.

00:03:54.936 --> 00:03:56.856 A:middle
It is a lot of work here that is

00:03:56.916 --> 00:03:59.446 A:middle
happening twice, so let's see if

00:03:59.446 --> 00:04:02.456 A:middle
you can do something about that.


00:03:59.446 --> 00:04:02.456 A:middle
you can do something about that.

00:04:02.766 --> 00:04:04.126 A:middle
See, now with VR application it

00:04:04.126 --> 00:04:05.336 A:middle
wants to benefit from

00:04:05.336 --> 00:04:06.656 A:middle
multi-sample [inaudible], it

00:04:07.236 --> 00:04:08.806 A:middle
needed to use the dedicated

00:04:08.976 --> 00:04:12.016 A:middle
textures per i, or single shared

00:04:12.016 --> 00:04:13.666 A:middle
one, for both.

00:04:13.716 --> 00:04:15.246 A:middle
But none of those layouts is

00:04:15.306 --> 00:04:15.726 A:middle
perfect.

00:04:16.576 --> 00:04:18.386 A:middle
The dedicated textures require

00:04:18.386 --> 00:04:20.505 A:middle
separate draw calls and passes,

00:04:20.886 --> 00:04:21.846 A:middle
as we just saw.

00:04:23.166 --> 00:04:25.246 A:middle
While straight textures enable

00:04:25.246 --> 00:04:27.296 A:middle
rendering of both eyes in single

00:04:27.656 --> 00:04:30.456 A:middle
rendered and results pass, they

00:04:30.456 --> 00:04:32.206 A:middle
are problematic when it comes to

00:04:32.276 --> 00:04:34.196 A:middle
post-processing the effects.

00:04:34.736 --> 00:04:36.986 A:middle
[Inaudible] textures have all

00:04:36.986 --> 00:04:38.956 A:middle
the benefits of both dedicated

00:04:39.126 --> 00:04:41.556 A:middle
and shared layouts, but

00:04:41.646 --> 00:04:43.026 A:middle
currently they couldn't be used

00:04:43.176 --> 00:04:44.056 A:middle
with MSAA.

00:04:45.816 --> 00:04:47.506 A:middle
This was forcing app developers

00:04:47.566 --> 00:04:48.826 A:middle
to use different rendering

00:04:48.936 --> 00:04:50.876 A:middle
part-time layouts, based on the

00:04:51.096 --> 00:04:54.046 A:middle
fact if they wanted to use MSAA

00:04:54.046 --> 00:04:54.406 A:middle
or not.

00:04:54.936 --> 00:04:56.716 A:middle
Or use different tricks to work

00:04:56.716 --> 00:04:57.646 A:middle
around it.

00:04:57.866 --> 00:04:59.416 A:middle
So let's see how we can optimize

00:04:59.466 --> 00:05:00.116 A:middle
this rendering.


00:04:59.466 --> 00:05:00.116 A:middle
this rendering.

00:05:02.166 --> 00:05:03.966 A:middle
Today, we introduce new texture

00:05:04.056 --> 00:05:06.026 A:middle
types to the multi-sample

00:05:06.026 --> 00:05:07.396 A:middle
already textured.

00:05:08.366 --> 00:05:10.726 A:middle
This texture type has all the

00:05:10.726 --> 00:05:13.166 A:middle
benefits of previously mentioned

00:05:13.266 --> 00:05:14.666 A:middle
types without any of the

00:05:14.736 --> 00:05:15.336 A:middle
drawbacks.

00:05:15.476 --> 00:05:17.806 A:middle
Thanks to that it is now

00:05:17.806 --> 00:05:19.606 A:middle
possible to separate from each

00:05:19.606 --> 00:05:22.516 A:middle
other rendering space, which

00:05:22.516 --> 00:05:24.696 A:middle
simplifies the post-processing

00:05:24.696 --> 00:05:28.286 A:middle
effects, views count, so that

00:05:28.286 --> 00:05:30.016 A:middle
application can fall back easily

00:05:30.016 --> 00:05:33.536 A:middle
to monoscope rendering and

00:05:33.536 --> 00:05:35.406 A:middle
control over anti-aliasing mode.

00:05:36.436 --> 00:05:38.786 A:middle
As a result, application can now

00:05:38.786 --> 00:05:40.956 A:middle
have single rendering files that

00:05:40.956 --> 00:05:43.456 A:middle
can be easily adopted to any

00:05:43.556 --> 00:05:46.056 A:middle
situation, and most important,

00:05:46.056 --> 00:05:48.206 A:middle
that can be rendered with single

00:05:48.206 --> 00:05:50.736 A:middle
draw and render pass in each

00:05:50.736 --> 00:05:51.056 A:middle
case.

00:05:53.936 --> 00:05:55.686 A:middle
So here we see code snippet for

00:05:55.686 --> 00:05:57.916 A:middle
creation of mentioned 2D multi

00:05:57.916 --> 00:05:59.126 A:middle
sample [inaudible] texture.


00:06:01.146 --> 00:06:03.446 A:middle
We set up sample count to 4, as

00:06:03.446 --> 00:06:05.386 A:middle
it's an optimal tradeoff between

00:06:05.426 --> 00:06:07.486 A:middle
quality and performance, and at

00:06:07.486 --> 00:06:09.736 A:middle
the same time, we set up our

00:06:09.826 --> 00:06:12.436 A:middle
other length to 2 as we want to

00:06:12.436 --> 00:06:16.346 A:middle
store each image for each I in

00:06:16.446 --> 00:06:17.226 A:middle
separate slice.

00:06:18.676 --> 00:06:21.776 A:middle
So let's see how our pipeline

00:06:21.776 --> 00:06:22.376 A:middle
will change.

00:06:23.606 --> 00:06:25.126 A:middle
We can now replace those 2D

00:06:25.126 --> 00:06:27.396 A:middle
multi-sample textures with

00:06:27.396 --> 00:06:29.596 A:middle
single 2D multi-sample

00:06:32.066 --> 00:06:32.156 A:middle
[inaudible] one.

00:06:33.136 --> 00:06:34.856 A:middle
So now application can render

00:06:34.966 --> 00:06:38.396 A:middle
both I in single render pass and

00:06:38.396 --> 00:06:40.686 A:middle
if it's using instancing, it can

00:06:40.976 --> 00:06:42.356 A:middle
even do that in single draw

00:06:42.356 --> 00:06:42.596 A:middle
code.

00:06:42.596 --> 00:06:45.606 A:middle
So that already looks great, but

00:06:45.606 --> 00:06:47.266 A:middle
we still need to resolve those

00:06:47.726 --> 00:06:49.976 A:middle
2D multi-sample array texture

00:06:49.976 --> 00:06:52.346 A:middle
slices into separate iOS

00:06:52.406 --> 00:06:54.636 A:middle
[inaudible] faces before we pass

00:06:54.636 --> 00:06:55.716 A:middle
them to compositor.

00:06:56.936 --> 00:06:59.156 A:middle
So let's focus on our way,

00:06:59.156 --> 00:07:01.276 A:middle
application shares textures with


00:06:59.156 --> 00:07:01.276 A:middle
application shares textures with

00:07:01.306 --> 00:07:01.746 A:middle
compositor.

00:07:01.746 --> 00:07:04.676 A:middle
So now, for sharing textures, we

00:07:04.676 --> 00:07:05.826 A:middle
use IOSurfaces.

00:07:06.786 --> 00:07:08.316 A:middle
They are sharing textures

00:07:08.426 --> 00:07:10.086 A:middle
between different process spaces

00:07:10.796 --> 00:07:14.086 A:middle
and different GPUs, that we've

00:07:14.186 --> 00:07:15.466 A:middle
got [inaudible] comes a price.

00:07:16.436 --> 00:07:19.466 A:middle
IOSurfaces can be only used to

00:07:19.466 --> 00:07:22.316 A:middle
share simple 2D textures, so if

00:07:22.316 --> 00:07:23.876 A:middle
you have a multi-sampled one,

00:07:24.266 --> 00:07:25.996 A:middle
storing [inaudible] or having

00:07:26.806 --> 00:07:27.386 A:middle
[inaudible], they couldn't be

00:07:27.386 --> 00:07:27.736 A:middle
shared.

00:07:29.046 --> 00:07:30.706 A:middle
That's why today we introduce

00:07:30.706 --> 00:07:32.836 A:middle
shareable Metal textures that

00:07:32.836 --> 00:07:34.676 A:middle
allow your applications to share

00:07:34.806 --> 00:07:36.486 A:middle
any type of Metal texture

00:07:36.796 --> 00:07:39.736 A:middle
between process spaces, as long

00:07:39.836 --> 00:07:42.046 A:middle
as these textures stay in scope

00:07:42.046 --> 00:07:43.106 A:middle
of single GPU.

00:07:43.996 --> 00:07:46.726 A:middle
This file features [inaudible]

00:07:46.856 --> 00:07:49.116 A:middle
advanced view of these cases.

00:07:49.636 --> 00:07:51.956 A:middle
For example, sharing depth of

00:07:52.036 --> 00:07:53.946 A:middle
your scene with VR compositor.

00:07:54.486 --> 00:07:55.846 A:middle
But, of course, it's not limited

00:07:55.846 --> 00:07:56.446 A:middle
just to that.

00:07:57.256 --> 00:07:59.016 A:middle
Now, let's look how those

00:07:59.086 --> 00:08:00.236 A:middle
textures can be created.


00:07:59.086 --> 00:08:00.236 A:middle
textures can be created.

00:08:02.636 --> 00:08:03.906 A:middle
Because shareable textures

00:08:03.996 --> 00:08:06.316 A:middle
allows us now to pass complex

00:08:06.366 --> 00:08:08.296 A:middle
textures between processes, we

00:08:08.296 --> 00:08:10.676 A:middle
will create 2D array texture

00:08:10.676 --> 00:08:12.006 A:middle
that we will pass to VR

00:08:12.206 --> 00:08:12.936 A:middle
compositor.

00:08:13.216 --> 00:08:16.116 A:middle
As you can see, to do that, we

00:08:16.226 --> 00:08:18.126 A:middle
use new methods, new shared

00:08:18.206 --> 00:08:19.426 A:middle
texture with this creator.

00:08:19.976 --> 00:08:22.986 A:middle
And while doing that, you need

00:08:23.056 --> 00:08:24.926 A:middle
to remember to use private

00:08:25.096 --> 00:08:27.036 A:middle
storage mode, as this texture

00:08:27.036 --> 00:08:29.286 A:middle
can be only accessed by the GPU

00:08:29.706 --> 00:08:33.126 A:middle
on which it was created.

00:08:33.876 --> 00:08:35.996 A:middle
Now, we see a code snippet

00:08:36.456 --> 00:08:38.546 A:middle
showing us how our VR

00:08:38.546 --> 00:08:41.416 A:middle
application would send IOSurface

00:08:41.556 --> 00:08:44.186 A:middle
to VR compositor in the past.

00:08:44.186 --> 00:08:45.526 A:middle
We will now go through this code

00:08:45.526 --> 00:08:47.656 A:middle
snippet, and see what changes

00:08:47.746 --> 00:08:50.676 A:middle
needs to be applied to switch

00:08:50.676 --> 00:08:52.656 A:middle
from using IOSurfaces to shared

00:08:52.706 --> 00:08:53.516 A:middle
Metal textures.

00:08:54.976 --> 00:08:56.166 A:middle
So we don't need those two

00:08:56.166 --> 00:08:59.366 A:middle
IOSurfaces anymore, and those

00:08:59.426 --> 00:09:01.006 A:middle
two textures that were backed by


00:08:59.426 --> 00:09:01.006 A:middle
two textures that were backed by

00:09:01.006 --> 00:09:03.256 A:middle
them can now be replaced with

00:09:03.256 --> 00:09:05.686 A:middle
single shareable Metal texture

00:09:05.976 --> 00:09:08.246 A:middle
that is over 2D array type.

00:09:09.236 --> 00:09:11.956 A:middle
We will then assign this texture

00:09:12.146 --> 00:09:15.136 A:middle
to both texture descriptors from

00:09:15.176 --> 00:09:19.116 A:middle
open VRSDK, and change its type

00:09:19.526 --> 00:09:21.416 A:middle
from IOSurface to Metal.

00:09:21.526 --> 00:09:25.076 A:middle
After doing these few changes,

00:09:25.836 --> 00:09:27.826 A:middle
we can submit image for the left

00:09:27.826 --> 00:09:31.606 A:middle
and right I to the compositor.

00:09:32.346 --> 00:09:34.036 A:middle
Compositor will now know that

00:09:34.036 --> 00:09:35.666 A:middle
we've passed shared Metal

00:09:35.666 --> 00:09:37.446 A:middle
texture with advanced layout,

00:09:37.686 --> 00:09:40.366 A:middle
instead of IOSurface, and if we

00:09:40.366 --> 00:09:42.526 A:middle
check, if its type is 2D array

00:09:42.856 --> 00:09:44.596 A:middle
or 2D multi-sampling array.

00:09:45.246 --> 00:09:47.336 A:middle
If it is, then compositor will

00:09:47.416 --> 00:09:49.736 A:middle
automatically assume that image

00:09:49.736 --> 00:09:51.546 A:middle
for the left i is stored in

00:09:51.546 --> 00:09:54.266 A:middle
slice 0, and image for right i

00:09:54.266 --> 00:09:55.876 A:middle
is stored in slice 1.

00:09:56.536 --> 00:09:57.916 A:middle
So your application doesn't need

00:09:57.966 --> 00:09:59.396 A:middle
to do anything more about that.

00:09:59.396 --> 00:10:03.326 A:middle
And of course, sharing Metal


00:09:59.396 --> 00:10:03.326 A:middle
And of course, sharing Metal

00:10:03.326 --> 00:10:05.266 A:middle
textures between application and

00:10:05.266 --> 00:10:06.806 A:middle
compositor is not the only use

00:10:06.856 --> 00:10:08.026 A:middle
case for shareable Metal

00:10:08.066 --> 00:10:08.636 A:middle
textures.

00:10:09.436 --> 00:10:11.126 A:middle
So here we have simple example

00:10:11.126 --> 00:10:12.506 A:middle
of how you can pass Metal

00:10:12.506 --> 00:10:14.156 A:middle
texture between any two

00:10:14.156 --> 00:10:14.956 A:middle
processes.

00:10:15.816 --> 00:10:17.526 A:middle
So we start exactly in the same

00:10:17.526 --> 00:10:17.766 A:middle
way.

00:10:18.046 --> 00:10:19.326 A:middle
We create our shareable Metal

00:10:19.326 --> 00:10:23.206 A:middle
texture, but now from this

00:10:23.286 --> 00:10:25.136 A:middle
texture, we create special

00:10:25.286 --> 00:10:27.456 A:middle
shared texture handle that can

00:10:27.456 --> 00:10:29.726 A:middle
be passed between process spaces

00:10:30.136 --> 00:10:31.176 A:middle
using cross-process

00:10:31.246 --> 00:10:32.556 A:middle
communication connection.

00:10:33.236 --> 00:10:36.056 A:middle
Once this handle is passed to

00:10:36.056 --> 00:10:39.306 A:middle
other process, it can be used to

00:10:39.306 --> 00:10:41.496 A:middle
recreate texture object.

00:10:42.346 --> 00:10:44.906 A:middle
But while doing that, you need

00:10:45.006 --> 00:10:46.936 A:middle
to remember to recreate your

00:10:47.016 --> 00:10:49.096 A:middle
texture object on exactly the

00:10:49.096 --> 00:10:51.616 A:middle
same device as it was originally

00:10:51.666 --> 00:10:53.326 A:middle
created in other process space,

00:10:53.896 --> 00:10:56.176 A:middle
as this texture cannot leave

00:10:56.176 --> 00:10:57.666 A:middle
scope of GPU.

00:10:58.266 --> 00:11:02.476 A:middle
So now let's get back to our


00:10:58.266 --> 00:11:02.476 A:middle
So now let's get back to our

00:11:02.716 --> 00:11:05.196 A:middle
pipeline and see what will

00:11:05.196 --> 00:11:05.576 A:middle
change.

00:11:05.606 --> 00:11:07.806 A:middle
Application can now replace

00:11:07.806 --> 00:11:10.466 A:middle
those separate IOSurfaces with

00:11:10.466 --> 00:11:13.096 A:middle
one 2D array texture, storing

00:11:13.096 --> 00:11:14.256 A:middle
the image for both i's.

00:11:15.346 --> 00:11:17.406 A:middle
This allows further optimization

00:11:18.026 --> 00:11:20.166 A:middle
as original 2D multi-sample

00:11:20.166 --> 00:11:21.876 A:middle
array texture can be now

00:11:21.876 --> 00:11:24.236 A:middle
resolved in one pass as well to

00:11:24.606 --> 00:11:25.906 A:middle
just create it shareable through

00:11:25.906 --> 00:11:26.736 A:middle
the array texture.

00:11:27.706 --> 00:11:28.716 A:middle
But that's not everything.

00:11:29.486 --> 00:11:30.786 A:middle
Let's look at the compositor.

00:11:32.286 --> 00:11:33.196 A:middle
Once we have simplified

00:11:33.196 --> 00:11:35.006 A:middle
rendering parts on application

00:11:35.006 --> 00:11:36.596 A:middle
site, there is nothing

00:11:36.716 --> 00:11:38.176 A:middle
preventing compositor from

00:11:38.406 --> 00:11:39.726 A:middle
benefiting from those new

00:11:39.726 --> 00:11:40.596 A:middle
features as well.

00:11:41.246 --> 00:11:45.056 A:middle
So compositor can now use those

00:11:45.126 --> 00:11:47.826 A:middle
incoming 2D array textures and

00:11:47.826 --> 00:11:50.086 A:middle
perform work for both i's in

00:11:50.086 --> 00:11:51.576 A:middle
single render pass as well.

00:11:51.736 --> 00:11:54.836 A:middle
And as you can see, we've just

00:11:54.836 --> 00:11:56.396 A:middle
simplified the whole pipeline.

00:11:57.816 --> 00:11:59.246 A:middle
So let's do recap of what we've

00:11:59.246 --> 00:11:59.766 A:middle
just learned.


00:12:01.776 --> 00:12:03.266 A:middle
We've just described two new

00:12:03.266 --> 00:12:04.236 A:middle
Metal features.

00:12:04.576 --> 00:12:07.846 A:middle
Shareable Metal textures, and 2D

00:12:07.846 --> 00:12:09.746 A:middle
multi-sample array texture type.

00:12:09.746 --> 00:12:12.356 A:middle
And the way they can be used to

00:12:12.406 --> 00:12:14.246 A:middle
further optimize your rendering

00:12:14.326 --> 00:12:14.856 A:middle
pipeline.

00:12:16.026 --> 00:12:17.406 A:middle
Both features will be soon

00:12:17.406 --> 00:12:19.326 A:middle
supported in upcoming SteamVR

00:12:19.326 --> 00:12:20.836 A:middle
runtime updates.

00:12:22.016 --> 00:12:23.686 A:middle
So now, let's focus on

00:12:23.686 --> 00:12:25.166 A:middle
techniques that will allow your

00:12:25.166 --> 00:12:27.376 A:middle
application to maximize its CPU

00:12:27.376 --> 00:12:28.736 A:middle
and GPU utilization.

00:12:29.796 --> 00:12:32.276 A:middle
We will divide this section into

00:12:32.366 --> 00:12:34.696 A:middle
two subsections-- Advanced frame

00:12:34.696 --> 00:12:36.656 A:middle
pacing and a reducing free rate.

00:12:38.386 --> 00:12:40.436 A:middle
We will start with frame pacing.

00:12:41.276 --> 00:12:43.426 A:middle
And in this section, we will

00:12:43.426 --> 00:12:45.446 A:middle
analyze application frame pacing

00:12:45.536 --> 00:12:47.116 A:middle
and how it can be optimized for

00:12:47.116 --> 00:12:47.266 A:middle
VR.

00:12:48.306 --> 00:12:49.936 A:middle
So let's start with simple,

00:12:50.146 --> 00:12:52.096 A:middle
single-threaded application that

00:12:52.096 --> 00:12:53.646 A:middle
is executing everything in

00:12:53.646 --> 00:12:54.476 A:middle
serial monitoring.

00:12:55.406 --> 00:12:57.336 A:middle
Such application will start its

00:12:57.336 --> 00:12:59.816 A:middle
frame by calling WaitGet pauses,


00:13:00.866 --> 00:13:03.256 A:middle
to receive pauses, and

00:13:03.256 --> 00:13:05.866 A:middle
synchronize its execution to the

00:13:05.866 --> 00:13:07.256 A:middle
frame rate of the headset.

00:13:09.026 --> 00:13:11.506 A:middle
Both Vive and Vive Pro has

00:13:11.506 --> 00:13:13.286 A:middle
refresh rate of 90 frames per

00:13:13.286 --> 00:13:14.936 A:middle
second, which means the

00:13:14.986 --> 00:13:17.096 A:middle
application has only 11.1

00:13:17.096 --> 00:13:18.706 A:middle
milliseconds to process the

00:13:18.706 --> 00:13:19.316 A:middle
whole frame.

00:13:20.086 --> 00:13:22.496 A:middle
For comparison, blink of an eye

00:13:22.746 --> 00:13:24.756 A:middle
takes about 300 milliseconds.

00:13:25.536 --> 00:13:27.286 A:middle
So in this time, the application

00:13:27.286 --> 00:13:28.666 A:middle
should render 50 frames.

00:13:30.326 --> 00:13:32.436 A:middle
So once our application receives

00:13:32.616 --> 00:13:34.736 A:middle
pauses from WaitGet pauses, it

00:13:34.806 --> 00:13:37.106 A:middle
can start simulation of your

00:13:37.106 --> 00:13:37.636 A:middle
trial [inaudible].

00:13:38.816 --> 00:13:39.886 A:middle
When this simulation is

00:13:39.956 --> 00:13:41.676 A:middle
complete, and state of all

00:13:41.676 --> 00:13:43.756 A:middle
objects is known, application

00:13:43.756 --> 00:13:46.076 A:middle
can continue with encoding

00:13:46.206 --> 00:13:48.286 A:middle
command buffer that will be then

00:13:48.286 --> 00:13:50.386 A:middle
sent to GPU for execution.

00:13:51.886 --> 00:13:54.786 A:middle
Once GPU is done, an image for

00:13:54.786 --> 00:13:57.416 A:middle
both i's is rendered, it can be

00:13:57.416 --> 00:13:59.906 A:middle
sent to VR compositor for final

00:13:59.906 --> 00:14:01.426 A:middle
post-processing, as we talked


00:13:59.906 --> 00:14:01.426 A:middle
post-processing, as we talked

00:14:01.516 --> 00:14:02.706 A:middle
about a few slides before.

00:14:02.706 --> 00:14:07.316 A:middle
After that, frames scanned out

00:14:07.646 --> 00:14:08.576 A:middle
from memory to [inaudible] in

00:14:08.636 --> 00:14:09.466 A:middle
the headset.

00:14:09.596 --> 00:14:12.266 A:middle
This transfer takes additional

00:14:12.266 --> 00:14:15.226 A:middle
frame as all pixels need to be

00:14:15.376 --> 00:14:17.376 A:middle
updated before image can be

00:14:17.436 --> 00:14:17.986 A:middle
presented.

00:14:19.296 --> 00:14:23.436 A:middle
Once all pixels are updated,

00:14:23.566 --> 00:14:25.686 A:middle
[inaudible] and user can see a

00:14:25.686 --> 00:14:26.106 A:middle
frame.

00:14:27.246 --> 00:14:28.346 A:middle
So as you can see from the

00:14:28.346 --> 00:14:29.846 A:middle
moment the application receives

00:14:29.926 --> 00:14:32.036 A:middle
pauses, to the moment image is

00:14:32.036 --> 00:14:34.476 A:middle
really projected, it takes about

00:14:34.566 --> 00:14:35.896 A:middle
25 milliseconds.

00:14:35.976 --> 00:14:39.556 A:middle
That is why application receives

00:14:39.686 --> 00:14:41.346 A:middle
pauses that are already

00:14:41.346 --> 00:14:43.296 A:middle
predicted into the future, to

00:14:43.546 --> 00:14:45.116 A:middle
the moment when photons will be

00:14:45.116 --> 00:14:47.806 A:middle
emitted, so that the rendered

00:14:47.896 --> 00:14:49.546 A:middle
image is matching the user

00:14:49.636 --> 00:14:49.946 A:middle
pause.

00:14:50.066 --> 00:14:54.336 A:middle
And this cascade of events

00:14:54.416 --> 00:14:56.046 A:middle
overlapping with previous and

00:14:56.046 --> 00:14:58.486 A:middle
next frame is creating our frame

00:14:58.516 --> 00:14:59.436 A:middle
basing diagram.

00:14:59.436 --> 00:15:02.096 A:middle
As you can see, in case of the


00:14:59.436 --> 00:15:02.096 A:middle
As you can see, in case of the

00:15:02.096 --> 00:15:04.966 A:middle
single-threaded application, GPU

00:15:04.966 --> 00:15:06.446 A:middle
is idle most of the time.

00:15:07.826 --> 00:15:08.816 A:middle
So let's see if we can do

00:15:08.816 --> 00:15:10.346 A:middle
anything about that.

00:15:11.776 --> 00:15:13.606 A:middle
We are now switching to

00:15:13.606 --> 00:15:15.216 A:middle
multi-threaded application,

00:15:15.716 --> 00:15:17.746 A:middle
which separates simulation of

00:15:17.776 --> 00:15:20.416 A:middle
its visual environment from

00:15:20.446 --> 00:15:22.656 A:middle
encoding operations to the GPU.

00:15:23.496 --> 00:15:24.996 A:middle
Encoding of those operations

00:15:24.996 --> 00:15:26.596 A:middle
will now happen on separate

00:15:26.596 --> 00:15:27.356 A:middle
rendering threads.

00:15:28.796 --> 00:15:29.766 A:middle
Because we've separated

00:15:29.866 --> 00:15:31.216 A:middle
simulation from encoding,

00:15:31.766 --> 00:15:33.596 A:middle
simulation for our frame can

00:15:33.696 --> 00:15:36.786 A:middle
happen in parallel to previous

00:15:36.786 --> 00:15:38.636 A:middle
frame encoding of GPU

00:15:38.636 --> 00:15:39.336 A:middle
operations.

00:15:40.636 --> 00:15:43.316 A:middle
This means that encoding is now

00:15:43.316 --> 00:15:45.746 A:middle
shifted area in time, and starts

00:15:45.796 --> 00:15:47.596 A:middle
immediately after we receive

00:15:47.706 --> 00:15:48.656 A:middle
predicted pauses.

00:15:49.216 --> 00:15:50.846 A:middle
This means that your application

00:15:50.846 --> 00:15:52.436 A:middle
will now have more time to

00:15:52.436 --> 00:15:54.736 A:middle
encode the GPU [inaudible] and

00:15:54.736 --> 00:15:56.666 A:middle
GPU will have more time to

00:15:56.746 --> 00:15:57.406 A:middle
process it.

00:15:57.406 --> 00:15:59.166 A:middle
So, as a result, your

00:15:59.166 --> 00:16:00.436 A:middle
application can have better


00:15:59.166 --> 00:16:00.436 A:middle
application can have better

00:16:00.436 --> 00:16:01.096 A:middle
visualize.

00:16:02.856 --> 00:16:04.216 A:middle
But there is one trick.

00:16:05.436 --> 00:16:07.386 A:middle
Because simulation is now

00:16:07.386 --> 00:16:09.256 A:middle
happening one frame in advance,

00:16:09.956 --> 00:16:12.196 A:middle
it requires separate set of

00:16:12.286 --> 00:16:13.326 A:middle
predicted pauses.

00:16:14.066 --> 00:16:16.586 A:middle
This set is predicted 56

00:16:16.586 --> 00:16:18.956 A:middle
milliseconds into the future so

00:16:18.956 --> 00:16:20.276 A:middle
that it will match the set

00:16:20.366 --> 00:16:21.886 A:middle
predicted for rendering thread

00:16:22.416 --> 00:16:24.176 A:middle
and both will match the moment

00:16:24.206 --> 00:16:25.266 A:middle
when photons are emitted.

00:16:27.126 --> 00:16:28.646 A:middle
This diagram already looks good

00:16:28.646 --> 00:16:31.056 A:middle
from CPU side, as we can see

00:16:31.056 --> 00:16:32.276 A:middle
application is nicely

00:16:32.276 --> 00:16:33.566 A:middle
distributing its work

00:16:33.566 --> 00:16:35.236 A:middle
[inaudible] CPU course, but

00:16:36.236 --> 00:16:37.566 A:middle
let's focus on GPU.

00:16:38.446 --> 00:16:43.596 A:middle
As you can see, now our example

00:16:43.596 --> 00:16:46.696 A:middle
application is encoding all

00:16:46.696 --> 00:16:48.576 A:middle
these GPU [inaudible] for the

00:16:48.746 --> 00:16:51.286 A:middle
whole frame into a single common

00:16:51.286 --> 00:16:54.016 A:middle
buffer, so unless this common

00:16:54.016 --> 00:16:56.466 A:middle
buffer is complete, GPU is

00:16:56.466 --> 00:16:57.316 A:middle
waiting idle.

00:16:58.836 --> 00:17:00.306 A:middle
But it's important to notice


00:16:58.836 --> 00:17:00.306 A:middle
But it's important to notice

00:17:00.546 --> 00:17:02.676 A:middle
that encoding of GPU operations

00:17:02.676 --> 00:17:05.336 A:middle
on a CPU takes much less time

00:17:05.586 --> 00:17:06.796 A:middle
than processing of these

00:17:06.796 --> 00:17:08.165 A:middle
operations on the GPU.

00:17:08.986 --> 00:17:10.336 A:middle
So we can benefit from this

00:17:10.336 --> 00:17:13.935 A:middle
fact, and split our encoding

00:17:13.935 --> 00:17:15.656 A:middle
operation into a few common

00:17:15.656 --> 00:17:17.876 A:middle
buffers while a few common

00:17:17.876 --> 00:17:19.276 A:middle
buffer will be encoded very

00:17:19.276 --> 00:17:21.266 A:middle
fast, with just few operations,

00:17:21.776 --> 00:17:23.715 A:middle
and submitted to GPU as fast as

00:17:23.786 --> 00:17:24.336 A:middle
possible.

00:17:25.626 --> 00:17:30.426 A:middle
This way, now our encoding is

00:17:30.486 --> 00:17:33.016 A:middle
processing in parallel to GPU

00:17:33.016 --> 00:17:34.626 A:middle
already processing our frame,

00:17:35.086 --> 00:17:36.826 A:middle
and as you can see, we've just

00:17:36.826 --> 00:17:39.926 A:middle
extended the time when GPU is

00:17:40.036 --> 00:17:43.456 A:middle
doing its work, and as a result,

00:17:43.456 --> 00:17:45.216 A:middle
further increase amount of work

00:17:45.216 --> 00:17:46.706 A:middle
that you can submit in a frame.

00:17:48.156 --> 00:17:49.226 A:middle
Now, let's get back to our

00:17:49.266 --> 00:17:50.826 A:middle
diagram, and see how it all

00:17:50.826 --> 00:17:51.906 A:middle
looks together.

00:17:53.446 --> 00:17:55.636 A:middle
So as you can see, now both CPU

00:17:55.636 --> 00:17:57.766 A:middle
and GPU are fully utilized.

00:17:58.746 --> 00:18:00.056 A:middle
So [inaudible] application is


00:17:58.746 --> 00:18:00.056 A:middle
So [inaudible] application is

00:18:00.056 --> 00:18:01.846 A:middle
already very good example of

00:18:01.846 --> 00:18:03.966 A:middle
your application, but there are

00:18:03.966 --> 00:18:05.446 A:middle
still few things we can do.

00:18:07.196 --> 00:18:09.396 A:middle
If you will notice, rendering

00:18:09.506 --> 00:18:11.626 A:middle
thread is still waiting with

00:18:11.696 --> 00:18:13.786 A:middle
encoding of any type of GPU work

00:18:14.306 --> 00:18:16.326 A:middle
before it will receive predicted

00:18:16.456 --> 00:18:16.876 A:middle
pauses.

00:18:17.566 --> 00:18:19.186 A:middle
But not all [inaudible] in the

00:18:19.186 --> 00:18:21.486 A:middle
frame requires those pauses.

00:18:22.536 --> 00:18:24.766 A:middle
So let's analyze in more detail

00:18:24.886 --> 00:18:26.086 A:middle
to pick our frame workloads.

00:18:27.486 --> 00:18:29.956 A:middle
Here, you can see a list of

00:18:30.006 --> 00:18:31.896 A:middle
workloads that may be executed

00:18:32.086 --> 00:18:32.916 A:middle
in each frame.

00:18:34.056 --> 00:18:35.656 A:middle
Part of them happen in screen

00:18:35.656 --> 00:18:37.696 A:middle
space or require general

00:18:37.696 --> 00:18:39.766 A:middle
knowledge about pause for which

00:18:39.766 --> 00:18:40.736 A:middle
frame is rendered.

00:18:41.496 --> 00:18:42.726 A:middle
We call such workloads

00:18:42.846 --> 00:18:44.116 A:middle
pause-dependent ones.

00:18:44.986 --> 00:18:46.506 A:middle
At the same time, there are

00:18:46.506 --> 00:18:48.746 A:middle
workloads that are generic and

00:18:48.746 --> 00:18:50.056 A:middle
can be executed without

00:18:50.096 --> 00:18:51.326 A:middle
knowledge about pauses

00:18:51.326 --> 00:18:51.996 A:middle
immediately.

00:18:53.096 --> 00:18:54.886 A:middle
We call those workloads pause

00:18:54.886 --> 00:18:55.886 A:middle
independent ones.

00:18:56.496 --> 00:18:59.306 A:middle
So currently, our application

00:18:59.306 --> 00:19:01.346 A:middle
was waiting for pauses to encode


00:18:59.306 --> 00:19:01.346 A:middle
was waiting for pauses to encode

00:19:01.346 --> 00:19:02.996 A:middle
any type of work to GPU.

00:19:03.626 --> 00:19:05.336 A:middle
But if we split those workloads

00:19:05.336 --> 00:19:08.636 A:middle
in half, we can encode pause

00:19:08.636 --> 00:19:09.676 A:middle
independent workloads

00:19:09.766 --> 00:19:11.936 A:middle
immediately and then wait for

00:19:12.026 --> 00:19:14.046 A:middle
pauses to continue with encoding

00:19:14.146 --> 00:19:15.156 A:middle
pause-dependent ones.

00:19:16.126 --> 00:19:19.456 A:middle
In this slide, we've already

00:19:19.456 --> 00:19:21.076 A:middle
separated pause independent

00:19:21.076 --> 00:19:23.006 A:middle
workloads from pause dependent

00:19:23.036 --> 00:19:23.346 A:middle
ones.

00:19:24.516 --> 00:19:26.096 A:middle
Pause independent workloads is

00:19:26.096 --> 00:19:27.346 A:middle
now encoded in [inaudible]

00:19:27.496 --> 00:19:29.096 A:middle
common buffer, and is marked

00:19:29.446 --> 00:19:31.066 A:middle
with a little bit darker shade

00:19:31.276 --> 00:19:32.746 A:middle
than pause-dependent workload

00:19:32.746 --> 00:19:33.446 A:middle
following it.

00:19:34.336 --> 00:19:35.666 A:middle
Because pause-independent

00:19:35.666 --> 00:19:36.886 A:middle
workload can be encoded

00:19:36.886 --> 00:19:39.146 A:middle
immediately, we will do exactly

00:19:39.146 --> 00:19:39.376 A:middle
that.

00:19:39.966 --> 00:19:41.526 A:middle
We will encode it as soon as the

00:19:41.636 --> 00:19:42.796 A:middle
previous frame workload is

00:19:42.796 --> 00:19:43.286 A:middle
encoded.

00:19:44.766 --> 00:19:46.866 A:middle
This gives CPU more time to

00:19:46.866 --> 00:19:49.246 A:middle
encode the GPU work, and what is

00:19:49.416 --> 00:19:51.646 A:middle
even more important, it ensures

00:19:51.646 --> 00:19:54.196 A:middle
us that this GPU work is already

00:19:54.196 --> 00:19:56.556 A:middle
waiting for being executed on

00:19:56.556 --> 00:19:59.336 A:middle
GPU so there will be exactly no

00:19:59.336 --> 00:20:00.576 A:middle
idle time on GPU.


00:19:59.336 --> 00:20:00.576 A:middle
idle time on GPU.

00:20:00.636 --> 00:20:01.846 A:middle
As soon as previous frame is

00:20:01.846 --> 00:20:04.086 A:middle
finished, GPU can start with the

00:20:04.626 --> 00:20:06.766 A:middle
next one.

00:20:06.896 --> 00:20:09.376 A:middle
The last subsection is a

00:20:09.376 --> 00:20:11.306 A:middle
multi-GPU workload distribution.

00:20:13.226 --> 00:20:15.666 A:middle
We can scale our workload across

00:20:15.666 --> 00:20:16.386 A:middle
multiple GPUs.

00:20:16.386 --> 00:20:19.226 A:middle
Current Mac Book Pro has two GPU

00:20:19.306 --> 00:20:21.166 A:middle
on board, and while they have

00:20:21.166 --> 00:20:22.056 A:middle
different performance

00:20:22.116 --> 00:20:23.616 A:middle
characteristics, there is

00:20:23.616 --> 00:20:25.126 A:middle
nothing preventing us from using

00:20:25.126 --> 00:20:25.366 A:middle
them.

00:20:26.036 --> 00:20:27.926 A:middle
Similarly, if each GPU is

00:20:27.986 --> 00:20:29.906 A:middle
connected, application can use

00:20:29.906 --> 00:20:31.756 A:middle
it for rendering to the headset

00:20:32.096 --> 00:20:34.866 A:middle
while using Mac's primary GPU to

00:20:34.896 --> 00:20:35.936 A:middle
offload some work.

00:20:39.066 --> 00:20:40.516 A:middle
So we've just separated

00:20:40.666 --> 00:20:43.286 A:middle
pause-independent work and moved

00:20:43.566 --> 00:20:45.256 A:middle
it to a secondary GPU.

00:20:45.796 --> 00:20:48.436 A:middle
We could do that because it was

00:20:48.436 --> 00:20:52.046 A:middle
already encoded much earlier in

00:20:52.046 --> 00:20:53.576 A:middle
our frame, and now this

00:20:53.666 --> 00:20:55.866 A:middle
pause-independent workload is

00:20:55.866 --> 00:20:57.516 A:middle
executing in parallel to

00:20:57.616 --> 00:20:58.986 A:middle
pause-dependent workload of

00:20:59.066 --> 00:20:59.746 A:middle
previous frame.


00:21:00.196 --> 00:21:01.706 A:middle
As a result, we further

00:21:01.706 --> 00:21:03.596 A:middle
increased the amount of GPU time

00:21:03.676 --> 00:21:04.916 A:middle
that you had for your frame.

00:21:07.546 --> 00:21:09.856 A:middle
But, by splitting this work into

00:21:09.856 --> 00:21:13.146 A:middle
multiple GPUs, we now get to the

00:21:13.256 --> 00:21:14.926 A:middle
point where we need a way to

00:21:14.926 --> 00:21:16.886 A:middle
synchronize those workloads with

00:21:16.886 --> 00:21:17.446 A:middle
each other.

00:21:22.676 --> 00:21:24.426 A:middle
So today we introduce new

00:21:24.426 --> 00:21:26.006 A:middle
synchronization parameters to

00:21:26.066 --> 00:21:27.316 A:middle
deal exactly with such

00:21:27.316 --> 00:21:28.086 A:middle
situation.

00:21:28.816 --> 00:21:31.196 A:middle
MTL Events can now be used to

00:21:31.196 --> 00:21:33.616 A:middle
synchronize GPU work in scope of

00:21:33.616 --> 00:21:35.566 A:middle
single GPU across different

00:21:35.626 --> 00:21:38.826 A:middle
Metal cues and MTL Shared Events

00:21:39.276 --> 00:21:41.436 A:middle
extends this functionality by

00:21:41.436 --> 00:21:42.886 A:middle
allowing it to synchronize

00:21:42.886 --> 00:21:44.816 A:middle
workloads across different GPUs

00:21:44.986 --> 00:21:46.176 A:middle
and even across different

00:21:46.236 --> 00:21:46.796 A:middle
processes.

00:21:49.136 --> 00:21:50.996 A:middle
So here we will go through the

00:21:51.106 --> 00:21:52.426 A:middle
simple code example.

00:21:53.546 --> 00:21:55.406 A:middle
We have our Mac, with attached

00:21:55.406 --> 00:21:57.486 A:middle
eGPU through Thunderbolt 3

00:21:57.486 --> 00:21:58.166 A:middle
connection.

00:21:58.266 --> 00:22:00.936 A:middle
This eGPU will be our primary


00:21:58.266 --> 00:22:00.936 A:middle
This eGPU will be our primary

00:22:00.936 --> 00:22:04.396 A:middle
GPU driving the headset, so we

00:22:04.396 --> 00:22:06.576 A:middle
can use GPU that is already in

00:22:06.576 --> 00:22:08.676 A:middle
our Mac as secondary supporting

00:22:08.676 --> 00:22:09.136 A:middle
GPU.

00:22:10.496 --> 00:22:12.766 A:middle
And we will use shared event to

00:22:12.766 --> 00:22:16.896 A:middle
synchronize workloads of both

00:22:18.486 --> 00:22:18.716 A:middle
GPUs.

00:22:19.206 --> 00:22:21.816 A:middle
Event initial value is zero, so

00:22:21.816 --> 00:22:22.996 A:middle
it's important to start

00:22:22.996 --> 00:22:25.526 A:middle
synchronization counter from 1.

00:22:26.176 --> 00:22:27.516 A:middle
That's because when we would

00:22:27.516 --> 00:22:30.096 A:middle
wait on just initialized event,

00:22:30.276 --> 00:22:32.476 A:middle
its counter of zero will cause

00:22:32.476 --> 00:22:34.696 A:middle
it to return immediately, so

00:22:34.696 --> 00:22:35.126 A:middle
there would be no

00:22:35.126 --> 00:22:35.976 A:middle
synchronization.

00:22:37.786 --> 00:22:39.276 A:middle
So our rendering thread now

00:22:39.276 --> 00:22:41.826 A:middle
starts encoding work for our

00:22:41.826 --> 00:22:43.836 A:middle
supporting GPU immediately.

00:22:44.536 --> 00:22:46.426 A:middle
It will encode pause-independent

00:22:46.426 --> 00:22:48.796 A:middle
work that will happen on our

00:22:48.796 --> 00:22:50.996 A:middle
supporting GPU course, and once

00:22:51.026 --> 00:22:53.426 A:middle
this work is complete, its

00:22:53.426 --> 00:22:55.496 A:middle
results will be stored in locker

00:22:55.646 --> 00:22:56.156 A:middle
memory.

00:22:56.796 --> 00:22:59.146 A:middle
That's why we follow with

00:22:59.146 --> 00:23:01.396 A:middle
encoding brief operation that


00:22:59.146 --> 00:23:01.396 A:middle
encoding brief operation that

00:23:01.396 --> 00:23:03.736 A:middle
will transfer those results to

00:23:03.736 --> 00:23:05.806 A:middle
system memory that is visible by

00:23:05.806 --> 00:23:06.676 A:middle
both GPUs.

00:23:07.426 --> 00:23:08.786 A:middle
And once this transfer is

00:23:08.786 --> 00:23:12.436 A:middle
complete, our supporting GPU can

00:23:12.906 --> 00:23:15.216 A:middle
safely signal our shared event.

00:23:15.866 --> 00:23:18.256 A:middle
This signal will tell eGPU that

00:23:18.316 --> 00:23:19.846 A:middle
now it's safe to take those

00:23:19.846 --> 00:23:20.236 A:middle
results.

00:23:21.496 --> 00:23:23.536 A:middle
So our rendering thread

00:23:23.536 --> 00:23:24.576 A:middle
committed this [inaudible]

00:23:24.576 --> 00:23:26.886 A:middle
common buffer, and supporting

00:23:26.916 --> 00:23:28.946 A:middle
GPU is already processing its

00:23:28.946 --> 00:23:29.246 A:middle
work.

00:23:30.016 --> 00:23:32.336 A:middle
At the same time, we can start

00:23:32.336 --> 00:23:34.086 A:middle
encoding command buffer for a

00:23:34.166 --> 00:23:36.026 A:middle
primary GPU that is driving the

00:23:36.076 --> 00:23:36.486 A:middle
headset.

00:23:37.676 --> 00:23:39.356 A:middle
In this command buffer, we will

00:23:39.356 --> 00:23:41.626 A:middle
start by waiting for our shared

00:23:41.626 --> 00:23:43.446 A:middle
event to be sure that the data

00:23:43.446 --> 00:23:45.516 A:middle
is in system memory, and once

00:23:45.516 --> 00:23:47.426 A:middle
it's there, and the shared event

00:23:47.426 --> 00:23:50.066 A:middle
is signaled, we can perform a

00:23:50.066 --> 00:23:51.306 A:middle
brief operation that will

00:23:51.306 --> 00:23:52.516 A:middle
transfer this data through

00:23:52.516 --> 00:23:54.826 A:middle
Thunderbolt 3 connection, back

00:23:55.096 --> 00:23:57.856 A:middle
to our [inaudible] GPU and once

00:23:57.956 --> 00:23:59.856 A:middle
this transfer is complete, it's

00:23:59.856 --> 00:24:01.936 A:middle
safe to perform pause-dependent


00:23:59.856 --> 00:24:01.936 A:middle
safe to perform pause-dependent

00:24:01.966 --> 00:24:05.246 A:middle
work, so a second command buffer

00:24:05.556 --> 00:24:08.206 A:middle
will signal lockout event to let

00:24:08.356 --> 00:24:10.166 A:middle
pause-dependent work know that

00:24:10.166 --> 00:24:11.546 A:middle
it can start executing.

00:24:12.366 --> 00:24:14.346 A:middle
After encoding and submitting

00:24:14.416 --> 00:24:15.776 A:middle
those two command buffers,

00:24:16.386 --> 00:24:18.436 A:middle
rendering thread can continue as

00:24:18.436 --> 00:24:20.566 A:middle
usual, with waiting for pauses,

00:24:20.816 --> 00:24:21.826 A:middle
and later encoding

00:24:21.916 --> 00:24:26.076 A:middle
pause-dependent work.

00:24:26.296 --> 00:24:28.296 A:middle
So now we have a mechanism to

00:24:28.296 --> 00:24:30.306 A:middle
synchronize different workloads

00:24:30.306 --> 00:24:31.146 A:middle
between different GPUs.

00:24:31.146 --> 00:24:35.156 A:middle
But as you can see, our

00:24:35.156 --> 00:24:37.426 A:middle
secondary GPU is still a little

00:24:37.426 --> 00:24:38.176 A:middle
bit idle.

00:24:38.226 --> 00:24:40.506 A:middle
That's because in this example

00:24:40.926 --> 00:24:43.886 A:middle
we decided to push through it,

00:24:44.316 --> 00:24:45.846 A:middle
pause dependent workloads that

00:24:45.846 --> 00:24:47.396 A:middle
have dependency with pause

00:24:47.396 --> 00:24:48.856 A:middle
dependent ones.

00:24:49.346 --> 00:24:49.786 A:middle
Excuse me.

00:24:50.796 --> 00:24:52.156 A:middle
But of course there are types of

00:24:52.206 --> 00:24:53.396 A:middle
workloads that have no

00:24:53.396 --> 00:24:55.086 A:middle
dependencies, and they can

00:24:55.216 --> 00:24:57.496 A:middle
happen at lower frequencies, the

00:24:57.496 --> 00:24:58.806 A:middle
frequency of the headset.

00:24:59.576 --> 00:25:01.076 A:middle
One example of such workloads


00:24:59.576 --> 00:25:01.076 A:middle
One example of such workloads

00:25:01.196 --> 00:25:03.456 A:middle
can be, for example, simulation

00:25:03.456 --> 00:25:05.076 A:middle
of physically based accurate

00:25:05.076 --> 00:25:07.076 A:middle
[inaudible] or anything else

00:25:07.766 --> 00:25:11.236 A:middle
that requires a lot of time to

00:25:11.976 --> 00:25:12.826 A:middle
be updated.

00:25:13.326 --> 00:25:15.846 A:middle
Such workload can happen in the

00:25:15.846 --> 00:25:17.316 A:middle
background, completely

00:25:17.316 --> 00:25:18.846 A:middle
asynchronously from rendering

00:25:18.846 --> 00:25:20.596 A:middle
frames, and each time it's

00:25:20.596 --> 00:25:23.336 A:middle
ready, its results will be sent

00:25:23.456 --> 00:25:24.536 A:middle
to primary GPU.

00:25:25.316 --> 00:25:27.296 A:middle
It's marked here with gray color

00:25:27.626 --> 00:25:28.996 A:middle
to indicate that it's not

00:25:28.996 --> 00:25:31.036 A:middle
related to any particular frame.

00:25:32.516 --> 00:25:33.616 A:middle
So, of course there are

00:25:33.616 --> 00:25:36.016 A:middle
different GPUs with different

00:25:36.066 --> 00:25:38.086 A:middle
performance characteristics, and

00:25:38.086 --> 00:25:38.976 A:middle
they will have different

00:25:38.976 --> 00:25:40.146 A:middle
bandwidth connections.

00:25:40.606 --> 00:25:42.966 A:middle
And your application will have

00:25:43.086 --> 00:25:44.976 A:middle
different workloads in a single

00:25:44.976 --> 00:25:47.096 A:middle
frame with different relations

00:25:47.176 --> 00:25:47.876 A:middle
between them.

00:25:48.986 --> 00:25:51.676 A:middle
So you will need to design a way

00:25:51.786 --> 00:25:53.446 A:middle
to distribute this workload on

00:25:53.446 --> 00:25:56.406 A:middle
your own, but saying all that,

00:25:56.406 --> 00:25:58.166 A:middle
it's important to start thinking

00:25:58.166 --> 00:26:00.076 A:middle
about this GPU workload


00:25:58.166 --> 00:26:00.076 A:middle
about this GPU workload

00:26:00.116 --> 00:26:02.106 A:middle
distribution, as multi-GPU

00:26:02.106 --> 00:26:04.026 A:middle
configuration are becoming

00:26:04.136 --> 00:26:05.956 A:middle
common on Apple platforms.

00:26:07.956 --> 00:26:10.266 A:middle
So let's summarize everything

00:26:10.266 --> 00:26:11.326 A:middle
that we've learned in this

00:26:11.416 --> 00:26:11.866 A:middle
section.

00:26:12.496 --> 00:26:13.426 A:middle
We showed multi-thread

00:26:13.426 --> 00:26:15.986 A:middle
application to take full benefit

00:26:16.076 --> 00:26:17.396 A:middle
of all CPU codes.

00:26:17.466 --> 00:26:20.556 A:middle
And split your command buffers,

00:26:20.786 --> 00:26:22.666 A:middle
to ensure that GPU is not idle.

00:26:23.756 --> 00:26:25.776 A:middle
When doing that, if possible,

00:26:26.066 --> 00:26:26.916 A:middle
try to separate

00:26:27.046 --> 00:26:28.396 A:middle
pause-independent from

00:26:28.466 --> 00:26:31.036 A:middle
pause-dependent workloads, to be

00:26:31.036 --> 00:26:32.946 A:middle
able to encode this work as soon

00:26:32.946 --> 00:26:35.746 A:middle
as possible, and even further,

00:26:36.206 --> 00:26:38.086 A:middle
splitting workloads by frequency

00:26:38.086 --> 00:26:41.126 A:middle
of update so if your application

00:26:41.126 --> 00:26:42.586 A:middle
will execute on multi-GPU

00:26:42.586 --> 00:26:44.486 A:middle
configuration, you can easily

00:26:44.486 --> 00:26:47.576 A:middle
distribute it across those GPUs.

00:26:48.126 --> 00:26:50.726 A:middle
And while doing that, ensure

00:26:51.136 --> 00:26:53.296 A:middle
that you drive each GPU with

00:26:53.296 --> 00:26:55.566 A:middle
separate rendering threads to

00:26:55.566 --> 00:26:57.446 A:middle
ensure that they all execute

00:26:57.446 --> 00:26:58.206 A:middle
asynchronously.

00:26:59.116 --> 00:27:01.126 A:middle
Now, you switch to reducing fill


00:26:59.116 --> 00:27:01.126 A:middle
Now, you switch to reducing fill

00:27:01.666 --> 00:27:01.766 A:middle
rate.

00:27:03.186 --> 00:27:04.986 A:middle
Vive Pro introduces new

00:27:05.046 --> 00:27:06.836 A:middle
challenges for VR application

00:27:06.836 --> 00:27:07.466 A:middle
developers.

00:27:08.026 --> 00:27:09.516 A:middle
To better understand scale of

00:27:09.516 --> 00:27:11.186 A:middle
the problem, we will compare

00:27:11.186 --> 00:27:12.676 A:middle
different medium fill rates.

00:27:12.676 --> 00:27:15.756 A:middle
So, for example, application

00:27:15.756 --> 00:27:18.556 A:middle
rendering in default scaling

00:27:18.616 --> 00:27:21.966 A:middle
rate to Vive headset, produces

00:27:22.266 --> 00:27:27.776 A:middle
436 megapixels per second.

00:27:27.776 --> 00:27:29.766 A:middle
And most advanced [inaudible]

00:27:30.236 --> 00:27:32.776 A:middle
against that [inaudible] HD TVs

00:27:32.776 --> 00:27:39.546 A:middle
have fill rate of 475 megapixels

00:27:39.606 --> 00:27:40.156 A:middle
per second.

00:27:40.916 --> 00:27:43.806 A:middle
Those numbers are already so big

00:27:44.136 --> 00:27:45.416 A:middle
that game developers use

00:27:45.476 --> 00:27:47.056 A:middle
different tweaks to reduce this

00:27:47.056 --> 00:27:47.486 A:middle
fill rate.

00:27:48.246 --> 00:27:49.856 A:middle
Now, let's see how Vive Pro

00:27:49.856 --> 00:27:51.226 A:middle
compares to those numbers.

00:27:53.046 --> 00:27:55.116 A:middle
Vive Pro has a normal fill rate

00:27:55.116 --> 00:27:58.676 A:middle
of 775 megapixels per second,

00:27:59.146 --> 00:28:00.826 A:middle
and if you add to that four


00:27:59.146 --> 00:28:00.826 A:middle
and if you add to that four

00:28:00.826 --> 00:28:02.976 A:middle
times multi-sampling [inaudible]

00:28:03.206 --> 00:28:05.186 A:middle
or bigger scaling rate, this

00:28:05.186 --> 00:28:06.486 A:middle
number will grow even more.

00:28:06.486 --> 00:28:09.786 A:middle
That is why reducing fill rate

00:28:09.786 --> 00:28:11.206 A:middle
is so important.

00:28:12.146 --> 00:28:13.406 A:middle
There are multiple techniques

00:28:13.406 --> 00:28:14.956 A:middle
there and new techniques are

00:28:14.956 --> 00:28:15.826 A:middle
made every day.

00:28:16.316 --> 00:28:19.046 A:middle
So I encourage you to try them

00:28:19.046 --> 00:28:22.106 A:middle
all, but today we will focus

00:28:22.106 --> 00:28:24.506 A:middle
only on a few still as they are

00:28:24.506 --> 00:28:27.746 A:middle
the simplest to implement and

00:28:27.746 --> 00:28:29.836 A:middle
bring nice performance gains.

00:28:30.356 --> 00:28:31.986 A:middle
So we will start with clipping

00:28:31.986 --> 00:28:33.056 A:middle
invisible pixels.

00:28:33.946 --> 00:28:36.186 A:middle
Here, you can see image rendered

00:28:36.186 --> 00:28:37.076 A:middle
for left eye.

00:28:38.526 --> 00:28:40.566 A:middle
But due to the nature of the

00:28:40.566 --> 00:28:44.766 A:middle
lens work, about 20% of those

00:28:44.896 --> 00:28:47.646 A:middle
pixels are lost after compositor

00:28:47.726 --> 00:28:49.506 A:middle
performs its distortion

00:28:49.506 --> 00:28:50.156 A:middle
correction.

00:28:50.786 --> 00:28:52.166 A:middle
So on the right, you can see

00:28:52.216 --> 00:28:53.796 A:middle
image that will be displayed on

00:28:53.796 --> 00:28:55.746 A:middle
a panel in a headset before it

00:28:55.746 --> 00:28:56.706 A:middle
goes through the lens.

00:28:58.746 --> 00:29:00.896 A:middle
So, the simplest way to reduce


00:28:58.746 --> 00:29:00.896 A:middle
So, the simplest way to reduce

00:29:00.896 --> 00:29:03.836 A:middle
our fill rate is to prevent our

00:29:03.836 --> 00:29:05.426 A:middle
application from rendering those

00:29:05.486 --> 00:29:07.066 A:middle
pixels that won't be visible

00:29:07.066 --> 00:29:09.616 A:middle
anyway, and you can do that

00:29:09.616 --> 00:29:12.176 A:middle
easily by using SteamVR Stencil

00:29:12.176 --> 00:29:12.946 A:middle
Mask.

00:29:14.416 --> 00:29:18.836 A:middle
So we've just saved 20% of our

00:29:18.836 --> 00:29:20.406 A:middle
fill rate by applying this

00:29:20.406 --> 00:29:22.626 A:middle
simple mask, and reduce our Vive

00:29:22.966 --> 00:29:26.806 A:middle
Pro fill rate to 620 megapixels.

00:29:29.286 --> 00:29:32.236 A:middle
Now, we will analyze implication

00:29:32.276 --> 00:29:33.776 A:middle
of this lens distortion

00:29:33.776 --> 00:29:35.326 A:middle
correction in more detail.

00:29:36.336 --> 00:29:40.836 A:middle
We will divide our field of view

00:29:40.836 --> 00:29:42.936 A:middle
into nine sections.

00:29:43.886 --> 00:29:45.986 A:middle
Central section has field of

00:29:45.986 --> 00:29:48.396 A:middle
view of 80 degrees horizontally

00:29:48.456 --> 00:29:51.276 A:middle
by 80 degrees vertically, and we

00:29:51.276 --> 00:29:53.206 A:middle
have surrounding sections on the

00:29:53.266 --> 00:29:54.396 A:middle
edges and corners.

00:29:55.306 --> 00:29:57.596 A:middle
We've color tinted them to

00:29:57.596 --> 00:29:58.956 A:middle
better visualize the

00:29:58.956 --> 00:30:00.726 A:middle
contribution to final image.


00:29:58.956 --> 00:30:00.726 A:middle
contribution to final image.

00:30:01.306 --> 00:30:05.196 A:middle
So as you can see, corners are

00:30:05.196 --> 00:30:08.236 A:middle
almost completely invisible and

00:30:08.506 --> 00:30:11.786 A:middle
edges have matched less

00:30:11.786 --> 00:30:13.596 A:middle
contribution to the image than

00:30:13.626 --> 00:30:14.696 A:middle
in the original one.

00:30:15.486 --> 00:30:17.996 A:middle
In fact, if you see this image

00:30:17.996 --> 00:30:19.996 A:middle
in the headset, you wouldn't be

00:30:20.066 --> 00:30:22.616 A:middle
able to look directly at the red

00:30:22.726 --> 00:30:23.346 A:middle
sections.

00:30:24.126 --> 00:30:25.846 A:middle
The only way to see them would

00:30:25.846 --> 00:30:27.366 A:middle
be with your peripheral vision.

00:30:28.886 --> 00:30:31.666 A:middle
So this gives us great hint.

00:30:33.306 --> 00:30:35.186 A:middle
We can render those edge and

00:30:35.236 --> 00:30:37.626 A:middle
corner sections and a reduced

00:30:37.626 --> 00:30:40.086 A:middle
fill rate, as they are mostly

00:30:40.086 --> 00:30:41.046 A:middle
invisible anyway.

00:30:42.276 --> 00:30:45.056 A:middle
We render the central section as

00:30:45.056 --> 00:30:45.956 A:middle
we did before.

00:30:47.296 --> 00:30:49.046 A:middle
But then we will render vertical

00:30:49.046 --> 00:30:51.856 A:middle
edges with half of the width and

00:30:51.906 --> 00:30:53.946 A:middle
horizontal sections with half of

00:30:53.976 --> 00:30:54.686 A:middle
the height.

00:30:54.686 --> 00:30:56.966 A:middle
And finally, we will render

00:30:57.026 --> 00:31:00.306 A:middle
corner edges at one-fourth of


00:30:57.026 --> 00:31:00.306 A:middle
corner edges at one-fourth of

00:31:00.306 --> 00:31:01.066 A:middle
the resolution.

00:31:03.076 --> 00:31:05.166 A:middle
Once our expensive rendering

00:31:05.246 --> 00:31:06.976 A:middle
pass is complete, we will

00:31:06.976 --> 00:31:09.606 A:middle
perform cheap upscaling pass

00:31:09.606 --> 00:31:11.416 A:middle
that will stretch those regions

00:31:11.646 --> 00:31:13.276 A:middle
back to the resolution at which

00:31:13.276 --> 00:31:14.616 A:middle
they need to be submitted to

00:31:14.616 --> 00:31:15.356 A:middle
compositor.

00:31:16.386 --> 00:31:18.186 A:middle
So you are wondering how much

00:31:18.226 --> 00:31:20.166 A:middle
we've gained by doing that.

00:31:21.316 --> 00:31:23.576 A:middle
In case of 80 by 80 degree

00:31:23.576 --> 00:31:25.546 A:middle
central region, we reduced our

00:31:25.546 --> 00:31:27.556 A:middle
fill rate all the way down to

00:31:27.556 --> 00:31:30.586 A:middle
491 megapixels per second.

00:31:31.736 --> 00:31:32.936 A:middle
But you remember that we just

00:31:32.996 --> 00:31:34.666 A:middle
talked about clipping invisible

00:31:34.666 --> 00:31:36.866 A:middle
pixels, so let's combine those

00:31:36.946 --> 00:31:38.036 A:middle
two techniques together.

00:31:40.016 --> 00:31:42.456 A:middle
By clipping pixels combined with

00:31:42.456 --> 00:31:44.016 A:middle
multi-resolution shading, you

00:31:44.016 --> 00:31:45.696 A:middle
can reduce your fill rate even

00:31:45.696 --> 00:31:48.796 A:middle
further to 456 megapixels per

00:31:48.796 --> 00:31:50.636 A:middle
second, and that is not a random

00:31:50.636 --> 00:31:50.996 A:middle
number.

00:31:51.696 --> 00:31:54.196 A:middle
In fact, that's a default fill

00:31:54.196 --> 00:31:57.456 A:middle
rate of Vive headset, so by just

00:31:57.456 --> 00:31:59.176 A:middle
using those two optimization

00:31:59.176 --> 00:32:01.246 A:middle
techniques, your application can


00:31:59.176 --> 00:32:01.246 A:middle
techniques, your application can

00:32:01.246 --> 00:32:03.536 A:middle
render to Vive Pro with much

00:32:03.536 --> 00:32:05.796 A:middle
higher resolution using exactly

00:32:05.796 --> 00:32:08.386 A:middle
the same GPU as it did when

00:32:08.386 --> 00:32:09.796 A:middle
rendering to Vive headset.

00:32:10.816 --> 00:32:12.486 A:middle
Of course, you can use those

00:32:12.556 --> 00:32:13.626 A:middle
techniques when rendering to

00:32:13.626 --> 00:32:15.346 A:middle
Vive as well, which will allow

00:32:15.346 --> 00:32:17.306 A:middle
you to bring visualize of your

00:32:17.566 --> 00:32:19.386 A:middle
application even further and

00:32:20.106 --> 00:32:21.046 A:middle
make it prettier.

00:32:21.626 --> 00:32:25.306 A:middle
There is one caveat here.

00:32:25.676 --> 00:32:27.166 A:middle
Multi-resolution shading

00:32:27.296 --> 00:32:30.356 A:middle
requires few render passes, so

00:32:30.356 --> 00:32:34.006 A:middle
it will increase your workload

00:32:34.126 --> 00:32:36.356 A:middle
on geometric [inaudible], but

00:32:36.356 --> 00:32:38.466 A:middle
you can easily mitigate that by

00:32:38.516 --> 00:32:39.996 A:middle
just reducing your central

00:32:39.996 --> 00:32:41.746 A:middle
vision by a few degrees.

00:32:42.556 --> 00:32:44.036 A:middle
Here, by just reducing our

00:32:44.036 --> 00:32:45.996 A:middle
central vision by 10 degrees,

00:32:46.486 --> 00:32:48.026 A:middle
we've reduced fill rate all the

00:32:48.026 --> 00:32:50.346 A:middle
way to 382 megapixels per

00:32:50.346 --> 00:32:50.826 A:middle
second.

00:32:51.546 --> 00:32:53.956 A:middle
And if your geometry workload is

00:32:53.956 --> 00:32:56.606 A:middle
really high, you can go further,

00:32:56.696 --> 00:32:59.146 A:middle
and experiment with lower fill

00:32:59.146 --> 00:33:02.116 A:middle
rate, lower regions, that will


00:32:59.146 --> 00:33:02.116 A:middle
rate, lower regions, that will

00:33:02.446 --> 00:33:03.966 A:middle
reduce fill rate even more.

00:33:04.846 --> 00:33:07.206 A:middle
In case of 55 by 55 degrees

00:33:07.206 --> 00:33:10.446 A:middle
central region, 80% of your

00:33:11.266 --> 00:33:12.536 A:middle
[inaudible] eye movement will be

00:33:12.536 --> 00:33:15.546 A:middle
still inside this region, but

00:33:15.546 --> 00:33:17.426 A:middle
we've reduced our fill rate by

00:33:17.426 --> 00:33:20.016 A:middle
more than half, to 360

00:33:20.146 --> 00:33:23.476 A:middle
megapixels per second.

00:33:23.696 --> 00:33:25.116 A:middle
So of course there are different

00:33:25.116 --> 00:33:26.316 A:middle
ways to implement

00:33:26.366 --> 00:33:29.446 A:middle
multi-resolution shading.

00:33:30.466 --> 00:33:32.326 A:middle
And you will get different

00:33:32.416 --> 00:33:34.626 A:middle
performance gains from that.

00:33:34.816 --> 00:33:36.366 A:middle
So I encourage you to experiment

00:33:36.366 --> 00:33:37.966 A:middle
with this technique and try what

00:33:38.006 --> 00:33:39.446 A:middle
will work for you best.

00:33:41.546 --> 00:33:42.926 A:middle
So let's summarize everything

00:33:42.926 --> 00:33:44.316 A:middle
that we've learned during this

00:33:46.536 --> 00:33:46.986 A:middle
session.

00:33:47.086 --> 00:33:48.676 A:middle
We've just announced plug and

00:33:48.716 --> 00:33:50.446 A:middle
play support for Vive Pro

00:33:50.486 --> 00:33:53.526 A:middle
Headsets, and introduced new

00:33:53.526 --> 00:33:55.256 A:middle
Metal 2 features that allow you

00:33:55.256 --> 00:33:57.306 A:middle
now to develop even more

00:33:57.306 --> 00:33:58.916 A:middle
advanced VR applications.

00:33:59.726 --> 00:34:01.486 A:middle
And I encourage you to take


00:33:59.726 --> 00:34:01.486 A:middle
And I encourage you to take

00:34:01.486 --> 00:34:03.246 A:middle
advantage of multi-GPU

00:34:03.246 --> 00:34:05.006 A:middle
configurations, as they are

00:34:05.006 --> 00:34:06.726 A:middle
becoming common on other

00:34:06.816 --> 00:34:07.416 A:middle
platforms.

00:34:08.076 --> 00:34:12.136 A:middle
You can learn more about this

00:34:12.136 --> 00:34:14.106 A:middle
session from this link, and I

00:34:14.106 --> 00:34:16.335 A:middle
would like to invite all of you

00:34:16.525 --> 00:34:17.606 A:middle
to meet with me and my

00:34:17.606 --> 00:34:19.616 A:middle
colleagues during Metal 4 VR

00:34:19.616 --> 00:34:21.766 A:middle
Lab, that will take place today

00:34:21.766 --> 00:34:24.136 A:middle
at 12:00 p.m. in Technology Lab

00:34:24.136 --> 00:34:24.536 A:middle
6.

00:34:24.626 --> 00:34:26.976 A:middle
Thank you very much.

00:34:27.516 --> 00:34:30.500 A:middle
[ Applause ]
