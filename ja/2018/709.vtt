WEBVTT

00:00:07.107 --> 00:00:16.550 align:start position:43% line:-1
(音楽)

00:00:21.688 --> 00:00:24.758 align:start position:43% line:-1
(拍手)

00:00:24.858 --> 00:00:25.759 align:start position:41% line:-1
こんにちは

00:00:25.859 --> 00:00:28.362 align:start position:43% line:-1
(拍手)

00:00:31.532 --> 00:00:34.067 align:start position:29% line:-2
Core MLの２回目の
セッションです

00:00:34.334 --> 00:00:38.272 align:start position:18% line:-2
私はCore MLチームのエンジニア
アセームです

00:00:40.807 --> 00:00:45.145 align:start position:25% line:-2
Core MLはデバイス上で
推論可能な Appleの―

00:00:45.245 --> 00:00:47.214 align:start position:27% line:-1
機械学習フレームワークです

00:00:48.382 --> 00:00:54.354 align:start position:20% line:-2
Appleのすべてのハードウェアに
最適化されています

00:00:55.455 --> 00:00:58.091 align:start position:34% line:-2
昨年は多くの
アプリケーションが

00:00:58.192 --> 00:01:02.696 align:start position:25% line:-2
Appleプラットフォームで
配信されました

00:00:58.192 --> 00:01:02.696 align:start position:25% line:-2
Appleプラットフォームで
配信されました

00:01:03.030 --> 00:01:04.932 align:start position:34% line:-1
すばらしいことです

00:01:05.265 --> 00:01:10.103 align:start position:27% line:-2
さらに今年は
新しい機能が追加されました

00:01:10.637 --> 00:01:15.475 align:start position:27% line:-2
アプリケーションのサイズを
大幅に縮小できます

00:01:16.543 --> 00:01:21.882 align:start position:23% line:-2
新しいバッチ予測APIを使えば
速度も向上します

00:01:23.016 --> 00:01:26.086 align:start position:29% line:-1
カスタマイズ機能を使えば

00:01:26.186 --> 00:01:30.357 align:start position:30% line:-2
最先端のリサーチを
組み込むことも簡単です

00:01:31.692 --> 00:01:34.094 align:start position:29% line:-1
ここまでが前回の復習です

00:01:34.461 --> 00:01:39.466 align:start position:27% line:-2
聞き逃した方は
スライドを確認してください

00:01:41.435 --> 00:01:44.071 align:start position:32% line:-1
今回はこれらの機能を

00:01:44.271 --> 00:01:47.341 align:start position:25% line:-1
実際にどう使うのか見てみます

00:01:47.975 --> 00:01:51.478 align:start position:32% line:-2
具体的には
いくつかの例を挙げて

00:01:51.712 --> 00:01:57.751 align:start position:20% line:-2
Core ML Toolsを使った
簡単な活用法を紹介します

00:01:57.985 --> 00:02:03.223 align:start position:25% line:-2
モデルのサイズを小さくしたり
機能をカスタマイズできます

00:01:57.985 --> 00:02:03.223 align:start position:25% line:-2
モデルのサイズを小さくしたり
機能をカスタマイズできます

00:02:04.558 --> 00:02:06.326 align:start position:38% line:-1
今回の議題です

00:02:07.060 --> 00:02:11.165 align:start position:20% line:-2
まず Core ML Toolsの
エコシステムを確認します

00:02:11.698 --> 00:02:15.669 align:start position:29% line:-2
それから量子化と
カスタムコンバージョンの

00:02:15.802 --> 00:02:17.771 align:start position:34% line:-1
デモをお見せします

00:02:17.971 --> 00:02:19.806 align:start position:34% line:-1
では 始めましょう

00:02:23.210 --> 00:02:25.612 align:start position:30% line:-1
まず MLModelは

00:02:26.046 --> 00:02:30.217 align:start position:27% line:-1
オンライン上で見つかります

00:02:32.319 --> 00:02:35.455 align:start position:29% line:-1
ダウンロードするだけです

00:02:36.056 --> 00:02:40.160 align:start position:21% line:-1
Appleの機械学習サイトからも

00:02:40.260 --> 00:02:44.598 align:start position:32% line:-2
いくつかのモデルを
ダウンロードできます

00:02:45.499 --> 00:02:50.103 align:start position:30% line:-2
自分のデータセット上で
モデルを学習させるには

00:02:50.204 --> 00:02:53.740 align:start position:23% line:-1
Create MLを使用します

00:02:53.841 --> 00:02:57.177 align:start position:29% line:-2
発表したばかりの
新しいフレームワークです

00:02:57.845 --> 00:03:01.181 align:start position:29% line:-1
機械学習に詳しくなくても

00:02:57.845 --> 00:03:01.181 align:start position:29% line:-1
機械学習に詳しくなくても

00:03:01.281 --> 00:03:04.284 align:start position:21% line:-1
簡単に使えるXcodeの機能です

00:03:04.384 --> 00:03:07.321 align:start position:34% line:-1
ぜひ試してください

00:03:08.455 --> 00:03:11.225 align:start position:32% line:-1
他の機械学習ツールに

00:03:11.325 --> 00:03:15.829 align:start position:30% line:-2
すでに精通している方も
いるでしょう

00:03:15.996 --> 00:03:18.398 align:start position:21% line:-2
そのため
Core ML Toolsという

00:03:18.499 --> 00:03:22.302 align:start position:27% line:-2
Pythonのパッケージを
リリースしました

00:03:22.503 --> 00:03:27.107 align:start position:29% line:-2
同時にコンバータも
いくつかリリースしました

00:03:28.342 --> 00:03:32.513 align:start position:34% line:-2
昨年は この分野で
活発な動きがあり

00:03:32.946 --> 00:03:35.249 align:start position:30% line:-1
現状はこうなっています

00:03:37.417 --> 00:03:42.756 align:start position:32% line:-2
数多くのコンバータが
リリースされています

00:03:42.890 --> 00:03:47.361 align:start position:25% line:-2
どのフレームワークを選ぶかは
あなた次第です

00:03:48.695 --> 00:03:52.933 align:start position:18% line:-2
すべてのコンバータは
Core ML Toolsの上位です

00:03:55.369 --> 00:03:59.406 align:start position:32% line:-2
２つのコンバータを
強調しておきましょう

00:04:01.141 --> 00:04:05.078 align:start position:32% line:-2
昨年 私たちは
Googleと協力し

00:04:05.179 --> 00:04:09.082 align:start position:21% line:-2
TensorFlowコンバータを
リリースしました

00:04:10.684 --> 00:04:15.556 align:start position:30% line:-2
新しいレイヤを試したい
研究者のために

00:04:15.689 --> 00:04:19.827 align:start position:30% line:-2
カスタムレイヤの
サポートを追加しました

00:04:21.094 --> 00:04:26.033 align:start position:27% line:-2
トレーニング中の量子化の
サポートもリリースしました

00:04:26.166 --> 00:04:28.936 align:start position:32% line:-2
Core ML 2が
サポートする量子化で

00:04:29.102 --> 00:04:31.538 align:start position:27% line:-1
まもなく追加される予定です

00:04:33.140 --> 00:04:38.178 align:start position:27% line:-2
さらにFacebookや
Prismaとの協力により

00:04:38.278 --> 00:04:41.248 align:start position:30% line:-1
ONNXを開発しました

00:04:42.182 --> 00:04:44.418 align:start position:36% line:-1
ONNXの魅力は

00:04:45.586 --> 00:04:50.123 align:start position:29% line:-2
様々なタイプの
トレーニングライブラリを

00:04:50.224 --> 00:04:54.695 align:start position:20% line:-1
Core MLに変換できることです

00:04:56.196 --> 00:05:00.734 align:start position:20% line:-2
以上がCore ML Toolsの
エコシステムの要約です

00:04:56.196 --> 00:05:00.734 align:start position:20% line:-2
以上がCore ML Toolsの
エコシステムの要約です

00:05:00.834 --> 00:05:05.806 align:start position:30% line:-2
量子化については
ソハイブに任せましょう

00:05:06.306 --> 00:05:11.678 align:start position:43% line:-1
(拍手)

00:05:14.081 --> 00:05:17.985 align:start position:21% line:-2
Core MLチームのエンジニア
ソハイブです

00:05:18.085 --> 00:05:19.953 align:start position:18% line:-1
Core ML Tools 2.0の

00:05:20.053 --> 00:05:23.457 align:start position:25% line:-2
新しい量子化ユーティリティを
紹介します

00:05:28.095 --> 00:05:32.533 align:start position:12% line:-2
Core ML Tools 2.0は最新の
Core MLフォーマットをサポートし

00:05:32.766 --> 00:05:37.070 align:start position:29% line:-2
モデルの変形や
量子化を簡単に実現する―

00:05:37.171 --> 00:05:39.873 align:start position:25% line:-1
ユーティリティを備えています

00:05:40.240 --> 00:05:44.444 align:start position:32% line:-2
モデルのサイズを
小さくするだけでなく

00:05:44.545 --> 00:05:49.383 align:start position:25% line:-2
アプリケーションのモデル数や
フットプリントを削減できます

00:05:50.317 --> 00:05:53.654 align:start position:27% line:-1
量子化から見ていきましょう

00:05:54.822 --> 00:05:57.457 align:start position:29% line:-2
トレーニング後の量子化を
サポートします

00:05:57.624 --> 00:06:00.460 align:start position:25% line:-2
オリジナルは Core ML
ニューラルネットワークの

00:05:57.624 --> 00:06:00.460 align:start position:25% line:-2
オリジナルは Core ML
ニューラルネットワークの

00:06:00.561 --> 00:06:03.564 align:start position:23% line:-1
32ビットフロートのモデルです

00:06:03.697 --> 00:06:07.734 align:start position:20% line:-2
Core ML Toolsを使って
これを量子化すると

00:06:08.101 --> 00:06:10.437 align:start position:30% line:-1
サイズが小さくなります

00:06:10.771 --> 00:06:16.343 align:start position:29% line:-2
量子化のビット数によって
サイズ縮小率は変わります

00:06:17.778 --> 00:06:21.181 align:start position:30% line:-2
量子化とは
どういうことでしょう？

00:06:21.281 --> 00:06:23.584 align:start position:30% line:-1
サイズを変える方法は？

00:06:23.984 --> 00:06:26.653 align:start position:34% line:-1
詳しく見ていきます

00:06:30.357 --> 00:06:35.662 align:start position:23% line:-2
ニューラルネットワークは
関数のレイヤで構成されています

00:06:36.063 --> 00:06:39.299 align:start position:29% line:-1
この関数をウェイトと呼び

00:06:39.700 --> 00:06:43.070 align:start position:27% line:-2
通常は32ビットフロートで
格納します

00:06:44.304 --> 00:06:47.474 align:start position:18% line:-1
前回はResnet50を紹介しました

00:06:47.674 --> 00:06:52.212 align:start position:34% line:-2
画像分類に使われる
機械学習モデルです

00:06:52.446 --> 00:06:56.617 align:start position:20% line:-2
2500万ものウェイトパラメータを
含んでいます

00:06:57.050 --> 00:07:00.420 align:start position:34% line:-2
少ないビット数で
表すことができれば

00:06:57.050 --> 00:07:00.420 align:start position:34% line:-2
少ないビット数で
表すことができれば

00:07:00.521 --> 00:07:05.526 align:start position:34% line:-2
モデルのサイズを
大幅に縮小できます

00:07:06.894 --> 00:07:09.997 align:start position:29% line:-1
このプロセスが量子化です

00:07:10.430 --> 00:07:13.467 align:start position:32% line:-2
量子化では
最小値と最大値の間の

00:07:13.567 --> 00:07:16.336 align:start position:23% line:-1
レイヤのウェイトを抜き取ります

00:07:16.503 --> 00:07:20.107 align:start position:32% line:-2
そして符号なし整数に
マッピングします

00:07:20.908 --> 00:07:23.544 align:start position:29% line:-1
APICの量子化の場合―

00:07:23.644 --> 00:07:26.947 align:start position:30% line:-2
マッピングの範囲は
０から255となります

00:07:27.047 --> 00:07:31.185 align:start position:21% line:-1
７ビットの場合は０から127です

00:07:31.385 --> 00:07:35.789 align:start position:30% line:-2
１ビットのマッピングは
０もしくは１となります

00:07:36.290 --> 00:07:40.794 align:start position:30% line:-2
ビット数が少ないほど
サイズは小さくなります

00:07:42.362 --> 00:07:47.568 align:start position:30% line:-2
浮動小数点の値を整数に
マッピングしています

00:07:48.202 --> 00:07:51.171 align:start position:27% line:-1
いくらか精度が落ちることは

00:07:51.672 --> 00:07:54.241 align:start position:38% line:-1
否定できません

00:07:54.741 --> 00:07:58.312 align:start position:32% line:-2
経験的には量子化の
ビット数が小さいほど

00:07:58.579 --> 00:08:00.948 align:start position:27% line:-1
モデルの精度は損なわれます

00:07:58.579 --> 00:08:00.948 align:start position:27% line:-1
モデルの精度は損なわれます

00:08:01.048 --> 00:08:02.783 align:start position:36% line:-1
後ほど解説します

00:08:03.851 --> 00:08:05.752 align:start position:36% line:-1
これが量子化です

00:08:05.986 --> 00:08:09.056 align:start position:34% line:-2
では どうやって
マッピングするのか

00:08:09.456 --> 00:08:13.594 align:start position:27% line:-2
多くのアルゴリズムや
テクニックが知られています

00:08:13.694 --> 00:08:16.797 align:start position:32% line:-2
Core MLが
サポートしているのは

00:08:17.164 --> 00:08:20.000 align:start position:23% line:-2
直線量子化と
ルックアップテーブル量子化です

00:08:20.634 --> 00:08:22.436 align:start position:32% line:-1
簡単に説明しましょう

00:08:26.306 --> 00:08:27.908 align:start position:39% line:-1
直線量子化は

00:08:28.008 --> 00:08:32.078 align:start position:30% line:-2
すべてのパラメータを
均等にマッピングします

00:08:32.913 --> 00:08:37.083 align:start position:29% line:-2
スケールとバイアスで
パラメータ化する方法です

00:08:37.183 --> 00:08:42.655 align:start position:21% line:-2
その値は量子化するレイヤの
パラメータに基づいて計算されます

00:08:43.056 --> 00:08:46.627 align:start position:30% line:-2
マッピングの効果を
簡単にイメージするには

00:08:46.793 --> 00:08:51.565 align:start position:30% line:-2
量子化されたウェイトを
元の浮動小数点数に

00:08:51.665 --> 00:08:53.433 align:start position:34% line:-1
戻せばいいだけです

00:08:53.834 --> 00:08:57.704 align:start position:29% line:-2
直線量子化では
スケールにバイアスを加え

00:08:57.805 --> 00:09:00.307 align:start position:27% line:-1
単純にウェイトを増やします

00:08:57.805 --> 00:09:00.307 align:start position:27% line:-1
単純にウェイトを増やします

00:09:02.142 --> 00:09:04.912 align:start position:29% line:-1
もう１つの量子化の方法は

00:09:05.012 --> 00:09:06.647 align:start position:27% line:-1
ルックアップテーブル量子化

00:09:07.181 --> 00:09:10.918 align:start position:21% line:-2
文字どおり
ルックアップテーブルを作成します

00:09:11.952 --> 00:09:17.090 align:start position:23% line:-2
ウェイトがどのように
元に戻るかイメージしてください

00:09:17.257 --> 00:09:22.996 align:start position:29% line:-2
量子化後のウェイトは
元の指数でしかありません

00:09:23.964 --> 00:09:27.301 align:start position:27% line:-1
直線量子化の場合とは違って

00:09:27.835 --> 00:09:32.139 align:start position:27% line:-2
ウェイトが等間隔で
並んでいる必要はありません

00:09:33.841 --> 00:09:38.045 align:start position:18% line:-2
つまり Core ML Toolsの
２種類の量子化で

00:09:38.679 --> 00:09:42.783 align:start position:29% line:-2
ニューラルネットワークの
精度の高いモデルの―

00:09:42.883 --> 00:09:45.752 align:start position:29% line:-1
ウェイトを量子化できます

00:09:46.186 --> 00:09:50.390 align:start position:29% line:-2
サイズを小さくする方法は
分かりましたが

00:09:50.824 --> 00:09:54.194 align:start position:25% line:-1
パラメータの計算は手間ですね

00:09:54.661 --> 00:09:57.998 align:start position:27% line:-2
直線量子化の
スケールとバイアスの値は？

00:09:58.332 --> 00:10:02.369 align:start position:30% line:-2
ルックアップテーブルは
どうやって作れば？

00:09:58.332 --> 00:10:02.369 align:start position:30% line:-2
ルックアップテーブルは
どうやって作れば？

00:10:03.036 --> 00:10:06.540 align:start position:25% line:-1
何も心配する必要はありません

00:10:06.940 --> 00:10:10.777 align:start position:29% line:-2
ビット数とアルゴリズムを
決めるだけで

00:10:10.878 --> 00:10:15.482 align:start position:20% line:-2
あとはCore ML Toolsが
処理してくれます

00:10:16.049 --> 00:10:16.984 align:start position:38% line:-1
実際のところ…

00:10:17.084 --> 00:10:22.022 align:start position:43% line:-1
(拍手)

00:10:22.656 --> 00:10:27.294 align:start position:25% line:-2
モデルを入手し量子化するのは
とても簡単です

00:10:27.394 --> 00:10:30.097 align:start position:20% line:-1
数行のPythonコードでできます

00:10:30.397 --> 00:10:32.966 align:start position:30% line:-1
デモをお見せしましょう

00:10:40.340 --> 00:10:42.609 align:start position:38% line:-1
デモを行うには

00:10:42.709 --> 00:10:46.280 align:start position:29% line:-2
ニューラルネットワークの
モデルが必要です

00:10:46.680 --> 00:10:51.919 align:start position:23% line:-2
Core ML機械学習サイトで
見つかります

00:10:52.019 --> 00:10:55.155 align:start position:27% line:-1
１つダウンロードしましょう

00:10:55.522 --> 00:10:58.659 align:start position:16% line:-1
SqueezeNetを選択して開きます

00:11:00.627 --> 00:11:03.464 align:start position:27% line:-1
サイズは５メガバイトですね

00:11:03.564 --> 00:11:08.602 align:start position:25% line:-1
入力画像は227×227画素

00:11:08.702 --> 00:11:10.103 align:start position:36% line:-1
出力は２種類です

00:11:10.437 --> 00:11:13.440 align:start position:16% line:-1
１つはclassLabelという文字列

00:11:13.540 --> 00:11:17.611 align:start position:30% line:-2
通常は入力画像のための
ラベルです

00:11:17.711 --> 00:11:22.349 align:start position:32% line:-2
もう１つの出力は
確率のマッピングです

00:11:23.183 --> 00:11:26.954 align:start position:25% line:-1
何の画像なのか候補を挙げます

00:11:28.789 --> 00:11:30.824 align:start position:34% line:-1
これを量子化します

00:11:31.458 --> 00:11:34.862 align:start position:27% line:-2
まず Pythonの環境を
確保します

00:11:34.962 --> 00:11:39.933 align:start position:20% line:-2
Jupyter Notebookが
使いやすいので開きます

00:11:46.673 --> 00:11:48.308 align:start position:36% line:-1
新規作成をします

00:11:49.109 --> 00:11:50.510 align:start position:41% line:-1
ズームして

00:11:51.311 --> 00:11:55.349 align:start position:25% line:-2
Core ML Toolsを
インポートします

00:11:58.919 --> 00:11:59.987 align:start position:41% line:-1
実行します

00:12:00.220 --> 00:12:04.992 align:start position:27% line:-2
次に量子化ユーティリティを
すべてインポートします

00:12:05.092 --> 00:12:07.294 align:start position:36% line:-1
これを実行します

00:12:16.169 --> 00:12:19.039 align:start position:27% line:-1
量子化するモデルが必要です

00:12:19.139 --> 00:12:23.410 align:start position:23% line:-2
先ほどのSqueezeNetの
モデルを取り込みます

00:12:32.719 --> 00:12:34.388 align:start position:30% line:-1
デスクトップに送ります

00:12:38.058 --> 00:12:38.826 align:start position:41% line:-1
これでよし

00:12:39.026 --> 00:12:43.330 align:start position:27% line:-2
たった１度のAPIコールで
量子化できます

00:12:43.464 --> 00:12:47.501 align:start position:29% line:-1
直線量子化を試してみます

00:12:51.572 --> 00:12:54.575 align:start position:9% line:-1
APIコールはquantize weights

00:12:54.808 --> 00:12:59.179 align:start position:30% line:-2
最初のパラメータは
オリジナルのモデルです

00:12:59.513 --> 00:13:03.650 align:start position:23% line:-1
量子化後のビット数を８ビットに

00:12:59.513 --> 00:13:03.650 align:start position:23% line:-1
量子化後のビット数を８ビットに

00:13:04.685 --> 00:13:08.755 align:start position:29% line:-2
量子化アルゴリズムは
linearを指定します

00:13:10.257 --> 00:13:14.995 align:start position:29% line:-2
ニューラルネットワークの
すべてのレイヤに対して

00:13:15.095 --> 00:13:19.099 align:start position:32% line:-2
反復処理が行われて
量子化が終了しました

00:13:20.467 --> 00:13:23.437 align:start position:30% line:-1
量子化することによって

00:13:23.537 --> 00:13:27.541 align:start position:30% line:-2
モデルの精度が落ちると
述べましたね

00:13:27.908 --> 00:13:31.578 align:start position:34% line:-2
元のモデルとの差は
どの程度でしょう

00:13:32.212 --> 00:13:36.250 align:start position:36% line:-2
それを確かめる
最も簡単な方法は

00:13:36.350 --> 00:13:40.154 align:start position:34% line:-2
まず 元のモデルの
データを推論します

00:13:40.587 --> 00:13:44.291 align:start position:27% line:-2
そして 量子化後のモデルの
同じデータと

00:13:44.391 --> 00:13:48.762 align:start position:25% line:-1
比較して一致率を求めるのです

00:13:49.029 --> 00:13:51.431 align:start position:25% line:-2
Core ML Toolsの
機能を使います

00:13:51.532 --> 00:13:55.869 align:start position:14% line:-1
compare modelsと入力します

00:13:56.203 --> 00:13:58.238 align:start position:30% line:-1
精度の高い元のモデルと

00:13:58.505 --> 00:14:01.275 align:start position:27% line:-1
量子化後のモデルを渡します

00:13:58.505 --> 00:14:01.275 align:start position:27% line:-1
量子化後のモデルを渡します

00:14:01.875 --> 00:14:07.481 align:start position:23% line:-2
これは入力が１つだけの
シンプルな画像分類モデルなので

00:14:08.115 --> 00:14:12.986 align:start position:30% line:-2
サンプル画像が入った
フォルダを使いましょう

00:14:13.086 --> 00:14:17.991 align:start position:27% line:-2
デスクトップに画像が入った
フォルダがあります

00:14:18.091 --> 00:14:23.230 align:start position:25% line:-2
一時的パラメータとして
このフォルダにパスを渡します

00:14:28.035 --> 00:14:31.605 align:start position:23% line:-1
フォルダの中の画像を解析します

00:14:31.705 --> 00:14:36.477 align:start position:21% line:-1
精度の高い元のモデルで推論したら

00:14:36.577 --> 00:14:40.447 align:start position:32% line:-2
量子化後のモデルでも
推論して比較します

00:14:41.348 --> 00:14:42.883 align:start position:36% line:-1
終わったようです

00:14:43.750 --> 00:14:47.254 align:start position:7% line:-2
“Top 1 Agreement 94.8％”と
出ています

00:14:47.721 --> 00:14:51.291 align:start position:25% line:-1
“トップ１合致率”の意味は？

00:14:51.525 --> 00:14:54.094 align:start position:27% line:-1
例えば犬の画像を入力したら

00:14:55.395 --> 00:15:00.934 align:start position:23% line:-2
元のモデルも量子化後のモデルも
犬だと予測したとします

00:14:55.395 --> 00:15:00.934 align:start position:23% line:-2
元のモデルも量子化後のモデルも
犬だと予測したとします

00:15:01.034 --> 00:15:04.471 align:start position:27% line:-1
その確率が94.8％でした

00:15:05.772 --> 00:15:08.609 align:start position:30% line:-1
このモデルでも十分です

00:15:08.709 --> 00:15:12.813 align:start position:30% line:-2
でも もう１つの方法も
試したいですね

00:15:13.514 --> 00:15:16.950 align:start position:32% line:-2
Core MLは
直線量子化だけでなく

00:15:17.050 --> 00:15:19.786 align:start position:25% line:-2
ルックアップテーブル量子化も
可能です

00:15:19.887 --> 00:15:24.324 align:start position:29% line:-2
その方法で このモデルを
量子化してみます

00:15:30.898 --> 00:15:34.935 align:start position:21% line:-1
元のモデルとビット数を指定します

00:15:35.636 --> 00:15:37.738 align:start position:34% line:-1
そしてアルゴリズム

00:15:39.273 --> 00:15:40.674 align:start position:36% line:-1
ミスタイプですね

00:15:48.882 --> 00:15:50.150 align:start position:41% line:-1
実行します

00:15:50.617 --> 00:15:53.687 align:start position:27% line:-2
k-meansは
ウェイトの分布を概算する―

00:15:53.787 --> 00:15:56.590 align:start position:29% line:-1
クラスター分析の手法です

00:15:56.690 --> 00:15:59.726 align:start position:36% line:-1
この分布を使って

00:15:59.827 --> 00:16:02.396 align:start position:30% line:-2
ルックアップテーブルを
作成します

00:15:59.827 --> 00:16:02.396 align:start position:30% line:-2
ルックアップテーブルを
作成します

00:16:02.496 --> 00:16:07.167 align:start position:27% line:-2
ニューラルネットワークの
すべてのレイヤを反復処理し

00:16:07.267 --> 00:16:11.705 align:start position:21% line:-2
量子化後のルックアップテーブルを
計算するのです

00:16:12.172 --> 00:16:17.010 align:start position:27% line:-2
モデルのアーキテクチャを
知り尽くしている専門家には

00:16:17.244 --> 00:16:19.713 align:start position:20% line:-1
k-meansは最適とは言えません

00:16:19.813 --> 00:16:23.750 align:start position:27% line:-2
その場合は
このアルゴリズムでなくても

00:16:24.651 --> 00:16:29.756 align:start position:23% line:-2
カスタムの関数を入力して
ルックアップテーブルが作れます

00:16:30.791 --> 00:16:34.795 align:start position:32% line:-2
この方法での
量子化が終わりました

00:16:35.128 --> 00:16:38.432 align:start position:30% line:-1
元のモデルと比較します

00:16:38.532 --> 00:16:41.835 align:start position:25% line:-1
再びモデル比較のAPIを呼び

00:16:42.236 --> 00:16:46.673 align:start position:27% line:-2
元のモデルと
量子化後のモデルを渡します

00:16:47.007 --> 00:16:49.076 align:start position:32% line:-1
そして先ほどと同じく

00:16:50.611 --> 00:16:52.079 align:start position:30% line:-1
サンプル画像のフォルダ

00:16:54.681 --> 00:16:58.752 align:start position:29% line:-2
元のモデルと
量子化後のモデルを使って

00:16:59.553 --> 00:17:01.488 align:start position:36% line:-1
画像を推論します

00:16:59.553 --> 00:17:01.488 align:start position:36% line:-1
画像を推論します

00:17:01.688 --> 00:17:05.992 align:start position:16% line:-2
Top 1 Agreementの数値が
先ほどより高いので

00:17:06.193 --> 00:17:10.164 align:start position:27% line:-2
ルックアップテーブルの方が
適していると分かります

00:17:10.329 --> 00:17:14.300 align:start position:27% line:-2
直線量子化が
適しているモデルもあります

00:17:14.635 --> 00:17:19.138 align:start position:29% line:-2
私のアプリケーションには
これで十分なので

00:17:19.239 --> 00:17:20.973 align:start position:38% line:-1
保存しましょう

00:17:23.410 --> 00:17:25.779 align:start position:29% line:-1
“save”と入力します

00:17:30.450 --> 00:17:34.721 align:start position:11% line:-2
“QuantizedSqueezenet”と
名前を付けます

00:17:40.994 --> 00:17:43.597 align:start position:38% line:-1
これで完了です

00:17:43.730 --> 00:17:47.834 align:start position:21% line:-1
元のモデルは５メガバイトでしたね

00:17:48.135 --> 00:17:50.370 align:start position:32% line:-1
量子化したモデルは？

00:17:52.606 --> 00:17:57.878 align:start position:29% line:-2
わずか1.3メガバイトに
なっているのが分かります

00:17:57.978 --> 00:18:03.417 align:start position:43% line:-1
(拍手)

00:17:57.978 --> 00:18:03.417 align:start position:43% line:-1
(拍手)

00:18:04.051 --> 00:18:08.689 align:start position:32% line:-2
量子化したモデルの
細かい部分については

00:18:08.789 --> 00:18:11.091 align:start position:32% line:-1
元のモデルと同じです

00:18:11.191 --> 00:18:14.862 align:start position:25% line:-1
入力は１つで出力は２種類です

00:18:15.162 --> 00:18:19.700 align:start position:23% line:-2
アプリケーションに使うモデルを
置き換える場合は

00:18:20.033 --> 00:18:24.037 align:start position:34% line:-2
量子化したモデルを
ドラッグするだけで

00:18:24.137 --> 00:18:26.540 align:start position:32% line:-1
サイズを縮小できます

00:18:32.346 --> 00:18:35.149 align:start position:30% line:-1
以上が量子化の方法です

00:18:38.619 --> 00:18:43.991 align:start position:20% line:-2
Core ML Toolsを使えば
こんなにも簡単です

00:18:44.324 --> 00:18:46.827 align:start position:34% line:-1
シンプルなAPIで

00:18:47.361 --> 00:18:51.298 align:start position:25% line:-1
元のモデルと量子化のビット数

00:18:51.532 --> 00:18:53.867 align:start position:23% line:-1
アルゴリズムを指定するだけです

00:18:54.201 --> 00:18:56.603 align:start position:23% line:-1
Core ML Toolsには

00:18:56.703 --> 00:19:02.009 align:start position:21% line:-2
量子化後と元のモデルを
比較するユーティリティもあります

00:18:56.703 --> 00:19:02.009 align:start position:21% line:-2
量子化後と元のモデルを
比較するユーティリティもあります

00:19:03.477 --> 00:19:05.646 align:start position:36% line:-1
デモで見たように

00:19:05.746 --> 00:19:09.182 align:start position:34% line:-2
量子化後のモデルは
精度が落ち―

00:19:09.817 --> 00:19:13.987 align:start position:34% line:-2
その程度はモデルと
データに依存します

00:19:14.555 --> 00:19:18.926 align:start position:34% line:-2
量子化してよくなる
モデルもあります

00:19:19.293 --> 00:19:23.897 align:start position:27% line:-2
一般的には
量子化ビット数が小さいほど

00:19:24.331 --> 00:19:26.133 align:start position:34% line:-1
精度が損なわれます

00:19:26.567 --> 00:19:30.304 align:start position:18% line:-2
デモでは
Top 1 Agreementの値で

00:19:30.404 --> 00:19:34.908 align:start position:29% line:-2
量子化後のモデルを
元のモデルと比較しました

00:19:35.442 --> 00:19:40.114 align:start position:27% line:-2
しかし 量子化後のモデルは
実際の使用事例に

00:19:40.214 --> 00:19:43.150 align:start position:30% line:-1
適合する必要があります

00:19:43.984 --> 00:19:47.588 align:start position:29% line:-2
前回のセッションでは
スタイル変換を行いました

00:19:48.188 --> 00:19:51.024 align:start position:36% line:-1
入力画像に対して

00:19:51.158 --> 00:19:54.728 align:start position:23% line:-1
図案化された画像が出力されます

00:19:55.462 --> 00:19:59.166 align:start position:32% line:-2
量子化レベルによる
違いを見てみましょう

00:20:00.067 --> 00:20:04.605 align:start position:29% line:-1
左上の画像をご覧ください

00:20:04.738 --> 00:20:10.410 align:start position:23% line:-2
32ビット 6.7メガバイトの
オリジナルの画像です

00:20:10.677 --> 00:20:14.715 align:start position:21% line:-2
８ビットの直線量子化で
わずか1.7メガバイトになります

00:20:14.815 --> 00:20:20.087 align:start position:29% line:-2
スタイル変換のデモには
十分な画質だと思われます

00:20:20.721 --> 00:20:23.891 align:start position:32% line:-1
４ビットまで下げても

00:20:23.991 --> 00:20:26.160 align:start position:36% line:-1
劣ってはいません

00:20:26.493 --> 00:20:30.330 align:start position:23% line:-1
個人的には３ビットでも十分です

00:20:30.664 --> 00:20:34.234 align:start position:32% line:-2
２ビットでは
アーチファクトが多く

00:20:34.434 --> 00:20:36.437 align:start position:32% line:-1
使いものになりません

00:20:38.872 --> 00:20:41.475 align:start position:30% line:-1
以上が量子化の解説です

00:20:42.075 --> 00:20:46.513 align:start position:21% line:-2
カスタムコンバージョンについては
アセームが解説します

00:20:46.613 --> 00:20:52.186 align:start position:43% line:-1
(拍手)

00:20:52.286 --> 00:20:53.420 align:start position:41% line:-1
ありがとう

00:20:55.122 --> 00:20:57.391 align:start position:30% line:-1
機械学習の分野において

00:20:57.491 --> 00:21:01.762 align:start position:32% line:-2
不可欠な機能について
話したいと思います

00:20:57.491 --> 00:21:01.762 align:start position:32% line:-2
不可欠な機能について
話したいと思います

00:21:02.262 --> 00:21:03.664 align:start position:38% line:-1
ご存じのように

00:21:04.164 --> 00:21:07.468 align:start position:23% line:-1
この分野は急速に拡大しています

00:21:07.701 --> 00:21:10.571 align:start position:25% line:-1
それを支援するソフトの提供は

00:21:10.737 --> 00:21:14.875 align:start position:23% line:-1
Core MLの重要な課題です

00:21:15.809 --> 00:21:17.211 align:start position:36% line:-1
例を挙げましょう

00:21:17.945 --> 00:21:22.516 align:start position:20% line:-2
Core MLがサポートしていない
新しいモデル

00:21:22.616 --> 00:21:25.385 align:start position:27% line:-1
もしくはサポートしていても

00:21:25.552 --> 00:21:29.256 align:start position:23% line:-1
一部のレイヤがまだ存在しない―

00:21:29.556 --> 00:21:32.092 align:start position:32% line:-1
モデルがあるとします

00:21:32.826 --> 00:21:35.829 align:start position:34% line:-1
そのような場合でも

00:21:35.929 --> 00:21:38.999 align:start position:21% line:-1
Core MLは使えるでしょうか

00:21:39.299 --> 00:21:41.268 align:start position:36% line:-1
答えはイエスです

00:21:41.635 --> 00:21:45.172 align:start position:34% line:-2
カスタマイズ機能を
使えばいいのです

00:21:46.173 --> 00:21:51.078 align:start position:29% line:-2
ニューラルネットワークに
新しいレイヤが

00:21:51.178 --> 00:21:53.781 align:start position:34% line:-1
追加された場合です

00:21:53.881 --> 00:21:57.217 align:start position:34% line:-2
それを変換して
アプリケーションに

00:21:57.317 --> 00:21:59.786 align:start position:29% line:-1
実装する方法を解説します

00:22:00.821 --> 00:22:03.323 align:start position:30% line:-1
まずはモデルの変換です

00:22:03.957 --> 00:22:07.494 align:start position:29% line:-2
Appleのコンバータを
使用したことがなくても

00:22:07.661 --> 00:22:10.964 align:start position:27% line:-1
とてもシンプルなAPIです

00:22:11.965 --> 00:22:15.335 align:start position:23% line:-1
Kerasコンバータを探します

00:22:15.435 --> 00:22:20.474 align:start position:21% line:-2
ONNXやTensorFlowを
探す場合と似ています

00:22:21.742 --> 00:22:25.879 align:start position:30% line:-2
ほとんどの場合は
これだけで機能しますが

00:22:25.979 --> 00:22:29.516 align:start position:29% line:-2
まれにエラーメッセージが
表示されます

00:22:30.717 --> 00:22:34.721 align:start position:27% line:-2
“この操作は
サポートしていません”など

00:22:35.055 --> 00:22:37.191 align:start position:34% line:-1
このような場合も―

00:22:37.291 --> 00:22:41.328 align:start position:34% line:-2
ちょっとした操作で
回避できます

00:22:41.628 --> 00:22:46.533 align:start position:30% line:-2
具体的に言えば
このような時に使うのが

00:22:46.633 --> 00:22:47.834 align:start position:34% line:-1
カスタムレイヤです

00:22:48.902 --> 00:22:53.073 align:start position:29% line:-1
変換の方法を説明する前に

00:22:53.874 --> 00:22:58.078 align:start position:30% line:-2
カスタムレイヤが必要な
事例を紹介します

00:23:01.315 --> 00:23:03.650 align:start position:25% line:-1
画像分類モデルを使うとします

00:23:03.750 --> 00:23:08.622 align:start position:30% line:-2
これがXcodeによる
このモデルの詳細です

00:23:08.856 --> 00:23:12.926 align:start position:29% line:-2
ニューラルネットワークの
可能性が高いですね

00:23:13.126 --> 00:23:15.963 align:start position:29% line:-2
しかも畳み込み
ニューラルネットワークで

00:23:16.063 --> 00:23:19.600 align:start position:30% line:-2
たくさんのレイヤや
活性化関数が含まれます

00:23:20.300 --> 00:23:25.706 align:start position:20% line:-2
Core MLがサポートしていない
関数だとしましょう

00:23:25.806 --> 00:23:30.210 align:start position:25% line:-1
機械学習のカンファレンスでは

00:23:30.377 --> 00:23:34.147 align:start position:34% line:-2
常に新しいレイヤが
開発されています

00:23:35.048 --> 00:23:38.485 align:start position:30% line:-1
このような場合は単純に

00:23:38.585 --> 00:23:42.489 align:start position:36% line:-2
新しいレイヤを
実装するだけです

00:23:42.656 --> 00:23:45.959 align:start position:32% line:-2
元のモデルとの違いは
下の部分の

00:23:46.059 --> 00:23:48.362 align:start position:32% line:-1
依存関係の欄だけです

00:23:49.363 --> 00:23:54.802 align:start position:30% line:-2
カスタムレイヤの存在が
記載されています

00:23:55.202 --> 00:23:56.937 align:start position:36% line:-1
もう１つの例です

00:23:57.037 --> 00:24:00.207 align:start position:30% line:-1
単純な分類子があります

00:23:57.037 --> 00:24:00.207 align:start position:30% line:-1
単純な分類子があります

00:24:01.175 --> 00:24:04.912 align:start position:11% line:-2
最近 Spatial Transformer
ネットワークの

00:24:05.012 --> 00:24:07.214 align:start position:30% line:-1
研究論文を見つけました

00:24:07.548 --> 00:24:10.384 align:start position:34% line:-1
これがその機能です

00:24:10.484 --> 00:24:13.954 align:start position:23% line:-2
数字の後ろに
ニューラルネットワークを挿入し

00:24:14.121 --> 00:24:16.957 align:start position:25% line:-1
この数字をローカライズします

00:24:17.257 --> 00:24:20.127 align:start position:25% line:-2
それを
グリッドサンプラレイヤに送り

00:24:20.260 --> 00:24:22.930 align:start position:23% line:-1
再び数字にレンダリングしますが

00:24:23.030 --> 00:24:25.465 align:start position:27% line:-1
すでに数字を認識しています

00:24:25.566 --> 00:24:28.302 align:start position:30% line:-2
ここから先は
通常の検出メソッドです

00:24:29.069 --> 00:24:32.272 align:start position:27% line:-1
詳細はともかく大事なことは

00:24:32.372 --> 00:24:37.244 align:start position:18% line:-2
Core MLがサポートしているのは
緑の部分です

00:24:37.377 --> 00:24:40.848 align:start position:23% line:-2
赤の部分の
新しいグリッドサンプラレイヤは

00:24:40.948 --> 00:24:44.017 align:start position:20% line:-2
Core MLがサポートしていない
試験的なレイヤです

00:24:44.351 --> 00:24:46.887 align:start position:34% line:-1
このモデルを使って

00:24:47.254 --> 00:24:51.325 align:start position:18% line:-2
Core ML Toolsの使い方を
見てみましょう

00:24:51.892 --> 00:24:53.760 align:start position:34% line:-1
デモをご覧ください

00:25:00.033 --> 00:25:02.102 align:start position:32% line:-1
うまくいくでしょうか

00:25:03.470 --> 00:25:05.439 align:start position:34% line:-1
画面を切り替えます

00:25:07.241 --> 00:25:10.277 align:start position:32% line:-1
ウインドウを閉じます

00:25:14.815 --> 00:25:17.951 align:start position:29% line:-1
MLもクリアにしましょう

00:25:18.051 --> 00:25:23.257 align:start position:12% line:-1
Jupyter Notebookを使います

00:25:29.863 --> 00:25:33.700 align:start position:29% line:-2
学習済みの
ネットワークに移動します

00:25:34.268 --> 00:25:39.406 align:start position:0% line:-2
“spatial transformer MNIST.h5”
というファイルがあります

00:25:39.506 --> 00:25:41.875 align:start position:30% line:-1
Kerasのモデルです

00:25:42.743 --> 00:25:46.013 align:start position:36% line:-2
モデルの入手法が
気になるでしょう

00:25:48.182 --> 00:25:49.683 align:start position:38% line:-1
とても簡単です

00:25:50.083 --> 00:25:53.921 align:start position:29% line:-2
空間変換の
オープンソースから見つけ

00:25:54.021 --> 00:25:57.357 align:start position:29% line:-2
Kerasにスクリプトを
提供しただけです

00:25:58.158 --> 00:26:02.796 align:start position:21% line:-2
同時にPythonのスクリプトも
手に入れました

00:25:58.158 --> 00:26:02.796 align:start position:21% line:-2
同時にPythonのスクリプトも
手に入れました

00:26:03.230 --> 00:26:06.099 align:start position:25% line:-2
本来
このグリッドサンプラレイヤは

00:26:06.300 --> 00:26:09.069 align:start position:18% line:-1
Kerasでもサポートされていません

00:26:09.269 --> 00:26:12.005 align:start position:30% line:-1
そのため実装するために

00:26:12.105 --> 00:26:16.143 align:start position:25% line:-2
Kerasのカスタムレイヤを
使用しました

00:26:16.310 --> 00:26:20.681 align:start position:32% line:-2
Core ML独自の
概念ではありません

00:26:20.781 --> 00:26:24.651 align:start position:23% line:-2
一般的な
機械学習フレームワークと同じ―

00:26:24.751 --> 00:26:27.387 align:start position:29% line:-1
新しいレイヤの試行法です

00:26:27.988 --> 00:26:30.724 align:start position:29% line:-1
このKerasモデルから

00:26:30.824 --> 00:26:34.061 align:start position:21% line:-2
どうやってCore MLモデルを
得ましょうか

00:26:34.328 --> 00:26:36.597 align:start position:41% line:-1
ここから…

00:26:40.267 --> 00:26:43.036 align:start position:21% line:-2
Python Notebookを
新たに開きます

00:26:44.104 --> 00:26:48.442 align:start position:23% line:-2
Kerasモデルを
Pythonにインポートします

00:26:51.812 --> 00:26:54.515 align:start position:29% line:-1
Kerasをインポートし

00:26:55.215 --> 00:26:58.051 align:start position:25% line:-2
Kerasのカスタムレイヤも
インポート

00:26:58.252 --> 00:27:01.221 align:start position:25% line:-1
それからモデルをロードします

00:26:58.252 --> 00:27:01.221 align:start position:25% line:-1
それからモデルをロードします

00:27:02.656 --> 00:27:06.059 align:start position:23% line:-1
Kerasモデルをロードしたら

00:27:06.160 --> 00:27:10.197 align:start position:29% line:-2
モデルやカスタムレイヤに
パーツを割り振ります

00:27:10.964 --> 00:27:14.802 align:start position:25% line:-2
このモデルをCore MLに
変換しましょう

00:27:15.602 --> 00:27:19.473 align:start position:14% line:-2
Core ML Toolsをインポートし
実行します

00:27:19.907 --> 00:27:23.844 align:start position:29% line:-1
先ほどもお見せしたように

00:27:23.944 --> 00:27:27.347 align:start position:27% line:-1
１度のコールで変換できます

00:27:28.448 --> 00:27:32.419 align:start position:30% line:-2
エラーが表示されるのは
想定内です

00:27:33.387 --> 00:27:36.023 align:start position:25% line:-1
大量のエラーメッセージですが

00:27:36.123 --> 00:27:40.194 align:start position:27% line:-1
肝心なのは最後の行だけです

00:27:40.294 --> 00:27:41.361 align:start position:38% line:-1
見てみましょう

00:27:46.733 --> 00:27:51.605 align:start position:23% line:-2
“このレイヤは
サポートしていない”と出ました

00:27:51.805 --> 00:27:55.142 align:start position:29% line:-1
これを解決するためには…

00:27:55.242 --> 00:27:58.312 align:start position:27% line:-1
閉じたほうが見やすいですね

00:27:58.412 --> 00:28:00.948 align:start position:27% line:-1
変換のコールを書き換えます

00:27:58.412 --> 00:28:00.948 align:start position:27% line:-1
変換のコールを書き換えます

00:28:01.048 --> 00:28:03.350 align:start position:27% line:-1
まずはCore MLモデル

00:28:05.953 --> 00:28:09.056 align:start position:34% line:-1
引数を１つ加えます

00:28:09.156 --> 00:28:11.558 align:start position:34% line:-1
“custom…”

00:28:13.227 --> 00:28:15.562 align:start position:11% line:-1
“conversion functions”

00:28:19.399 --> 00:28:23.070 align:start position:34% line:-2
これが辞書になって
レイヤの名前から

00:28:23.303 --> 00:28:27.708 align:start position:20% line:-2
私が定義する関数まで含み
“GridSampler”とします

00:28:27.841 --> 00:28:30.344 align:start position:27% line:-1
まずは おさらいしましょう

00:28:30.510 --> 00:28:35.916 align:start position:27% line:-2
コンバータはKerasの
すべてのレイヤを解析します

00:28:36.783 --> 00:28:40.687 align:start position:32% line:-2
解析したレイヤごとに
パラメータを―

00:28:40.787 --> 00:28:43.857 align:start position:27% line:-1
Core MLに翻訳します

00:28:44.658 --> 00:28:47.394 align:start position:36% line:-2
カスタムレイヤは
対応できません

00:28:47.728 --> 00:28:51.665 align:start position:27% line:-2
そこで グリッドサンプラの
関数を与えると

00:28:51.932 --> 00:28:54.701 align:start position:32% line:-1
変換が可能になります

00:28:54.868 --> 00:28:57.504 align:start position:32% line:-1
関数を見てみましょう

00:29:00.941 --> 00:29:02.309 align:start position:38% line:-1
これが関数です

00:29:02.810 --> 00:29:06.480 align:start position:25% line:-1
やっていることは３つだけです

00:29:07.381 --> 00:29:11.685 align:start position:25% line:-1
まず クラスの名前を与えます

00:29:11.919 --> 00:29:15.722 align:start position:34% line:-2
ここにはレイヤは
実装されていません

00:29:15.856 --> 00:29:21.128 align:start position:27% line:-2
アプリケーションに実装され
クラスにカプセル化されます

00:29:21.228 --> 00:29:24.498 align:start position:29% line:-1
その時のクラスの名前です

00:29:24.631 --> 00:29:28.802 align:start position:30% line:-2
変換の時には
名前を指定するだけです

00:29:29.136 --> 00:29:33.240 align:start position:25% line:-1
続いて誰が見ても分かるように

00:29:33.340 --> 00:29:38.645 align:start position:23% line:-1
モデルの詳細な情報を提供します

00:29:39.246 --> 00:29:42.516 align:start position:25% line:-2
最後にKerasのレイヤから
Core MLに

00:29:42.616 --> 00:29:44.885 align:start position:30% line:-1
翻訳するパラメータです

00:29:44.985 --> 00:29:49.189 align:start position:34% line:-2
このレイヤの場合は
出力の高さと幅を

00:29:49.289 --> 00:29:51.525 align:start position:27% line:-1
Core MLに翻訳します

00:29:51.825 --> 00:29:54.127 align:start position:30% line:-1
パラメータがない場合は

00:29:54.228 --> 00:29:57.931 align:start position:30% line:-2
こんなことをする必要は
ありません

00:29:58.298 --> 00:30:00.300 align:start position:30% line:-1
パラメータが多い場合は

00:29:58.298 --> 00:30:00.300 align:start position:30% line:-1
パラメータが多い場合は

00:30:00.400 --> 00:30:05.405 align:start position:21% line:-2
この方法でCore MLモデルに
カプセル化できます

00:30:06.240 --> 00:30:11.612 align:start position:27% line:-2
クラスを定義する際の方法に
よく似ていますね

00:30:11.712 --> 00:30:14.848 align:start position:32% line:-2
名前と情報
パラメータを与えます

00:30:15.482 --> 00:30:17.084 align:start position:36% line:-1
これを実行します

00:30:19.853 --> 00:30:23.257 align:start position:29% line:-1
無事に変換が終了しました

00:30:25.492 --> 00:30:28.295 align:start position:43% line:-1
続いて…

00:30:28.962 --> 00:30:31.798 align:start position:34% line:-1
うまく動きませんね

00:30:35.569 --> 00:30:38.972 align:start position:32% line:-1
一度 すべて消します

00:30:40.507 --> 00:30:45.012 align:start position:14% line:-2
Core ML Toolsの機能を使えば
簡単に

00:30:45.812 --> 00:30:48.615 align:start position:30% line:-1
モデルを可視化できます

00:30:50.717 --> 00:30:54.421 align:start position:30% line:-1
モデルを可視化しました

00:30:54.521 --> 00:30:58.659 align:start position:29% line:-2
ローカライズしたレイヤが
並んでいます

00:30:58.759 --> 00:31:00.427 align:start position:29% line:-1
これはカスタムレイヤです

00:30:58.759 --> 00:31:00.427 align:start position:29% line:-1
これはカスタムレイヤです

00:31:00.527 --> 00:31:02.996 align:start position:23% line:-1
クリックでパラメータが開きます

00:31:03.096 --> 00:31:06.166 align:start position:29% line:-1
私がつけたクラスの名前と

00:31:06.667 --> 00:31:09.169 align:start position:29% line:-1
パラメータが表示されます

00:31:09.970 --> 00:31:13.807 align:start position:27% line:-2
ドラッグ＆ドロップする前に
問題がないか

00:31:13.907 --> 00:31:16.143 align:start position:29% line:-1
可視化して確かめましょう

00:31:19.279 --> 00:31:21.181 align:start position:36% line:-1
これは違いますね

00:31:21.281 --> 00:31:23.684 align:start position:30% line:-1
このモデルを保存します

00:31:31.158 --> 00:31:32.926 align:start position:34% line:-1
モデルを見てみます

00:31:33.660 --> 00:31:36.663 align:start position:38% line:-1
これは閉じて…

00:31:42.669 --> 00:31:45.539 align:start position:30% line:-1
ディレクトリを入力して

00:31:46.773 --> 00:31:48.275 align:start position:41% line:-1
移動します

00:31:51.945 --> 00:31:55.516 align:start position:20% line:-1
クリックしてXcodeを確認します

00:31:55.616 --> 00:32:00.554 align:start position:21% line:-1
カスタムレイヤの情報もありますね

00:31:55.616 --> 00:32:00.554 align:start position:21% line:-1
カスタムレイヤの情報もありますね

00:32:02.289 --> 00:32:03.624 align:start position:34% line:-1
スライドに戻ります

00:32:05.025 --> 00:32:10.197 align:start position:43% line:-1
(拍手)

00:32:10.297 --> 00:32:14.735 align:start position:32% line:-2
このように関数は
簡単なコードによって

00:32:14.835 --> 00:32:17.704 align:start position:25% line:-1
Core MLに変換できます

00:32:17.805 --> 00:32:22.409 align:start position:21% line:-2
TensorFlowコンバータや
ONNXコンバータと

00:32:22.509 --> 00:32:24.378 align:start position:34% line:-1
プロセスは同じです

00:32:25.212 --> 00:32:30.284 align:start position:27% line:-2
左がパラメータを含む
カスタムレイヤのモデルです

00:32:30.450 --> 00:32:33.320 align:start position:27% line:-2
Xcodeに
ドラッグ＆ドロップするには

00:32:33.420 --> 00:32:38.425 align:start position:25% line:-2
Swiftファイルにクラスを
実装させる必要があります

00:32:38.525 --> 00:32:40.060 align:start position:38% line:-1
見てみましょう

00:32:40.160 --> 00:32:41.862 align:start position:43% line:-1
クラスと

00:32:41.962 --> 00:32:45.866 align:start position:27% line:-1
初期化関数が含まれています

00:32:45.966 --> 00:32:50.337 align:start position:29% line:-2
モデルの中のパラメータを
初期化します

00:32:50.804 --> 00:32:56.243 align:start position:23% line:-2
そして このクラスの
主な関数はevaluateです

00:32:58.145 --> 00:33:02.816 align:start position:36% line:-2
レイヤが実行する
数学関数の実装は

00:32:58.145 --> 00:33:02.816 align:start position:36% line:-2
レイヤが実行する
数学関数の実装は

00:33:02.916 --> 00:33:04.718 align:start position:36% line:-1
ここでなされます

00:33:05.185 --> 00:33:08.055 align:start position:27% line:-1
出力もしくは入力シェイプは

00:33:08.155 --> 00:33:12.426 align:start position:30% line:-2
レイヤが生成する
出力サイズを指定します

00:33:12.526 --> 00:33:16.663 align:start position:29% line:-2
アプリケーションが
効率的に実行されるように

00:33:16.930 --> 00:33:20.100 align:start position:27% line:-1
バッファサイズを分配します

00:33:21.902 --> 00:33:26.940 align:start position:29% line:-2
ここまで 新しいレイヤの
対処法を解説しました

00:33:27.474 --> 00:33:32.679 align:start position:27% line:-2
カスタムレイヤに概念が似た
カスタムモデルです

00:33:33.280 --> 00:33:37.084 align:start position:34% line:-2
考え方は同じですが
より一般的な方法で

00:33:37.184 --> 00:33:41.655 align:start position:30% line:-2
どんなネットワークにも
対応できます

00:33:41.755 --> 00:33:45.125 align:start position:29% line:-2
ニューラルネットワークに
限りません

00:33:45.559 --> 00:33:48.996 align:start position:34% line:-2
より柔軟性があると
言えるでしょう

00:33:50.531 --> 00:33:52.065 align:start position:38% line:-1
まとめましょう

00:33:52.332 --> 00:33:54.368 align:start position:34% line:-1
このセッションでは

00:33:54.468 --> 00:33:59.006 align:start position:25% line:-2
Core ML Toolsの
エコシステムを確認しました

00:33:59.106 --> 00:34:03.977 align:start position:29% line:-2
Core MLモデルには
様々な入手先があります

00:33:59.106 --> 00:34:03.977 align:start position:29% line:-2
Core MLモデルには
様々な入手先があります

00:34:04.444 --> 00:34:06.980 align:start position:30% line:-1
Core MLモデルは

00:34:08.181 --> 00:34:10.551 align:start position:36% line:-1
量子化も簡単です

00:34:10.784 --> 00:34:14.888 align:start position:30% line:-1
さらに 数行のコードで

00:34:14.987 --> 00:34:18.592 align:start position:30% line:-2
新しいカスタムレイヤを
加えられます

00:34:20.761 --> 00:34:23.464 align:start position:30% line:-2
詳しくはドキュメントを
ご覧ください

00:34:23.563 --> 00:34:27.333 align:start position:29% line:-2
ラボでもお待ちしています
ありがとう

00:34:27.434 --> 00:34:30.404 align:start position:43% line:-1
(拍手)
