WEBVTT

00:00:07.174 --> 00:00:15.782 align:start position:43% line:-1
(音楽)

00:00:21.288 --> 00:00:27.194 align:start position:43% line:-1
(拍手)

00:00:27.294 --> 00:00:30.764 align:start position:34% line:-2
おはようございます
マイケルです

00:00:31.064 --> 00:00:34.168 align:start position:30% line:-2
新しいCore MLの
セッションです

00:00:35.602 --> 00:00:40.741 align:start position:16% line:-2
昨年のCore MLは機械学習モデルの
Appへの導入を―

00:00:40.841 --> 00:00:44.311 align:start position:25% line:-1
驚くほど簡単なものにしました

00:00:45.412 --> 00:00:48.916 align:start position:27% line:-2
使っていただいているようで
うれしいです

00:00:49.850 --> 00:00:55.322 align:start position:30% line:-2
もしAppに
新たな能力が備われば―

00:00:55.589 --> 00:00:58.358 align:start position:29% line:-1
とてもすばらしいでしょう

00:00:59.026 --> 00:01:01.094 align:start position:36% line:-1
例えば画像の理解

00:00:59.026 --> 00:01:01.094 align:start position:36% line:-1
例えば画像の理解

00:01:02.696 --> 00:01:06.500 align:start position:32% line:-2
もしくはテキストの
分析などができたら？

00:01:08.702 --> 00:01:13.874 align:start position:27% line:-2
あなたのAppが
音声や音楽の認識や

00:01:15.342 --> 00:01:18.679 align:start position:32% line:-2
動作の認識が
できたらどうでしょう

00:01:19.980 --> 00:01:23.283 align:start position:30% line:-2
さらにコンテンツの
変換や作成ができたら？

00:01:24.384 --> 00:01:28.755 align:start position:29% line:-2
以上の機能は
とても簡単に手に入ります

00:01:29.089 --> 00:01:33.727 align:start position:30% line:-2
Core MLモデルに
エンコードできるからです

00:01:35.128 --> 00:01:37.464 align:start position:30% line:-1
中をのぞいてみましょう

00:01:38.098 --> 00:01:42.903 align:start position:25% line:-2
ニューラルネットワークや
ツリーアンサンブルがあります

00:01:43.670 --> 00:01:49.209 align:start position:25% line:-2
ここには大量のデータから得た
パラメータが存在します

00:01:50.544 --> 00:01:53.780 align:start position:34% line:-2
しかしあなたが扱うべきは
１つのファイルのみです

00:01:54.381 --> 00:01:57.284 align:start position:38% line:-2
実装の詳細より
その機能や―

00:01:57.384 --> 00:02:01.755 align:start position:34% line:-2
実現している体験に
注目してください

00:01:57.384 --> 00:02:01.755 align:start position:34% line:-2
実現している体験に
注目してください

00:02:04.791 --> 00:02:10.030 align:start position:21% line:-2
Core MLモデルの追加は
Xcodeのプロジェクトにファイルを加えるだけ

00:02:11.198 --> 00:02:13.066 align:start position:34% line:-2
シンプルなビューが
出てきます

00:02:13.667 --> 00:02:17.204 align:start position:27% line:-2
実現したい動作の設定のため
必要な入力と―

00:02:17.304 --> 00:02:19.173 align:start position:27% line:-1
提供される出力を指定します

00:02:20.107 --> 00:02:23.844 align:start position:25% line:-2
次に進むとインターフェイスが
表示されます

00:02:24.811 --> 00:02:27.915 align:start position:30% line:-2
数行のコードで
このモデルが使えます

00:02:28.815 --> 00:02:32.853 align:start position:23% line:-2
１行目ではモデルのロード
２行目では推論を指示しています

00:02:33.687 --> 00:02:36.890 align:start position:27% line:-2
３行目にあるように
特定の出力を指定することもできます

00:02:38.091 --> 00:02:40.694 align:start position:30% line:-2
コードの書き直しが
不要なことも

00:02:40.794 --> 00:02:43.764 align:start position:23% line:-2
Core MLが高度なAPIに
統合されているからです

00:02:43.864 --> 00:02:47.668 align:start position:25% line:-2
Core MLモデルの提供だけで
カスタマイズも可能です

00:02:48.068 --> 00:02:51.872 align:start position:14% line:-2
Visionでは
VNCoreMLRequestで行います

00:02:51.972 --> 00:02:53.507 align:start position:12% line:-1
新しいNatural Languageでは

00:02:53.607 --> 00:02:56.944 align:start position:14% line:-2
Core MLモデルからNLModelの
インスタンスが生成できます

00:02:59.513 --> 00:03:01.114 align:start position:23% line:-1
以上がCore MLの概要です

00:02:59.513 --> 00:03:01.114 align:start position:23% line:-1
以上がCore MLの概要です

00:03:01.648 --> 00:03:03.517 align:start position:30% line:-2
これから
新機能について話します

00:03:04.284 --> 00:03:07.754 align:start position:32% line:-2
この１年で多くの
フィードバックを得て

00:03:07.855 --> 00:03:11.458 align:start position:32% line:-2
Core ML 2の
機能強化をしました

00:03:12.626 --> 00:03:15.295 align:start position:30% line:-1
２つに分けて話をします

00:03:15.696 --> 00:03:21.201 align:start position:25% line:-2
最初のセッションでは
Appに関する新機能について

00:03:21.702 --> 00:03:26.940 align:start position:29% line:-2
10時から予定している
２つ目のセッションでは―

00:03:27.441 --> 00:03:29.042 align:start position:30% line:-1
ツールについて話します

00:03:29.343 --> 00:03:34.014 align:start position:20% line:-2
Core ML 2を活用するための
更新や変換方法も紹介します

00:03:36.917 --> 00:03:40.354 align:start position:30% line:-2
App関連の新機能では
３つに焦点を当てます

00:03:40.721 --> 00:03:44.925 align:start position:30% line:-2
１つ目は
同じ機能を維持しつつ―

00:03:45.025 --> 00:03:47.995 align:start position:32% line:-2
モデルのサイズと数を
減らす方法

00:03:48.829 --> 00:03:52.866 align:start position:23% line:-2
２つ目は 単一モデルから
多くのパフォーマンスを得る方法

00:03:54.101 --> 00:03:58.939 align:start position:23% line:-2
３つ目は Core MLを使い
急激に進化し続けている―

00:03:59.039 --> 00:04:01.675 align:start position:36% line:-2
機械学習分野に
対応する方法です

00:03:59.039 --> 00:04:01.675 align:start position:36% line:-2
機械学習分野に
対応する方法です

00:04:02.209 --> 00:04:04.478 align:start position:27% line:-1
まずはモデルサイズからです

00:04:04.578 --> 00:04:06.246 align:start position:27% line:-1
フランチェスコに代わります

00:04:07.014 --> 00:04:10.384 align:start position:43% line:-1
(拍手)

00:04:10.484 --> 00:04:11.618 align:start position:32% line:-1
マイケル ありがとう

00:04:12.853 --> 00:04:13.420 align:start position:41% line:-1
こんにちは

00:04:14.321 --> 00:04:18.291 align:start position:25% line:-2
Core MLのサイズ縮小は
大変重要です

00:04:18.625 --> 00:04:22.596 align:start position:27% line:-2
ここで Appの
サイズ縮小に有益な―

00:04:22.930 --> 00:04:26.667 align:start position:27% line:-2
Core ML 2の２つの
新機能を紹介します

00:04:28.435 --> 00:04:32.239 align:start position:21% line:-2
Core MLは機能学習モデルを
デバイス上で実行させます

00:04:33.640 --> 00:04:37.444 align:start position:27% line:-2
クラウド上での実行と比べて
４つの利点があります

00:04:37.744 --> 00:04:40.848 align:start position:29% line:-1
第１にプライバシーの尊重

00:04:41.081 --> 00:04:43.584 align:start position:25% line:-2
デバイス上で
機械学習モデルを実行するため

00:04:43.851 --> 00:04:47.154 align:start position:29% line:-2
データがデバイス外に
流出することはありません

00:04:47.988 --> 00:04:50.991 align:start position:30% line:-2
第２にリアルタイムでの
パフォーマンスの実現

00:04:51.992 --> 00:04:56.396 align:start position:27% line:-2
ハードウェアやデバイスは
機械学習に対し超効率的です

00:04:57.064 --> 00:05:00.767 align:start position:30% line:-2
サーバの保守や
支払いも必要ありません

00:04:57.064 --> 00:05:00.767 align:start position:30% line:-2
サーバの保守や
支払いも必要ありません

00:05:01.335 --> 00:05:05.239 align:start position:27% line:-2
Core MLの推論が
いつでも どこでも可能です

00:05:05.506 --> 00:05:07.474 align:start position:36% line:-2
ネット接続環境に
左右されません

00:05:07.975 --> 00:05:09.943 align:start position:27% line:-1
これらのメリットを得るには

00:05:10.043 --> 00:05:13.480 align:start position:27% line:-2
機械学習モデルの
デバイスへの保存が必要です

00:05:14.014 --> 00:05:19.119 align:start position:23% line:-2
モデルのサイズが大きいと
Appのサイズも大きくなります

00:05:19.753 --> 00:05:24.324 align:start position:23% line:-2
例えば機能が充実した
すばらしいAppがあるとします

00:05:24.424 --> 00:05:26.693 align:start position:32% line:-1
ユーザの満足度も高い

00:05:26.860 --> 00:05:30.597 align:start position:32% line:-2
そこで デバイス上の
機械学習を利用し

00:05:30.697 --> 00:05:34.735 align:start position:34% line:-2
すばらしい機能を
加えることにします

00:05:34.902 --> 00:05:39.106 align:start position:20% line:-2
そのために
Core MLモデルに学習させます

00:05:39.773 --> 00:05:44.311 align:start position:32% line:-2
ユーザはさらに満足し
幸せを感じるでしょう

00:05:45.078 --> 00:05:49.616 align:start position:23% line:-2
ただAppのサイズは
増加してしまいます

00:05:49.950 --> 00:05:52.119 align:start position:29% line:-1
機械学習機能の追加により

00:05:52.219 --> 00:05:56.390 align:start position:30% line:-2
数十から数百メガバイト
増えることもあります

00:05:57.524 --> 00:06:00.260 align:start position:29% line:-1
さらに新機能を追加すれば

00:05:57.524 --> 00:06:00.260 align:start position:29% line:-1
さらに新機能を追加すれば

00:06:00.928 --> 00:06:03.697 align:start position:27% line:-1
サイズの増加は止まりません

00:06:04.631 --> 00:06:06.833 align:start position:32% line:-1
できることがあります

00:06:06.934 --> 00:06:11.205 align:start position:27% line:-2
機械学習モデルが
Appの他の機能をサポートするのなら

00:06:11.638 --> 00:06:14.341 align:start position:27% line:-1
それをバンドル外に保てます

00:06:15.275 --> 00:06:21.315 align:start position:23% line:-2
ユーザは必要時にダウンロードし
デバイス上でコンパイルできます

00:06:21.715 --> 00:06:27.120 align:start position:27% line:-2
この場合 サイズ変更はなく
最初は問題ありません

00:06:27.221 --> 00:06:31.358 align:start position:30% line:-2
ただ ダウンロードして
すべての機能を使おうとすると

00:06:32.059 --> 00:06:35.529 align:start position:27% line:-2
最終的にAppの
サイズは増えます

00:06:36.196 --> 00:06:38.866 align:start position:27% line:-1
もしモデル自体のサイズを―

00:06:40.000 --> 00:06:45.005 align:start position:25% line:-2
小さくすれば
問題は解決するのでしょうか？

00:06:46.306 --> 00:06:50.344 align:start position:23% line:-2
App内にそのモデルを含めれば
バンドルが小さくなります

00:06:51.378 --> 00:06:56.483 align:start position:21% line:-2
小さいモデルを含めることで
スムーズなダウンロードが可能です

00:06:57.084 --> 00:07:00.521 align:start position:30% line:-2
Appのメモリ使用量は
少なくなります

00:06:57.084 --> 00:07:00.521 align:start position:30% line:-2
Appのメモリ使用量は
少なくなります

00:07:00.888 --> 00:07:05.759 align:start position:25% line:-2
メモリの節約は 一般的に
Appとシステムに好都合です

00:07:06.894 --> 00:07:12.299 align:start position:25% line:-2
Core MLのサイズ問題に
どう取り組むかを見ましょう

00:07:13.400 --> 00:07:14.801 align:start position:36% line:-1
まずはモデルの数

00:07:14.902 --> 00:07:18.939 align:start position:27% line:-2
これは
機械学習機能の数によります

00:07:19.273 --> 00:07:21.041 align:start position:34% line:-1
そしてウェイトの数

00:07:21.441 --> 00:07:26.146 align:start position:23% line:-2
ウェイトの数は選択した
アーキテクチャにより異なります

00:07:26.513 --> 00:07:28.115 align:start position:32% line:-1
マイケルの言及どおり

00:07:28.882 --> 00:07:32.619 align:start position:25% line:-1
ウェイトとは機械学習モデルが

00:07:32.719 --> 00:07:35.989 align:start position:23% line:-1
習得した情報を記憶する場所です

00:07:36.290 --> 00:07:39.860 align:start position:32% line:-2
複雑なタスクの実行を
習得すれば

00:07:39.960 --> 00:07:44.164 align:start position:32% line:-2
何千万ものウェイトに
なることもあります

00:07:45.532 --> 00:07:47.334 align:start position:30% line:-1
最後はウェイトのサイズ

00:07:47.434 --> 00:07:51.004 align:start position:32% line:-2
習得中のパラメータの
格納方法は？

00:07:51.805 --> 00:07:53.540 align:start position:36% line:-1
ここは注目点です

00:07:54.408 --> 00:07:58.445 align:start position:27% line:-2
ニューラルネットワークには
いくつかの方法があります

00:07:59.746 --> 00:08:02.950 align:start position:18% line:-1
iOS 11のCore MLの場合は

00:07:59.746 --> 00:08:02.950 align:start position:18% line:-1
iOS 11のCore MLの場合は

00:08:03.450 --> 00:08:08.288 align:start position:23% line:-2
浮動小数点数を用い
32ビットで格納されていました

00:08:09.923 --> 00:08:11.625 align:start position:32% line:-1
iOS 11.2では

00:08:11.959 --> 00:08:16.463 align:start position:30% line:-2
フィードバックをもとに
16ビットになりました

00:08:16.697 --> 00:08:22.002 align:start position:25% line:-2
同じ精度で必要なストレージは
半分になりました

00:08:22.202 --> 00:08:25.305 align:start position:25% line:-1
今年 新たに導入を試みたのは

00:08:25.572 --> 00:08:27.841 align:start position:29% line:-1
量子化(quantized)されたウェイトです

00:08:28.542 --> 00:08:33.947 align:start position:18% line:-2
量子化の末に
32や16という制限はなくなりました

00:08:34.114 --> 00:08:38.318 align:start position:27% line:-2
ニューラルネットワークは
８ビットや４ビットも可能で

00:08:38.519 --> 00:08:41.121 align:start position:29% line:-1
１ビットまで下げられます

00:08:42.155 --> 00:08:45.626 align:start position:27% line:-1
それでは量子化を見ましょう

00:08:46.293 --> 00:08:50.330 align:start position:23% line:-2
ニューラルネットワークに
ウェイトのサブセットがあります

00:08:50.531 --> 00:08:55.002 align:start position:29% line:-2
ウェイトは連続した範囲で
任意の値を取ります

00:08:55.536 --> 00:09:00.941 align:start position:27% line:-2
単一のウェイトが
どのような値でも持てるのです

00:08:55.536 --> 00:09:00.941 align:start position:27% line:-2
単一のウェイトが
どのような値でも持てるのです

00:09:01.041 --> 00:09:03.143 align:start position:21% line:-1
実際にニューラルネットワークでは

00:09:03.243 --> 00:09:07.948 align:start position:27% line:-2
32ビットフロートを使って
ウェイトを格納しています

00:09:08.081 --> 00:09:10.784 align:start position:27% line:-1
つまり 連続性を表すために

00:09:10.884 --> 00:09:14.388 align:start position:30% line:-2
ウェイトは
数十億の値を取るのです

00:09:14.555 --> 00:09:19.193 align:start position:23% line:-2
ただしニューラルネットワークは
低精度のウェイトでも作動します

00:09:19.893 --> 00:09:24.264 align:start position:27% line:-2
量子化は一連の値を分断する
プロセスであり

00:09:24.464 --> 00:09:28.702 align:start position:32% line:-2
可能値のサブセットが
小さく離散するよう―

00:09:29.436 --> 00:09:30.904 align:start position:41% line:-1
制御します

00:09:31.171 --> 00:09:35.442 align:start position:32% line:-2
例えばこの量子化は
連続するウェイトを―

00:09:36.310 --> 00:09:39.379 align:start position:21% line:-1
たった256の可能値に変えました

00:09:39.479 --> 00:09:43.183 align:start position:34% line:-2
どんな値でも
取得可能だったのが

00:09:43.283 --> 00:09:47.254 align:start position:30% line:-2
量子化後は
たった256種類です

00:09:47.955 --> 00:09:52.192 align:start position:32% line:-2
このようにウェイトの
軽量化が図れたので

00:09:52.593 --> 00:09:56.029 align:start position:25% line:-2
Core MLに必要な情報は
たった８ビットです

00:09:56.864 --> 00:10:00.200 align:start position:23% line:-1
ここで止まらず さらに進みます

00:09:56.864 --> 00:10:00.200 align:start position:23% line:-1
ここで止まらず さらに進みます

00:10:00.767 --> 00:10:04.104 align:start position:27% line:-2
ネットワークに対し
256のオプションではなく

00:10:04.204 --> 00:10:08.375 align:start position:34% line:-2
８個しか与えない
制御を加えられます

00:10:09.576 --> 00:10:15.148 align:start position:29% line:-2
８個のオプションに対して
各ウェイトが必要なのは―

00:10:15.415 --> 00:10:16.683 align:start position:39% line:-1
３ビットです

00:10:17.551 --> 00:10:22.656 align:start position:27% line:-2
ウェイトを示すための
値の選択方法をお見せします

00:10:22.756 --> 00:10:26.026 align:start position:32% line:-2
値は範囲内で
均一に分布していれば

00:10:26.126 --> 00:10:31.765 align:start position:23% line:-2
直線量子化ですが
ルックアップテーブル量子化では

00:10:33.367 --> 00:10:37.538 align:start position:32% line:-2
任意の方法で
値を分散させられます

00:10:37.738 --> 00:10:42.276 align:start position:30% line:-2
量子化がサイズ縮小に
役立つ様子を見ましょう

00:10:42.376 --> 00:10:45.112 align:start position:21% line:-1
Resnet50に注目しましょう

00:10:45.212 --> 00:10:49.216 align:start position:29% line:-2
様々なタスクに使用される
アーキテクチャです

00:10:50.017 --> 00:10:53.187 align:start position:18% line:-1
2500万のパラメータを含んでいます

00:10:53.620 --> 00:10:57.257 align:start position:34% line:-2
表示に必要なのは
32ビットフロート

00:10:57.925 --> 00:11:00.928 align:start position:27% line:-2
モデルの総サイズは
100メガバイトを超えます

00:10:57.925 --> 00:11:00.928 align:start position:27% line:-2
モデルの総サイズは
100メガバイトを超えます

00:11:02.396 --> 00:11:06.133 align:start position:29% line:-2
８ビットに量子化しても
アーキテクチャは変わらず

00:11:06.233 --> 00:11:09.536 align:start position:29% line:-2
2500万のパラメータは
残りますが

00:11:09.636 --> 00:11:13.974 align:start position:30% line:-2
１ウェイトに必要なのは
１バイトのみです

00:11:14.074 --> 00:11:17.244 align:start position:27% line:-2
モデルのサイズは４分の１に
なりました

00:11:17.344 --> 00:11:20.747 align:start position:29% line:-2
格納に必要なのは
たった26メガバイトです

00:11:20.948 --> 00:11:27.020 align:start position:29% line:-2
さらに進んで各ウェイトに
必要なのは４ビットとなり

00:11:27.354 --> 00:11:29.223 align:start position:32% line:-1
縮小が実現しています

00:11:30.457 --> 00:11:36.430 align:start position:43% line:-1
(拍手)

00:11:36.530 --> 00:11:42.769 align:start position:21% line:-2
Core MLでは量子化モードを
８ビットまでサポートしています

00:11:44.271 --> 00:11:47.941 align:start position:25% line:-2
量子化は
アーキテクチャ縮小のための―

00:11:48.041 --> 00:11:51.211 align:start position:27% line:-1
優れた技術と言えるでしょう

00:11:51.378 --> 00:11:53.313 align:start position:30% line:-1
それを手に入れるには？

00:11:54.781 --> 00:12:01.555 align:start position:16% line:-2
Core MLフォーマットの場合は
量子化にCore ML Toolsを使いますが

00:11:54.781 --> 00:12:01.555 align:start position:16% line:-2
Core MLフォーマットの場合は
量子化にCore ML Toolsを使いますが

00:12:01.655 --> 00:12:04.591 align:start position:20% line:-1
Core ML 2の場合は自動です

00:12:05.492 --> 00:12:08.195 align:start position:25% line:-1
量子化モデルの学習も可能です

00:12:09.263 --> 00:12:12.599 align:start position:25% line:-1
ゼロから量子化して学習ことも

00:12:12.699 --> 00:12:15.802 align:start position:25% line:-1
既存モデルの再学習も可能です

00:12:16.403 --> 00:12:21.909 align:start position:25% line:-2
量子化モデルの取得後に
Core MLに変換します

00:12:22.209 --> 00:12:25.345 align:start position:32% line:-2
Appへの
変更はありません

00:12:25.579 --> 00:12:29.483 align:start position:36% line:-2
モデル内の値は
異なる精度ですが

00:12:29.583 --> 00:12:33.353 align:start position:34% line:-2
インターフェイスは
全く変更されません

00:12:35.522 --> 00:12:38.792 align:start position:29% line:-1
ただし 量子化モデルでは―

00:12:38.992 --> 00:12:43.764 align:start position:27% line:-2
元の浮動小数点モデルに比べて
低精度の近似値となります

00:12:44.231 --> 00:12:49.136 align:start position:25% line:-2
つまり正確性とモデルサイズの
トレードオフがあるのです

00:12:49.703 --> 00:12:53.407 align:start position:27% line:-2
このトレードオフはモデルや
ユースケースに依存します

00:12:53.774 --> 00:12:56.243 align:start position:29% line:-1
研究が活発な分野なので―

00:12:56.443 --> 00:12:59.947 align:start position:34% line:-2
常に量子化モデルの
精度をチェックし

00:13:00.047 --> 00:13:03.684 align:start position:25% line:-1
浮動小数点バージョンと比較し

00:13:04.017 --> 00:13:08.155 align:start position:32% line:-2
適切なデータかどうか
確認すべきでしょう

00:13:08.922 --> 00:13:15.262 align:start position:25% line:-2
では実際に量子化モデルの
使用法をデモで見てみましょう

00:13:15.362 --> 00:13:19.233 align:start position:43% line:-1
(拍手)

00:13:25.205 --> 00:13:27.541 align:start position:32% line:-2
スタイル変換の
Appです

00:13:28.075 --> 00:13:33.447 align:start position:27% line:-2
ニューラルネットワークは
学習済みのスタイルを用いて

00:13:33.547 --> 00:13:36.416 align:start position:27% line:-2
ユーザ画像のレンダリングを
学習します

00:13:36.650 --> 00:13:38.051 align:start position:29% line:-1
私のAppです

00:13:39.219 --> 00:13:42.589 align:start position:29% line:-1
４つのスタイルを使います

00:13:42.689 --> 00:13:45.559 align:start position:29% line:-1
シティ ガラス 油絵 波

00:13:45.659 --> 00:13:49.797 align:start position:32% line:-2
そしてライブラリから
画像を選びます

00:13:49.897 --> 00:13:53.700 align:start position:34% line:-2
そしてデバイス上で
スタイルを変えます

00:13:53.934 --> 00:13:58.172 align:start position:32% line:-2
この元画像を
シティスタイルで描写

00:13:59.940 --> 00:14:00.807 align:start position:45% line:-1
ガラス

00:13:59.940 --> 00:14:00.807 align:start position:45% line:-1
ガラス

00:14:02.309 --> 00:14:03.210 align:start position:46% line:-1
油絵

00:14:04.845 --> 00:14:05.946 align:start position:43% line:-1
そして波

00:14:07.414 --> 00:14:09.917 align:start position:27% line:-1
Xcodeを見てみましょう

00:14:10.984 --> 00:14:15.722 align:start position:16% line:-2
Core MLとVision APIを
使用しています

00:14:16.190 --> 00:14:20.260 align:start position:12% line:-2
Xcodeには４つのCore MLモデルが
バンドルされています

00:14:20.360 --> 00:14:23.864 align:start position:25% line:-2
先ほどの
シティ ガラス 油絵 波です

00:14:24.464 --> 00:14:26.667 align:start position:30% line:-1
ここで確認ができますが

00:14:26.767 --> 00:14:32.306 align:start position:25% line:-2
これらは量子化モデルのため
それぞれ6.7メガバイトです

00:14:33.040 --> 00:14:36.343 align:start position:34% line:-2
ある解像度の
入力画像を取り込み

00:14:36.577 --> 00:14:40.047 align:start position:25% line:-2
同じ解像度の図案化した画像を
生成するのです

00:14:40.981 --> 00:14:42.850 align:start position:34% line:-1
ここで調べたいのは

00:14:42.950 --> 00:14:48.489 align:start position:23% line:-2
量子化への切り替えで節約できた
ストレージとメモリスペースです

00:14:48.589 --> 00:14:51.425 align:start position:14% line:-1
Core ML Toolsを使いましょう

00:14:51.525 --> 00:14:55.729 align:start position:29% line:-2
これらのモデルの
量子化表現を取得しました

00:14:56.196 --> 00:14:58.899 align:start position:34% line:-2
モデル入手のための
チュートリアルは

00:14:58.999 --> 00:15:03.637 align:start position:16% line:-2
パート２でCore ML Toolsの
詳細を説明します

00:14:58.999 --> 00:15:03.637 align:start position:16% line:-2
パート２でCore ML Toolsの
詳細を説明します

00:15:04.071 --> 00:15:06.807 align:start position:27% line:-1
ガラススタイルを見ましょう

00:15:06.907 --> 00:15:11.211 align:start position:34% line:-2
量子化バージョンの
違いをご覧ください

00:15:11.778 --> 00:15:16.083 align:start position:20% line:-2
新しいモデルを
Xcode内にドラッグするだけです

00:15:17.951 --> 00:15:21.188 align:start position:29% line:-2
そしてAppを
再実行します

00:15:22.489 --> 00:15:25.792 align:start position:21% line:-1
サイズが大幅に縮小されていますね

00:15:25.893 --> 00:15:31.965 align:start position:21% line:-2
８ビット版は６～７メガバイトから
1.7にダウンしています

00:15:33.000 --> 00:15:36.937 align:start position:43% line:-1
(拍手)

00:15:37.037 --> 00:15:41.675 align:start position:25% line:-2
さらに４ビット版は
１メガバイト未満になりました

00:15:41.909 --> 00:15:46.246 align:start position:23% line:-2
３ビット版は49キロバイトしか
ありません

00:15:47.114 --> 00:15:49.149 align:start position:27% line:-1
Appに戻って―

00:15:51.151 --> 00:15:56.590 align:start position:27% line:-2
元のバージョンに
ガラスを適用してみましょう

00:15:57.257 --> 00:16:02.062 align:start position:27% line:-2
同じに見えますが
ここで８ビット版と比べても

00:15:57.257 --> 00:16:02.062 align:start position:27% line:-2
同じに見えますが
ここで８ビット版と比べても

00:16:04.364 --> 00:16:06.567 align:start position:34% line:-1
変わりはありません

00:16:06.800 --> 00:16:09.903 align:start position:23% line:-1
量子化メソッドが安定しています

00:16:10.804 --> 00:16:15.676 align:start position:29% line:-2
さらに挑戦して
４ビット版を試しましょう

00:16:16.944 --> 00:16:18.979 align:start position:36% line:-1
すばらしいですね

00:16:20.180 --> 00:16:22.182 align:start position:34% line:-1
３ビット版を試すと

00:16:24.852 --> 00:16:27.588 align:start position:29% line:-1
ここで色が変わりましたね

00:16:27.688 --> 00:16:32.926 align:start position:30% line:-2
許容範囲はデザイナーと
確認するべきでしょう

00:16:33.260 --> 00:16:37.865 align:start position:29% line:-2
２ビット版になると
期待どおりにはいきません

00:16:37.965 --> 00:16:41.735 align:start position:29% line:-2
ホラー系に取っておき
デザイナーには見せません

00:16:41.835 --> 00:16:46.406 align:start position:43% line:-1
(拍手)

00:16:46.507 --> 00:16:48.942 align:start position:29% line:-1
４ビット版に戻りましょう

00:16:49.143 --> 00:16:54.748 align:start position:25% line:-2
量子化モデルは元の近似値だと
思い出してください

00:16:55.148 --> 00:16:58.986 align:start position:25% line:-2
常に元のバージョンとの比較を
お勧めします

00:16:59.086 --> 00:17:04.691 align:start position:27% line:-2
モデルと量子化技術において
ミスマッチがあるはずです

00:16:59.086 --> 00:17:04.691 align:start position:27% line:-2
モデルと量子化技術において
ミスマッチがあるはずです

00:17:06.492 --> 00:17:10.597 align:start position:29% line:-2
デザイナーとの議論を経て
画像を評価し

00:17:10.695 --> 00:17:15.903 align:start position:27% line:-2
最小サイズで最良の
４ビットサイズに決めました

00:17:16.970 --> 00:17:22.675 align:start position:27% line:-2
他の浮動小数点バージョンを
削除してしまいましょう

00:17:23.477 --> 00:17:26.380 align:start position:29% line:-1
そして４ビットに変えます

00:17:31.018 --> 00:17:33.420 align:start position:25% line:-1
最後にAppを実行

00:17:40.527 --> 00:17:42.529 align:start position:34% line:-1
同じ画像を選びます

00:17:45.165 --> 00:17:46.733 align:start position:32% line:-1
スタイルを変更します

00:17:48.702 --> 00:17:50.037 align:start position:39% line:-1
これがシティ

00:17:50.871 --> 00:17:51.705 align:start position:45% line:-1
ガラス

00:17:53.807 --> 00:17:54.775 align:start position:46% line:-1
油絵

00:17:56.376 --> 00:17:57.478 align:start position:43% line:-1
そして波

00:18:00.214 --> 00:18:03.684 align:start position:27% line:-2
このデモでは４つのモデルが
ありました

00:18:04.051 --> 00:18:09.156 align:start position:21% line:-2
巨大な32ビット版では
Appは27メガバイト

00:18:09.389 --> 00:18:12.893 align:start position:29% line:-1
４ビットに切り替えました

00:18:12.993 --> 00:18:16.897 align:start position:20% line:-1
サイズは3.4メガバイトにまで縮小

00:18:17.598 --> 00:18:18.365 align:start position:43% line:-1
そして…

00:18:18.465 --> 00:18:23.003 align:start position:43% line:-1
(拍手)

00:18:23.103 --> 00:18:26.039 align:start position:36% line:-2
犠牲を払わず
品質を保ちました

00:18:26.173 --> 00:18:32.412 align:start position:27% line:-2
すべての量子化バージョンは
すばらしいクオリティです

00:18:34.481 --> 00:18:37.818 align:start position:30% line:-2
量子化は細かなレベルで
ウェイトや―

00:18:37.918 --> 00:18:41.421 align:start position:30% line:-2
Appの
サイズ縮小に役立ちます

00:18:42.189 --> 00:18:46.493 align:start position:25% line:-2
次はAppが必要な
モデル数を減らす方法です

00:18:47.794 --> 00:18:49.797 align:start position:32% line:-1
最も単純なケースでは

00:18:50.097 --> 00:18:55.936 align:start position:23% line:-2
３つの機械学習機能には
３つの機械学習モデルが必要です

00:18:56.136 --> 00:19:01.308 align:start position:23% line:-2
しかし場合により
異なる機能を

00:18:56.136 --> 00:19:01.308 align:start position:23% line:-2
しかし場合により
異なる機能を

00:19:01.408 --> 00:19:03.977 align:start position:30% line:-1
1つのモデルでサポートすることも可能です

00:19:04.344 --> 00:19:07.347 align:start position:32% line:-2
マルチタスクのモデルに
学習させて

00:19:07.614 --> 00:19:12.052 align:start position:29% line:-2
同時にマルチタスクを
実行させることも可能です

00:19:12.419 --> 00:19:16.690 align:start position:12% line:-2
これはTuri Createのセッションで
用いたサンプルです

00:19:16.924 --> 00:19:21.061 align:start position:20% line:-2
場合によりCore MLの新機能も
使用可能です

00:19:21.161 --> 00:19:23.497 align:start position:23% line:-1
“柔軟なシェイプとサイズ”です

00:19:24.364 --> 00:19:28.068 align:start position:21% line:-1
スタイル変換のデモに戻りましょう

00:19:28.168 --> 00:19:32.739 align:start position:29% line:-2
Xcodeでは入力画像と
出力画像のサイズが

00:19:32.839 --> 00:19:36.376 align:start position:32% line:-2
モデルの定義の一部で
コード化されています

00:19:36.810 --> 00:19:40.614 align:start position:23% line:-2
異なる解像度で
同じスタイルを実行したければ？

00:19:41.014 --> 00:19:45.719 align:start position:23% line:-2
同じネットワークを
異なるサイズで実行したい時は？

00:19:46.787 --> 00:19:51.592 align:start position:29% line:-2
例えばユーザは 高画質の
スタイル変換を望んで

00:19:51.792 --> 00:19:55.362 align:start position:25% line:-1
高解像度の画像を使うでしょう

00:19:55.662 --> 00:19:59.633 align:start position:27% line:-2
低解像度の画像しか
入力として指定できない場合

00:20:00.000 --> 00:20:04.705 align:start position:23% line:-2
デベロッパとしては
解像度を落として取り込んだ後―

00:20:04.805 --> 00:20:07.474 align:start position:32% line:-2
再び解像度を
上げるしかありません

00:20:07.741 --> 00:20:10.611 align:start position:27% line:-1
ユーザは感心しないでしょう

00:20:11.778 --> 00:20:13.180 align:start position:36% line:-1
従来のモデルでも

00:20:14.014 --> 00:20:19.052 align:start position:21% line:-2
Core ML Toolsを使い
高解像度の画像を

00:20:19.486 --> 00:20:22.222 align:start position:29% line:-1
取り込むことができました

00:20:23.290 --> 00:20:25.993 align:start position:29% line:-2
つまり今までも
Core MLモデルに―

00:20:26.093 --> 00:20:32.065 align:start position:25% line:-2
高解像度の画像を直接取り込み
処理できていたのです

00:20:33.534 --> 00:20:39.606 align:start position:29% line:-2
ユーザは最終的な画像に
多くの処理を追加するため

00:20:40.107 --> 00:20:44.912 align:start position:29% line:-2
ズームインした際の画像は
繊細にしたかったのです

00:20:46.513 --> 00:20:48.715 align:start position:36% line:-1
ただし今までは―

00:20:48.816 --> 00:20:52.953 align:start position:23% line:-2
２つの異なるモデルを作ることで
それを可能にしていました

00:20:53.053 --> 00:20:56.256 align:start position:38% line:-2
通常解像度版と
高解像度版です

00:20:56.557 --> 00:21:00.327 align:start position:23% line:-2
ネットワークですべての解像度を
サポートすると

00:20:56.557 --> 00:21:00.327 align:start position:23% line:-2
ネットワークですべての解像度を
サポートすると

00:21:00.427 --> 00:21:04.064 align:start position:27% line:-2
Appのサイズは
２倍になります

00:21:04.498 --> 00:21:07.701 align:start position:32% line:-2
今は柔軟なシェイプを
実現しています

00:21:07.801 --> 00:21:10.137 align:start position:29% line:-1
そのシェイプを使うことで

00:21:10.237 --> 00:21:14.675 align:start position:30% line:-2
多くの解像度に対応する
単一モデルができました

00:21:15.676 --> 00:21:16.543 align:start position:36% line:-1
Xcodeでは…

00:21:16.643 --> 00:21:21.248 align:start position:43% line:-1
(拍手)

00:21:21.348 --> 00:21:26.787 align:start position:32% line:-2
入力に画像ファイルが
指定されていますが

00:21:27.187 --> 00:21:31.925 align:start position:27% line:-2
解像度のサイズを
柔軟に切り替えられるのです

00:21:32.025 --> 00:21:35.662 align:start position:32% line:-2
この単純なサンプルに
SDとHDがあります

00:21:36.296 --> 00:21:39.099 align:start position:25% line:-1
モデルは１つだけでいいのです

00:21:40.400 --> 00:21:42.636 align:start position:29% line:-1
冗長なコードは要りません

00:21:43.303 --> 00:21:47.741 align:start position:30% line:-2
SDとHDの切り替えが
高速で実行できます

00:21:47.841 --> 00:21:51.345 align:start position:34% line:-2
モデルのリロードが
必要ないためです

00:21:52.546 --> 00:21:56.016 align:start position:36% line:-2
柔軟性の指定には
オプションが２つ

00:21:57.050 --> 00:21:59.453 align:start position:32% line:-1
次元の範囲を定義し―

00:21:59.553 --> 00:22:03.390 align:start position:34% line:-2
最小および最大の
幅と高さを決めます

00:21:59.553 --> 00:22:03.390 align:start position:34% line:-2
最小および最大の
幅と高さを決めます

00:22:03.624 --> 00:22:06.427 align:start position:27% line:-1
そして任意の値を選択します

00:22:07.127 --> 00:22:11.632 align:start position:30% line:-2
すべてのシェイプを
列挙することも可能です

00:22:11.732 --> 00:22:17.471 align:start position:25% line:-2
例えばすべてのアスペクト比と
解像度が違うとします

00:22:17.571 --> 00:22:20.440 align:start position:18% line:-1
Core MLはそれを予測しています

00:22:20.541 --> 00:22:24.511 align:start position:29% line:-2
多くの最適化を
実行する機会があるのです

00:22:24.978 --> 00:22:28.048 align:start position:21% line:-1
Appも小さくなります

00:22:29.249 --> 00:22:30.851 align:start position:34% line:-1
柔軟性があるのは？

00:22:30.951 --> 00:22:34.788 align:start position:32% line:-2
複数の解像度を
サポートできるのは？

00:22:36.256 --> 00:22:38.292 align:start position:29% line:-2
畳み込みの
ニューラルネットワークは

00:22:38.392 --> 00:22:42.563 align:start position:32% line:-2
MS転送に使用される
処理タスクであり

00:22:42.763 --> 00:22:45.899 align:start position:25% line:-1
画像補正や超解像を処理します

00:22:45.999 --> 00:22:48.035 align:start position:23% line:-1
アーキテクチャの処理も可能です

00:22:48.435 --> 00:22:53.140 align:start position:25% line:-2
Core ML Toolsが
モデルの機能をチェックします

00:22:54.174 --> 00:22:57.744 align:start position:29% line:-2
Core MLユーザは
柔軟なサイズ対応が可能で

00:22:57.844 --> 00:23:00.547 align:start position:34% line:-2
ウェイトのサイズは
量子化で縮小可能

00:22:57.844 --> 00:23:00.547 align:start position:34% line:-2
ウェイトのサイズは
量子化で縮小可能

00:23:00.647 --> 00:23:02.549 align:start position:30% line:-1
しかしウェイトの数は？

00:23:03.217 --> 00:23:08.889 align:start position:21% line:-2
Core MLは
様々なアーキテクチャをサポートし

00:23:08.989 --> 00:23:14.495 align:start position:21% line:-2
機械学習に適したサイズのモデルを
選択します

00:23:14.595 --> 00:23:18.298 align:start position:21% line:-1
Core MLはAppのサイズを

00:23:18.398 --> 00:23:21.368 align:start position:34% line:-2
これら３要素を使い
最適化します

00:23:21.468 --> 00:23:24.571 align:start position:27% line:-1
いつでも推論は超高性能です

00:23:24.738 --> 00:23:27.975 align:start position:29% line:-2
パフォーマンスと
カスタマイズの新機能は―

00:23:28.075 --> 00:23:29.710 align:start position:36% line:-1
ビルが説明します

00:23:29.810 --> 00:23:30.377 align:start position:41% line:-1
ありがとう

00:23:30.477 --> 00:23:36.283 align:start position:43% line:-1
(拍手)

00:23:37.985 --> 00:23:38.719 align:start position:32% line:-1
ありがとうございます

00:23:39.786 --> 00:23:43.123 align:start position:29% line:-2
Core MLの基本的な
設計原則の１つは

00:23:43.223 --> 00:23:46.727 align:start position:21% line:-2
Appに
最高のパフォーマンスを与えること

00:23:46.827 --> 00:23:53.934 align:start position:20% line:-2
そのゴールに沿ったCore MLの
新たな機能をご紹介します

00:23:54.902 --> 00:23:58.205 align:start position:23% line:-2
先ほどフランチェスコが
使ったサンプルを見てみましょう

00:23:58.305 --> 00:24:04.077 align:start position:23% line:-2
App上では 入力された画像を
図案化します

00:23:58.305 --> 00:24:04.077 align:start position:23% line:-2
App上では 入力された画像を
図案化します

00:24:04.344 --> 00:24:07.314 align:start position:29% line:-2
それを可能にする
重要な要素が２つあります

00:24:07.414 --> 00:24:13.253 align:start position:21% line:-2
スタイル適用のためのパラメータを
格納するMLモデルファイル

00:24:13.520 --> 00:24:17.157 align:start position:27% line:-2
そしてMLモデルに取り込む
推論エンジンです

00:24:17.257 --> 00:24:21.228 align:start position:30% line:-2
それは出力の生成に
必要な計算を実行します

00:24:21.895 --> 00:24:25.966 align:start position:21% line:-2
スタイル変換を効率的に行うために
Appleの技術が―

00:24:26.066 --> 00:24:28.702 align:start position:32% line:-2
どのように
活用されているのか？

00:24:30.137 --> 00:24:36.210 align:start position:23% line:-2
ニューラルネットワークの例で
レイヤと呼ばれる数学的演算です

00:24:36.376 --> 00:24:41.882 align:start position:30% line:-2
各レイヤが画像を変換し
図案化して出力します

00:24:42.583 --> 00:24:48.789 align:start position:21% line:-2
モデルには変換やスタイルを決める
各レイヤのウェイトが格納されます

00:24:49.623 --> 00:24:55.095 align:start position:21% line:-2
Core MLの推論エンジンでは
各レイヤを高度に最適化

00:24:55.195 --> 00:24:57.331 align:start position:20% line:-1
GPUではMetalシェーダを使い

00:24:57.431 --> 00:25:01.201 align:start position:23% line:-2
CPU上では有能な計算ができる
Accelerateを使います

00:24:57.431 --> 00:25:01.201 align:start position:23% line:-2
CPU上では有能な計算ができる
Accelerateを使います

00:25:01.301 --> 00:25:05.806 align:start position:21% line:-2
モデル デバイスの状態などを考え
異なる計算を―

00:25:05.906 --> 00:25:09.510 align:start position:25% line:-1
異なるハードウェアに送ります

00:25:11.178 --> 00:25:14.281 align:start position:30% line:-2
さらにネットワーク内の
レイヤを融合し

00:25:14.381 --> 00:25:17.451 align:start position:27% line:-1
必要な計算を少なく抑えます

00:25:18.786 --> 00:25:22.089 align:start position:21% line:-1
状況を理解して最適化をするのです

00:25:22.189 --> 00:25:26.693 align:start position:16% line:-2
モデルの詳細は
MLModelのファイルに入っています

00:25:27.060 --> 00:25:31.432 align:start position:23% line:-2
推論エンジンとデバイスの詳細も
分かっています

00:25:32.299 --> 00:25:35.302 align:start position:27% line:-1
我々が必ず最適化をするので

00:25:35.402 --> 00:25:38.972 align:start position:32% line:-2
皆さんはユーザだけに
集中してください

00:25:40.340 --> 00:25:42.376 align:start position:29% line:-1
作業負荷はどうでしょう？

00:25:42.476 --> 00:25:46.513 align:start position:30% line:-2
複数の予測を
行う必要がある場合は？

00:25:47.214 --> 00:25:50.851 align:start position:23% line:-2
情報がないと
Core MLは最適化しません

00:25:51.452 --> 00:25:57.157 align:start position:27% line:-2
同じ作業量をこなすには
次のようなことが必要でした

00:25:57.257 --> 00:26:01.662 align:start position:21% line:-2
既存のCore ML予測APIに
“for”でループを配置

00:25:57.257 --> 00:26:01.662 align:start position:21% line:-2
既存のCore ML予測APIに
“for”でループを配置

00:26:01.762 --> 00:26:05.432 align:start position:30% line:-2
そして入力をループして
出力を生成します

00:26:06.900 --> 00:26:11.572 align:start position:29% line:-2
裏側で何が起こっているか
詳しく見てみましょう

00:26:12.172 --> 00:26:15.576 align:start position:25% line:-1
まず各画像の前処理が必要です

00:26:15.676 --> 00:26:18.645 align:start position:30% line:-2
GPUへのデータ送信も
もちろん必須です

00:26:19.046 --> 00:26:22.916 align:start position:32% line:-2
その後 計算し
出力画像を生成します

00:26:23.016 --> 00:26:28.689 align:start position:20% line:-2
そしてGPUからデータを取り出して
Appに返す後処理があります

00:26:29.823 --> 00:26:34.728 align:start position:21% line:-2
この画像の改善の鍵は
GPUパイプラインのバブルの除去

00:26:35.863 --> 00:26:38.932 align:start position:29% line:-2
パフォーマンス向上に
つながる理由は 主に２つ

00:26:39.032 --> 00:26:43.937 align:start position:23% line:-2
まずGPUの待機時間がなくなり
全体の計算時間が短縮

00:26:44.037 --> 00:26:47.574 align:start position:21% line:-1
次にGPUは継続して作動するため

00:26:47.674 --> 00:26:50.277 align:start position:29% line:-1
高いパフォーマンスを見せ

00:26:50.377 --> 00:26:54.681 align:start position:27% line:-2
各出力を
計算する時間を短縮できます

00:26:55.616 --> 00:26:59.987 align:start position:20% line:-2
しかしCore MLにはこのような
心配は要りません

00:27:00.087 --> 00:27:03.724 align:start position:23% line:-1
実際 皆さんが必要としているのは

00:27:03.924 --> 00:27:07.261 align:start position:27% line:-1
処理時間を短くすることです

00:27:07.795 --> 00:27:13.400 align:start position:29% line:-2
解決のため 今年は新たに
バッチAPIを紹介します

00:27:14.101 --> 00:27:19.540 align:start position:25% line:-2
以前は入力をループし別々に
予測したのが 新APIでは―

00:27:20.440 --> 00:27:24.812 align:start position:32% line:-2
１行の予測で
入力の配列を消費し―

00:27:24.912 --> 00:27:26.813 align:start position:36% line:-1
出力の配列を生成

00:27:26.914 --> 00:27:28.515 align:start position:21% line:-1
残りはCore MLが処理します

00:27:28.615 --> 00:27:34.288 align:start position:43% line:-1
(拍手)

00:27:34.788 --> 00:27:39.593 align:start position:20% line:-2
では 先ほどのスタイル変換Appを
例に見てみましょう

00:27:39.693 --> 00:27:43.831 align:start position:30% line:-2
ライブラリ内の全画像に
画質を適用するため―

00:27:43.931 --> 00:27:46.633 align:start position:30% line:-2
それだけに特化した
単純なAppを使います

00:27:46.733 --> 00:27:49.203 align:start position:27% line:-1
200枚の画像に適用します

00:27:49.303 --> 00:27:51.839 align:start position:34% line:-1
左側を見てください

00:27:51.939 --> 00:27:55.843 align:start position:25% line:-2
ループのため
昨年のAPIを実装しています

00:27:55.943 --> 00:27:58.445 align:start position:25% line:-1
右側が新しいバッチAPIです

00:27:58.545 --> 00:28:01.415 align:start position:29% line:-1
早速 動かしてみましょう

00:27:58.545 --> 00:28:01.415 align:start position:29% line:-1
早速 動かしてみましょう

00:28:03.817 --> 00:28:05.652 align:start position:34% line:-1
右側は既に処理完了

00:28:05.752 --> 00:28:09.356 align:start position:34% line:-2
左側はまだ処理中…
やっと完了です

00:28:09.456 --> 00:28:15.162 align:start position:43% line:-1
(拍手)

00:28:15.262 --> 00:28:18.999 align:start position:29% line:-2
新しいAPIには
明らかな改善が見られます

00:28:19.399 --> 00:28:24.872 align:start position:21% line:-2
その改善はモデルやデバイスなどに
左右されるでしょうが

00:28:24.972 --> 00:28:27.274 align:start position:32% line:-1
予測が大量にある場合

00:28:27.374 --> 00:28:32.179 align:start position:20% line:-2
新しいAPIを使用し
Core MLに計算させてください

00:28:35.682 --> 00:28:39.620 align:start position:32% line:-2
ユーザに役立つ機能が
ない場合は―

00:28:39.720 --> 00:28:42.756 align:start position:27% line:-1
世界一高性能でも無意味です

00:28:43.624 --> 00:28:46.460 align:start position:29% line:-1
その役立つ機能が何であれ

00:28:46.560 --> 00:28:51.832 align:start position:29% line:-2
Core MLを高性能で
簡単なものにしたいです

00:28:52.466 --> 00:28:56.437 align:start position:32% line:-2
機械学習の分野は
急速に拡大しています

00:28:56.737 --> 00:28:58.071 align:start position:39% line:-1
その速さは？

00:28:58.172 --> 00:29:01.241 align:start position:30% line:-1
少し私の話をしましょう

00:28:58.172 --> 00:29:01.241 align:start position:30% line:-1
少し私の話をしましょう

00:29:02.843 --> 00:29:07.114 align:start position:32% line:-2
機械学習で解答可能な
単純な質問です

00:29:07.648 --> 00:29:12.152 align:start position:30% line:-2
私が知りたいのは
ここに馬がいるかどうか

00:29:12.586 --> 00:29:16.690 align:start position:34% line:-2
笑いが聞こえるほど
愚かな質問ですね

00:29:16.790 --> 00:29:19.760 align:start position:27% line:-1
小さな子供は大好きでしょう

00:29:20.094 --> 00:29:22.362 align:start position:34% line:-1
過去に戻りましょう

00:29:22.463 --> 00:29:27.401 align:start position:29% line:-2
私が大学院に行き始めた時
考えた問題です

00:29:27.501 --> 00:29:29.903 align:start position:34% line:-1
私の洞察はと言うと

00:29:30.871 --> 00:29:32.906 align:start position:32% line:-1
“どうかな　難解だ”

00:29:33.240 --> 00:29:35.275 align:start position:32% line:-1
“よく分からないよ”

00:29:35.876 --> 00:29:40.247 align:start position:32% line:-2
それから私も年を取り
少し賢くなりました

00:29:40.347 --> 00:29:42.983 align:start position:30% line:-1
この分野の変化は著しい

00:29:43.083 --> 00:29:47.020 align:start position:25% line:-2
ニューラルネットワークにより
新しい結果も出ています

00:29:47.721 --> 00:29:49.656 align:start position:32% line:-1
私は見解を変えました

00:29:49.756 --> 00:29:53.293 align:start position:25% line:-1
最先端の研究では答えが出ます

00:29:53.393 --> 00:29:56.730 align:start position:29% line:-2
コンピュータが
馬の認識技術を持つのです

00:29:56.830 --> 00:29:58.098 align:start position:36% line:-1
ワクワクしますね

00:29:58.198 --> 00:29:59.733 align:start position:41% line:-1
(笑い声)

00:30:00.334 --> 00:30:02.369 align:start position:36% line:-1
さらに時が過ぎて

00:30:02.469 --> 00:30:06.073 align:start position:30% line:-2
Appleに勤務し
再び見解が変化しました

00:30:06.440 --> 00:30:09.543 align:start position:25% line:-2
今であれば
Create MLを使います

00:30:09.643 --> 00:30:12.813 align:start position:23% line:-2
UIは最高で すぐに馬の種類も
判別できるでしょう

00:30:13.313 --> 00:30:15.883 align:start position:29% line:-1
機械学習の専門家であれば

00:30:15.983 --> 00:30:19.052 align:start position:29% line:-2
“何を言ってるんだ？”と
思うでしょう

00:30:19.153 --> 00:30:21.288 align:start position:32% line:-2
“2007年の時点で
この問題を解けたし”

00:30:21.388 --> 00:30:24.158 align:start position:27% line:-2
“2012年には
100回は判別できた”とね

00:30:24.491 --> 00:30:25.626 align:start position:38% line:-1
それはさておき

00:30:25.726 --> 00:30:31.565 align:start position:21% line:-2
長持ちする高品質のソフトウェアを
望むなら 緊張するでしょう

00:30:31.665 --> 00:30:35.536 align:start position:32% line:-2
11年後 この問題の
全体像が変わりました

00:30:36.203 --> 00:30:40.607 align:start position:25% line:-2
安心のためにCore MLの
機能を見てみましょう

00:30:41.575 --> 00:30:46.513 align:start position:27% line:-2
再び 写真に馬がいるか探す
モデルを例にとります

00:30:46.613 --> 00:30:49.249 align:start position:21% line:-1
これはニューラルネットワークです

00:30:49.716 --> 00:30:54.621 align:start position:21% line:-2
前述のとおり 高度に最適化された
レイヤから成ります

00:30:54.721 --> 00:31:00.160 align:start position:27% line:-2
推論エンジンで 各レイヤが
高度に最適化されています

00:30:54.721 --> 00:31:00.160 align:start position:27% line:-2
推論エンジンで 各レイヤが
高度に最適化されています

00:31:00.894 --> 00:31:04.298 align:start position:32% line:-2
我々は多くの対象をサポートし
増やし続け

00:31:04.398 --> 00:31:06.934 align:start position:30% line:-1
新たな開発を続けています

00:31:07.734 --> 00:31:11.071 align:start position:32% line:-2
しかしCore MLのサポート対象ではない
レイヤが必要となったら？

00:31:12.272 --> 00:31:16.910 align:start position:25% line:-2
過去の選択肢は
“待つ”か“別モデル”でした

00:31:17.444 --> 00:31:20.981 align:start position:27% line:-2
でもこれが馬の発見に重要な
レイヤだったら？

00:31:21.115 --> 00:31:23.851 align:start position:30% line:-1
これは画期的な機能です

00:31:23.951 --> 00:31:25.219 align:start position:39% line:-1
待てますか？

00:31:26.820 --> 00:31:29.857 align:start position:34% line:-2
これは大きな
問題かもしれません

00:31:31.191 --> 00:31:34.928 align:start position:23% line:-2
そこでニューラルネットワークの
カスタムレイヤを導入

00:31:35.095 --> 00:31:37.865 align:start position:25% line:-1
これで レイヤが欠けていても

00:31:37.965 --> 00:31:43.637 align:start position:25% line:-2
Core MLモデルの残りと
組み合わせて実装できます

00:31:44.004 --> 00:31:47.941 align:start position:27% line:-2
モデル内にカスタムレイヤを
その実装クラスの名前で格納

00:31:48.041 --> 00:31:50.510 align:start position:11% line:-1
AAPLCustomHorseLayerです

00:31:51.111 --> 00:31:55.649 align:start position:27% line:-2
あなたが実装したクラスは
推論エンジンの欠けている役割を担い

00:31:55.883 --> 00:31:57.851 align:start position:32% line:-1
他のレイヤと同様に

00:31:57.951 --> 00:32:03.357 align:start position:27% line:-2
カスタムレイヤはすべてのインスタンスに
対応する必要があります

00:31:57.951 --> 00:32:03.357 align:start position:27% line:-2
カスタムレイヤはすべてのインスタンスに
対応する必要があります

00:32:04.758 --> 00:32:07.561 align:start position:27% line:-2
実行時にAppに
含まれている必要があります

00:32:07.661 --> 00:32:11.999 align:start position:21% line:-2
そして特定のレイヤのパラメータは
残りの情報と一緒に

00:32:12.099 --> 00:32:14.434 align:start position:20% line:-1
MLModelにカプセル化されます

00:32:15.969 --> 00:32:17.838 align:start position:25% line:-1
カスタムレイヤの実装は単純で

00:32:18.138 --> 00:32:20.440 align:start position:18% line:-1
MLCustomLayerプロトコルを使うだけ

00:32:20.541 --> 00:32:25.312 align:start position:16% line:-2
MLModelのデータに基づきレイヤの
初期化メソッドを実装します

00:32:26.079 --> 00:32:30.584 align:start position:27% line:-2
レイヤの出力用スペースの
大きさを返すメソッドも必要です

00:32:31.151 --> 00:32:33.220 align:start position:38% line:-1
その計算方法のメソッドも

00:32:35.222 --> 00:32:40.327 align:start position:29% line:-2
パフォーマンスは同じまま
柔軟性を追加できます

00:32:40.994 --> 00:32:43.230 align:start position:27% line:-2
プロトコルにはオプションも
用意されています

00:32:43.330 --> 00:32:46.300 align:start position:25% line:-2
モデルで使う
Metalシェーダの実装です

00:32:46.400 --> 00:32:47.901 align:start position:34% line:-1
“レイヤ”です

00:32:48.335 --> 00:32:53.707 align:start position:20% line:-2
これでCore MLの残りの部分と
同じコマンドでコード化できます

00:32:53.807 --> 00:32:58.178 align:start position:20% line:-2
エンコーディングやGPUとの連携に
関わるオーバーヘッドもありません

00:32:58.545 --> 00:33:03.450 align:start position:30% line:-2
Metalシェーダを提供しないと
すべての演算はCPUで行われます

00:32:58.545 --> 00:33:03.450 align:start position:30% line:-2
Metalシェーダを提供しないと
すべての演算はCPUで行われます

00:33:04.952 --> 00:33:10.057 align:start position:18% line:-2
ニューラルネットワークモデルと
同じようにCore MLも進歩します

00:33:10.557 --> 00:33:11.825 align:start position:32% line:-1
しかし限界はあります

00:33:12.860 --> 00:33:18.599 align:start position:12% line:-2
カスタムレイヤはMLMultiArrayの
入力と出力のみを取ります

00:33:19.032 --> 00:33:21.568 align:start position:27% line:-2
ニューラルネットワークとの
自然な関係ですが

00:33:21.668 --> 00:33:25.572 align:start position:23% line:-2
機械学習分野の進歩は
この分野だけに とどまりません

00:33:26.640 --> 00:33:32.579 align:start position:23% line:-2
かつてニューラルネットワークは
画像認識の解決策じゃなかった

00:33:33.046 --> 00:33:35.549 align:start position:29% line:-1
しかし今や最先端技術です

00:33:37.284 --> 00:33:42.823 align:start position:25% line:-2
カスタムレイヤが適合しない
機械学習Appもあるでしょう

00:33:43.023 --> 00:33:48.729 align:start position:27% line:-2
機械学習Appは類似空間に
画像を埋め込むことが可能で

00:33:48.829 --> 00:33:55.235 align:start position:27% line:-2
最近傍メソッドや局所性鋭敏型ハッシュなどを使えば
似た画像の検索も可能です

00:33:56.870 --> 00:34:03.010 align:start position:25% line:-2
モデルで 音声と動作データを
組み合わせることも可能です

00:33:56.870 --> 00:34:03.010 align:start position:25% line:-2
モデルで 音声と動作データを
組み合わせることも可能です

00:34:04.912 --> 00:34:10.650 align:start position:23% line:-2
全く新しいモデルタイプを使った
斬新な体験も提供できます

00:34:11.051 --> 00:34:15.489 align:start position:18% line:-2
Core MLのシンプルさと可搬性が
望まれます

00:34:15.589 --> 00:34:19.592 align:start position:34% line:-2
柔軟性も犠牲にする
必要はありません

00:34:20.793 --> 00:34:22.795 align:start position:29% line:-1
カスタムモデルの導入です

00:34:23.464 --> 00:34:30.036 align:start position:16% line:-2
カスタムモデルを使用して
Core MLにはない機能をカプセル化

00:34:30.404 --> 00:34:34.808 align:start position:25% line:-2
カスタムレイヤと同じく
実装クラスの名が格納されます

00:34:35.042 --> 00:34:38.978 align:start position:27% line:-2
クラスは一般推論エンジンの
役割を果たします

00:34:39.079 --> 00:34:42.983 align:start position:25% line:-2
パラメータは
MLModelに保存されます

00:34:43.550 --> 00:34:48.054 align:start position:25% line:-2
モデルはコードとは関係なく
App内のアセットとなります

00:34:50.456 --> 00:34:52.760 align:start position:23% line:-1
カスタムモデルの実装も簡単です

00:34:52.860 --> 00:34:55.329 align:start position:16% line:-1
MLCustomModelを公開します

00:34:55.429 --> 00:34:59.466 align:start position:23% line:-2
MLModelのデータに基づき
初期化メソッドを入力しましょう

00:35:00.134 --> 00:35:02.970 align:start position:30% line:-2
次に入力に対する推論計算用の
メソッドを入れます

00:35:03.337 --> 00:35:10.210 align:start position:21% line:-2
特定のモデルで最適化を行う場合
バッチ実装のオプションがあります

00:35:10.310 --> 00:35:12.880 align:start position:34% line:-2
または単一の予測を
呼び出します

00:35:14.615 --> 00:35:19.419 align:start position:16% line:-2
Appでのカスタマイズモデル使用は
他のCore MLモデルとほぼ同じです

00:35:19.586 --> 00:35:24.358 align:start position:18% line:-2
Xcodeではカスタマイズ要素を持つ
モデルには依存関係があり

00:35:24.458 --> 00:35:28.228 align:start position:30% line:-2
実装の名称と
簡単な説明を列挙します

00:35:28.529 --> 00:35:31.598 align:start position:29% line:-1
すべての準備が整いました

00:35:31.698 --> 00:35:36.036 align:start position:25% line:-2
推論APIは 単一の推論でも
バッチでも変わりません

00:35:38.172 --> 00:35:42.676 align:start position:18% line:-2
カスタムレイヤとモデルにより
Core MLをより良く利用できます

00:35:42.776 --> 00:35:47.814 align:start position:25% line:-2
しかも機械学習の分野に必要な
柔軟性は保持できます

00:35:48.582 --> 00:35:50.918 align:start position:25% line:-2
新しいニューラルネットワーク
レイヤは―

00:35:51.018 --> 00:35:56.790 align:start position:27% line:-2
カスタムレイヤを使用すると
様々な最適化が利用できます

00:35:57.057 --> 00:36:01.461 align:start position:23% line:-2
カスタムモデルは
タイプや機能の柔軟性がある一方

00:35:57.057 --> 00:36:01.461 align:start position:23% line:-2
カスタムモデルは
タイプや機能の柔軟性がある一方

00:36:01.562 --> 00:36:04.398 align:start position:25% line:-1
多くの実装作業を必要とします

00:36:05.866 --> 00:36:10.704 align:start position:23% line:-2
どちらのカスタマイズも
パラメータをカプセル化できます

00:36:10.804 --> 00:36:13.407 align:start position:32% line:-2
モデルの可搬性を高め
コードをシンプルに

00:36:15.976 --> 00:36:19.913 align:start position:34% line:-2
すばらしい新機能を
紹介しましたので

00:36:20.214 --> 00:36:23.617 align:start position:29% line:-2
是非ベータ版を
ダウンロードしてください

00:36:27.087 --> 00:36:30.357 align:start position:23% line:-2
Core MLにAppサイズの
縮小機能があり

00:36:30.457 --> 00:36:32.326 align:start position:30% line:-1
パフォーマンスの向上や

00:36:32.426 --> 00:36:36.029 align:start position:29% line:-2
最新の機械学習との
柔軟性や互換性もあります

00:36:36.530 --> 00:36:39.366 align:start position:30% line:-2
モデルサイズを縮小する
量子化の仕組み

00:36:39.466 --> 00:36:42.770 align:start position:21% line:-1
新しいバッチAPIの効率的な処理

00:36:42.870 --> 00:36:47.774 align:start position:21% line:-2
カスタムレイヤとカスタムモデルの
活用法を紹介しました

00:36:48.375 --> 00:36:51.745 align:start position:25% line:-2
Create MLの
新しいツールとの組み合わせで

00:36:51.845 --> 00:36:58.185 align:start position:21% line:-2
AppにML対応の機能を追加して
ユーザのサポートができます

00:36:59.853 --> 00:37:04.792 align:start position:25% line:-2
休憩後にここで
機能の確認をしてみてください

00:36:59.853 --> 00:37:04.792 align:start position:25% line:-2
休憩後にここで
機能の確認をしてみてください

00:37:04.892 --> 00:37:08.362 align:start position:25% line:-2
Core ML Toolsの
ソフトウェアを使って

00:37:08.462 --> 00:37:13.767 align:start position:32% line:-2
モデルサイズの縮小を
実際にお見せします

00:37:13.867 --> 00:37:14.668 align:start position:41% line:-1
ありがとう

00:37:14.968 --> 00:37:20.340 align:start position:43% line:-1
(拍手)
