WEBVTT

00:00:07.107 --> 00:00:16.250 align:start position:43% line:-1
(音楽)

00:00:18.752 --> 00:00:25.292 align:start position:43% line:-1
(拍手)

00:00:25.392 --> 00:00:28.228 align:start position:34% line:-1
WWDCへようこそ

00:00:28.328 --> 00:00:33.333 align:start position:21% line:-2
コーヒーで
一息入れたいところだと思いますが

00:00:33.433 --> 00:00:36.036 align:start position:29% line:-1
私の話をお楽しみください

00:00:36.170 --> 00:00:37.204 align:start position:39% line:-1
私はフランク

00:00:37.304 --> 00:00:41.175 align:start position:18% line:-2
Core MLと
Visionフレームワークを用いた―

00:00:41.275 --> 00:00:43.510 align:start position:25% line:-2
コンピュータビジョンについて
ご紹介します

00:00:44.311 --> 00:00:46.046 align:start position:38% line:-1
まず手始めに―

00:00:46.613 --> 00:00:52.486 align:start position:23% line:-2
画像分類のカスタマイズについて
お話しします

00:00:53.220 --> 00:00:55.656 align:start position:39% line:-1
次に物体認識

00:00:56.356 --> 00:01:01.895 align:start position:21% line:-2
最後にVisionの基本に関して
詳しくお伝えします

00:00:56.356 --> 00:01:01.895 align:start position:21% line:-2
最後にVisionの基本に関して
詳しくお伝えします

00:01:04.164 --> 00:01:06.099 align:start position:34% line:-1
画像分類については

00:01:07.267 --> 00:01:11.638 align:start position:27% line:-2
その利点を
すでにお聞きになりましたね

00:01:11.738 --> 00:01:17.311 align:start position:30% line:-2
花や果物を使ったデモを
ご覧いただきましたが

00:01:17.411 --> 00:01:20.747 align:start position:21% line:-1
ここでは より技術的な話をします

00:01:20.848 --> 00:01:27.354 align:start position:27% line:-2
例えば ロボットの部品を
扱う店を開いたとしましょう

00:01:27.487 --> 00:01:30.190 align:start position:30% line:-1
部品がたくさんあるので

00:01:30.290 --> 00:01:36.964 align:start position:27% line:-2
アプリケーションを用いて
部品を識別することにします

00:01:38.232 --> 00:01:41.068 align:start position:34% line:-2
そこで 分類器を
トレーニングします

00:01:41.635 --> 00:01:44.905 align:start position:34% line:-1
分類器が完成したら

00:01:45.005 --> 00:01:49.510 align:start position:29% line:-2
iOSアプリケーションを
構築します

00:01:50.043 --> 00:01:53.280 align:start position:29% line:-1
この作業を行っていく中で

00:01:53.380 --> 00:01:58.318 align:start position:30% line:-2
注意すべき点についても
後ほどお伝えします

00:02:00.854 --> 00:02:02.990 align:start position:21% line:-1
では トレーニングから説明します

00:02:03.290 --> 00:02:05.759 align:start position:25% line:-1
Create MLを用います

00:02:07.027 --> 00:02:10.430 align:start position:27% line:-1
まずは画像を用意しましょう

00:02:11.665 --> 00:02:17.070 align:start position:27% line:-2
画像を保存するフォルダ名が
分類ラベルになります

00:02:18.805 --> 00:02:23.043 align:start position:29% line:-2
画像データは
どれほど必要でしょうか？

00:02:23.977 --> 00:02:30.717 align:start position:27% line:-2
１つのカテゴリにつき
最低10件程度は必要ですが

00:02:31.151 --> 00:02:36.924 align:start position:29% line:-2
画像数が多いほど
分類結果は正確になります

00:02:38.325 --> 00:02:42.829 align:start position:32% line:-2
画像数のバランスにも
注意が必要です

00:02:42.930 --> 00:02:47.634 align:start position:32% line:-2
カテゴリによって
数に大きな差があると

00:02:47.734 --> 00:02:50.237 align:start position:36% line:-2
トレーニングは
うまくいきません

00:02:50.337 --> 00:02:53.707 align:start position:27% line:-1
同程度の数を準備しましょう

00:02:55.609 --> 00:02:59.713 align:start position:18% line:-2
augmentationという機能も
効果的で

00:03:00.013 --> 00:03:03.450 align:start position:32% line:-2
より安定したモデルに
なります

00:03:03.550 --> 00:03:06.653 align:start position:23% line:-1
ただし これを使うからといって

00:03:06.753 --> 00:03:10.991 align:start position:29% line:-2
画像が少なくても
済むわけではありませんよ

00:03:11.258 --> 00:03:15.896 align:start position:27% line:-2
augmentationは
画像に変化を加えます

00:03:15.996 --> 00:03:19.333 align:start position:25% line:-1
ぼかしたり 回転させたりして

00:03:19.433 --> 00:03:22.669 align:start position:32% line:-2
トレーニング用に
見た目を変えるのです

00:03:24.738 --> 00:03:27.774 align:start position:30% line:-2
トレーニングの仕組みを
見てみましょう

00:03:29.343 --> 00:03:31.912 align:start position:29% line:-1
転移学習という技術を使い

00:03:32.012 --> 00:03:35.916 align:start position:27% line:-2
Create MLの
分類器をトレーニングします

00:03:36.283 --> 00:03:40.521 align:start position:34% line:-2
これには学習済みの
モデルを用います

00:03:40.621 --> 00:03:45.058 align:start position:27% line:-2
数百万の画像で
数週間かけてトレーニングし

00:03:45.158 --> 00:03:48.862 align:start position:29% line:-1
その状態から始められます

00:03:50.364 --> 00:03:54.735 align:start position:32% line:-2
このモデルを使うと
画像の特徴を抽出して

00:03:54.835 --> 00:03:58.639 align:start position:36% line:-2
数値化することが
可能になります

00:03:59.373 --> 00:04:05.479 align:start position:27% line:-2
ここにデータを取り込んで
分類器をトレーニングすると

00:03:59.373 --> 00:04:05.479 align:start position:27% line:-2
ここにデータを取り込んで
分類器をトレーニングすると

00:04:05.579 --> 00:04:09.349 align:start position:27% line:-1
カスタムモデルが完成します

00:04:11.285 --> 00:04:14.855 align:start position:27% line:-1
この学習済みモデルに加えて

00:04:15.355 --> 00:04:20.293 align:start position:4% line:-2
Vision FeaturePrint.Sceneも
あります

00:04:20.994 --> 00:04:26.133 align:start position:21% line:-2
Create MLと連携させて
画像分類器をトレーニングできます

00:04:27.701 --> 00:04:30.571 align:start position:34% line:-2
大量のデータで
トレーニング済みで

00:04:31.371 --> 00:04:35.209 align:start position:29% line:-2
1000以上のカテゴリを
分類できます

00:04:35.309 --> 00:04:39.213 align:start position:29% line:-1
これは非常に便利ですよね

00:04:40.681 --> 00:04:44.785 align:start position:23% line:-1
すでに数年前から このモデルを

00:04:44.885 --> 00:04:48.856 align:start position:30% line:-2
写真アプリケーションで
使ってきました

00:04:49.957 --> 00:04:55.629 align:start position:30% line:-2
今後も改良は続けますが
注意すべき点があります

00:04:56.630 --> 00:04:59.299 align:start position:34% line:-1
最新版のモデルでも

00:04:59.399 --> 00:05:04.338 align:start position:25% line:-2
活用するには再トレーニングが
必要ということです

00:04:59.399 --> 00:05:04.338 align:start position:25% line:-2
活用するには再トレーニングが
必要ということです

00:05:04.571 --> 00:05:10.844 align:start position:21% line:-2
新しいモデルが登場した時のために
データをとっておき

00:05:10.944 --> 00:05:14.815 align:start position:29% line:-2
それを使って
再トレーニングしましょう

00:05:16.984 --> 00:05:20.120 align:start position:27% line:-1
この新しいVisionは―

00:05:21.922 --> 00:05:26.360 align:start position:34% line:-2
すでに デバイスに
搭載されています

00:05:26.460 --> 00:05:31.532 align:start position:27% line:-2
ディスクのフットプリントを
小さく抑えられるからです

00:05:32.032 --> 00:05:33.667 align:start position:36% line:-1
比べてみましょう

00:05:34.001 --> 00:05:38.772 align:start position:25% line:-2
最初は現在
一般的なモデルの１つである―

00:05:38.872 --> 00:05:44.111 align:start position:25% line:-2
ResNetで分類器を
トレーニングした際の容量です

00:05:44.411 --> 00:05:46.013 align:start position:39% line:-1
98MBです

00:05:47.314 --> 00:05:53.387 align:start position:20% line:-2
次に より小さいモデルの
SqueezeNetで試してみます

00:05:53.754 --> 00:05:59.193 align:start position:30% line:-2
５MBまで減りましたが
対応能力は限られます

00:05:59.493 --> 00:06:00.727 align:start position:36% line:-1
Visionは―

00:05:59.493 --> 00:06:00.727 align:start position:36% line:-1
Visionは―

00:06:01.728 --> 00:06:04.131 align:start position:32% line:-1
なんと１MB以下です

00:06:06.233 --> 00:06:11.505 align:start position:25% line:-2
すでに最適化されている点でも
とても優秀です

00:06:11.605 --> 00:06:17.444 align:start position:25% line:-2
ハードウェアやGPU
CPUとの連携も考慮しており

00:06:17.878 --> 00:06:21.682 align:start position:32% line:-2
我が社のデバイス上で
効率的に働きます

00:06:24.318 --> 00:06:25.986 align:start position:30% line:-1
トレーニングの方法は？

00:06:26.954 --> 00:06:31.291 align:start position:18% line:-1
Create MLが画像を読み込むと

00:06:31.391 --> 00:06:35.596 align:start position:4% line:-2
Vision FeaturePrint.Sceneと
連携します

00:06:36.530 --> 00:06:42.369 align:start position:20% line:-2
そして 分類器がトレーニングされ
Core MLモデルが作成されます

00:06:42.469 --> 00:06:44.104 align:start position:34% line:-1
だから小さいのです

00:06:45.506 --> 00:06:48.475 align:start position:29% line:-1
実際に画像を分類させる時

00:06:48.775 --> 00:06:52.446 align:start position:32% line:-2
必要なのは
画像とモデルだけです

00:06:52.746 --> 00:07:00.087 align:start position:23% line:-2
VisionとCore MLは
分類方法を学習しているので

00:06:52.746 --> 00:07:00.087 align:start position:23% line:-2
VisionとCore MLは
分類方法を学習しているので

00:07:00.187 --> 00:07:04.358 align:start position:30% line:-2
画像の分類結果が
出てくるというわけです

00:07:07.227 --> 00:07:10.230 align:start position:23% line:-1
これがトレーニングの全体像です

00:07:11.131 --> 00:07:15.669 align:start position:32% line:-2
続いて 冒頭で触れた
注意点についてです

00:07:16.737 --> 00:07:17.538 align:start position:45% line:-1
まず―

00:07:18.639 --> 00:07:22.943 align:start position:32% line:-2
分類器は必要な時だけ
実行しましょう

00:07:24.344 --> 00:07:28.649 align:start position:30% line:-2
畳み込みネットワークを
使っているからです

00:07:28.749 --> 00:07:35.289 align:start position:25% line:-2
つまり 実行すると
CPUやGPUも動きだすので

00:07:35.389 --> 00:07:38.292 align:start position:29% line:-1
必要な時だけにしましょう

00:07:38.892 --> 00:07:42.062 align:start position:27% line:-1
後ほどデモをお見せしますが

00:07:42.663 --> 00:07:48.602 align:start position:25% line:-2
カメラを動かしている時などは
分類はしないように

00:07:50.037 --> 00:07:55.275 align:start position:30% line:-2
静止した状態になったら
分類を実行するのです

00:07:56.009 --> 00:07:59.980 align:start position:23% line:-2
それには
レジストレーション機能を使って

00:08:00.080 --> 00:08:02.382 align:start position:30% line:-1
２つの画像を比較します

00:08:02.516 --> 00:08:09.189 align:start position:21% line:-2
どれくらいピクセルを変換すれば
画像が一致するかを判断するのです

00:08:09.523 --> 00:08:12.059 align:start position:32% line:-1
優秀なアルゴリズムで

00:08:12.159 --> 00:08:17.264 align:start position:27% line:-2
対象物が正確に撮れる状態か
教えてくれます

00:08:19.633 --> 00:08:23.871 align:start position:9% line:-2
VNTranslationalImage
RegistrationRequestを使うと

00:08:25.038 --> 00:08:27.975 align:start position:30% line:-1
必要な情報が得られます

00:08:28.075 --> 00:08:31.311 align:start position:27% line:-1
実際に動画で見てみましょう

00:08:31.445 --> 00:08:35.048 align:start position:25% line:-1
動画上に現れる黄色のラインは

00:08:35.148 --> 00:08:39.318 align:start position:23% line:-2
カメラや
レジストレーションリクエストが

00:08:39.419 --> 00:08:41.688 align:start position:27% line:-1
どう動いたかを表しています

00:08:41.855 --> 00:08:46.093 align:start position:36% line:-2
カメラを動かすと
ラインは長くなり

00:08:46.193 --> 00:08:49.229 align:start position:27% line:-1
動きを止めると短くなります

00:08:50.931 --> 00:08:55.903 align:start position:29% line:-2
カメラの動きによって
ラインの長さが変化します

00:08:56.904 --> 00:09:01.408 align:start position:32% line:-2
静止したタイミングで
分類器を実行します

00:08:56.904 --> 00:09:01.408 align:start position:32% line:-2
静止したタイミングで
分類器を実行します

00:09:03.677 --> 00:09:07.347 align:start position:32% line:-2
次の注意点は
代替策を用意すること

00:09:07.648 --> 00:09:09.349 align:start position:39% line:-1
大切ですよね

00:09:09.683 --> 00:09:12.085 align:start position:29% line:-1
分類を誤る場合もあります

00:09:13.554 --> 00:09:17.424 align:start position:27% line:-1
たとえ精度が高い分類器でも

00:09:17.524 --> 00:09:21.261 align:start position:36% line:-2
万が一の場合の
対応策は必要です

00:09:22.462 --> 00:09:25.799 align:start position:29% line:-1
手元に対象物がない場合も

00:09:25.899 --> 00:09:29.403 align:start position:27% line:-1
対応できるようにするには？

00:09:29.603 --> 00:09:33.474 align:start position:25% line:-2
Visionフレームワークの
バーコード検出を用いて

00:09:33.574 --> 00:09:36.543 align:start position:30% line:-1
データを読み取るのです

00:09:37.211 --> 00:09:40.681 align:start position:30% line:-2
では ここで
デモをお見せしましょう

00:09:41.748 --> 00:09:46.520 align:start position:43% line:-1
(拍手)

00:09:52.993 --> 00:09:57.297 align:start position:30% line:-2
スクリーンの右側に
見えるのがデバイスです

00:09:57.531 --> 00:10:01.201 align:start position:25% line:-2
ロボットの店の
アプリケーションを起動します

00:09:57.531 --> 00:10:01.201 align:start position:25% line:-2
ロボットの店の
アプリケーションを起動します

00:10:01.568 --> 00:10:04.638 align:start position:36% line:-2
動かしている間は
何も起きません

00:10:04.738 --> 00:10:09.009 align:start position:27% line:-2
対象物を表示して静止すると
ラインが現れて

00:10:09.109 --> 00:10:11.778 align:start position:29% line:-2
ステッピングモーターだと
判別します

00:10:12.112 --> 00:10:14.815 align:start position:30% line:-1
他にも試してみましょう

00:10:18.418 --> 00:10:20.287 align:start position:27% line:-1
これはマイクロコントローラ

00:10:23.357 --> 00:10:25.092 align:start position:25% line:-1
ステッピングモータードライバ

00:10:25.192 --> 00:10:28.128 align:start position:34% line:-1
手のひらに載せて…

00:10:29.663 --> 00:10:31.598 align:start position:27% line:-1
クローズドループベルトです

00:10:35.335 --> 00:10:37.504 align:start position:36% line:-1
これは親ねじです

00:10:37.604 --> 00:10:40.874 align:start position:30% line:-1
QRコードも認識します

00:10:41.408 --> 00:10:43.443 align:start position:32% line:-1
ケーブルが短いですね

00:10:46.046 --> 00:10:48.482 align:start position:25% line:-1
学習講座のページが開きました

00:10:48.582 --> 00:10:49.583 align:start position:43% line:-1
これで…

00:10:49.883 --> 00:10:50.584 align:start position:43% line:-1
フランク

00:10:51.418 --> 00:10:52.653 align:start position:41% line:-1
何でしょう

00:10:53.453 --> 00:10:54.188 align:start position:43% line:-1
フランク

00:10:55.622 --> 00:10:59.993 align:start position:30% line:-2
この部品でも
試してみてくれないか？

00:11:00.093 --> 00:11:01.895 align:start position:34% line:-1
上司のブレットです

00:11:04.331 --> 00:11:05.365 align:start position:43% line:-1
よろしく

00:11:08.502 --> 00:11:11.572 align:start position:27% line:-1
依頼はいつも ぎりぎりです

00:11:12.272 --> 00:11:14.374 align:start position:32% line:-1
また お願いするかも

00:11:15.275 --> 00:11:17.711 align:start position:34% line:-1
土曜は働きませんよ

00:11:18.212 --> 00:11:21.315 align:start position:29% line:-1
これはサーボモータですね

00:11:21.982 --> 00:11:24.351 align:start position:29% line:-1
では やってみましょうか

00:11:25.586 --> 00:11:26.987 align:start position:39% line:-1
試してみます

00:11:28.088 --> 00:11:30.524 align:start position:32% line:-1
認識できるでしょうか

00:11:30.624 --> 00:11:33.460 align:start position:30% line:-1
どうやら駄目なようです

00:11:33.560 --> 00:11:35.596 align:start position:36% line:-1
分類を誤りました

00:11:35.863 --> 00:11:37.030 align:start position:41% line:-1
バグですね

00:11:37.865 --> 00:11:39.399 align:start position:38% line:-1
修正が必要です

00:11:39.867 --> 00:11:41.201 align:start position:38% line:-1
直したい人は？

00:11:41.668 --> 00:11:44.338 align:start position:43% line:-1
(拍手)

00:11:44.438 --> 00:11:46.340 align:start position:39% line:-1
立候補者は？

00:11:46.473 --> 00:11:47.541 align:start position:38% line:-1
分かりましたよ

00:11:49.409 --> 00:11:54.915 align:start position:29% line:-2
ではまず サーボモータの
画像を用意します

00:11:55.015 --> 00:11:59.586 align:start position:30% line:-2
スタジオへ行って
撮影してもいいのですが

00:11:59.820 --> 00:12:04.458 align:start position:29% line:-2
今回は 私が愛用している
カメラを使いましょう

00:11:59.820 --> 00:12:04.458 align:start position:29% line:-2
今回は 私が愛用している
カメラを使いましょう

00:12:05.259 --> 00:12:09.930 align:start position:30% line:-2
サーボモータの画像を
たくさん撮っていきます

00:12:12.366 --> 00:12:17.004 align:start position:29% line:-2
角度を変えつつ 他の物が
写らないようにします

00:12:23.410 --> 00:12:27.347 align:start position:32% line:-2
画像は最低でも10枚
用意しましょう

00:12:27.447 --> 00:12:31.018 align:start position:30% line:-2
背景を変えて撮ることも
大切です

00:12:35.222 --> 00:12:40.260 align:start position:29% line:-2
この上で数枚撮ったあとは
手のひらに載せて撮ります

00:12:46.833 --> 00:12:49.736 align:start position:30% line:-1
これで画像数は十分です

00:12:51.305 --> 00:12:55.642 align:start position:27% line:-2
では実際に
トレーニングを行いましょう

00:12:57.211 --> 00:12:58.111 align:start position:46% line:-1
よし

00:12:59.613 --> 00:13:04.251 align:start position:23% line:-2
撮った画像を
アプリケーションで取り込みます

00:12:59.613 --> 00:13:04.251 align:start position:23% line:-2
撮った画像を
アプリケーションで取り込みます

00:13:04.985 --> 00:13:06.520 align:start position:12% line:-1
QuickTime Playerを隠して…

00:13:09.122 --> 00:13:12.726 align:start position:34% line:-2
Finder内に
表示されているのは

00:13:12.826 --> 00:13:17.264 align:start position:25% line:-2
モデルのトレーニングに使った
データ一式です

00:13:17.731 --> 00:13:19.833 align:start position:29% line:-1
新しいフォルダを作成し―

00:13:21.235 --> 00:13:22.970 align:start position:27% line:-1
“Servo”と名付けます

00:13:25.772 --> 00:13:30.911 align:start position:30% line:-2
撮影したばかりの画像を
全て選択したら…

00:13:34.515 --> 00:13:37.784 align:start position:21% line:-1
“Servo”フォルダにドラッグ

00:13:41.121 --> 00:13:44.458 align:start position:30% line:-1
これで準備ができました

00:13:44.558 --> 00:13:46.693 align:start position:38% line:-1
上司のせいで―

00:13:46.894 --> 00:13:50.330 align:start position:27% line:-2
またトレーニングしなければ
なりません

00:13:50.497 --> 00:13:51.298 align:start position:46% line:-1
よし

00:13:52.232 --> 00:13:57.571 align:start position:23% line:-2
ここでは単純なスクリプトの
Playgroundを用います

00:13:57.671 --> 00:14:01.808 align:start position:29% line:-2
あとでアプリケーションに
組み込むためです

00:13:57.671 --> 00:14:01.808 align:start position:29% line:-2
あとでアプリケーションに
組み込むためです

00:14:02.342 --> 00:14:06.246 align:start position:29% line:-2
フォルダに入れたデータを
ポイントして

00:14:06.713 --> 00:14:11.485 align:start position:27% line:-2
分類器をトレーニングしたら
モデルを書き出します

00:14:12.686 --> 00:14:17.057 align:start position:30% line:-2
ご覧のように
次々と処理が行われます

00:14:17.357 --> 00:14:21.929 align:start position:29% line:-2
フォルダに保存した画像が
全て読み込まれ―

00:14:22.229 --> 00:14:25.466 align:start position:27% line:-1
データが解析されていきます

00:14:25.566 --> 00:14:32.239 align:start position:25% line:-2
必要に応じてサイズが縮小され
モデルの学習が進められます

00:14:32.339 --> 00:14:36.677 align:start position:34% line:-2
わずかなコードで
複雑な処理が行われ

00:14:36.777 --> 00:14:41.281 align:start position:30% line:-2
作業が完了すると
モデルの出来上がりです

00:14:41.715 --> 00:14:43.550 align:start position:36% line:-1
終わりそうですね

00:14:44.818 --> 00:14:46.153 align:start position:39% line:-1
もう少しです

00:14:47.120 --> 00:14:49.089 align:start position:39% line:-1
完成しました

00:14:53.093 --> 00:14:59.266 align:start position:23% line:-2
先ほど 店のアプリケーションで
使っていたのと同じモデルです

00:15:00.033 --> 00:15:04.171 align:start position:20% line:-1
サイズは わずか148KBしかなく

00:15:04.438 --> 00:15:08.008 align:start position:30% line:-2
スタートアップ画面より
小容量です

00:15:09.042 --> 00:15:15.749 align:start position:43% line:-1
(拍手)

00:15:15.849 --> 00:15:19.820 align:start position:25% line:-2
ここで強調しておきたいことが
あります

00:15:21.321 --> 00:15:26.593 align:start position:23% line:-2
必要な画像はカラーで
サイズは299×299ピクセル

00:15:26.693 --> 00:15:30.197 align:start position:30% line:-2
分類器の場合
多くが この大きさです

00:15:31.331 --> 00:15:35.836 align:start position:34% line:-2
それでは モデルが
完成したようなので

00:15:35.936 --> 00:15:40.974 align:start position:29% line:-2
plist形式の
商品データベースを開いて

00:15:42.109 --> 00:15:44.778 align:start position:23% line:-1
サーボモータの情報を追加します

00:15:48.048 --> 00:15:51.051 align:start position:23% line:-2
これを
“Servo”と名付けましょう

00:15:52.686 --> 00:15:56.223 align:start position:29% line:-1
そしてラベルを入力します

00:15:56.323 --> 00:15:59.459 align:start position:34% line:-1
“サーボモータ”と

00:16:00.861 --> 00:16:02.896 align:start position:43% line:-1
説明は―

00:16:03.697 --> 00:16:08.735 align:start position:29% line:-1
“サッサッと動くモータ”

00:16:09.770 --> 00:16:10.904 align:start position:41% line:-1
こんな感じ

00:16:12.139 --> 00:16:13.907 align:start position:39% line:-1
技術的ですね

00:16:14.775 --> 00:16:16.143 align:start position:32% line:-1
うまくいくでしょうか

00:16:17.177 --> 00:16:18.946 align:start position:30% line:-1
アプリケーションを起動

00:16:28.355 --> 00:16:30.691 align:start position:30% line:-1
では 試してみましょう

00:16:32.759 --> 00:16:34.328 align:start position:34% line:-1
正しく認識しました

00:16:34.428 --> 00:16:41.602 align:start position:43% line:-1
(拍手)

00:16:41.702 --> 00:16:48.208 align:start position:29% line:-2
世界で初めてステージ上で
分類器をトレーニングし

00:16:48.308 --> 00:16:50.077 align:start position:39% line:-1
実行しました

00:16:50.711 --> 00:16:52.379 align:start position:36% line:-1
少し緊張しました

00:16:52.513 --> 00:16:53.981 align:start position:41% line:-1
(笑い声)

00:16:54.081 --> 00:16:55.516 align:start position:43% line:-1
(拍手)

00:16:55.616 --> 00:16:56.283 align:start position:41% line:-1
ありがとう

00:16:56.383 --> 00:17:01.121 align:start position:43% line:-1
(拍手)

00:16:56.383 --> 00:17:01.121 align:start position:43% line:-1
(拍手)

00:17:01.788 --> 00:17:07.194 align:start position:30% line:-2
今の工程について
少し説明させてください

00:17:08.929 --> 00:17:11.131 align:start position:32% line:-1
コードをお見せします

00:17:12.266 --> 00:17:13.066 align:start position:46% line:-1
よし

00:17:14.201 --> 00:17:17.137 align:start position:30% line:-1
不要なものは閉じますね

00:17:18.771 --> 00:17:20.040 align:start position:39% line:-1
少し広げて…

00:17:22.108 --> 00:17:25.244 align:start position:32% line:-1
今の流れを解説します

00:17:25.345 --> 00:17:28.882 align:start position:5% line:-2
まず
sequenceRequestHandlerを作り

00:17:28.982 --> 00:17:31.952 align:start position:25% line:-1
レジストレーションに用います

00:17:32.052 --> 00:17:37.024 align:start position:29% line:-2
すでに話があったとおり
物体の追跡に適しています

00:17:37.958 --> 00:17:41.528 align:start position:30% line:-2
リクエストを作成したら
順に並べます

00:17:41.628 --> 00:17:46.667 align:start position:27% line:-2
レジストレーションには
結果が15件出るようにして

00:17:46.767 --> 00:17:50.404 align:start position:30% line:-2
カメラが静止しているか
確認します

00:17:51.238 --> 00:17:55.242 align:start position:23% line:-1
その間 保持するバッファは１つ

00:17:55.342 --> 00:17:57.611 align:start position:34% line:-1
分類を行う間もです

00:17:58.679 --> 00:18:03.383 align:start position:32% line:-2
時間がかかるので
別のキューに入れます

00:17:58.679 --> 00:18:03.383 align:start position:32% line:-2
時間がかかるので
別のキューに入れます

00:18:05.919 --> 00:18:11.291 align:start position:30% line:-2
ご覧いただいているのが
私が使用したコードです

00:18:11.458 --> 00:18:14.795 align:start position:21% line:-1
Visionタスクの設定方法は？

00:18:15.095 --> 00:18:18.532 align:start position:30% line:-2
実行するタスクは
バーコードリクエストと

00:18:18.632 --> 00:18:20.968 align:start position:34% line:-1
分類リクエストです

00:18:21.268 --> 00:18:23.203 align:start position:29% line:-2
まず
バーコードリクエストです

00:18:23.904 --> 00:18:28.342 align:start position:32% line:-2
完了ハンドラの状態を
確認しましょう

00:18:28.909 --> 00:18:34.314 align:start position:30% line:-2
バーコードは１つなので
最初の結果だけを見ます

00:18:35.015 --> 00:18:38.585 align:start position:34% line:-2
デコードできるかも
確かめましょう

00:18:38.685 --> 00:18:42.656 align:start position:25% line:-1
デモでは うまくいきましたね

00:18:43.957 --> 00:18:47.327 align:start position:27% line:-1
これをリクエストに加えます

00:18:47.427 --> 00:18:49.797 align:start position:29% line:-1
続いて分類リクエストです

00:18:49.897 --> 00:18:53.233 align:start position:27% line:-1
今回使ったのは私の分類器で

00:18:53.333 --> 00:18:59.239 align:start position:27% line:-2
それをバンドルからロードし
モデルを作りました

00:18:59.339 --> 00:19:02.910 align:start position:34% line:-2
今回はコード補完を
使っていません

00:18:59.339 --> 00:19:02.910 align:start position:34% line:-2
今回はコード補完を
使っていません

00:19:03.010 --> 00:19:06.613 align:start position:18% line:-2
これは私がCore MLで使っている
唯一のコードですし

00:19:06.713 --> 00:19:09.516 align:start position:29% line:-1
自分で調整できるからです

00:19:09.616 --> 00:19:14.254 align:start position:30% line:-2
コード補完を使うことも
効果的だと思います

00:19:14.788 --> 00:19:20.661 align:start position:11% line:-2
こうしてVision Core MLモデルと
リクエストを構築しました

00:19:20.761 --> 00:19:26.633 align:start position:27% line:-2
リクエストが返されると
完了ハンドラが実行されます

00:19:26.733 --> 00:19:31.205 align:start position:34% line:-2
どんな分類結果が
出てきたか確認して

00:19:31.738 --> 00:19:34.007 align:start position:32% line:-1
しきい値を設定します

00:19:34.174 --> 00:19:38.846 align:start position:30% line:-2
ここでは実験的に
0.98と設定しました

00:19:38.946 --> 00:19:42.349 align:start position:29% line:-2
正解の自信が
98％あるという意味です

00:19:43.383 --> 00:19:49.256 align:start position:23% line:-2
この設定により
不確実な分類結果を除去できます

00:19:49.356 --> 00:19:51.525 align:start position:36% line:-1
あとで説明します

00:19:52.893 --> 00:19:54.928 align:start position:29% line:-1
リクエストがそろいました

00:19:55.495 --> 00:19:59.466 align:start position:32% line:-2
これらを実行する際に
関数を設定して

00:19:59.566 --> 00:20:02.269 align:start position:29% line:-1
対象の画像を解析させます

00:19:59.566 --> 00:20:02.269 align:start position:29% line:-1
対象の画像を解析させます

00:20:02.436 --> 00:20:05.239 align:start position:30% line:-1
実際に解析を行う時には

00:20:05.572 --> 00:20:11.245 align:start position:16% line:-2
device orientationで
デバイスの向きを確認します

00:20:11.879 --> 00:20:17.017 align:start position:11% line:-2
VNImageRequestHandlerを
実行するバッファに作ります

00:20:17.851 --> 00:20:22.256 align:start position:25% line:-1
そして非同期的に実行させます

00:20:24.291 --> 00:20:29.763 align:start position:29% line:-2
以上がCore MLと
バーコードの処理方法です

00:20:30.264 --> 00:20:34.535 align:start position:30% line:-2
次は 対象物を
正確に捉える仕組みです

00:20:34.635 --> 00:20:39.339 align:start position:30% line:-2
リセット可能なキューに
ポイントを追加しました

00:20:39.940 --> 00:20:43.610 align:start position:27% line:-2
そして
記録したポイントのキューを

00:20:43.710 --> 00:20:46.346 align:start position:30% line:-1
調べる機能を作りました

00:20:46.447 --> 00:20:49.383 align:start position:27% line:-1
自分の経験から 最大でも―

00:20:49.483 --> 00:20:53.687 align:start position:27% line:-2
20ピクセル程度になるよう
設定しました

00:20:53.787 --> 00:20:58.392 align:start position:27% line:-2
すると カメラが静止したと
認識されます

00:20:59.827 --> 00:21:01.728 align:start position:29% line:-1
次は出力のキャプチャです

00:20:59.827 --> 00:21:01.728 align:start position:29% line:-1
次は出力のキャプチャです

00:21:01.828 --> 00:21:06.233 align:start position:18% line:-2
これはカメラのバッファと
AVFoundationのコードです

00:21:06.700 --> 00:21:10.104 align:start position:30% line:-2
前のピクセルバッファを
残しておき

00:21:10.204 --> 00:21:13.740 align:start position:27% line:-1
レジストレーションと比較し

00:21:14.007 --> 00:21:17.311 align:start position:23% line:-1
終了したらスワップアウトします

00:21:17.844 --> 00:21:21.915 align:start position:9% line:-2
VNTranslationalImage
RegistrationRequestを作成し

00:21:22.649 --> 00:21:26.820 align:start position:7% line:-2
sequenceRequestHandler上で
リクエストを実行します

00:21:27.287 --> 00:21:31.158 align:start position:25% line:-1
結果が出たら内容を確認します

00:21:31.658 --> 00:21:33.527 align:start position:38% line:-1
配列に追加して

00:21:34.428 --> 00:21:38.098 align:start position:30% line:-2
カメラが静止した状態か
確認します

00:21:38.499 --> 00:21:43.570 align:start position:25% line:-2
確認できたら黄色いボックスを
表示するようにします

00:21:44.404 --> 00:21:47.374 align:start position:29% line:-1
バッファは解析済みなので

00:21:47.708 --> 00:21:52.646 align:start position:32% line:-2
画像を解析するように
指示を出します

00:21:54.548 --> 00:21:59.686 align:start position:30% line:-2
ご覧のとおり
非同期呼び出しの最後に

00:21:59.786 --> 00:22:02.656 align:start position:32% line:-1
バッファを解放します

00:21:59.786 --> 00:22:02.656 align:start position:32% line:-1
バッファを解放します

00:22:02.856 --> 00:22:06.693 align:start position:30% line:-2
そして 他にバッファが
ないか確認して

00:22:06.827 --> 00:22:12.466 align:start position:27% line:-2
１つのバッファだけが
動いていることを確かめます

00:22:12.566 --> 00:22:16.470 align:start position:34% line:-2
カメラのフレームを
安定させるためです

00:22:17.371 --> 00:22:22.209 align:start position:29% line:-2
実行に際して
幾つか補足させてください

00:22:22.309 --> 00:22:23.410 align:start position:41% line:-1
１つ目は―

00:22:24.478 --> 00:22:29.783 align:start position:27% line:-2
画面の下方にある
コンソールを見ると実際に…

00:22:29.883 --> 00:22:33.120 align:start position:34% line:-1
少しお待ちください

00:22:35.923 --> 00:22:37.758 align:start position:38% line:-1
画面が現れます

00:22:38.325 --> 00:22:40.661 align:start position:30% line:-1
信頼スコアが低いですね

00:22:40.761 --> 00:22:45.199 align:start position:27% line:-2
ただの白い背景で
何も認識できていないのです

00:22:45.499 --> 00:22:48.936 align:start position:29% line:-2
識別可能な物を表示すると
すぐに…

00:22:49.570 --> 00:22:52.005 align:start position:30% line:-1
信頼スコアが上がります

00:22:52.105 --> 00:22:55.709 align:start position:27% line:-1
対象物を認識できたからです

00:22:56.844 --> 00:22:59.213 align:start position:30% line:-1
もう１つ ご覧ください

00:23:01.849 --> 00:23:05.119 align:start position:27% line:-1
CPUに注目してみましょう

00:23:07.054 --> 00:23:11.792 align:start position:30% line:-2
今はただ 画像を
表示しているだけですが

00:23:12.159 --> 00:23:14.828 align:start position:30% line:-1
カメラを動かしてみます

00:23:15.662 --> 00:23:19.800 align:start position:30% line:-2
CPU使用率は22％に
上がりました

00:23:19.900 --> 00:23:24.204 align:start position:34% line:-2
分類器を実行すると
さらに上がるので

00:23:24.671 --> 00:23:28.876 align:start position:30% line:-2
必要時のみ動かすことを
お勧めします

00:23:31.011 --> 00:23:33.981 align:start position:32% line:-1
盛りだくさんでしたね

00:23:34.081 --> 00:23:38.719 align:start position:32% line:-2
スライドに戻って
おさらいをしましょう

00:23:39.786 --> 00:23:41.588 align:start position:36% line:-1
スライドでしたね

00:23:41.688 --> 00:23:47.094 align:start position:43% line:-1
(拍手)

00:23:48.161 --> 00:23:49.463 align:start position:39% line:-1
おさらいです

00:23:49.930 --> 00:23:52.900 align:start position:34% line:-1
まずは対象物の認識

00:23:53.867 --> 00:23:55.569 align:start position:5% line:-1
VNSequenceRequestHandlerと

00:23:55.669 --> 00:23:59.039 align:start position:14% line:-2
VNTranslationalImage
RegistrationRequestで

00:24:00.140 --> 00:24:02.309 align:start position:29% line:-1
前のフレームと比較します

00:24:03.377 --> 00:24:08.348 align:start position:30% line:-2
すると アライメントの
変換が分かるので

00:24:08.448 --> 00:24:14.354 align:start position:27% line:-2
フレームが どう移行したか
知ることができます

00:24:15.923 --> 00:24:19.660 align:start position:30% line:-2
カメラが静止した時だけ
解析するには

00:24:20.194 --> 00:24:25.332 align:start position:7% line:-1
VNImageRequestHandlerを作り

00:24:25.966 --> 00:24:31.839 align:start position:27% line:-2
バーコード検出と分類機能を
実行させます

00:24:32.105 --> 00:24:36.577 align:start position:29% line:-2
そうすると
Visionが最適化され

00:24:36.677 --> 00:24:40.581 align:start position:25% line:-1
より速い処理が可能になります

00:24:43.083 --> 00:24:47.488 align:start position:25% line:-2
バッファをいくつ保持するかも
話しましたね

00:24:47.588 --> 00:24:49.923 align:start position:32% line:-1
自分で管理しましょう

00:24:50.891 --> 00:24:55.629 align:start position:27% line:-2
畳み込みネットワークなどは
時間がかかるので

00:24:55.929 --> 00:25:00.200 align:start position:29% line:-2
バックグラウンドキューで
動かすようにします

00:24:55.929 --> 00:25:00.200 align:start position:29% line:-2
バックグラウンドキューで
動かすようにします

00:25:00.300 --> 00:25:04.638 align:start position:30% line:-2
そうすれば
同時にカメラを使えます

00:25:04.972 --> 00:25:10.077 align:start position:29% line:-2
撮影時 キューにタスクが
たまることは望まないので

00:25:10.177 --> 00:25:14.348 align:start position:32% line:-2
今回はバッファを
１つだけにしましたね

00:25:14.448 --> 00:25:17.084 align:start position:29% line:-1
すると うまくいきました

00:25:17.184 --> 00:25:21.955 align:start position:30% line:-2
必要なバッファだけが
動いていることを確認し

00:25:22.122 --> 00:25:28.195 align:start position:29% line:-2
終了したらリセットして
新たなバッファを使います

00:25:31.098 --> 00:25:36.970 align:start position:23% line:-2
なぜ Core MLモデルに
Visionを使うのでしょうか

00:25:38.105 --> 00:25:42.042 align:start position:25% line:-1
それには重要な理由があります

00:25:42.209 --> 00:25:45.445 align:start position:25% line:-1
モデルを思い出してみましょう

00:25:45.546 --> 00:25:49.416 align:start position:25% line:-2
299×299ピクセルという
妙なサイズの画像で―

00:25:49.516 --> 00:25:53.487 align:start position:32% line:-2
このモデルは
トレーニングをします

00:25:53.787 --> 00:25:58.959 align:start position:23% line:-2
でも 撮影される画像のサイズは
さまざまですね

00:25:59.760 --> 00:26:05.132 align:start position:30% line:-2
そこで Visionが
その画像を処理して

00:25:59.760 --> 00:26:05.132 align:start position:30% line:-2
そこで Visionが
その画像を処理して

00:26:05.232 --> 00:26:09.136 align:start position:29% line:-2
RGB変換や
サイズ縮小をしてくれます

00:26:09.403 --> 00:26:14.741 align:start position:27% line:-2
Visionの働きにより
画像処理が容易になるのです

00:26:17.377 --> 00:26:21.949 align:start position:29% line:-2
続いて 物体認識について
説明しましょう

00:26:24.451 --> 00:26:28.722 align:start position:30% line:-2
なお クロワッサンが
危険な目に遭いますので

00:26:28.822 --> 00:26:31.258 align:start position:27% line:-1
気が弱い方はご注意ください

00:26:34.528 --> 00:26:37.898 align:start position:32% line:-1
物体認識に用いるのは

00:26:37.998 --> 00:26:42.903 align:start position:32% line:-2
YOLOという技術に
基づいたモデルです

00:26:43.003 --> 00:26:46.206 align:start position:29% line:-1
極めて速度が速いモデルで

00:26:46.306 --> 00:26:50.711 align:start position:32% line:-2
境界ボックスや
ラベルを取得できます

00:26:50.811 --> 00:26:54.181 align:start position:32% line:-2
さらに複数の対象物を
検出します

00:26:57.417 --> 00:27:00.954 align:start position:34% line:-2
位置が分かることも
利点ですが

00:26:57.417 --> 00:27:00.954 align:start position:34% line:-2
位置が分かることも
利点ですが

00:27:01.054 --> 00:27:06.326 align:start position:29% line:-2
総合的な分類器ほど
分類が得意ではありません

00:27:07.327 --> 00:27:10.597 align:start position:30% line:-2
画像認識より多く
トレーニングが必要です

00:27:10.697 --> 00:27:15.769 align:start position:21% line:-2
昨日のセッションでは
Turi Createを用いた―

00:27:15.869 --> 00:27:20.007 align:start position:34% line:-2
トレーニング方法の
実演がありましたね

00:27:21.708 --> 00:27:24.912 align:start position:25% line:-1
では デモをお見せしましょう

00:27:30.551 --> 00:27:32.553 align:start position:34% line:-1
ロボットの店は閉店

00:27:35.422 --> 00:27:36.690 align:start position:38% line:-1
朝食の時間です

00:27:42.196 --> 00:27:43.130 align:start position:45% line:-1
では―

00:27:43.897 --> 00:27:49.703 align:start position:16% line:-2
Breakfast Finderという
アプリケーションを起動します

00:27:52.206 --> 00:27:55.008 align:start position:34% line:-2
クロワッサンが
認識されていますね

00:27:55.209 --> 00:27:58.645 align:start position:29% line:-1
それにベーグルとバナナも

00:28:00.147 --> 00:28:03.817 align:start position:34% line:-2
フレーム内の全てを
認識できています

00:28:04.785 --> 00:28:08.989 align:start position:32% line:-2
料理番組の場合
作り方を見せながらも

00:28:09.089 --> 00:28:11.658 align:start position:32% line:-2
実は事前に
完成版が出来ています

00:28:12.459 --> 00:28:14.361 align:start position:29% line:-1
でも このクロワッサンは

00:28:14.461 --> 00:28:19.299 align:start position:32% line:-2
モデルよりも
ずっと新しいはずです

00:28:20.067 --> 00:28:21.568 align:start position:41% line:-1
(笑い声)

00:28:21.668 --> 00:28:22.703 align:start position:45% line:-1
確かに

00:28:24.104 --> 00:28:25.572 align:start position:36% line:-1
クロワッサンです

00:28:25.973 --> 00:28:31.578 align:start position:43% line:-1
(拍手)

00:28:34.314 --> 00:28:35.082 align:start position:45% line:-1
さて…

00:28:35.349 --> 00:28:37.017 align:start position:41% line:-1
(笑い声)

00:28:38.385 --> 00:28:40.654 align:start position:30% line:-1
なかなか飲み込めません

00:28:41.188 --> 00:28:42.256 align:start position:41% line:-1
(笑い声)

00:28:44.491 --> 00:28:47.261 align:start position:30% line:-1
コードを確認しましょう

00:28:53.133 --> 00:28:55.035 align:start position:30% line:-1
相違点はどこでしょう？

00:28:56.069 --> 00:28:59.206 align:start position:29% line:-1
リクエストの設定方法です

00:28:59.706 --> 00:29:05.746 align:start position:23% line:-2
先ほどと同じように
Core MLモデルを使います

00:28:59.706 --> 00:29:05.746 align:start position:23% line:-2
先ほどと同じように
Core MLモデルを使います

00:29:05.846 --> 00:29:07.848 align:start position:34% line:-1
リクエストを作って

00:29:08.382 --> 00:29:12.319 align:start position:25% line:-1
結果をどう出力するか決めます

00:29:17.357 --> 00:29:21.395 align:start position:23% line:-1
これを容易にする方法があります

00:29:21.762 --> 00:29:26.366 align:start position:32% line:-2
ここに 新しい
オブジェクトである―

00:29:26.467 --> 00:29:31.405 align:start position:0% line:-2
VNRecognizedObjectObservationが
ありますね

00:29:31.505 --> 00:29:37.077 align:start position:30% line:-2
これで 境界ボックスや
ラベルが得られます

00:29:37.911 --> 00:29:40.147 align:start position:29% line:-1
ここで１つ お見せします

00:29:40.914 --> 00:29:43.817 align:start position:34% line:-2
アプリケーションを
起動しましょう

00:29:51.325 --> 00:29:52.292 align:start position:46% line:-1
よし

00:29:53.927 --> 00:29:56.063 align:start position:23% line:-1
ブレークポイントで停止しました

00:29:56.163 --> 00:30:01.802 align:start position:29% line:-2
では 結果が１つに
絞られる経緯を説明します

00:29:56.163 --> 00:30:01.802 align:start position:29% line:-2
では 結果が１つに
絞られる経緯を説明します

00:30:04.471 --> 00:30:05.772 align:start position:34% line:-1
この部分を使って…

00:30:11.478 --> 00:30:17.651 align:start position:2% line:-2
“objectObservation.labels”と
入力します

00:30:19.486 --> 00:30:23.190 align:start position:36% line:-2
ご覧のとおり
結果は複数出ます

00:30:23.290 --> 00:30:25.359 align:start position:36% line:-1
ベーグルにバナナ

00:30:25.459 --> 00:30:28.028 align:start position:30% line:-1
コーヒーはありませんが

00:30:28.128 --> 00:30:30.731 align:start position:32% line:-1
クロワッサンや卵など

00:30:30.831 --> 00:30:34.835 align:start position:36% line:-2
確率の高い順番に
分類されています

00:30:34.935 --> 00:30:40.107 align:start position:29% line:-2
だから １番目を読み取る
設定にしているのです

00:30:40.207 --> 00:30:44.444 align:start position:29% line:-2
分類結果には
登録した全ての物の名称が

00:30:44.711 --> 00:30:47.347 align:start position:30% line:-1
出るようになっています

00:30:48.549 --> 00:30:54.555 align:start position:14% line:-2
Breakfast Finderを閉じて
再びスライドに戻りましょう

00:30:58.425 --> 00:31:02.196 align:start position:29% line:-2
この機能を可能にしたのが
新しいAPIの―

00:30:58.425 --> 00:31:02.196 align:start position:29% line:-2
この機能を可能にしたのが
新しいAPIの―

00:31:02.296 --> 00:31:05.399 align:start position:0% line:-2
VNRecognizedObjectObservation
です

00:31:07.201 --> 00:31:11.371 align:start position:30% line:-2
Core MLモデルの
リクエストが実行され

00:31:11.472 --> 00:31:17.411 align:start position:29% line:-2
かつ 物体認識を行う場合
自動的に出てきます

00:31:20.881 --> 00:31:23.750 align:start position:29% line:-1
YOLOを基にしています

00:31:23.851 --> 00:31:29.056 align:start position:29% line:-2
YOLOは目新しくないと
思うかもしれませんが

00:31:29.790 --> 00:31:34.461 align:start position:30% line:-2
今までは多くのコードが
必要でしたね

00:31:34.561 --> 00:31:38.899 align:start position:23% line:-1
これなら たった数行で済むので

00:31:38.999 --> 00:31:41.702 align:start position:23% line:-1
YOLOモデルを簡単に使えます

00:31:42.069 --> 00:31:44.071 align:start position:32% line:-1
コードに戻りましょう

00:31:44.204 --> 00:31:48.375 align:start position:32% line:-2
モデルを作成したら
リクエストを作ります

00:31:48.876 --> 00:31:50.844 align:start position:38% line:-1
完了ハンドラは

00:31:50.978 --> 00:31:55.682 align:start position:23% line:-1
複数の対象物の領域を確認します

00:31:55.916 --> 00:32:00.420 align:start position:29% line:-2
さらに 境界ボックスや
ラベルを提示してくれます

00:31:55.916 --> 00:32:00.420 align:start position:29% line:-2
さらに 境界ボックスや
ラベルを提示してくれます

00:32:04.057 --> 00:32:07.161 align:start position:25% line:-1
１つ補足したいことがあります

00:32:08.328 --> 00:32:13.934 align:start position:21% line:-2
フレームごとに検出を実行したので
画面上で四角形が揺れていました

00:32:14.902 --> 00:32:18.005 align:start position:29% line:-2
トラッキングを
用いたほうがよいでしょう

00:32:18.605 --> 00:32:23.510 align:start position:30% line:-2
モデルを通常より速く
実行させられるからです

00:32:25.145 --> 00:32:29.850 align:start position:29% line:-2
トラッキングリクエストは
時間がかかりません

00:32:31.185 --> 00:32:35.889 align:start position:29% line:-2
画面上で対象物を追う際に
トラッキングをすると

00:32:37.024 --> 00:32:39.660 align:start position:34% line:-1
動作が速くなります

00:32:39.793 --> 00:32:42.963 align:start position:32% line:-2
しかもスムージングが
可能なので

00:32:43.063 --> 00:32:45.866 align:start position:29% line:-1
四角形の揺れも収まります

00:32:45.966 --> 00:32:50.270 align:start position:25% line:-2
実際に動きが
滑らかになった実例もあります

00:32:50.838 --> 00:32:52.873 align:start position:30% line:-1
トラッキングについては

00:32:54.041 --> 00:32:59.947 align:start position:27% line:-2
前のセッションで実装などの
詳しい話がありました

00:33:01.949 --> 00:33:02.883 align:start position:43% line:-1
最後に―

00:33:03.250 --> 00:33:07.988 align:start position:29% line:-2
Visionに関して
理解を深めていきましょう

00:33:08.822 --> 00:33:12.192 align:start position:25% line:-2
Visionフレームワークの
注意点があります

00:33:12.860 --> 00:33:18.432 align:start position:29% line:-2
まず よく問題となるのが
画像の向きです

00:33:19.900 --> 00:33:23.871 align:start position:30% line:-2
幾つかのVisionや
新しい顔検出機能には

00:33:23.971 --> 00:33:28.842 align:start position:27% line:-2
画像の向きに
依存しないものもありますが

00:33:29.042 --> 00:33:30.978 align:start position:36% line:-1
以前は違いました

00:33:32.045 --> 00:33:35.716 align:start position:30% line:-2
正しい向きを
把握する必要があります

00:33:36.283 --> 00:33:41.989 align:start position:27% line:-2
しかも 自分が見た向きと
ディスクに保存された向きが

00:33:42.089 --> 00:33:44.291 align:start position:32% line:-1
違う場合もあるのです

00:33:44.925 --> 00:33:50.197 align:start position:14% line:-2
EXIF orientationがあれば
向きが特定できます

00:33:51.131 --> 00:33:57.971 align:start position:30% line:-2
EXIFは撮影時に
正しい方向を把握します

00:33:58.071 --> 00:34:02.443 align:start position:20% line:-1
その情報がVisionに送られると

00:33:58.071 --> 00:34:02.443 align:start position:20% line:-1
その情報がVisionに送られると

00:34:02.576 --> 00:34:08.114 align:start position:27% line:-2
Visionが情報を取得し
調整してくれるのです

00:34:09.149 --> 00:34:13.587 align:start position:25% line:-2
しかし 先ほどのデモのように
動画の場合は

00:34:13.687 --> 00:34:16.089 align:start position:32% line:-1
自分で情報を送ります

00:34:16.188 --> 00:34:21.428 align:start position:12% line:-2
そこで UIDevice.current.
orientationを確認し

00:34:21.527 --> 00:34:27.167 align:start position:2% line:-2
CGImagePropertyOrientationに
変換します

00:34:29.369 --> 00:34:32.306 align:start position:30% line:-1
次は座標系についてです

00:34:33.373 --> 00:34:36.543 align:start position:34% line:-2
Visionの場合
原点は左下隅です

00:34:37.710 --> 00:34:43.217 align:start position:32% line:-2
そして画像に沿って
垂直に処理されるため

00:34:43.317 --> 00:34:45.418 align:start position:34% line:-1
向きが重要なのです

00:34:47.187 --> 00:34:50.591 align:start position:32% line:-2
正規化された座標上で
処理されますが

00:34:50.891 --> 00:34:54.527 align:start position:27% line:-2
ピクセル数が不明な
レジストレーションは別です

00:34:54.761 --> 00:35:00.801 align:start position:21% line:-2
正規座標系とは 座標が0.0から
1.1までの範囲のものです

00:34:54.761 --> 00:35:00.801 align:start position:21% line:-2
正規座標系とは 座標が0.0から
1.1までの範囲のものです

00:35:02.302 --> 00:35:07.174 align:start position:27% line:-2
画像上で顔とランドマークが
検出されています

00:35:07.441 --> 00:35:10.110 align:start position:30% line:-1
境界ボックスが表示され

00:35:10.210 --> 00:35:15.716 align:start position:29% line:-2
その中にランドマークと
その座標が示されています

00:35:17.184 --> 00:35:21.789 align:start position:25% line:-2
座標空間に戻る際は関数と
VNUtils.hを用います

00:35:21.889 --> 00:35:27.694 align:start position:0% line:-2
VNImageRectForNormalizedRectが
変換するのと同じです

00:35:31.298 --> 00:35:36.970 align:start position:27% line:-2
続いて 先ほども登場した
信頼スコアについて話します

00:35:38.705 --> 00:35:43.110 align:start position:30% line:-2
アルゴリズムによる
分類結果とその信頼度は

00:35:43.844 --> 00:35:50.284 align:start position:27% line:-2
結果を分析する上で
とても重要な要素となります

00:35:50.384 --> 00:35:54.588 align:start position:34% line:-2
０は信頼度が低く
１では高くなります

00:35:58.892 --> 00:35:59.660 align:start position:43% line:-1
クリック

00:36:02.262 --> 00:36:03.263 align:start position:43% line:-1
出ました

00:36:03.364 --> 00:36:06.366 align:start position:32% line:-2
残念ながら
アルゴリズムによって

00:36:06.467 --> 00:36:10.337 align:start position:34% line:-2
信頼スコアの基準は
異なります

00:36:10.437 --> 00:36:16.477 align:start position:27% line:-2
例えば テキスト検出の場合
信頼スコアは いつも１です

00:36:16.610 --> 00:36:20.614 align:start position:29% line:-2
検出できなければ
何も実行されないからです

00:36:21.181 --> 00:36:27.287 align:start position:29% line:-2
しかし 分類器は
幅広いスコアを提示します

00:36:27.521 --> 00:36:28.889 align:start position:38% line:-1
例を見てみます

00:36:30.591 --> 00:36:35.662 align:start position:30% line:-2
最初は ロボットの店の
商品画像です

00:36:36.063 --> 00:36:37.931 align:start position:32% line:-1
モデルに分類させると

00:36:38.298 --> 00:36:42.369 align:start position:27% line:-2
“ステッピングモーター”と
高スコアで出ました

00:36:43.637 --> 00:36:45.539 align:start position:39% line:-1
次の画像では

00:36:45.806 --> 00:36:49.076 align:start position:27% line:-2
ギャラリーにあったモデルを
使います

00:36:49.710 --> 00:36:52.980 align:start position:34% line:-2
モデルの能力を
比べるわけではなく

00:36:53.080 --> 00:36:57.751 align:start position:34% line:-2
結果や信頼スコアを
分析するためです

00:36:58.485 --> 00:37:02.089 align:start position:36% line:-2
では 分類結果を
見てみましょう

00:36:58.485 --> 00:37:02.089 align:start position:36% line:-2
では 分類結果を
見てみましょう

00:37:03.390 --> 00:37:07.961 align:start position:30% line:-2
悪くない結果ですが
自信は なさそうですね

00:37:08.062 --> 00:37:11.899 align:start position:21% line:-1
信頼スコアは0.395と低めです

00:37:11.999 --> 00:37:15.202 align:start position:30% line:-2
でも“砂”や“浜辺”は
合っていますよね

00:37:15.436 --> 00:37:19.606 align:start position:34% line:-2
画像を探す時には
使えると思いますが

00:37:19.707 --> 00:37:23.043 align:start position:34% line:-2
ラベルにできるかは
疑問が残ります

00:37:24.244 --> 00:37:25.846 align:start position:38% line:-1
続いてはこちら

00:37:26.980 --> 00:37:30.384 align:start position:34% line:-2
スクーターと女性が
写っています

00:37:31.752 --> 00:37:34.621 align:start position:34% line:-2
“サツマイモ”とは
心外でしょうね

00:37:34.721 --> 00:37:36.356 align:start position:41% line:-1
(笑い声)

00:37:39.393 --> 00:37:41.228 align:start position:36% line:-1
さらに もう１つ

00:37:41.562 --> 00:37:43.397 align:start position:36% line:-1
コードの画像です

00:37:44.097 --> 00:37:45.966 align:start position:39% line:-1
分類結果は？

00:37:47.267 --> 00:37:50.270 align:start position:27% line:-2
愚かなことに
“ウェブサイト”だそうです

00:37:53.507 --> 00:37:56.510 align:start position:34% line:-2
信頼スコアについて
まとめます

00:37:58.245 --> 00:38:02.683 align:start position:27% line:-2
スコアが1.0でも
100％正解ではありません

00:37:58.245 --> 00:38:02.683 align:start position:27% line:-2
スコアが1.0でも
100％正解ではありません

00:38:02.783 --> 00:38:05.152 align:start position:36% line:-2
アルゴリズムには
沿っていますが

00:38:05.252 --> 00:38:10.057 align:start position:29% line:-2
先ほどの例のように
人間の認識と差があります

00:38:11.391 --> 00:38:16.730 align:start position:27% line:-2
よって アプリケーションに
使う時はご注意ください

00:38:16.830 --> 00:38:20.701 align:start position:32% line:-2
例えば 医療用の
アプリケーションなら

00:38:21.168 --> 00:38:25.172 align:start position:34% line:-2
結果の精度によって
病気の告知方法に

00:38:25.272 --> 00:38:28.075 align:start position:34% line:-1
配慮が必要でしょう

00:38:30.577 --> 00:38:33.313 align:start position:25% line:-1
ここで使える技が２つあります

00:38:33.414 --> 00:38:39.286 align:start position:27% line:-2
デモのように 信頼スコアに
しきい値を用いる方法が１つ

00:38:39.386 --> 00:38:43.223 align:start position:34% line:-2
信頼度の低い結果が
除去されます

00:38:43.590 --> 00:38:49.296 align:start position:23% line:-2
画像検索アプリケーションの中で
使う方法が２つ目です

00:38:49.396 --> 00:38:51.565 align:start position:36% line:-1
スコアが低くても

00:38:51.665 --> 00:38:56.103 align:start position:32% line:-2
正解が含まれる場合が
あるからです

00:39:01.074 --> 00:39:04.745 align:start position:23% line:-2
さらに詳しい情報は
デベロッパWebサイトでどうぞ

00:39:04.845 --> 00:39:08.515 align:start position:34% line:-2
明日15時から
ラボも行いますので

00:39:08.615 --> 00:39:10.851 align:start position:32% line:-1
ぜひ ご参加ください

00:39:11.585 --> 00:39:16.924 align:start position:25% line:-2
アプリケーションデベロッパの
皆さんに感謝します

00:39:17.024 --> 00:39:19.793 align:start position:29% line:-1
今後も楽しみにしています

00:39:19.893 --> 00:39:23.397 align:start position:25% line:-1
ご来場ありがとうございました

00:39:23.497 --> 00:39:27.801 align:start position:43% line:-1
(拍手)
