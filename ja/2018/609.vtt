WEBVTT

00:00:06.974 --> 00:00:14.948 align:start position:43% line:-1
(音楽)

00:00:21.121 --> 00:00:27.027 align:start position:43% line:-1
(拍手)

00:00:29.730 --> 00:00:35.002 align:start position:0% line:-2
Metal for Accelerating Machine
Learningのセッションへようこそ

00:00:35.435 --> 00:00:39.640 align:start position:27% line:-2
GPUソフトウェアチームの
アナ･チコノバです

00:00:42.843 --> 00:00:46.213 align:start position:29% line:-2
Metalをベースとする
MPSフレームワークは

00:00:46.446 --> 00:00:48.916 align:start position:21% line:-1
iOSとmacOSに最適化した―

00:00:49.016 --> 00:00:52.152 align:start position:21% line:-2
GPUで加速化したプリミティブを
提供します

00:00:52.753 --> 00:00:57.858 align:start position:29% line:-2
画像処理や機械学習などの
プリミティブです

00:00:58.492 --> 00:01:04.631 align:start position:23% line:-2
過去のWWDCで “推論”に
関するセッションがありましたが

00:00:58.492 --> 00:01:04.631 align:start position:23% line:-2
過去のWWDCで “推論”に
関するセッションがありましたが

00:01:06.300 --> 00:01:11.438 align:start position:25% line:-2
今年はiOSとmacOS上の
“訓練”に関する話もします

00:01:11.872 --> 00:01:15.676 align:start position:43% line:-1
(拍手)

00:01:15.776 --> 00:01:16.610 align:start position:45% line:-1
どうも

00:01:18.712 --> 00:01:22.449 align:start position:27% line:-2
レイトレーシングの高速化の
サポートについても

00:01:22.549 --> 00:01:26.420 align:start position:29% line:-2
今週前半に
セッションが行われました

00:01:26.520 --> 00:01:29.389 align:start position:11% line:-2
Metal for Ray
Tracing Accelerationです

00:01:29.690 --> 00:01:33.393 align:start position:32% line:-2
ビデオはオンラインで
まもなく公開されます

00:01:34.261 --> 00:01:39.166 align:start position:29% line:-2
ここでは機械学習の
主に訓練について話します

00:01:42.069 --> 00:01:44.204 align:start position:30% line:-1
訓練と推論は関係します

00:01:44.571 --> 00:01:49.810 align:start position:21% line:-2
ディープラーニングアルゴリズムの
第１フェーズは訓練です

00:01:50.310 --> 00:01:53.447 align:start position:29% line:-1
例を使って説明しましょう

00:01:53.547 --> 00:01:58.719 align:start position:32% line:-2
猫や犬などのクラスに
画像を分類する例です

00:01:59.853 --> 00:02:03.023 align:start position:36% line:-2
猫を認識するよう
訓練するには

00:01:59.853 --> 00:02:03.023 align:start position:36% line:-2
猫を認識するよう
訓練するには

00:02:03.123 --> 00:02:06.760 align:start position:29% line:-2
ラベル付けした猫の画像を
大量に与えます

00:02:06.960 --> 00:02:12.332 align:start position:23% line:-2
認識させたい他の動物についても
同様の処理をします

00:02:13.967 --> 00:02:18.705 align:start position:27% line:-2
訓練はコストと時間がかかる
反復プロセスです

00:02:19.306 --> 00:02:22.142 align:start position:27% line:-2
訓練の結果は
学習済みパラメータとなり―

00:02:24.611 --> 00:02:28.348 align:start position:34% line:-2
次の推論フェーズに
必要になります

00:02:28.649 --> 00:02:31.585 align:start position:36% line:-2
初めて見る画像を
分類するには

00:02:31.685 --> 00:02:37.157 align:start position:25% line:-2
“これは猫だ”という学習済み
パラメータが元になるのです

00:02:38.192 --> 00:02:43.130 align:start position:23% line:-2
訓練と推論の両方に
GPUによる加速化を提供します

00:02:45.732 --> 00:02:51.405 align:start position:27% line:-2
その前に 今年追加された
CNN推論の話をしましょう

00:02:51.872 --> 00:02:54.842 align:start position:29% line:-2
畳み込みと転置畳み込みの
プリミティブに

00:02:54.942 --> 00:02:58.412 align:start position:34% line:-2
FP16の蓄積を
サポートする機能は

00:02:58.846 --> 00:03:03.517 align:start position:12% line:-2
Apple A11 Bionic GPUで
利用できます

00:02:58.846 --> 00:03:03.517 align:start position:12% line:-2
Apple A11 Bionic GPUで
利用できます

00:03:04.284 --> 00:03:08.455 align:start position:34% line:-2
FP16の蓄積を
推論に使用するのは

00:03:08.555 --> 00:03:14.494 align:start position:27% line:-2
ニューラルネットワークでは
精度の点で十分です

00:03:15.495 --> 00:03:20.434 align:start position:25% line:-2
FP16は精度とパワーの面で
大きなメリットがあるので

00:03:20.534 --> 00:03:24.338 align:start position:36% line:-2
ぜひ 推論作業に
活用してください

00:03:25.572 --> 00:03:30.878 align:start position:23% line:-2
これは畳み込みのプリミティブに
FP16の蓄積を利用する例です

00:03:30.978 --> 00:03:34.314 align:start position:2% line:-2
accumulatorPrecisionOptionを
設定するだけです

00:03:36.617 --> 00:03:42.923 align:start position:21% line:-2
今回のメインテーマは
ニューラルネットワークの訓練です

00:03:43.023 --> 00:03:46.059 align:start position:25% line:-1
まず CNNから始めましょう

00:03:48.762 --> 00:03:52.032 align:start position:36% line:-2
手書き数字認識
ネットワークです

00:03:53.133 --> 00:03:56.403 align:start position:29% line:-1
手書き画像が入力されると

00:03:56.803 --> 00:04:00.774 align:start position:25% line:-2
０～９のうち
どれか１つがアサインされます

00:03:56.803 --> 00:04:00.774 align:start position:25% line:-2
０～９のうち
どれか１つがアサインされます

00:04:01.542 --> 00:04:06.647 align:start position:30% line:-2
例では数字７の画像が
正しく分類されています

00:04:09.283 --> 00:04:13.320 align:start position:32% line:-2
推論のための
訓練済みパラメータが

00:04:13.921 --> 00:04:19.526 align:start position:25% line:-2
畳み込みと完全に接続された
プリミティブに重みを加えます

00:04:20.293 --> 00:04:23.597 align:start position:27% line:-2
目標は
訓練済みパラメータを計算し

00:04:23.697 --> 00:04:28.735 align:start position:36% line:-2
推論中に出力を
修正することです

00:04:30.304 --> 00:04:34.775 align:start position:30% line:-2
重みは最初からないので
計算が必要なため

00:04:34.942 --> 00:04:39.813 align:start position:25% line:-2
まず 小さな ランダムな数で
重みを初期化します

00:04:39.913 --> 00:04:41.882 align:start position:34% line:-1
これで準備完了です

00:04:41.982 --> 00:04:45.552 align:start position:30% line:-2
では 訓練プロセスの
全ステップを見ましょう

00:04:47.988 --> 00:04:53.460 align:start position:27% line:-2
訓練は反復プロセスです
４つのステップからなります

00:04:53.894 --> 00:04:55.762 align:start position:32% line:-1
最初がフォワードパス

00:04:55.863 --> 00:05:00.601 align:start position:29% line:-2
入力をネットワークに渡し
出力を作ります

00:04:55.863 --> 00:05:00.601 align:start position:29% line:-2
入力をネットワークに渡し
出力を作ります

00:05:00.934 --> 00:05:02.836 align:start position:34% line:-1
推論に似ていますね

00:05:04.137 --> 00:05:06.206 align:start position:32% line:-1
次に損失を計算します

00:05:06.473 --> 00:05:11.411 align:start position:34% line:-2
損失とは出力と
正解データの差です

00:05:13.180 --> 00:05:16.717 align:start position:29% line:-2
訓練アルゴリズムの目的は
損失の最小化です

00:05:18.685 --> 00:05:21.054 align:start position:29% line:-1
次のステップは勾配のパス

00:05:21.388 --> 00:05:25.859 align:start position:34% line:-2
出力と正解の差を
ネットワークに戻し

00:05:25.959 --> 00:05:29.229 align:start position:30% line:-1
重みを更新することです

00:05:29.830 --> 00:05:35.135 align:start position:27% line:-2
訓練の継続でネットワークは
より訓練されるのです

00:05:35.235 --> 00:05:39.139 align:start position:34% line:-2
入力のマッピングで
出力を修正でき

00:05:39.673 --> 00:05:41.909 align:start position:29% line:-1
損失の最小化を促進します

00:05:43.177 --> 00:05:47.981 align:start position:21% line:-2
概要は以上です　次は各ステップを
詳細に見ていきます

00:05:50.317 --> 00:05:55.355 align:start position:27% line:-2
フォワードパスは
出力計算のための順伝播です

00:05:56.023 --> 00:06:00.961 align:start position:27% line:-2
訓練当初は ネットワークが
うまく機能しません

00:05:56.023 --> 00:06:00.961 align:start position:27% line:-2
訓練当初は ネットワークが
うまく機能しません

00:06:01.728 --> 00:06:05.365 align:start position:34% line:-2
なぜ間違った結果に
なるのでしょう

00:06:05.499 --> 00:06:09.570 align:start position:30% line:-2
それは想定内ですが
重みを初期化したためで

00:06:09.670 --> 00:06:12.272 align:start position:32% line:-1
訓練がまだだからです

00:06:13.807 --> 00:06:20.013 align:start position:23% line:-2
そこで ネットワークの成績を
数値化する重みが必要になります

00:06:20.113 --> 00:06:23.784 align:start position:32% line:-2
この情報を使い
重みを改善することで

00:06:23.884 --> 00:06:28.455 align:start position:30% line:-2
訓練を続ければ
良い結果が出るはずです

00:06:30.123 --> 00:06:34.428 align:start position:29% line:-2
そのためには まず
正解を知らねばなりません

00:06:34.795 --> 00:06:37.931 align:start position:32% line:-2
今から 正解データを
ラベルと呼びます

00:06:38.031 --> 00:06:41.535 align:start position:23% line:-2
入力画像とともに入れる
ネットワークへの入力のことです

00:06:42.202 --> 00:06:44.371 align:start position:32% line:-2
ここでは
10の値のベクトルで

00:06:44.471 --> 00:06:49.243 align:start position:30% line:-2
正解の７に１
他は０をアサインします

00:06:51.512 --> 00:06:56.016 align:start position:25% line:-2
各クラスにつき
10分の１の確率で出力します

00:06:56.383 --> 00:06:58.919 align:start position:29% line:-1
ご覧のように訓練の最初は

00:06:59.019 --> 00:07:03.323 align:start position:32% line:-2
ネットワークの正解が
非常に低いです

00:06:59.019 --> 00:07:03.323 align:start position:32% line:-2
ネットワークの正解が
非常に低いです

00:07:03.490 --> 00:07:07.261 align:start position:38% line:-2
９に最高確率を
アサインします

00:07:07.361 --> 00:07:10.097 align:start position:29% line:-1
答えに９を出したからです

00:07:11.331 --> 00:07:15.969 align:start position:27% line:-2
この情報を全部
損失プリミティブに渡します

00:07:18.572 --> 00:07:20.674 align:start position:34% line:-1
先ほど述べたように

00:07:21.341 --> 00:07:26.680 align:start position:29% line:-2
損失は出力と
正解データの差を測ります

00:07:27.381 --> 00:07:30.684 align:start position:32% line:-2
アルゴリズムの目的は
損失の最小化です

00:07:32.219 --> 00:07:34.788 align:start position:30% line:-1
後半のグラフも使います

00:07:36.456 --> 00:07:40.294 align:start position:29% line:-2
勾配プリミティブは
フォワードプリミティブに

00:07:40.394 --> 00:07:42.529 align:start position:38% line:-1
対応しています

00:07:42.696 --> 00:07:47.901 align:start position:32% line:-2
勾配プリミティブは
重みの更新に必要です

00:07:49.770 --> 00:07:54.274 align:start position:30% line:-2
損失プリミティブは
最初の勾配を計算します

00:07:54.374 --> 00:07:58.078 align:start position:32% line:-2
これは入力に関する
損失関数の派生物です

00:07:58.178 --> 00:08:03.884 align:start position:23% line:-2
そして この勾配を
ネットワークを通じ逆伝播します

00:07:58.178 --> 00:08:03.884 align:start position:23% line:-2
そして この勾配を
ネットワークを通じ逆伝播します

00:08:03.984 --> 00:08:09.323 align:start position:29% line:-2
最初の勾配プリミティブが
逆向きに送られるのです

00:08:09.423 --> 00:08:13.126 align:start position:20% line:-2
ここでは
SoftMax勾配プリミティブです

00:08:13.961 --> 00:08:19.366 align:start position:25% line:-2
連鎖率を使うと
勾配の逆伝播が可能になります

00:08:20.400 --> 00:08:24.104 align:start position:36% line:-2
勾配を計算し
重みを更新します

00:08:24.204 --> 00:08:29.510 align:start position:29% line:-2
各反復で重みに適用する
微小なデルタを計算します

00:08:31.245 --> 00:08:35.414 align:start position:34% line:-2
更新された重みは
次の訓練反復に使い

00:08:35.849 --> 00:08:39.986 align:start position:32% line:-2
損失値が
低くなるのが理想です

00:08:43.357 --> 00:08:45.993 align:start position:34% line:-1
実際の訓練状況では

00:08:46.226 --> 00:08:48.862 align:start position:36% line:-1
単一画像ではなく

00:08:48.962 --> 00:08:52.132 align:start position:32% line:-2
画像のグループまたは
バッチを使います

00:08:52.232 --> 00:08:55.435 align:start position:27% line:-2
例えば
32または64のバッチです

00:08:55.802 --> 00:09:00.474 align:start position:29% line:-2
損失計算には対応する
ラベルのバッチが必要です

00:08:55.802 --> 00:09:00.474 align:start position:29% line:-2
損失計算には対応する
ラベルのバッチが必要です

00:09:00.574 --> 00:09:03.143 align:start position:27% line:-1
この場合のラベルのバッチは

00:09:03.243 --> 00:09:06.780 align:start position:36% line:-2
１が正しいクラス
他が０となります

00:09:09.416 --> 00:09:11.084 align:start position:38% line:-1
訓練で使うのは

00:09:11.185 --> 00:09:15.789 align:start position:27% line:-2
異なる画像のバッチと
対応するラベルのバッチです

00:09:15.956 --> 00:09:18.859 align:start position:29% line:-1
訓練反復を実行しましょう

00:09:21.361 --> 00:09:26.133 align:start position:29% line:-2
最初の画像のバッチに対し
フォワードパス 損失計算

00:09:26.233 --> 00:09:30.204 align:start position:34% line:-2
勾配のパス
重み更新を行います

00:09:30.504 --> 00:09:34.041 align:start position:34% line:-2
２つ目のバッチの
プロセスも同じです

00:09:34.141 --> 00:09:38.979 align:start position:29% line:-2
フォワードパス 損失計算
勾配のパス 重み更新です

00:09:40.013 --> 00:09:46.186 align:start position:25% line:-2
訓練の反復を続け
ネットワークの損失を減少させ

00:09:46.587 --> 00:09:49.356 align:start position:34% line:-1
精度を向上させます

00:09:49.490 --> 00:09:50.824 align:start position:38% line:-1
訓練を続けます

00:09:50.924 --> 00:09:53.994 align:start position:30% line:-2
損失が
特定のしきい値を下回り

00:09:54.094 --> 00:09:57.931 align:start position:34% line:-2
ネットワーク精度が
希望水準になれば

00:09:58.665 --> 00:10:00.667 align:start position:38% line:-1
訓練は十分です

00:09:58.665 --> 00:10:00.667 align:start position:38% line:-1
訓練は十分です

00:10:00.767 --> 00:10:04.605 align:start position:25% line:-2
計算した訓練済みパラメータを
推論に使えます

00:10:04.738 --> 00:10:08.976 align:start position:21% line:-1
次は MPSフレームワークを使い

00:10:09.076 --> 00:10:11.678 align:start position:29% line:-2
ニューラルネットワークを
訓練します

00:10:11.879 --> 00:10:15.849 align:start position:27% line:-2
グラフの抽象化を利用すれば
ネットワークは

00:10:15.949 --> 00:10:19.520 align:start position:32% line:-2
MPSでは
グラフとして描けます

00:10:20.821 --> 00:10:22.890 align:start position:29% line:-1
まず 訓練グラフを作成し

00:10:24.391 --> 00:10:29.229 align:start position:23% line:-2
入力データを準備し 重みを指定
グラフを実行します

00:10:29.329 --> 00:10:35.002 align:start position:23% line:-2
フォワードパス 損失計算
勾配のパス 重み更新を行います

00:10:35.802 --> 00:10:41.074 align:start position:30% line:-2
訓練は反復プロセスで
多数の反復が必要ですが

00:10:41.174 --> 00:10:43.977 align:start position:34% line:-2
やめる時期を
知る必要もあります

00:10:44.077 --> 00:10:47.381 align:start position:34% line:-2
では 各トピックの
詳細を見ましょう

00:10:47.681 --> 00:10:50.717 align:start position:29% line:-1
訓練グラフの作成からです

00:10:52.619 --> 00:10:54.054 align:start position:38% line:-1
繰り返しますが

00:10:54.154 --> 00:10:56.957 align:start position:20% line:-2
MPSでは ニューラルネットワーク
グラフAPIを使い

00:10:57.057 --> 00:10:58.625 align:start position:30% line:-1
ネットワークを描けます

00:10:59.059 --> 00:11:01.328 align:start position:32% line:-1
これは　手入力した―

00:10:59.059 --> 00:11:01.328 align:start position:32% line:-1
これは　手入力した―

00:11:01.428 --> 00:11:04.298 align:start position:30% line:-2
値認識のネットワークを
視覚化したものです

00:11:04.531 --> 00:11:09.403 align:start position:29% line:-2
中に画像ノードが見えます
小さな白いノードです

00:11:10.737 --> 00:11:16.910 align:start position:29% line:-2
画像ノードが記述するのは
入力 出力 中間結果です

00:11:18.745 --> 00:11:22.316 align:start position:23% line:-2
オペレーション間を
どうデータが動いたか記述します

00:11:22.683 --> 00:11:26.553 align:start position:29% line:-2
畳み込みやプーリングなど
データのオペレーションは

00:11:26.954 --> 00:11:30.257 align:start position:36% line:-2
フィルタノードで
記述されます

00:11:30.791 --> 00:11:34.795 align:start position:21% line:-2
一般的なニューラルネットワークの
作成に必要な全ノードを

00:11:34.895 --> 00:11:36.296 align:start position:34% line:-1
サポートしています

00:11:37.130 --> 00:11:41.068 align:start position:30% line:-2
ニューラルネットワーク
グラフAPIは簡単です

00:11:41.602 --> 00:11:48.408 align:start position:16% line:-2
これを使ったMPSImageNodeの
作成例を見ましょう

00:11:48.575 --> 00:11:52.779 align:start position:23% line:-2
これがグラフAPIを使い
畳み込みノードを作成した例です

00:11:53.313 --> 00:11:57.918 align:start position:27% line:-2
各フォワードノードに対する
訓練用勾配ノードを

00:11:58.018 --> 00:11:59.520 align:start position:34% line:-1
サポートしています

00:11:59.620 --> 00:12:03.957 align:start position:36% line:-2
勾配ノード作成の
コードは１行です

00:11:59.620 --> 00:12:03.957 align:start position:36% line:-2
勾配ノード作成の
コードは１行です

00:12:04.057 --> 00:12:08.228 align:start position:29% line:-2
これが畳み込みノードから
勾配畳み込みノードを

00:12:08.328 --> 00:12:09.897 align:start position:38% line:-1
作成する例です

00:12:12.966 --> 00:12:14.968 align:start position:30% line:-1
次はグラフを構築します

00:12:16.069 --> 00:12:18.205 align:start position:27% line:-1
これは小さいネットワークで

00:12:18.305 --> 00:12:21.141 align:start position:36% line:-2
畳み込みノード
プーリングノード

00:12:21.241 --> 00:12:23.277 align:start position:32% line:-2
別の畳み込みノードが
続きます

00:12:23.744 --> 00:12:29.249 align:start position:27% line:-2
これらのノードをグラフに
接続するのはとても簡単です

00:12:29.449 --> 00:12:33.587 align:start position:27% line:-1
あるノードの結果画像を取り

00:12:33.687 --> 00:12:38.091 align:start position:32% line:-2
ソース画像として
次のノードに渡します

00:12:38.859 --> 00:12:41.828 align:start position:38% line:-2
これでグラフが
結合されました

00:12:42.696 --> 00:12:44.932 align:start position:29% line:-1
次は訓練グラフを作ります

00:12:45.666 --> 00:12:48.769 align:start position:23% line:-1
まず グラフに損失ノードを追加

00:12:49.970 --> 00:12:51.772 align:start position:36% line:-1
勾配ノードもです

00:12:51.972 --> 00:12:56.009 align:start position:29% line:-2
これでフォワードノードに
対応する勾配ノードを

00:12:56.109 --> 00:12:58.145 align:start position:30% line:-1
１行のコードで作れます

00:12:58.245 --> 00:13:02.783 align:start position:30% line:-2
前と同じようにつなげば
訓練グラフの完成です

00:12:58.245 --> 00:13:02.783 align:start position:30% line:-2
前と同じようにつなげば
訓練グラフの完成です

00:13:05.686 --> 00:13:10.724 align:start position:27% line:-2
ご覧のようにグラフAPIは
使い方が簡単です

00:13:11.525 --> 00:13:13.093 align:start position:38% line:-1
グラフは自動で

00:13:13.193 --> 00:13:18.398 align:start position:30% line:-2
中間結果や出力画像まで
管理してくれます

00:13:19.099 --> 00:13:23.403 align:start position:32% line:-2
また中間画像に
メモリをエイリアスし

00:13:23.504 --> 00:13:27.975 align:start position:21% line:-2
Metalヒープで
メモリフットプリントを削減します

00:13:28.775 --> 00:13:34.515 align:start position:30% line:-2
グラフのノードを
融合することもできます

00:13:34.615 --> 00:13:39.620 align:start position:25% line:-2
不要なノードをカットするなど
最適化も可能です

00:13:40.254 --> 00:13:43.023 align:start position:34% line:-2
そして グラフは
自動でパディングと

00:13:43.123 --> 00:13:46.927 align:start position:30% line:-2
ステートオブジェクトの
管理もします

00:13:47.961 --> 00:13:50.330 align:start position:32% line:-2
ぜひ グラフAPIを
活用してください

00:13:54.768 --> 00:13:57.304 align:start position:30% line:-1
訓練グラフを作った後は

00:13:57.404 --> 00:14:01.608 align:start position:34% line:-2
グラフに渡す入力を
見ていきましょう

00:13:57.404 --> 00:14:01.608 align:start position:34% line:-2
グラフに渡す入力を
見ていきましょう

00:14:02.442 --> 00:14:07.548 align:start position:29% line:-2
まず GPUにグラフの
エンコードを呼び出します

00:14:08.849 --> 00:14:12.920 align:start position:32% line:-2
訓練では１枚ずつ
画像を送ることはなく

00:14:13.020 --> 00:14:16.323 align:start position:29% line:-2
画像のグループかバッチを
使います

00:14:16.423 --> 00:14:19.893 align:start position:32% line:-2
グラフへの入力は
画像のバッチなので―

00:14:20.761 --> 00:14:23.564 align:start position:34% line:-1
画像の各バッチには

00:14:23.664 --> 00:14:27.701 align:start position:29% line:-2
損失計算のため
対応するラベルが必要です

00:14:29.670 --> 00:14:34.007 align:start position:32% line:-2
ラベルはグラフに
ステートとして渡され

00:14:34.141 --> 00:14:38.312 align:start position:30% line:-2
エンコードのコールが
ステートを受け入れます

00:14:38.645 --> 00:14:41.682 align:start position:32% line:-2
バッチとステートとは
何でしょうか

00:14:41.782 --> 00:14:43.884 align:start position:29% line:-1
まずバッチから説明します

00:14:44.418 --> 00:14:48.021 align:start position:34% line:-2
バッチとは画像や
ステートの配列です

00:14:48.121 --> 00:14:51.458 align:start position:29% line:-2
今年から訓練のサポートに
加えました

00:14:51.959 --> 00:14:57.965 align:start position:0% line:-2
新しい２つのMPSタイプは
MPSImageBatchとMPSStateBatchです

00:14:58.432 --> 00:15:02.970 align:start position:23% line:-2
今回はAPIを使って既存の
Metal Textureから

00:14:58.432 --> 00:15:02.970 align:start position:23% line:-2
今回はAPIを使って既存の
Metal Textureから

00:15:03.971 --> 00:15:06.974 align:start position:32% line:-1
単一画像を作成します

00:15:08.175 --> 00:15:12.613 align:start position:25% line:-2
APIで画像のバッチを作成し
バッチに新しい画像を

00:15:12.713 --> 00:15:16.450 align:start position:34% line:-2
グラフに渡せるよう
アペンドした例です

00:15:18.385 --> 00:15:20.654 align:start position:29% line:-2
次は
ステートオブジェクトです

00:15:21.121 --> 00:15:24.792 align:start position:27% line:-2
MPSのステートは不透明な
データの入れ物で

00:15:25.659 --> 00:15:27.761 align:start position:32% line:-1
訓練でよく使われます

00:15:27.861 --> 00:15:32.533 align:start position:34% line:-2
フォワードノードの
ステートを取り込み

00:15:32.766 --> 00:15:36.370 align:start position:30% line:-2
これが後で
勾配ノードに使われます

00:15:36.937 --> 00:15:39.506 align:start position:32% line:-1
全てグラフが行うので

00:15:39.606 --> 00:15:43.076 align:start position:29% line:-2
デベロッパたちは
ステートの心配は不要です

00:15:43.177 --> 00:15:46.980 align:start position:32% line:-2
でも仕組みを知るのは
いいことですよね

00:15:48.949 --> 00:15:52.186 align:start position:34% line:-2
手書き数字認識
ネットワークに戻り

00:15:53.153 --> 00:15:57.558 align:start position:27% line:-2
ドロップアウト勾配ノードと
ドロップアウトを見ましょう

00:16:00.661 --> 00:16:06.633 align:start position:21% line:-2
フォワードドロップアウトノードは
入力値を０にします

00:16:07.234 --> 00:16:09.369 align:start position:30% line:-2
ドロップアウト
ステートオブジェクトは

00:16:09.469 --> 00:16:12.906 align:start position:27% line:-2
フォワードドロップアウトの
情報を取り込み

00:16:13.607 --> 00:16:16.643 align:start position:30% line:-2
これがドロップアウト
勾配ノードに使われます

00:16:16.877 --> 00:16:23.617 align:start position:27% line:-2
フォワードのゼロアウト同様
同じ場所で入力勾配の値を

00:16:23.717 --> 00:16:26.019 align:start position:34% line:-1
ゼロにするためです

00:16:28.956 --> 00:16:33.227 align:start position:27% line:-2
ステートはグラフが
管理するので心配無用ですが

00:16:33.760 --> 00:16:38.265 align:start position:32% line:-2
損失計算のラベルは
ステートとして渡され

00:16:38.966 --> 00:16:41.201 align:start position:32% line:-1
ユーザ入力が必要です

00:16:41.301 --> 00:16:43.770 align:start position:29% line:-1
正解データとなるからです

00:16:43.904 --> 00:16:47.040 align:start position:32% line:-2
損失計算の
ラベルのバッチを作り

00:16:47.141 --> 00:16:49.543 align:start position:27% line:-1
入力としてグラフに渡します

00:16:50.043 --> 00:16:55.015 align:start position:30% line:-2
損失計算の単一ラベルを
作成する例はこれです

00:16:55.115 --> 00:17:01.121 align:start position:21% line:-2
損失データの記述子はメモリの中の
レベルデータの配置を記述します

00:16:55.115 --> 00:17:01.121 align:start position:21% line:-2
損失データの記述子はメモリの中の
レベルデータの配置を記述します

00:17:01.688 --> 00:17:06.660 align:start position:7% line:-2
次に この記述子でMPSCNNLossLabel
オブジェクトを作ります

00:17:08.262 --> 00:17:13.133 align:start position:32% line:-2
訓練用にバッチを作り
グラフ実行が終わると

00:17:13.333 --> 00:17:18.839 align:start position:27% line:-2
ラベルのバッチは
画像ごとの損失値を含みます

00:17:18.939 --> 00:17:24.377 align:start position:27% line:-2
この値やバッチ中の単一値は
計算し調べることができます

00:17:27.647 --> 00:17:32.486 align:start position:30% line:-2
訓練グラフとグラフへの
入力について話しました

00:17:32.586 --> 00:17:36.723 align:start position:30% line:-2
次は グラフノードへの
重みの付与です

00:17:38.892 --> 00:17:42.463 align:start position:32% line:-2
完全結合の畳み込みに
重みを与えるには

00:17:42.629 --> 00:17:46.800 align:start position:30% line:-2
バッチとインスタンスの
ノーマライズノードで

00:17:46.900 --> 00:17:49.369 align:start position:12% line:-2
Data Source Providerの
プロトコルを使います

00:17:50.838 --> 00:17:55.409 align:start position:27% line:-2
これを使った
畳み込みノードの作成例です

00:17:56.043 --> 00:18:00.147 align:start position:32% line:-2
プロトコルに合致する
クラスを実装します

00:17:56.043 --> 00:18:00.147 align:start position:32% line:-2
プロトコルに合致する
クラスを実装します

00:18:00.247 --> 00:18:02.449 align:start position:23% line:-1
MyWeightsと呼びますね

00:18:04.618 --> 00:18:08.455 align:start position:29% line:-2
データソースプロバイダは
非常に有用です

00:18:08.555 --> 00:18:12.826 align:start position:27% line:-2
例えば ネットワークに
大量の畳み込みノードがあり

00:18:13.160 --> 00:18:16.730 align:start position:34% line:-2
重みの全体サイズが
大きい時があります

00:18:16.830 --> 00:18:22.336 align:start position:27% line:-2
そんな時は 一度に重みを
メモリに入れたくありません

00:18:22.636 --> 00:18:26.907 align:start position:30% line:-2
メモリフットプリントは
低く抑えたいのです

00:18:27.374 --> 00:18:29.810 align:start position:29% line:-1
データソースプロバイダは

00:18:29.910 --> 00:18:34.882 align:start position:21% line:-2
Just-In-Timeロードと
パージを行います

00:18:35.582 --> 00:18:39.953 align:start position:27% line:-2
そのため １つのカーネルに
重みをロードし

00:18:40.053 --> 00:18:43.690 align:start position:30% line:-2
次の畳み込みカーネルに
移る前にパージできます

00:18:46.193 --> 00:18:48.729 align:start position:20% line:-1
これがMyWeightsの実装です

00:18:49.363 --> 00:18:52.466 align:start position:32% line:-1
初期化メソッドを使い

00:18:52.566 --> 00:18:56.003 align:start position:25% line:-1
メモリに取り込み 準備します

00:18:56.103 --> 00:18:58.939 align:start position:32% line:-2
グラフがロード機能を
呼び出した後は

00:18:59.039 --> 00:19:03.043 align:start position:27% line:-2
パージメソッドが呼び出され
重みを解放できます

00:18:59.039 --> 00:19:03.043 align:start position:27% line:-2
パージメソッドが呼び出され
重みを解放できます

00:19:03.577 --> 00:19:06.447 align:start position:29% line:-2
訓練に必須の
データソースプロバイダは

00:19:06.547 --> 00:19:08.782 align:start position:32% line:-1
後ほど詳細に扱います

00:19:11.852 --> 00:19:16.290 align:start position:29% line:-2
訓練グラフを作り
入力と重みが準備できると

00:19:16.390 --> 00:19:18.892 align:start position:25% line:-1
GPUでグラフを実行できます

00:19:20.360 --> 00:19:25.065 align:start position:21% line:-2
GPU上でのグラフ変更は
Metal Setupで行います

00:19:25.299 --> 00:19:29.570 align:start position:30% line:-2
訓練グラフを初期化し
入力の用意ができました

00:19:29.670 --> 00:19:32.306 align:start position:34% line:-1
訓練を始めましょう

00:19:35.042 --> 00:19:39.980 align:start position:29% line:-2
訓練は反復プロセスのため
訓練ループを設定します

00:19:40.514 --> 00:19:44.484 align:start position:32% line:-2
設定したエポック数分
実行されます

00:19:44.751 --> 00:19:46.286 align:start position:38% line:-1
エポック数とは

00:19:46.386 --> 00:19:51.258 align:start position:30% line:-2
データセット全体で
反復したい数のことです

00:19:51.692 --> 00:19:54.728 align:start position:34% line:-2
各エポックで
複数の反復とします

00:19:54.862 --> 00:19:58.499 align:start position:29% line:-2
反復回数はデータセットの
画像総数を

00:19:58.599 --> 00:20:01.502 align:start position:32% line:-2
32か64のバッチで
割ったものです

00:19:58.599 --> 00:20:01.502 align:start position:32% line:-2
32か64のバッチで
割ったものです

00:20:02.135 --> 00:20:05.038 align:start position:27% line:-1
では 訓練反復を見ましょう

00:20:07.040 --> 00:20:12.146 align:start position:27% line:-2
各訓練反復では画像バッチを
エンコードします

00:20:13.046 --> 00:20:18.752 align:start position:25% line:-2
しかし GPUが画像バッチの
処理を終わるのをCPUが待ち

00:20:18.852 --> 00:20:21.622 align:start position:32% line:-1
エンコードコマンドを

00:20:21.722 --> 00:20:26.960 align:start position:27% line:-2
コマンドバッファに送るのは
望ましくありません

00:20:27.461 --> 00:20:31.198 align:start position:30% line:-2
CPUとGPUを
同時に動かしたいのです

00:20:31.298 --> 00:20:33.734 align:start position:34% line:-2
そこで
ダブルバッファです

00:20:34.401 --> 00:20:40.340 align:start position:29% line:-2
今回の設定では初期値２の
計数セマフォを作ります

00:20:40.440 --> 00:20:44.411 align:start position:29% line:-2
２つのエンコードだけ
同時進行させたいからです

00:20:45.579 --> 00:20:52.085 align:start position:25% line:-2
訓練反復関数を入力し
セマフォに重みを呼び出します

00:20:52.786 --> 00:20:58.392 align:start position:27% line:-2
カウント値が０であれば待ち
それ以外は継続します

00:20:59.426 --> 00:21:03.831 align:start position:29% line:-2
すぐにエンコードコールが
返ってきます

00:20:59.426 --> 00:21:03.831 align:start position:29% line:-2
すぐにエンコードコールが
返ってきます

00:21:04.097 --> 00:21:08.836 align:start position:25% line:-2
GPUのグラフ実行が終わると
ユーザ指定コールバックです

00:21:09.303 --> 00:21:11.905 align:start position:27% line:-1
GPUのグラフ処理が終了し

00:21:12.005 --> 00:21:16.810 align:start position:29% line:-2
CPUはGPUに処理の
エンコードを継続させます

00:21:17.578 --> 00:21:20.280 align:start position:34% line:-2
セマファで
待っていた処理です

00:21:21.281 --> 00:21:22.683 align:start position:32% line:-1
なぜダブルバッファで

00:21:22.783 --> 00:21:27.821 align:start position:27% line:-2
GPUのグラフ実行と
同時ではないのでしょうか？

00:21:28.689 --> 00:21:33.527 align:start position:29% line:-2
コマンドバッファの方が
時間がかからないからです

00:21:33.627 --> 00:21:38.565 align:start position:29% line:-2
メモリの使用を減らすため
同時処理を避けています

00:21:41.235 --> 00:21:43.670 align:start position:34% line:-1
グラフを実行すると

00:21:43.771 --> 00:21:49.142 align:start position:29% line:-2
フォワードパス 損失計算
勾配のパスを行い

00:21:49.243 --> 00:21:51.345 align:start position:29% line:-1
グラフは重みを更新します

00:21:51.478 --> 00:21:53.914 align:start position:25% line:-1
では 重みの更新を見ましょう

00:21:55.782 --> 00:22:00.888 align:start position:29% line:-2
データソースプロバイダは
訓練に必須であり

00:21:55.782 --> 00:22:00.888 align:start position:29% line:-2
データソースプロバイダは
訓練に必須であり

00:22:01.455 --> 00:22:06.627 align:start position:32% line:-2
任意の更新メソッドで
重みの更新が必要です

00:22:07.661 --> 00:22:10.998 align:start position:29% line:-1
更新メソッドは自動ですが

00:22:11.098 --> 00:22:14.635 align:start position:34% line:-2
具体的なステップを
見てみましょう

00:22:16.870 --> 00:22:19.773 align:start position:27% line:-1
勾配のパス中に勾配を計算し

00:22:19.873 --> 00:22:24.244 align:start position:29% line:-2
各訓練で重みに
小さいデルタを適用します

00:22:25.379 --> 00:22:30.284 align:start position:25% line:-2
どうやるかはオプティマイザで
記述されています

00:22:30.484 --> 00:22:35.689 align:start position:27% line:-2
この関数は古い重みと
計算済みの勾配を入力として

00:22:35.789 --> 00:22:39.560 align:start position:29% line:-2
更新した重みを出力として
生成します

00:22:41.094 --> 00:22:45.232 align:start position:29% line:-2
更新にはオプティマイザを
使用するでしょう

00:22:45.899 --> 00:22:50.304 align:start position:23% line:-2
様々な重み更新の
バリアントをサポートしています

00:22:50.404 --> 00:22:54.107 align:start position:27% line:-2
Adamや確率的勾配降下法
RMSPropなどです

00:22:54.708 --> 00:22:59.580 align:start position:30% line:-2
重み更新は自分で
定義することもできます

00:22:59.913 --> 00:23:03.951 align:start position:23% line:-2
では MPSでの
オプティマイザの使い方を見ます

00:22:59.913 --> 00:23:03.951 align:start position:23% line:-2
では MPSでの
オプティマイザの使い方を見ます

00:23:06.153 --> 00:23:09.423 align:start position:29% line:-2
データソースプロバイダは
initメソッドです

00:23:09.523 --> 00:23:14.061 align:start position:29% line:-2
オプティマイザを作るのは
１回だけです

00:23:15.229 --> 00:23:18.766 align:start position:32% line:-2
更新メソッドの実行を
見ましょう

00:23:19.433 --> 00:23:24.371 align:start position:30% line:-2
入力はソースステートと
勾配ステートです

00:23:26.039 --> 00:23:28.375 align:start position:27% line:-1
ソースステートは古い重みを

00:23:28.475 --> 00:23:31.478 align:start position:30% line:-2
勾配ステートは
計算済み勾配を含みます

00:23:31.578 --> 00:23:37.351 align:start position:23% line:-2
オプティマイザをエンコードし
最後にソースステートを返します

00:23:37.451 --> 00:23:40.721 align:start position:32% line:-2
重みが更新されました
簡単ですね

00:23:43.590 --> 00:23:46.093 align:start position:30% line:-1
もう１ステップあります

00:23:46.226 --> 00:23:51.465 align:start position:27% line:-2
繰り返しますが
ネットワーク訓練は反復です

00:23:52.699 --> 00:23:54.968 align:start position:34% line:-1
いつ訓練をやめるか

00:23:55.135 --> 00:24:00.407 align:start position:27% line:-2
訓練ループの観点から
どう決定するかお話しします

00:23:55.135 --> 00:24:00.407 align:start position:27% line:-2
訓練ループの観点から
どう決定するかお話しします

00:24:03.243 --> 00:24:08.048 align:start position:27% line:-2
訓練をエポックの回数分行う
訓練ループです

00:24:09.116 --> 00:24:13.153 align:start position:30% line:-2
まずは画像の
テストセットが必要です

00:24:13.253 --> 00:24:17.858 align:start position:25% line:-2
これには訓練に使用しなかった
画像も含まれています

00:24:17.958 --> 00:24:21.828 align:start position:29% line:-2
これらは精度の評価のみに
使われます

00:24:22.262 --> 00:24:25.299 align:start position:30% line:-1
各エポックごとに任意で

00:24:25.399 --> 00:24:29.503 align:start position:32% line:-2
GPUがグラフ実行を
やめるのを待ちます

00:24:29.636 --> 00:24:35.943 align:start position:23% line:-2
現在の訓練済みパラメータを使い
推論ネットワークを初期化します

00:24:36.743 --> 00:24:40.180 align:start position:27% line:-1
テストセットでこれを実行し

00:24:40.280 --> 00:24:44.952 align:start position:32% line:-2
ネットワークの精度が
あるレベルに達したら

00:24:45.052 --> 00:24:46.687 align:start position:38% line:-1
訓練をやめます

00:24:49.857 --> 00:24:52.493 align:start position:34% line:-2
MPSでの
ネットワーク訓練に

00:24:52.593 --> 00:24:55.863 align:start position:36% line:-2
必要なステップを
お話ししました

00:24:55.963 --> 00:24:57.364 align:start position:39% line:-1
次はデモです

00:24:58.599 --> 00:25:02.102 align:start position:36% line:-2
他のセッションで
お話ししたように

00:24:58.599 --> 00:25:02.102 align:start position:36% line:-2
他のセッションで
お話ししたように

00:25:02.603 --> 00:25:05.505 align:start position:30% line:-1
MPSフレームワークは

00:25:06.340 --> 00:25:09.543 align:start position:20% line:-2
Core MLやCreate ML
Turi Createを動かします

00:25:10.144 --> 00:25:14.715 align:start position:21% line:-2
Turi Createは簡単かつ
フレキシブルで高性能な

00:25:14.815 --> 00:25:18.051 align:start position:32% line:-2
Core MLを
作るツールセットです

00:25:18.352 --> 00:25:25.058 align:start position:21% line:-2
画像分類 オブジェクト検出
推薦など 様々なタスクが可能です

00:25:25.159 --> 00:25:30.964 align:start position:23% line:-2
Turi Createの詳細は
セッションビデオをご覧ください

00:25:32.166 --> 00:25:36.270 align:start position:25% line:-2
このデモで
Turi Createによる

00:25:36.370 --> 00:25:42.142 align:start position:23% line:-2
オブジェクト検出ネットワークの
訓練をします

00:25:42.943 --> 00:25:46.647 align:start position:0% line:-2
Platforms State of the Unionで
言ったように

00:25:46.747 --> 00:25:49.483 align:start position:36% line:-2
MPSを使うと
９倍速くなります

00:25:50.050 --> 00:25:55.455 align:start position:29% line:-2
認識したオブジェクトに
境界ボックスが描かれます

00:26:01.195 --> 00:26:02.463 align:start position:38% line:-1
デモで使うのは

00:26:04.765 --> 00:26:08.569 align:start position:14% line:-1
MacBook Proと外付けGPUです

00:26:09.770 --> 00:26:12.906 align:start position:7% line:-1
Turi CreateをMacBook Proで

00:26:13.307 --> 00:26:18.245 align:start position:30% line:-2
外付けGPUを使い
MPSで訓練を行います

00:26:18.812 --> 00:26:24.852 align:start position:20% line:-2
MacBook Proの計算能力を
外付けGPUで高める絶好の例です

00:26:25.152 --> 00:26:28.489 align:start position:25% line:-2
外付けGPUは
AMD Vega GPUです

00:26:29.289 --> 00:26:32.693 align:start position:29% line:-2
Turi Createは
インポート済みで

00:26:32.793 --> 00:26:37.765 align:start position:23% line:-2
オブジェクト検出ネットワークと
訓練データセットも既にあります

00:26:37.865 --> 00:26:43.003 align:start position:27% line:-2
まず10回の反復で
ネットワークの訓練を行い―

00:26:44.671 --> 00:26:46.840 align:start position:30% line:-2
次にネットワーク全体に
適用します

00:26:46.940 --> 00:26:50.611 align:start position:25% line:-2
全てのプリミティブと
オプティマイザ 重み更新は―

00:26:52.279 --> 00:26:55.015 align:start position:27% line:-1
外付けGPUで動いています

00:26:58.085 --> 00:27:00.754 align:start position:27% line:-1
10回の訓練が終わりました

00:26:58.085 --> 00:27:00.754 align:start position:27% line:-1
10回の訓練が終わりました

00:27:01.221 --> 00:27:05.826 align:start position:23% line:-2
実際は 回数がもっと多いですが
デモでは省略します

00:27:05.959 --> 00:27:11.198 align:start position:30% line:-2
では 前もって訓練した
ネットワークをロードし

00:27:11.298 --> 00:27:15.903 align:start position:30% line:-2
実行した結果を
映像でお見せしましょう

00:27:18.238 --> 00:27:20.107 align:start position:36% line:-1
これはバナナです

00:27:20.207 --> 00:27:24.278 align:start position:30% line:-2
境界ボックスで囲まれ
正しく分類されています

00:27:24.878 --> 00:27:28.782 align:start position:30% line:-2
朝食の
コーヒーとクロワッサン

00:27:29.116 --> 00:27:31.818 align:start position:32% line:-1
それに怖い顔の卵です

00:27:34.254 --> 00:27:36.690 align:start position:14% line:-1
以上 Turi Createのデモでした

00:27:37.324 --> 00:27:43.297 align:start position:43% line:-1
(拍手)

00:27:43.397 --> 00:27:44.565 align:start position:32% line:-1
ありがとうございます

00:27:47.468 --> 00:27:51.538 align:start position:27% line:-2
次は リカレントニューラル
ネットワークの訓練です

00:27:52.306 --> 00:27:55.809 align:start position:32% line:-2
まずは
おさらいから始めます

00:27:57.244 --> 00:28:00.147 align:start position:32% line:-1
CNNの欠点の１つは

00:27:57.244 --> 00:28:00.147 align:start position:32% line:-1
CNNの欠点の１つは

00:28:00.247 --> 00:28:04.685 align:start position:34% line:-2
以前起こったことを
記憶できない点です

00:28:05.219 --> 00:28:07.755 align:start position:32% line:-1
１つの入力を取り込み

00:28:07.855 --> 00:28:13.827 align:start position:29% line:-2
画像の可能性のあるものを
単一出力として生成します

00:28:16.530 --> 00:28:19.700 align:start position:34% line:-2
一方 RNNは
記憶することができ

00:28:19.800 --> 00:28:24.037 align:start position:32% line:-2
入力と出力の
シーケンスが得意です

00:28:24.538 --> 00:28:28.976 align:start position:27% line:-2
例えば 画像の中の１つの
確率のセットを取り込みます

00:28:29.109 --> 00:28:31.111 align:start position:30% line:-1
それがCNNの出力です

00:28:31.211 --> 00:28:33.380 align:start position:30% line:-1
CNNが生成するものが

00:28:33.480 --> 00:28:37.084 align:start position:29% line:-2
画像のキャプションとなる
単語のシーケンスです

00:28:38.252 --> 00:28:44.224 align:start position:23% line:-2
文を構成する単語のシーケンスを
入力として取り込み

00:28:44.324 --> 00:28:49.029 align:start position:34% line:-2
例えばロシア語と
フィンランド語など

00:28:49.129 --> 00:28:52.933 align:start position:27% line:-2
異なる言語に翻訳された文を
出力できます

00:28:54.735 --> 00:28:59.807 align:start position:25% line:-2
多くのRNNのモデルの中でも
最も一般的なのが

00:28:59.907 --> 00:29:03.877 align:start position:11% line:-2
Long Short-Term Memory
略してLSTMでしょう

00:28:59.907 --> 00:29:03.877 align:start position:11% line:-2
Long Short-Term Memory
略してLSTMでしょう

00:29:04.545 --> 00:29:10.050 align:start position:25% line:-2
既に昨年のWWDCで
LSTMのゲートを詳しく扱い

00:29:10.150 --> 00:29:13.420 align:start position:34% line:-2
LSTM推論の例も
お見せしました

00:29:13.620 --> 00:29:18.325 align:start position:25% line:-2
LSTMの詳細は
当該セッションをご覧ください

00:29:19.459 --> 00:29:24.598 align:start position:30% line:-2
今年はRNNの全部の
モデルをサポートします

00:29:25.099 --> 00:29:29.603 align:start position:23% line:-2
このセッションでは
LSTMの訓練について話します

00:29:32.439 --> 00:29:34.374 align:start position:34% line:-1
具体例を見ましょう

00:29:34.608 --> 00:29:40.414 align:start position:25% line:-2
行動の分類ネットワークは
動作感覚データを入力とします

00:29:40.514 --> 00:29:45.119 align:start position:30% line:-2
例えば 加速度計などの
センサの読み取り値です

00:29:45.485 --> 00:29:50.924 align:start position:25% line:-2
そのデータを元に
ユーザの身体行動を識別します

00:29:51.024 --> 00:29:56.163 align:start position:29% line:-2
例えば サイクリング中か
ウォーキング中かなどです

00:29:58.999 --> 00:30:03.370 align:start position:29% line:-2
興味深い
ネットワーク設定でしょう

00:29:58.999 --> 00:30:03.370 align:start position:29% line:-2
興味深い
ネットワーク設定でしょう

00:30:03.470 --> 00:30:08.008 align:start position:30% line:-2
含まれるプリミティブは
CNNに続いて

00:30:08.108 --> 00:30:12.412 align:start position:30% line:-2
LSTM またCNNと
なっています

00:30:12.513 --> 00:30:14.948 align:start position:34% line:-1
なぜこんな設定に？

00:30:16.817 --> 00:30:19.820 align:start position:29% line:-1
入力されたセンサデータは

00:30:20.420 --> 00:30:24.124 align:start position:32% line:-2
６つのチャネルによる
1D画像で表されます

00:30:24.224 --> 00:30:29.763 align:start position:23% line:-2
チャネルの１つが加速度計などの
数字を読み取ります

00:30:30.564 --> 00:30:33.867 align:start position:32% line:-2
各1D画像は
2000ピクセルです

00:30:33.967 --> 00:30:37.438 align:start position:32% line:-2
これを時間サンプルと
考えます

00:30:37.638 --> 00:30:41.808 align:start position:30% line:-2
識別したい行動は
経時的に起こるからです

00:30:44.545 --> 00:30:48.582 align:start position:27% line:-2
1D畳み込みプリミティブを
通じて

00:30:49.116 --> 00:30:54.054 align:start position:29% line:-2
画像は2000から
20サンプルに絞られます

00:30:56.023 --> 00:30:58.158 align:start position:32% line:-2
多数の特徴チャネルを
使うので

00:30:58.258 --> 00:31:01.628 align:start position:36% line:-2
データの特徴は
失われていません

00:30:58.258 --> 00:31:01.628 align:start position:36% line:-2
データの特徴は
失われていません

00:31:03.096 --> 00:31:09.603 align:start position:20% line:-2
これが長さが20のシーケンスとして
LSTMのプリミティブに渡されます

00:31:10.304 --> 00:31:12.606 align:start position:23% line:-1
LSTMを20反復 実行します

00:31:12.740 --> 00:31:16.910 align:start position:27% line:-2
LSTMは2000ではなく
20の長さで動作するので

00:31:17.010 --> 00:31:20.781 align:start position:29% line:-2
より高度な特徴のデータと
なっています

00:31:22.416 --> 00:31:25.018 align:start position:38% line:-2
追加のCNNの
プリミティブも

00:31:25.352 --> 00:31:28.589 align:start position:32% line:-2
データに高度な特徴を
持っています

00:31:29.289 --> 00:31:32.960 align:start position:23% line:-2
最後は
SoftMaxプリミティブです

00:31:33.060 --> 00:31:36.296 align:start position:25% line:-2
異なるアクティビティクラスの
確率を生成

00:31:36.396 --> 00:31:38.098 align:start position:32% line:-1
これが出力になります

00:31:38.565 --> 00:31:41.135 align:start position:27% line:-1
では 訓練について話します

00:31:42.169 --> 00:31:44.771 align:start position:32% line:-2
必要なのは
損失のプリミティブで

00:31:44.872 --> 00:31:48.308 align:start position:32% line:-2
ネットワークの出力と
ラベルを入力とします

00:31:48.475 --> 00:31:52.279 align:start position:30% line:-2
そして 後半のグラフが
必要となります

00:31:52.379 --> 00:31:56.216 align:start position:21% line:-2
対応するフォワードプリミティブの
勾配プリミティブは

00:31:56.316 --> 00:31:58.418 align:start position:23% line:-1
LSTMのプリミティブなどです

00:31:58.986 --> 00:32:00.621 align:start position:38% line:-1
訓練するために

00:31:58.986 --> 00:32:00.621 align:start position:38% line:-1
訓練するために

00:32:01.655 --> 00:32:06.760 align:start position:21% line:-2
ネットワークで フォワードパスと
損失計算を行います

00:32:07.494 --> 00:32:12.399 align:start position:21% line:-2
そして勾配のパスで 勾配を計算し
重みを更新します

00:32:12.499 --> 00:32:16.904 align:start position:34% line:-2
これはCNN訓練の
設定に似ています

00:32:17.004 --> 00:32:19.706 align:start position:27% line:-1
最後はもちろん重み更新です

00:32:19.807 --> 00:32:23.977 align:start position:32% line:-2
LSTMも重みがあり
更新が必要です

00:32:25.979 --> 00:32:30.484 align:start position:34% line:-2
このネットワークを
MPSで訓練します

00:32:30.584 --> 00:32:35.823 align:start position:23% line:-2
フレームワークを使った
LSTM層の作り方を見ましょう

00:32:36.490 --> 00:32:39.593 align:start position:27% line:-2
まず LSTM層の記述子を
作ります

00:32:40.494 --> 00:32:46.200 align:start position:25% line:-2
データソースプロバイダを使い
記述子を初期化します

00:32:46.300 --> 00:32:48.402 align:start position:30% line:-1
初期化訓練パラメータは

00:32:48.502 --> 00:32:51.672 align:start position:30% line:-2
小さなランダム数字か
チェックポイント値です

00:32:52.306 --> 00:32:57.077 align:start position:32% line:-2
訓練の記述子の設定は
推論と全く同じです

00:32:58.479 --> 00:33:04.952 align:start position:4% line:-2
Layer Descriptor Setupの詳細は
昨年のWWDCで説明されました

00:32:58.479 --> 00:33:04.952 align:start position:4% line:-2
Layer Descriptor Setupの詳細は
昨年のWWDCで説明されました

00:33:05.052 --> 00:33:10.657 align:start position:25% line:-2
詳しい情報は当該セッションを
ご参照ください

00:33:11.091 --> 00:33:12.893 align:start position:36% line:-1
記述子ができたら

00:33:13.794 --> 00:33:17.931 align:start position:27% line:-2
次に これで
LSTMの訓練層を作ります

00:33:19.666 --> 00:33:25.873 align:start position:21% line:-2
MPSは訓練の重みを埋め込むのに
指定したデータソースを使います

00:33:26.039 --> 00:33:29.943 align:start position:32% line:-2
計算済み勾配を保つ
マトリクスも必要です

00:33:30.677 --> 00:33:33.914 align:start position:30% line:-1
マトリクスを作るのに―

00:33:34.014 --> 00:33:37.417 align:start position:2% line:-2
WeightGradientMatrices APIが
使えます

00:33:37.651 --> 00:33:42.689 align:start position:29% line:-2
訓練の重みはフォワードと
勾配のパスで使われ

00:33:42.790 --> 00:33:47.427 align:start position:27% line:-2
計算済み勾配と共に
オプティマイザに渡されます

00:33:49.263 --> 00:33:53.767 align:start position:30% line:-2
LSTMの訓練用の
入力と出力を準備します

00:33:54.401 --> 00:33:59.673 align:start position:23% line:-2
これは 入力と出力シーケンスを
保つマトリクスを作る例です

00:33:59.773 --> 00:34:04.978 align:start position:25% line:-2
フォワードと勾配のパスに
各20のマトリクスが必要です

00:33:59.773 --> 00:34:04.978 align:start position:25% line:-2
フォワードと勾配のパスに
各20のマトリクスが必要です

00:34:05.612 --> 00:34:09.049 align:start position:32% line:-2
こうしてマトリクスを
初期化します

00:34:11.685 --> 00:34:15.922 align:start position:34% line:-2
これでMPSによる
訓練を始められます

00:34:16.023 --> 00:34:21.728 align:start position:18% line:-2
ここでハイライトするのは
時間に関するLSTMフィルタのみです

00:34:23.429 --> 00:34:29.136 align:start position:25% line:-2
フォワードパスで
20のマトリクスを実行します

00:34:29.703 --> 00:34:31.038 align:start position:32% line:-1
バックワードパスでは

00:34:31.138 --> 00:34:35.809 align:start position:29% line:-2
20のマトリクスを実行し
勾配を計算します

00:34:36.543 --> 00:34:40.681 align:start position:34% line:-2
これで訓練の重みと
計算済み勾配ができ

00:34:40.781 --> 00:34:44.251 align:start position:32% line:-2
オプティマイザに渡し
重みを更新します

00:34:45.619 --> 00:34:48.054 align:start position:34% line:-1
１つ言いたいことは

00:34:49.289 --> 00:34:55.362 align:start position:27% line:-2
CNNは画像で LSTMは
マトリクスで動きます

00:34:55.896 --> 00:34:59.032 align:start position:27% line:-1
カーネルに利便性を与えると

00:34:59.133 --> 00:35:02.502 align:start position:29% line:-2
画像とマトリクスの変換が
容易になるのです

00:34:59.133 --> 00:35:02.502 align:start position:29% line:-2
画像とマトリクスの変換が
容易になるのです

00:35:03.003 --> 00:35:06.507 align:start position:34% line:-2
画像をマトリクスに
コピーするため

00:35:06.607 --> 00:35:10.010 align:start position:12% line:-2
MPSImageCopyToMatrixを
使います

00:35:10.110 --> 00:35:12.012 align:start position:36% line:-1
これでできました

00:35:12.112 --> 00:35:16.149 align:start position:34% line:-2
画像のバッチで
エンコードできます

00:35:17.017 --> 00:35:19.920 align:start position:32% line:-2
各デスティネーション
マトリクスは

00:35:20.020 --> 00:35:22.189 align:start position:34% line:-2
１つのソース画像を
含んでいます

00:35:22.923 --> 00:35:25.392 align:start position:29% line:-1
マトリクスからのコピーは

00:35:25.792 --> 00:35:29.062 align:start position:18% line:-2
MPS Matrix Copy to
Image Kernelを使います

00:35:29.163 --> 00:35:33.467 align:start position:36% line:-2
こうしてGPUに
エンコードします

00:35:35.235 --> 00:35:41.041 align:start position:23% line:-2
MPSを使ったCNNとRNNの
訓練をお見せして―

00:35:41.708 --> 00:35:46.013 align:start position:18% line:-2
MPSによるTuri Createの
デモもお見せしました

00:35:46.113 --> 00:35:48.148 align:start position:30% line:-1
デモはもう１つあります

00:35:49.416 --> 00:35:55.222 align:start position:16% line:-2
GoogleとTensorFlowへの
サポートを行ってきたのは

00:35:55.656 --> 00:35:59.059 align:start position:30% line:-2
macOSの機械学習を
加速するためです

00:35:59.159 --> 00:36:01.361 align:start position:30% line:-1
そのデモをご覧ください

00:35:59.159 --> 00:36:01.361 align:start position:30% line:-1
そのデモをご覧ください

00:36:01.461 --> 00:36:03.897 align:start position:30% line:-1
特に注目してほしいのは

00:36:03.997 --> 00:36:07.668 align:start position:25% line:-2
MPSによる
TensorFlowを使った

00:36:08.001 --> 00:36:11.004 align:start position:27% line:-2
InceptionV3の
オブジェクト分類の訓練です

00:36:11.638 --> 00:36:12.706 align:start position:39% line:-1
このデモでも

00:36:14.475 --> 00:36:18.745 align:start position:29% line:-2
MacBook Proに
外付けGPUを接続します

00:36:19.179 --> 00:36:23.116 align:start position:25% line:-2
MacBook Proで
TensorFlowを実行し

00:36:23.217 --> 00:36:27.721 align:start position:27% line:-2
外付けGPUで
MPSによる訓練を行います

00:36:27.821 --> 00:36:32.226 align:start position:18% line:-2
このデモ用に
TensorFlowはインポート済み

00:36:32.326 --> 00:36:35.963 align:start position:16% line:-2
InceptionV3とデータセットも
ロード済みです

00:36:36.063 --> 00:36:39.767 align:start position:29% line:-2
30反復で
ネットワークを訓練します

00:36:40.834 --> 00:36:42.936 align:start position:39% line:-1
速いでしょう

00:36:43.303 --> 00:36:47.875 align:start position:27% line:-2
全てのプリミティブ
オプティマイザ 重み更新は

00:36:47.975 --> 00:36:50.510 align:start position:36% line:-2
外付けGPUで
実行されています

00:36:50.611 --> 00:36:52.112 align:start position:36% line:-1
もう終わりました

00:36:52.379 --> 00:36:57.351 align:start position:34% line:-2
訓練速度はおよそ
毎秒100画像です

00:36:57.684 --> 00:37:00.954 align:start position:30% line:-1
既に言われているように

00:36:57.684 --> 00:37:00.954 align:start position:30% line:-1
既に言われているように

00:37:01.155 --> 00:37:06.427 align:start position:14% line:-2
MPSによるTensorFlowの
InceptionV3ネットワーク訓練は

00:37:06.660 --> 00:37:10.664 align:start position:36% line:-2
MPS無しに比べ
20倍の速さです

00:37:11.165 --> 00:37:13.267 align:start position:21% line:-1
TensorFlowのデモでした

00:37:14.368 --> 00:37:16.003 align:start position:43% line:-1
(拍手)

00:37:16.103 --> 00:37:16.904 align:start position:41% line:-1
ありがとう

00:37:22.009 --> 00:37:23.977 align:start position:30% line:-1
セッションのまとめです

00:37:24.745 --> 00:37:31.318 align:start position:21% line:-2
今年 畳み込みと転置畳み込み用に
FP16の蓄積を追加しました

00:37:31.485 --> 00:37:34.955 align:start position:34% line:-2
CNNの推論を
向上させるためです

00:37:35.122 --> 00:37:39.259 align:start position:21% line:-2
訓練用に追加された
GPUで加速化したプリミティブは

00:37:39.359 --> 00:37:43.497 align:start position:32% line:-2
iOSとmacOSに
最適化されています

00:37:44.631 --> 00:37:47.801 align:start position:30% line:-2
ニューラルネットワーク
グラフAPIも追加され

00:37:48.335 --> 00:37:51.572 align:start position:36% line:-2
GPUでの訓練を
容易にしました

00:37:51.672 --> 00:37:56.510 align:start position:21% line:-2
異なるGPUで最高の
パフォーマンスを引き出しています

00:37:58.612 --> 00:38:04.184 align:start position:29% line:-2
さらに詳しい情報は
デベロッパWebサイトへ

00:37:58.612 --> 00:38:04.184 align:start position:29% line:-2
さらに詳しい情報は
デベロッパWebサイトへ

00:38:05.452 --> 00:38:10.657 align:start position:16% line:-2
Metal for Machine
Learningラボは明日９時からです

00:38:10.758 --> 00:38:12.326 align:start position:38% line:-1
ご参加ください

00:38:13.794 --> 00:38:17.931 align:start position:27% line:-2
ありがとうございました
WWDCをお楽しみください

00:38:18.031 --> 00:38:19.333 align:start position:43% line:-1
(拍手)
