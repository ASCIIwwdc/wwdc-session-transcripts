WEBVTT

00:00:27.066 --> 00:00:27.856 A:middle
&gt;&gt; Good morning, everyone.

00:00:28.616 --> 00:00:30.316 A:middle
My name is Krishna and I'm from

00:00:30.316 --> 00:00:31.556 A:middle
the Core ML Engineering team,

00:00:32.026 --> 00:00:33.836 A:middle
and today we're going to talk

00:00:33.836 --> 00:00:36.286 A:middle
about Core ML in Depth.

00:00:37.176 --> 00:00:39.046 A:middle
This year, we introduced Core

00:00:39.096 --> 00:00:39.366 A:middle
ML.

00:00:39.846 --> 00:00:41.776 A:middle
It's the easiest way for you to

00:00:41.776 --> 00:00:42.876 A:middle
integrate machine learning

00:00:42.876 --> 00:00:44.566 A:middle
models in your applications.

00:00:45.566 --> 00:00:49.266 A:middle
Core ML is available on macOS,

00:00:49.266 --> 00:00:51.936 A:middle
iOS, watchOS, and tvOS.

00:00:52.096 --> 00:00:55.786 A:middle
We had a session on Tuesday that

00:00:55.786 --> 00:00:56.616 A:middle
introduced Core ML.

00:00:56.616 --> 00:00:58.346 A:middle
For those of you that missed

00:00:58.346 --> 00:00:59.956 A:middle
that session, let's just take a

00:00:59.956 --> 00:01:01.726 A:middle
couple moments to recap some of

00:00:59.956 --> 00:01:01.726 A:middle
couple moments to recap some of

00:01:01.726 --> 00:01:02.816 A:middle
the key things we learned in

00:01:02.816 --> 00:01:03.346 A:middle
that session.

00:01:04.376 --> 00:01:06.366 A:middle
Now the first and the most

00:01:06.366 --> 00:01:08.926 A:middle
important thing about Core ML is

00:01:08.926 --> 00:01:09.976 A:middle
that you can think of your

00:01:09.976 --> 00:01:11.816 A:middle
machine learning models just

00:01:11.816 --> 00:01:14.076 A:middle
like code, and you interact with

00:01:14.076 --> 00:01:16.466 A:middle
them just like any other Swift

00:01:17.706 --> 00:01:17.876 A:middle
class.

00:01:18.286 --> 00:01:20.076 A:middle
Your workflow looks a bit like

00:01:20.076 --> 00:01:20.296 A:middle
this.

00:01:21.136 --> 00:01:22.056 A:middle
You start with a machine

00:01:22.056 --> 00:01:24.126 A:middle
learning model, you drag and

00:01:24.126 --> 00:01:26.896 A:middle
drop that model into Xcode,

00:01:26.896 --> 00:01:28.086 A:middle
Xcode will automatically

00:01:28.086 --> 00:01:29.996 A:middle
generate a Swift or an Objective

00:01:29.996 --> 00:01:31.956 A:middle
C interface for you to program

00:01:31.956 --> 00:01:32.896 A:middle
against that model.

00:01:33.726 --> 00:01:35.466 A:middle
You write your application code,

00:01:35.466 --> 00:01:36.346 A:middle
you build it.

00:01:37.026 --> 00:01:39.356 A:middle
Xcode will bundle both the code

00:01:39.356 --> 00:01:40.906 A:middle
as well as the model in your

00:01:41.696 --> 00:01:41.766 A:middle
app.

00:01:43.016 --> 00:01:45.036 A:middle
In that session, we also saw a

00:01:45.036 --> 00:01:46.616 A:middle
little demo of a flower

00:01:46.616 --> 00:01:47.036 A:middle
predictor.

00:01:47.826 --> 00:01:49.176 A:middle
It was an application where

00:01:49.176 --> 00:01:51.126 A:middle
given a picture, let's say this

00:01:51.126 --> 00:01:53.286 A:middle
pink rose, the application is

00:01:53.326 --> 00:01:54.586 A:middle
supposed to tell you what kind

00:01:54.586 --> 00:01:55.886 A:middle
of a flower it was and how

00:01:55.886 --> 00:01:56.956 A:middle
confident it was.

00:01:58.526 --> 00:02:00.586 A:middle
We saw that in order to use that

00:01:58.526 --> 00:02:00.586 A:middle
We saw that in order to use that

00:02:00.586 --> 00:02:02.026 A:middle
or build that application, it

00:02:02.026 --> 00:02:03.426 A:middle
just took a few lines of code.

00:02:04.126 --> 00:02:06.156 A:middle
One line of code to instantiate

00:02:06.156 --> 00:02:08.346 A:middle
the model, and one line of code

00:02:08.586 --> 00:02:10.606 A:middle
to make a prediction from that

00:02:11.536 --> 00:02:11.706 A:middle
model.

00:02:11.836 --> 00:02:13.426 A:middle
So in this session, we're going

00:02:13.426 --> 00:02:14.386 A:middle
to pick up from where we left

00:02:14.386 --> 00:02:15.786 A:middle
off and we're going to talk a

00:02:15.786 --> 00:02:16.656 A:middle
little bit more about the

00:02:16.656 --> 00:02:17.996 A:middle
different kinds of use cases,

00:02:17.996 --> 00:02:19.296 A:middle
all the cool stuff you guys can

00:02:19.296 --> 00:02:20.046 A:middle
do with Core ML.

00:02:20.726 --> 00:02:22.986 A:middle
We're then going to talk about

00:02:22.986 --> 00:02:25.086 A:middle
how Core ML is optimized for the

00:02:25.086 --> 00:02:26.736 A:middle
hardware on which it runs for or

00:02:26.736 --> 00:02:28.596 A:middle
runs on, and what that means for

00:02:28.596 --> 00:02:30.336 A:middle
you as a developer.

00:02:30.996 --> 00:02:32.546 A:middle
Finally, we're going to talk

00:02:32.546 --> 00:02:34.106 A:middle
about how you can obtain Core ML

00:02:34.106 --> 00:02:35.456 A:middle
models for use in all your

00:02:35.456 --> 00:02:36.056 A:middle
applications.

00:02:36.256 --> 00:02:38.036 A:middle
So it's going to be a fun

00:02:38.086 --> 00:02:39.386 A:middle
session with a couple demos,

00:02:39.906 --> 00:02:40.676 A:middle
let's get started.

00:02:41.826 --> 00:02:43.556 A:middle
So you've already seen an

00:02:43.556 --> 00:02:45.196 A:middle
example of an app that used

00:02:45.196 --> 00:02:46.656 A:middle
images, the flower predictor.

00:02:47.296 --> 00:02:48.426 A:middle
But with Core ML you can do a

00:02:48.426 --> 00:02:49.836 A:middle
lot more than just images.

00:02:50.636 --> 00:02:52.106 A:middle
You can work with gestures,

00:02:52.456 --> 00:02:53.966 A:middle
let's say handwriting detection

00:02:53.966 --> 00:02:54.586 A:middle
on the watch.

00:02:55.766 --> 00:02:57.176 A:middle
You can work with video, let's

00:02:57.176 --> 00:02:58.186 A:middle
say you want to do credit card

00:02:58.186 --> 00:02:58.606 A:middle
detection.

00:02:59.876 --> 00:03:02.346 A:middle
You can work with audio, and you

00:02:59.876 --> 00:03:02.346 A:middle
You can work with audio, and you

00:03:02.346 --> 00:03:04.016 A:middle
can even work with text.

00:03:05.366 --> 00:03:07.086 A:middle
Now by taking inputs of all of

00:03:07.086 --> 00:03:08.806 A:middle
these different types, you can

00:03:08.806 --> 00:03:10.136 A:middle
build a large variety of

00:03:10.136 --> 00:03:10.876 A:middle
applications.

00:03:12.306 --> 00:03:13.456 A:middle
Let's say you want to build an

00:03:13.456 --> 00:03:14.786 A:middle
application that as you type

00:03:14.786 --> 00:03:16.756 A:middle
some text it tells you if it's a

00:03:16.756 --> 00:03:19.116 A:middle
happy text or a sad text or a

00:03:19.116 --> 00:03:20.426 A:middle
passive aggressive text or

00:03:20.426 --> 00:03:21.106 A:middle
angry.

00:03:22.206 --> 00:03:23.246 A:middle
You can do that with Sentiment

00:03:23.246 --> 00:03:25.186 A:middle
Analysis, and we'll see a little

00:03:25.376 --> 00:03:27.536 A:middle
demo of that today.

00:03:27.706 --> 00:03:29.026 A:middle
You can -- with Style Transfer

00:03:29.026 --> 00:03:30.366 A:middle
you can even make pictures of

00:03:30.366 --> 00:03:31.756 A:middle
your family look like Vincent

00:03:31.756 --> 00:03:32.556 A:middle
Van Gogh paintings.

00:03:34.086 --> 00:03:35.396 A:middle
And with Gesture Recognition,

00:03:35.656 --> 00:03:37.216 A:middle
you can have a whole new way to

00:03:37.216 --> 00:03:38.056 A:middle
take inputs to your

00:03:38.056 --> 00:03:38.746 A:middle
applications.

00:03:39.626 --> 00:03:41.306 A:middle
Now all of these are amazing

00:03:41.306 --> 00:03:43.566 A:middle
possibilities because with Core

00:03:43.566 --> 00:03:45.936 A:middle
ML you can use a large variety

00:03:45.936 --> 00:03:46.556 A:middle
of models.

00:03:47.656 --> 00:03:49.116 A:middle
You can use Classical Machine

00:03:49.116 --> 00:03:50.616 A:middle
Learning Models like Generalized

00:03:50.616 --> 00:03:52.116 A:middle
Linear Models, Trees, and

00:03:52.176 --> 00:03:53.176 A:middle
Support Vector Machines.

00:03:53.896 --> 00:03:55.626 A:middle
Now these ones are great because

00:03:55.686 --> 00:03:57.656 A:middle
they are small, you can make

00:03:57.656 --> 00:03:58.996 A:middle
fast predictions with them and

00:03:58.996 --> 00:03:59.906 A:middle
they are on any device.

00:04:00.936 --> 00:04:03.116 A:middle
But you can also work with a

00:04:03.116 --> 00:04:04.796 A:middle
large variety of Neural

00:04:05.196 --> 00:04:05.576 A:middle
Networks.

00:04:05.576 --> 00:04:07.166 A:middle
We have support for over 30

00:04:07.166 --> 00:04:08.586 A:middle
different layer types and that's

00:04:08.776 --> 00:04:09.186 A:middle
huge.

00:04:09.986 --> 00:04:10.946 A:middle
You can do things like

00:04:10.946 --> 00:04:12.296 A:middle
Feedforward and Convolution

00:04:12.296 --> 00:04:13.516 A:middle
Linear Networks for all your

00:04:13.516 --> 00:04:14.616 A:middle
image and video-based

00:04:14.616 --> 00:04:16.606 A:middle
applications, and you can also

00:04:16.606 --> 00:04:17.916 A:middle
do things like Recurrent Neural

00:04:17.916 --> 00:04:19.606 A:middle
Networks or LSDMs for all of

00:04:19.606 --> 00:04:21.106 A:middle
your text-based applications.

00:04:22.016 --> 00:04:23.526 A:middle
We'll take a look at Recurrent

00:04:23.526 --> 00:04:24.946 A:middle
Neural Networks in today's

00:04:25.666 --> 00:04:25.986 A:middle
session.

00:04:26.636 --> 00:04:29.386 A:middle
In fact, with Core ML you can

00:04:29.386 --> 00:04:31.016 A:middle
also combine models of various

00:04:31.016 --> 00:04:31.696 A:middle
different types.

00:04:31.696 --> 00:04:33.646 A:middle
So you can take, let's say, a

00:04:33.646 --> 00:04:35.056 A:middle
Neural Network and combine it

00:04:35.056 --> 00:04:37.126 A:middle
with a Tree and then you can get

00:04:37.126 --> 00:04:38.276 A:middle
one big model with that.

00:04:38.616 --> 00:04:39.816 A:middle
So this concept is called a

00:04:39.816 --> 00:04:40.366 A:middle
Pipeline.

00:04:40.786 --> 00:04:44.706 A:middle
But most importantly for you as

00:04:44.706 --> 00:04:46.166 A:middle
a developer, we want you to

00:04:46.166 --> 00:04:47.636 A:middle
focus on the code that you're

00:04:47.636 --> 00:04:49.306 A:middle
writing in your apps and not on

00:04:49.306 --> 00:04:50.796 A:middle
the specific complexities of the

00:04:50.796 --> 00:04:51.826 A:middle
model that's running there.

00:04:52.426 --> 00:04:55.996 A:middle
And we achieve that by giving

00:04:55.996 --> 00:04:57.596 A:middle
you a functional abstraction

00:04:57.596 --> 00:04:58.236 A:middle
viewer models.

00:04:58.786 --> 00:05:00.446 A:middle
So all you need to care is your

00:04:58.786 --> 00:05:00.446 A:middle
So all you need to care is your

00:05:00.446 --> 00:05:02.296 A:middle
models are prediction functions

00:05:02.296 --> 00:05:04.326 A:middle
that take in some inputs and

00:05:04.326 --> 00:05:05.286 A:middle
give out some outputs.

00:05:06.186 --> 00:05:08.256 A:middle
And these inputs and outputs can

00:05:08.256 --> 00:05:09.716 A:middle
be of five different types;

00:05:10.406 --> 00:05:13.726 A:middle
numeric, categorical, images,

00:05:14.376 --> 00:05:16.076 A:middle
arrays, and dictionaries.

00:05:17.476 --> 00:05:19.086 A:middle
Now let's just take a little

00:05:19.086 --> 00:05:20.086 A:middle
look at each of these five

00:05:20.136 --> 00:05:21.616 A:middle
different types.

00:05:22.136 --> 00:05:23.986 A:middle
So numerics and categories are

00:05:23.986 --> 00:05:25.956 A:middle
exposed to you in Swift as

00:05:26.056 --> 00:05:28.106 A:middle
doubles, integers or strings.

00:05:28.106 --> 00:05:29.126 A:middle
So it's very natural.

00:05:30.036 --> 00:05:31.896 A:middle
We have a little example of an

00:05:31.896 --> 00:05:33.306 A:middle
application that uses these two

00:05:33.306 --> 00:05:35.026 A:middle
types on developer.apple.com.

00:05:35.556 --> 00:05:37.096 A:middle
It's an application that does

00:05:37.096 --> 00:05:38.086 A:middle
house price prediction.

00:05:38.996 --> 00:05:40.156 A:middle
So some of the inputs to this

00:05:40.156 --> 00:05:41.936 A:middle
model are numeric, that is

00:05:41.936 --> 00:05:43.166 A:middle
they're continuous so you can go

00:05:43.166 --> 00:05:44.706 A:middle
from zero to infinity.

00:05:45.606 --> 00:05:47.686 A:middle
And some of them are categorical

00:05:47.806 --> 00:05:50.196 A:middle
or discrete, so you go zero, 1,

00:05:50.246 --> 00:05:52.936 A:middle
2, 3, 4.

00:05:53.146 --> 00:05:54.566 A:middle
You've already seen an example

00:05:54.566 --> 00:05:55.376 A:middle
of using images.

00:05:55.946 --> 00:05:57.226 A:middle
Now these images are exposed to

00:05:57.226 --> 00:05:58.876 A:middle
you as CVPixelBuffers.

00:05:59.666 --> 00:06:02.786 A:middle
For the more complex things like

00:05:59.666 --> 00:06:02.786 A:middle
For the more complex things like

00:06:02.856 --> 00:06:04.456 A:middle
gestures, audio and video, we

00:06:04.456 --> 00:06:06.286 A:middle
have a new type called

00:06:06.286 --> 00:06:08.926 A:middle
MLMultiArray to encapsulate a

00:06:08.926 --> 00:06:10.126 A:middle
multidimensional array.

00:06:10.666 --> 00:06:13.356 A:middle
And for a lot of your text-based

00:06:13.356 --> 00:06:14.796 A:middle
applications, you'll be

00:06:14.796 --> 00:06:16.136 A:middle
interacting with dictionaries.

00:06:16.866 --> 00:06:17.756 A:middle
Here are the dictionaries.

00:06:17.756 --> 00:06:19.166 A:middle
The keys are either strings or

00:06:19.166 --> 00:06:21.096 A:middle
integers, and the values are

00:06:21.156 --> 00:06:21.486 A:middle
doubles.

00:06:22.746 --> 00:06:24.536 A:middle
Let's take a little look at

00:06:24.536 --> 00:06:26.136 A:middle
using Text and working with

00:06:26.136 --> 00:06:26.646 A:middle
Dictionaries.

00:06:27.326 --> 00:06:30.656 A:middle
And we're going to do that with

00:06:30.656 --> 00:06:32.446 A:middle
an application of Sentiment

00:06:32.446 --> 00:06:32.946 A:middle
Analysis.

00:06:33.886 --> 00:06:35.206 A:middle
Now I've always wanted this app

00:06:35.246 --> 00:06:36.966 A:middle
where if I type some text I want

00:06:36.966 --> 00:06:38.686 A:middle
the UI to pop and reflect the

00:06:38.686 --> 00:06:39.496 A:middle
mood that I'm in.

00:06:40.006 --> 00:06:42.086 A:middle
So if I say Core ML is awesome!

00:06:42.086 --> 00:06:42.926 A:middle
I love using it!

00:06:43.136 --> 00:06:44.286 A:middle
I want it to go green and I

00:06:44.286 --> 00:06:47.226 A:middle
want, like, a happy face.

00:06:47.226 --> 00:06:49.006 A:middle
And if I talk to you about, say,

00:06:49.006 --> 00:06:49.936 A:middle
how bad the lunch was.

00:06:49.936 --> 00:06:50.936 A:middle
Like, today's lunch was

00:06:50.936 --> 00:06:52.036 A:middle
disappointing and sad.

00:06:52.036 --> 00:06:52.776 A:middle
I want it to go red.

00:06:52.776 --> 00:06:55.586 A:middle
So that's what I want to do.

00:06:55.916 --> 00:06:57.916 A:middle
So what does it take to build an

00:06:57.916 --> 00:06:58.896 A:middle
application like this?

00:06:59.466 --> 00:07:00.486 A:middle
So I'm going to start with an

00:06:59.466 --> 00:07:00.486 A:middle
So I'm going to start with an

00:07:00.486 --> 00:07:02.456 A:middle
app shell where the user can

00:07:02.456 --> 00:07:03.226 A:middle
type in some text.

00:07:04.676 --> 00:07:05.986 A:middle
As soon as the user hits the

00:07:05.986 --> 00:07:07.656 A:middle
space bar, I'm going to take all

00:07:07.656 --> 00:07:09.326 A:middle
of that text, give it to a

00:07:09.326 --> 00:07:11.086 A:middle
machine learning model, and get

00:07:11.086 --> 00:07:12.516 A:middle
back a sentiment prediction.

00:07:13.616 --> 00:07:14.776 A:middle
So the sentiment prediction is

00:07:14.776 --> 00:07:16.316 A:middle
either going to be happy,

00:07:16.316 --> 00:07:17.436 A:middle
neutral or sad.

00:07:18.526 --> 00:07:19.726 A:middle
As soon as I get back this

00:07:19.776 --> 00:07:21.136 A:middle
prediction, I'm going to go back

00:07:21.136 --> 00:07:23.506 A:middle
and quickly update the UI to

00:07:23.506 --> 00:07:24.496 A:middle
reflect the mode I'm in.

00:07:25.666 --> 00:07:26.936 A:middle
The most important thing for you

00:07:26.936 --> 00:07:28.426 A:middle
to note is all of this can

00:07:28.426 --> 00:07:30.626 A:middle
happen real time on the device

00:07:30.626 --> 00:07:32.526 A:middle
as the user is typing, so it

00:07:32.526 --> 00:07:34.156 A:middle
makes for an amazing experience.

00:07:34.766 --> 00:07:37.466 A:middle
So let's see how you can go

00:07:37.466 --> 00:07:38.496 A:middle
ahead and build that app.

00:07:39.316 --> 00:07:40.436 A:middle
Well, the most important thing

00:07:40.436 --> 00:07:42.796 A:middle
here is the model, and for this

00:07:42.796 --> 00:07:43.836 A:middle
we're going to use a Sentiment

00:07:43.836 --> 00:07:44.576 A:middle
Analysis model.

00:07:45.276 --> 00:07:46.206 A:middle
But for this sent Sentiment

00:07:46.206 --> 00:07:47.286 A:middle
Analysis model is going to

00:07:47.286 --> 00:07:49.406 A:middle
operate on word counts not on

00:07:49.406 --> 00:07:50.846 A:middle
the raw text, but on word

00:07:50.846 --> 00:07:51.346 A:middle
counts.

00:07:52.066 --> 00:07:53.366 A:middle
So these word counts will be

00:07:53.366 --> 00:07:54.906 A:middle
represented as dictionaries

00:07:55.876 --> 00:07:57.966 A:middle
where the keys are the words and

00:07:57.966 --> 00:07:59.326 A:middle
the values are the number of

00:07:59.326 --> 00:08:00.606 A:middle
times that word appears in a

00:07:59.326 --> 00:08:00.606 A:middle
times that word appears in a

00:08:00.646 --> 00:08:01.006 A:middle
sentence.

00:08:01.796 --> 00:08:03.446 A:middle
So Core ML is awesome.

00:08:03.446 --> 00:08:04.276 A:middle
I love using it.

00:08:04.276 --> 00:08:05.656 A:middle
Translates to a dictionary that

00:08:05.656 --> 00:08:06.466 A:middle
looks a bit like this.

00:08:07.816 --> 00:08:09.376 A:middle
So once I have my Word Counts I

00:08:09.466 --> 00:08:10.856 A:middle
can pass that to my Sentiment

00:08:10.856 --> 00:08:12.796 A:middle
Analysis model and I can get

00:08:12.796 --> 00:08:13.446 A:middle
back a prediction.

00:08:13.976 --> 00:08:16.356 A:middle
In this case it's "happy".

00:08:16.556 --> 00:08:17.756 A:middle
But you might wonder, okay, how

00:08:17.756 --> 00:08:19.346 A:middle
do I go for my raw text to word

00:08:19.346 --> 00:08:19.786 A:middle
count.

00:08:20.486 --> 00:08:21.616 A:middle
Well, you might have already

00:08:21.616 --> 00:08:23.336 A:middle
seen the session on NLP, but you

00:08:23.416 --> 00:08:25.356 A:middle
can use the already existing

00:08:25.356 --> 00:08:27.646 A:middle
tools in the NSLinguisticTagger

00:08:27.776 --> 00:08:29.366 A:middle
to tokenize and count number of

00:08:29.366 --> 00:08:29.696 A:middle
words.

00:08:30.196 --> 00:08:32.856 A:middle
So I'll use NLP to preprocess my

00:08:32.856 --> 00:08:34.265 A:middle
texts, specifically the

00:08:34.265 --> 00:08:36.186 A:middle
NSLinguisticTagger, and then I'm

00:08:36.186 --> 00:08:37.496 A:middle
going to get my word counts

00:08:37.946 --> 00:08:39.326 A:middle
which I'll then give to a model

00:08:39.696 --> 00:08:40.726 A:middle
and get a prediction out of it.

00:08:41.836 --> 00:08:43.306 A:middle
So with that, you can build an

00:08:43.306 --> 00:08:44.236 A:middle
application like this.

00:08:44.766 --> 00:08:46.236 A:middle
But let's not just talk about

00:08:46.236 --> 00:08:47.196 A:middle
it, let's go ahead and do it.

00:08:48.376 --> 00:08:51.986 A:middle
So I'm going to walk over and

00:08:51.986 --> 00:08:56.906 A:middle
open up Xcode.

00:08:57.036 --> 00:08:59.426 A:middle
So what I have here is Xcode and

00:08:59.426 --> 00:09:00.036 A:middle
a simulator.

00:08:59.426 --> 00:09:00.036 A:middle
a simulator.

00:09:00.736 --> 00:09:02.186 A:middle
The simulator is now running an

00:09:02.186 --> 00:09:02.626 A:middle
app shell.

00:09:03.146 --> 00:09:04.106 A:middle
The app shell doesn't have the

00:09:04.106 --> 00:09:05.306 A:middle
model in there, so if I type

00:09:05.306 --> 00:09:07.806 A:middle
something, let's say, Core ML is

00:09:09.036 --> 00:09:11.826 A:middle
amazing, amazing fun, nothing

00:09:11.826 --> 00:09:13.266 A:middle
really happens to the UI.

00:09:13.806 --> 00:09:14.946 A:middle
So what we're going to do right

00:09:14.946 --> 00:09:16.376 A:middle
now is we're going to go ahead

00:09:16.376 --> 00:09:17.416 A:middle
and incorporate the machine

00:09:17.416 --> 00:09:19.216 A:middle
learning model in here so that

00:09:19.216 --> 00:09:20.526 A:middle
this app is going to become much

00:09:20.526 --> 00:09:21.216 A:middle
more vibrant.

00:09:21.216 --> 00:09:24.296 A:middle
So the first thing I'm going to

00:09:24.296 --> 00:09:27.716 A:middle
do is open up Finder and drag

00:09:27.716 --> 00:09:29.286 A:middle
the Sentiment Analysis model

00:09:29.526 --> 00:09:30.246 A:middle
into Xcode.

00:09:30.786 --> 00:09:33.726 A:middle
Let's go take a look at what

00:09:33.726 --> 00:09:34.346 A:middle
this model is.

00:09:35.276 --> 00:09:38.246 A:middle
So as you can see, this is a

00:09:38.246 --> 00:09:39.486 A:middle
Sentiment Analysis model.

00:09:40.206 --> 00:09:41.256 A:middle
The type of this model is a

00:09:41.256 --> 00:09:43.026 A:middle
Pipeline Classifier, so it does

00:09:43.026 --> 00:09:44.206 A:middle
a couple different things before

00:09:44.206 --> 00:09:45.326 A:middle
it gives the final prediction.

00:09:46.686 --> 00:09:49.136 A:middle
It's only 167 kilobytes, so it's

00:09:49.136 --> 00:09:49.876 A:middle
pretty tiny.

00:09:51.256 --> 00:09:53.456 A:middle
And the inputs to this model are

00:09:53.456 --> 00:09:55.356 A:middle
word counts, and the word counts

00:09:55.456 --> 00:09:58.476 A:middle
are dictionaries where the key

00:09:58.476 --> 00:09:59.576 A:middle
is the word and the value is the

00:09:59.576 --> 00:10:00.796 A:middle
number of time that word

00:09:59.576 --> 00:10:00.796 A:middle
number of time that word

00:10:00.796 --> 00:10:01.186 A:middle
appeared.

00:10:01.916 --> 00:10:03.206 A:middle
And I get two outputs from this

00:10:03.206 --> 00:10:05.556 A:middle
model, a Sentiment Label, that's

00:10:05.556 --> 00:10:06.366 A:middle
one of two things.

00:10:06.616 --> 00:10:08.676 A:middle
It's either good or bad.

00:10:08.676 --> 00:10:11.546 A:middle
And a Sentiment Score, which is

00:10:11.546 --> 00:10:13.696 A:middle
a probability associated with

00:10:13.696 --> 00:10:15.326 A:middle
the good sentiment or the bad

00:10:15.326 --> 00:10:15.716 A:middle
sentiment.

00:10:16.756 --> 00:10:17.656 A:middle
So that's a dictionary.

00:10:18.346 --> 00:10:19.646 A:middle
So what I'm going to use in this

00:10:19.646 --> 00:10:20.926 A:middle
application is I'm going to use

00:10:20.926 --> 00:10:23.146 A:middle
the Sentiment Score to determine

00:10:23.416 --> 00:10:25.306 A:middle
within a range of zero to 1 how

00:10:25.306 --> 00:10:26.866 A:middle
nice this text was, and that's

00:10:26.866 --> 00:10:27.936 A:middle
what I'm going to be using to

00:10:27.936 --> 00:10:29.426 A:middle
update my UI.

00:10:30.716 --> 00:10:32.846 A:middle
So let me go ahead and include

00:10:33.196 --> 00:10:34.786 A:middle
this model in the target of my

00:10:34.786 --> 00:10:37.766 A:middle
application, and then Xcode will

00:10:37.766 --> 00:10:39.066 A:middle
automatically generate a nice

00:10:39.066 --> 00:10:39.956 A:middle
interface for me.

00:10:40.616 --> 00:10:41.706 A:middle
So I can go back to my

00:10:41.706 --> 00:10:43.466 A:middle
ViewController and now I'm going

00:10:43.466 --> 00:10:44.536 A:middle
to implement the logic to

00:10:44.896 --> 00:10:45.996 A:middle
incorporate this Machine

00:10:45.996 --> 00:10:46.866 A:middle
Learning Model in there.

00:10:47.566 --> 00:10:48.566 A:middle
So for that, I'm going to

00:10:48.566 --> 00:10:50.236 A:middle
implement this function, predict

00:10:50.236 --> 00:10:51.886 A:middle
SentimentScoreFromRawText.

00:10:52.236 --> 00:10:53.456 A:middle
So this function is going to

00:10:53.456 --> 00:10:54.666 A:middle
take a sentence which is the

00:10:54.666 --> 00:10:55.816 A:middle
entire string.

00:10:56.526 --> 00:10:57.816 A:middle
It gets called every time the

00:10:57.816 --> 00:11:00.006 A:middle
user types a space, and what it

00:10:57.816 --> 00:11:00.006 A:middle
user types a space, and what it

00:11:00.006 --> 00:11:01.446 A:middle
returns is a double value

00:11:01.786 --> 00:11:03.406 A:middle
between zero and 1, where zero

00:11:03.406 --> 00:11:05.216 A:middle
is really, really sad and 1 is

00:11:05.216 --> 00:11:05.986 A:middle
really, really happy.

00:11:07.906 --> 00:11:09.086 A:middle
So the first thing I want to do

00:11:09.086 --> 00:11:10.256 A:middle
is I'm going to instantiate this

00:11:10.256 --> 00:11:11.746 A:middle
model, and I can simply do that

00:11:11.746 --> 00:11:13.236 A:middle
by saying let model =

00:11:13.286 --> 00:11:14.286 A:middle
SentimentAnalysis.

00:11:15.376 --> 00:11:16.956 A:middle
And then I'm going to predict

00:11:16.956 --> 00:11:19.156 A:middle
use this model to make this

00:11:19.186 --> 00:11:19.656 A:middle
prediction.

00:11:19.976 --> 00:11:21.076 A:middle
But as you can see, the input

00:11:21.076 --> 00:11:22.676 A:middle
here is a sentence but what I

00:11:22.676 --> 00:11:24.116 A:middle
really want is a word count.

00:11:24.996 --> 00:11:26.146 A:middle
So I've already implemented this

00:11:26.146 --> 00:11:26.896 A:middle
function called

00:11:26.896 --> 00:11:28.106 A:middle
tokenizeAndCountWords.

00:11:28.546 --> 00:11:29.536 A:middle
This function uses the

00:11:29.536 --> 00:11:31.176 A:middle
NSLinguisticTagger to tokenize

00:11:31.176 --> 00:11:32.256 A:middle
the sentence and then count the

00:11:32.256 --> 00:11:33.876 A:middle
number of tokens in that

00:11:33.876 --> 00:11:34.296 A:middle
sentence.

00:11:34.636 --> 00:11:35.696 A:middle
So I'm going to skip over that

00:11:35.696 --> 00:11:38.546 A:middle
and I'm just going to call that

00:11:38.546 --> 00:11:38.996 A:middle
function.

00:11:38.996 --> 00:11:39.856 A:middle
So I'm going to say let

00:11:39.856 --> 00:11:41.486 A:middle
WordCounts =

00:11:41.776 --> 00:11:43.786 A:middle
tokenizeAndCountWords sentence.

00:11:44.896 --> 00:11:46.036 A:middle
And then I'm going to use this

00:11:46.036 --> 00:11:47.316 A:middle
word count and provide that to

00:11:47.316 --> 00:11:47.776 A:middle
my model.

00:11:47.776 --> 00:11:49.686 A:middle
So I'm going to say if let

00:11:49.686 --> 00:11:52.116 A:middle
prediction = try

00:11:52.116 --> 00:11:54.166 A:middle
model.prediction(wordCounts),

00:11:54.736 --> 00:11:56.246 A:middle
and simply pass that wordCount

00:11:56.246 --> 00:11:56.526 A:middle
there.

00:11:57.456 --> 00:11:59.116 A:middle
And if this succeeds, I'm going

00:11:59.116 --> 00:12:01.456 A:middle
to use the prediction object to

00:11:59.116 --> 00:12:01.456 A:middle
to use the prediction object to

00:12:01.456 --> 00:12:03.186 A:middle
get out the sentiment score, but

00:12:03.186 --> 00:12:04.466 A:middle
because I want a value between

00:12:04.466 --> 00:12:05.646 A:middle
zero and 1 I'm going to get the

00:12:05.646 --> 00:12:06.666 A:middle
score and not the label.

00:12:07.176 --> 00:12:08.406 A:middle
So I'll take the sentiment score

00:12:08.406 --> 00:12:09.726 A:middle
associated with the sentiment

00:12:09.726 --> 00:12:11.286 A:middle
"good" and I'll return that to

00:12:11.286 --> 00:12:11.666 A:middle
my UI.

00:12:11.666 --> 00:12:13.606 A:middle
And if this fails, by any

00:12:13.606 --> 00:12:14.766 A:middle
chance, I'm going to go down

00:12:14.766 --> 00:12:15.446 A:middle
0.5.

00:12:15.636 --> 00:12:16.486 A:middle
So I have a little error

00:12:16.486 --> 00:12:19.636 A:middle
handling here as well.

00:12:19.836 --> 00:12:20.986 A:middle
So I'm going to go ahead and

00:12:20.986 --> 00:12:21.926 A:middle
build that application.

00:12:22.326 --> 00:12:23.846 A:middle
So during this process, as you

00:12:23.846 --> 00:12:25.196 A:middle
might be aware, the model and

00:12:25.196 --> 00:12:26.626 A:middle
the code are both getting

00:12:26.626 --> 00:12:28.536 A:middle
packaged and getting shipped to

00:12:28.536 --> 00:12:29.116 A:middle
the device.

00:12:29.776 --> 00:12:31.516 A:middle
Another thing to note is that

00:12:31.516 --> 00:12:33.236 A:middle
the compiler, the Core ML

00:12:33.236 --> 00:12:35.346 A:middle
compiler gets shipped as part of

00:12:35.346 --> 00:12:36.376 A:middle
the Xcode pool chain.

00:12:36.546 --> 00:12:37.646 A:middle
So if you want to compile them

00:12:37.646 --> 00:12:38.876 A:middle
all or run the code generator

00:12:38.876 --> 00:12:40.306 A:middle
yourself, you can use the

00:12:40.306 --> 00:12:41.046 A:middle
compiler directly.

00:12:42.616 --> 00:12:44.826 A:middle
So now let's go use this app and

00:12:44.826 --> 00:12:45.836 A:middle
let's type something nice.

00:12:46.716 --> 00:12:49.466 A:middle
Let's type "Core ML is amazing

00:12:49.506 --> 00:12:49.706 A:middle
fun."

00:12:49.706 --> 00:12:50.356 A:middle
That's what I want to write.

00:12:51.186 --> 00:12:53.606 A:middle
"Core ML is amazing fun and I

00:12:53.606 --> 00:12:54.546 A:middle
love using it."

00:12:55.546 --> 00:12:56.846 A:middle
So immediately you saw the UI

00:12:56.916 --> 00:12:58.236 A:middle
popped and I got a little green

00:12:58.236 --> 00:12:59.486 A:middle
and I'm happy and, you know,

00:12:59.636 --> 00:13:00.156 A:middle
this is great.

00:12:59.636 --> 00:13:00.156 A:middle
this is great.

00:13:01.516 --> 00:13:03.706 A:middle
[ Applause ]

00:13:04.206 --> 00:13:05.846 A:middle
But now I want to type something

00:13:05.846 --> 00:13:07.356 A:middle
bad, but I don't really want to

00:13:07.356 --> 00:13:08.526 A:middle
make fun of anything or anyone

00:13:08.526 --> 00:13:09.606 A:middle
so I want to talk about how my

00:13:09.606 --> 00:13:11.186 A:middle
life is terrible without CoreML.

00:13:12.516 --> 00:13:15.356 A:middle
"Life without CoreML is sloppy,

00:13:16.516 --> 00:13:19.896 A:middle
terrible and sad."

00:13:20.806 --> 00:13:22.396 A:middle
So obviously the UI is really

00:13:22.476 --> 00:13:23.716 A:middle
sad because, you know, life

00:13:23.716 --> 00:13:25.106 A:middle
without Core ML is really sad.

00:13:26.046 --> 00:13:27.746 A:middle
So what we really saw was a

00:13:27.916 --> 00:13:30.486 A:middle
seamless integration between NLP

00:13:30.486 --> 00:13:32.056 A:middle
and Core ML, so I built this

00:13:32.056 --> 00:13:33.586 A:middle
Sentiment Analysis Model and I

00:13:33.586 --> 00:13:35.256 A:middle
was able to make my application

00:13:35.256 --> 00:13:36.506 A:middle
a lot more vibrant.

00:13:36.626 --> 00:13:38.256 A:middle
And all of this was happening in

00:13:38.256 --> 00:13:39.976 A:middle
real time on the device as the

00:13:39.976 --> 00:13:40.696 A:middle
user typed it.

00:13:42.076 --> 00:13:45.996 A:middle
So that was pretty cool.

00:13:46.196 --> 00:13:48.256 A:middle
Let's go recap the two main

00:13:48.256 --> 00:13:49.296 A:middle
things that we talked about in

00:13:49.296 --> 00:13:49.716 A:middle
this demo.

00:13:50.446 --> 00:13:52.196 A:middle
So the first thing was that the

00:13:52.196 --> 00:13:54.136 A:middle
preprocess text we use the

00:13:54.136 --> 00:13:55.046 A:middle
NSLinguisticTagger.

00:13:55.516 --> 00:13:58.586 A:middle
The second thing was that once I

00:13:58.586 --> 00:14:00.106 A:middle
got those word counts I could

00:13:58.586 --> 00:14:00.106 A:middle
got those word counts I could

00:14:00.106 --> 00:14:01.546 A:middle
then give it to a model and get

00:14:01.546 --> 00:14:03.536 A:middle
a prediction out of it.

00:14:03.846 --> 00:14:05.126 A:middle
And this is a pattern you're

00:14:05.126 --> 00:14:06.886 A:middle
going to encounter a lot with

00:14:06.886 --> 00:14:08.756 A:middle
text based applications because

00:14:08.756 --> 00:14:11.066 A:middle
most text space applications do

00:14:11.066 --> 00:14:13.106 A:middle
not work directly on raw text.

00:14:13.666 --> 00:14:15.836 A:middle
There's always a little bit of

00:14:15.836 --> 00:14:16.946 A:middle
preprocessing that you have to

00:14:16.946 --> 00:14:17.396 A:middle
do for it.

00:14:17.966 --> 00:14:20.616 A:middle
But that was really a simple

00:14:20.616 --> 00:14:21.126 A:middle
example.

00:14:21.126 --> 00:14:22.436 A:middle
It was an introductory example.

00:14:22.966 --> 00:14:24.276 A:middle
Let's step our game, let's get

00:14:24.276 --> 00:14:24.966 A:middle
to the next level.

00:14:25.666 --> 00:14:26.726 A:middle
Let's talk about something

00:14:26.726 --> 00:14:28.296 A:middle
you've all interacted with on a

00:14:28.296 --> 00:14:29.246 A:middle
daily basis.

00:14:29.916 --> 00:14:31.506 A:middle
This is the Apple keyboard.

00:14:32.496 --> 00:14:33.916 A:middle
Now, when you type words in the

00:14:33.916 --> 00:14:35.526 A:middle
Apple keyboard, as you might all

00:14:35.526 --> 00:14:36.866 A:middle
be aware, you get very

00:14:36.866 --> 00:14:38.816 A:middle
contextual predictions of what's

00:14:38.876 --> 00:14:40.336 A:middle
the next most likely word you're

00:14:40.336 --> 00:14:40.726 A:middle
going to type.

00:14:41.416 --> 00:14:43.176 A:middle
So if I say, "I'm not sure if

00:14:43.176 --> 00:14:45.876 A:middle
Oliver will eat oysters, but he

00:14:45.876 --> 00:14:46.526 A:middle
will."

00:14:46.666 --> 00:14:48.216 A:middle
They keyboard tells you "so",

00:14:48.216 --> 00:14:50.066 A:middle
"totally" and "love" are three

00:14:50.066 --> 00:14:52.196 A:middle
likely words you're going to

00:14:52.776 --> 00:14:53.166 A:middle
type next.

00:14:53.166 --> 00:14:54.766 A:middle
So how do you go about building

00:14:54.766 --> 00:14:56.166 A:middle
something as sophisticated as

00:14:56.166 --> 00:14:56.416 A:middle
this?

00:14:57.256 --> 00:14:58.416 A:middle
So this is a predictive

00:14:58.416 --> 00:15:00.356 A:middle
keyboard, and the machine

00:14:58.416 --> 00:15:00.356 A:middle
keyboard, and the machine

00:15:00.356 --> 00:15:02.856 A:middle
learning task here is to make a

00:15:02.856 --> 00:15:05.106 A:middle
prediction for the next word.

00:15:05.816 --> 00:15:07.706 A:middle
The model that's being used here

00:15:07.786 --> 00:15:08.986 A:middle
or the model that will be used

00:15:08.986 --> 00:15:11.046 A:middle
in an application like this is

00:15:11.486 --> 00:15:13.116 A:middle
usually a model that takes the

00:15:13.246 --> 00:15:14.146 A:middle
sequence of words.

00:15:14.386 --> 00:15:16.316 A:middle
So "I'm not sure Oliver will eat

00:15:16.316 --> 00:15:17.536 A:middle
oysters, but he will."

00:15:17.536 --> 00:15:18.746 A:middle
is a sequence of words.

00:15:18.746 --> 00:15:20.586 A:middle
I give that as input to the

00:15:20.586 --> 00:15:22.046 A:middle
model and I get a prediction.

00:15:23.186 --> 00:15:24.616 A:middle
So you might wonder, okay,

00:15:24.616 --> 00:15:26.426 A:middle
what's the difference between

00:15:26.426 --> 00:15:28.046 A:middle
this model that we just saw and

00:15:28.046 --> 00:15:29.136 A:middle
the Sentiment Analysis one?

00:15:29.136 --> 00:15:30.556 A:middle
They look the same to me.

00:15:31.496 --> 00:15:34.266 A:middle
The key difference is that here

00:15:34.336 --> 00:15:35.926 A:middle
the input is a sequence of

00:15:35.926 --> 00:15:36.236 A:middle
words.

00:15:36.866 --> 00:15:38.546 A:middle
So if you jumble up the words

00:15:38.546 --> 00:15:39.946 A:middle
and give it to the model you're

00:15:39.946 --> 00:15:41.066 A:middle
going to get a completely

00:15:41.066 --> 00:15:41.766 A:middle
different prediction.

00:15:43.536 --> 00:15:44.876 A:middle
And to do something like this,

00:15:44.876 --> 00:15:46.246 A:middle
most machine learning models

00:15:46.446 --> 00:15:48.166 A:middle
will have a notion of state

00:15:48.166 --> 00:15:50.086 A:middle
that's associated with them, and

00:15:50.086 --> 00:15:50.996 A:middle
that's how they get this

00:15:50.996 --> 00:15:51.456 A:middle
behavior.

00:15:52.166 --> 00:15:54.186 A:middle
And the state gets passed along

00:15:54.416 --> 00:15:55.766 A:middle
as every prediction is made.

00:15:56.246 --> 00:15:58.136 A:middle
So it's like a baton in a relay

00:15:58.136 --> 00:15:58.406 A:middle
race.

00:15:58.626 --> 00:15:59.246 A:middle
Every time you make a

00:15:59.246 --> 00:16:00.656 A:middle
prediction, take the state and

00:15:59.246 --> 00:16:00.656 A:middle
prediction, take the state and

00:16:00.656 --> 00:16:02.906 A:middle
pass it along.

00:16:03.056 --> 00:16:04.416 A:middle
We're going to do something like

00:16:04.416 --> 00:16:06.616 A:middle
this using an LSDM, usually.

00:16:06.886 --> 00:16:08.546 A:middle
Specifically, like a [inaudible]

00:16:08.546 --> 00:16:09.256 A:middle
network.

00:16:09.696 --> 00:16:11.056 A:middle
But with Core ML, all of this is

00:16:11.056 --> 00:16:12.026 A:middle
going to be a lot easier.

00:16:12.606 --> 00:16:13.766 A:middle
So, let's take a look at what

00:16:13.766 --> 00:16:16.056 A:middle
you do but we'll do it with a

00:16:16.056 --> 00:16:17.356 A:middle
little more fun application.

00:16:17.736 --> 00:16:18.756 A:middle
We'll do it with a Shakespeare

00:16:18.756 --> 00:16:19.136 A:middle
Keyboard.

00:16:19.786 --> 00:16:20.706 A:middle
So instead of a regular

00:16:20.706 --> 00:16:22.376 A:middle
keyboard, this keyboard is going

00:16:22.376 --> 00:16:23.066 A:middle
to make me sound like

00:16:23.066 --> 00:16:23.476 A:middle
Shakespeare.

00:16:24.176 --> 00:16:26.336 A:middle
So if I say, "Shall I compare?"

00:16:26.656 --> 00:16:28.216 A:middle
It should say "thee", "summers",

00:16:28.216 --> 00:16:29.316 A:middle
"day" are the next three words

00:16:29.316 --> 00:16:31.846 A:middle
I'm likely to type.

00:16:32.026 --> 00:16:33.626 A:middle
So, what's really the difference

00:16:33.626 --> 00:16:35.256 A:middle
between the Shakespeare Keyboard

00:16:35.256 --> 00:16:36.466 A:middle
and the regular keyboard?

00:16:36.466 --> 00:16:38.716 A:middle
It's really the model that's

00:16:38.766 --> 00:16:39.976 A:middle
predicting the next word.

00:16:40.506 --> 00:16:42.076 A:middle
So one of those models is

00:16:42.136 --> 00:16:43.636 A:middle
trained on Shakespeare data and

00:16:44.126 --> 00:16:45.936 A:middle
another one is just trained on

00:16:45.936 --> 00:16:47.046 A:middle
regular English data.

00:16:47.956 --> 00:16:49.386 A:middle
So this concept is the Language

00:16:49.386 --> 00:16:49.686 A:middle
Model.

00:16:50.576 --> 00:16:52.316 A:middle
So I just threw so many new

00:16:52.316 --> 00:16:53.536 A:middle
concepts at you, a Language

00:16:53.536 --> 00:16:54.856 A:middle
Model, Sequences, LSDM, but

00:16:54.856 --> 00:16:57.196 A:middle
don't worry, with Core ML this

00:16:57.196 --> 00:16:58.256 A:middle
should be a lot easier.

00:16:58.796 --> 00:16:59.616 A:middle
Let's see how you would do

00:16:59.616 --> 00:17:00.236 A:middle
something like this.

00:16:59.616 --> 00:17:00.236 A:middle
something like this.

00:17:01.406 --> 00:17:04.096 A:middle
So I start with a model and I'm

00:17:04.096 --> 00:17:05.476 A:middle
going to give it the first word,

00:17:05.476 --> 00:17:07.185 A:middle
let's say in this case, "Shall".

00:17:08.266 --> 00:17:09.606 A:middle
That's the current word.

00:17:10.596 --> 00:17:12.236 A:middle
And what I'll get back from the

00:17:12.236 --> 00:17:13.526 A:middle
model are two things.

00:17:14.646 --> 00:17:16.236 A:middle
A set of choices for the next

00:17:16.236 --> 00:17:16.526 A:middle
word.

00:17:16.826 --> 00:17:19.316 A:middle
So in this case I get basically

00:17:19.316 --> 00:17:20.726 A:middle
a probability associated with

00:17:20.726 --> 00:17:23.266 A:middle
all the set of next words, and

00:17:23.776 --> 00:17:25.415 A:middle
I'm also going to get a state

00:17:25.715 --> 00:17:27.256 A:middle
associated with this prediction.

00:17:28.616 --> 00:17:29.986 A:middle
So I'll take these next word

00:17:29.986 --> 00:17:31.596 A:middle
choices and I'll give them to

00:17:31.596 --> 00:17:32.016 A:middle
the user.

00:17:32.016 --> 00:17:34.376 A:middle
The user will either select one

00:17:34.376 --> 00:17:35.816 A:middle
of those three words or maybe

00:17:35.816 --> 00:17:37.176 A:middle
they'll type their own word.

00:17:37.176 --> 00:17:38.916 A:middle
Either way I get a next word.

00:17:40.336 --> 00:17:41.906 A:middle
I'll use that next word, pass it

00:17:41.906 --> 00:17:42.976 A:middle
back to the model for the next

00:17:42.976 --> 00:17:44.786 A:middle
prediction, and I'm also going

00:17:44.786 --> 00:17:46.106 A:middle
to take the state, pass it back

00:17:46.106 --> 00:17:47.016 A:middle
to the model for the next

00:17:47.016 --> 00:17:47.386 A:middle
prediction.

00:17:48.406 --> 00:17:50.226 A:middle
So in steady state every time

00:17:50.226 --> 00:17:51.166 A:middle
you're going to do two things.

00:17:51.646 --> 00:17:52.576 A:middle
You're going to take the current

00:17:52.576 --> 00:17:53.846 A:middle
word in the state and give it to

00:17:53.846 --> 00:17:55.536 A:middle
the model, and what you'll get

00:17:55.536 --> 00:17:57.026 A:middle
back are the set of choices for

00:17:57.026 --> 00:17:58.356 A:middle
the next word and some state.

00:17:59.256 --> 00:18:00.016 A:middle
And the second thing you're

00:17:59.256 --> 00:18:00.016 A:middle
And the second thing you're

00:18:00.016 --> 00:18:00.726 A:middle
going to do is you're going to

00:18:00.726 --> 00:18:02.036 A:middle
pass that all back to the model

00:18:02.036 --> 00:18:02.816 A:middle
for the next prediction.

00:18:03.236 --> 00:18:04.296 A:middle
So, it's pretty simple.

00:18:05.076 --> 00:18:06.066 A:middle
Let's see what the code would

00:18:06.066 --> 00:18:07.946 A:middle
look like to do something like

00:18:08.856 --> 00:18:08.956 A:middle
that.

00:18:09.186 --> 00:18:10.686 A:middle
So I'm going to start by saying

00:18:10.686 --> 00:18:11.536 A:middle
let output =

00:18:11.536 --> 00:18:12.666 A:middle
model.prediction(input).

00:18:12.666 --> 00:18:15.766 A:middle
I'll take the probabilities

00:18:15.766 --> 00:18:17.056 A:middle
associated with the next word

00:18:17.056 --> 00:18:18.686 A:middle
and I'll give it to a function

00:18:18.686 --> 00:18:20.486 A:middle
say displayTopPredictions which

00:18:20.826 --> 00:18:22.286 A:middle
says selects the top 3 and gives

00:18:22.286 --> 00:18:23.696 A:middle
that to the user.

00:18:24.636 --> 00:18:26.196 A:middle
The user is either going to

00:18:26.236 --> 00:18:27.576 A:middle
select one of those 3 words or

00:18:27.576 --> 00:18:29.236 A:middle
maybe type their own, either way

00:18:29.236 --> 00:18:30.696 A:middle
I'll get that from this function

00:18:30.696 --> 00:18:33.006 A:middle
getWordFromUser and I'll pass

00:18:33.006 --> 00:18:34.346 A:middle
that back to the input as the

00:18:34.346 --> 00:18:34.906 A:middle
current word.

00:18:35.396 --> 00:18:36.826 A:middle
I'll take the state, pass it

00:18:36.826 --> 00:18:38.696 A:middle
along to the model again.

00:18:39.246 --> 00:18:41.406 A:middle
So in just a few lines of code,

00:18:41.706 --> 00:18:43.276 A:middle
you can integrate a more less

00:18:43.326 --> 00:18:44.986 A:middle
complex as an LSDM that involves

00:18:44.986 --> 00:18:46.876 A:middle
state, the language model,

00:18:46.876 --> 00:18:48.296 A:middle
keyboard, all sorts of things in

00:18:48.296 --> 00:18:49.296 A:middle
just a few lines of code.

00:18:49.846 --> 00:18:51.036 A:middle
So that was about the different

00:18:51.036 --> 00:18:52.406 A:middle
sets of use cases and a little

00:18:52.406 --> 00:18:53.246 A:middle
bit about text.

00:18:54.416 --> 00:18:55.736 A:middle
Now let's talk about how Core ML

00:18:56.236 --> 00:18:58.006 A:middle
is optimized for the hardware on

00:18:58.006 --> 00:18:59.526 A:middle
which it runs and most

00:18:59.526 --> 00:19:01.106 A:middle
importantly what that means for

00:18:59.526 --> 00:19:01.106 A:middle
importantly what that means for

00:19:01.106 --> 00:19:02.196 A:middle
all of you when you're building

00:19:03.146 --> 00:19:03.276 A:middle
apps.

00:19:04.096 --> 00:19:05.506 A:middle
So we're going to motivate that

00:19:05.506 --> 00:19:07.576 A:middle
with a little video of real time

00:19:07.576 --> 00:19:08.366 A:middle
object detection.

00:19:09.336 --> 00:19:10.926 A:middle
What's important to note here is

00:19:10.926 --> 00:19:13.976 A:middle
that the camera feed is live

00:19:13.976 --> 00:19:15.556 A:middle
going to a model, and a

00:19:15.556 --> 00:19:17.236 A:middle
relatively powerful model, and

00:19:17.236 --> 00:19:18.196 A:middle
you're getting accurate

00:19:18.196 --> 00:19:20.306 A:middle
predictions as you see, live.

00:19:21.196 --> 00:19:22.846 A:middle
And this is only possible

00:19:23.006 --> 00:19:24.366 A:middle
because Core ML is super

00:19:24.366 --> 00:19:25.796 A:middle
optimized for the hardware on

00:19:25.796 --> 00:19:26.416 A:middle
which it runs.

00:19:27.126 --> 00:19:28.586 A:middle
And in this case, the model runs

00:19:28.586 --> 00:19:30.156 A:middle
in about, say, under 50

00:19:30.156 --> 00:19:30.816 A:middle
milliseconds.

00:19:31.486 --> 00:19:34.936 A:middle
I was hoping nobody laugh

00:19:34.936 --> 00:19:36.606 A:middle
because this joke has been said

00:19:36.716 --> 00:19:37.676 A:middle
7 times already.

00:19:38.516 --> 00:19:41.866 A:middle
[ Laughter and Applause ]

00:19:42.366 --> 00:19:44.236 A:middle
So what really matters for you

00:19:44.236 --> 00:19:45.646 A:middle
is that Core ML is built on top

00:19:45.646 --> 00:19:46.926 A:middle
of the performance primitives,

00:19:47.326 --> 00:19:49.096 A:middle
Accelerate and MPS.

00:19:49.626 --> 00:19:50.816 A:middle
But more importantly, it

00:19:50.816 --> 00:19:52.356 A:middle
completely hides the hardware

00:19:52.356 --> 00:19:53.456 A:middle
from you so you don't have to

00:19:53.456 --> 00:19:54.696 A:middle
worry about whether it's running

00:19:54.696 --> 00:19:56.636 A:middle
on the CPU or the GPU.

00:19:57.226 --> 00:19:58.606 A:middle
So that demo that you saw, you

00:19:58.606 --> 00:19:59.926 A:middle
might ask, okay, how many knobs

00:19:59.926 --> 00:20:01.126 A:middle
did I have to turn to get that

00:19:59.926 --> 00:20:01.126 A:middle
did I have to turn to get that

00:20:01.126 --> 00:20:01.526 A:middle
to work?

00:20:01.526 --> 00:20:02.916 A:middle
Well it's zero.

00:20:03.146 --> 00:20:04.076 A:middle
That's the performance you'll

00:20:04.076 --> 00:20:05.136 A:middle
get out of the box.

00:20:06.516 --> 00:20:11.766 A:middle
[ Applause ]

00:20:12.266 --> 00:20:14.406 A:middle
So specifically that demo that

00:20:14.406 --> 00:20:16.356 A:middle
you saw and flower predictor

00:20:16.356 --> 00:20:18.146 A:middle
that you saw earlier, those two

00:20:18.146 --> 00:20:20.696 A:middle
were compute heavy tasks, and we

00:20:20.696 --> 00:20:22.366 A:middle
knew that so we showed you them

00:20:22.366 --> 00:20:23.246 A:middle
on the GPU.

00:20:24.046 --> 00:20:25.526 A:middle
Whereas some of the text based

00:20:25.526 --> 00:20:27.316 A:middle
demos like Sentiment Analysis

00:20:27.316 --> 00:20:29.146 A:middle
and Next Word Prediction, these

00:20:29.146 --> 00:20:30.756 A:middle
were memory heavy tasks and

00:20:30.756 --> 00:20:32.246 A:middle
that's why we showed you them on

00:20:32.246 --> 00:20:32.826 A:middle
the CPU.

00:20:33.906 --> 00:20:35.346 A:middle
But most importantly, they all

00:20:35.396 --> 00:20:36.796 A:middle
just run on Core ML so you don't

00:20:36.796 --> 00:20:38.006 A:middle
have to worry about where it's

00:20:38.006 --> 00:20:38.306 A:middle
running.

00:20:38.486 --> 00:20:39.636 A:middle
We've got your back.

00:20:40.396 --> 00:20:42.296 A:middle
And this kind of abstraction

00:20:42.296 --> 00:20:43.746 A:middle
lets us do powerful things.

00:20:44.376 --> 00:20:46.006 A:middle
So for the Image Captioning, for

00:20:46.006 --> 00:20:47.706 A:middle
example, where part of that

00:20:47.706 --> 00:20:49.596 A:middle
model is compute heavy and part

00:20:49.596 --> 00:20:51.336 A:middle
of that model is memory heavy,

00:20:51.536 --> 00:20:53.096 A:middle
we automatically contact Switch

00:20:53.096 --> 00:20:55.346 A:middle
from the GPU to the CPU so that

00:20:55.346 --> 00:20:56.906 A:middle
you can get the best of both

00:20:57.546 --> 00:20:57.696 A:middle
worlds.

00:20:58.836 --> 00:21:01.136 A:middle
So this was all about use cases

00:20:58.836 --> 00:21:01.136 A:middle
So this was all about use cases

00:21:01.136 --> 00:21:03.656 A:middle
and performance, but Core ML is

00:21:03.656 --> 00:21:04.646 A:middle
much more than just the

00:21:04.646 --> 00:21:05.236 A:middle
framework.

00:21:05.686 --> 00:21:06.896 A:middle
It's a file format and a

00:21:06.956 --> 00:21:08.796 A:middle
collection of tools to help you

00:21:08.796 --> 00:21:10.126 A:middle
get more and more models that

00:21:10.126 --> 00:21:11.186 A:middle
you can use in your apps.

00:21:11.706 --> 00:21:12.936 A:middle
And to talk about that, I'd like

00:21:12.936 --> 00:21:13.866 A:middle
to invite my friend and

00:21:13.866 --> 00:21:14.866 A:middle
colleague, Zach.

00:21:16.516 --> 00:21:22.736 A:middle
[ Applause ]

00:21:23.236 --> 00:21:23.876 A:middle
&gt;&gt; Thanks, Krishna.

00:21:25.036 --> 00:21:27.176 A:middle
Hi. My name is Zach and I'm an

00:21:27.176 --> 00:21:29.506 A:middle
engineer on the Core ML

00:21:29.506 --> 00:21:30.186 A:middle
Engineering Team.

00:21:31.516 --> 00:21:33.996 A:middle
[ Applause ]

00:21:34.496 --> 00:21:35.676 A:middle
And I'm really excited to talk

00:21:35.726 --> 00:21:37.856 A:middle
to you today about the Core ML

00:21:38.006 --> 00:21:39.716 A:middle
Model Format and where you can

00:21:39.716 --> 00:21:41.526 A:middle
get models in this format for

00:21:41.526 --> 00:21:43.356 A:middle
use in your apps.

00:21:44.176 --> 00:21:46.136 A:middle
So by now, you've seen this

00:21:46.136 --> 00:21:48.006 A:middle
diagram many times and this

00:21:48.006 --> 00:21:50.146 A:middle
shows how easy it is to use a

00:21:50.146 --> 00:21:51.206 A:middle
Machine Learning Model.

00:21:51.386 --> 00:21:52.816 A:middle
Simply drag and drop it into

00:21:53.076 --> 00:21:54.106 A:middle
Xcode and you get a code

00:21:54.106 --> 00:21:54.596 A:middle
interface.

00:21:55.326 --> 00:21:56.356 A:middle
But by now you're probably

00:21:56.356 --> 00:21:58.356 A:middle
wondering where do these models

00:21:58.356 --> 00:21:58.856 A:middle
come from?

00:21:59.306 --> 00:22:02.076 A:middle
Well, there are really two

00:21:59.306 --> 00:22:02.076 A:middle
Well, there are really two

00:22:02.076 --> 00:22:04.146 A:middle
places you can look for Machine

00:22:04.146 --> 00:22:05.486 A:middle
Learning Models in the Core ML

00:22:05.486 --> 00:22:06.076 A:middle
Model Format.

00:22:06.926 --> 00:22:09.216 A:middle
The first is the example models

00:22:09.436 --> 00:22:10.966 A:middle
on developer.apple.com.

00:22:11.686 --> 00:22:13.146 A:middle
These are a variety of

00:22:13.206 --> 00:22:15.336 A:middle
pre-trained models already in

00:22:15.476 --> 00:22:17.316 A:middle
the Core ML Model Format and

00:22:17.316 --> 00:22:18.636 A:middle
this is the easiest way to get

00:22:18.636 --> 00:22:20.086 A:middle
started if you're new to machine

00:22:20.086 --> 00:22:20.326 A:middle
learning.

00:22:21.426 --> 00:22:23.456 A:middle
But we also know there's a whole

00:22:23.456 --> 00:22:24.816 A:middle
wide world of machine learning

00:22:24.816 --> 00:22:25.296 A:middle
out there.

00:22:25.996 --> 00:22:27.196 A:middle
There are a lot of existing

00:22:27.256 --> 00:22:29.196 A:middle
popular training tools and a lot

00:22:29.196 --> 00:22:31.006 A:middle
of existing models out there in

00:22:31.006 --> 00:22:32.056 A:middle
these formats already.

00:22:32.626 --> 00:22:33.976 A:middle
So we want to make it possible

00:22:34.186 --> 00:22:35.796 A:middle
to take machine learning models,

00:22:36.086 --> 00:22:37.546 A:middle
trained using the most popular

00:22:37.546 --> 00:22:40.146 A:middle
tools, and use them in your apps

00:22:40.146 --> 00:22:40.486 A:middle
today.

00:22:42.156 --> 00:22:44.276 A:middle
So to that end, we've created

00:22:44.536 --> 00:22:45.546 A:middle
Core ML Tools.

00:22:46.236 --> 00:22:47.946 A:middle
It's a converter package that

00:22:47.946 --> 00:22:49.706 A:middle
takes models in a variety of

00:22:49.746 --> 00:22:51.606 A:middle
popular formats and converts

00:22:51.656 --> 00:22:53.056 A:middle
them into the Core ML Model

00:22:53.056 --> 00:22:56.546 A:middle
Format and it's open source.

00:22:57.516 --> 00:23:02.786 A:middle
[ Applause ]

00:22:57.516 --> 00:23:02.786 A:middle
[ Applause ]

00:23:03.286 --> 00:23:04.566 A:middle
We've released Core ML Tools

00:23:04.566 --> 00:23:06.416 A:middle
under the permissive BSD license

00:23:06.736 --> 00:23:09.416 A:middle
so that there are no barriers to

00:23:12.086 --> 00:23:12.296 A:middle
adoption.

00:23:12.426 --> 00:23:14.846 A:middle
So to get a model off the

00:23:14.846 --> 00:23:16.056 A:middle
internet somewhere, you're going

00:23:16.056 --> 00:23:17.396 A:middle
to start with a model in a

00:23:17.396 --> 00:23:18.116 A:middle
different format.

00:23:18.116 --> 00:23:18.806 A:middle
Let's say Caffe.

00:23:19.926 --> 00:23:21.316 A:middle
So Caffe is a really popular

00:23:21.316 --> 00:23:22.586 A:middle
deep learning training library.

00:23:23.126 --> 00:23:25.076 A:middle
If you're starting with a model

00:23:25.076 --> 00:23:26.946 A:middle
in, say, Caffe Format, the way

00:23:26.946 --> 00:23:28.136 A:middle
that you get it into Core ML

00:23:28.136 --> 00:23:29.476 A:middle
Model Format and to use it in

00:23:29.476 --> 00:23:31.106 A:middle
your application is to run it

00:23:31.196 --> 00:23:32.966 A:middle
through a converter from Core ML

00:23:32.966 --> 00:23:33.336 A:middle
Tools.

00:23:34.206 --> 00:23:36.156 A:middle
Or if you don't find a model out

00:23:36.156 --> 00:23:37.386 A:middle
there that does what you want,

00:23:37.916 --> 00:23:38.996 A:middle
you can start with your own

00:23:38.996 --> 00:23:40.826 A:middle
training data and use any of a

00:23:40.826 --> 00:23:42.416 A:middle
variety of these popular tools

00:23:42.636 --> 00:23:43.946 A:middle
to train your own model in that

00:23:43.946 --> 00:23:44.326 A:middle
format.

00:23:44.826 --> 00:23:46.326 A:middle
From there, again, you run the

00:23:46.326 --> 00:23:48.186 A:middle
converter to produce a model in

00:23:48.186 --> 00:23:49.796 A:middle
Core ML Model Format and the

00:23:49.796 --> 00:23:51.146 A:middle
rest of the workflow stays

00:23:51.146 --> 00:23:51.996 A:middle
exactly the same.

00:23:52.406 --> 00:23:53.686 A:middle
Simply drag and drop the model

00:23:53.686 --> 00:23:55.066 A:middle
into Xcode and you get a code

00:23:55.066 --> 00:23:55.726 A:middle
interface.

00:23:56.516 --> 00:24:01.500 A:middle
[ Applause ]

00:23:56.516 --> 00:24:01.500 A:middle
[ Applause ]

00:24:04.046 --> 00:24:06.296 A:middle
Using Core ML Tools is as easy

00:24:06.296 --> 00:24:08.716 A:middle
as pip install coremltools which

00:24:08.746 --> 00:24:09.726 A:middle
downloads and installs the

00:24:09.726 --> 00:24:10.306 A:middle
package.

00:24:10.886 --> 00:24:12.546 A:middle
This is a python package with

00:24:12.596 --> 00:24:14.296 A:middle
converters for a variety of

00:24:14.356 --> 00:24:16.166 A:middle
popular training tools, and most

00:24:16.166 --> 00:24:17.826 A:middle
of these tools are already in

00:24:17.826 --> 00:24:18.336 A:middle
python.

00:24:18.596 --> 00:24:19.776 A:middle
So to be part of that machine

00:24:19.776 --> 00:24:21.396 A:middle
learning ecosystem, this is a

00:24:21.396 --> 00:24:25.036 A:middle
python library as well.

00:24:25.236 --> 00:24:26.796 A:middle
Let's look at the breakdown of

00:24:26.796 --> 00:24:28.116 A:middle
what's inside this package.

00:24:28.866 --> 00:24:30.486 A:middle
At the very top are each of the

00:24:30.486 --> 00:24:32.466 A:middle
converters, and this is a set of

00:24:32.556 --> 00:24:34.586 A:middle
converters, one for each popular

00:24:34.586 --> 00:24:35.386 A:middle
training library.

00:24:36.616 --> 00:24:38.436 A:middle
Underneath that, we have Core ML

00:24:38.436 --> 00:24:40.076 A:middle
bindings and a converter

00:24:40.076 --> 00:24:41.636 A:middle
library, and this is what we've

00:24:41.636 --> 00:24:43.056 A:middle
used to build all of the

00:24:43.056 --> 00:24:43.646 A:middle
converters.

00:24:43.986 --> 00:24:45.806 A:middle
So here the Core ML bindings

00:24:46.166 --> 00:24:47.956 A:middle
allow you to call directly into

00:24:47.956 --> 00:24:49.746 A:middle
Core ML from python and get

00:24:49.746 --> 00:24:51.216 A:middle
backup prediction, and that's

00:24:51.386 --> 00:24:53.046 A:middle
really useful to verify that the

00:24:53.246 --> 00:24:54.676 A:middle
prediction you get for a

00:24:54.676 --> 00:24:56.156 A:middle
converted model is exactly the

00:24:56.156 --> 00:24:57.596 A:middle
same as the prediction you would

00:24:57.596 --> 00:24:59.146 A:middle
get with the original training

00:24:59.146 --> 00:24:59.646 A:middle
framework.

00:25:00.486 --> 00:25:01.516 A:middle
We also have a converter

00:25:01.516 --> 00:25:03.196 A:middle
library, which is a high-level

00:25:03.196 --> 00:25:05.296 A:middle
API for building converters, and

00:25:05.296 --> 00:25:06.696 A:middle
its shared code among all of

00:25:06.696 --> 00:25:08.016 A:middle
these converters so that make it

00:25:08.016 --> 00:25:09.246 A:middle
really easy to build new

00:25:09.246 --> 00:25:10.736 A:middle
converters for new formats.

00:25:12.196 --> 00:25:13.806 A:middle
Underneath all of that is the

00:25:13.806 --> 00:25:15.136 A:middle
Core ML Specification.

00:25:15.976 --> 00:25:18.146 A:middle
This is a read and write API to

00:25:18.146 --> 00:25:20.426 A:middle
the Core ML Model Format

00:25:20.426 --> 00:25:20.956 A:middle
directly.

00:25:21.466 --> 00:25:23.266 A:middle
So all of the individual fields

00:25:23.416 --> 00:25:26.556 A:middle
can be accessed here.

00:25:27.016 --> 00:25:28.266 A:middle
We've designed the package this

00:25:28.266 --> 00:25:30.836 A:middle
way so that it's compatible and

00:25:30.836 --> 00:25:31.506 A:middle
extensible.

00:25:32.126 --> 00:25:33.906 A:middle
At the top level, the converters

00:25:33.906 --> 00:25:36.756 A:middle
give Core ML compatibility with

00:25:36.756 --> 00:25:38.236 A:middle
a variety of popular tools.

00:25:39.776 --> 00:25:41.546 A:middle
Underneath that, the Core ML

00:25:41.546 --> 00:25:43.556 A:middle
Bindings, Converter Library, and

00:25:43.686 --> 00:25:45.536 A:middle
the Core ML Specification make

00:25:45.536 --> 00:25:47.596 A:middle
this package extensible so it's

00:25:47.596 --> 00:25:49.686 A:middle
easy to build new converters and

00:25:49.716 --> 00:25:51.696 A:middle
to build converters for a lot of

00:25:51.696 --> 00:25:52.896 A:middle
existing formats that aren't

00:25:52.926 --> 00:25:53.266 A:middle
there yet.

00:25:53.916 --> 00:25:55.686 A:middle
And because this is open source,

00:25:56.176 --> 00:25:57.856 A:middle
it's easy to take this package

00:25:58.166 --> 00:25:59.636 A:middle
and even integrate it into

00:25:59.636 --> 00:26:01.476 A:middle
another open source library and

00:25:59.636 --> 00:26:01.476 A:middle
another open source library and

00:26:01.476 --> 00:26:02.736 A:middle
build new converters on top.

00:26:02.736 --> 00:26:03.766 A:middle
And there are no restrictions

00:26:03.766 --> 00:26:04.016 A:middle
here.

00:26:04.126 --> 00:26:06.976 A:middle
This is BSD licensed.

00:26:07.516 --> 00:26:10.500 A:middle
[ Applause ]

00:26:13.226 --> 00:26:15.266 A:middle
The Core ML Model Format is a

00:26:15.266 --> 00:26:17.256 A:middle
single document format and it

00:26:17.256 --> 00:26:19.216 A:middle
encapsulates both the functional

00:26:19.216 --> 00:26:20.736 A:middle
description of the model in

00:26:20.736 --> 00:26:22.536 A:middle
terms of its inputs and outputs,

00:26:22.966 --> 00:26:24.126 A:middle
as well as the trained

00:26:24.156 --> 00:26:25.176 A:middle
parameters of the model.

00:26:25.576 --> 00:26:27.656 A:middle
So to look at an example, for a

00:26:27.656 --> 00:26:29.086 A:middle
simple model like a Linear

00:26:29.086 --> 00:26:30.716 A:middle
Regression, this would be the

00:26:30.716 --> 00:26:32.056 A:middle
set of weights and offset that

00:26:32.056 --> 00:26:33.166 A:middle
are learned at training time.

00:26:33.676 --> 00:26:35.246 A:middle
And for a more complex model

00:26:35.246 --> 00:26:36.676 A:middle
like a Neural Network, this

00:26:36.676 --> 00:26:38.476 A:middle
actually encapsulates both the

00:26:38.476 --> 00:26:40.406 A:middle
structure of the network as well

00:26:40.406 --> 00:26:41.866 A:middle
as the learned weights at

00:26:41.866 --> 00:26:42.416 A:middle
training time.

00:26:43.236 --> 00:26:44.976 A:middle
And this is a public file format

00:26:45.146 --> 00:26:46.596 A:middle
and it's fully documented on

00:26:46.596 --> 00:26:51.186 A:middle
developer.apple.com.

00:26:51.746 --> 00:26:53.016 A:middle
When you look at a Machine

00:26:53.016 --> 00:26:55.266 A:middle
Learning Model in Xcode, you see

00:26:55.266 --> 00:26:56.546 A:middle
a view something like this.

00:26:56.546 --> 00:26:57.776 A:middle
You get all of the metadata and

00:26:57.866 --> 00:26:59.936 A:middle
the functional interface, and

00:27:00.046 --> 00:27:02.116 A:middle
what we now see is that that's

00:27:02.116 --> 00:27:04.086 A:middle
entirely powered by this Core ML

00:27:04.086 --> 00:27:04.706 A:middle
Model Format.

00:27:04.766 --> 00:27:06.126 A:middle
So the Single Document Format

00:27:06.206 --> 00:27:07.526 A:middle
contains all the information

00:27:07.776 --> 00:27:09.506 A:middle
Xcode needs to give you a UI on

00:27:09.686 --> 00:27:11.316 A:middle
top of this model and to let

00:27:11.316 --> 00:27:12.816 A:middle
your code call it and then to

00:27:12.816 --> 00:27:14.846 A:middle
execute it on device.

00:27:16.356 --> 00:27:18.876 A:middle
The Core ML converters all work

00:27:18.876 --> 00:27:19.446 A:middle
in the same way.

00:27:20.096 --> 00:27:21.886 A:middle
They start by taking a model in

00:27:21.886 --> 00:27:23.466 A:middle
a source format, for instance

00:27:23.526 --> 00:27:25.936 A:middle
Caffe, and converting it into

00:27:25.936 --> 00:27:27.066 A:middle
the Core ML Model Format.

00:27:28.246 --> 00:27:30.426 A:middle
There's a set of unified APIs to

00:27:30.426 --> 00:27:31.906 A:middle
convert these models from a

00:27:31.906 --> 00:27:33.656 A:middle
variety of formats into Core ML

00:27:33.656 --> 00:27:34.046 A:middle
Format.

00:27:34.446 --> 00:27:35.506 A:middle
So if you know how to convert

00:27:35.506 --> 00:27:36.956 A:middle
from one format, you know how to

00:27:36.996 --> 00:27:38.366 A:middle
convert from all formats.

00:27:39.026 --> 00:27:43.366 A:middle
Let's take an example and look

00:27:43.366 --> 00:27:44.916 A:middle
more closely at how we would

00:27:44.916 --> 00:27:46.416 A:middle
convert a Caffe model.

00:27:47.466 --> 00:27:48.916 A:middle
Caffe works a bit like this.

00:27:49.146 --> 00:27:50.626 A:middle
It has several files to

00:27:50.626 --> 00:27:51.546 A:middle
represent the model.

00:27:52.236 --> 00:27:54.556 A:middle
The .caffemodel file represents

00:27:54.716 --> 00:27:56.036 A:middle
the learned weights in that

00:27:56.126 --> 00:27:58.846 A:middle
model which the .prototxt file

00:27:59.126 --> 00:28:00.626 A:middle
represents the structure of the

00:27:59.126 --> 00:28:00.626 A:middle
represents the structure of the

00:28:00.626 --> 00:28:01.276 A:middle
Neural Network.

00:28:02.516 --> 00:28:04.166 A:middle
When Caffe is doing inference,

00:28:04.806 --> 00:28:06.126 A:middle
you would start by taking an

00:28:06.126 --> 00:28:07.876 A:middle
image, say, like a rose like

00:28:07.916 --> 00:28:10.156 A:middle
this, and you'd pass it into

00:28:10.156 --> 00:28:11.206 A:middle
Caffe with these two files.

00:28:11.796 --> 00:28:13.346 A:middle
And Caffe would give back an

00:28:13.426 --> 00:28:15.146 A:middle
index of a class label like,

00:28:15.246 --> 00:28:16.236 A:middle
say, 74.

00:28:17.186 --> 00:28:18.696 A:middle
Then there's a third file, a

00:28:18.696 --> 00:28:21.226 A:middle
labels.txt that maps those

00:28:21.226 --> 00:28:23.356 A:middle
indices to string class labels

00:28:23.576 --> 00:28:24.186 A:middle
like "Rose".

00:28:25.066 --> 00:28:26.606 A:middle
So it's important to note that

00:28:26.656 --> 00:28:28.886 A:middle
those 3 files really encapsulate

00:28:28.886 --> 00:28:30.296 A:middle
together all of the information

00:28:30.296 --> 00:28:31.716 A:middle
in the model, and so that's

00:28:31.716 --> 00:28:33.156 A:middle
what's needed for conversion

00:28:33.156 --> 00:28:34.226 A:middle
into the Core ML Format.

00:28:35.896 --> 00:28:38.606 A:middle
So now, let's look at an example

00:28:38.606 --> 00:28:40.396 A:middle
of converting a Caffe model into

00:28:40.396 --> 00:28:42.526 A:middle
a Core ML Model.

00:28:43.516 --> 00:28:46.500 A:middle
[ Applause ]

00:28:51.066 --> 00:28:52.706 A:middle
I'm going to start by opening an

00:28:52.706 --> 00:28:54.226 A:middle
interactive python prompt here.

00:28:54.696 --> 00:28:56.466 A:middle
So we can type python code and

00:28:56.466 --> 00:28:58.716 A:middle
see the output in the real time.

00:28:59.536 --> 00:29:00.846 A:middle
So I'm going to start by

00:28:59.536 --> 00:29:00.846 A:middle
So I'm going to start by

00:29:00.906 --> 00:29:02.646 A:middle
importing coremltools.

00:29:02.646 --> 00:29:03.836 A:middle
Again, this is the name of that

00:29:03.916 --> 00:29:04.786 A:middle
package in python.

00:29:04.786 --> 00:29:09.276 A:middle
And as soon as that's done, I

00:29:09.276 --> 00:29:11.006 A:middle
can just type coremltools.

00:29:11.466 --> 00:29:12.706 A:middle
And when I'm working with a new

00:29:12.706 --> 00:29:14.506 A:middle
python package, the first thing

00:29:14.506 --> 00:29:16.436 A:middle
I like to do is tab complete on

00:29:16.556 --> 00:29:17.736 A:middle
it and see what's available in

00:29:17.736 --> 00:29:18.136 A:middle
the API.

00:29:19.446 --> 00:29:21.466 A:middle
So here on tab complete, we can

00:29:21.526 --> 00:29:23.316 A:middle
see that coremltools contains

00:29:23.416 --> 00:29:25.026 A:middle
converters which is each of

00:29:25.026 --> 00:29:26.356 A:middle
those high-level converters from

00:29:26.356 --> 00:29:27.906 A:middle
another format into the Core ML

00:29:27.906 --> 00:29:30.646 A:middle
Format, as well as models,

00:29:30.816 --> 00:29:32.736 A:middle
specification version and utils

00:29:33.196 --> 00:29:34.506 A:middle
which are the framework bindings

00:29:34.576 --> 00:29:36.256 A:middle
and the converter library, and

00:29:36.286 --> 00:29:37.636 A:middle
together with those you can

00:29:37.636 --> 00:29:38.946 A:middle
build a new converter and test

00:29:39.196 --> 00:29:40.036 A:middle
that it gives the same

00:29:40.036 --> 00:29:41.216 A:middle
predictions as the original

00:29:41.216 --> 00:29:41.986 A:middle
training framework.

00:29:42.646 --> 00:29:44.956 A:middle
And the .protonamesbase which

00:29:44.956 --> 00:29:46.686 A:middle
contains the read and write APIs

00:29:46.896 --> 00:29:48.266 A:middle
for the Core ML Model Format.

00:29:49.126 --> 00:29:50.156 A:middle
Today we're going to focus on

00:29:50.156 --> 00:29:50.746 A:middle
the converters.

00:29:51.546 --> 00:29:53.176 A:middle
So again, if I do .converters

00:29:53.276 --> 00:29:54.736 A:middle
and then tab complete once more,

00:29:55.136 --> 00:29:56.566 A:middle
I can see all of the converters

00:29:56.566 --> 00:29:57.746 A:middle
that are available in this name

00:29:57.746 --> 00:29:58.546 A:middle
space right now.

00:29:58.616 --> 00:30:00.846 A:middle
So there's caffe, keras, libsvn,

00:29:58.616 --> 00:30:00.846 A:middle
So there's caffe, keras, libsvn,

00:30:01.066 --> 00:30:02.646 A:middle
scikit-learn, and xgboost.

00:30:03.046 --> 00:30:04.066 A:middle
And today we're going to focus

00:30:04.066 --> 00:30:04.626 A:middle
on Caffe.

00:30:05.446 --> 00:30:07.416 A:middle
So once more I'll do .caffe and

00:30:07.576 --> 00:30:08.606 A:middle
tab complete and see what's

00:30:08.606 --> 00:30:09.116 A:middle
available.

00:30:09.116 --> 00:30:10.346 A:middle
And it just tab completed for

00:30:10.346 --> 00:30:10.546 A:middle
me.

00:30:10.756 --> 00:30:12.396 A:middle
Convert. So it's that simple.

00:30:12.396 --> 00:30:13.486 A:middle
There's just one function in

00:30:13.486 --> 00:30:15.426 A:middle
here called convert, and let's

00:30:15.426 --> 00:30:17.226 A:middle
look at how we would use that.

00:30:18.756 --> 00:30:22.596 A:middle
So first I'm going to start by

00:30:22.676 --> 00:30:23.676 A:middle
setting up the inputs.

00:30:24.006 --> 00:30:25.766 A:middle
So I know I have a Caffe model

00:30:26.666 --> 00:30:27.716 A:middle
defined by two files.

00:30:27.786 --> 00:30:29.516 A:middle
So I'm going to say caffemodel =

00:30:29.636 --> 00:30:30.786 A:middle
and I'm going to give a two pole

00:30:31.066 --> 00:30:32.506 A:middle
of two strings pointing to the

00:30:32.506 --> 00:30:34.196 A:middle
file names of that Caffe Model,

00:30:34.476 --> 00:30:37.326 A:middle
which are flowers.caffemodel and

00:30:37.396 --> 00:30:38.876 A:middle
flowers.prototxt.

00:30:39.046 --> 00:30:40.786 A:middle
And together those represent the

00:30:40.786 --> 00:30:42.536 A:middle
learned weights in the network

00:30:42.536 --> 00:30:43.426 A:middle
as well as the network

00:30:43.426 --> 00:30:43.936 A:middle
structure.

00:30:44.486 --> 00:30:48.636 A:middle
Next I'm going to set up a class

00:30:48.686 --> 00:30:49.356 A:middle
label file.

00:30:49.356 --> 00:30:52.666 A:middle
So I'm going to say labels = and

00:30:52.666 --> 00:30:54.436 A:middle
I have labels.txt here.

00:30:55.356 --> 00:30:56.816 A:middle
And that represents the mapping

00:30:56.906 --> 00:30:58.706 A:middle
of numeric indices to string

00:30:58.706 --> 00:30:59.446 A:middle
class labels.

00:31:00.886 --> 00:31:02.216 A:middle
Now to run the converter.

00:31:02.486 --> 00:31:03.376 A:middle
It's very simple.

00:31:03.686 --> 00:31:05.126 A:middle
All I have to do is say

00:31:05.236 --> 00:31:10.286 A:middle
coremlmodel = coremltools

00:31:10.676 --> 00:31:13.626 A:middle
.converters.caffe.convert and it

00:31:13.626 --> 00:31:16.496 A:middle
all tab completes, and I'm just

00:31:16.496 --> 00:31:18.466 A:middle
going to pass in that caffemodel

00:31:19.066 --> 00:31:21.286 A:middle
and classlabels = labels.

00:31:21.856 --> 00:31:22.886 A:middle
So I'm just passing in those

00:31:22.886 --> 00:31:23.596 A:middle
three files.

00:31:24.376 --> 00:31:27.426 A:middle
And when the converter finishes,

00:31:27.766 --> 00:31:29.416 A:middle
what I get back is a Core ML

00:31:29.416 --> 00:31:29.736 A:middle
Model.

00:31:30.516 --> 00:31:32.116 A:middle
Right here in python, I can

00:31:32.116 --> 00:31:33.996 A:middle
print out the model and see the

00:31:33.996 --> 00:31:36.396 A:middle
interface that I get with that

00:31:36.396 --> 00:31:36.716 A:middle
model.

00:31:37.286 --> 00:31:38.516 A:middle
So I can see that it has one

00:31:38.516 --> 00:31:41.156 A:middle
input named "data" and that

00:31:41.156 --> 00:31:43.236 A:middle
input is a multi-array which

00:31:43.236 --> 00:31:46.406 A:middle
shaped 3 by 227 by 227 and typed

00:31:46.486 --> 00:31:46.856 A:middle
double.

00:31:47.096 --> 00:31:49.166 A:middle
And we'll get back to that in a

00:31:49.166 --> 00:31:49.436 A:middle
minute.

00:31:50.176 --> 00:31:51.566 A:middle
It also has 2 outputs.

00:31:52.126 --> 00:31:54.046 A:middle
One is named "prob" and it's a

00:31:54.046 --> 00:31:56.096 A:middle
dictionary with string keys, so

00:31:56.096 --> 00:31:57.176 A:middle
that's going to represent the

00:31:57.176 --> 00:31:59.276 A:middle
probabilities for each possible

00:31:59.276 --> 00:31:59.976 A:middle
class label.

00:32:00.966 --> 00:32:02.386 A:middle
And another output named

00:32:02.386 --> 00:32:03.906 A:middle
classLabel as a string, and

00:32:04.006 --> 00:32:05.186 A:middle
that's simply going to be the

00:32:05.186 --> 00:32:06.346 A:middle
most likely class label.

00:32:06.536 --> 00:32:07.686 A:middle
So for convenience, you don't

00:32:07.686 --> 00:32:08.366 A:middle
have to look at all the

00:32:08.366 --> 00:32:09.746 A:middle
probabilities to find out which

00:32:09.746 --> 00:32:10.656 A:middle
one is the most likely.

00:32:13.276 --> 00:32:15.696 A:middle
But looking at this, I know that

00:32:15.696 --> 00:32:17.706 A:middle
this input type is not quite the

00:32:17.706 --> 00:32:19.146 A:middle
interface that I wanted the

00:32:19.146 --> 00:32:21.436 A:middle
model to have, so I can go back

00:32:21.826 --> 00:32:22.856 A:middle
and run the converter with

00:32:22.856 --> 00:32:24.726 A:middle
another parameter to modify the

00:32:24.726 --> 00:32:26.366 A:middle
input type because instead of a

00:32:26.366 --> 00:32:28.216 A:middle
multi-array, I would like for

00:32:28.216 --> 00:32:29.976 A:middle
this model to take an image as

00:32:29.976 --> 00:32:30.246 A:middle
input.

00:32:31.896 --> 00:32:33.666 A:middle
So I'm going to go back and add

00:32:34.336 --> 00:32:36.306 A:middle
image input names = data.

00:32:36.916 --> 00:32:38.246 A:middle
And again, just looking at the

00:32:38.246 --> 00:32:39.446 A:middle
output here, you can see that

00:32:39.476 --> 00:32:41.356 A:middle
the input name is data, so it's

00:32:41.356 --> 00:32:42.786 A:middle
going to know what to do with

00:32:43.846 --> 00:32:44.936 A:middle
that input.

00:32:45.156 --> 00:32:46.736 A:middle
If I run the converter once more

00:32:47.126 --> 00:32:48.156 A:middle
and then again print out the

00:32:48.156 --> 00:32:50.816 A:middle
model interface, now I see that

00:32:50.816 --> 00:32:52.666 A:middle
the input named data is an image

00:32:52.936 --> 00:32:55.486 A:middle
with width 227, height 227, and

00:32:55.526 --> 00:32:56.636 A:middle
color space RGB.

00:32:59.516 --> 00:33:03.726 A:middle
[ Applause ]

00:32:59.516 --> 00:33:03.726 A:middle
[ Applause ]

00:33:04.226 --> 00:33:05.376 A:middle
Now that we have a Core ML

00:33:05.376 --> 00:33:07.666 A:middle
Model, let's check and make sure

00:33:07.666 --> 00:33:09.056 A:middle
that the conversion succeeded

00:33:09.376 --> 00:33:10.646 A:middle
and thus we get correct

00:33:10.756 --> 00:33:12.126 A:middle
predictions with this Core ML

00:33:12.126 --> 00:33:12.466 A:middle
Model.

00:33:13.826 --> 00:33:15.486 A:middle
I'm going to start by importing

00:33:15.486 --> 00:33:16.966 A:middle
the python image library so that

00:33:16.966 --> 00:33:18.696 A:middle
I can work with images and pass

00:33:18.696 --> 00:33:19.886 A:middle
an image directly into the

00:33:19.886 --> 00:33:20.226 A:middle
model.

00:33:20.856 --> 00:33:23.096 A:middle
So I'm going to say from PIL

00:33:23.546 --> 00:33:28.196 A:middle
input Image and then Rose =

00:33:28.326 --> 00:33:30.946 A:middle
Image.open rose.jpg.

00:33:31.736 --> 00:33:34.126 A:middle
And just to prove to you I've

00:33:34.126 --> 00:33:36.756 A:middle
got nothing up my sleeve, I'm

00:33:36.756 --> 00:33:39.976 A:middle
going to call rose.show and show

00:33:39.976 --> 00:33:41.896 A:middle
you that this is indeed a

00:33:41.896 --> 00:33:43.566 A:middle
picture of a rose.

00:33:47.036 --> 00:33:49.036 A:middle
[ Applause ]

00:33:49.056 --> 00:33:49.966 A:middle
You don't need to clap for that.

00:33:50.516 --> 00:33:52.716 A:middle
[ Laughter ]

00:33:53.216 --> 00:33:55.446 A:middle
So now that I've shown that this

00:33:55.446 --> 00:33:56.846 A:middle
image actually does represent a

00:33:56.846 --> 00:33:58.176 A:middle
rose, let's see if the model

00:33:58.176 --> 00:33:58.706 A:middle
agrees.

00:33:59.486 --> 00:34:01.476 A:middle
So checking the prediction is as

00:33:59.486 --> 00:34:01.476 A:middle
So checking the prediction is as

00:34:01.476 --> 00:34:02.806 A:middle
easy as calling

00:34:02.906 --> 00:34:06.466 A:middle
coremlmodel.predict, and this is

00:34:06.526 --> 00:34:08.596 A:middle
that Core ML framework binding

00:34:08.696 --> 00:34:09.856 A:middle
that we talked about earlier.

00:34:10.956 --> 00:34:11.856 A:middle
And we're going to pass the

00:34:11.856 --> 00:34:14.766 A:middle
input named data the value rose.

00:34:16.416 --> 00:34:17.585 A:middle
And immediately we get back a

00:34:17.585 --> 00:34:20.096 A:middle
prediction of class label rose.

00:34:21.516 --> 00:34:26.196 A:middle
[ Applause ]

00:34:26.696 --> 00:34:27.726 A:middle
But let's make sure the model --

00:34:27.726 --> 00:34:29.206 A:middle
let's make sure it's not a fluke

00:34:29.206 --> 00:34:30.176 A:middle
and let's make sure the model

00:34:30.176 --> 00:34:31.335 A:middle
really knows that this is a

00:34:31.335 --> 00:34:31.686 A:middle
rose.

00:34:32.016 --> 00:34:32.976 A:middle
So we're going to scroll down

00:34:32.976 --> 00:34:34.396 A:middle
through the class probabilities

00:34:34.985 --> 00:34:36.376 A:middle
until we see rose here.

00:34:37.936 --> 00:34:39.136 A:middle
And we can see that the model is

00:34:39.136 --> 00:34:40.456 A:middle
actually very confident that

00:34:40.456 --> 00:34:41.096 A:middle
this is a rose.

00:34:41.096 --> 00:34:44.025 A:middle
So this is .991 out of 1

00:34:44.456 --> 00:34:45.926 A:middle
confidence that this is a rose.

00:34:45.985 --> 00:34:47.396 A:middle
So I'm going to conclude that

00:34:47.446 --> 00:34:49.196 A:middle
probably this model did convert

00:34:49.196 --> 00:34:49.656 A:middle
correctly.

00:34:50.426 --> 00:34:51.826 A:middle
If I was doing this in a real

00:34:51.826 --> 00:34:53.295 A:middle
application, I would want to

00:34:53.295 --> 00:34:54.466 A:middle
actually test this a bit more

00:34:54.466 --> 00:34:55.826 A:middle
rigorously so I would provide

00:34:55.826 --> 00:34:57.396 A:middle
more than one example and I

00:34:57.426 --> 00:34:59.036 A:middle
would also want to check that

00:34:59.076 --> 00:35:00.406 A:middle
the predictions that I get here

00:34:59.076 --> 00:35:00.406 A:middle
the predictions that I get here

00:35:00.406 --> 00:35:02.016 A:middle
from Core ML are exactly the

00:35:02.106 --> 00:35:03.696 A:middle
same as the predictions that

00:35:03.846 --> 00:35:05.176 A:middle
Caffe would have given me for

00:35:05.176 --> 00:35:06.716 A:middle
the same input, and that's how

00:35:06.716 --> 00:35:07.816 A:middle
we know that the conversion has

00:35:07.856 --> 00:35:08.366 A:middle
succeeded.

00:35:09.176 --> 00:35:10.526 A:middle
But that will take too long for

00:35:10.526 --> 00:35:12.526 A:middle
this demo so let's move on.

00:35:13.186 --> 00:35:15.126 A:middle
What I'm going to do now is save

00:35:15.286 --> 00:35:16.966 A:middle
the model out and then look at

00:35:16.966 --> 00:35:17.806 A:middle
it in Xcode.

00:35:18.386 --> 00:35:18.966 A:middle
So I'm, going to say

00:35:18.966 --> 00:35:21.426 A:middle
coremlmodel.save, and I'm going

00:35:21.426 --> 00:35:21.816 A:middle
to call it

00:35:21.896 --> 00:35:23.886 A:middle
FlowerPredictor.mlmodel.

00:35:24.566 --> 00:35:27.736 A:middle
And then I'm just going to open

00:35:27.736 --> 00:35:29.076 A:middle
the current directory and finder

00:35:29.516 --> 00:35:31.186 A:middle
and double-click that model to

00:35:31.186 --> 00:35:33.646 A:middle
open it in Xcode.

00:35:33.786 --> 00:35:36.656 A:middle
And what we can see here is that

00:35:36.656 --> 00:35:37.926 A:middle
it's a Machine Learning Model

00:35:37.926 --> 00:35:39.326 A:middle
with name FlowerPredictor.

00:35:39.326 --> 00:35:40.356 A:middle
Type is Neural Network

00:35:40.356 --> 00:35:43.846 A:middle
Classifier and its size is 229.1

00:35:43.846 --> 00:35:44.266 A:middle
megabytes.

00:35:45.346 --> 00:35:46.306 A:middle
But there's a lot of missing

00:35:46.306 --> 00:35:47.186 A:middle
information, too.

00:35:47.186 --> 00:35:48.686 A:middle
It doesn't know the author, the

00:35:48.686 --> 00:35:51.216 A:middle
license, the description or the

00:35:51.216 --> 00:35:52.616 A:middle
descriptions for the inputs and

00:35:52.616 --> 00:35:52.936 A:middle
outputs.

00:35:53.896 --> 00:35:55.346 A:middle
So while this is a working

00:35:55.346 --> 00:35:57.256 A:middle
model, it's not necessarily one

00:35:57.256 --> 00:35:58.286 A:middle
I would want to give to a

00:35:58.286 --> 00:35:59.666 A:middle
colleague or put on the internet

00:36:00.096 --> 00:36:01.696 A:middle
because it's not quite as useful

00:36:01.696 --> 00:36:03.066 A:middle
if it doesn't really declare

00:36:03.066 --> 00:36:04.196 A:middle
what it's supposed to do and how

00:36:04.196 --> 00:36:04.646 A:middle
to use it.

00:36:05.336 --> 00:36:06.136 A:middle
So I'm going to be a good

00:36:06.186 --> 00:36:07.656 A:middle
citizen and go back and give

00:36:07.656 --> 00:36:08.846 A:middle
this model some metadata.

00:36:14.066 --> 00:36:15.836 A:middle
Back in the python prompt, I can

00:36:15.836 --> 00:36:17.436 A:middle
just mutate the model right here

00:36:17.976 --> 00:36:19.816 A:middle
by assigning to fields at the

00:36:19.876 --> 00:36:20.396 A:middle
top level.

00:36:20.396 --> 00:36:24.076 A:middle
So I can say author = "Zach

00:36:24.976 --> 00:36:25.126 A:middle
Nation".

00:36:25.896 --> 00:36:29.736 A:middle
coremlmodel.license = "BSD".

00:36:31.646 --> 00:36:35.916 A:middle
coremlmodel.shortdescription = a

00:36:36.026 --> 00:36:37.686 A:middle
flower classifier.

00:36:39.286 --> 00:36:41.396 A:middle
And let's set the help text for

00:36:41.396 --> 00:36:42.606 A:middle
those inputs and outputs as

00:36:42.606 --> 00:36:44.376 A:middle
well, because not only does that

00:36:44.376 --> 00:36:46.536 A:middle
show up in the Xcode view, but

00:36:46.536 --> 00:36:48.536 A:middle
when the generated code is there

00:36:48.536 --> 00:36:50.036 A:middle
and you can call into it that

00:36:50.036 --> 00:36:51.976 A:middle
actually becomes documentation

00:36:52.066 --> 00:36:53.476 A:middle
comments in the generated code.

00:36:53.916 --> 00:36:55.306 A:middle
So when your tab completing an

00:36:55.556 --> 00:36:56.796 A:middle
Xcode this is what someone

00:36:56.796 --> 00:36:58.166 A:middle
consuming this mode will see.

00:36:58.826 --> 00:37:00.656 A:middle
So I'm going to say

00:36:58.826 --> 00:37:00.656 A:middle
So I'm going to say

00:37:00.906 --> 00:37:03.506 A:middle
coremlmodel.inputdescription for

00:37:03.506 --> 00:37:07.816 A:middle
"data" is an image of a flower.

00:37:09.466 --> 00:37:09.836 A:middle
And

00:37:09.836 --> 00:37:11.996 A:middle
coremlmodel.outputdescription

00:37:11.996 --> 00:37:16.006 A:middle
"prob" is the probabilities for

00:37:16.006 --> 00:37:20.516 A:middle
each flower type, for the given

00:37:20.516 --> 00:37:20.986 A:middle
input.

00:37:21.656 --> 00:37:21.746 A:middle
And

00:37:23.276 --> 00:37:26.486 A:middle
coremlmodel.outputdescription

00:37:26.546 --> 00:37:30.516 A:middle
"classLabel" is "The most likely

00:37:30.546 --> 00:37:33.126 A:middle
type of flower, for the given

00:37:33.176 --> 00:37:33.486 A:middle
input."

00:37:34.066 --> 00:37:37.056 A:middle
And now we can just save that

00:37:37.056 --> 00:37:39.796 A:middle
model once again and I'm just

00:37:41.106 --> 00:37:42.516 A:middle
going to clobber the file that

00:37:42.516 --> 00:37:44.256 A:middle
was there because now I want the

00:37:44.256 --> 00:37:44.936 A:middle
one with metadata.

00:37:44.936 --> 00:37:46.936 A:middle
So I'm going to just save it

00:37:46.936 --> 00:37:47.946 A:middle
right on top of the file that

00:37:47.946 --> 00:37:49.926 A:middle
was there before and open that

00:37:49.926 --> 00:37:51.226 A:middle
directory and finder again.

00:37:52.046 --> 00:37:53.176 A:middle
And now when I double-click the

00:37:53.176 --> 00:37:55.546 A:middle
model and open it in Xcode, we

00:37:55.546 --> 00:37:57.176 A:middle
can see that it contains useful

00:37:57.176 --> 00:37:58.996 A:middle
metadata describing how the

00:37:58.996 --> 00:38:00.536 A:middle
model is intended should be used

00:37:58.996 --> 00:38:00.536 A:middle
model is intended should be used

00:38:00.786 --> 00:38:02.506 A:middle
and what the inputs and outputs

00:38:02.576 --> 00:38:02.816 A:middle
do.

00:38:04.516 --> 00:38:09.500 A:middle
[ Applause ]

00:38:13.076 --> 00:38:16.996 A:middle
So to recap, what we saw is that

00:38:16.996 --> 00:38:18.706 A:middle
using Core ML Tools to convert a

00:38:18.706 --> 00:38:21.266 A:middle
model is as easy as import

00:38:21.266 --> 00:38:23.526 A:middle
coremltools, setting up the

00:38:23.526 --> 00:38:25.566 A:middle
inputs, and then calling a

00:38:25.646 --> 00:38:27.186 A:middle
simple high-level convert

00:38:27.186 --> 00:38:29.316 A:middle
function to get back a model in

00:38:29.316 --> 00:38:30.356 A:middle
Core ML Model Format.

00:38:31.096 --> 00:38:32.756 A:middle
And the best part is, let's say

00:38:32.756 --> 00:38:33.946 A:middle
you switch training frameworks

00:38:34.226 --> 00:38:36.676 A:middle
from Caffe to Keras, switching

00:38:36.676 --> 00:38:38.416 A:middle
converters is as easy as

00:38:38.476 --> 00:38:40.366 A:middle
updating the name space because

00:38:40.366 --> 00:38:41.646 A:middle
all of the convert functions

00:38:41.816 --> 00:38:43.826 A:middle
share the same high-level API

00:38:47.516 --> 00:38:51.796 A:middle
[ Applause ]

00:38:52.296 --> 00:38:54.926 A:middle
Core ML Tools supports Caffe and

00:38:54.956 --> 00:38:57.026 A:middle
Keras models as Neural Networks.

00:38:57.486 --> 00:38:58.966 A:middle
Scikit-Learn for Pipelines.

00:39:00.146 --> 00:39:02.066 A:middle
Scikit-Learn and XGBoost for

00:39:02.066 --> 00:39:04.876 A:middle
Tree Ensembles, and LIBSVM and

00:39:05.066 --> 00:39:06.876 A:middle
Scikit-Learn for Linear Models

00:39:07.026 --> 00:39:08.366 A:middle
and Support Vector Machines.

00:39:09.136 --> 00:39:10.346 A:middle
It's also worth noting that

00:39:10.506 --> 00:39:12.196 A:middle
Keras is a really powerful

00:39:12.376 --> 00:39:14.216 A:middle
high-level interface to several

00:39:14.216 --> 00:39:15.506 A:middle
popular deep learning training

00:39:15.506 --> 00:39:17.056 A:middle
tools, including TensorFlow.

00:39:17.646 --> 00:39:18.446 A:middle
So if you're training a

00:39:18.446 --> 00:39:20.406 A:middle
TensorFlow Model in Keras, you

00:39:20.406 --> 00:39:22.356 A:middle
can use Core ML Tools to convert

00:39:22.356 --> 00:39:24.606 A:middle
it into Core ML Model Format.

00:39:26.516 --> 00:39:31.196 A:middle
[ Applause ]

00:39:31.696 --> 00:39:34.046 A:middle
Obtaining models, you want to

00:39:34.046 --> 00:39:35.176 A:middle
look in two places.

00:39:35.816 --> 00:39:37.936 A:middle
One is the set of example models

00:39:37.936 --> 00:39:39.466 A:middle
on developer.apple.com.

00:39:39.846 --> 00:39:40.766 A:middle
And again, these are

00:39:40.896 --> 00:39:42.526 A:middle
pre-training models already in

00:39:42.526 --> 00:39:44.206 A:middle
the Core ML Model Format and so

00:39:44.206 --> 00:39:45.466 A:middle
this is the easiest way to get

00:39:45.466 --> 00:39:46.916 A:middle
started if you're new to Machine

00:39:46.916 --> 00:39:48.516 A:middle
Learning or if one of these

00:39:48.516 --> 00:39:50.256 A:middle
models does the task that you're

00:39:50.256 --> 00:39:51.516 A:middle
trying to do in your app.

00:39:51.956 --> 00:39:52.946 A:middle
But because there's a whole

00:39:52.946 --> 00:39:54.066 A:middle
world of machine learning out

00:39:54.126 --> 00:39:55.836 A:middle
there and a variety of models in

00:39:55.836 --> 00:39:57.266 A:middle
use cases in a variety of

00:39:57.266 --> 00:39:59.236 A:middle
formats, we've created Core ML

00:39:59.236 --> 00:40:01.056 A:middle
Tools to allow you to convert

00:39:59.236 --> 00:40:01.056 A:middle
Tools to allow you to convert

00:40:01.246 --> 00:40:02.376 A:middle
from any of these popular

00:40:02.376 --> 00:40:04.236 A:middle
formats into the Core ML Model

00:40:05.096 --> 00:40:05.286 A:middle
Format.

00:40:06.516 --> 00:40:11.306 A:middle
[ Applause ]

00:40:11.806 --> 00:40:13.526 A:middle
So, in summary, what we've

00:40:13.526 --> 00:40:15.826 A:middle
learned today is that Core ML

00:40:15.826 --> 00:40:17.396 A:middle
makes it really easy to

00:40:17.396 --> 00:40:18.356 A:middle
integrate Machine Learning

00:40:18.356 --> 00:40:19.486 A:middle
Models into your app.

00:40:19.886 --> 00:40:22.016 A:middle
Simply drag and drop into Xcode

00:40:22.016 --> 00:40:23.336 A:middle
and you get a code interfaced to

00:40:23.336 --> 00:40:23.736 A:middle
the model.

00:40:25.176 --> 00:40:26.976 A:middle
Core ML has rich datatype

00:40:27.046 --> 00:40:28.876 A:middle
support for a variety of use

00:40:28.946 --> 00:40:30.336 A:middle
cases and it deals with

00:40:30.336 --> 00:40:31.486 A:middle
datatypes that you're already

00:40:31.486 --> 00:40:33.566 A:middle
familiar with from your app

00:40:35.316 --> 00:40:35.436 A:middle
code.

00:40:35.626 --> 00:40:37.226 A:middle
Core ML is hardware optimized

00:40:37.406 --> 00:40:38.486 A:middle
and it's built on top of

00:40:38.536 --> 00:40:39.796 A:middle
performance primitives like

00:40:39.796 --> 00:40:41.296 A:middle
Metal Performance Shaders and

00:40:41.296 --> 00:40:42.976 A:middle
Accelerate so that you get the

00:40:42.976 --> 00:40:44.526 A:middle
best possible performance on

00:40:44.526 --> 00:40:45.066 A:middle
device.

00:40:45.656 --> 00:40:49.526 A:middle
And through Core ML Tools, Core

00:40:49.526 --> 00:40:51.116 A:middle
ML is compatible with the most

00:40:51.156 --> 00:40:53.376 A:middle
popular Machine Learning Formats

00:40:53.726 --> 00:40:54.896 A:middle
and more will be added over

00:40:55.746 --> 00:40:55.836 A:middle
time.

00:40:57.286 --> 00:40:59.106 A:middle
For more information, please see

00:40:59.106 --> 00:41:00.986 A:middle
developer.apple.com with our

00:40:59.106 --> 00:41:00.986 A:middle
developer.apple.com with our

00:41:00.986 --> 00:41:02.556 A:middle
session number 710.

00:41:03.116 --> 00:41:05.236 A:middle
We have a couple of related

00:41:05.236 --> 00:41:06.496 A:middle
sessions coming up you may be

00:41:06.496 --> 00:41:07.336 A:middle
interested in.

00:41:07.526 --> 00:41:08.516 A:middle
To look at some low-level

00:41:08.516 --> 00:41:09.896 A:middle
details about how we get such

00:41:09.896 --> 00:41:11.016 A:middle
good performance on this

00:41:11.016 --> 00:41:12.266 A:middle
hardware, check out the

00:41:12.266 --> 00:41:14.026 A:middle
Accelerate and Metal 2 sessions.

00:41:14.436 --> 00:41:14.796 A:middle
Thank you.

00:41:15.516 --> 00:41:20.500 A:middle
[ Applause ]
