WEBVTT

00:00:29.716 --> 00:00:30.086 A:middle
&gt;&gt; Thank you.

00:00:30.856 --> 00:00:31.806 A:middle
Good afternoon, everyone.

00:00:32.546 --> 00:00:34.146 A:middle
Welcome to the session "What's

00:00:34.146 --> 00:00:35.166 A:middle
New in Audio?"

00:00:36.156 --> 00:00:37.486 A:middle
I'm Akshatha Nagesh, from the

00:00:37.486 --> 00:00:39.786 A:middle
Audio Team, and today, I would

00:00:39.786 --> 00:00:41.626 A:middle
like to share with you all the

00:00:41.626 --> 00:00:43.706 A:middle
new, exciting features we have

00:00:43.706 --> 00:00:45.606 A:middle
in audio in this year's OS

00:00:45.606 --> 00:00:45.996 A:middle
releases.

00:00:46.636 --> 00:00:49.906 A:middle
I'll begin with a quick overview

00:00:50.076 --> 00:00:50.956 A:middle
of the audio stack.

00:00:52.216 --> 00:00:54.126 A:middle
Audio frameworks offer a wide

00:00:54.276 --> 00:00:56.426 A:middle
variety of APIs, and our main

00:00:56.426 --> 00:00:58.556 A:middle
goal is to help you deliver an

00:00:58.556 --> 00:01:00.436 A:middle
exceptional audio experience to

00:01:00.436 --> 00:01:01.826 A:middle
the end user, through your apps.

00:01:03.326 --> 00:01:04.946 A:middle
At the top, we have the AV

00:01:04.946 --> 00:01:06.826 A:middle
foundation framework, with APIs

00:01:06.826 --> 00:01:09.576 A:middle
like AVAudioSession, Engine,

00:01:09.826 --> 00:01:11.756 A:middle
Player, Recorder, etcetera.

00:01:12.736 --> 00:01:14.486 A:middle
And these APIs cater to the

00:01:14.486 --> 00:01:16.086 A:middle
needs of most of the apps.

00:01:17.216 --> 00:01:18.426 A:middle
But if you wanted to further

00:01:18.426 --> 00:01:20.496 A:middle
customize the experience, you

00:01:20.496 --> 00:01:22.196 A:middle
could use our other frameworks

00:01:22.196 --> 00:01:24.546 A:middle
and APIs like AUAudioUnits,

00:01:24.756 --> 00:01:26.696 A:middle
Audio Codecs, in Audio Toolbox

00:01:26.696 --> 00:01:28.926 A:middle
framework, Code Mini framework,

00:01:29.396 --> 00:01:31.366 A:middle
AudioHAL framework, etcetera.

00:01:32.786 --> 00:01:34.266 A:middle
In our last year's talk here at

00:01:34.266 --> 00:01:36.676 A:middle
WWDC, we did a walkthrough of

00:01:36.726 --> 00:01:38.526 A:middle
all these APIs and more,

00:01:38.776 --> 00:01:39.626 A:middle
throughout the stack.

00:01:40.106 --> 00:01:41.856 A:middle
And I highly encourage you to

00:01:41.886 --> 00:01:43.086 A:middle
check that out.

00:01:43.796 --> 00:01:45.496 A:middle
Now, let's see what's on the

00:01:45.496 --> 00:01:46.486 A:middle
agenda for today.

00:01:47.076 --> 00:01:49.526 A:middle
We will see the new features

00:01:49.526 --> 00:01:51.396 A:middle
we've added in some of these

00:01:51.396 --> 00:01:53.646 A:middle
APIs, starting with the ones in

00:01:53.646 --> 00:01:54.806 A:middle
AVFoundation framework.

00:01:55.506 --> 00:01:56.596 A:middle
And that includes,

00:01:56.596 --> 00:01:58.846 A:middle
AVAudioEngine, AVAudioSession,

00:01:59.206 --> 00:02:00.776 A:middle
and the enhancements we have in

00:02:00.776 --> 00:02:02.876 A:middle
AVFoundation on watchOS 4.

00:02:04.236 --> 00:02:06.276 A:middle
Later on, we'll move over to the

00:02:06.276 --> 00:02:08.176 A:middle
Audio Toolbox world, and see the

00:02:08.176 --> 00:02:10.786 A:middle
enhancements in AUAudioUnits and

00:02:10.786 --> 00:02:11.636 A:middle
Audio Formats.

00:02:12.376 --> 00:02:13.966 A:middle
And finally, we'll wrap up

00:02:14.056 --> 00:02:15.786 A:middle
today's session with an update

00:02:15.946 --> 00:02:17.336 A:middle
on Inter-Device Audio Mode.

00:02:18.776 --> 00:02:20.906 A:middle
We also have a few demos along

00:02:20.906 --> 00:02:22.876 A:middle
the way, to show you many of

00:02:22.876 --> 00:02:25.126 A:middle
these new features in action.

00:02:25.996 --> 00:02:27.266 A:middle
So, let's begin with

00:02:27.306 --> 00:02:28.446 A:middle
AVAudioEngine.

00:02:29.896 --> 00:02:31.746 A:middle
And here's a quick recap of the

00:02:31.746 --> 00:02:32.106 A:middle
API.

00:02:33.246 --> 00:02:35.436 A:middle
AVAudioEngine is a powerful

00:02:35.436 --> 00:02:37.926 A:middle
Objective-C and Swift based API

00:02:37.926 --> 00:02:38.186 A:middle
set.

00:02:38.946 --> 00:02:40.676 A:middle
And the main goal of this API,

00:02:41.046 --> 00:02:42.996 A:middle
is to simplify dealing with real

00:02:42.996 --> 00:02:45.306 A:middle
time audio, and to make it

00:02:45.306 --> 00:02:46.816 A:middle
really easy for you to write

00:02:46.936 --> 00:02:49.336 A:middle
code to perform various audio

00:02:49.336 --> 00:02:50.906 A:middle
tasks, ranging from simple

00:02:50.906 --> 00:02:53.026 A:middle
playback, to recording, to even

00:02:53.056 --> 00:02:54.596 A:middle
complex tasks like audio

00:02:54.596 --> 00:02:56.956 A:middle
processing, mixing, and even 3D

00:02:56.956 --> 00:02:57.996 A:middle
audio specialization.

00:02:59.136 --> 00:03:00.626 A:middle
And again, in our previous

00:03:00.626 --> 00:03:03.866 A:middle
year's talk here at WWDC, we

00:03:03.866 --> 00:03:05.956 A:middle
have covered this API in detail.

00:03:06.306 --> 00:03:08.046 A:middle
So, please check those out if

00:03:08.046 --> 00:03:09.876 A:middle
you're not familiar with this

00:03:10.416 --> 00:03:10.516 A:middle
API.

00:03:11.376 --> 00:03:13.566 A:middle
The Engine manages a graph of

00:03:13.626 --> 00:03:15.736 A:middle
nodes, and a node is the basic

00:03:15.736 --> 00:03:17.126 A:middle
building block of the Engine.

00:03:18.076 --> 00:03:19.826 A:middle
So, here's a sample Engine setup

00:03:20.116 --> 00:03:21.636 A:middle
and this is a classic karaoke

00:03:21.636 --> 00:03:22.186 A:middle
example.

00:03:22.186 --> 00:03:24.286 A:middle
As you can see, there are

00:03:24.286 --> 00:03:25.896 A:middle
various nodes connected

00:03:25.896 --> 00:03:27.496 A:middle
together, to form the processing

00:03:27.496 --> 00:03:27.816 A:middle
graph.

00:03:28.986 --> 00:03:31.346 A:middle
We have the InputNode that is

00:03:31.346 --> 00:03:33.146 A:middle
implicitly connected to the

00:03:33.496 --> 00:03:34.866 A:middle
[inaudible] and is capturing

00:03:35.006 --> 00:03:35.776 A:middle
user's voice.

00:03:36.726 --> 00:03:38.286 A:middle
This is being processed through

00:03:38.286 --> 00:03:39.856 A:middle
an EffectNode which could be for

00:03:39.856 --> 00:03:42.326 A:middle
example, an EQ.

00:03:42.326 --> 00:03:43.926 A:middle
We also have something called a

00:03:44.086 --> 00:03:45.296 A:middle
[inaudible] on the InputNode

00:03:45.686 --> 00:03:47.026 A:middle
through which we could be

00:03:47.106 --> 00:03:48.826 A:middle
analyzing user's voice to see

00:03:48.826 --> 00:03:50.646 A:middle
how he's performing, and based

00:03:50.646 --> 00:03:52.296 A:middle
on that, we could be playing out

00:03:52.296 --> 00:03:53.366 A:middle
some cues to the user through a

00:03:53.576 --> 00:03:54.416 A:middle
PlayerNode.

00:03:55.796 --> 00:03:57.206 A:middle
And we have another PlayerNode

00:03:57.356 --> 00:03:58.716 A:middle
that is playing the backing

00:03:58.716 --> 00:04:00.406 A:middle
track as the user is singing.

00:04:00.736 --> 00:04:03.456 A:middle
All of these signals are mixed

00:04:03.456 --> 00:04:05.536 A:middle
together, in a MixerNode and

00:04:05.536 --> 00:04:07.386 A:middle
finally, given to the OutputNode

00:04:07.666 --> 00:04:09.066 A:middle
which plays it out through the

00:04:09.066 --> 00:04:09.786 A:middle
output hardware.

00:04:10.896 --> 00:04:13.386 A:middle
This is a simple example of the

00:04:13.386 --> 00:04:15.466 A:middle
engine setup, but with all the

00:04:15.466 --> 00:04:16.866 A:middle
nodes and the features the

00:04:16.866 --> 00:04:18.606 A:middle
Engine actually offers, you

00:04:18.606 --> 00:04:20.326 A:middle
could build a lot more complex

00:04:20.396 --> 00:04:21.856 A:middle
processing graph, based on your

00:04:21.976 --> 00:04:22.676 A:middle
app's needs.

00:04:23.446 --> 00:04:25.656 A:middle
So, that was a recap of the

00:04:25.656 --> 00:04:26.206 A:middle
Engine.

00:04:26.336 --> 00:04:27.976 A:middle
Now, let's see what's new in the

00:04:27.976 --> 00:04:29.006 A:middle
Engine this year.

00:04:30.356 --> 00:04:31.956 A:middle
We have a couple of new modes,

00:04:32.316 --> 00:04:34.226 A:middle
namely the Manual Rendering Mode

00:04:34.436 --> 00:04:36.546 A:middle
and Auto Shutdown Mode, and

00:04:36.546 --> 00:04:38.146 A:middle
also, we have some enhancements

00:04:38.146 --> 00:04:40.326 A:middle
in AVAudioPlayerNode, related to

00:04:40.326 --> 00:04:41.636 A:middle
the file and buffer completion

00:04:41.636 --> 00:04:42.216 A:middle
callbacks.

00:04:43.246 --> 00:04:44.916 A:middle
We'll see each of these, one by

00:04:44.916 --> 00:04:46.896 A:middle
one, starting with the Manual

00:04:47.156 --> 00:04:48.406 A:middle
Rendering Mode.

00:04:50.656 --> 00:04:52.506 A:middle
So, this is the karaoke example

00:04:52.506 --> 00:04:53.356 A:middle
that we just saw.

00:04:54.486 --> 00:04:56.536 A:middle
And as you can see, the Input

00:04:56.536 --> 00:04:58.136 A:middle
and the OutputNodes here, are

00:04:58.206 --> 00:05:00.226 A:middle
connected to the audio hardware,

00:05:00.676 --> 00:05:02.056 A:middle
and hence, the Engine

00:05:02.246 --> 00:05:03.816 A:middle
automatically renders in real

00:05:03.816 --> 00:05:03.936 A:middle
time.

00:05:03.936 --> 00:05:07.406 A:middle
The IO here is driven by the

00:05:07.406 --> 00:05:07.886 A:middle
hardware.

00:05:08.846 --> 00:05:10.956 A:middle
But what if you wanted the

00:05:10.956 --> 00:05:12.676 A:middle
Engine to render, not to the

00:05:12.676 --> 00:05:13.846 A:middle
device, but to the app?

00:05:14.626 --> 00:05:16.626 A:middle
And say, at the rate faster than

00:05:16.626 --> 00:05:16.886 A:middle
real time?

00:05:18.496 --> 00:05:19.946 A:middle
So, here is Manual Rendering

00:05:19.946 --> 00:05:21.606 A:middle
Mode which enables you to do

00:05:21.606 --> 00:05:21.886 A:middle
that.

00:05:23.236 --> 00:05:24.986 A:middle
And as you can see, under this

00:05:24.986 --> 00:05:26.466 A:middle
mode, the Input and the

00:05:26.466 --> 00:05:27.836 A:middle
OutputNodes, will not be

00:05:27.836 --> 00:05:29.666 A:middle
connected to any audio device,

00:05:30.436 --> 00:05:32.546 A:middle
and the app will be responsible

00:05:32.546 --> 00:05:33.826 A:middle
for pulling the Engine for

00:05:33.906 --> 00:05:36.436 A:middle
Output and to provide the Input

00:05:36.666 --> 00:05:38.146 A:middle
to the Engine which will be

00:05:38.216 --> 00:05:39.776 A:middle
optionally through the InputNode

00:05:40.286 --> 00:05:41.846 A:middle
or PlayerNode, etcetera.

00:05:43.046 --> 00:05:45.526 A:middle
So, the app drives the IO in

00:05:45.526 --> 00:05:46.556 A:middle
Manual Rendering Mode.

00:05:47.056 --> 00:05:50.476 A:middle
We have two variants under

00:05:50.476 --> 00:05:51.336 A:middle
Manual Rendering.

00:05:51.826 --> 00:05:53.796 A:middle
That is the Offline and Real

00:05:53.796 --> 00:05:55.546 A:middle
Time Manual Rendering Modes.

00:05:56.086 --> 00:05:57.356 A:middle
And again, we'll see each of

00:05:57.356 --> 00:05:59.756 A:middle
these in detail and also, later

00:05:59.756 --> 00:06:01.416 A:middle
in this section, I'll show you a

00:06:01.416 --> 00:06:03.366 A:middle
demo of the Offline Manual

00:06:03.366 --> 00:06:04.056 A:middle
Rendering Mode.

00:06:04.476 --> 00:06:09.266 A:middle
Under the Offline Manual

00:06:09.266 --> 00:06:11.586 A:middle
Rendering Mode, the Engine and

00:06:11.676 --> 00:06:13.396 A:middle
all the nodes in your processing

00:06:13.396 --> 00:06:15.266 A:middle
graph, operate under no

00:06:15.266 --> 00:06:16.426 A:middle
deadlines or real-time

00:06:16.426 --> 00:06:17.106 A:middle
constraints.

00:06:18.126 --> 00:06:19.866 A:middle
And because of this flexibility,

00:06:20.186 --> 00:06:22.476 A:middle
a node may choose to say use a

00:06:22.476 --> 00:06:24.346 A:middle
more expensive signal processing

00:06:24.346 --> 00:06:26.816 A:middle
algorithm when it's offline, or

00:06:27.156 --> 00:06:28.826 A:middle
a node for example, a player

00:06:28.826 --> 00:06:30.826 A:middle
node, may choose to block on the

00:06:30.826 --> 00:06:32.806 A:middle
render thread, until all the

00:06:32.806 --> 00:06:34.446 A:middle
data that it needs as input,

00:06:34.676 --> 00:06:35.366 A:middle
becomes ready.

00:06:36.586 --> 00:06:38.306 A:middle
But these things may not -- will

00:06:38.306 --> 00:06:40.106 A:middle
not happen with the nodes are

00:06:40.106 --> 00:06:41.696 A:middle
actually rendering in real time,

00:06:42.066 --> 00:06:43.026 A:middle
as we'll see soon.

00:06:43.276 --> 00:06:46.406 A:middle
So, let's consider a simple

00:06:46.406 --> 00:06:48.576 A:middle
example where we could use the

00:06:48.576 --> 00:06:49.926 A:middle
offline mode.

00:06:51.236 --> 00:06:53.906 A:middle
So, here's an example where an

00:06:53.906 --> 00:06:55.986 A:middle
app wants to process the audio

00:06:55.986 --> 00:06:57.216 A:middle
data in a source file.

00:06:57.216 --> 00:06:59.396 A:middle
I'll place some effects onto

00:06:59.396 --> 00:07:01.256 A:middle
that data, and dump the process

00:07:01.286 --> 00:07:03.056 A:middle
output to a destination file.

00:07:03.586 --> 00:07:05.886 A:middle
As you can see, there is no

00:07:05.886 --> 00:07:07.616 A:middle
rendering to the device involved

00:07:07.696 --> 00:07:07.886 A:middle
here.

00:07:08.226 --> 00:07:10.276 A:middle
And hence, the app can now use

00:07:10.276 --> 00:07:12.586 A:middle
the Engine in the offline mode.

00:07:13.516 --> 00:07:15.006 A:middle
So, it could set up a very

00:07:15.006 --> 00:07:17.056 A:middle
simple graph in the Engine, like

00:07:17.056 --> 00:07:17.416 A:middle
this.

00:07:18.056 --> 00:07:20.126 A:middle
It could use the PlayerNode to

00:07:20.126 --> 00:07:21.376 A:middle
read the data from the source

00:07:21.376 --> 00:07:23.576 A:middle
file, process it through an

00:07:23.576 --> 00:07:24.816 A:middle
EffectNode, which could be for

00:07:24.816 --> 00:07:26.856 A:middle
example a [inaudible], and then,

00:07:27.106 --> 00:07:28.236 A:middle
pull the data out of the

00:07:28.236 --> 00:07:30.166 A:middle
OutputNode and drive the process

00:07:30.166 --> 00:07:31.726 A:middle
data into a destination file.

00:07:32.916 --> 00:07:34.736 A:middle
And we will soon see a demo of

00:07:34.736 --> 00:07:36.926 A:middle
this exact setup in a couple of

00:07:36.926 --> 00:07:38.016 A:middle
slides.

00:07:38.886 --> 00:07:42.096 A:middle
There are many more applications

00:07:42.266 --> 00:07:43.536 A:middle
where you can use the offline

00:07:43.536 --> 00:07:43.766 A:middle
mode.

00:07:44.416 --> 00:07:45.536 A:middle
And some of these are listed

00:07:45.596 --> 00:07:45.746 A:middle
here.

00:07:46.586 --> 00:07:48.436 A:middle
Apart from post-processing of

00:07:48.476 --> 00:07:49.696 A:middle
audio files that I just

00:07:49.696 --> 00:07:51.666 A:middle
mentioned, you could also use

00:07:51.666 --> 00:07:54.086 A:middle
offline mode to say mix audio

00:07:54.086 --> 00:07:54.476 A:middle
files.

00:07:55.556 --> 00:07:57.686 A:middle
You could use it for offline

00:07:57.686 --> 00:07:59.646 A:middle
processing using a very CPU

00:07:59.646 --> 00:08:01.246 A:middle
intensive or a higher quality

00:08:01.346 --> 00:08:02.806 A:middle
algorithm, which may not be

00:08:02.806 --> 00:08:04.346 A:middle
feasible to use in real time.

00:08:05.386 --> 00:08:06.936 A:middle
Or simply, you could use the

00:08:06.936 --> 00:08:09.496 A:middle
offline mode, to test, debug, or

00:08:09.636 --> 00:08:11.756 A:middle
tune your live Engine setup.

00:08:12.306 --> 00:08:15.766 A:middle
So, that concludes the offline

00:08:15.766 --> 00:08:17.486 A:middle
mode and as promised, I'll show

00:08:17.486 --> 00:08:20.936 A:middle
you a demo of this in action.

00:08:21.886 --> 00:08:27.056 A:middle
Alright so, what I have here is

00:08:27.056 --> 00:08:28.126 A:middle
an [inaudible] Playground.

00:08:29.136 --> 00:08:31.776 A:middle
And this is the example where we

00:08:31.776 --> 00:08:33.486 A:middle
will post-process the audio data

00:08:33.596 --> 00:08:36.126 A:middle
in a source file, apply a

00:08:36.366 --> 00:08:37.226 A:middle
[inaudible] effect on the data,

00:08:37.636 --> 00:08:39.186 A:middle
and dump the output into a

00:08:39.186 --> 00:08:40.076 A:middle
destination file.

00:08:40.646 --> 00:08:42.876 A:middle
I have some code snippets here

00:08:42.876 --> 00:08:43.936 A:middle
and [inaudible] on [inaudible].

00:08:44.076 --> 00:08:47.326 A:middle
So, the first thing I do here,

00:08:48.466 --> 00:08:51.716 A:middle
is set up the Engine to render

00:08:51.956 --> 00:08:53.706 A:middle
in a live mode to the device,

00:08:53.706 --> 00:08:55.976 A:middle
just to see how the source file

00:08:55.976 --> 00:08:58.536 A:middle
sounds without having added any

00:08:58.536 --> 00:08:59.826 A:middle
effect to it.

00:09:01.516 --> 00:09:04.506 A:middle
So, I'm first opening up the

00:09:04.506 --> 00:09:06.176 A:middle
source file, which I want to

00:09:06.226 --> 00:09:06.486 A:middle
read.

00:09:07.116 --> 00:09:10.706 A:middle
And then, I'm creating and

00:09:10.706 --> 00:09:11.816 A:middle
configuring my Engine.

00:09:12.506 --> 00:09:14.546 A:middle
So, I have an Engine and a

00:09:14.706 --> 00:09:15.536 A:middle
PlayerNode.

00:09:16.486 --> 00:09:17.836 A:middle
And I'm going to take the player

00:09:18.296 --> 00:09:19.676 A:middle
to the main mixer node of the

00:09:19.676 --> 00:09:21.406 A:middle
Engine, which is implicitly

00:09:21.436 --> 00:09:24.206 A:middle
connected to the OutputNode of

00:09:25.356 --> 00:09:25.726 A:middle
the Engine.

00:09:25.726 --> 00:09:27.006 A:middle
Then I'm scheduling the source

00:09:27.006 --> 00:09:28.766 A:middle
file that I have on the player

00:09:28.976 --> 00:09:30.176 A:middle
so that it can read the data

00:09:30.176 --> 00:09:30.976 A:middle
from the source file.

00:09:31.686 --> 00:09:34.116 A:middle
And then I'm starting the Engine

00:09:34.116 --> 00:09:34.996 A:middle
and starting the player.

00:09:35.866 --> 00:09:37.216 A:middle
So, as I mentioned, the Engine

00:09:37.216 --> 00:09:38.966 A:middle
is now in a live mode, and this

00:09:38.966 --> 00:09:41.256 A:middle
will render to the device.

00:09:41.636 --> 00:09:43.476 A:middle
So, let's see how the source

00:09:43.476 --> 00:09:45.416 A:middle
file sounds without any effects.

00:09:46.516 --> 00:09:54.716 A:middle
[ Music ]

00:09:55.216 --> 00:09:56.776 A:middle
Okay, so that's how the source

00:09:56.776 --> 00:09:59.146 A:middle
file sounds like.

00:09:59.236 --> 00:10:01.586 A:middle
So, now what I'll do is, add a

00:10:01.586 --> 00:10:04.096 A:middle
reverb effect to process the

00:10:04.096 --> 00:10:04.366 A:middle
data.

00:10:05.516 --> 00:10:07.156 A:middle
So, I'll remove the player to

00:10:07.156 --> 00:10:09.406 A:middle
main mixer connection, and I'll

00:10:09.506 --> 00:10:10.736 A:middle
insert the reverb.

00:10:11.806 --> 00:10:13.406 A:middle
So, here I've created a reverb

00:10:14.196 --> 00:10:16.026 A:middle
and I'm setting the parameters

00:10:16.026 --> 00:10:16.596 A:middle
of the reverb.

00:10:16.796 --> 00:10:18.926 A:middle
And in this example, I'm using a

00:10:18.926 --> 00:10:22.096 A:middle
factory preset and wetDryMix of

00:10:22.396 --> 00:10:23.206 A:middle
70%.

00:10:24.106 --> 00:10:25.176 A:middle
And then I'm inserting the

00:10:25.176 --> 00:10:27.436 A:middle
reverb in the playback part in

00:10:27.436 --> 00:10:28.816 A:middle
between the player and the main

00:10:28.816 --> 00:10:29.196 A:middle
mixer.

00:10:30.386 --> 00:10:32.786 A:middle
So, now if I run the example, we

00:10:32.786 --> 00:10:34.886 A:middle
can see how the processed output

00:10:34.976 --> 00:10:36.426 A:middle
will sound like.

00:10:37.516 --> 00:10:45.816 A:middle
[ Music ]

00:10:46.316 --> 00:10:48.776 A:middle
Okay, so now at this point, if I

00:10:48.776 --> 00:10:50.386 A:middle
want, I could go ahead and tune

00:10:50.386 --> 00:10:51.916 A:middle
my reverb parameter so that it

00:10:51.916 --> 00:10:53.326 A:middle
sounds exactly as I want.

00:10:53.786 --> 00:10:55.026 A:middle
So, suppose I'm happy with all

00:10:55.026 --> 00:10:56.736 A:middle
the parameters and then now I

00:10:56.736 --> 00:10:58.136 A:middle
want to completely export my

00:10:58.136 --> 00:10:59.686 A:middle
source file into a destination

00:10:59.686 --> 00:10:59.906 A:middle
file.

00:11:00.306 --> 00:11:01.546 A:middle
And this is where the offline

00:11:01.546 --> 00:11:02.526 A:middle
mode comes into picture.

00:11:03.876 --> 00:11:07.246 A:middle
So, what I'll first do is, I'll

00:11:07.246 --> 00:11:08.806 A:middle
enable -- I'll switch the Engine

00:11:08.806 --> 00:11:10.026 A:middle
from the live mode to the

00:11:10.026 --> 00:11:10.646 A:middle
offline mode.

00:11:10.646 --> 00:11:17.816 A:middle
So, what I've done here is I'm

00:11:18.076 --> 00:11:22.126 A:middle
calling an Enable Manual

00:11:22.416 --> 00:11:24.466 A:middle
Rendering Mode API, and I'm

00:11:24.466 --> 00:11:26.056 A:middle
saying, "It needs to be the

00:11:26.056 --> 00:11:27.236 A:middle
offline variant of it."

00:11:28.256 --> 00:11:30.156 A:middle
I'm specifying a format of the

00:11:30.216 --> 00:11:31.956 A:middle
output which I want the Engine

00:11:32.086 --> 00:11:32.706 A:middle
to give me.

00:11:33.236 --> 00:11:34.696 A:middle
And this is, in this example,

00:11:34.696 --> 00:11:36.256 A:middle
same as the format of the input.

00:11:36.716 --> 00:11:39.056 A:middle
And then I'm specifying a

00:11:39.056 --> 00:11:40.336 A:middle
certain maximum number of

00:11:40.336 --> 00:11:42.526 A:middle
frames, which is the maximum

00:11:42.666 --> 00:11:43.836 A:middle
number of frames that you will

00:11:43.836 --> 00:11:45.786 A:middle
ever ask the Engine to render in

00:11:45.786 --> 00:11:47.056 A:middle
a single rendered call.

00:11:47.696 --> 00:11:49.476 A:middle
And in this example, the value's

00:11:49.476 --> 00:11:50.536 A:middle
4096.

00:11:50.756 --> 00:11:52.556 A:middle
But you can configure this as

00:11:52.556 --> 00:11:52.966 A:middle
you wish.

00:11:53.516 --> 00:11:57.576 A:middle
So, now if I go ahead and run

00:11:58.086 --> 00:11:59.836 A:middle
this example, nothing will

00:11:59.836 --> 00:12:01.536 A:middle
happen because the Engine is now

00:12:01.536 --> 00:12:03.186 A:middle
in the offline mode, and it's

00:12:03.186 --> 00:12:04.066 A:middle
ready to render.

00:12:04.356 --> 00:12:05.586 A:middle
But of course, it's waiting for

00:12:05.586 --> 00:12:08.016 A:middle
the app to pull the Engine for

00:12:08.016 --> 00:12:08.466 A:middle
output.

00:12:09.556 --> 00:12:11.816 A:middle
So, what we'll do next is to

00:12:11.816 --> 00:12:13.296 A:middle
actually pull the Engine for

00:12:13.296 --> 00:12:13.776 A:middle
output.

00:12:16.636 --> 00:12:18.466 A:middle
So, here I'm creating an output

00:12:18.466 --> 00:12:21.586 A:middle
file to which I want to dump the

00:12:21.586 --> 00:12:22.296 A:middle
process data.

00:12:22.956 --> 00:12:26.326 A:middle
And I'm creating an output

00:12:26.326 --> 00:12:28.706 A:middle
buffer to which I'll ask the

00:12:28.706 --> 00:12:30.666 A:middle
Engine to render sequentially in

00:12:30.706 --> 00:12:31.696 A:middle
every rendered call.

00:12:32.676 --> 00:12:34.326 A:middle
And the format of this buffer is

00:12:34.326 --> 00:12:35.766 A:middle
the same format that as I

00:12:35.766 --> 00:12:37.616 A:middle
mentioned, when enabling the

00:12:37.616 --> 00:12:38.536 A:middle
offline mode.

00:12:39.046 --> 00:12:42.206 A:middle
And then comes the rendered loop

00:12:42.396 --> 00:12:44.236 A:middle
where I'll [inaudible] pull the

00:12:44.236 --> 00:12:45.496 A:middle
engine for output.

00:12:46.216 --> 00:12:47.676 A:middle
Now, in this example, I have a

00:12:47.676 --> 00:12:49.006 A:middle
source file which is about three

00:12:49.006 --> 00:12:49.816 A:middle
minutes long.

00:12:50.556 --> 00:12:52.026 A:middle
So, I really don't want to

00:12:52.026 --> 00:12:54.076 A:middle
allocate a huge output buffer

00:12:54.246 --> 00:12:55.846 A:middle
and ask the Engine to render the

00:12:55.846 --> 00:12:57.516 A:middle
entire three minutes of data in

00:12:57.516 --> 00:12:58.486 A:middle
a single rendered call.

00:12:58.996 --> 00:13:00.596 A:middle
And that's why what I'm doing is

00:13:00.676 --> 00:13:02.756 A:middle
allocating an output buffer of a

00:13:02.756 --> 00:13:05.206 A:middle
very reasonable size, but

00:13:05.206 --> 00:13:05.986 A:middle
[inaudible] pulling the Engine

00:13:05.986 --> 00:13:07.836 A:middle
for output into the same buffer,

00:13:07.836 --> 00:13:09.266 A:middle
and then dumping the output to

00:13:09.266 --> 00:13:10.186 A:middle
the destination file.

00:13:10.676 --> 00:13:13.786 A:middle
So, in every iteration, I'll

00:13:13.786 --> 00:13:16.216 A:middle
decide the number of frames to

00:13:16.216 --> 00:13:17.336 A:middle
render in this particular

00:13:17.366 --> 00:13:17.906 A:middle
rendered call.

00:13:18.566 --> 00:13:20.266 A:middle
And I call the rendered offline

00:13:20.416 --> 00:13:21.176 A:middle
[inaudible] around the Engine,

00:13:21.326 --> 00:13:23.076 A:middle
asking it to render those many

00:13:23.076 --> 00:13:24.636 A:middle
number of frames, and giving it

00:13:24.636 --> 00:13:26.456 A:middle
the output buffer that we just

00:13:26.456 --> 00:13:26.986 A:middle
allocated.

00:13:27.916 --> 00:13:29.466 A:middle
And depending on the status, if

00:13:29.466 --> 00:13:32.086 A:middle
it rendered success, the data

00:13:32.086 --> 00:13:33.706 A:middle
was rendered successfully and I

00:13:33.706 --> 00:13:35.506 A:middle
can go ahead and drag the data

00:13:35.616 --> 00:13:37.896 A:middle
into my output file, and in case

00:13:37.896 --> 00:13:39.146 A:middle
it rendered an error, then

00:13:39.146 --> 00:13:40.496 A:middle
something went wrong, so you can

00:13:40.496 --> 00:13:42.886 A:middle
check the error code for more

00:13:42.886 --> 00:13:43.456 A:middle
information.

00:13:44.636 --> 00:13:45.686 A:middle
So, finally, when the

00:13:45.686 --> 00:13:47.316 A:middle
rendering's done, I'll stop the

00:13:47.316 --> 00:13:49.276 A:middle
player and I'll stop the Engine.

00:13:50.146 --> 00:13:51.476 A:middle
So, now if I go ahead and run

00:13:51.476 --> 00:13:53.536 A:middle
this example, the entire source

00:13:53.536 --> 00:13:55.066 A:middle
file will get exported and the

00:13:55.066 --> 00:13:56.376 A:middle
data will be dumped into the

00:13:56.376 --> 00:13:57.196 A:middle
destination file.

00:13:57.876 --> 00:14:02.596 A:middle
So, let's do that.

00:14:02.816 --> 00:14:04.366 A:middle
Okay, so as you may have

00:14:04.366 --> 00:14:06.736 A:middle
observed, the three-minute

00:14:07.036 --> 00:14:09.566 A:middle
length long source file got

00:14:09.566 --> 00:14:11.266 A:middle
rendered into an output file,

00:14:11.746 --> 00:14:13.106 A:middle
way faster than real time.

00:14:13.486 --> 00:14:14.646 A:middle
And that is one of the main

00:14:14.646 --> 00:14:15.866 A:middle
applications of the offline

00:14:15.866 --> 00:14:16.416 A:middle
rendering mode.

00:14:17.416 --> 00:14:19.796 A:middle
So, what we'll do next is again,

00:14:19.796 --> 00:14:21.916 A:middle
listen to the source file, and

00:14:23.046 --> 00:14:25.396 A:middle
the destination file, and make

00:14:25.396 --> 00:14:28.946 A:middle
sure that the data was indeed

00:14:29.006 --> 00:14:29.396 A:middle
processed.

00:14:30.116 --> 00:14:31.636 A:middle
So, that is my source file.

00:14:33.146 --> 00:14:35.216 A:middle
And this is my destination file.

00:14:35.796 --> 00:14:40.636 A:middle
So, first we'll listen to the

00:14:40.636 --> 00:14:41.866 A:middle
source file.

00:14:42.516 --> 00:14:48.766 A:middle
[ Music ]

00:14:49.266 --> 00:14:51.786 A:middle
So, as you saw, it is pretty

00:14:51.786 --> 00:14:52.156 A:middle
dry.

00:14:53.096 --> 00:14:54.946 A:middle
And now, the processed file.

00:14:55.516 --> 00:15:03.746 A:middle
[ Music ]

00:15:04.246 --> 00:15:06.156 A:middle
Okay, so as expected, the

00:15:06.186 --> 00:15:07.876 A:middle
processed data has reverb effect

00:15:07.876 --> 00:15:08.426 A:middle
added to it.

00:15:09.746 --> 00:15:12.066 A:middle
So, that concludes the offline

00:15:12.066 --> 00:15:13.446 A:middle
rendering demo.

00:15:13.616 --> 00:15:15.316 A:middle
And I'll switch back to the

00:15:16.086 --> 00:15:16.246 A:middle
slides.

00:15:19.516 --> 00:15:24.666 A:middle
[ Applause ]

00:15:25.166 --> 00:15:26.136 A:middle
So, as I mentioned, there are

00:15:26.136 --> 00:15:27.606 A:middle
many more applications to the

00:15:27.756 --> 00:15:28.526 A:middle
rendering mode.

00:15:28.976 --> 00:15:31.446 A:middle
And I'm also happy to announce

00:15:31.506 --> 00:15:33.856 A:middle
that the sample code for this

00:15:33.906 --> 00:15:35.676 A:middle
example, is already available on

00:15:35.676 --> 00:15:37.316 A:middle
our Sessions Homepage, and we'll

00:15:37.316 --> 00:15:39.336 A:middle
show you a link to that homepage

00:15:39.336 --> 00:15:40.426 A:middle
at the end of presentation.

00:15:42.436 --> 00:15:44.356 A:middle
Now, going to the second variant

00:15:44.356 --> 00:15:45.606 A:middle
of the Manual Rendering Mode.

00:15:46.396 --> 00:15:47.746 A:middle
The real time Manual Entering

00:15:47.746 --> 00:15:47.916 A:middle
Mode.

00:15:48.696 --> 00:15:50.516 A:middle
As the name itself suggests,

00:15:50.626 --> 00:15:52.556 A:middle
under this mode, the Engine and

00:15:52.556 --> 00:15:53.966 A:middle
all the nodes in your processing

00:15:53.966 --> 00:15:55.836 A:middle
graph, assume that they are

00:15:55.886 --> 00:15:57.276 A:middle
rendering under a real-time

00:15:57.346 --> 00:15:57.886 A:middle
context.

00:15:58.376 --> 00:15:59.736 A:middle
And hence, the they honor the

00:15:59.776 --> 00:16:01.026 A:middle
real-time constraints.

00:16:01.766 --> 00:16:03.756 A:middle
That is, they will not make any

00:16:03.756 --> 00:16:05.776 A:middle
kind of a blocking calls on the

00:16:05.806 --> 00:16:06.396 A:middle
render thread.

00:16:07.046 --> 00:16:08.556 A:middle
For example, they will not call

00:16:08.556 --> 00:16:09.556 A:middle
any libdispatch.

00:16:10.146 --> 00:16:12.036 A:middle
They will not allocate memory or

00:16:12.076 --> 00:16:13.416 A:middle
wait to block on a mutex.

00:16:14.346 --> 00:16:15.836 A:middle
And because of this constraint,

00:16:16.106 --> 00:16:17.916 A:middle
suppose the input data for node

00:16:18.046 --> 00:16:19.396 A:middle
is not ready in time.

00:16:20.016 --> 00:16:22.046 A:middle
A node has no other choice, but

00:16:22.046 --> 00:16:23.756 A:middle
the say, "Drop the data for that

00:16:23.796 --> 00:16:25.516 A:middle
particular render cycle, or

00:16:25.746 --> 00:16:27.406 A:middle
assume zeros and proceed."

00:16:29.696 --> 00:16:31.486 A:middle
Now, let's see where you would

00:16:31.486 --> 00:16:32.826 A:middle
use the Engine in the real-time

00:16:32.826 --> 00:16:34.546 A:middle
Manual Rendering Mode.

00:16:35.236 --> 00:16:37.436 A:middle
Suppose you have a custom AU

00:16:37.436 --> 00:16:38.086 A:middle
audio unit.

00:16:38.986 --> 00:16:41.286 A:middle
That is, in the live playback

00:16:41.376 --> 00:16:43.456 A:middle
part, and within the internal

00:16:43.456 --> 00:16:45.116 A:middle
render block of your audio unit,

00:16:45.416 --> 00:16:46.836 A:middle
you would like to process the

00:16:46.836 --> 00:16:48.386 A:middle
data that is going through,

00:16:48.736 --> 00:16:50.746 A:middle
using some other audio unit or

00:16:50.796 --> 00:16:52.066 A:middle
audio units.

00:16:52.906 --> 00:16:54.996 A:middle
In that case, you can set up the

00:16:54.996 --> 00:16:57.316 A:middle
Engine to use those other audio

00:16:57.316 --> 00:16:59.716 A:middle
units and process the data in

00:16:59.716 --> 00:17:01.186 A:middle
the real-time Manual Rendering

00:17:01.726 --> 00:17:01.826 A:middle
Mode.

00:17:02.596 --> 00:17:04.236 A:middle
The second example would be,

00:17:04.366 --> 00:17:05.746 A:middle
suppose you wanted to process

00:17:05.746 --> 00:17:07.416 A:middle
the audio data that belongs to a

00:17:07.416 --> 00:17:09.286 A:middle
movie or video, as it is

00:17:09.286 --> 00:17:10.636 A:middle
streaming or playing back.

00:17:11.526 --> 00:17:12.516 A:middle
Because this happens in the

00:17:12.516 --> 00:17:14.016 A:middle
real-time, you could use the

00:17:14.016 --> 00:17:15.656 A:middle
Engine in real-time Manual

00:17:15.656 --> 00:17:17.306 A:middle
Rendering Mode, to do that audio

00:17:17.306 --> 00:17:17.846 A:middle
processing.

00:17:18.516 --> 00:17:19.986 A:middle
And now, let's consider the

00:17:19.986 --> 00:17:22.386 A:middle
second use case and see how to

00:17:22.386 --> 00:17:24.756 A:middle
set up and use the Engine both

00:17:24.756 --> 00:17:26.446 A:middle
as an example an in code.

00:17:27.106 --> 00:17:30.926 A:middle
So, here's the app that's

00:17:30.926 --> 00:17:33.416 A:middle
receiving input movie stream,

00:17:33.596 --> 00:17:35.236 A:middle
and displaying back in

00:17:35.236 --> 00:17:37.046 A:middle
real-time, say to a TV.

00:17:37.656 --> 00:17:39.016 A:middle
But what it wants to do is

00:17:39.236 --> 00:17:42.406 A:middle
process the audio data as it in

00:17:42.406 --> 00:17:44.046 A:middle
the input, before it goes to the

00:17:44.046 --> 00:17:44.466 A:middle
output.

00:17:45.776 --> 00:17:47.736 A:middle
So, now it can use the Engine in

00:17:47.736 --> 00:17:49.456 A:middle
the real-time Manual Rendering

00:17:49.456 --> 00:17:49.796 A:middle
Mode.

00:17:50.766 --> 00:17:52.586 A:middle
So, it could set up a processing

00:17:52.586 --> 00:17:53.896 A:middle
graph like this.

00:17:53.896 --> 00:17:55.656 A:middle
It can provide the input through

00:17:55.856 --> 00:17:58.016 A:middle
the input node, process it

00:17:58.186 --> 00:17:59.836 A:middle
through an effect node, and then

00:17:59.886 --> 00:18:01.306 A:middle
pull the data from the output

00:18:01.356 --> 00:18:04.626 A:middle
node and then play it back to

00:18:05.356 --> 00:18:07.116 A:middle
the device.

00:18:07.246 --> 00:18:09.156 A:middle
Now, let's see a code example on

00:18:09.156 --> 00:18:11.396 A:middle
how to set up and use the Engine

00:18:11.436 --> 00:18:11.956 A:middle
in this mode.

00:18:16.336 --> 00:18:17.616 A:middle
So, here's the code.

00:18:17.996 --> 00:18:20.246 A:middle
And note that the setting up the

00:18:20.246 --> 00:18:22.136 A:middle
Engine itself, happens from a

00:18:22.136 --> 00:18:23.626 A:middle
non-real-time context.

00:18:23.946 --> 00:18:25.886 A:middle
And it's only rendering part

00:18:26.026 --> 00:18:27.276 A:middle
that actually happens from a

00:18:27.276 --> 00:18:28.286 A:middle
real-time context.

00:18:28.836 --> 00:18:30.596 A:middle
So, here's the setup code, where

00:18:30.596 --> 00:18:32.706 A:middle
you first cleared the Engine,

00:18:33.186 --> 00:18:36.306 A:middle
and by default, on creation, the

00:18:36.306 --> 00:18:38.036 A:middle
Engine will be ready to render

00:18:38.206 --> 00:18:40.026 A:middle
to the device until you switch

00:18:40.026 --> 00:18:41.536 A:middle
it over to the Manual Rendering

00:18:41.536 --> 00:18:41.746 A:middle
Mode.

00:18:42.846 --> 00:18:44.376 A:middle
So, you cleared the Engine, make

00:18:44.376 --> 00:18:45.946 A:middle
your required connections, and

00:18:45.946 --> 00:18:47.796 A:middle
then switch it over to the

00:18:47.796 --> 00:18:48.796 A:middle
Manual Rendering Mode.

00:18:49.636 --> 00:18:51.116 A:middle
So, this is the same API that we

00:18:51.116 --> 00:18:52.876 A:middle
saw in the demo, except that we

00:18:52.876 --> 00:18:55.536 A:middle
are now saying -- now asking the

00:18:55.536 --> 00:18:57.106 A:middle
Engine to operate under

00:18:57.106 --> 00:18:58.556 A:middle
real-time Manual Rendering Mode.

00:18:59.326 --> 00:19:01.296 A:middle
And specifying the format for

00:19:01.296 --> 00:19:03.076 A:middle
the output and maximum number of

00:19:03.076 --> 00:19:03.556 A:middle
frames.

00:19:04.546 --> 00:19:07.946 A:middle
The next thing you do is session

00:19:08.056 --> 00:19:09.566 A:middle
cache, something called a

00:19:09.566 --> 00:19:10.396 A:middle
surrender block.

00:19:10.926 --> 00:19:12.546 A:middle
Now, because the rendering of

00:19:12.626 --> 00:19:13.966 A:middle
the Engine happens from a

00:19:13.966 --> 00:19:16.076 A:middle
real-time context, you will not

00:19:16.116 --> 00:19:17.496 A:middle
be able to use the render

00:19:17.596 --> 00:19:19.496 A:middle
offline Objective-C or Swift

00:19:19.496 --> 00:19:20.966 A:middle
meta that we saw in the demo.

00:19:21.346 --> 00:19:23.076 A:middle
And that is because, it is not

00:19:23.146 --> 00:19:25.226 A:middle
safe to use Objective-C or Swift

00:19:25.226 --> 00:19:26.286 A:middle
runtime from a real-time

00:19:26.286 --> 00:19:26.896 A:middle
context.

00:19:27.436 --> 00:19:28.976 A:middle
So, instead, the engine itself

00:19:28.976 --> 00:19:30.826 A:middle
provides you a render block that

00:19:30.826 --> 00:19:32.506 A:middle
you can search and cache, and

00:19:32.506 --> 00:19:34.086 A:middle
then later use this render block

00:19:34.286 --> 00:19:35.626 A:middle
to render the engine from the

00:19:35.626 --> 00:19:36.686 A:middle
real-time context.

00:19:38.256 --> 00:19:40.456 A:middle
The next thing is -- to do, is

00:19:40.456 --> 00:19:42.016 A:middle
to set up your input node so

00:19:42.016 --> 00:19:43.386 A:middle
that you can provide your input

00:19:43.386 --> 00:19:44.646 A:middle
data to the Engine.

00:19:45.416 --> 00:19:48.156 A:middle
And here, you specify the format

00:19:48.156 --> 00:19:49.786 A:middle
of the input that you will

00:19:49.786 --> 00:19:51.536 A:middle
provide, and this can be a

00:19:51.536 --> 00:19:52.586 A:middle
different format than the

00:19:52.626 --> 00:19:53.046 A:middle
output.

00:19:54.016 --> 00:19:55.916 A:middle
And you also provide a block

00:19:55.916 --> 00:19:57.396 A:middle
which the Engine will call,

00:19:57.546 --> 00:19:59.076 A:middle
whenever it needs the input

00:19:59.186 --> 00:19:59.546 A:middle
data.

00:20:01.696 --> 00:20:03.716 A:middle
And when this block gets called,

00:20:03.716 --> 00:20:05.476 A:middle
the Engine will let you know how

00:20:05.476 --> 00:20:07.136 A:middle
many number of input frames it

00:20:07.136 --> 00:20:07.936 A:middle
actually needs.

00:20:08.606 --> 00:20:10.616 A:middle
And at that point, if you have

00:20:10.616 --> 00:20:12.986 A:middle
the data, you'll fill up an

00:20:12.986 --> 00:20:14.646 A:middle
input audio buffer list and

00:20:14.646 --> 00:20:15.986 A:middle
return it to the engine.

00:20:16.846 --> 00:20:18.416 A:middle
But if you don't have data, you

00:20:18.416 --> 00:20:20.096 A:middle
can return nil at this point.

00:20:21.446 --> 00:20:22.876 A:middle
Now note that the input node can

00:20:22.876 --> 00:20:25.156 A:middle
be used both in the offline and

00:20:25.276 --> 00:20:26.696 A:middle
real-time Manual Rendering Mode.

00:20:27.246 --> 00:20:28.886 A:middle
But when you're using it in the

00:20:28.886 --> 00:20:30.316 A:middle
real-time Manual Rendering Mode,

00:20:30.686 --> 00:20:32.576 A:middle
this input block also gets

00:20:32.576 --> 00:20:34.366 A:middle
called from a real-time context,

00:20:34.746 --> 00:20:36.146 A:middle
which means that you need to

00:20:36.146 --> 00:20:38.096 A:middle
take care not to make any kind

00:20:38.096 --> 00:20:39.936 A:middle
of blocking calls within this

00:20:40.556 --> 00:20:42.026 A:middle
input block.

00:20:43.356 --> 00:20:45.236 A:middle
The next part of the setup is to

00:20:45.236 --> 00:20:47.586 A:middle
clear your output buffer, and

00:20:47.586 --> 00:20:49.386 A:middle
the difference here is you will

00:20:49.386 --> 00:20:51.956 A:middle
create an AVAudioPCMBuffer and

00:20:51.956 --> 00:20:53.806 A:middle
fetch its audio buffer list

00:20:54.006 --> 00:20:55.726 A:middle
which is what you'll use in the

00:20:55.726 --> 00:20:57.206 A:middle
real-time render logic.

00:20:57.726 --> 00:21:00.206 A:middle
And finally, you'll go ahead and

00:21:00.206 --> 00:21:00.976 A:middle
start the Engine.

00:21:01.546 --> 00:21:03.286 A:middle
So, now the Engine is all set up

00:21:03.286 --> 00:21:04.646 A:middle
and ready to render, and is

00:21:04.646 --> 00:21:06.706 A:middle
waiting for the app to pull for

00:21:06.776 --> 00:21:08.076 A:middle
the output data.

00:21:08.616 --> 00:21:12.846 A:middle
Now here comes the actual render

00:21:12.886 --> 00:21:13.346 A:middle
logic.

00:21:13.916 --> 00:21:15.626 A:middle
And note that this part of the

00:21:15.666 --> 00:21:17.836 A:middle
chord is written in C++, and

00:21:17.836 --> 00:21:19.516 A:middle
that is because as I mentioned,

00:21:19.716 --> 00:21:21.546 A:middle
we are -- it's not safe to use

00:21:21.546 --> 00:21:24.046 A:middle
Objective-C or Swift runtime

00:21:24.096 --> 00:21:25.386 A:middle
from a real-time context.

00:21:26.546 --> 00:21:28.166 A:middle
So, what we're doing first is

00:21:28.716 --> 00:21:30.156 A:middle
calling the render block that we

00:21:30.246 --> 00:21:32.516 A:middle
cached earlier, and asking the

00:21:32.516 --> 00:21:33.626 A:middle
Engine to render a certain

00:21:33.626 --> 00:21:35.296 A:middle
number or frames, and giving it

00:21:35.296 --> 00:21:36.606 A:middle
the outputBufferList that we

00:21:36.606 --> 00:21:37.076 A:middle
created.

00:21:38.086 --> 00:21:39.606 A:middle
And finally, depending on the

00:21:39.606 --> 00:21:41.856 A:middle
status, if you get a success, it

00:21:41.856 --> 00:21:43.426 A:middle
means everything went fine and

00:21:43.426 --> 00:21:44.726 A:middle
the data was rendered to the

00:21:44.726 --> 00:21:45.416 A:middle
output buffer.

00:21:46.216 --> 00:21:47.976 A:middle
But you could also get an

00:21:47.976 --> 00:21:49.736 A:middle
insufficient data from input

00:21:49.736 --> 00:21:51.776 A:middle
note as a status, which means

00:21:51.776 --> 00:21:54.846 A:middle
that when your input block was

00:21:54.896 --> 00:21:56.526 A:middle
called by the Engine for input

00:21:56.526 --> 00:21:58.386 A:middle
data, you did not have enough

00:21:58.386 --> 00:22:00.276 A:middle
data in your written nil from

00:22:00.276 --> 00:22:01.056 A:middle
that input block.

00:22:01.946 --> 00:22:03.816 A:middle
And note that in this case, in

00:22:03.816 --> 00:22:05.696 A:middle
case you have other sources in

00:22:05.696 --> 00:22:07.116 A:middle
your processing graph, for

00:22:07.116 --> 00:22:08.576 A:middle
example, you have some of the

00:22:08.606 --> 00:22:08.946 A:middle
[inaudible] notes.

00:22:09.396 --> 00:22:10.666 A:middle
Those notes could have still

00:22:10.666 --> 00:22:12.446 A:middle
rendered the input data, so you

00:22:12.446 --> 00:22:14.176 A:middle
may still have some output in

00:22:14.176 --> 00:22:15.096 A:middle
your output buffer.

00:22:15.446 --> 00:22:17.256 A:middle
So, you can check the sizes of

00:22:17.306 --> 00:22:19.076 A:middle
your output buffer, to determine

00:22:19.136 --> 00:22:20.876 A:middle
whether or not it has any data.

00:22:22.276 --> 00:22:23.936 A:middle
And of course, you handle the

00:22:23.936 --> 00:22:26.326 A:middle
other status which includes the

00:22:26.326 --> 00:22:28.196 A:middle
error, and that is pretty much

00:22:28.196 --> 00:22:30.246 A:middle
the render logic in real-time

00:22:30.246 --> 00:22:31.866 A:middle
Manual Rendering Mode.

00:22:33.896 --> 00:22:37.106 A:middle
Now, lastly a note on the render

00:22:37.176 --> 00:22:37.546 A:middle
cause.

00:22:38.276 --> 00:22:39.396 A:middle
In the offline mode, because

00:22:39.396 --> 00:22:40.456 A:middle
there are no deadlines or

00:22:40.506 --> 00:22:42.056 A:middle
real-time constraints, you can

00:22:42.056 --> 00:22:43.796 A:middle
use either the Objective-C or

00:22:43.796 --> 00:22:45.606 A:middle
the Swift render of line method,

00:22:45.966 --> 00:22:47.666 A:middle
or you could use the render

00:22:47.666 --> 00:22:49.246 A:middle
block based render call in order

00:22:49.246 --> 00:22:50.176 A:middle
to render the Engine.

00:22:50.776 --> 00:22:52.116 A:middle
But in real-time Manual

00:22:52.116 --> 00:22:53.956 A:middle
Rendering Mode, you must use the

00:22:53.956 --> 00:22:55.276 A:middle
block based render call.

00:22:55.946 --> 00:22:58.646 A:middle
So, that brings us to the end of

00:22:58.706 --> 00:22:59.866 A:middle
Manual Rendering Mode.

00:23:00.196 --> 00:23:03.836 A:middle
Now let's now see the next new

00:23:03.836 --> 00:23:05.356 A:middle
mode we have in the Engine,

00:23:05.356 --> 00:23:07.306 A:middle
which is the Auto Shutdown Mode.

00:23:09.046 --> 00:23:10.476 A:middle
Now, normally it is the

00:23:10.476 --> 00:23:12.496 A:middle
responsibility of the app to

00:23:12.576 --> 00:23:14.576 A:middle
pause or stop the Engine when it

00:23:14.576 --> 00:23:16.306 A:middle
is not in use in order to

00:23:16.306 --> 00:23:16.976 A:middle
conserve power.

00:23:16.976 --> 00:23:19.766 A:middle
For example, say we have a music

00:23:19.766 --> 00:23:21.236 A:middle
app that is using one of the

00:23:21.276 --> 00:23:22.906 A:middle
player nodes for playing back

00:23:23.626 --> 00:23:26.106 A:middle
some file, and say the user

00:23:26.106 --> 00:23:27.346 A:middle
stops the playback.

00:23:28.156 --> 00:23:29.986 A:middle
Now the app, should not only

00:23:30.126 --> 00:23:32.316 A:middle
pause or stop the player node,

00:23:32.596 --> 00:23:34.356 A:middle
but it should also pause or stop

00:23:34.356 --> 00:23:36.246 A:middle
the Engine in order to prevent

00:23:36.246 --> 00:23:37.436 A:middle
it from running idle.

00:23:38.496 --> 00:23:39.836 A:middle
But in the past, we have seen

00:23:39.836 --> 00:23:41.726 A:middle
that not all the apps actually

00:23:41.726 --> 00:23:43.846 A:middle
do this, and especially that's

00:23:43.846 --> 00:23:44.646 A:middle
true on watchOS.

00:23:45.396 --> 00:23:47.166 A:middle
And hence, we are now adding the

00:23:47.166 --> 00:23:49.546 A:middle
safety net in order to conserve

00:23:49.806 --> 00:23:51.486 A:middle
power with this auto shutdown

00:23:51.486 --> 00:23:51.716 A:middle
mode.

00:23:52.866 --> 00:23:54.136 A:middle
When the Engine is operating

00:23:54.136 --> 00:23:56.246 A:middle
under this mode, it will

00:23:56.246 --> 00:23:58.076 A:middle
continuously monitor and if it

00:23:58.076 --> 00:24:00.276 A:middle
detects that the Engine is

00:24:00.276 --> 00:24:01.826 A:middle
running idle for a certain

00:24:01.826 --> 00:24:03.656 A:middle
duration, it will go ahead and

00:24:03.656 --> 00:24:05.176 A:middle
stop the audio hardware and

00:24:05.176 --> 00:24:05.506 A:middle
delete.

00:24:06.286 --> 00:24:07.966 A:middle
And later on, suppose any of the

00:24:07.966 --> 00:24:09.796 A:middle
sources become active again, it

00:24:09.796 --> 00:24:11.166 A:middle
will start the audio hardware

00:24:11.166 --> 00:24:11.786 A:middle
dynamically.

00:24:12.376 --> 00:24:13.666 A:middle
And all of this happens under

00:24:13.666 --> 00:24:13.966 A:middle
the hood.

00:24:15.196 --> 00:24:16.266 A:middle
And this is the enforced

00:24:16.266 --> 00:24:18.436 A:middle
behavior on watchOS, but it can

00:24:18.436 --> 00:24:20.186 A:middle
also be optionally enabled on

00:24:20.186 --> 00:24:20.986 A:middle
other platforms.

00:24:23.316 --> 00:24:26.106 A:middle
Now, next onto the enhancements

00:24:26.106 --> 00:24:27.326 A:middle
in AV Audio Player Node.

00:24:27.946 --> 00:24:31.196 A:middle
AV Audio Player Node is one of

00:24:31.196 --> 00:24:32.726 A:middle
the source nodes in the Engine,

00:24:33.066 --> 00:24:34.536 A:middle
through which you could schedule

00:24:34.536 --> 00:24:36.466 A:middle
a buffer or file for playback.

00:24:36.966 --> 00:24:39.696 A:middle
And the existing [inaudible]

00:24:39.696 --> 00:24:41.396 A:middle
methods, take a completion

00:24:41.436 --> 00:24:42.956 A:middle
handler and they call the

00:24:42.956 --> 00:24:44.806 A:middle
completion handler when the data

00:24:44.806 --> 00:24:46.246 A:middle
that you have provided has been

00:24:46.246 --> 00:24:47.546 A:middle
consumed by the player.

00:24:49.056 --> 00:24:50.996 A:middle
We are now adding new completion

00:24:50.996 --> 00:24:52.436 A:middle
handler and new types of

00:24:52.526 --> 00:24:54.526 A:middle
callbacks, in order for you to

00:24:54.666 --> 00:24:56.516 A:middle
know various stages of

00:24:56.556 --> 00:24:57.236 A:middle
completion.

00:24:57.776 --> 00:25:01.836 A:middle
The first new callback type is

00:25:01.836 --> 00:25:03.196 A:middle
the data consumed type.

00:25:03.686 --> 00:25:05.396 A:middle
And this is exactly same as the

00:25:05.396 --> 00:25:06.776 A:middle
existing completion handler.

00:25:07.246 --> 00:25:09.536 A:middle
That is, when the completion

00:25:09.536 --> 00:25:11.326 A:middle
handler gets called, it means

00:25:11.326 --> 00:25:12.786 A:middle
the data has been consumed by

00:25:12.786 --> 00:25:13.236 A:middle
the player.

00:25:13.236 --> 00:25:15.386 A:middle
So, at that point, if you

00:25:15.446 --> 00:25:17.106 A:middle
wanted, you could recycle that

00:25:17.106 --> 00:25:19.606 A:middle
buffer, or if you have more data

00:25:19.866 --> 00:25:21.376 A:middle
to schedule on the player, you

00:25:21.416 --> 00:25:21.936 A:middle
could do that.

00:25:22.796 --> 00:25:24.746 A:middle
The second type of callback is

00:25:24.746 --> 00:25:26.076 A:middle
the data rendered callback.

00:25:26.466 --> 00:25:27.896 A:middle
And that means that the data

00:25:28.256 --> 00:25:29.726 A:middle
that you provided, has been

00:25:29.906 --> 00:25:31.316 A:middle
rendered when the completion

00:25:31.316 --> 00:25:32.196 A:middle
handler gets called.

00:25:33.136 --> 00:25:34.446 A:middle
And this does not account for

00:25:34.446 --> 00:25:36.226 A:middle
any downstream signal processing

00:25:36.226 --> 00:25:38.776 A:middle
latencies in your processing

00:25:39.516 --> 00:25:39.666 A:middle
graph.

00:25:40.236 --> 00:25:42.496 A:middle
The last type is the data played

00:25:42.496 --> 00:25:44.016 A:middle
back type, which is the most

00:25:44.016 --> 00:25:44.786 A:middle
interesting one.

00:25:45.286 --> 00:25:46.736 A:middle
And this means that when your

00:25:46.786 --> 00:25:48.226 A:middle
completion handler gets called,

00:25:48.526 --> 00:25:50.176 A:middle
the buffer or the file that you

00:25:50.176 --> 00:25:52.146 A:middle
scheduled, has actually finished

00:25:52.246 --> 00:25:53.476 A:middle
playing from the listener's

00:25:53.516 --> 00:25:54.186 A:middle
perspective.

00:25:55.016 --> 00:25:56.626 A:middle
And this is applicable only when

00:25:56.626 --> 00:25:57.906 A:middle
the Engine is rendering to the

00:25:57.906 --> 00:25:58.396 A:middle
device.

00:25:59.086 --> 00:26:00.546 A:middle
And this accounts for all the

00:26:00.546 --> 00:26:02.026 A:middle
signal processing latencies,

00:26:02.236 --> 00:26:03.846 A:middle
downstream of the player in your

00:26:03.876 --> 00:26:06.246 A:middle
processing graph, as well as any

00:26:06.246 --> 00:26:07.826 A:middle
latency in the audio playback

00:26:07.886 --> 00:26:08.326 A:middle
device.

00:26:09.506 --> 00:26:12.216 A:middle
So, as a code example, let's see

00:26:12.646 --> 00:26:14.416 A:middle
a scheduled file method through

00:26:14.416 --> 00:26:15.666 A:middle
which you can schedule a file

00:26:15.666 --> 00:26:16.386 A:middle
for playback.

00:26:17.266 --> 00:26:19.066 A:middle
So, here, I'm scheduling a file

00:26:19.066 --> 00:26:20.816 A:middle
for playback and indicating that

00:26:20.816 --> 00:26:22.186 A:middle
I'm interested to know when the

00:26:22.186 --> 00:26:23.856 A:middle
data has played back.

00:26:25.186 --> 00:26:26.566 A:middle
That me -- and I'm providing a

00:26:26.566 --> 00:26:27.406 A:middle
completion handler.

00:26:28.076 --> 00:26:29.336 A:middle
So, when the completion handler

00:26:29.336 --> 00:26:31.056 A:middle
gets called, it means that my

00:26:31.056 --> 00:26:32.756 A:middle
file has finished playing, and

00:26:32.756 --> 00:26:33.966 A:middle
at this point, I can say,

00:26:33.966 --> 00:26:35.846 A:middle
"Notify my UI thread to update

00:26:35.846 --> 00:26:38.326 A:middle
the UI," or I can notify my main

00:26:38.326 --> 00:26:39.676 A:middle
thread to go ahead and stop the

00:26:39.676 --> 00:26:40.836 A:middle
Engine, if that's applicable.

00:26:41.446 --> 00:26:45.566 A:middle
So, that brings us to the end of

00:26:45.616 --> 00:26:47.086 A:middle
the enhancements we have in AV

00:26:47.086 --> 00:26:47.726 A:middle
Audio Engine.

00:26:48.376 --> 00:26:49.916 A:middle
At this point, I would also like

00:26:49.966 --> 00:26:52.026 A:middle
to mention that we will soon be

00:26:52.026 --> 00:26:54.726 A:middle
deprecating the AU Graph API in

00:26:54.726 --> 00:26:56.076 A:middle
the Audio Toolbox framework, in

00:26:56.146 --> 00:26:59.256 A:middle
2018, so please move over to

00:26:59.256 --> 00:27:01.076 A:middle
using AV Audio Engine instead of

00:27:01.126 --> 00:27:02.916 A:middle
AU Graph if you've not already

00:27:02.916 --> 00:27:03.926 A:middle
done that.

00:27:06.456 --> 00:27:08.466 A:middle
Now let's go to the second set

00:27:08.466 --> 00:27:10.016 A:middle
of API in the AV Foundation

00:27:10.016 --> 00:27:11.666 A:middle
framework, AV Audio Session.

00:27:12.076 --> 00:27:15.866 A:middle
AirPlay 2 is a brand-new

00:27:15.866 --> 00:27:17.946 A:middle
technology in this year's iOS,

00:27:17.946 --> 00:27:19.396 A:middle
tvOS, and macOS [inaudible].

00:27:19.396 --> 00:27:22.486 A:middle
And this lets you do multi-room

00:27:22.646 --> 00:27:24.546 A:middle
audio with AirPlay 2 capable

00:27:24.546 --> 00:27:26.336 A:middle
devices, which is for example,

00:27:26.336 --> 00:27:26.886 A:middle
the Homepod.

00:27:27.466 --> 00:27:30.036 A:middle
So, there is a separate

00:27:30.036 --> 00:27:31.676 A:middle
dedicated session called

00:27:31.676 --> 00:27:32.946 A:middle
"Interviews in AirPlay 2,"

00:27:33.036 --> 00:27:34.906 A:middle
happening this Thursday at 4:10

00:27:34.956 --> 00:27:37.826 A:middle
p.m. to go over all the features

00:27:37.826 --> 00:27:39.216 A:middle
of this technology.

00:27:39.446 --> 00:27:40.646 A:middle
So, you can catch that if you're

00:27:40.646 --> 00:27:42.826 A:middle
interested in knowing more

00:27:44.096 --> 00:27:44.286 A:middle
details.

00:27:44.406 --> 00:27:45.946 A:middle
Also seated with AirPlay 2 is

00:27:45.946 --> 00:27:47.406 A:middle
something called Long-Form

00:27:47.406 --> 00:27:47.746 A:middle
audio.

00:27:48.486 --> 00:27:49.876 A:middle
And this is a category of

00:27:49.996 --> 00:27:52.536 A:middle
content, for example music or

00:27:52.666 --> 00:27:55.246 A:middle
podcast, which is typically more

00:27:55.246 --> 00:27:57.426 A:middle
than a few minutes long, and

00:27:57.426 --> 00:27:59.116 A:middle
whose playback can be shared

00:27:59.286 --> 00:27:59.776 A:middle
with others.

00:28:01.046 --> 00:28:02.316 A:middle
For example, say you have a

00:28:02.316 --> 00:28:04.036 A:middle
party at home, and you are

00:28:04.036 --> 00:28:05.566 A:middle
playing back a music playlist

00:28:05.566 --> 00:28:07.236 A:middle
through an AirPlay device.

00:28:07.546 --> 00:28:09.656 A:middle
Now that is categorized as --

00:28:09.656 --> 00:28:10.976 A:middle
that can be categorized as a

00:28:10.976 --> 00:28:12.276 A:middle
long-form audio content.

00:28:13.376 --> 00:28:15.856 A:middle
Now with AirPlay 2 and long-form

00:28:15.856 --> 00:28:18.616 A:middle
audio, we now get a separate

00:28:18.616 --> 00:28:20.966 A:middle
shared route for the long-form

00:28:20.966 --> 00:28:22.806 A:middle
audio apps to the AirPlay 2

00:28:22.806 --> 00:28:23.306 A:middle
devices.

00:28:23.896 --> 00:28:26.426 A:middle
And I'll explain about that in a

00:28:26.426 --> 00:28:27.696 A:middle
little more detail.

00:28:28.986 --> 00:28:30.766 A:middle
And right -- and now, we have

00:28:30.766 --> 00:28:33.216 A:middle
new API in AV Audio Session, for

00:28:33.216 --> 00:28:35.496 A:middle
an app to identify itself as

00:28:35.496 --> 00:28:37.056 A:middle
being long-form and take

00:28:37.056 --> 00:28:38.736 A:middle
advantage of this separate

00:28:39.516 --> 00:28:41.146 A:middle
shared audio route.

00:28:42.416 --> 00:28:45.046 A:middle
So, let's consider the example I

00:28:45.046 --> 00:28:45.766 A:middle
just mentioned.

00:28:45.766 --> 00:28:47.626 A:middle
So, say you have a party at

00:28:47.626 --> 00:28:49.056 A:middle
home, and you're playing back

00:28:49.056 --> 00:28:50.776 A:middle
music to an AirPlay device.

00:28:51.476 --> 00:28:52.666 A:middle
We'll contrast the current

00:28:52.666 --> 00:28:54.546 A:middle
behavior and see how the

00:28:54.546 --> 00:28:56.436 A:middle
behavior changes with long-form

00:28:56.436 --> 00:28:57.066 A:middle
audio routing.

00:28:57.456 --> 00:28:58.636 A:middle
So, here is the current

00:28:58.636 --> 00:28:59.076 A:middle
behavior.

00:28:59.606 --> 00:29:01.206 A:middle
So, you -- the music is now

00:29:01.206 --> 00:29:03.476 A:middle
playing back through the AirPlay

00:29:03.476 --> 00:29:05.826 A:middle
device, and suppose you now get

00:29:05.826 --> 00:29:07.896 A:middle
a phone call.

00:29:08.116 --> 00:29:10.586 A:middle
What happens is, at this point,

00:29:10.586 --> 00:29:11.926 A:middle
your music playback gets

00:29:11.926 --> 00:29:13.786 A:middle
interrupted and it stops.

00:29:14.416 --> 00:29:16.286 A:middle
And the phone call gets routed

00:29:16.476 --> 00:29:17.856 A:middle
to the system audio which could

00:29:17.856 --> 00:29:18.586 A:middle
be receiver or [inaudible]

00:29:18.586 --> 00:29:19.186 A:middle
speaker.

00:29:20.236 --> 00:29:21.826 A:middle
And only when the phone call

00:29:21.826 --> 00:29:23.706 A:middle
ends, is when the music gets a

00:29:23.736 --> 00:29:25.936 A:middle
resumable [inaudible] and it

00:29:25.936 --> 00:29:27.026 A:middle
resumes the playback.

00:29:28.186 --> 00:29:30.166 A:middle
So, as you can see, a phone call

00:29:30.166 --> 00:29:32.106 A:middle
interrupting your party music is

00:29:32.106 --> 00:29:34.396 A:middle
not really an ideal scenario.

00:29:35.126 --> 00:29:36.546 A:middle
So, we'll now see how the

00:29:36.546 --> 00:29:38.956 A:middle
behavior changes with long-form

00:29:38.956 --> 00:29:39.566 A:middle
audio routing.

00:29:41.256 --> 00:29:43.586 A:middle
So lets see the same example.

00:29:43.586 --> 00:29:45.536 A:middle
So, now that we have music

00:29:45.756 --> 00:29:47.196 A:middle
playing back through an AirPlay

00:29:47.266 --> 00:29:48.546 A:middle
2 capable device.

00:29:49.416 --> 00:29:51.966 A:middle
And then, a phone call comes in.

00:29:52.706 --> 00:29:54.316 A:middle
Now because the phone call is

00:29:54.316 --> 00:29:56.776 A:middle
not a long-form audio, it does

00:29:56.776 --> 00:29:58.316 A:middle
not interrupt your music

00:29:58.316 --> 00:30:00.256 A:middle
playback, and it gets routed

00:30:00.256 --> 00:30:02.136 A:middle
independently to the system

00:30:02.136 --> 00:30:03.976 A:middle
audio without any issues.

00:30:04.526 --> 00:30:06.216 A:middle
So, with long-form audio

00:30:06.246 --> 00:30:08.636 A:middle
routing, two of the sessions can

00:30:08.636 --> 00:30:10.696 A:middle
coexist without interrupting

00:30:10.956 --> 00:30:12.826 A:middle
each other, and as you can see,

00:30:12.876 --> 00:30:14.666 A:middle
this is definitely an enhanced

00:30:14.786 --> 00:30:15.756 A:middle
user experience.

00:30:16.856 --> 00:30:16.946 A:middle
So,-- .

00:30:18.516 --> 00:30:22.746 A:middle
[ Applause ]

00:30:23.246 --> 00:30:25.206 A:middle
So, to summarize, with long-form

00:30:25.206 --> 00:30:27.606 A:middle
audio routing, all the apps that

00:30:27.606 --> 00:30:29.396 A:middle
identified themselves as being

00:30:29.396 --> 00:30:31.136 A:middle
long-form, which is for example,

00:30:31.276 --> 00:30:33.876 A:middle
music, podcast, or any other

00:30:33.876 --> 00:30:36.396 A:middle
music streaming app, they get

00:30:36.396 --> 00:30:38.126 A:middle
the dedicated -- they get a

00:30:38.126 --> 00:30:39.656 A:middle
separate shared route to the

00:30:39.656 --> 00:30:41.196 A:middle
AirPlay 2 capable device.

00:30:42.006 --> 00:30:43.046 A:middle
Now, note that there is a

00:30:43.046 --> 00:30:44.746 A:middle
session arbitrated in between.

00:30:45.146 --> 00:30:48.036 A:middle
And that ensures that only one

00:30:48.086 --> 00:30:50.006 A:middle
of these apps is playing to the

00:30:50.006 --> 00:30:51.436 A:middle
AirPlay device at the time.

00:30:51.646 --> 00:30:53.776 A:middle
So, these apps cannot mix with

00:30:53.776 --> 00:30:54.546 A:middle
each other.

00:30:55.056 --> 00:30:57.226 A:middle
And all the other apps that use

00:30:57.226 --> 00:30:58.486 A:middle
the system route, which are

00:30:58.486 --> 00:31:00.486 A:middle
non-long-form, can either

00:31:00.616 --> 00:31:02.276 A:middle
interrupt each other or mix with

00:31:02.276 --> 00:31:04.466 A:middle
each other, and they get routed

00:31:04.606 --> 00:31:06.446 A:middle
to the system audio without

00:31:06.446 --> 00:31:07.956 A:middle
interrupting your long-form

00:31:07.956 --> 00:31:08.606 A:middle
audio playback.

00:31:10.336 --> 00:31:13.886 A:middle
Now, let's see how an app can

00:31:13.946 --> 00:31:15.496 A:middle
identify itself as being

00:31:15.496 --> 00:31:17.136 A:middle
long-form and take advantage of

00:31:17.186 --> 00:31:17.796 A:middle
this routing.

00:31:19.176 --> 00:31:21.956 A:middle
So, on iOS and tvOS, the code is

00:31:21.956 --> 00:31:22.646 A:middle
really simple.

00:31:23.006 --> 00:31:24.926 A:middle
You get shared instance of your

00:31:25.026 --> 00:31:26.996 A:middle
AVAudio session, and you use

00:31:27.046 --> 00:31:28.806 A:middle
this new API to set your

00:31:28.806 --> 00:31:31.206 A:middle
category as playback and route

00:31:31.206 --> 00:31:36.096 A:middle
sharing policy as long-form.

00:31:36.276 --> 00:31:38.496 A:middle
Now, moving over to the macOS,

00:31:39.216 --> 00:31:41.726 A:middle
the routing is very similar to

00:31:41.726 --> 00:31:43.026 A:middle
the iOS and tvOS.

00:31:43.376 --> 00:31:45.236 A:middle
All the long-form audio apps,

00:31:45.236 --> 00:31:47.386 A:middle
for example your iTunes and any

00:31:47.386 --> 00:31:49.966 A:middle
other music streaming app, gets

00:31:50.176 --> 00:31:52.216 A:middle
routed to the AirPlay 2 capable

00:31:52.216 --> 00:31:54.506 A:middle
device, and of course, there is

00:31:54.506 --> 00:31:55.856 A:middle
an arbitrator in between.

00:31:57.046 --> 00:31:59.566 A:middle
And the other system apps like

00:31:59.926 --> 00:32:02.626 A:middle
GarageBand, Safari, or Game App,

00:32:02.626 --> 00:32:04.476 A:middle
do not interrupt your long-form

00:32:04.476 --> 00:32:06.506 A:middle
audio apps, and they always mix

00:32:06.506 --> 00:32:08.216 A:middle
with each other and get routed

00:32:08.396 --> 00:32:09.686 A:middle
to the default device.

00:32:10.836 --> 00:32:12.576 A:middle
And to enable the support of

00:32:12.576 --> 00:32:13.926 A:middle
long-form audio routing on

00:32:13.926 --> 00:32:15.696 A:middle
macOS, we are now bringing a

00:32:15.696 --> 00:32:17.596 A:middle
very small subset of AVAudio

00:32:17.596 --> 00:32:19.066 A:middle
Session to macOS.

00:32:19.666 --> 00:32:21.496 A:middle
So, as an app, in order to

00:32:21.496 --> 00:32:23.056 A:middle
identify yourself as being

00:32:23.056 --> 00:32:25.056 A:middle
long-form, you again get the

00:32:25.056 --> 00:32:27.066 A:middle
shared and sense of your AVAudio

00:32:27.066 --> 00:32:28.576 A:middle
Session, and set the route

00:32:28.576 --> 00:32:30.116 A:middle
sharing policy as being

00:32:30.116 --> 00:32:30.636 A:middle
long-form.

00:32:31.166 --> 00:32:34.586 A:middle
So, that is the end of AVAudio

00:32:34.586 --> 00:32:36.476 A:middle
Session enhancements, and let's

00:32:36.476 --> 00:32:38.226 A:middle
now see the last section in the

00:32:38.226 --> 00:32:39.736 A:middle
AV Foundation framework, that is

00:32:39.736 --> 00:32:40.986 A:middle
the enhancement on watchOS.

00:32:41.606 --> 00:32:45.936 A:middle
So, we introduced the AV -- we

00:32:45.936 --> 00:32:47.936 A:middle
made AVAudio Player API

00:32:48.016 --> 00:32:50.336 A:middle
available in watchOS 3.1SDK.

00:32:50.926 --> 00:32:51.786 A:middle
And this is the first time we

00:32:51.786 --> 00:32:53.546 A:middle
get to mention it at WWDC.

00:32:54.116 --> 00:32:55.366 A:middle
And the nice thing about using

00:32:55.366 --> 00:32:57.256 A:middle
the AVAudio Player for playback

00:32:57.536 --> 00:32:59.266 A:middle
is that it comes associated with

00:32:59.266 --> 00:33:01.026 A:middle
its AVAudio Session, so you

00:33:01.026 --> 00:33:02.766 A:middle
could use the session category

00:33:02.766 --> 00:33:04.326 A:middle
options like [inaudible] or mix

00:33:04.376 --> 00:33:06.816 A:middle
with others, to describe your

00:33:06.816 --> 00:33:07.646 A:middle
app's behavior.

00:33:08.396 --> 00:33:10.836 A:middle
Now starting watchOS 4, we are

00:33:11.466 --> 00:33:13.476 A:middle
exposing more APIs in order to

00:33:13.476 --> 00:33:14.896 A:middle
do recording.

00:33:15.176 --> 00:33:17.066 A:middle
That is, we are making AVAudio

00:33:17.096 --> 00:33:19.576 A:middle
Recorder and AVAudio Input Node

00:33:19.576 --> 00:33:21.386 A:middle
and AVAudio Engine, available.

00:33:22.836 --> 00:33:24.186 A:middle
And with these, comes the

00:33:24.186 --> 00:33:25.646 A:middle
AVAudio recording permissions,

00:33:25.816 --> 00:33:27.146 A:middle
through which an app can

00:33:27.146 --> 00:33:28.786 A:middle
[inaudible] the user permission

00:33:28.786 --> 00:33:29.286 A:middle
to record.

00:33:30.126 --> 00:33:31.656 A:middle
Now, [inaudible] to this you

00:33:31.656 --> 00:33:33.136 A:middle
could use the watch [inaudible]

00:33:33.396 --> 00:33:35.186 A:middle
framework to do the recording,

00:33:35.436 --> 00:33:37.106 A:middle
using the Apple UI.

00:33:37.296 --> 00:33:39.786 A:middle
But now, with these APIs, you

00:33:39.786 --> 00:33:42.406 A:middle
could do the recording with your

00:33:42.406 --> 00:33:43.226 A:middle
own UI.

00:33:44.306 --> 00:33:45.946 A:middle
With AVAudio Recorder, you could

00:33:45.946 --> 00:33:47.656 A:middle
record to a file, or if you

00:33:47.656 --> 00:33:49.046 A:middle
wanted to get access to the

00:33:49.046 --> 00:33:50.256 A:middle
microphone [inaudible] directly,

00:33:50.436 --> 00:33:51.996 A:middle
you could use the AVAudio Input

00:33:51.996 --> 00:33:53.916 A:middle
Node, and also optionally, write

00:33:53.916 --> 00:33:54.506 A:middle
it to a file.

00:33:55.546 --> 00:33:57.056 A:middle
And here are the formats that

00:33:57.056 --> 00:33:58.976 A:middle
are supported on watchOS, both

00:33:58.976 --> 00:34:00.376 A:middle
for playback and recording.

00:34:01.576 --> 00:34:03.816 A:middle
A last note on the recording

00:34:03.816 --> 00:34:04.346 A:middle
policies.

00:34:05.276 --> 00:34:06.966 A:middle
The recording can start only

00:34:06.966 --> 00:34:08.256 A:middle
when the app is in foreground.

00:34:08.846 --> 00:34:10.246 A:middle
But it is allowed to continue

00:34:10.246 --> 00:34:12.326 A:middle
recording in the background, but

00:34:12.326 --> 00:34:13.946 A:middle
-- and the right microphone icon

00:34:13.996 --> 00:34:15.676 A:middle
will be displayed at the top so

00:34:15.676 --> 00:34:17.076 A:middle
that the user is aware of it.

00:34:18.366 --> 00:34:20.256 A:middle
And recording in background is

00:34:20.526 --> 00:34:22.276 A:middle
CPU limited, similar to the

00:34:22.856 --> 00:34:23.936 A:middle
[inaudible] sessions and you can

00:34:23.936 --> 00:34:25.696 A:middle
refer to this URL for more

00:34:25.696 --> 00:34:26.136 A:middle
details.

00:34:28.006 --> 00:34:29.476 A:middle
Now, let's move over to the

00:34:29.476 --> 00:34:31.246 A:middle
Audio Toolbox world and look at

00:34:31.246 --> 00:34:33.086 A:middle
the enhancements in AUAudio Unit

00:34:33.316 --> 00:34:34.706 A:middle
and audio formats.

00:34:35.236 --> 00:34:38.516 A:middle
We have two main enhancements in

00:34:38.516 --> 00:34:39.246 A:middle
AUAudio Unit.

00:34:40.126 --> 00:34:41.466 A:middle
And at the end of this section,

00:34:41.496 --> 00:34:42.996 A:middle
we will also show you a demo

00:34:43.196 --> 00:34:44.726 A:middle
with those two new features in

00:34:47.826 --> 00:34:47.986 A:middle
action.

00:34:48.166 --> 00:34:49.956 A:middle
Now, Audio Unit host

00:34:49.956 --> 00:34:51.646 A:middle
applications choose various

00:34:51.646 --> 00:34:53.656 A:middle
strategies in order to recommend

00:34:53.766 --> 00:34:56.116 A:middle
how to display the UI for AU.

00:34:56.426 --> 00:34:58.816 A:middle
They can decide to say embed the

00:34:58.816 --> 00:35:01.696 A:middle
AU's UI in their own UI, or they

00:35:01.696 --> 00:35:03.076 A:middle
could present a full screen

00:35:03.076 --> 00:35:05.146 A:middle
separate UI for the AU.

00:35:06.106 --> 00:35:07.596 A:middle
Now, this presents mainly a

00:35:07.626 --> 00:35:08.726 A:middle
challenge on the [inaudible]

00:35:08.806 --> 00:35:10.706 A:middle
devices because currently, the

00:35:10.706 --> 00:35:13.006 A:middle
view sizes are not defined, and

00:35:13.006 --> 00:35:14.716 A:middle
the audio unit is expected to

00:35:14.716 --> 00:35:17.036 A:middle
adapt to any UI size that the

00:35:17.036 --> 00:35:18.656 A:middle
host has actually chosen.

00:35:19.856 --> 00:35:21.056 A:middle
In order to overcome this

00:35:21.056 --> 00:35:23.126 A:middle
limitation, we're now adding a

00:35:23.156 --> 00:35:25.506 A:middle
way in which the host and the AU

00:35:25.656 --> 00:35:27.076 A:middle
can negotiate with each other

00:35:27.506 --> 00:35:29.556 A:middle
and the AU can inform the host

00:35:29.846 --> 00:35:30.766 A:middle
about all the view

00:35:30.766 --> 00:35:32.186 A:middle
configurations that it actually

00:35:32.186 --> 00:35:32.746 A:middle
supports.

00:35:33.096 --> 00:35:34.906 A:middle
Now, let's see how this

00:35:35.256 --> 00:35:38.196 A:middle
negotiation can take place.

00:35:38.366 --> 00:35:41.336 A:middle
The host first compiles a list

00:35:41.336 --> 00:35:43.126 A:middle
of all the available view

00:35:43.126 --> 00:35:45.986 A:middle
configurations for the AU, and

00:35:45.986 --> 00:35:49.536 A:middle
then hands the audio over to the

00:35:49.536 --> 00:35:49.603 A:middle
AU.

00:35:50.006 --> 00:35:51.206 A:middle
The AU can then [inaudible]

00:35:51.206 --> 00:35:52.616 A:middle
through all these available

00:35:52.616 --> 00:35:54.376 A:middle
configurations, and then let the

00:35:54.376 --> 00:35:56.576 A:middle
host know about the

00:35:57.006 --> 00:35:58.326 A:middle
configuration that it actually

00:35:58.326 --> 00:35:58.876 A:middle
supports.

00:35:59.696 --> 00:36:01.466 A:middle
And then, the host can choose

00:36:01.466 --> 00:36:02.556 A:middle
one of the supported

00:36:02.596 --> 00:36:04.276 A:middle
configurations and then it will

00:36:04.276 --> 00:36:06.086 A:middle
let the AU know about the final

00:36:06.086 --> 00:36:07.266 A:middle
selected configuration.

00:36:08.416 --> 00:36:10.456 A:middle
Now, let's see a code example on

00:36:10.456 --> 00:36:12.216 A:middle
how this negotiation takes

00:36:12.216 --> 00:36:12.546 A:middle
place.

00:36:13.006 --> 00:36:14.616 A:middle
We'll first look at the audio

00:36:14.616 --> 00:36:15.996 A:middle
unit extension site.

00:36:16.596 --> 00:36:19.566 A:middle
The first thing the AU has to do

00:36:20.356 --> 00:36:22.236 A:middle
is to override the supported

00:36:22.236 --> 00:36:24.186 A:middle
view configuration method from

00:36:24.186 --> 00:36:24.846 A:middle
the base class.

00:36:25.516 --> 00:36:27.156 A:middle
And this is called by the host

00:36:27.446 --> 00:36:28.986 A:middle
with the list of all the

00:36:28.986 --> 00:36:31.016 A:middle
available configurations.

00:36:32.276 --> 00:36:34.526 A:middle
Then, the AU can iterate through

00:36:34.566 --> 00:36:36.566 A:middle
each of these configurations and

00:36:36.566 --> 00:36:38.426 A:middle
decide which ones it actually

00:36:38.426 --> 00:36:38.966 A:middle
supports.

00:36:39.466 --> 00:36:41.696 A:middle
Now, the configuration itself,

00:36:41.876 --> 00:36:43.806 A:middle
contains a width and a height,

00:36:44.066 --> 00:36:46.846 A:middle
which recommends the view size.

00:36:47.186 --> 00:36:48.906 A:middle
And also, it has a host test

00:36:48.906 --> 00:36:49.736 A:middle
controller flag.

00:36:50.636 --> 00:36:52.576 A:middle
And that flag indicates whether

00:36:52.576 --> 00:36:54.886 A:middle
or not the host is presenting

00:36:54.886 --> 00:36:56.716 A:middle
its own controller in this

00:36:56.716 --> 00:36:58.496 A:middle
particular view configuration.

00:36:59.006 --> 00:37:00.696 A:middle
So, depending on all these

00:37:00.696 --> 00:37:03.166 A:middle
factors, an AU can choose

00:37:03.246 --> 00:37:04.396 A:middle
whether it supports that

00:37:04.466 --> 00:37:05.536 A:middle
particular configuration.

00:37:06.826 --> 00:37:08.366 A:middle
Note that there is a wild card

00:37:08.366 --> 00:37:11.466 A:middle
configuration which is 0x0, and

00:37:11.466 --> 00:37:12.586 A:middle
that means -- and that

00:37:12.586 --> 00:37:14.976 A:middle
represents a full default size

00:37:15.296 --> 00:37:17.056 A:middle
that the AU can support.

00:37:17.696 --> 00:37:19.946 A:middle
And on macOS, this actually

00:37:19.946 --> 00:37:21.756 A:middle
translates to a separate,

00:37:21.916 --> 00:37:23.766 A:middle
resizable window -- full size,

00:37:23.766 --> 00:37:26.996 A:middle
resizable window, for the AU's

00:37:27.036 --> 00:37:27.296 A:middle
UI.

00:37:28.156 --> 00:37:31.576 A:middle
So, the AU has its own logic to

00:37:31.576 --> 00:37:32.966 A:middle
decide which configuration it

00:37:32.966 --> 00:37:34.796 A:middle
supports, and then finally, it

00:37:34.906 --> 00:37:36.656 A:middle
compares a list of the indices

00:37:37.036 --> 00:37:39.466 A:middle
corresponding to the ones that

00:37:39.466 --> 00:37:40.846 A:middle
it supports, and [inaudible]

00:37:40.876 --> 00:37:43.746 A:middle
this index set back to the host.

00:37:44.966 --> 00:37:46.866 A:middle
The last thing that the AU has

00:37:46.946 --> 00:37:49.266 A:middle
to do, is to override select

00:37:49.416 --> 00:37:51.116 A:middle
method, which is called by the

00:37:51.116 --> 00:37:53.086 A:middle
host with the configuration that

00:37:53.086 --> 00:37:55.206 A:middle
it has finally selected, and

00:37:55.206 --> 00:37:57.596 A:middle
then, the AU can let its view

00:37:57.596 --> 00:37:59.346 A:middle
controller know about the final

00:37:59.346 --> 00:38:00.566 A:middle
selected configuration.

00:38:02.166 --> 00:38:03.886 A:middle
Now, let's go to the host site

00:38:04.086 --> 00:38:06.266 A:middle
and see how the code looks like.

00:38:07.296 --> 00:38:10.566 A:middle
The host has to compile the list

00:38:10.566 --> 00:38:12.226 A:middle
of available configurations, and

00:38:12.226 --> 00:38:13.706 A:middle
in this example, it is saying

00:38:13.926 --> 00:38:15.826 A:middle
that it has a large and a small

00:38:15.826 --> 00:38:17.096 A:middle
configuration available.

00:38:17.716 --> 00:38:19.606 A:middle
And in the last configuration,

00:38:19.796 --> 00:38:21.316 A:middle
the host is saying it's not

00:38:21.506 --> 00:38:23.586 A:middle
presenting its controller, so

00:38:23.586 --> 00:38:25.246 A:middle
the host has controller flag as

00:38:25.346 --> 00:38:25.676 A:middle
false.

00:38:26.016 --> 00:38:27.326 A:middle
And in the small configuration,

00:38:27.536 --> 00:38:29.356 A:middle
the host does present its

00:38:29.356 --> 00:38:30.866 A:middle
controller, so the flag is true.

00:38:32.096 --> 00:38:34.526 A:middle
The host then calls the

00:38:34.526 --> 00:38:36.066 A:middle
supported view configurations

00:38:36.066 --> 00:38:38.626 A:middle
method on the AU, and provides

00:38:38.626 --> 00:38:40.496 A:middle
this list of configurations.

00:38:40.976 --> 00:38:42.556 A:middle
And depending on the return set

00:38:42.556 --> 00:38:44.556 A:middle
of indices, it goes ahead and

00:38:44.556 --> 00:38:45.596 A:middle
selects one of the

00:38:45.596 --> 00:38:46.416 A:middle
configurations.

00:38:46.656 --> 00:38:48.196 A:middle
And in this particular example,

00:38:48.396 --> 00:38:49.726 A:middle
the host is just toggling

00:38:49.866 --> 00:38:51.306 A:middle
between the large and the small

00:38:51.306 --> 00:38:51.986 A:middle
configuration.

00:38:52.456 --> 00:38:55.576 A:middle
So, that is end of the preferred

00:38:55.726 --> 00:38:57.286 A:middle
view configuration negotiation.

00:38:57.706 --> 00:38:59.086 A:middle
Now, let's see the second main

00:38:59.216 --> 00:39:01.596 A:middle
new feature we have, which is

00:39:01.596 --> 00:39:03.486 A:middle
the support for MIDI output in

00:39:03.486 --> 00:39:04.626 A:middle
an audio unit extension.

00:39:05.916 --> 00:39:07.966 A:middle
We have now support for an AU to

00:39:07.966 --> 00:39:10.186 A:middle
emit MIDI output synchronized

00:39:10.306 --> 00:39:11.376 A:middle
with its audio output.

00:39:12.056 --> 00:39:13.906 A:middle
And this mainly useful if the

00:39:13.906 --> 00:39:16.146 A:middle
host wants to record and edit

00:39:16.306 --> 00:39:17.926 A:middle
both the MIDI performance, as

00:39:17.926 --> 00:39:19.616 A:middle
well as the audio output, from

00:39:19.766 --> 00:39:20.686 A:middle
the AU.

00:39:20.996 --> 00:39:23.366 A:middle
So, the host installs a MIDI

00:39:23.366 --> 00:39:25.176 A:middle
output event block on the AU,

00:39:25.406 --> 00:39:26.876 A:middle
and the AU should call this

00:39:26.926 --> 00:39:29.326 A:middle
block every render cycle and

00:39:29.326 --> 00:39:31.176 A:middle
provide the MIDI output for that

00:39:31.236 --> 00:39:32.286 A:middle
particular render cycle.

00:39:34.596 --> 00:39:36.796 A:middle
We also have a couple of other

00:39:36.796 --> 00:39:37.896 A:middle
enhancements in the Audio

00:39:37.896 --> 00:39:38.836 A:middle
Toolbox framework.

00:39:39.136 --> 00:39:40.516 A:middle
The first one is related to a

00:39:40.516 --> 00:39:42.366 A:middle
privacy enhancement.

00:39:43.136 --> 00:39:46.346 A:middle
So, starting iOS 11 SDK, all the

00:39:46.346 --> 00:39:48.166 A:middle
audio unit extension host apps

00:39:48.746 --> 00:39:50.436 A:middle
will need the inter-app-audio

00:39:50.436 --> 00:39:51.966 A:middle
entitlement to be able to

00:39:51.966 --> 00:39:53.626 A:middle
communicate with the audio unit

00:39:53.626 --> 00:39:54.206 A:middle
extensions.

00:39:55.166 --> 00:39:57.546 A:middle
And we also have a new API for

00:39:57.936 --> 00:40:00.926 A:middle
an AU to publish a very

00:40:00.926 --> 00:40:03.076 A:middle
meaningful short name so that

00:40:03.076 --> 00:40:05.676 A:middle
the host say, can use this short

00:40:05.676 --> 00:40:07.356 A:middle
name if it has to display the

00:40:07.356 --> 00:40:10.286 A:middle
list of AU names in a space

00:40:10.286 --> 00:40:12.466 A:middle
constraint list.

00:40:13.826 --> 00:40:17.086 A:middle
So, that brings us to the end of

00:40:17.086 --> 00:40:18.386 A:middle
all the enhancements in Audio

00:40:18.386 --> 00:40:19.856 A:middle
Toolbox framework, and as

00:40:19.946 --> 00:40:23.116 A:middle
promised, we have a demo to show

00:40:23.116 --> 00:40:24.526 A:middle
these new features in action.

00:40:24.526 --> 00:40:26.286 A:middle
And I call upon Bela for that.

00:40:27.516 --> 00:40:33.076 A:middle
[ Applause ]

00:40:33.576 --> 00:40:38.106 A:middle
&gt;&gt; Thank you, Akshatha and good

00:40:38.106 --> 00:40:39.006 A:middle
afternoon everyone.

00:40:39.006 --> 00:40:40.716 A:middle
My name is Bela Balazs and I am

00:40:40.716 --> 00:40:43.746 A:middle
an engineer on the Core Audio

00:40:43.746 --> 00:40:44.436 A:middle
Team.

00:40:44.436 --> 00:40:47.086 A:middle
Today, we would like to show you

00:40:47.086 --> 00:40:48.956 A:middle
an application of our newly

00:40:48.956 --> 00:40:50.656 A:middle
introduced APIs.

00:40:51.116 --> 00:40:52.476 A:middle
For this purpose, we have

00:40:52.476 --> 00:40:54.226 A:middle
developed an example audio unit,

00:40:54.316 --> 00:40:55.276 A:middle
which has the following

00:40:55.276 --> 00:40:56.126 A:middle
capabilities.

00:40:57.156 --> 00:40:58.986 A:middle
It supports its preferred view

00:40:58.986 --> 00:41:00.346 A:middle
configuration with the Audio

00:41:00.346 --> 00:41:01.696 A:middle
Unit host application.

00:41:02.556 --> 00:41:03.836 A:middle
It supports multiple view

00:41:03.836 --> 00:41:05.806 A:middle
configurations, and it uses the

00:41:05.806 --> 00:41:09.286 A:middle
newly bridged MIDI output API in

00:41:09.286 --> 00:41:11.526 A:middle
order to pass on MIDI data to

00:41:11.526 --> 00:41:13.266 A:middle
the Audio Unit host application

00:41:13.266 --> 00:41:14.496 A:middle
for recording purposes.

00:41:15.746 --> 00:41:17.306 A:middle
So, here I have an upcoming

00:41:17.306 --> 00:41:18.506 A:middle
version of GarageBand.

00:41:19.286 --> 00:41:20.926 A:middle
And I have loaded my example

00:41:20.926 --> 00:41:22.106 A:middle
audio unit to a track.

00:41:22.756 --> 00:41:24.986 A:middle
Here you can see the custom view

00:41:24.986 --> 00:41:27.146 A:middle
of my audio unit, together with

00:41:27.146 --> 00:41:28.256 A:middle
the GarageBand keyboard.

00:41:28.676 --> 00:41:31.196 A:middle
In this reconfiguration, I rely

00:41:31.196 --> 00:41:32.576 A:middle
on the GarageBand keyboard to

00:41:32.576 --> 00:41:33.446 A:middle
play my instrument.

00:41:34.236 --> 00:41:35.776 A:middle
I have mapped out three drum

00:41:35.776 --> 00:41:36.936 A:middle
samples on the keyboard.

00:41:37.166 --> 00:41:39.296 A:middle
I have a kick, I have a snare,

00:41:39.826 --> 00:41:40.706 A:middle
and I have a high hat.

00:41:41.486 --> 00:41:43.236 A:middle
In addition to these, on the

00:41:43.236 --> 00:41:45.206 A:middle
view of my audio unit, I also

00:41:45.206 --> 00:41:46.796 A:middle
have a volume slider to control

00:41:46.796 --> 00:41:48.926 A:middle
the volume of these samples.

00:41:51.476 --> 00:41:53.756 A:middle
However, my audio unit also has

00:41:53.756 --> 00:41:55.526 A:middle
a different view configuration,

00:41:55.576 --> 00:41:57.246 A:middle
and I can switch to it using

00:41:57.246 --> 00:41:58.816 A:middle
this newly added button on the

00:41:58.816 --> 00:42:00.966 A:middle
right -- lower, right section of

00:42:00.966 --> 00:42:01.496 A:middle
the screen.

00:42:02.106 --> 00:42:04.086 A:middle
When I activate that button, I

00:42:04.086 --> 00:42:05.766 A:middle
get taken to the large view of

00:42:05.766 --> 00:42:07.556 A:middle
my audio unit and the GarageBand

00:42:07.556 --> 00:42:08.516 A:middle
keyboard disappears.

00:42:09.336 --> 00:42:11.226 A:middle
When I activate it again, I get

00:42:11.286 --> 00:42:12.786 A:middle
taken back to the small view of

00:42:12.786 --> 00:42:13.536 A:middle
my audio unit.

00:42:14.086 --> 00:42:15.416 A:middle
This is made possible by

00:42:15.416 --> 00:42:18.576 A:middle
GarageBand's publishing all the

00:42:18.576 --> 00:42:20.216 A:middle
available view configurations to

00:42:20.216 --> 00:42:22.706 A:middle
my audio unit, and my audio unit

00:42:22.706 --> 00:42:24.226 A:middle
goes through that list and marks

00:42:24.226 --> 00:42:25.846 A:middle
each of them as supported or

00:42:25.846 --> 00:42:27.786 A:middle
unsupported, and at the end of

00:42:27.786 --> 00:42:29.356 A:middle
this process, GarageBand knows

00:42:29.356 --> 00:42:30.936 A:middle
that my audio unit supports two

00:42:30.936 --> 00:42:33.076 A:middle
view configurations and it can

00:42:33.076 --> 00:42:34.096 A:middle
toggle between them.

00:42:35.176 --> 00:42:36.806 A:middle
In case my audio unit only

00:42:36.806 --> 00:42:37.766 A:middle
supported one view

00:42:37.766 --> 00:42:39.956 A:middle
configuration, then this button

00:42:39.956 --> 00:42:41.396 A:middle
could be hidden by GarageBand,

00:42:41.396 --> 00:42:42.846 A:middle
but my audio unit could still

00:42:42.846 --> 00:42:44.036 A:middle
take full advantage of the

00:42:44.036 --> 00:42:46.396 A:middle
negotiation process to negotiate

00:42:46.396 --> 00:42:48.446 A:middle
the preferred view configuration

00:42:48.446 --> 00:42:49.416 A:middle
for that one view.

00:42:50.226 --> 00:42:53.446 A:middle
In this small view, the host has

00:42:53.446 --> 00:42:55.276 A:middle
controller flag as set to true,

00:42:56.026 --> 00:42:57.286 A:middle
and that is why the GarageBand

00:42:57.286 --> 00:42:58.266 A:middle
keyboard is visible.

00:42:58.566 --> 00:42:59.596 A:middle
In the larger view

00:42:59.596 --> 00:43:01.056 A:middle
configuration, the GarageBand

00:43:01.056 --> 00:43:03.286 A:middle
keyboard is hidden because that

00:43:03.286 --> 00:43:04.636 A:middle
flag is set to false.

00:43:05.246 --> 00:43:06.696 A:middle
In this view configuration, my

00:43:06.696 --> 00:43:08.986 A:middle
audio unit has its own playing

00:43:08.986 --> 00:43:11.046 A:middle
surface, which I can use to play

00:43:11.046 --> 00:43:11.726 A:middle
my instrument.

00:43:12.066 --> 00:43:14.346 A:middle
I have a kick, a snare, and a

00:43:14.346 --> 00:43:14.826 A:middle
high hat.

00:43:15.986 --> 00:43:17.486 A:middle
And in addition to these three

00:43:17.486 --> 00:43:21.086 A:middle
buttons, I also have a new

00:43:21.086 --> 00:43:22.496 A:middle
button on the right-hand side

00:43:22.556 --> 00:43:23.716 A:middle
called Repeat Note.

00:43:23.986 --> 00:43:25.496 A:middle
And this allows me to repeat

00:43:25.496 --> 00:43:27.996 A:middle
each sample at the certain rate.

00:43:28.606 --> 00:43:30.126 A:middle
And I can set those rates

00:43:30.186 --> 00:43:31.516 A:middle
independently from each other

00:43:31.516 --> 00:43:32.486 A:middle
using the sliders.

00:43:33.436 --> 00:43:38.436 A:middle
And I can toggle each sample in

00:43:38.436 --> 00:43:39.556 A:middle
and out of the drum loop.

00:43:40.516 --> 00:43:50.776 A:middle
[ Drums playing ]

00:43:51.276 --> 00:43:52.976 A:middle
This allows me to easily

00:43:52.976 --> 00:43:54.326 A:middle
construct drum loops that

00:43:54.526 --> 00:43:56.306 A:middle
respect the tempo of my track.

00:43:57.726 --> 00:43:59.696 A:middle
So, let's use the MIDI output

00:43:59.696 --> 00:44:01.976 A:middle
API to record the output of this

00:44:01.976 --> 00:44:03.316 A:middle
audio unit extension.

00:44:04.046 --> 00:44:05.436 A:middle
I have the synchronized rates

00:44:05.436 --> 00:44:07.516 A:middle
button here, which sets my rates

00:44:07.516 --> 00:44:09.766 A:middle
to 110 BPM.

00:44:09.766 --> 00:44:11.806 A:middle
And first, I will record a kick,

00:44:11.936 --> 00:44:13.396 A:middle
snare drum loop.

00:44:13.396 --> 00:44:14.636 A:middle
And then when the recording

00:44:14.636 --> 00:44:16.406 A:middle
wraps around, I will add my high

00:44:16.406 --> 00:44:16.806 A:middle
hats.

00:44:17.236 --> 00:44:18.606 A:middle
This is made possible by

00:44:18.606 --> 00:44:20.376 A:middle
GarageBand's merge recording

00:44:20.376 --> 00:44:20.876 A:middle
feature.

00:44:21.656 --> 00:44:22.826 A:middle
So, let's do just that.

00:44:23.516 --> 00:44:26.556 A:middle
[ Drums playing ]

00:44:27.056 --> 00:44:28.686 A:middle
I will just record four bars of

00:44:28.866 --> 00:44:29.996 A:middle
that.

00:44:30.476 --> 00:44:36.626 A:middle
And then add my high hats.

00:44:37.516 --> 00:44:44.176 A:middle
[ Drums playing ]

00:44:44.676 --> 00:44:46.636 A:middle
My high hats have been added to

00:44:46.636 --> 00:44:47.326 A:middle
the recording.

00:44:47.906 --> 00:44:50.876 A:middle
And now we can go to the track

00:44:50.876 --> 00:44:52.086 A:middle
view and take a look at our

00:44:52.086 --> 00:44:53.236 A:middle
recorded media output.

00:44:54.136 --> 00:44:58.826 A:middle
And I can quantize the track.

00:44:59.516 --> 00:45:05.086 A:middle
And then we can play it back.

00:45:05.546 --> 00:45:09.076 A:middle
And we have the full MIDI

00:45:09.076 --> 00:45:10.426 A:middle
editing capabilities of

00:45:10.426 --> 00:45:12.096 A:middle
GarageBand at our disposal to

00:45:12.096 --> 00:45:13.476 A:middle
construct our drum track.

00:45:14.366 --> 00:45:15.716 A:middle
And this concludes my demo.

00:45:15.766 --> 00:45:16.656 A:middle
Thank you very much for your

00:45:16.656 --> 00:45:17.066 A:middle
attention.

00:45:17.066 --> 00:45:18.176 A:middle
And I would like to hand it back

00:45:18.176 --> 00:45:19.276 A:middle
to my colleague, Akshatha.

00:45:19.846 --> 00:45:20.156 A:middle
Thank you.

00:45:21.516 --> 00:45:25.516 A:middle
[ Applause ]

00:45:26.016 --> 00:45:29.696 A:middle
&gt;&gt; Thank you, Bela.

00:45:29.886 --> 00:45:31.596 A:middle
So, now, onto the last set of

00:45:31.726 --> 00:45:32.686 A:middle
enhancements in the Audio

00:45:32.686 --> 00:45:34.246 A:middle
Toolbox framework, related to

00:45:34.246 --> 00:45:35.206 A:middle
the audio formats.

00:45:36.626 --> 00:45:38.396 A:middle
We now have support for two of

00:45:38.656 --> 00:45:40.286 A:middle
the popular formats, namely the

00:45:40.286 --> 00:45:42.056 A:middle
FLAC and the Opus format.

00:45:42.056 --> 00:45:44.706 A:middle
On the FLAC side, we have the

00:45:44.756 --> 00:45:46.566 A:middle
codec, file, and the streaming

00:45:46.566 --> 00:45:48.496 A:middle
support, and for Opus, we have

00:45:48.496 --> 00:45:49.976 A:middle
the codec, and the file I/O

00:45:49.976 --> 00:45:51.416 A:middle
support using the code audio

00:45:51.416 --> 00:45:52.266 A:middle
format container.

00:45:54.376 --> 00:45:56.336 A:middle
From audio formats to spatial

00:45:56.336 --> 00:45:58.346 A:middle
audio formats, those of you who

00:45:58.346 --> 00:45:59.326 A:middle
are interested in [inaudible]

00:45:59.326 --> 00:46:02.096 A:middle
audio, AR, and VR applications,

00:46:02.416 --> 00:46:04.026 A:middle
you may be happy to know that we

00:46:04.026 --> 00:46:05.456 A:middle
now support ambisonics.

00:46:06.106 --> 00:46:07.886 A:middle
And for those of you who may not

00:46:07.886 --> 00:46:09.016 A:middle
be really familiar with

00:46:09.016 --> 00:46:11.586 A:middle
ambisonics like me, ambisonics

00:46:11.686 --> 00:46:14.006 A:middle
is also a multichannel format,

00:46:14.536 --> 00:46:16.256 A:middle
but the difference is that the

00:46:16.256 --> 00:46:18.006 A:middle
traditional surround formats

00:46:18.006 --> 00:46:20.306 A:middle
that we know of, for example 5.1

00:46:20.466 --> 00:46:22.946 A:middle
or 7.1, have the signals that

00:46:23.086 --> 00:46:24.606 A:middle
actually represent the speaker

00:46:24.606 --> 00:46:24.986 A:middle
layout.

00:46:25.596 --> 00:46:28.466 A:middle
Whereas ambisonics provide a

00:46:28.606 --> 00:46:29.696 A:middle
speaker independent

00:46:29.696 --> 00:46:31.176 A:middle
representation of the sound

00:46:32.226 --> 00:46:32.536 A:middle
feed.

00:46:32.536 --> 00:46:34.236 A:middle
So, they are by nature,

00:46:34.346 --> 00:46:35.036 A:middle
[inaudible] from the playback

00:46:35.036 --> 00:46:35.486 A:middle
system.

00:46:36.156 --> 00:46:38.256 A:middle
And at the time of rendering, is

00:46:38.256 --> 00:46:40.076 A:middle
when they can be decoded to the

00:46:40.076 --> 00:46:41.686 A:middle
listener's speaker setup.

00:46:42.326 --> 00:46:43.306 A:middle
And this provides more

00:46:43.306 --> 00:46:44.746 A:middle
flexibility for the content

00:46:44.746 --> 00:46:45.256 A:middle
producers.

00:46:46.436 --> 00:46:48.166 A:middle
We now support the first order

00:46:48.166 --> 00:46:49.856 A:middle
ambisonics which is called the

00:46:49.856 --> 00:46:52.646 A:middle
B-format and higher ordered

00:46:52.646 --> 00:46:55.416 A:middle
ambisonics with the Order N, can

00:46:55.416 --> 00:46:57.696 A:middle
range from 1 through 254.

00:46:58.076 --> 00:46:59.896 A:middle
And depending on the order, the

00:47:00.036 --> 00:47:02.276 A:middle
channels itself can go from zero

00:47:02.516 --> 00:47:03.966 A:middle
-- the ambisonic channel number

00:47:04.046 --> 00:47:06.986 A:middle
can go from zero to 65,024.

00:47:07.826 --> 00:47:09.266 A:middle
And we support two of the

00:47:09.526 --> 00:47:11.576 A:middle
popular normalized streams,

00:47:12.066 --> 00:47:13.966 A:middle
namely the SN3D and the N3D

00:47:13.966 --> 00:47:16.336 A:middle
streams, and we support decoding

00:47:16.336 --> 00:47:19.716 A:middle
ambisonics to any arbitrary

00:47:19.876 --> 00:47:21.576 A:middle
speaker layout, and conversion

00:47:21.576 --> 00:47:23.276 A:middle
between the B-format and these

00:47:23.276 --> 00:47:24.076 A:middle
normalized streams.

00:47:24.696 --> 00:47:28.906 A:middle
The last enhancement is on the

00:47:28.906 --> 00:47:30.146 A:middle
AU Spatial Mixer side.

00:47:30.516 --> 00:47:32.306 A:middle
So, this is an Apple built-in

00:47:32.556 --> 00:47:34.716 A:middle
spatial mixer, which is used for

00:47:34.716 --> 00:47:36.236 A:middle
3D audio spatialization.

00:47:37.006 --> 00:47:39.216 A:middle
And the AVAudio Environment

00:47:39.216 --> 00:47:40.636 A:middle
Node, which is a node in the

00:47:40.636 --> 00:47:42.656 A:middle
AVAudio Engine, also uses the

00:47:42.656 --> 00:47:44.266 A:middle
Spatial Mixer underneath.

00:47:44.856 --> 00:47:47.046 A:middle
And we now have a new rendering

00:47:47.046 --> 00:47:48.826 A:middle
algorithm in this Spatial Mixer,

00:47:49.086 --> 00:47:52.136 A:middle
called HRTFHQ, high quality.

00:47:52.546 --> 00:47:54.236 A:middle
And this differs from the

00:47:54.236 --> 00:47:56.946 A:middle
current existing HRTF algorithm

00:47:57.176 --> 00:47:58.256 A:middle
in the sense that it has a

00:47:58.256 --> 00:47:59.996 A:middle
better frequency response and

00:47:59.996 --> 00:48:01.646 A:middle
better localization of sources

00:48:01.646 --> 00:48:02.566 A:middle
in the 3D space.

00:48:03.816 --> 00:48:05.056 A:middle
So, that concludes all the

00:48:05.056 --> 00:48:06.366 A:middle
enhancements in the Audio

00:48:06.366 --> 00:48:08.266 A:middle
Toolbox framework and now, I

00:48:08.266 --> 00:48:09.996 A:middle
hand it over to Torrey to take

00:48:09.996 --> 00:48:11.666 A:middle
it away from here, and give you

00:48:11.666 --> 00:48:14.016 A:middle
an update on inter-device audio

00:48:14.386 --> 00:48:14.646 A:middle
mode.

00:48:15.516 --> 00:48:20.066 A:middle
[ Applause ]

00:48:20.566 --> 00:48:21.396 A:middle
&gt;&gt; Thank you, Akshatha.

00:48:21.496 --> 00:48:23.236 A:middle
I am Torrey Holbrook Walker, and

00:48:23.236 --> 00:48:24.456 A:middle
I'm going to take you home today

00:48:24.456 --> 00:48:26.236 A:middle
with inter-device audio mode, or

00:48:26.236 --> 00:48:27.326 A:middle
if you want to be cool, you can

00:48:27.326 --> 00:48:28.776 A:middle
just say IDAM for short.

00:48:29.236 --> 00:48:30.386 A:middle
And you remember IDAM.

00:48:30.596 --> 00:48:32.356 A:middle
You take your iOS device.

00:48:32.356 --> 00:48:33.326 A:middle
You plug it into your Mac.

00:48:33.326 --> 00:48:35.006 A:middle
You open up Audio MIDI setup and

00:48:35.006 --> 00:48:36.216 A:middle
then it shows right up there in

00:48:36.216 --> 00:48:38.096 A:middle
the Audio Device Window, you can

00:48:38.136 --> 00:48:38.986 A:middle
-- there's a button next to it

00:48:38.986 --> 00:48:39.656 A:middle
that says Enable.

00:48:39.656 --> 00:48:41.076 A:middle
And if you click it, boom,

00:48:41.266 --> 00:48:42.526 A:middle
you've immediately got the

00:48:42.526 --> 00:48:44.176 A:middle
capability to record audio

00:48:44.176 --> 00:48:46.056 A:middle
digitally over the USB lightning

00:48:46.056 --> 00:48:47.226 A:middle
cable that came with the device,

00:48:47.636 --> 00:48:49.586 A:middle
and it looks just like a USB

00:48:49.586 --> 00:48:51.576 A:middle
audio input to the Mac host.

00:48:51.576 --> 00:48:53.316 A:middle
So, it uses the same driver, the

00:48:53.316 --> 00:48:54.466 A:middle
same low latency driver, that's

00:48:54.466 --> 00:48:56.506 A:middle
used on MacOS 4, class-compliant

00:48:56.506 --> 00:48:57.266 A:middle
audio devices.

00:48:57.586 --> 00:48:58.936 A:middle
And you've been able to do this

00:48:58.936 --> 00:49:01.566 A:middle
since El Capitan and iOS 9.

00:49:01.956 --> 00:49:03.476 A:middle
Well, today we would like to

00:49:03.476 --> 00:49:06.046 A:middle
wave a fond farewell to IDAM.

00:49:06.106 --> 00:49:07.936 A:middle
So, wave goodbye IDAM.

00:49:07.936 --> 00:49:08.966 A:middle
Goodbye IDAM.

00:49:09.436 --> 00:49:10.736 A:middle
And while you're waving, say

00:49:10.736 --> 00:49:12.676 A:middle
hello to IDAM, Inter Device

00:49:12.676 --> 00:49:13.646 A:middle
Audio and MIDI.

00:49:14.386 --> 00:49:15.936 A:middle
So, this year, we are adding

00:49:16.046 --> 00:49:18.366 A:middle
MIDI to IDAM configuration, and

00:49:18.366 --> 00:49:19.956 A:middle
that will allow you to send and

00:49:19.956 --> 00:49:21.936 A:middle
receive your musical instrument

00:49:21.936 --> 00:49:23.986 A:middle
data to your iOS device using

00:49:23.986 --> 00:49:25.296 A:middle
the same cable that came with

00:49:25.296 --> 00:49:25.846 A:middle
the device.

00:49:26.206 --> 00:49:28.016 A:middle
It's class-compliant once again,

00:49:28.276 --> 00:49:31.266 A:middle
so on the iOS side, you will see

00:49:31.386 --> 00:49:33.086 A:middle
a MIDI source and destination

00:49:33.086 --> 00:49:34.046 A:middle
representing the Mac.

00:49:34.046 --> 00:49:35.266 A:middle
On the Mac, you will see a

00:49:35.266 --> 00:49:36.216 A:middle
source and destination

00:49:36.216 --> 00:49:37.766 A:middle
representing your iOS device.

00:49:38.436 --> 00:49:40.806 A:middle
Now, this will require iOS 11,

00:49:40.806 --> 00:49:42.706 A:middle
but you can do it as far back as

00:49:42.706 --> 00:49:44.466 A:middle
MacOS El Capitan or later,

00:49:44.506 --> 00:49:45.616 A:middle
because it's a class-compliant

00:49:45.616 --> 00:49:46.316 A:middle
implementation.

00:49:46.846 --> 00:49:47.546 A:middle
And you don't have to do

00:49:47.546 --> 00:49:48.746 A:middle
anything special to get MIDI.

00:49:48.746 --> 00:49:49.446 A:middle
You're going to get it

00:49:49.446 --> 00:49:51.106 A:middle
automatically anytime you enter

00:49:51.106 --> 00:49:52.286 A:middle
the item configuration by

00:49:52.286 --> 00:49:53.036 A:middle
clicking Enable.

00:49:53.036 --> 00:49:54.466 A:middle
Do you need to do anything to

00:49:54.466 --> 00:49:55.986 A:middle
your app to support that?

00:49:55.986 --> 00:49:57.256 A:middle
No. It will just work if it

00:49:57.256 --> 00:49:58.076 A:middle
works with MIDI.

00:49:59.006 --> 00:50:00.376 A:middle
So, while you're in the IDAM

00:50:00.376 --> 00:50:01.786 A:middle
configuration, your device will

00:50:01.786 --> 00:50:03.526 A:middle
be able to charge and sync, but

00:50:03.526 --> 00:50:04.916 A:middle
you will temporarily lose the

00:50:04.916 --> 00:50:06.536 A:middle
ability to photo import and

00:50:06.536 --> 00:50:06.836 A:middle
tether.

00:50:07.076 --> 00:50:07.986 A:middle
You can get that back by

00:50:07.986 --> 00:50:09.276 A:middle
clicking the Disable button or

00:50:09.276 --> 00:50:12.006 A:middle
hot plugging the device on your

00:50:12.006 --> 00:50:12.356 A:middle
Mac.

00:50:12.356 --> 00:50:13.796 A:middle
The input, the audio input, side

00:50:13.796 --> 00:50:15.066 A:middle
of this can be aggregated, so if

00:50:15.066 --> 00:50:16.616 A:middle
you've got multiple iOS devices,

00:50:16.616 --> 00:50:18.776 A:middle
like I do, say, your iPhone and

00:50:18.776 --> 00:50:20.286 A:middle
your iPad and your kid's iPad,

00:50:20.606 --> 00:50:22.946 A:middle
you could say enable IDAM

00:50:22.946 --> 00:50:23.966 A:middle
configuration on all three of

00:50:23.966 --> 00:50:25.256 A:middle
these and aggregate them into a

00:50:25.256 --> 00:50:27.156 A:middle
single, six-channel audio input

00:50:27.156 --> 00:50:28.386 A:middle
device that your digital audio

00:50:28.386 --> 00:50:28.976 A:middle
workstation can see.

00:50:29.106 --> 00:50:30.996 A:middle
And because the MIDI

00:50:30.996 --> 00:50:32.336 A:middle
communication is bidirectional,

00:50:32.626 --> 00:50:34.636 A:middle
you can use it as -- you could

00:50:34.636 --> 00:50:37.636 A:middle
say for example, "Send MIDI to a

00:50:37.636 --> 00:50:39.796 A:middle
synthesizer application," and

00:50:39.796 --> 00:50:41.136 A:middle
record the audio back from it.

00:50:41.456 --> 00:50:43.056 A:middle
Or you could just design a MIDI

00:50:43.056 --> 00:50:44.476 A:middle
controller application for an

00:50:44.476 --> 00:50:45.626 A:middle
iPad, that magical piece of

00:50:45.626 --> 00:50:47.176 A:middle
glass, and you could use that to

00:50:47.176 --> 00:50:47.926 A:middle
control your [inaudible].

00:50:48.396 --> 00:50:50.106 A:middle
But talk is cheap, and demos pay

00:50:50.106 --> 00:50:50.566 A:middle
the bills.

00:50:50.856 --> 00:50:53.906 A:middle
So, let's see this in action.

00:50:54.496 --> 00:50:56.186 A:middle
So, before I actually bring up

00:50:56.186 --> 00:50:57.816 A:middle
my demo machine here, I want to

00:50:57.816 --> 00:51:00.006 A:middle
show you the application that

00:51:00.006 --> 00:51:00.946 A:middle
I'm going to use here.

00:51:02.306 --> 00:51:04.576 A:middle
And it is called Feud Machine.

00:51:05.066 --> 00:51:07.296 A:middle
So, I've got Feud Machine open

00:51:07.296 --> 00:51:07.516 A:middle
here.

00:51:07.626 --> 00:51:10.156 A:middle
And on Feud Machine, this is a

00:51:10.156 --> 00:51:12.026 A:middle
multi-playhead MIDI sequencer.

00:51:12.376 --> 00:51:13.416 A:middle
So, that means that you can

00:51:13.416 --> 00:51:15.726 A:middle
actually use one MIDI sequence

00:51:15.766 --> 00:51:17.216 A:middle
and use different playheads,

00:51:17.506 --> 00:51:18.596 A:middle
perhaps moving at different

00:51:18.596 --> 00:51:20.646 A:middle
times, in different directions,

00:51:21.046 --> 00:51:23.136 A:middle
and use that to create a complex

00:51:23.266 --> 00:51:26.026 A:middle
arpeggio using phasing and a

00:51:26.026 --> 00:51:26.886 A:middle
timing relationship.

00:51:27.286 --> 00:51:28.886 A:middle
So, I'm just going to play this

00:51:28.886 --> 00:51:29.506 A:middle
pattern here.

00:51:29.606 --> 00:51:31.516 A:middle
And there are a lot of

00:51:31.516 --> 00:51:33.816 A:middle
playheads.

00:51:33.816 --> 00:51:36.026 A:middle
I'll just stop some of them.

00:51:36.026 --> 00:51:40.206 A:middle
So, this is just one.

00:51:40.206 --> 00:51:43.126 A:middle
I'll add another.

00:51:43.126 --> 00:51:44.666 A:middle
Add another.

00:51:44.666 --> 00:51:45.096 A:middle
Add another.

00:51:45.366 --> 00:51:46.366 A:middle
As you see, we can create

00:51:46.366 --> 00:51:48.086 A:middle
arpeggios very easily this way.

00:51:48.646 --> 00:51:49.556 A:middle
So, there are other patterns

00:51:49.556 --> 00:51:50.456 A:middle
that I could use.

00:51:50.646 --> 00:51:52.186 A:middle
For example, this one's called

00:51:52.186 --> 00:51:52.436 A:middle
"Dotted".

00:51:52.436 --> 00:51:56.206 A:middle
This one's "Triplet."

00:51:56.206 --> 00:51:59.156 A:middle
But we'll still with this one,

00:51:59.156 --> 00:52:00.666 A:middle
and we're going to use this

00:52:00.776 --> 00:52:02.756 A:middle
actually to control a project

00:52:02.756 --> 00:52:04.016 A:middle
that we're working on in Logic.

00:52:04.366 --> 00:52:05.356 A:middle
So, now, I'll move over to my

00:52:05.356 --> 00:52:06.056 A:middle
demo machine.

00:52:06.786 --> 00:52:08.036 A:middle
I'm going to click Enable here.

00:52:08.856 --> 00:52:11.136 A:middle
And I'll see it come up as a USB

00:52:11.136 --> 00:52:12.386 A:middle
audio input, and if I look at

00:52:12.386 --> 00:52:14.186 A:middle
the MIDI studio window, I'll

00:52:14.186 --> 00:52:16.116 A:middle
also see that it shows up here

00:52:16.116 --> 00:52:17.556 A:middle
as a MIDI source and destination

00:52:17.556 --> 00:52:18.516 A:middle
that I can use in Logic.

00:52:18.946 --> 00:52:20.136 A:middle
So, if I launch a project that

00:52:20.136 --> 00:52:21.846 A:middle
I've been working on here -- now

00:52:26.156 --> 00:52:28.016 A:middle
this is a short, four-bar loop

00:52:28.016 --> 00:52:29.436 A:middle
that I'm working on for a gaming

00:52:29.436 --> 00:52:30.246 A:middle
scoring screen.

00:52:30.246 --> 00:52:32.706 A:middle
So, after this video game level

00:52:32.706 --> 00:52:34.386 A:middle
is completed, the player can

00:52:34.386 --> 00:52:35.576 A:middle
look at their results and they

00:52:35.576 --> 00:52:36.626 A:middle
will be listening to this loop.

00:52:37.296 --> 00:52:39.496 A:middle
And the loop right now, before

00:52:39.496 --> 00:52:40.426 A:middle
I've added anything to it,

00:52:40.426 --> 00:52:40.976 A:middle
sounds like this.

00:52:41.516 --> 00:52:51.546 A:middle
[ Music ]

00:52:52.046 --> 00:52:54.316 A:middle
Now, I want to add the arpeggio

00:52:54.316 --> 00:52:55.286 A:middle
part over this.

00:52:55.596 --> 00:52:56.566 A:middle
So, what I'm going to do is I'm

00:52:56.566 --> 00:52:57.526 A:middle
just going to double-click here

00:52:57.526 --> 00:52:58.466 A:middle
to add another track.

00:52:58.466 --> 00:53:00.796 A:middle
I'm going to choose an arpeggio,

00:53:01.686 --> 00:53:03.296 A:middle
maybe something like a square.

00:53:06.356 --> 00:53:07.126 A:middle
There we go.

00:53:07.526 --> 00:53:09.236 A:middle
I'll do percussive squares here.

00:53:09.316 --> 00:53:10.456 A:middle
And in the channel strip, you

00:53:10.456 --> 00:53:11.696 A:middle
can actually see an arpeggiator.

00:53:11.696 --> 00:53:12.646 A:middle
I'm not going to need that

00:53:12.646 --> 00:53:13.676 A:middle
because I'm going to play this

00:53:13.676 --> 00:53:14.466 A:middle
with Feud Machine.

00:53:14.936 --> 00:53:17.596 A:middle
So, if I record enable this, and

00:53:17.596 --> 00:53:20.276 A:middle
I arm my sequence here, I'll be

00:53:20.276 --> 00:53:23.096 A:middle
able to hear Feud Machine play

00:53:23.206 --> 00:53:25.296 A:middle
the soft synth here in Logic.

00:53:26.026 --> 00:53:29.856 A:middle
So, I'll solo that.

00:53:29.976 --> 00:53:31.516 A:middle
This is all four playheads

00:53:31.516 --> 00:53:33.016 A:middle
moving at the same time.

00:53:33.016 --> 00:53:34.136 A:middle
I could turn them off.

00:53:34.196 --> 00:53:35.616 A:middle
I could just have one playhead

00:53:35.616 --> 00:53:37.526 A:middle
if I wanted to.

00:53:37.606 --> 00:53:39.156 A:middle
Or as many as all four.

00:53:39.156 --> 00:53:40.636 A:middle
So, I'm going to record this

00:53:40.636 --> 00:53:42.676 A:middle
into my track, and we'll see

00:53:42.676 --> 00:53:44.276 A:middle
what that sounds like in

00:53:44.276 --> 00:53:45.056 A:middle
context.

00:53:45.596 --> 00:53:52.796 A:middle
Oops, sorry about that.

00:53:52.796 --> 00:53:55.946 A:middle
I have to record arm here and

00:53:56.636 --> 00:53:56.866 A:middle
play.

00:53:57.516 --> 00:54:06.546 A:middle
[ Music ]

00:54:07.046 --> 00:54:11.286 A:middle
Okay, so I've recorded my

00:54:11.286 --> 00:54:14.266 A:middle
automation here, and I can use

00:54:14.266 --> 00:54:15.846 A:middle
this automation and I can

00:54:16.006 --> 00:54:19.246 A:middle
playback from the iPad here.

00:54:19.246 --> 00:54:20.096 A:middle
So, if I listen to this in

00:54:20.096 --> 00:54:21.336 A:middle
context, it sounds like this.

00:54:21.406 --> 00:54:26.466 A:middle
So, now I've got MIDI going -- a

00:54:26.466 --> 00:54:28.136 A:middle
MIDI start command going to Feud

00:54:28.136 --> 00:54:28.576 A:middle
Machine.

00:54:28.576 --> 00:54:30.136 A:middle
Feud Machine's playing our soft

00:54:30.136 --> 00:54:30.926 A:middle
synth here.

00:54:30.996 --> 00:54:32.506 A:middle
And I've got some automation

00:54:32.506 --> 00:54:34.446 A:middle
here for the recording.

00:54:34.446 --> 00:54:37.116 A:middle
And that concludes my demo for

00:54:37.116 --> 00:54:39.546 A:middle
MIDI over IDAM configuration.

00:54:40.666 --> 00:54:41.886 A:middle
Let's head back to the slides.

00:54:42.516 --> 00:54:46.216 A:middle
[ Applause ]

00:54:46.716 --> 00:54:47.736 A:middle
Okay, we've talked about a lot

00:54:47.736 --> 00:54:48.356 A:middle
of things today.

00:54:48.356 --> 00:54:49.806 A:middle
We've talked about enhancements

00:54:49.806 --> 00:54:51.046 A:middle
to AVAudio Engine, including

00:54:51.046 --> 00:54:52.226 A:middle
Manual Rendering which you can

00:54:52.226 --> 00:54:53.706 A:middle
now do offline, or you can do

00:54:53.706 --> 00:54:54.246 A:middle
real-time.

00:54:54.726 --> 00:54:55.866 A:middle
There's AirPlay 2 support.

00:54:55.866 --> 00:54:57.096 A:middle
There'll be an entirely other

00:54:57.096 --> 00:54:58.876 A:middle
session on AirPlay 2 down the

00:54:58.876 --> 00:55:00.226 A:middle
road in the conference.

00:55:00.226 --> 00:55:01.306 A:middle
Please make sure to check that

00:55:01.306 --> 00:55:02.176 A:middle
out if you're interested.

00:55:02.376 --> 00:55:04.506 A:middle
Watch OS 4, you can now record.

00:55:04.506 --> 00:55:05.236 A:middle
We've talked about the

00:55:05.236 --> 00:55:07.036 A:middle
capabilities and the limitations

00:55:07.036 --> 00:55:08.506 A:middle
and policies regarding that.

00:55:08.506 --> 00:55:09.956 A:middle
For AUAudio Units, you can now

00:55:09.956 --> 00:55:10.786 A:middle
negotiate your view

00:55:10.786 --> 00:55:12.076 A:middle
configurations and you can also

00:55:12.076 --> 00:55:13.576 A:middle
synchronize your MIDI output

00:55:13.576 --> 00:55:15.186 A:middle
with your audio output for your

00:55:15.186 --> 00:55:15.253 A:middle
AU.

00:55:15.253 --> 00:55:16.396 A:middle
We've talked about some other

00:55:16.396 --> 00:55:18.996 A:middle
audio enhancements including new

00:55:18.996 --> 00:55:20.906 A:middle
supported formats, ambisonics,

00:55:20.906 --> 00:55:22.496 A:middle
head related transfer functions,

00:55:22.826 --> 00:55:24.136 A:middle
and we wrapped up with talking

00:55:24.136 --> 00:55:25.816 A:middle
about IDAM, which now stands for

00:55:25.816 --> 00:55:27.176 A:middle
Inter Device Audio and MIDI.

00:55:27.746 --> 00:55:29.536 A:middle
The central URL for information

00:55:29.536 --> 00:55:31.646 A:middle
regarding this particular talk

00:55:31.646 --> 00:55:32.146 A:middle
is here.

00:55:32.726 --> 00:55:34.696 A:middle
And if you're interested in

00:55:34.696 --> 00:55:37.206 A:middle
audio, you may also be

00:55:37.206 --> 00:55:40.006 A:middle
interested in these related

00:55:40.006 --> 00:55:41.586 A:middle
sessions later on in the week.

00:55:42.116 --> 00:55:44.636 A:middle
We thank you very much for your

00:55:44.636 --> 00:55:45.806 A:middle
time and attention, and have a

00:55:45.806 --> 00:55:46.976 A:middle
fantastic conference.

00:55:47.516 --> 00:55:51.500 A:middle
[ Applause ]