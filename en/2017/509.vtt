WEBVTT

00:00:25.076 --> 00:00:27.016 A:middle
&gt;&gt; Hello, good afternoon and

00:00:27.016 --> 00:00:28.686 A:middle
welcome to session 509,

00:00:29.026 --> 00:00:30.836 A:middle
Introducing AirPlay 2 Unlocking

00:00:30.836 --> 00:00:31.656 A:middle
Multi-Room Audio.

00:00:32.196 --> 00:00:33.886 A:middle
My name is David Saracino, I'm a

00:00:33.886 --> 00:00:34.666 A:middle
member of the AirPlay

00:00:34.666 --> 00:00:36.286 A:middle
engineering team, and I'm very

00:00:36.286 --> 00:00:37.286 A:middle
excited to be here this

00:00:37.286 --> 00:00:38.486 A:middle
afternoon to talk to you about

00:00:38.486 --> 00:00:39.576 A:middle
the many new features we've

00:00:39.576 --> 00:00:41.126 A:middle
added to audio to AirPlay over

00:00:41.126 --> 00:00:42.756 A:middle
the last year, and how you can

00:00:42.756 --> 00:00:45.006 A:middle
adopt them in your app.

00:00:45.396 --> 00:00:46.466 A:middle
But before we get into that

00:00:46.466 --> 00:00:47.686 A:middle
adoption and how you can build

00:00:47.686 --> 00:00:49.056 A:middle
this into your app, let's first

00:00:49.056 --> 00:00:50.926 A:middle
take a quick survey of AirPlay

00:00:51.226 --> 00:00:52.596 A:middle
today, and where we're taking it

00:00:52.596 --> 00:00:54.056 A:middle
with AirPlay 2.

00:00:54.636 --> 00:00:56.876 A:middle
So, with AirPlay today, you can

00:00:56.876 --> 00:00:58.616 A:middle
wirelessly send your myriad

00:00:58.616 --> 00:01:00.906 A:middle
screen, audio, or video content

00:01:01.196 --> 00:01:02.826 A:middle
from just about any Apple device

00:01:03.066 --> 00:01:04.556 A:middle
to an Apple TV or AirPlay

00:01:04.556 --> 00:01:04.956 A:middle
speaker.

00:01:06.296 --> 00:01:07.596 A:middle
Over the past year, we've added

00:01:07.596 --> 00:01:08.896 A:middle
so many features to the audio

00:01:08.896 --> 00:01:10.276 A:middle
domain that that's where we're

00:01:10.276 --> 00:01:11.166 A:middle
going to spend the majority of

00:01:11.166 --> 00:01:11.506 A:middle
our talk.

00:01:12.996 --> 00:01:14.146 A:middle
And because we've added so many

00:01:14.146 --> 00:01:15.296 A:middle
features to the audio domain

00:01:15.646 --> 00:01:17.326 A:middle
we're introducing this as a new

00:01:17.326 --> 00:01:18.826 A:middle
feature called AirPlay 2.

00:01:21.106 --> 00:01:22.216 A:middle
So, what is AirPlay 2?

00:01:22.216 --> 00:01:25.166 A:middle
Well with AirPlay 2, you can

00:01:25.166 --> 00:01:27.176 A:middle
still wirelessly send the audio

00:01:27.176 --> 00:01:28.726 A:middle
content from your app to an

00:01:28.726 --> 00:01:29.406 A:middle
AirPlay speaker.

00:01:29.926 --> 00:01:32.436 A:middle
But additionally, with AirPlay

00:01:32.436 --> 00:01:34.986 A:middle
2, you can send that content to

00:01:34.986 --> 00:01:37.346 A:middle
multiple AirPlay 2 speakers with

00:01:37.346 --> 00:01:40.546 A:middle
very tight sync.

00:01:40.726 --> 00:01:41.986 A:middle
Additionally, in AirPlay 2,

00:01:42.316 --> 00:01:43.346 A:middle
we've enhanced the audio

00:01:43.346 --> 00:01:44.826 A:middle
buffering on the AirPlay 2

00:01:44.826 --> 00:01:46.616 A:middle
speakers so that your content

00:01:46.616 --> 00:01:47.876 A:middle
can play with the high degree of

00:01:47.876 --> 00:01:49.586 A:middle
robustness, reliability, and

00:01:49.586 --> 00:01:50.416 A:middle
responsiveness.

00:01:51.306 --> 00:01:53.946 A:middle
And lastly, we're introducing

00:01:53.946 --> 00:01:54.906 A:middle
multi-device control.

00:01:55.336 --> 00:01:57.016 A:middle
And this will allow multiple

00:01:57.016 --> 00:01:58.766 A:middle
Apple devices in your home to

00:01:58.766 --> 00:02:00.216 A:middle
interact with the audio that's

00:02:00.216 --> 00:02:01.226 A:middle
being streamed throughout your

00:02:02.086 --> 00:02:02.206 A:middle
house.

00:02:03.336 --> 00:02:04.596 A:middle
So, where is AirPlay 2

00:02:04.596 --> 00:02:05.106 A:middle
supported?

00:02:05.836 --> 00:02:07.406 A:middle
Well I'm happy to say if you

00:02:07.406 --> 00:02:10.016 A:middle
have iOS, tvOS, or macOS app,

00:02:10.486 --> 00:02:11.556 A:middle
you can take the steps that I'm

00:02:11.556 --> 00:02:13.686 A:middle
about to outline today and build

00:02:13.686 --> 00:02:14.686 A:middle
them into your app to take

00:02:14.686 --> 00:02:15.776 A:middle
advantage of AirPlay 2.

00:02:16.326 --> 00:02:19.706 A:middle
And when you do, your app will

00:02:19.706 --> 00:02:21.156 A:middle
be able to play on a very wide

00:02:21.156 --> 00:02:23.086 A:middle
ecosystem of AirPlay 2 speakers,

00:02:23.396 --> 00:02:25.136 A:middle
including the HomePod, latest

00:02:25.136 --> 00:02:26.996 A:middle
generation Apple TV, and

00:02:26.996 --> 00:02:28.436 A:middle
third-party AirPlay 2 speakers

00:02:28.436 --> 00:02:29.206 A:middle
that will soon be coming to

00:02:29.206 --> 00:02:29.526 A:middle
market.

00:02:29.966 --> 00:02:32.666 A:middle
So, that's the high-level

00:02:32.666 --> 00:02:34.126 A:middle
overview of AirPlay and AirPlay

00:02:34.126 --> 00:02:34.386 A:middle
2.

00:02:35.306 --> 00:02:36.366 A:middle
Let's look at our agenda for the

00:02:36.366 --> 00:02:38.436 A:middle
rest of the talk.

00:02:38.646 --> 00:02:39.696 A:middle
First, we're going to talk about

00:02:39.786 --> 00:02:41.146 A:middle
basic AirPlay 2 adoption.

00:02:41.436 --> 00:02:42.636 A:middle
The steps that you need to do

00:02:42.636 --> 00:02:44.346 A:middle
take in order to get AirPlay 2

00:02:44.346 --> 00:02:45.546 A:middle
inside your app.

00:02:46.446 --> 00:02:47.706 A:middle
Next, we're going to focus on

00:02:47.706 --> 00:02:49.036 A:middle
some advanced playback scenarios

00:02:49.036 --> 00:02:50.356 A:middle
that you may encounter as you

00:02:50.356 --> 00:02:51.276 A:middle
adopt AirPlay 2.

00:02:52.096 --> 00:02:53.186 A:middle
And lastly, we're going to talk

00:02:53.186 --> 00:02:54.166 A:middle
about the availability of

00:02:54.166 --> 00:02:55.376 A:middle
AirPlay 2.

00:02:57.396 --> 00:03:00.026 A:middle
So, let's begin our talk about

00:03:00.026 --> 00:03:00.926 A:middle
AirPlay 2 adoption.

00:03:02.146 --> 00:03:04.416 A:middle
So, in order to adopt AirPlay 2

00:03:04.416 --> 00:03:05.886 A:middle
in your app, there are basically

00:03:05.956 --> 00:03:07.176 A:middle
four steps you need to take.

00:03:08.246 --> 00:03:10.386 A:middle
First, you should identify your

00:03:10.386 --> 00:03:12.116 A:middle
app as presenting long-form

00:03:12.116 --> 00:03:12.476 A:middle
audio.

00:03:12.876 --> 00:03:14.176 A:middle
I'll explain what long-form

00:03:14.176 --> 00:03:17.116 A:middle
audio is in a minute.

00:03:17.276 --> 00:03:18.796 A:middle
Next, you should add an AirPlay

00:03:18.796 --> 00:03:20.586 A:middle
picker inside your app.

00:03:21.686 --> 00:03:23.506 A:middle
And third, you should integrate

00:03:23.506 --> 00:03:24.356 A:middle
with certain parts of the

00:03:24.356 --> 00:03:25.566 A:middle
MediaPlayer framework.

00:03:26.126 --> 00:03:29.036 A:middle
And lastly, you should adopt one

00:03:29.036 --> 00:03:30.306 A:middle
of the playback APIs that are

00:03:30.306 --> 00:03:31.776 A:middle
specifically designed to take

00:03:31.776 --> 00:03:32.906 A:middle
advantage of the enhanced

00:03:32.906 --> 00:03:35.016 A:middle
buffering in AirPlay 2.

00:03:35.776 --> 00:03:37.036 A:middle
So, let's walk through each of

00:03:37.036 --> 00:03:37.736 A:middle
these individually.

00:03:39.556 --> 00:03:41.836 A:middle
First, identifying yourself as

00:03:41.836 --> 00:03:43.106 A:middle
presenting long-form audio

00:03:43.106 --> 00:03:43.596 A:middle
content.

00:03:44.416 --> 00:03:45.596 A:middle
So, what is long-form audio

00:03:45.596 --> 00:03:46.066 A:middle
content?

00:03:46.546 --> 00:03:48.206 A:middle
Well long-form audio is anything

00:03:48.206 --> 00:03:49.796 A:middle
like, is content like music,

00:03:50.166 --> 00:03:52.946 A:middle
podcasts, or audiobooks, as

00:03:52.946 --> 00:03:54.246 A:middle
distinct from things like system

00:03:54.246 --> 00:03:56.246 A:middle
sounds on a Mac.

00:03:56.736 --> 00:03:58.156 A:middle
Now, identifying yourself as

00:03:58.156 --> 00:03:59.726 A:middle
presenting long-form audio

00:03:59.726 --> 00:04:00.916 A:middle
content is very easy.

00:04:01.736 --> 00:04:02.916 A:middle
You simply set your

00:04:02.916 --> 00:04:04.986 A:middle
application's AVAudioSession's

00:04:05.116 --> 00:04:06.816 A:middle
route sharing policy to be

00:04:06.816 --> 00:04:07.386 A:middle
long-form.

00:04:08.776 --> 00:04:10.166 A:middle
Now here's a code snippet of how

00:04:10.166 --> 00:04:11.086 A:middle
you do that on iOS.

00:04:11.966 --> 00:04:12.916 A:middle
This is something that many of

00:04:12.916 --> 00:04:14.786 A:middle
you iOS developers are likely

00:04:14.786 --> 00:04:16.686 A:middle
familiar with setting your

00:04:16.686 --> 00:04:18.656 A:middle
category and mode, and there's

00:04:18.656 --> 00:04:20.226 A:middle
just a new parameter here which

00:04:20.226 --> 00:04:21.306 A:middle
is routeSharingPolicy:

00:04:21.706 --> 00:04:22.256 A:middle
.longform.

00:04:23.526 --> 00:04:24.816 A:middle
As I said, this has been around

00:04:24.816 --> 00:04:26.556 A:middle
on iOS for a little while.

00:04:26.556 --> 00:04:27.676 A:middle
This class is actually,

00:04:27.676 --> 00:04:29.386 A:middle
AVAudioSession is new altogether

00:04:29.386 --> 00:04:31.436 A:middle
on macOS, and I'm not going to

00:04:31.436 --> 00:04:32.496 A:middle
show a code snippet, but it's

00:04:32.496 --> 00:04:34.336 A:middle
even simpler than what you have

00:04:34.336 --> 00:04:35.186 A:middle
to do on iOS.

00:04:35.586 --> 00:04:37.046 A:middle
You simply set the route sharing

00:04:37.046 --> 00:04:37.966 A:middle
policy to long-form.

00:04:39.096 --> 00:04:40.866 A:middle
And for more information on this

00:04:40.866 --> 00:04:42.956 A:middle
new route sharing policy and

00:04:42.956 --> 00:04:44.446 A:middle
what it can do for your app in

00:04:44.446 --> 00:04:45.216 A:middle
regards to the rest of the

00:04:45.216 --> 00:04:47.266 A:middle
system, for example allow the

00:04:47.266 --> 00:04:49.086 A:middle
user to take a phone call while

00:04:49.086 --> 00:04:51.716 A:middle
you're app is AirPlay, using

00:04:51.716 --> 00:04:53.226 A:middle
AirPlay 2 to stream to speakers,

00:04:53.646 --> 00:04:54.826 A:middle
I encourage you to take a look

00:04:54.826 --> 00:04:55.916 A:middle
at this session from earlier in

00:04:55.916 --> 00:04:57.496 A:middle
the week called What's New in

00:04:57.496 --> 00:04:57.846 A:middle
Audio.

00:04:57.876 --> 00:05:00.976 A:middle
All right, so that's the first

00:05:00.976 --> 00:05:03.196 A:middle
step you need to do to take

00:05:03.196 --> 00:05:04.266 A:middle
advantage of AirPlay 2.

00:05:04.826 --> 00:05:06.556 A:middle
The second is to add an AirPlay

00:05:06.556 --> 00:05:08.346 A:middle
picker inside your app.

00:05:09.016 --> 00:05:11.916 A:middle
This will allow users to route

00:05:11.916 --> 00:05:13.926 A:middle
their content to AirPlay

00:05:13.926 --> 00:05:15.386 A:middle
speakers without leaving the

00:05:15.386 --> 00:05:17.386 A:middle
confines of your app.

00:05:17.716 --> 00:05:18.966 A:middle
And doing this is very easy.

00:05:18.966 --> 00:05:21.966 A:middle
You simply adopt a new API

00:05:22.396 --> 00:05:23.416 A:middle
called AVKit's

00:05:23.416 --> 00:05:24.846 A:middle
AVRoutePickerView.

00:05:25.426 --> 00:05:26.756 A:middle
You simply add this view to your

00:05:26.756 --> 00:05:27.496 A:middle
view hierarchy.

00:05:28.776 --> 00:05:30.606 A:middle
And you may want to control when

00:05:30.606 --> 00:05:32.206 A:middle
this is shown, for example only

00:05:32.206 --> 00:05:34.376 A:middle
show it if there actually is an

00:05:34.376 --> 00:05:36.006 A:middle
AirPlay 2 speaker or an AirPlay

00:05:36.006 --> 00:05:37.366 A:middle
speaker available to be routed

00:05:37.366 --> 00:05:37.606 A:middle
to.

00:05:38.246 --> 00:05:39.916 A:middle
And you can do that by adopting

00:05:39.916 --> 00:05:42.046 A:middle
AVFoundation's AVRouteDetector

00:05:42.146 --> 00:05:43.406 A:middle
which will tell you if there are

00:05:43.406 --> 00:05:44.666 A:middle
speakers, if there are routes

00:05:44.666 --> 00:05:45.206 A:middle
available.

00:05:46.636 --> 00:05:49.786 A:middle
These API, they're new in the

00:05:49.786 --> 00:05:53.206 A:middle
latest OS releases and they're

00:05:53.206 --> 00:05:55.546 A:middle
available on macOS, iOS, and

00:05:55.546 --> 00:05:56.036 A:middle
tvOS.

00:05:57.066 --> 00:05:58.276 A:middle
And a note to all of you iOS

00:05:58.276 --> 00:05:59.426 A:middle
developers who are currently

00:05:59.426 --> 00:06:01.496 A:middle
using MPVolumeView, it will

00:06:01.496 --> 00:06:03.066 A:middle
still work, but we are

00:06:03.066 --> 00:06:04.146 A:middle
encouraging people to move to

00:06:04.146 --> 00:06:05.086 A:middle
these API instead.

00:06:05.636 --> 00:06:08.236 A:middle
So, that's the second thing you

00:06:08.236 --> 00:06:09.646 A:middle
need to do to get your app up

00:06:09.646 --> 00:06:10.866 A:middle
and running with AirPlay 2.

00:06:11.576 --> 00:06:13.426 A:middle
The third thing you should do is

00:06:13.426 --> 00:06:14.786 A:middle
to integrate your app with

00:06:14.786 --> 00:06:15.866 A:middle
certain parts of the MediaPlayer

00:06:15.866 --> 00:06:16.326 A:middle
framework.

00:06:16.836 --> 00:06:18.036 A:middle
Now this is rather large, so

00:06:18.036 --> 00:06:18.986 A:middle
there's basically two things

00:06:18.986 --> 00:06:20.566 A:middle
that I'm specifically focusing

00:06:20.566 --> 00:06:20.936 A:middle
on today.

00:06:20.936 --> 00:06:23.416 A:middle
And these are things that will,

00:06:24.036 --> 00:06:26.496 A:middle
these API will allow you to do

00:06:26.496 --> 00:06:27.726 A:middle
things like display the

00:06:27.726 --> 00:06:29.896 A:middle
currently playing album art on

00:06:29.896 --> 00:06:31.836 A:middle
the lock screen or an Apple TV

00:06:32.776 --> 00:06:33.906 A:middle
it's being AirPlayed to.

00:06:34.286 --> 00:06:35.556 A:middle
And additionally, they will

00:06:35.556 --> 00:06:37.526 A:middle
allow you to receive playback

00:06:37.526 --> 00:06:39.716 A:middle
commands and pause commands from

00:06:39.716 --> 00:06:42.056 A:middle
other devices on the network or

00:06:42.056 --> 00:06:43.846 A:middle
from other accessories like

00:06:43.846 --> 00:06:44.336 A:middle
headphones.

00:06:44.916 --> 00:06:47.066 A:middle
And the two pieces of API that

00:06:47.066 --> 00:06:48.646 A:middle
we need, we are asking you to

00:06:48.646 --> 00:06:49.036 A:middle
adopt.

00:06:49.796 --> 00:06:50.516 A:middle
The first is

00:06:50.516 --> 00:06:52.446 A:middle
MPRemoteCommandCenter and this

00:06:52.446 --> 00:06:53.676 A:middle
will allow you to receive those

00:06:53.676 --> 00:06:55.996 A:middle
remote commands, and the second

00:06:56.276 --> 00:06:58.486 A:middle
is MPNowPlayingInfoCenter which

00:06:58.486 --> 00:06:59.476 A:middle
will allow you to inform the

00:06:59.476 --> 00:07:01.076 A:middle
system metadata about the

00:07:01.076 --> 00:07:02.456 A:middle
currently playing track.

00:07:02.626 --> 00:07:05.456 A:middle
All right, so that's the third

00:07:05.456 --> 00:07:06.676 A:middle
thing you need to do to get your

00:07:06.676 --> 00:07:08.086 A:middle
app up and running with AirPlay

00:07:08.086 --> 00:07:08.336 A:middle
2.

00:07:08.986 --> 00:07:10.536 A:middle
The fourth this is you should

00:07:10.536 --> 00:07:11.946 A:middle
adopt one of the playback APIs

00:07:11.946 --> 00:07:13.846 A:middle
that are specifically designed

00:07:13.886 --> 00:07:15.666 A:middle
to take advantage of enhanced

00:07:15.666 --> 00:07:16.916 A:middle
buffering in AirPlay 2.

00:07:18.106 --> 00:07:18.926 A:middle
And to motivate this

00:07:18.926 --> 00:07:20.786 A:middle
conversation, let's take a look

00:07:20.786 --> 00:07:22.136 A:middle
a little bit deeper at AirPlay

00:07:22.136 --> 00:07:24.526 A:middle
audio and the buffer levels

00:07:24.646 --> 00:07:26.556 A:middle
beginning with how AirPlay works

00:07:26.556 --> 00:07:26.876 A:middle
today.

00:07:28.076 --> 00:07:30.266 A:middle
So, AirPlay today is effectively

00:07:30.266 --> 00:07:32.506 A:middle
a real-time stream of audio to

00:07:32.506 --> 00:07:33.826 A:middle
which the speakers adds just a

00:07:33.826 --> 00:07:35.486 A:middle
few seconds of buffering before

00:07:35.486 --> 00:07:36.506 A:middle
playing out in real-time.

00:07:37.066 --> 00:07:39.936 A:middle
Now, this works very well to a

00:07:39.936 --> 00:07:41.906 A:middle
single speaker, and it works

00:07:41.906 --> 00:07:43.626 A:middle
pretty well with lots of

00:07:43.626 --> 00:07:44.116 A:middle
content.

00:07:45.136 --> 00:07:48.256 A:middle
But, if we are able to restrict

00:07:48.256 --> 00:07:49.646 A:middle
ourselves on only focusing on

00:07:49.646 --> 00:07:51.526 A:middle
long-form content, like music,

00:07:51.596 --> 00:07:53.516 A:middle
podcasts or audiobooks, we can

00:07:53.516 --> 00:07:56.356 A:middle
probably do better.

00:07:56.526 --> 00:07:58.616 A:middle
So, let's talk about the

00:07:58.616 --> 00:08:00.586 A:middle
enhanced buffering in AirPlay 2.

00:08:01.186 --> 00:08:03.386 A:middle
So, what am I talking about with

00:08:03.386 --> 00:08:04.946 A:middle
enhanced buffering in AirPlay 2?

00:08:05.536 --> 00:08:09.326 A:middle
Well, as the name implies, we've

00:08:09.326 --> 00:08:11.986 A:middle
added very large buffer capacity

00:08:11.986 --> 00:08:13.516 A:middle
on the AirPlay 2 speakers.

00:08:13.726 --> 00:08:14.566 A:middle
Here I want you to think

00:08:14.566 --> 00:08:16.796 A:middle
minutes, not seconds.

00:08:17.816 --> 00:08:18.746 A:middle
Additionally, we're able to

00:08:18.746 --> 00:08:20.226 A:middle
stream the audio content from

00:08:20.226 --> 00:08:21.486 A:middle
your app to the speaker

00:08:21.486 --> 00:08:22.596 A:middle
faster-than-real-time.

00:08:23.126 --> 00:08:25.416 A:middle
And I think the benefits of this

00:08:25.416 --> 00:08:26.096 A:middle
should be clear.

00:08:27.396 --> 00:08:28.956 A:middle
The large buffering on the

00:08:28.956 --> 00:08:30.126 A:middle
AirPlay speakers will add a

00:08:30.126 --> 00:08:32.236 A:middle
large degree of robustness to

00:08:32.236 --> 00:08:33.136 A:middle
the AirPlay session.

00:08:33.916 --> 00:08:35.106 A:middle
You should be able to survive

00:08:35.106 --> 00:08:36.586 A:middle
more typical network glitches,

00:08:36.586 --> 00:08:38.046 A:middle
like walking, taking the trash

00:08:38.046 --> 00:08:39.226 A:middle
out, or walking to the dead spot

00:08:39.226 --> 00:08:40.326 A:middle
of the house, or even

00:08:40.326 --> 00:08:41.406 A:middle
microwaving some popcorn.

00:08:43.336 --> 00:08:44.606 A:middle
Additionally, this should

00:08:44.606 --> 00:08:46.106 A:middle
provide more responsive playback

00:08:46.106 --> 00:08:46.806 A:middle
experience.

00:08:47.556 --> 00:08:48.876 A:middle
The real-time nature of existing

00:08:48.876 --> 00:08:50.016 A:middle
AirPlay means that there's a

00:08:50.016 --> 00:08:51.816 A:middle
fixed output latency that is

00:08:51.816 --> 00:08:53.376 A:middle
related to the buffer level on

00:08:53.376 --> 00:08:54.196 A:middle
the AirPlay speaker.

00:08:55.346 --> 00:08:57.046 A:middle
So, when you hit play, with

00:08:57.046 --> 00:08:58.386 A:middle
AirPlay 2 it should play a lot

00:08:58.386 --> 00:08:58.776 A:middle
faster.

00:08:58.776 --> 00:08:59.726 A:middle
When you hit skip, it should

00:08:59.726 --> 00:09:00.676 A:middle
skip a lot faster.

00:09:01.726 --> 00:09:04.476 A:middle
This will add a great, this is a

00:09:04.476 --> 00:09:06.366 A:middle
great user experience for your

00:09:06.366 --> 00:09:08.586 A:middle
users which is why we're really

00:09:08.586 --> 00:09:09.506 A:middle
excited to talk about the

00:09:09.506 --> 00:09:10.196 A:middle
enhanced buffering.

00:09:10.716 --> 00:09:14.106 A:middle
And so in order to take

00:09:14.106 --> 00:09:15.336 A:middle
advantage of the advanced

00:09:15.336 --> 00:09:16.766 A:middle
buffering, you should adopt one

00:09:16.766 --> 00:09:17.466 A:middle
of a few API.

00:09:18.646 --> 00:09:20.656 A:middle
The first, is AVPlayer and

00:09:20.656 --> 00:09:21.416 A:middle
AVQueuePlayer.

00:09:21.606 --> 00:09:23.696 A:middle
The AVPlayer's set of playback

00:09:23.696 --> 00:09:23.976 A:middle
API.

00:09:24.686 --> 00:09:26.016 A:middle
These have been around for quite

00:09:26.016 --> 00:09:27.686 A:middle
a while and they're your easiest

00:09:27.686 --> 00:09:29.196 A:middle
route to AirPlay 2 in the

00:09:29.196 --> 00:09:29.906 A:middle
enhanced buffering.

00:09:31.286 --> 00:09:33.146 A:middle
The second API, set of API are

00:09:33.146 --> 00:09:34.556 A:middle
new API that we're introducing

00:09:34.556 --> 00:09:35.736 A:middle
today which are

00:09:35.736 --> 00:09:37.766 A:middle
AVSampleBufferAudio Renderer and

00:09:37.766 --> 00:09:38.796 A:middle
AVSampleBufferRender

00:09:38.796 --> 00:09:39.456 A:middle
Synchronizer.

00:09:40.896 --> 00:09:42.536 A:middle
These will prevent, present more

00:09:42.536 --> 00:09:44.786 A:middle
flexibility to apps that need

00:09:45.396 --> 00:09:45.466 A:middle
it.

00:09:46.096 --> 00:09:47.276 A:middle
So, let's talk about these

00:09:47.276 --> 00:09:50.326 A:middle
individually by first surveying

00:09:50.326 --> 00:09:51.516 A:middle
AVPlayer and AVQueuePlayer.

00:09:52.666 --> 00:09:53.646 A:middle
So, as I've said these have been

00:09:53.646 --> 00:09:54.896 A:middle
around for quite a while, since

00:09:54.896 --> 00:09:56.516 A:middle
iOS 4 on the iOS platforms.

00:09:57.596 --> 00:09:59.026 A:middle
And because of that there's a

00:09:59.026 --> 00:10:00.316 A:middle
ton of documentation on the

00:10:00.316 --> 00:10:01.716 A:middle
developer website and a lot of

00:10:01.716 --> 00:10:02.516 A:middle
sample code there.

00:10:03.046 --> 00:10:04.286 A:middle
So, if you want a lot of detail

00:10:04.286 --> 00:10:06.326 A:middle
on these, I encourage you to

00:10:06.326 --> 00:10:07.896 A:middle
look to the developer website,

00:10:07.896 --> 00:10:09.466 A:middle
because I'm just going to give a

00:10:09.466 --> 00:10:10.646 A:middle
very high-level overview of

00:10:10.646 --> 00:10:11.486 A:middle
these API today.

00:10:12.366 --> 00:10:14.316 A:middle
So, what I'm going to do, is I'm

00:10:14.316 --> 00:10:15.876 A:middle
going to walk through what it

00:10:15.876 --> 00:10:17.336 A:middle
takes to build an app with this

00:10:17.336 --> 00:10:17.666 A:middle
API.

00:10:18.196 --> 00:10:19.236 A:middle
So, here you have your Client

00:10:19.236 --> 00:10:20.526 A:middle
App, and if you want to build an

00:10:20.526 --> 00:10:21.706 A:middle
app with an AVPlayer or

00:10:21.706 --> 00:10:23.186 A:middle
AVQueuePlayer, the first thing

00:10:23.186 --> 00:10:24.356 A:middle
you're going to do is your going

00:10:24.356 --> 00:10:25.926 A:middle
instantiate one of the objects.

00:10:27.246 --> 00:10:28.716 A:middle
Here I'm using an AVQueuePlayer

00:10:28.716 --> 00:10:29.916 A:middle
but the steps are exactly the

00:10:29.916 --> 00:10:31.196 A:middle
same if you use AVPlayer.

00:10:31.686 --> 00:10:35.576 A:middle
Next, you're going to take a URL

00:10:35.576 --> 00:10:37.006 A:middle
that points to the content that

00:10:37.006 --> 00:10:38.616 A:middle
you want to play, and that

00:10:38.616 --> 00:10:40.316 A:middle
content can be local or it can

00:10:40.316 --> 00:10:41.296 A:middle
be in the cloud, it can be

00:10:41.296 --> 00:10:41.586 A:middle
remote.

00:10:41.586 --> 00:10:43.296 A:middle
You're going to take that URL,

00:10:43.296 --> 00:10:45.006 A:middle
and you're going to wrap it in

00:10:45.006 --> 00:10:46.766 A:middle
an AVAsset and you're going to

00:10:46.766 --> 00:10:48.246 A:middle
wrap that AVAsset in an

00:10:48.246 --> 00:10:48.766 A:middle
AVPlayerItem.

00:10:50.296 --> 00:10:51.786 A:middle
Next, you're going to give that

00:10:51.786 --> 00:10:53.146 A:middle
AVPlayerItem to the

00:10:53.146 --> 00:10:53.646 A:middle
AVQueuePlayer.

00:10:54.246 --> 00:10:56.636 A:middle
Now after you've handed it over,

00:10:56.636 --> 00:10:57.466 A:middle
you're ready to initiate

00:10:57.466 --> 00:10:57.846 A:middle
playback.

00:10:57.966 --> 00:11:00.536 A:middle
And you do so but simply setting

00:11:00.536 --> 00:11:01.366 A:middle
the rate of 1 on the

00:11:01.366 --> 00:11:03.856 A:middle
AVQueuePlayer, which in response

00:11:03.856 --> 00:11:05.146 A:middle
will begin downloading the audio

00:11:05.146 --> 00:11:07.496 A:middle
data from wherever it resides,

00:11:08.036 --> 00:11:10.266 A:middle
and then playing it out the

00:11:10.266 --> 00:11:10.806 A:middle
speakers.

00:11:11.206 --> 00:11:15.876 A:middle
So, this is the quick survey of

00:11:15.876 --> 00:11:17.346 A:middle
AVPlayer and AVQueuePlayer, I

00:11:17.346 --> 00:11:18.466 A:middle
should also note that this works

00:11:18.466 --> 00:11:19.876 A:middle
really well for video content.

00:11:20.546 --> 00:11:21.316 A:middle
So, if you want to play some

00:11:21.316 --> 00:11:22.686 A:middle
video content, you can do it

00:11:22.686 --> 00:11:23.986 A:middle
pretty easily with AVPlayer and

00:11:23.986 --> 00:11:24.446 A:middle
AVQueuePlayer.

00:11:25.026 --> 00:11:29.056 A:middle
So, just to reiterate, your

00:11:29.056 --> 00:11:31.036 A:middle
easiest way to AirPlay 2 is

00:11:31.036 --> 00:11:31.866 A:middle
using these API.

00:11:32.666 --> 00:11:34.486 A:middle
But we recognize that this won't

00:11:34.486 --> 00:11:35.346 A:middle
work for everybody.

00:11:35.746 --> 00:11:37.146 A:middle
There's a certain class of audio

00:11:37.146 --> 00:11:38.166 A:middle
playing apps that either

00:11:38.166 --> 00:11:39.736 A:middle
require, that want to do their

00:11:39.736 --> 00:11:40.936 A:middle
own IO possibly.

00:11:41.446 --> 00:11:43.916 A:middle
Possibly their own DRM or even

00:11:43.976 --> 00:11:46.506 A:middle
preprocessing on the media data

00:11:46.596 --> 00:11:47.456 A:middle
before it's rendered out.

00:11:47.566 --> 00:11:48.866 A:middle
They need more flexibility than

00:11:48.866 --> 00:11:50.216 A:middle
the, than what these API

00:11:50.346 --> 00:11:50.716 A:middle
provide.

00:11:51.176 --> 00:11:54.416 A:middle
And for these developers we're

00:11:54.416 --> 00:11:55.986 A:middle
introducing these new classes,

00:11:56.536 --> 00:11:58.616 A:middle
AVSampleBufferAudio Renderer and

00:11:58.616 --> 00:11:59.586 A:middle
AVSampleBufferRender

00:11:59.586 --> 00:12:00.236 A:middle
Synchronizer.

00:12:01.766 --> 00:12:03.646 A:middle
Now with these APIs when you use

00:12:03.646 --> 00:12:05.006 A:middle
them to do playback, your app

00:12:05.006 --> 00:12:06.566 A:middle
has additional responsibilities.

00:12:07.786 --> 00:12:09.536 A:middle
So, first of all your app is

00:12:09.536 --> 00:12:10.846 A:middle
responsible for sourcing and

00:12:10.846 --> 00:12:11.666 A:middle
parsing the content.

00:12:12.156 --> 00:12:13.286 A:middle
You need to go get it wherever

00:12:13.286 --> 00:12:14.796 A:middle
it is, download it, read it off

00:12:14.796 --> 00:12:16.396 A:middle
disc, whatever.

00:12:17.046 --> 00:12:18.596 A:middle
And then your app has to parse

00:12:18.596 --> 00:12:20.806 A:middle
it and feed the raw audio data,

00:12:20.806 --> 00:12:22.786 A:middle
the raw audio buffers to the API

00:12:22.926 --> 00:12:23.436 A:middle
for rendering.

00:12:24.936 --> 00:12:26.086 A:middle
This is kind of similar to

00:12:26.086 --> 00:12:27.386 A:middle
AudioQueue but it works better

00:12:27.386 --> 00:12:28.806 A:middle
with the deeper buffers that we

00:12:28.806 --> 00:12:31.776 A:middle
need for buffered AirPlay, for

00:12:31.916 --> 00:12:32.526 A:middle
enhanced AirPlay.

00:12:32.826 --> 00:12:35.366 A:middle
Because these are new, we're

00:12:35.366 --> 00:12:36.486 A:middle
going to spend the remainder of

00:12:36.486 --> 00:12:37.666 A:middle
this session talking about

00:12:37.976 --> 00:12:38.356 A:middle
these.

00:12:38.496 --> 00:12:42.676 A:middle
All right, so let's walk through

00:12:42.676 --> 00:12:44.156 A:middle
a simple block diagram of how

00:12:44.156 --> 00:12:45.436 A:middle
you might build an app using

00:12:45.436 --> 00:12:45.906 A:middle
these API.

00:12:47.096 --> 00:12:48.706 A:middle
So, again use your Client App,

00:12:49.436 --> 00:12:50.286 A:middle
and the first thing you're going

00:12:50.286 --> 00:12:51.376 A:middle
to do when building an app with

00:12:51.376 --> 00:12:52.046 A:middle
these is you're going to

00:12:52.046 --> 00:12:52.896 A:middle
instantiate an

00:12:53.286 --> 00:12:54.486 A:middle
AVSampleBufferRender

00:12:54.486 --> 00:12:55.776 A:middle
Synchronizer and

00:12:55.776 --> 00:12:57.176 A:middle
AVSampleBufferAudio Renderer.

00:12:58.156 --> 00:12:59.656 A:middle
Now of these classes, the

00:12:59.656 --> 00:13:01.516 A:middle
AudioRenderer class is the one

00:13:01.516 --> 00:13:02.436 A:middle
that is responsible for

00:13:02.436 --> 00:13:04.226 A:middle
rendering the audio, and the

00:13:04.226 --> 00:13:05.686 A:middle
Synchronizer class is the one

00:13:05.686 --> 00:13:06.766 A:middle
that's responsible for

00:13:06.766 --> 00:13:08.146 A:middle
establishing the media timeline.

00:13:09.416 --> 00:13:10.506 A:middle
Now, there's good reason, you

00:13:10.506 --> 00:13:11.536 A:middle
may be asking yourself, why are

00:13:11.536 --> 00:13:12.586 A:middle
they two classes, why didn't you

00:13:12.586 --> 00:13:13.506 A:middle
roll it into one?

00:13:13.626 --> 00:13:14.566 A:middle
Well, I assure you there's a

00:13:14.566 --> 00:13:15.146 A:middle
good reason.

00:13:15.146 --> 00:13:16.046 A:middle
We'll talk about that later.

00:13:16.306 --> 00:13:17.126 A:middle
But never the less,

00:13:17.616 --> 00:13:19.106 A:middle
AudioRenderer it does the

00:13:19.106 --> 00:13:20.066 A:middle
rendering of the audio.

00:13:20.186 --> 00:13:21.676 A:middle
The Synchronizer establishes the

00:13:21.676 --> 00:13:23.636 A:middle
media timeline.

00:13:24.156 --> 00:13:25.646 A:middle
So, after you've instantiated

00:13:25.646 --> 00:13:27.786 A:middle
these, you add the AudioRenderer

00:13:27.976 --> 00:13:28.866 A:middle
to the Synchronizer.

00:13:29.436 --> 00:13:31.596 A:middle
This tells the AudioRenderer to

00:13:31.596 --> 00:13:33.006 A:middle
follow the media timeline

00:13:33.006 --> 00:13:34.816 A:middle
established by the Synchronizer.

00:13:34.816 --> 00:13:38.386 A:middle
Now, as you begin working with

00:13:38.386 --> 00:13:39.816 A:middle
an AVSampleBufferAudio Renderer,

00:13:39.866 --> 00:13:40.836 A:middle
one of the things it's going to

00:13:40.836 --> 00:13:41.766 A:middle
do is it's going to tell you

00:13:41.766 --> 00:13:43.656 A:middle
when it wants more media data.

00:13:44.376 --> 00:13:45.686 A:middle
And when it tells you that it

00:13:45.686 --> 00:13:46.906 A:middle
wants more media data, in

00:13:46.906 --> 00:13:48.686 A:middle
response, you should feed it.

00:13:49.776 --> 00:13:50.796 A:middle
So, give it some audio data.

00:13:51.416 --> 00:13:54.016 A:middle
And after you've done that, you

00:13:54.016 --> 00:13:55.676 A:middle
can begin playback by setting

00:13:55.676 --> 00:13:57.066 A:middle
the rate of 1 on the

00:13:57.066 --> 00:13:57.706 A:middle
Synchronizer.

00:13:58.216 --> 00:14:00.596 A:middle
And after you've set the rate of

00:14:00.596 --> 00:14:02.476 A:middle
1 on the Synchronizer, audio

00:14:02.476 --> 00:14:04.016 A:middle
data will begin flowing out of

00:14:04.016 --> 00:14:04.676 A:middle
the AudioRenderer.

00:14:05.226 --> 00:14:09.136 A:middle
So, that's the basic high-level

00:14:09.136 --> 00:14:10.356 A:middle
overview of how you build a

00:14:10.356 --> 00:14:11.646 A:middle
playback engine, with

00:14:11.646 --> 00:14:13.216 A:middle
AVSampleBufferAudio Renderer and

00:14:13.216 --> 00:14:14.036 A:middle
AVSampleBufferRender

00:14:14.036 --> 00:14:14.656 A:middle
Synchronizer.

00:14:15.136 --> 00:14:16.056 A:middle
Now I'd like to invite my

00:14:16.056 --> 00:14:17.506 A:middle
colleague Adam Sonnanstine up on

00:14:17.506 --> 00:14:19.236 A:middle
stage to give a demo of this.

00:14:20.016 --> 00:14:21.196 A:middle
[ Applause ]

00:14:21.196 --> 00:14:21.776 A:middle
&gt;&gt; Thank you, David.

00:14:23.156 --> 00:14:24.566 A:middle
I'm very happy to be here today

00:14:24.566 --> 00:14:26.836 A:middle
to demonstrate AirPlay 2 and its

00:14:26.836 --> 00:14:28.356 A:middle
enhanced reliability and

00:14:28.356 --> 00:14:29.016 A:middle
robustness.

00:14:29.066 --> 00:14:31.236 A:middle
I'm going to do that using this

00:14:31.236 --> 00:14:32.726 A:middle
sample application that we've

00:14:32.726 --> 00:14:33.256 A:middle
developed.

00:14:33.256 --> 00:14:35.206 A:middle
And this application will be

00:14:35.266 --> 00:14:37.416 A:middle
available as sample code shortly

00:14:37.416 --> 00:14:38.626 A:middle
after the conference ends.

00:14:39.316 --> 00:14:40.916 A:middle
And we also have an Apple TV on

00:14:40.916 --> 00:14:42.336 A:middle
stage so I can demonstrate

00:14:42.646 --> 00:14:44.576 A:middle
AirPlaying from the phone to the

00:14:44.576 --> 00:14:46.626 A:middle
Apple TV both with current

00:14:46.626 --> 00:14:48.236 A:middle
AirPlay and with AirPlay 2.

00:14:48.566 --> 00:14:50.136 A:middle
So let's take a look at the app.

00:14:50.136 --> 00:14:51.816 A:middle
You can see it's just a simple

00:14:51.816 --> 00:14:53.266 A:middle
sort of stripped down music

00:14:53.266 --> 00:14:54.266 A:middle
player interface.

00:14:54.816 --> 00:14:57.156 A:middle
We have this nice AirPlay or

00:14:57.156 --> 00:14:59.226 A:middle
sorry Control Center integration

00:14:59.566 --> 00:15:01.066 A:middle
because I've adopted the

00:15:01.126 --> 00:15:02.786 A:middle
MediaPlayer APIs that David

00:15:02.786 --> 00:15:03.496 A:middle
mentioned before.

00:15:03.496 --> 00:15:05.106 A:middle
So, I'm just going to go ahead

00:15:05.106 --> 00:15:05.946 A:middle
and start playing.

00:15:05.946 --> 00:15:07.736 A:middle
And so you can hear it, I'll

00:15:08.346 --> 00:15:10.426 A:middle
start AirPlaying to my Apple TV.

00:15:10.996 --> 00:15:16.216 A:middle
[music] Now this app has not yet

00:15:16.216 --> 00:15:18.486 A:middle
been optimized for AirPlay 2 so

00:15:18.486 --> 00:15:19.646 A:middle
I just want to give you a base

00:15:19.716 --> 00:15:21.746 A:middle
line of what the performance is

00:15:21.746 --> 00:15:23.036 A:middle
with the current AirPlay.

00:15:23.726 --> 00:15:25.806 A:middle
And I'm going to do that, I want

00:15:25.806 --> 00:15:27.676 A:middle
you to imagine that you are

00:15:27.956 --> 00:15:29.616 A:middle
enjoying this music sitting on

00:15:29.616 --> 00:15:31.346 A:middle
my couch in my living room, the

00:15:31.346 --> 00:15:32.646 A:middle
music being streamed from my

00:15:32.646 --> 00:15:34.706 A:middle
phone to my Apple TV and I

00:15:34.706 --> 00:15:36.296 A:middle
decide that it's a good time to

00:15:36.436 --> 00:15:37.786 A:middle
walk outside with the phone in

00:15:37.786 --> 00:15:39.476 A:middle
my pocket to take out the trash,

00:15:40.366 --> 00:15:42.816 A:middle
maybe to, walking right outside

00:15:42.816 --> 00:15:45.236 A:middle
of my Wi-Fi range, and I'm going

00:15:45.236 --> 00:15:46.746 A:middle
to simulate that by using this

00:15:46.806 --> 00:15:48.976 A:middle
bag, which shields everything I

00:15:48.976 --> 00:15:50.596 A:middle
put inside it from

00:15:50.596 --> 00:15:52.836 A:middle
electromagnetic radiation going

00:15:52.836 --> 00:15:55.006 A:middle
in and from coming out, and that

00:15:55.006 --> 00:15:56.176 A:middle
includes Wi-Fi.

00:15:56.876 --> 00:16:00.166 A:middle
So, I'll take my phone, and here

00:16:00.166 --> 00:16:03.096 A:middle
I am walking outside and you can

00:16:03.096 --> 00:16:05.766 A:middle
hear that almost immediately the

00:16:05.766 --> 00:16:06.656 A:middle
music cuts out.

00:16:07.016 --> 00:16:07.996 A:middle
You've probably experienced

00:16:07.996 --> 00:16:09.826 A:middle
something like this before and

00:16:09.826 --> 00:16:11.046 A:middle
if you're actually sitting in my

00:16:11.046 --> 00:16:12.376 A:middle
living room, listening to music

00:16:12.626 --> 00:16:13.586 A:middle
you're probably going to think

00:16:13.586 --> 00:16:14.906 A:middle
I'm not a very good host.

00:16:15.716 --> 00:16:17.826 A:middle
So, let's go back and I'll go

00:16:17.826 --> 00:16:19.146 A:middle
ahead and pause the music.

00:16:20.696 --> 00:16:23.446 A:middle
And we'll switch into Xcode here

00:16:23.446 --> 00:16:24.896 A:middle
and I'll show you how you can do

00:16:25.246 --> 00:16:27.606 A:middle
a couple of simple steps to opt

00:16:27.856 --> 00:16:30.446 A:middle
your app, this app into AirPlay

00:16:30.446 --> 00:16:30.736 A:middle
2.

00:16:31.716 --> 00:16:33.876 A:middle
So, here we are in Xcode and I

00:16:33.876 --> 00:16:35.636 A:middle
have just a very small snippet

00:16:35.636 --> 00:16:37.076 A:middle
from my application here, the

00:16:37.076 --> 00:16:38.316 A:middle
rest of it's implemented in

00:16:38.526 --> 00:16:39.386 A:middle
other files.

00:16:39.776 --> 00:16:41.416 A:middle
And I just have a function that

00:16:41.876 --> 00:16:43.946 A:middle
the rest of the app is using to

00:16:44.176 --> 00:16:45.956 A:middle
grab an object that it can use

00:16:45.956 --> 00:16:48.486 A:middle
to actually do the audio

00:16:48.486 --> 00:16:49.016 A:middle
playback.

00:16:49.506 --> 00:16:50.466 A:middle
It's basically a factory

00:16:50.466 --> 00:16:50.866 A:middle
function.

00:16:50.866 --> 00:16:52.446 A:middle
And this can return an object

00:16:52.446 --> 00:16:53.956 A:middle
that conforms to a protocol that

00:16:53.956 --> 00:16:54.956 A:middle
I've defined elsewhere in the

00:16:54.956 --> 00:16:55.186 A:middle
app.

00:16:55.606 --> 00:16:56.246 A:middle
We don't need to look at the

00:16:56.246 --> 00:16:57.836 A:middle
details, but it defines methods

00:16:57.836 --> 00:16:59.356 A:middle
for things like play and pause

00:16:59.356 --> 00:17:00.966 A:middle
and the sort of basic playback

00:17:00.966 --> 00:17:02.326 A:middle
operations that a player should

00:17:02.326 --> 00:17:02.576 A:middle
do.

00:17:03.276 --> 00:17:04.406 A:middle
And we have an existing

00:17:04.406 --> 00:17:06.026 A:middle
implementation of this protocol

00:17:06.106 --> 00:17:07.716 A:middle
which is being used in the demo

00:17:07.716 --> 00:17:08.396 A:middle
that we just saw.

00:17:08.396 --> 00:17:10.516 A:middle
And what we're going to do right

00:17:10.516 --> 00:17:11.716 A:middle
now is I'm going to create a

00:17:11.716 --> 00:17:14.566 A:middle
brand-new implementation of this

00:17:14.566 --> 00:17:15.706 A:middle
audio player, and I'm going to

00:17:15.706 --> 00:17:17.536 A:middle
call it SampleBufferAudioPlayer

00:17:17.536 --> 00:17:19.426 A:middle
because it's going to be built

00:17:19.426 --> 00:17:21.356 A:middle
using AVSampleBufferAudio

00:17:21.356 --> 00:17:21.786 A:middle
Renderer.

00:17:21.786 --> 00:17:23.596 A:middle
I'm just going to preemptively

00:17:23.596 --> 00:17:25.096 A:middle
swap that in so that the next

00:17:25.096 --> 00:17:26.886 A:middle
time we launch the app, it will

00:17:26.886 --> 00:17:28.156 A:middle
use the new implementation

00:17:28.156 --> 00:17:28.826 A:middle
instead of the old

00:17:28.826 --> 00:17:29.526 A:middle
implementation.

00:17:30.736 --> 00:17:32.386 A:middle
So, as I mentioned, this class

00:17:32.386 --> 00:17:33.846 A:middle
is going to be built on top of

00:17:33.846 --> 00:17:35.666 A:middle
AVSampleBufferAudio Renderer,

00:17:35.896 --> 00:17:36.946 A:middle
and we're also going to need to

00:17:37.046 --> 00:17:38.266 A:middle
use AVSampleBufferRender

00:17:38.266 --> 00:17:39.016 A:middle
Synchronizer.

00:17:39.296 --> 00:17:40.576 A:middle
These are the classes that David

00:17:40.576 --> 00:17:41.786 A:middle
just introduced to you.

00:17:42.376 --> 00:17:43.616 A:middle
And I just want to reiterate

00:17:43.616 --> 00:17:45.766 A:middle
what David said that AVPlayer

00:17:45.766 --> 00:17:46.796 A:middle
would give you all of the

00:17:46.796 --> 00:17:48.176 A:middle
benefits that I'm about to show

00:17:48.176 --> 00:17:49.626 A:middle
you, but with a little bit less

00:17:49.626 --> 00:17:50.486 A:middle
work on your part.

00:17:50.486 --> 00:17:51.536 A:middle
So, if you're already using

00:17:51.536 --> 00:17:53.026 A:middle
AVPlayer, or you think you can

00:17:53.026 --> 00:17:54.926 A:middle
use AVPlayer, we recommend that

00:17:54.926 --> 00:17:55.416 A:middle
you do that.

00:17:55.596 --> 00:17:57.036 A:middle
For the rest of you, I want to

00:17:57.036 --> 00:17:58.176 A:middle
show you how to use these new

00:17:58.176 --> 00:17:58.786 A:middle
classes.

00:18:00.166 --> 00:18:03.716 A:middle
So, once I have my state here,

00:18:03.716 --> 00:18:05.236 A:middle
I'm going to hook up my

00:18:05.776 --> 00:18:06.816 A:middle
AudioRenderer with my

00:18:06.816 --> 00:18:08.476 A:middle
RenderSynchronizer using the

00:18:08.476 --> 00:18:10.066 A:middle
addRenderer method, and I'll do

00:18:10.066 --> 00:18:11.046 A:middle
that as soon as my

00:18:11.086 --> 00:18:12.516 A:middle
SampleBufferAudioPlayer is

00:18:12.516 --> 00:18:12.936 A:middle
created.

00:18:13.416 --> 00:18:15.796 A:middle
And then we need to interact

00:18:15.796 --> 00:18:17.206 A:middle
with the renderer, and we're

00:18:17.206 --> 00:18:18.396 A:middle
going to do that by calling the

00:18:18.396 --> 00:18:20.486 A:middle
requestMediaDataWhenReady

00:18:20.486 --> 00:18:20.786 A:middle
method.

00:18:20.786 --> 00:18:22.496 A:middle
And what this is going to do is

00:18:22.496 --> 00:18:24.236 A:middle
it's going to call a closure in

00:18:24.236 --> 00:18:26.766 A:middle
my app so that I can feed the

00:18:26.766 --> 00:18:28.206 A:middle
AudioRenderer some more audio

00:18:28.206 --> 00:18:29.756 A:middle
data whenever the AudioRenderer

00:18:29.756 --> 00:18:30.826 A:middle
decides that it's ready to

00:18:30.826 --> 00:18:31.656 A:middle
receive more data.

00:18:32.396 --> 00:18:35.296 A:middle
And it will call this closure as

00:18:35.296 --> 00:18:37.116 A:middle
often as it needs to to stay

00:18:37.116 --> 00:18:39.116 A:middle
full of audio data.

00:18:40.796 --> 00:18:43.146 A:middle
Now within my closure, I'm

00:18:43.146 --> 00:18:44.666 A:middle
actually going to loop so that

00:18:44.986 --> 00:18:46.476 A:middle
I'm going to keep appending more

00:18:46.476 --> 00:18:47.566 A:middle
data as long as the

00:18:47.566 --> 00:18:49.426 A:middle
AudioRenderer is still ready for

00:18:49.426 --> 00:18:50.166 A:middle
more media data.

00:18:51.256 --> 00:18:52.886 A:middle
Within my loop, the first thing

00:18:52.886 --> 00:18:55.156 A:middle
I need to do is grab my next

00:18:55.156 --> 00:18:57.196 A:middle
chunk of audio data and package

00:18:57.196 --> 00:18:58.716 A:middle
it as a CMSampleBuffer.

00:18:59.366 --> 00:19:01.726 A:middle
Now this method here is my app's

00:19:01.826 --> 00:19:04.116 A:middle
own logic for doing this, for

00:19:04.116 --> 00:19:05.726 A:middle
grabbing its next little bit of

00:19:05.726 --> 00:19:06.366 A:middle
audio data.

00:19:06.776 --> 00:19:07.746 A:middle
Your app will have your own

00:19:07.746 --> 00:19:09.216 A:middle
version of this logic, maybe

00:19:09.216 --> 00:19:10.596 A:middle
pulling the data off the network

00:19:10.596 --> 00:19:11.876 A:middle
or decrypting it from disc.

00:19:11.876 --> 00:19:13.526 A:middle
If you want to see the details

00:19:13.526 --> 00:19:15.426 A:middle
of my version, once again, check

00:19:15.426 --> 00:19:16.376 A:middle
out the sample code.

00:19:17.156 --> 00:19:19.056 A:middle
And I have this set up to return

00:19:19.056 --> 00:19:20.796 A:middle
an optional CMSampleBuffer and

00:19:20.796 --> 00:19:22.716 A:middle
that's just so I can use a nil

00:19:22.716 --> 00:19:24.376 A:middle
return value to signal that I've

00:19:24.376 --> 00:19:26.926 A:middle
reached the end of data.

00:19:27.106 --> 00:19:28.976 A:middle
Once I have my sample buffer, I

00:19:28.976 --> 00:19:30.966 A:middle
turn around and enqueue it into

00:19:30.966 --> 00:19:32.046 A:middle
the AudioRenderer using the

00:19:32.046 --> 00:19:32.896 A:middle
enqueue method.

00:19:32.896 --> 00:19:35.026 A:middle
And what this will do is it will

00:19:35.026 --> 00:19:37.146 A:middle
hand the audio data off to the

00:19:37.146 --> 00:19:38.456 A:middle
renderer so that it can schedule

00:19:38.456 --> 00:19:39.406 A:middle
it to be played at the

00:19:39.406 --> 00:19:40.216 A:middle
appropriate time.

00:19:41.286 --> 00:19:43.286 A:middle
As I mentioned, I'm using a nil

00:19:43.566 --> 00:19:44.976 A:middle
sample buffer to signal that I

00:19:44.976 --> 00:19:46.016 A:middle
don't have any more data.

00:19:46.486 --> 00:19:47.776 A:middle
And when that happens I need to

00:19:47.776 --> 00:19:48.716 A:middle
explicitly tell the

00:19:48.716 --> 00:19:50.556 A:middle
AudioRenderer to stop requesting

00:19:50.556 --> 00:19:51.416 A:middle
more media data.

00:19:52.006 --> 00:19:53.406 A:middle
If I don't do this, and I exit

00:19:53.406 --> 00:19:55.376 A:middle
my closure, that AudioRenderer

00:19:55.376 --> 00:19:57.046 A:middle
is just going to invoke the

00:19:57.046 --> 00:19:58.896 A:middle
closure right away, when it's

00:19:58.896 --> 00:20:00.736 A:middle
ready for data again, but since

00:20:00.736 --> 00:20:01.616 A:middle
I don't have anything more to

00:20:01.616 --> 00:20:02.686 A:middle
give it, I don't want that to

00:20:02.686 --> 00:20:03.036 A:middle
happen.

00:20:03.106 --> 00:20:04.356 A:middle
So, I need to tell it to stop.

00:20:06.046 --> 00:20:07.796 A:middle
And this function here is pretty

00:20:07.796 --> 00:20:09.406 A:middle
much your entire interaction

00:20:09.406 --> 00:20:10.896 A:middle
with the AudioRenderer for a

00:20:10.896 --> 00:20:12.316 A:middle
simple use case like this.

00:20:13.476 --> 00:20:14.376 A:middle
Now, we need to do a couple

00:20:14.376 --> 00:20:15.146 A:middle
things with the

00:20:15.146 --> 00:20:16.166 A:middle
RenderSynchronizer.

00:20:16.706 --> 00:20:19.116 A:middle
I have a play method, and all

00:20:19.116 --> 00:20:21.066 A:middle
that play really is, is setting

00:20:21.066 --> 00:20:22.546 A:middle
the RenderSynchronizer's rate to

00:20:22.546 --> 00:20:23.906 A:middle
1, which will start playback.

00:20:23.906 --> 00:20:25.776 A:middle
I have a little bit of prep work

00:20:25.776 --> 00:20:26.836 A:middle
I need to do there, which we

00:20:26.836 --> 00:20:27.956 A:middle
won't look at the details, but

00:20:27.956 --> 00:20:29.576 A:middle
it does end up calling this

00:20:29.576 --> 00:20:30.826 A:middle
start enqueueing method so you

00:20:30.826 --> 00:20:32.036 A:middle
can sort of get a feel for how

00:20:32.036 --> 00:20:32.896 A:middle
things flow here.

00:20:33.376 --> 00:20:35.096 A:middle
And I have a little bit of UI

00:20:35.096 --> 00:20:36.636 A:middle
updating to do every time I play

00:20:36.636 --> 00:20:38.326 A:middle
or pause, so this method will

00:20:38.326 --> 00:20:39.886 A:middle
dispatch back to the main queue

00:20:39.886 --> 00:20:41.336 A:middle
in order to keep the UI up to

00:20:41.336 --> 00:20:41.586 A:middle
date.

00:20:42.106 --> 00:20:44.566 A:middle
Similarly, I have a pause

00:20:44.566 --> 00:20:45.736 A:middle
method, and the only difference

00:20:45.736 --> 00:20:47.376 A:middle
here is that it sets the

00:20:47.376 --> 00:20:49.376 A:middle
renderSynchronizer's rate to 0.

00:20:50.356 --> 00:20:52.796 A:middle
So, now you've seen all of the

00:20:52.796 --> 00:20:53.546 A:middle
interaction that we're going to

00:20:53.546 --> 00:20:54.846 A:middle
have with AVFoundation.

00:20:55.076 --> 00:20:56.396 A:middle
I have one more bit of code I

00:20:56.396 --> 00:20:57.576 A:middle
need to drop in, just to make

00:20:57.576 --> 00:20:59.326 A:middle
sure my app will build and work

00:20:59.326 --> 00:21:00.836 A:middle
correctly, which we won't look

00:21:00.836 --> 00:21:02.236 A:middle
at the details of, but I'll just

00:21:02.236 --> 00:21:02.846 A:middle
drop it there.

00:21:03.556 --> 00:21:05.586 A:middle
And then, we will rebuild the

00:21:05.586 --> 00:21:06.166 A:middle
application.

00:21:06.166 --> 00:21:09.036 A:middle
And I seem to have some

00:21:10.356 --> 00:21:11.666 A:middle
compilation errors.

00:21:12.296 --> 00:21:14.846 A:middle
So, what I'm going to do is

00:21:15.696 --> 00:21:18.266 A:middle
figure out what I did wrong.

00:21:31.666 --> 00:21:32.886 A:middle
Well, why don't we just take

00:21:32.966 --> 00:21:37.476 A:middle
this and, ah I think I know

00:21:37.476 --> 00:21:38.156 A:middle
what's wrong here.

00:21:52.256 --> 00:21:55.436 A:middle
Just drag that over here, and go

00:21:55.546 --> 00:21:58.606 A:middle
back here and we'll try again.

00:21:58.606 --> 00:22:04.156 A:middle
All right, so we got our build

00:22:04.156 --> 00:22:04.426 A:middle
ready.

00:22:04.896 --> 00:22:06.186 A:middle
And now we're relaunching the

00:22:06.186 --> 00:22:06.486 A:middle
app.

00:22:07.156 --> 00:22:08.446 A:middle
So, we'll switch back to our

00:22:08.446 --> 00:22:09.386 A:middle
side by side view.

00:22:09.386 --> 00:22:13.006 A:middle
And once the app finishes

00:22:13.046 --> 00:22:14.806 A:middle
launching, I'm going to go ahead

00:22:14.806 --> 00:22:16.906 A:middle
and restart the music playback.

00:22:18.716 --> 00:22:19.536 A:middle
Here we go.

00:22:19.726 --> 00:22:23.916 A:middle
And once the music starts

00:22:23.916 --> 00:22:25.646 A:middle
playing [music] now we're

00:22:25.646 --> 00:22:28.156 A:middle
playing using AirPlay 2 from the

00:22:28.156 --> 00:22:29.296 A:middle
phone to the Apple TV.

00:22:29.946 --> 00:22:31.266 A:middle
So, now I want to run the same

00:22:31.266 --> 00:22:33.656 A:middle
scenario that I did before using

00:22:34.066 --> 00:22:34.956 A:middle
our bag again.

00:22:35.606 --> 00:22:37.636 A:middle
So, let's grab the phone.

00:22:39.636 --> 00:22:41.086 A:middle
And we'll put it in the bag.

00:22:41.086 --> 00:22:42.606 A:middle
Once again, here's me taking the

00:22:42.706 --> 00:22:44.676 A:middle
phone outside, outside of Wi-Fi

00:22:44.676 --> 00:22:45.226 A:middle
range.

00:22:46.426 --> 00:22:47.766 A:middle
I'll fold up the bag nice and

00:22:47.766 --> 00:22:48.106 A:middle
tight.

00:22:49.036 --> 00:22:50.476 A:middle
And as you can see, where as in

00:22:50.476 --> 00:22:51.976 A:middle
the first demo, the music cut

00:22:51.976 --> 00:22:53.846 A:middle
out almost immediately, now that

00:22:53.846 --> 00:22:55.696 A:middle
we're using AirPlay 2, the music

00:22:55.696 --> 00:22:57.146 A:middle
can keep playing even through

00:22:57.146 --> 00:22:58.466 A:middle
these sorts of minor Wi-Fi

00:22:58.466 --> 00:22:59.036 A:middle
interruptions.

00:22:59.546 --> 00:23:00.796 A:middle
So, that's the power of AirPlay

00:23:00.796 --> 00:23:02.816 A:middle
2 using AVSampleBufferAudio

00:23:02.816 --> 00:23:03.146 A:middle
Renderer.

00:23:03.516 --> 00:23:04.956 A:middle
Thank you very much and back to

00:23:04.956 --> 00:23:05.256 A:middle
David.

00:23:07.071 --> 00:23:09.071 A:middle
[ Applause ]

00:23:09.126 --> 00:23:09.806 A:middle
&gt;&gt; Thank you, Adam.

00:23:10.396 --> 00:23:12.136 A:middle
So, now that we've shown, walked

00:23:12.136 --> 00:23:13.606 A:middle
you through the steps to create

00:23:13.606 --> 00:23:14.576 A:middle
a simple app with

00:23:14.576 --> 00:23:16.216 A:middle
AVSampleBufferAudio Renderer and

00:23:16.216 --> 00:23:17.106 A:middle
AVSampleBufferRender

00:23:17.106 --> 00:23:19.336 A:middle
Synchronizer, let's move on to

00:23:19.336 --> 00:23:20.986 A:middle
some more advanced playback

00:23:20.986 --> 00:23:22.406 A:middle
scenarios that you may be, you

00:23:22.406 --> 00:23:24.106 A:middle
may encounter when using these

00:23:24.106 --> 00:23:24.416 A:middle
API.

00:23:24.696 --> 00:23:27.366 A:middle
So, what we're going to talk

00:23:27.366 --> 00:23:29.456 A:middle
about in this section is audio

00:23:29.456 --> 00:23:30.446 A:middle
buffer levels of

00:23:30.726 --> 00:23:32.356 A:middle
AVSampleBufferAudio Renderer.

00:23:32.356 --> 00:23:34.026 A:middle
We're going to talk to about how

00:23:34.026 --> 00:23:36.146 A:middle
to implement a seek, how to

00:23:36.146 --> 00:23:38.106 A:middle
implement play queues, some of

00:23:38.106 --> 00:23:39.926 A:middle
the support audio formats with

00:23:39.926 --> 00:23:41.476 A:middle
AVSampleBufferAudio Renderer,

00:23:41.766 --> 00:23:42.806 A:middle
and lastly, we're going to take

00:23:42.806 --> 00:23:44.446 A:middle
a slight detour and talk about

00:23:44.446 --> 00:23:45.486 A:middle
video synchronization.

00:23:47.736 --> 00:23:49.416 A:middle
So, let's jump into the next

00:23:49.416 --> 00:23:51.496 A:middle
section and talk about the audio

00:23:51.496 --> 00:23:52.276 A:middle
buffer levels of

00:23:52.276 --> 00:23:53.566 A:middle
AVSampleBufferAudio Renderer.

00:23:54.546 --> 00:23:55.696 A:middle
So, what am I talking about?

00:23:55.696 --> 00:23:57.616 A:middle
I'm talking about the fact that

00:23:57.616 --> 00:23:59.836 A:middle
the amount of audio data request

00:23:59.836 --> 00:24:01.176 A:middle
by an AVSampleBufferAudio

00:24:01.176 --> 00:24:03.496 A:middle
Renderer of your app will vary

00:24:03.706 --> 00:24:05.886 A:middle
depending on the current route.

00:24:07.156 --> 00:24:08.506 A:middle
So, let's take a look at this

00:24:08.506 --> 00:24:09.016 A:middle
pictorially.

00:24:09.526 --> 00:24:10.886 A:middle
Here I've drawn a media timeline

00:24:10.886 --> 00:24:12.606 A:middle
and I'm going to drop in the

00:24:12.606 --> 00:24:13.036 A:middle
playhead.

00:24:14.456 --> 00:24:15.286 A:middle
And when you're playing back

00:24:15.286 --> 00:24:17.496 A:middle
locally, the AudioRenderer is

00:24:17.496 --> 00:24:18.566 A:middle
only going to ask for a few

00:24:18.566 --> 00:24:20.076 A:middle
seconds ahead of the playhead.

00:24:21.186 --> 00:24:23.256 A:middle
So, that is where the, that is

00:24:23.256 --> 00:24:24.866 A:middle
where you should enqueue to, as

00:24:24.866 --> 00:24:25.856 A:middle
much as it asks for.

00:24:27.146 --> 00:24:29.066 A:middle
And as you play, again you're

00:24:29.066 --> 00:24:30.036 A:middle
just going to enqueue a few

00:24:30.036 --> 00:24:31.606 A:middle
seconds ahead of the app.

00:24:32.996 --> 00:24:34.546 A:middle
But suppose your user suddenly

00:24:34.546 --> 00:24:36.926 A:middle
decides to route to an AirPlay 2

00:24:36.926 --> 00:24:37.326 A:middle
speaker.

00:24:38.596 --> 00:24:40.246 A:middle
Now when that happens, the

00:24:40.246 --> 00:24:42.146 A:middle
AVSampleBufferAudio Renderer is

00:24:42.146 --> 00:24:43.766 A:middle
going to ask for up to multiple

00:24:43.766 --> 00:24:45.016 A:middle
minutes ahead of the playhead.

00:24:46.306 --> 00:24:47.746 A:middle
And once again, when you hit

00:24:47.746 --> 00:24:49.276 A:middle
play, you'll work multiple

00:24:49.276 --> 00:24:50.286 A:middle
minutes ahead of the playhead.

00:24:51.376 --> 00:24:53.126 A:middle
Now the key here, is that the

00:24:53.126 --> 00:24:54.866 A:middle
amount of data requested by

00:24:54.866 --> 00:24:56.516 A:middle
AVSampleBufferAudio Renderer

00:24:56.936 --> 00:24:58.586 A:middle
varies depending on where the

00:24:58.586 --> 00:24:59.486 A:middle
audio is currently routed.

00:24:59.486 --> 00:25:01.716 A:middle
If it's routed locally, this

00:25:01.716 --> 00:25:03.126 A:middle
will just be seconds, to

00:25:03.126 --> 00:25:04.716 A:middle
Bluetooth seconds, to an AirPlay

00:25:04.716 --> 00:25:06.236 A:middle
1 speaker seconds.

00:25:07.236 --> 00:25:08.806 A:middle
But as soon as the user routes

00:25:08.806 --> 00:25:10.846 A:middle
your audio content to an AirPlay

00:25:10.846 --> 00:25:13.616 A:middle
2 speaker, that AudioRenderer is

00:25:13.616 --> 00:25:14.556 A:middle
going to get really hungry and

00:25:14.556 --> 00:25:15.686 A:middle
it's going to ask for multiple

00:25:15.686 --> 00:25:16.816 A:middle
minutes of audio data.

00:25:18.096 --> 00:25:19.326 A:middle
And the key here is that your

00:25:19.326 --> 00:25:20.376 A:middle
app should be ready to handle

00:25:20.376 --> 00:25:21.016 A:middle
these changes.

00:25:21.516 --> 00:25:25.146 A:middle
All right, next let's talk about

00:25:25.146 --> 00:25:25.516 A:middle
seek.

00:25:26.856 --> 00:25:27.936 A:middle
So, what is a seek?

00:25:28.136 --> 00:25:29.856 A:middle
Well a seek very quick, very

00:25:29.856 --> 00:25:31.816 A:middle
simply, is manually changing the

00:25:31.816 --> 00:25:32.796 A:middle
location of the playhead.

00:25:33.876 --> 00:25:35.046 A:middle
So, again let's draw out our

00:25:35.046 --> 00:25:36.526 A:middle
media timeline that we just saw

00:25:36.526 --> 00:25:37.366 A:middle
a moment ago.

00:25:38.176 --> 00:25:40.006 A:middle
Put in the playhead, and talk

00:25:40.006 --> 00:25:42.276 A:middle
about local play or talk about

00:25:42.876 --> 00:25:44.036 A:middle
standard playback scenario.

00:25:44.716 --> 00:25:46.836 A:middle
User hits play, and then after

00:25:46.836 --> 00:25:48.286 A:middle
it plays for a little bit the

00:25:48.286 --> 00:25:49.496 A:middle
user decides you know what, I

00:25:49.496 --> 00:25:51.206 A:middle
want to seek further into the

00:25:51.206 --> 00:25:51.576 A:middle
track.

00:25:51.576 --> 00:25:52.956 A:middle
So, they pick up the playhead

00:25:52.956 --> 00:25:54.206 A:middle
and they drag it.

00:25:55.076 --> 00:25:56.506 A:middle
So, they've asked for a seek.

00:25:57.046 --> 00:25:59.496 A:middle
So, how do we handle this with

00:25:59.496 --> 00:26:00.806 A:middle
AVSampleBufferAudio Renderer?

00:26:01.366 --> 00:26:02.626 A:middle
Well it's actually really easy.

00:26:03.696 --> 00:26:04.496 A:middle
The first thing that you're

00:26:04.496 --> 00:26:05.296 A:middle
going to do is you're going to

00:26:05.296 --> 00:26:05.716 A:middle
stop.

00:26:05.836 --> 00:26:07.606 A:middle
You're going to stop playback of

00:26:07.606 --> 00:26:08.986 A:middle
the AVSampleBufferRender

00:26:08.986 --> 00:26:10.326 A:middle
Synchronizer and you're going to

00:26:10.326 --> 00:26:12.416 A:middle
stop enqueueing media data into

00:26:12.416 --> 00:26:13.376 A:middle
the AVSampleBufferAudio

00:26:13.376 --> 00:26:13.666 A:middle
Renderer.

00:26:14.176 --> 00:26:17.226 A:middle
Next, you're going to issue a

00:26:17.226 --> 00:26:18.356 A:middle
flush on the

00:26:18.356 --> 00:26:19.956 A:middle
SampleBufferAudioRenderer which

00:26:19.956 --> 00:26:21.556 A:middle
will clear out all media data

00:26:21.556 --> 00:26:22.566 A:middle
that's already been enqueued.

00:26:23.106 --> 00:26:25.716 A:middle
And at that point, you're free

00:26:25.716 --> 00:26:27.646 A:middle
to begin audio, re-enqueueing

00:26:27.646 --> 00:26:30.456 A:middle
audio data at any media time, so

00:26:30.456 --> 00:26:32.786 A:middle
you do it beginning at the seek

00:26:32.786 --> 00:26:33.256 A:middle
to time.

00:26:33.796 --> 00:26:36.216 A:middle
And after you've enqueued media

00:26:36.216 --> 00:26:38.246 A:middle
data the seek to time, kick off

00:26:38.246 --> 00:26:39.846 A:middle
playback once again and there

00:26:39.846 --> 00:26:40.146 A:middle
you go.

00:26:40.216 --> 00:26:43.876 A:middle
So, that's a seek.

00:26:45.096 --> 00:26:46.586 A:middle
So, now that I've shown you how

00:26:46.586 --> 00:26:47.926 A:middle
seek works, let's take a look at

00:26:47.926 --> 00:26:49.046 A:middle
how you would implement that in

00:26:49.046 --> 00:26:51.266 A:middle
code, by extending Adam's app

00:26:51.806 --> 00:26:52.686 A:middle
with a method called

00:26:52.686 --> 00:26:53.516 A:middle
seek(toMediaTime.

00:26:54.626 --> 00:26:55.846 A:middle
So, how do we implement this?

00:26:56.116 --> 00:26:56.926 A:middle
Well it's pretty easy.

00:26:57.336 --> 00:26:58.536 A:middle
The first thing we're going to

00:26:58.536 --> 00:26:59.936 A:middle
do is we're going to tell the

00:26:59.936 --> 00:27:01.246 A:middle
renderSynchronizer to stop

00:27:01.246 --> 00:27:02.756 A:middle
playback by setting the rate to

00:27:02.756 --> 00:27:03.156 A:middle
0.

00:27:03.966 --> 00:27:04.766 A:middle
And then we're going to tell the

00:27:04.766 --> 00:27:06.286 A:middle
AudioRenderer to stop requesting

00:27:06.286 --> 00:27:07.456 A:middle
media data.

00:27:08.406 --> 00:27:10.056 A:middle
Next, we're going flush the

00:27:10.056 --> 00:27:11.556 A:middle
AudioRenderer to clear out all

00:27:11.556 --> 00:27:12.666 A:middle
the old audio data we've

00:27:12.666 --> 00:27:13.106 A:middle
enqueued.

00:27:14.436 --> 00:27:15.516 A:middle
And then we're going to call

00:27:15.516 --> 00:27:17.706 A:middle
some app specific code, that

00:27:17.706 --> 00:27:20.016 A:middle
tells your sample generating

00:27:20.016 --> 00:27:21.346 A:middle
code that the next sample that

00:27:21.346 --> 00:27:23.056 A:middle
it should prepare is at that

00:27:23.056 --> 00:27:23.906 A:middle
seek to time.

00:27:24.346 --> 00:27:26.066 A:middle
Remember your app is responsible

00:27:26.066 --> 00:27:27.556 A:middle
for producing the audio data

00:27:28.176 --> 00:27:30.706 A:middle
when using this API, so you need

00:27:30.706 --> 00:27:32.226 A:middle
to instruct it where the next

00:27:32.226 --> 00:27:33.596 A:middle
audio sample should be generated

00:27:33.596 --> 00:27:33.916 A:middle
from.

00:27:34.446 --> 00:27:37.046 A:middle
And after that happens, you can

00:27:37.046 --> 00:27:38.516 A:middle
reinstall your closure on the

00:27:38.516 --> 00:27:40.006 A:middle
AudioRenderer to tell it to call

00:27:40.006 --> 00:27:41.296 A:middle
you back for more audio data.

00:27:41.986 --> 00:27:43.426 A:middle
And you can set a rate to 1 on

00:27:43.426 --> 00:27:44.246 A:middle
the RenderSynchronizer.

00:27:45.556 --> 00:27:46.216 A:middle
Pretty simple.

00:27:46.526 --> 00:27:47.136 A:middle
So, that's seek.

00:27:47.586 --> 00:27:49.976 A:middle
Let's get into something more

00:27:49.976 --> 00:27:50.946 A:middle
interesting which is play

00:27:50.946 --> 00:27:51.406 A:middle
queues.

00:27:51.406 --> 00:27:53.576 A:middle
And what is a play queue?

00:27:53.576 --> 00:27:54.716 A:middle
Well here we have a screenshot

00:27:54.716 --> 00:27:55.286 A:middle
from Adam's app.

00:27:55.856 --> 00:27:57.516 A:middle
And a play queue is very simple

00:27:57.516 --> 00:27:59.686 A:middle
is, you know, you order a set of

00:27:59.686 --> 00:28:00.086 A:middle
items.

00:28:00.086 --> 00:28:01.396 A:middle
I hit play on one and they all

00:28:01.396 --> 00:28:02.176 A:middle
play out in order.

00:28:02.616 --> 00:28:05.756 A:middle
So, if we take these, this play

00:28:05.756 --> 00:28:06.976 A:middle
queue and we lay it out on that

00:28:07.046 --> 00:28:08.616 A:middle
media timeline, what we're going

00:28:08.616 --> 00:28:09.896 A:middle
to see is Item 1 followed by

00:28:09.896 --> 00:28:11.876 A:middle
Item 2, followed by Item 3.

00:28:13.156 --> 00:28:14.956 A:middle
That's just a very generic look

00:28:14.956 --> 00:28:16.896 A:middle
of those items laid out on this

00:28:16.896 --> 00:28:17.826 A:middle
timeline we've been showing.

00:28:18.606 --> 00:28:19.886 A:middle
But if we dig into the timelines

00:28:19.886 --> 00:28:22.026 A:middle
especially we're going to see

00:28:22.026 --> 00:28:23.196 A:middle
the timelines of each item,

00:28:23.196 --> 00:28:24.076 A:middle
we're going to see something

00:28:24.076 --> 00:28:24.806 A:middle
slightly different.

00:28:25.116 --> 00:28:26.416 A:middle
Let's suppose hypothetically

00:28:26.416 --> 00:28:27.996 A:middle
that each item is 100 seconds in

00:28:27.996 --> 00:28:28.346 A:middle
length.

00:28:29.426 --> 00:28:30.886 A:middle
That means that each item will

00:28:30.886 --> 00:28:33.936 A:middle
go from 0 to 100, 0 to 100, 0 to

00:28:33.936 --> 00:28:34.336 A:middle
100.

00:28:34.896 --> 00:28:38.636 A:middle
Of course the AudioRenderer

00:28:38.636 --> 00:28:39.986 A:middle
knows nothing about these

00:28:39.986 --> 00:28:40.996 A:middle
individual items.

00:28:41.266 --> 00:28:42.536 A:middle
All the AudioRenderer has is a

00:28:42.536 --> 00:28:43.816 A:middle
continuous media timeline.

00:28:45.146 --> 00:28:46.606 A:middle
So, as you enqueue audio data

00:28:46.836 --> 00:28:48.596 A:middle
into the AVSampleBufferAudio

00:28:48.596 --> 00:28:51.096 A:middle
Renderer, you may need to offset

00:28:51.736 --> 00:28:53.946 A:middle
from the item's natural timeline

00:28:54.056 --> 00:28:55.816 A:middle
to the continuous timeline of

00:28:55.816 --> 00:28:57.086 A:middle
the AVSampleBufferAudio

00:28:57.086 --> 00:28:57.336 A:middle
Renderer.

00:28:57.896 --> 00:29:00.396 A:middle
And again, let's take a look at

00:29:00.396 --> 00:29:01.976 A:middle
this enqueuing animation that

00:29:01.976 --> 00:29:02.746 A:middle
we've seen before.

00:29:03.356 --> 00:29:05.076 A:middle
Here are I'm playing back

00:29:05.076 --> 00:29:06.226 A:middle
locally and I've just enqueued a

00:29:06.226 --> 00:29:07.266 A:middle
few seconds ahead of the

00:29:07.496 --> 00:29:09.406 A:middle
playhead and as you can see I'm

00:29:09.406 --> 00:29:10.966 A:middle
going to queue each item as I go

00:29:10.966 --> 00:29:11.486 A:middle
through it.

00:29:12.346 --> 00:29:13.606 A:middle
And if the user is routed to an

00:29:13.606 --> 00:29:14.806 A:middle
AirPlay 2 speaker, and we're

00:29:14.806 --> 00:29:15.676 A:middle
working well ahead of the

00:29:15.676 --> 00:29:16.846 A:middle
playhead, same idea.

00:29:16.846 --> 00:29:18.156 A:middle
You're just going to enqueue

00:29:18.156 --> 00:29:20.176 A:middle
ever so slightly ahead of the

00:29:21.136 --> 00:29:21.336 A:middle
playhead.

00:29:21.366 --> 00:29:21.836 A:middle
All right.

00:29:22.646 --> 00:29:24.426 A:middle
So, that's the simple idea of

00:29:24.426 --> 00:29:24.896 A:middle
play queues.

00:29:24.896 --> 00:29:25.566 A:middle
Let's get into something a

00:29:25.566 --> 00:29:26.536 A:middle
little more interesting,

00:29:26.776 --> 00:29:27.316 A:middle
editing.

00:29:28.566 --> 00:29:29.566 A:middle
And in this hypothetical

00:29:29.566 --> 00:29:32.266 A:middle
example, let's suppose the user

00:29:32.266 --> 00:29:33.206 A:middle
decides they don't want to

00:29:33.206 --> 00:29:34.226 A:middle
listen to Item 2 anymore.

00:29:34.466 --> 00:29:35.746 A:middle
So, they remove it from the

00:29:35.746 --> 00:29:37.916 A:middle
queue, and so items 3 and 4

00:29:37.916 --> 00:29:41.486 A:middle
shift over in place.

00:29:41.606 --> 00:29:43.836 A:middle
Now, when that happens, it's not

00:29:43.836 --> 00:29:44.326 A:middle
a big deal.

00:29:44.536 --> 00:29:46.806 A:middle
The user will expect Item 1 to

00:29:46.806 --> 00:29:48.516 A:middle
play, followed by Item 3, and

00:29:48.516 --> 00:29:49.296 A:middle
followed by Item 4.

00:29:49.826 --> 00:29:52.166 A:middle
But that's a really relatively

00:29:52.166 --> 00:29:53.186 A:middle
simple case of play queue

00:29:53.186 --> 00:29:56.416 A:middle
editing, where I, made the edit

00:29:56.756 --> 00:29:58.106 A:middle
before playback is engaged.

00:30:00.086 --> 00:30:01.516 A:middle
But since we're working well

00:30:01.516 --> 00:30:03.776 A:middle
ahead of the playhead oftentimes

00:30:03.776 --> 00:30:04.206 A:middle
when using the

00:30:04.206 --> 00:30:05.586 A:middle
AVSampleBufferAudio Renderer,

00:30:06.176 --> 00:30:07.376 A:middle
you could run into a situation

00:30:07.376 --> 00:30:10.146 A:middle
like this, where the user is

00:30:10.146 --> 00:30:11.456 A:middle
instantiating, or initiated

00:30:11.456 --> 00:30:12.346 A:middle
playback.

00:30:12.946 --> 00:30:15.436 A:middle
You're still playing Item 1, but

00:30:15.436 --> 00:30:17.646 A:middle
you've begin to enqueue media

00:30:17.646 --> 00:30:18.886 A:middle
data from Item 2.

00:30:19.426 --> 00:30:22.136 A:middle
And then the user decides they

00:30:22.136 --> 00:30:22.996 A:middle
don't want to listen to Item 2

00:30:22.996 --> 00:30:23.276 A:middle
anymore.

00:30:23.276 --> 00:30:25.966 A:middle
So, what the user expects is

00:30:25.966 --> 00:30:28.496 A:middle
Item 2 disappears, Items 3 and 4

00:30:28.496 --> 00:30:29.046 A:middle
shift over.

00:30:29.616 --> 00:30:33.266 A:middle
And once again, what the user

00:30:33.266 --> 00:30:35.356 A:middle
expects is that after Item 1,

00:30:35.356 --> 00:30:36.226 A:middle
the currently playing track

00:30:36.226 --> 00:30:37.886 A:middle
plays, Item 3 will begin to

00:30:37.886 --> 00:30:38.166 A:middle
play.

00:30:39.576 --> 00:30:40.576 A:middle
But if we do nothing at this

00:30:40.576 --> 00:30:41.646 A:middle
point, since we've already

00:30:41.646 --> 00:30:43.586 A:middle
enqueued audio data from Item 2

00:30:43.586 --> 00:30:45.146 A:middle
into the AudioRenderer, well

00:30:45.146 --> 00:30:46.196 A:middle
that's what we're going to hear,

00:30:46.286 --> 00:30:48.916 A:middle
a blip of that, because we have

00:30:48.916 --> 00:30:50.356 A:middle
the wrong audio data in the

00:30:50.356 --> 00:30:50.906 A:middle
AudioRenderer.

00:30:51.506 --> 00:30:54.046 A:middle
So, what do we do here?

00:30:54.636 --> 00:30:55.706 A:middle
Well it's actually relatively

00:30:55.706 --> 00:30:57.336 A:middle
simple to handle, because

00:30:57.336 --> 00:30:58.666 A:middle
there's a command called Flush

00:30:58.666 --> 00:30:59.506 A:middle
from Source Time.

00:31:00.746 --> 00:31:01.866 A:middle
And what this command Flush from

00:31:01.866 --> 00:31:03.686 A:middle
Source Time does, what it means,

00:31:03.686 --> 00:31:05.436 A:middle
is that given this time that I

00:31:05.436 --> 00:31:07.046 A:middle
specify to you, I want you to

00:31:07.046 --> 00:31:08.776 A:middle
throw away all of the media data

00:31:08.776 --> 00:31:11.056 A:middle
on the timeline after it.

00:31:11.256 --> 00:31:12.596 A:middle
So, here I'm going to call Flush

00:31:12.596 --> 00:31:15.226 A:middle
from Source Time with the source

00:31:15.226 --> 00:31:18.146 A:middle
time pointing at the time in the

00:31:18.176 --> 00:31:20.016 A:middle
continuous timeline that it's

00:31:20.016 --> 00:31:22.176 A:middle
the transition from Item 1 to

00:31:22.176 --> 00:31:22.756 A:middle
the next item.

00:31:23.326 --> 00:31:24.296 A:middle
So, I call that and it throws

00:31:24.296 --> 00:31:25.056 A:middle
away all the media data.

00:31:25.056 --> 00:31:27.876 A:middle
Next thing that it does, is it

00:31:27.876 --> 00:31:29.286 A:middle
resets the pointer to the last

00:31:29.286 --> 00:31:31.206 A:middle
enqueued sample buffer to that

00:31:31.356 --> 00:31:33.226 A:middle
source time, so then I'm free to

00:31:33.226 --> 00:31:35.186 A:middle
enqueue media data from Item 3.

00:31:36.416 --> 00:31:37.436 A:middle
And of course, playback

00:31:37.436 --> 00:31:39.166 A:middle
progresses and we're good to go.

00:31:40.116 --> 00:31:42.076 A:middle
The key point about this is, for

00:31:42.076 --> 00:31:44.006 A:middle
the animation purposes in this

00:31:44.006 --> 00:31:46.796 A:middle
talk, I showed it may look like

00:31:46.796 --> 00:31:48.486 A:middle
playback was paused, but you can

00:31:48.486 --> 00:31:49.856 A:middle
actually execute this command

00:31:50.026 --> 00:31:51.716 A:middle
while playback is engaged, so it

00:31:51.716 --> 00:31:53.166 A:middle
can be totally transparent to

00:31:53.166 --> 00:31:53.736 A:middle
your users.

00:31:55.936 --> 00:31:56.826 A:middle
All right.

00:31:57.396 --> 00:31:58.876 A:middle
So, let's talk about the steps

00:31:58.876 --> 00:32:00.336 A:middle
involved in executing the flush

00:32:00.336 --> 00:32:01.036 A:middle
from source time.

00:32:01.036 --> 00:32:02.356 A:middle
There's basically three of them.

00:32:02.356 --> 00:32:04.026 A:middle
First is, stop enqueueing audio

00:32:04.026 --> 00:32:04.846 A:middle
data in the renderer.

00:32:05.166 --> 00:32:06.566 A:middle
Note that I'm not saying stop

00:32:06.706 --> 00:32:07.726 A:middle
playback, because again you

00:32:07.726 --> 00:32:08.386 A:middle
don't have to do that.

00:32:09.226 --> 00:32:09.876 A:middle
Then you issue the

00:32:09.876 --> 00:32:12.196 A:middle
flushfromSourceTime and after

00:32:12.196 --> 00:32:12.766 A:middle
you've issued the

00:32:12.766 --> 00:32:14.856 A:middle
flushfromSourceTime, well that

00:32:14.856 --> 00:32:15.896 A:middle
flush from source is an

00:32:15.896 --> 00:32:17.886 A:middle
asynchronous option, operation

00:32:18.066 --> 00:32:19.396 A:middle
into which you pass a closure.

00:32:19.986 --> 00:32:20.756 A:middle
Well, you should wait for the

00:32:20.756 --> 00:32:21.586 A:middle
callback to be called.

00:32:22.126 --> 00:32:25.946 A:middle
Now there are few gotchas with

00:32:25.946 --> 00:32:26.716 A:middle
this, even though it's a

00:32:26.716 --> 00:32:28.046 A:middle
relatively simple operation, and

00:32:28.046 --> 00:32:29.526 A:middle
the first is that the flush may

00:32:29.526 --> 00:32:29.866 A:middle
fail.

00:32:30.746 --> 00:32:31.736 A:middle
Now, why may it fail?

00:32:32.236 --> 00:32:34.096 A:middle
Well, suppose the source time

00:32:34.096 --> 00:32:35.536 A:middle
the you specified is too close

00:32:35.536 --> 00:32:36.896 A:middle
to or behind the playhead.

00:32:37.706 --> 00:32:39.426 A:middle
Well in those situations, we may

00:32:39.426 --> 00:32:40.486 A:middle
not be able to get the audio

00:32:40.486 --> 00:32:41.686 A:middle
data back from the audio

00:32:41.686 --> 00:32:42.076 A:middle
hardware.

00:32:43.336 --> 00:32:46.066 A:middle
And in those cases well, rather

00:32:46.066 --> 00:32:47.866 A:middle
than leaving you in an unknown

00:32:47.866 --> 00:32:49.806 A:middle
state where you may play out

00:32:49.806 --> 00:32:51.366 A:middle
stale data, we're just going to

00:32:51.366 --> 00:32:52.986 A:middle
fail the operation and it's, and

00:32:52.986 --> 00:32:54.946 A:middle
it's going to be as if it was

00:32:54.946 --> 00:32:57.536 A:middle
never issued in the first place.

00:32:57.716 --> 00:32:59.326 A:middle
So, the second gotcha which is

00:32:59.326 --> 00:33:00.536 A:middle
really just the other side of

00:33:00.536 --> 00:33:01.886 A:middle
the same coin is that you need

00:33:01.886 --> 00:33:02.826 A:middle
to wait for the callback.

00:33:03.296 --> 00:33:05.146 A:middle
So, you should wait for the

00:33:05.146 --> 00:33:06.346 A:middle
callback which will tell you

00:33:06.346 --> 00:33:07.246 A:middle
whether or not that flush

00:33:07.246 --> 00:33:10.326 A:middle
failed, and if it did you need

00:33:10.326 --> 00:33:11.346 A:middle
to take the appropriate action.

00:33:12.056 --> 00:33:12.986 A:middle
So, let's take a look at this in

00:33:12.986 --> 00:33:14.566 A:middle
code, again by extended the

00:33:14.566 --> 00:33:17.036 A:middle
sample app by calling a method

00:33:17.036 --> 00:33:18.246 A:middle
called -- by implementing a

00:33:18.246 --> 00:33:18.906 A:middle
method called

00:33:19.396 --> 00:33:21.726 A:middle
FlushfromSourceTime, perform

00:33:21.726 --> 00:33:22.506 A:middle
FlushfromSourceTime.

00:33:23.656 --> 00:33:26.836 A:middle
So, once again, in this method

00:33:26.966 --> 00:33:28.156 A:middle
the first thing you're going to

00:33:28.156 --> 00:33:28.906 A:middle
do is you're going to tell the

00:33:28.906 --> 00:33:30.366 A:middle
AudioRenderer to stop requesting

00:33:30.366 --> 00:33:30.866 A:middle
media data.

00:33:31.746 --> 00:33:33.046 A:middle
And then you're likely to call

00:33:33.046 --> 00:33:34.886 A:middle
some app specific logic to

00:33:34.886 --> 00:33:36.296 A:middle
really ensure that no media,

00:33:36.296 --> 00:33:37.956 A:middle
additional media data is

00:33:37.956 --> 00:33:38.776 A:middle
enqueued.

00:33:38.776 --> 00:33:40.646 A:middle
This is really important,

00:33:40.886 --> 00:33:42.056 A:middle
because this is an asynchronous

00:33:42.056 --> 00:33:43.316 A:middle
operation so it's naturally

00:33:43.316 --> 00:33:43.736 A:middle
racy.

00:33:44.166 --> 00:33:44.986 A:middle
So, we want to make sure that

00:33:44.986 --> 00:33:46.136 A:middle
you're not enqueueing any

00:33:46.136 --> 00:33:47.646 A:middle
additional audio data while that

00:33:47.646 --> 00:33:49.276 A:middle
FlushfromSourceTime is flight.

00:33:49.766 --> 00:33:52.466 A:middle
So, after you've made sure that

00:33:52.466 --> 00:33:53.586 A:middle
you're no longer enqueueing

00:33:53.586 --> 00:33:54.826 A:middle
audio data in the AudioRenderer,

00:33:55.196 --> 00:33:56.426 A:middle
you can actually execute the

00:33:56.426 --> 00:33:57.416 A:middle
FlushfromSourceTime.

00:33:57.876 --> 00:33:59.296 A:middle
Again, you'll pass in a closure

00:33:59.296 --> 00:34:00.506 A:middle
because this is an asynchronous

00:34:00.666 --> 00:34:01.306 A:middle
operation.

00:34:01.416 --> 00:34:02.846 A:middle
And then closure will tell you

00:34:02.846 --> 00:34:04.846 A:middle
then whether or not the call to

00:34:04.846 --> 00:34:05.616 A:middle
the closure will tell you

00:34:05.616 --> 00:34:06.296 A:middle
whether or not the flush

00:34:06.296 --> 00:34:06.886 A:middle
succeeded.

00:34:07.606 --> 00:34:09.196 A:middle
If it succeeded as I'm showing

00:34:09.196 --> 00:34:11.486 A:middle
here, well, the first thing

00:34:11.486 --> 00:34:12.546 A:middle
you're going to do is again

00:34:12.546 --> 00:34:13.506 A:middle
you're going to tell your sample

00:34:13.506 --> 00:34:15.266 A:middle
generating app, your app's

00:34:15.546 --> 00:34:17.856 A:middle
sample generating code to begin

00:34:17.986 --> 00:34:19.816 A:middle
preparing samples at that source

00:34:19.816 --> 00:34:20.036 A:middle
time.

00:34:20.736 --> 00:34:22.036 A:middle
And then you can reinstall your

00:34:22.036 --> 00:34:23.546 A:middle
callback closure and begin

00:34:23.546 --> 00:34:24.756 A:middle
enqueueing again.

00:34:25.696 --> 00:34:27.586 A:middle
Of course, the flush may fail,

00:34:27.996 --> 00:34:29.456 A:middle
in here it's really app specific

00:34:29.456 --> 00:34:30.886 A:middle
logic to decide what you want to

00:34:30.886 --> 00:34:32.056 A:middle
do in these situations.

00:34:32.786 --> 00:34:33.926 A:middle
Maybe you want to just advance

00:34:33.926 --> 00:34:34.736 A:middle
to the next track.

00:34:34.736 --> 00:34:35.946 A:middle
Maybe you want to execute a full

00:34:35.946 --> 00:34:37.656 A:middle
flush and glitch playback, it's

00:34:37.656 --> 00:34:38.216 A:middle
really up to you.

00:34:38.786 --> 00:34:43.286 A:middle
So, that's play queues and Flush

00:34:43.286 --> 00:34:44.086 A:middle
from Source Time.

00:34:44.856 --> 00:34:47.676 A:middle
Let's move on to the supported

00:34:47.676 --> 00:34:48.646 A:middle
audio formats in

00:34:48.646 --> 00:34:49.746 A:middle
AVSampleBufferAudio Renderer.

00:34:51.656 --> 00:34:53.156 A:middle
So, what audio formats does the

00:34:53.156 --> 00:34:55.086 A:middle
AVSampleBufferAudio Renderer

00:34:55.086 --> 00:34:55.516 A:middle
support?

00:34:55.516 --> 00:34:57.886 A:middle
Well good news, basically all

00:34:57.886 --> 00:34:59.376 A:middle
platform supported audio formats

00:34:59.376 --> 00:35:00.596 A:middle
are also supported by the

00:35:00.596 --> 00:35:01.816 A:middle
AVSampleBufferAudio Renderer.

00:35:01.906 --> 00:35:04.526 A:middle
So, this includes LPCM, AAC,

00:35:04.556 --> 00:35:07.376 A:middle
mp3, Apple Lossless, lots of

00:35:07.376 --> 00:35:09.506 A:middle
sample rates, lots of bit

00:35:10.556 --> 00:35:10.756 A:middle
depths.

00:35:10.866 --> 00:35:13.126 A:middle
And additionally, mixed formats

00:35:13.126 --> 00:35:13.886 A:middle
may be enqueued.

00:35:14.466 --> 00:35:17.346 A:middle
If Item 1 is AAC at 44.1 you can

00:35:17.346 --> 00:35:19.556 A:middle
then enqueue that and then MP3

00:35:19.556 --> 00:35:23.376 A:middle
at 48k and 16bit Apple Lossless

00:35:23.786 --> 00:35:24.976 A:middle
at 48 kilohertz.

00:35:25.156 --> 00:35:26.836 A:middle
You can just enqueue the audio

00:35:26.836 --> 00:35:28.036 A:middle
data from each of these back to

00:35:28.036 --> 00:35:29.196 A:middle
back and we will take care of

00:35:29.196 --> 00:35:30.406 A:middle
the format transitions for you.

00:35:31.466 --> 00:35:33.236 A:middle
So, those are the supported

00:35:33.236 --> 00:35:33.616 A:middle
formats.

00:35:33.826 --> 00:35:34.866 A:middle
Let's talk about the preferred

00:35:34.866 --> 00:35:35.386 A:middle
formats.

00:35:35.926 --> 00:35:38.706 A:middle
So, because we can play anything

00:35:38.706 --> 00:35:39.716 A:middle
just give us what you got.

00:35:39.766 --> 00:35:41.176 A:middle
You have LPCM, give it to us,

00:35:41.176 --> 00:35:42.166 A:middle
encoded give it to us.

00:35:42.656 --> 00:35:44.276 A:middle
But one caveat there is all

00:35:44.276 --> 00:35:46.186 A:middle
things being equal, if you have

00:35:46.186 --> 00:35:48.846 A:middle
a decision between encoded or

00:35:48.846 --> 00:35:50.126 A:middle
PCM, we would prefer the

00:35:50.126 --> 00:35:51.576 A:middle
encoded, but don't do any

00:35:51.576 --> 00:35:53.196 A:middle
special logic to give us that.

00:35:53.286 --> 00:35:54.126 A:middle
Just give us what you have.

00:35:55.416 --> 00:35:56.476 A:middle
And we prefer interleaved

00:35:56.476 --> 00:35:58.336 A:middle
channel formats and 1 to 2

00:35:58.336 --> 00:35:59.536 A:middle
seconds of audio per

00:35:59.536 --> 00:36:00.366 A:middle
CMSampleBuffer.

00:36:00.366 --> 00:36:03.946 A:middle
All right, now I'd like to take

00:36:03.946 --> 00:36:05.326 A:middle
a slight detour and talk about

00:36:05.326 --> 00:36:06.356 A:middle
video synchronization.

00:36:07.656 --> 00:36:08.606 A:middle
Now, you may be wondering why

00:36:08.606 --> 00:36:09.996 A:middle
we're talking about video in a

00:36:09.996 --> 00:36:11.776 A:middle
AirPlay talk that's mainly about

00:36:11.776 --> 00:36:12.226 A:middle
audio.

00:36:13.196 --> 00:36:15.196 A:middle
And it's because the classes

00:36:15.196 --> 00:36:16.466 A:middle
that we're introducing today not

00:36:16.466 --> 00:36:18.706 A:middle
only are they good for AirPlay 2

00:36:18.886 --> 00:36:19.796 A:middle
but they're also just really

00:36:19.796 --> 00:36:21.346 A:middle
good playback APIs for general

00:36:21.346 --> 00:36:22.056 A:middle
use cases.

00:36:22.666 --> 00:36:24.036 A:middle
And you may want to use them to

00:36:24.036 --> 00:36:24.656 A:middle
play video.

00:36:25.226 --> 00:36:26.836 A:middle
Now, once again, if you can use

00:36:26.836 --> 00:36:28.186 A:middle
AVPlayer, please use that.

00:36:28.186 --> 00:36:29.946 A:middle
But if you can't use AVPlayer

00:36:29.946 --> 00:36:31.636 A:middle
and you want to play video, here

00:36:32.236 --> 00:36:33.066 A:middle
you go.

00:36:33.416 --> 00:36:36.496 A:middle
So, let's refer, jump back to a

00:36:36.496 --> 00:36:37.686 A:middle
block diagram that we showed

00:36:37.686 --> 00:36:38.786 A:middle
earlier in the presentation.

00:36:38.936 --> 00:36:40.506 A:middle
We've got the Client App, the

00:36:40.506 --> 00:36:41.206 A:middle
AudioRenderer and the

00:36:41.206 --> 00:36:41.766 A:middle
Synchronizer.

00:36:42.586 --> 00:36:43.826 A:middle
Well, if I simply move those out

00:36:43.826 --> 00:36:45.206 A:middle
of the way, I can make room for

00:36:45.206 --> 00:36:47.426 A:middle
a new renderer class and here

00:36:47.426 --> 00:36:48.396 A:middle
I'm going to add an

00:36:48.396 --> 00:36:49.626 A:middle
AVSampleBufferDisplayLayer.

00:36:50.556 --> 00:36:51.766 A:middle
Now for those of you who are

00:36:51.766 --> 00:36:52.366 A:middle
unfamiliar with

00:36:52.366 --> 00:36:54.596 A:middle
AVSampleBufferDisplayLayer, it's

00:36:54.596 --> 00:36:56.176 A:middle
a class similar to the new

00:36:56.176 --> 00:36:57.546 A:middle
AVSampleBufferAudio Renderer,

00:36:57.756 --> 00:36:58.956 A:middle
except this one is geared

00:36:58.956 --> 00:36:59.716 A:middle
towards video.

00:37:00.136 --> 00:37:01.026 A:middle
It's been around for quite a

00:37:01.026 --> 00:37:01.546 A:middle
while and there's some

00:37:01.546 --> 00:37:04.256 A:middle
documentation and sample code on

00:37:04.256 --> 00:37:05.196 A:middle
the developer website.

00:37:06.166 --> 00:37:09.136 A:middle
But new in these releases is the

00:37:09.136 --> 00:37:10.266 A:middle
idea that you can have its

00:37:10.266 --> 00:37:12.576 A:middle
timeline controlled by a

00:37:12.576 --> 00:37:13.446 A:middle
RenderSynchronizer.

00:37:13.726 --> 00:37:14.636 A:middle
You can add it to a

00:37:14.636 --> 00:37:15.886 A:middle
RenderSynchronizer just as you

00:37:15.886 --> 00:37:16.896 A:middle
add the AudioRenderer to your

00:37:16.896 --> 00:37:17.626 A:middle
RenderSynchronizer.

00:37:18.046 --> 00:37:19.906 A:middle
And this is really cool.

00:37:19.956 --> 00:37:21.636 A:middle
Because then you can add the

00:37:21.636 --> 00:37:23.736 A:middle
audio data to the AudioRenderer.

00:37:24.166 --> 00:37:27.366 A:middle
The video data to the video

00:37:27.366 --> 00:37:30.326 A:middle
renderer, set a rate of 1 on the

00:37:30.326 --> 00:37:32.726 A:middle
Synchronizer, and because

00:37:32.726 --> 00:37:33.466 A:middle
they're tied to the same

00:37:33.466 --> 00:37:34.916 A:middle
timeline, that will come out in

00:37:34.916 --> 00:37:35.126 A:middle
sync.

00:37:35.676 --> 00:37:37.086 A:middle
Now a couple words of caution,

00:37:37.306 --> 00:37:39.026 A:middle
the video will not be AirPlayed,

00:37:39.466 --> 00:37:40.476 A:middle
and additionally when you're

00:37:40.476 --> 00:37:42.036 A:middle
using long-form you can only add

00:37:42.036 --> 00:37:43.286 A:middle
one AudioRenderer to a

00:37:43.286 --> 00:37:44.126 A:middle
RenderSynchronizer.

00:37:44.716 --> 00:37:46.386 A:middle
But never the less, I think you

00:37:46.386 --> 00:37:48.556 A:middle
can see the power in this and

00:37:48.556 --> 00:37:49.946 A:middle
flexibility in this architecture

00:37:50.176 --> 00:37:51.246 A:middle
and I'm sure you'll come up with

00:37:51.246 --> 00:37:52.676 A:middle
some really cool use case,

00:37:52.676 --> 00:37:54.336 A:middle
applications and we're excited

00:37:54.336 --> 00:37:56.546 A:middle
to find out what you can do.

00:37:57.676 --> 00:37:58.106 A:middle
All right.

00:37:58.106 --> 00:37:59.336 A:middle
Lastly, let's talk about the

00:37:59.336 --> 00:38:00.716 A:middle
availability of AirPlay 2.

00:38:02.086 --> 00:38:04.406 A:middle
So, I'm happy to say that the

00:38:04.406 --> 00:38:06.706 A:middle
APIs that I've discussed today

00:38:06.706 --> 00:38:08.456 A:middle
plus the advanced buffering are

00:38:08.456 --> 00:38:10.976 A:middle
all available in the beta that

00:38:10.976 --> 00:38:12.206 A:middle
you guys have access to today.

00:38:13.486 --> 00:38:16.566 A:middle
And you simply set the AirPlay 2

00:38:16.566 --> 00:38:18.286 A:middle
toggle in the developer pane,

00:38:18.476 --> 00:38:19.276 A:middle
flip that on.

00:38:19.716 --> 00:38:21.166 A:middle
And then you can use an updated

00:38:21.166 --> 00:38:22.766 A:middle
Apple TV as your AirPlay 2

00:38:22.766 --> 00:38:24.686 A:middle
receiver and send to it.

00:38:26.016 --> 00:38:27.376 A:middle
In an upcoming beta, we're going

00:38:27.376 --> 00:38:28.766 A:middle
to enable multi-room audio.

00:38:29.586 --> 00:38:30.606 A:middle
And lastly, this will be

00:38:30.606 --> 00:38:31.896 A:middle
available to customers in an

00:38:31.896 --> 00:38:32.726 A:middle
upcoming release.

00:38:33.616 --> 00:38:34.476 A:middle
Let's go through the summary.

00:38:34.476 --> 00:38:36.006 A:middle
We've covered a lot today.

00:38:36.396 --> 00:38:38.456 A:middle
So, AirPlay 2 introduces many

00:38:38.456 --> 00:38:39.456 A:middle
new features for audio.

00:38:41.056 --> 00:38:42.566 A:middle
Long-form audio applications can

00:38:42.566 --> 00:38:44.566 A:middle
enable them with the steps that

00:38:44.566 --> 00:38:45.366 A:middle
I've outlined today.

00:38:46.336 --> 00:38:48.206 A:middle
And AirPlay 2 adoption can begin

00:38:48.206 --> 00:38:49.356 A:middle
with the beta you guys all have

00:38:49.356 --> 00:38:51.286 A:middle
in your hands.

00:38:51.536 --> 00:38:54.096 A:middle
Additional information, this

00:38:54.096 --> 00:38:55.556 A:middle
website will have the

00:38:55.556 --> 00:38:56.496 A:middle
presentation that we've gone

00:38:56.496 --> 00:38:57.516 A:middle
over today, and there will be

00:38:57.516 --> 00:38:58.756 A:middle
sample code available soon.

00:38:59.346 --> 00:39:02.016 A:middle
A couple sessions that we've

00:39:02.016 --> 00:39:02.806 A:middle
talked about earlier.

00:39:02.806 --> 00:39:03.926 A:middle
There's the What's New in Audio

00:39:03.926 --> 00:39:04.996 A:middle
session, that's the one that

00:39:04.996 --> 00:39:06.356 A:middle
will discuss long-form in more

00:39:06.356 --> 00:39:07.676 A:middle
depth and also Introducing

00:39:07.676 --> 00:39:08.176 A:middle
MusicKit.

00:39:08.616 --> 00:39:09.516 A:middle
That's one that you should check

00:39:09.516 --> 00:39:09.726 A:middle
out.

00:39:10.026 --> 00:39:11.086 A:middle
Thank you very much and I hope

00:39:11.086 --> 00:39:11.856 A:middle
you have a great rest of the

00:39:11.856 --> 00:39:12.116 A:middle
week.

00:39:13.016 --> 00:39:15.000 A:middle
[ Applause ]