WEBVTT

00:00:18.516 --> 00:00:21.966 A:middle
[ Applause ]

00:00:22.466 --> 00:00:22.986 A:middle
&gt;&gt; Good morning.

00:00:23.126 --> 00:00:24.386 A:middle
And welcome to the modernizing

00:00:24.386 --> 00:00:25.586 A:middle
Grand Central Dispatch Usage

00:00:25.616 --> 00:00:25.976 A:middle
Session.

00:00:26.436 --> 00:00:27.806 A:middle
I'm Daniel Chimene from the Core

00:00:27.806 --> 00:00:29.566 A:middle
Darwin Team and my colleagues

00:00:29.566 --> 00:00:31.686 A:middle
and I are here today to show you

00:00:31.766 --> 00:00:33.036 A:middle
how you can take advantage of

00:00:33.036 --> 00:00:34.746 A:middle
Grand Central Dispatch to get

00:00:34.746 --> 00:00:35.746 A:middle
the best performance in your

00:00:35.746 --> 00:00:36.276 A:middle
application.

00:00:37.536 --> 00:00:39.276 A:middle
As app developers, you spent

00:00:39.276 --> 00:00:40.956 A:middle
hundreds or thousands of hours

00:00:41.026 --> 00:00:42.706 A:middle
building amazing experiences for

00:00:42.786 --> 00:00:43.416 A:middle
your users.

00:00:43.476 --> 00:00:45.166 A:middle
Taking advantage of our powerful

00:00:45.166 --> 00:00:45.616 A:middle
devices.

00:00:46.616 --> 00:00:47.976 A:middle
You want your users to be able

00:00:47.976 --> 00:00:49.096 A:middle
to have a great experience.

00:00:49.596 --> 00:00:51.386 A:middle
Not just on one device, but

00:00:51.386 --> 00:00:52.526 A:middle
across all the variety of

00:00:52.526 --> 00:00:56.196 A:middle
devices that Apple makes.

00:00:56.776 --> 00:00:58.476 A:middle
GCD is designed to help you

00:00:58.476 --> 00:00:59.566 A:middle
dynamically scale your

00:00:59.566 --> 00:01:00.356 A:middle
application code.

00:01:00.456 --> 00:01:01.456 A:middle
From the single core Apple

00:01:01.456 --> 00:01:03.056 A:middle
Watch, all the way up to a mini

00:01:03.056 --> 00:01:03.536 A:middle
core Mac.

00:01:04.486 --> 00:01:05.496 A:middle
You don't want to have to worry

00:01:05.496 --> 00:01:07.086 A:middle
too much about what kind of

00:01:07.086 --> 00:01:08.246 A:middle
hardware your users are running.

00:01:09.116 --> 00:01:10.026 A:middle
But there are problematic

00:01:10.096 --> 00:01:11.386 A:middle
problems that can affect the

00:01:11.386 --> 00:01:13.216 A:middle
scalability and the efficiency

00:01:13.676 --> 00:01:14.246 A:middle
of your code.

00:01:14.296 --> 00:01:15.796 A:middle
Both on the low end and on the

00:01:15.796 --> 00:01:16.166 A:middle
high end.

00:01:17.166 --> 00:01:17.986 A:middle
That's what we're here to talk

00:01:17.986 --> 00:01:18.486 A:middle
about today.

00:01:19.326 --> 00:01:20.906 A:middle
We want to help you ensure that

00:01:21.026 --> 00:01:22.216 A:middle
all the work you're putting into

00:01:22.216 --> 00:01:23.206 A:middle
your app to make it a great

00:01:23.206 --> 00:01:24.586 A:middle
experience for your users

00:01:25.206 --> 00:01:26.846 A:middle
translates across all of these

00:01:26.846 --> 00:01:27.306 A:middle
devices.

00:01:28.986 --> 00:01:30.536 A:middle
You may have been using GCD

00:01:30.536 --> 00:01:33.166 A:middle
API's like dispatch async, and

00:01:33.166 --> 00:01:34.446 A:middle
others to create cues and

00:01:34.446 --> 00:01:35.426 A:middle
dispatch work to the system.

00:01:36.336 --> 00:01:37.226 A:middle
These are only some of the

00:01:37.226 --> 00:01:38.476 A:middle
interfaces to the concurrency

00:01:38.476 --> 00:01:40.206 A:middle
technology that we call Grand

00:01:40.206 --> 00:01:40.976 A:middle
Central Dispatch.

00:01:41.686 --> 00:01:42.896 A:middle
Today, we're going to take a

00:01:42.896 --> 00:01:44.476 A:middle
peek under the covers of GCD.

00:01:44.506 --> 00:01:46.576 A:middle
This is an advanced session

00:01:46.666 --> 00:01:47.846 A:middle
packed full of information.

00:01:48.366 --> 00:01:49.316 A:middle
So, let's get started right

00:01:49.316 --> 00:01:50.566 A:middle
away, by looking at our

00:01:50.566 --> 00:01:50.926 A:middle
hardware.

00:01:52.136 --> 00:01:53.656 A:middle
The amazing chips in our devices

00:01:53.656 --> 00:01:54.916 A:middle
have been getting faster and

00:01:54.916 --> 00:01:55.806 A:middle
faster over time.

00:01:56.276 --> 00:01:57.826 A:middle
However, much of the speed is

00:01:57.826 --> 00:01:58.756 A:middle
not just because the chips

00:01:58.756 --> 00:01:59.836 A:middle
themselves are getting faster,

00:02:00.316 --> 00:02:01.026 A:middle
but because they're getting

00:02:01.026 --> 00:02:02.386 A:middle
smarter, and smarter about

00:02:02.386 --> 00:02:03.066 A:middle
running your code.

00:02:03.166 --> 00:02:04.496 A:middle
And they're learning from what

00:02:04.496 --> 00:02:06.086 A:middle
your code does over time to

00:02:06.086 --> 00:02:07.136 A:middle
operate more efficiently.

00:02:07.646 --> 00:02:12.246 A:middle
However, if your code goes off

00:02:12.316 --> 00:02:13.816 A:middle
core, because it's completed its

00:02:13.816 --> 00:02:15.526 A:middle
task, then it may no longer be

00:02:15.526 --> 00:02:16.836 A:middle
able to take advantage of the

00:02:16.906 --> 00:02:18.126 A:middle
history that that core has built

00:02:18.126 --> 00:02:18.366 A:middle
up.

00:02:18.476 --> 00:02:20.186 A:middle
And you might leave performance

00:02:20.186 --> 00:02:21.656 A:middle
on the table when you come back

00:02:21.846 --> 00:02:22.336 A:middle
on core.

00:02:23.286 --> 00:02:24.646 A:middle
We've even seen examples of this

00:02:24.646 --> 00:02:25.996 A:middle
on our own frameworks, when we

00:02:25.996 --> 00:02:27.326 A:middle
applied some of the optimization

00:02:27.366 --> 00:02:28.236 A:middle
techniques that we're going to

00:02:28.236 --> 00:02:30.436 A:middle
discuss today, we saw large

00:02:30.436 --> 00:02:33.086 A:middle
speed ups from simple changes to

00:02:33.086 --> 00:02:34.106 A:middle
avoid these problematic

00:02:34.106 --> 00:02:34.426 A:middle
patterns.

00:02:36.856 --> 00:02:38.916 A:middle
So, using these techniques lets

00:02:38.916 --> 00:02:40.406 A:middle
you bring high performance apps

00:02:40.566 --> 00:02:41.966 A:middle
to more users with less work.

00:02:42.666 --> 00:02:44.296 A:middle
Today, we're going to give you

00:02:44.296 --> 00:02:45.316 A:middle
some insight into what our

00:02:45.316 --> 00:02:46.776 A:middle
system is doing under the covers

00:02:47.046 --> 00:02:47.756 A:middle
with your code.

00:02:47.756 --> 00:02:49.316 A:middle
So, you can tune your code to

00:02:49.316 --> 00:02:50.916 A:middle
take the best advantage of what

00:02:50.916 --> 00:02:51.886 A:middle
GCD has to offer.

00:02:52.676 --> 00:02:53.546 A:middle
We're going to discuss a few

00:02:53.546 --> 00:02:54.086 A:middle
things today.

00:02:55.126 --> 00:02:56.526 A:middle
First, we're going to discuss

00:02:56.526 --> 00:02:57.736 A:middle
how you can best express

00:02:57.946 --> 00:02:59.386 A:middle
parallelism and concurrency.

00:03:00.026 --> 00:03:01.996 A:middle
How you can chose the best way

00:03:02.036 --> 00:03:03.906 A:middle
to express concurrency to grand

00:03:03.906 --> 00:03:04.636 A:middle
central dispatch.

00:03:05.546 --> 00:03:07.036 A:middle
We're going to introduce Unified

00:03:07.076 --> 00:03:08.466 A:middle
Queue Identity, which is a major

00:03:08.466 --> 00:03:09.566 A:middle
under the hood improvement to

00:03:09.566 --> 00:03:10.646 A:middle
GCD that we're publishing this

00:03:10.646 --> 00:03:10.846 A:middle
year.

00:03:11.666 --> 00:03:12.626 A:middle
And we're finally going to show

00:03:12.626 --> 00:03:13.886 A:middle
you how you can find problem

00:03:13.886 --> 00:03:15.136 A:middle
spots in your code, with

00:03:15.136 --> 00:03:15.596 A:middle
instruments.

00:03:16.626 --> 00:03:17.766 A:middle
So, let's start by discussing

00:03:17.766 --> 00:03:19.196 A:middle
parallelism and concurrency.

00:03:20.486 --> 00:03:24.506 A:middle
So, for the purpose of this

00:03:24.546 --> 00:03:25.846 A:middle
talk, we're talking about

00:03:25.946 --> 00:03:27.506 A:middle
parallelism which is about how

00:03:27.506 --> 00:03:30.006 A:middle
your code executes in parallel,

00:03:30.476 --> 00:03:31.686 A:middle
simultaneously across many

00:03:31.686 --> 00:03:32.326 A:middle
different cores.

00:03:32.756 --> 00:03:34.566 A:middle
Concurrency is about how you

00:03:34.566 --> 00:03:35.806 A:middle
compose the independent

00:03:35.806 --> 00:03:37.076 A:middle
components of your application

00:03:37.386 --> 00:03:38.236 A:middle
to run concurrently.

00:03:38.856 --> 00:03:40.186 A:middle
The easy way to separate these

00:03:40.186 --> 00:03:41.796 A:middle
two concepts in your mind, is to

00:03:41.796 --> 00:03:42.846 A:middle
realize that parallelism is

00:03:42.846 --> 00:03:43.826 A:middle
something that usually requires

00:03:43.826 --> 00:03:45.146 A:middle
multiple cores and you want to

00:03:45.146 --> 00:03:46.166 A:middle
use them all at the same time.

00:03:46.526 --> 00:03:47.696 A:middle
And concurrency is something

00:03:47.696 --> 00:03:48.866 A:middle
that you can do even on a single

00:03:48.866 --> 00:03:49.456 A:middle
core system.

00:03:49.456 --> 00:03:51.016 A:middle
It's about how you interpose the

00:03:51.016 --> 00:03:52.496 A:middle
different tasks that are part of

00:03:52.496 --> 00:03:53.126 A:middle
your application.

00:03:53.576 --> 00:03:55.296 A:middle
So, let's start by talking about

00:03:55.296 --> 00:03:57.056 A:middle
parallelism and how you might us

00:03:57.056 --> 00:03:58.576 A:middle
it when you're writing an app.

00:03:59.676 --> 00:04:02.466 A:middle
So, let's imagine you make an

00:04:02.466 --> 00:04:04.096 A:middle
app and it processes huge

00:04:04.096 --> 00:04:04.596 A:middle
images.

00:04:04.856 --> 00:04:05.916 A:middle
And you want to be able to take

00:04:05.916 --> 00:04:07.136 A:middle
advantage of the many cores on a

00:04:07.136 --> 00:04:08.566 A:middle
Mac Pro to be able to process

00:04:08.566 --> 00:04:09.386 A:middle
those images faster.

00:04:10.336 --> 00:04:11.936 A:middle
What you do is break up that

00:04:11.936 --> 00:04:12.746 A:middle
image into chunks.

00:04:13.576 --> 00:04:15.566 A:middle
And have each core process those

00:04:15.566 --> 00:04:18.146 A:middle
chunks in parallel.

00:04:19.466 --> 00:04:20.366 A:middle
This gives you a speed up,

00:04:20.606 --> 00:04:21.236 A:middle
because the cores are

00:04:21.236 --> 00:04:22.966 A:middle
simultaneously working on

00:04:22.966 --> 00:04:23.996 A:middle
different parts of the image.

00:04:25.346 --> 00:04:26.926 A:middle
So, how do you implement this?

00:04:27.066 --> 00:04:29.506 A:middle
Well first, you should stop and

00:04:29.506 --> 00:04:31.126 A:middle
consider whether or not you can

00:04:31.126 --> 00:04:32.276 A:middle
take advantage of our system

00:04:32.276 --> 00:04:32.736 A:middle
frameworks.

00:04:33.396 --> 00:04:35.596 A:middle
For example, accelerate has

00:04:35.656 --> 00:04:37.246 A:middle
built-in support for parallel

00:04:37.246 --> 00:04:38.876 A:middle
execution of advanced image

00:04:38.876 --> 00:04:39.436 A:middle
algorithms.

00:04:40.066 --> 00:04:42.206 A:middle
Metal and core image can take

00:04:42.206 --> 00:04:44.236 A:middle
advantage of the powerful GPU.

00:04:45.846 --> 00:04:47.176 A:middle
Well, let's say you've decided

00:04:47.176 --> 00:04:49.186 A:middle
to implement this yourself, GCD

00:04:49.186 --> 00:04:50.596 A:middle
gives you a tool that lets you

00:04:50.596 --> 00:04:52.146 A:middle
easily express this pattern.

00:04:52.956 --> 00:04:54.396 A:middle
The way you express parallels in

00:04:54.396 --> 00:04:55.696 A:middle
GCD is with the API called

00:04:55.696 --> 00:04:56.516 A:middle
concurrentPerform.

00:04:57.246 --> 00:04:58.966 A:middle
This lets the framework optimize

00:04:58.966 --> 00:05:00.296 A:middle
the parallel case because it

00:05:00.296 --> 00:05:01.336 A:middle
knows that you're trying to do a

00:05:01.446 --> 00:05:03.036 A:middle
parallel computation across all

00:05:03.036 --> 00:05:03.586 A:middle
the cores.

00:05:04.586 --> 00:05:06.466 A:middle
concurrentPerform is a parallel

00:05:06.466 --> 00:05:07.986 A:middle
for loop that automatically load

00:05:07.986 --> 00:05:09.366 A:middle
balances your computation across

00:05:09.416 --> 00:05:11.896 A:middle
all the cores in the system.

00:05:12.086 --> 00:05:13.326 A:middle
When you use this with Swift, it

00:05:13.326 --> 00:05:14.446 A:middle
automatically chooses the

00:05:14.446 --> 00:05:15.936 A:middle
correct context to run all your

00:05:15.936 --> 00:05:16.616 A:middle
computation in.

00:05:17.206 --> 00:05:18.386 A:middle
This year, we've brought that

00:05:18.386 --> 00:05:19.746 A:middle
same power to the objective C

00:05:19.746 --> 00:05:21.996 A:middle
interface dispatch apply with

00:05:21.996 --> 00:05:23.406 A:middle
the dispatch apply auto keeper.

00:05:24.326 --> 00:05:25.656 A:middle
This replaces the Q argument

00:05:26.436 --> 00:05:28.106 A:middle
allowing the system to choose

00:05:28.106 --> 00:05:29.156 A:middle
the right context to run your

00:05:29.156 --> 00:05:30.096 A:middle
code in automatically.

00:05:31.416 --> 00:05:32.646 A:middle
So, now let's take a look at

00:05:32.646 --> 00:05:33.716 A:middle
this other parameter, which is

00:05:33.716 --> 00:05:34.636 A:middle
the iteration count.

00:05:35.256 --> 00:05:36.256 A:middle
This is how many times your

00:05:36.256 --> 00:05:37.416 A:middle
block is called in parallel

00:05:37.416 --> 00:05:38.086 A:middle
across the system.

00:05:39.456 --> 00:05:40.706 A:middle
How do you choose a good value

00:05:40.706 --> 00:05:40.936 A:middle
here?

00:05:41.776 --> 00:05:43.236 A:middle
You might imagine that a good

00:05:43.236 --> 00:05:44.346 A:middle
value would be the number of

00:05:44.406 --> 00:05:44.836 A:middle
cores.

00:05:45.296 --> 00:05:47.376 A:middle
Let's imagine that we're

00:05:47.376 --> 00:05:48.436 A:middle
executing our workload on a

00:05:48.436 --> 00:05:49.246 A:middle
three-core system.

00:05:50.006 --> 00:05:51.486 A:middle
Here, you can see the ideal

00:05:51.486 --> 00:05:53.216 A:middle
case, where three blocks run in

00:05:53.216 --> 00:05:54.396 A:middle
parallel on all three cores.

00:05:55.016 --> 00:05:56.626 A:middle
The real world isn't necessarily

00:05:56.626 --> 00:05:57.166 A:middle
this perfect.

00:05:57.856 --> 00:05:58.906 A:middle
What might happens if the third

00:05:58.906 --> 00:06:00.346 A:middle
core here is taken up for awhile

00:06:00.346 --> 00:06:02.166 A:middle
with UI rendering?

00:06:03.356 --> 00:06:05.146 A:middle
Well, what happens is the load

00:06:05.146 --> 00:06:06.696 A:middle
balancer has to move that third

00:06:06.696 --> 00:06:09.136 A:middle
block over to the first core in

00:06:09.136 --> 00:06:10.206 A:middle
order to execute it, because

00:06:10.206 --> 00:06:11.166 A:middle
it's the third course taken up.

00:06:11.566 --> 00:06:13.796 A:middle
And we get a bubble of idle CPU.

00:06:13.946 --> 00:06:15.666 A:middle
We could have taken advantage of

00:06:15.666 --> 00:06:17.556 A:middle
this time, to do more parallel

00:06:17.556 --> 00:06:17.766 A:middle
work.

00:06:18.166 --> 00:06:19.486 A:middle
And so, instead our workload

00:06:19.486 --> 00:06:19.986 A:middle
took longer.

00:06:21.296 --> 00:06:22.236 A:middle
How can we fix that?

00:06:22.586 --> 00:06:24.166 A:middle
Well, we can increase the

00:06:24.166 --> 00:06:26.866 A:middle
iteration count and give the

00:06:26.866 --> 00:06:28.256 A:middle
load balancer more flexibility.

00:06:29.766 --> 00:06:30.216 A:middle
It looks good.

00:06:30.466 --> 00:06:31.186 A:middle
That hole is gone.

00:06:31.846 --> 00:06:32.796 A:middle
There's actually another hole

00:06:32.796 --> 00:06:35.676 A:middle
over here, on the third core.

00:06:36.186 --> 00:06:37.166 A:middle
We could take advantage of that

00:06:37.206 --> 00:06:37.736 A:middle
time as well.

00:06:39.756 --> 00:06:42.226 A:middle
So, as Tim said on Monday, let's

00:06:42.226 --> 00:06:43.996 A:middle
turn the iteration cup up to 11.

00:06:43.996 --> 00:06:48.986 A:middle
There. We filled the hole, and

00:06:48.986 --> 00:06:50.106 A:middle
we have efficient execution.

00:06:50.536 --> 00:06:51.676 A:middle
We're using all of the available

00:06:51.676 --> 00:06:52.726 A:middle
resources on the system until we

00:06:52.726 --> 00:06:53.116 A:middle
finish.

00:06:53.606 --> 00:06:55.576 A:middle
This is still a very simplistic

00:06:55.576 --> 00:06:56.036 A:middle
example.

00:06:56.336 --> 00:06:57.546 A:middle
To deal with the real-world

00:06:57.546 --> 00:06:59.216 A:middle
complexity, you want to use an

00:06:59.276 --> 00:07:01.246 A:middle
order of magnitude more, say

00:07:01.426 --> 00:07:02.066 A:middle
1000.

00:07:03.136 --> 00:07:04.126 A:middle
You can use a large enough

00:07:04.126 --> 00:07:05.526 A:middle
iteration count so the load

00:07:05.526 --> 00:07:07.206 A:middle
balancer has the flexibility to

00:07:07.206 --> 00:07:08.376 A:middle
fill gaps in the system and take

00:07:08.376 --> 00:07:10.356 A:middle
the maximum of your amount of

00:07:10.356 --> 00:07:11.456 A:middle
advantage of the available

00:07:11.456 --> 00:07:12.366 A:middle
resources of the system.

00:07:13.116 --> 00:07:14.456 A:middle
However, you should be sure to

00:07:14.456 --> 00:07:15.816 A:middle
balance the overhead of the load

00:07:15.816 --> 00:07:17.826 A:middle
balancer versus the useful work

00:07:17.956 --> 00:07:19.866 A:middle
that each block in your parallel

00:07:19.866 --> 00:07:20.596 A:middle
for loop does.

00:07:21.706 --> 00:07:23.266 A:middle
Remember that not every CPU is

00:07:23.266 --> 00:07:24.306 A:middle
available to you all the time.

00:07:24.306 --> 00:07:26.056 A:middle
There are many tasks running

00:07:26.136 --> 00:07:27.326 A:middle
concurrently on the system.

00:07:27.636 --> 00:07:29.516 A:middle
And additionally, not every

00:07:29.516 --> 00:07:30.606 A:middle
worker thread will make equal

00:07:30.606 --> 00:07:31.006 A:middle
progress.

00:07:32.496 --> 00:07:34.516 A:middle
So, to recap, if you have a

00:07:34.516 --> 00:07:36.486 A:middle
parallel problem, make sure to

00:07:36.486 --> 00:07:37.696 A:middle
leverage the system frameworks

00:07:37.696 --> 00:07:38.416 A:middle
that are available to you.

00:07:38.506 --> 00:07:40.476 A:middle
You can use their power to solve

00:07:40.476 --> 00:07:41.006 A:middle
your problem.

00:07:42.056 --> 00:07:43.326 A:middle
Additionally, make sure to take

00:07:43.326 --> 00:07:44.696 A:middle
advantage of the automatic load

00:07:44.696 --> 00:07:45.576 A:middle
balancing inside

00:07:45.576 --> 00:07:46.356 A:middle
concurrentPerform.

00:07:46.356 --> 00:07:47.926 A:middle
Give it the flexibility to do

00:07:47.926 --> 00:07:48.746 A:middle
what it does best.

00:07:49.496 --> 00:07:51.106 A:middle
So, that's the discussion about

00:07:51.106 --> 00:07:51.636 A:middle
parallelism.

00:07:51.936 --> 00:07:52.906 A:middle
Now, let's switch to the main

00:07:52.906 --> 00:07:54.146 A:middle
topic for today, which is

00:07:54.146 --> 00:07:54.806 A:middle
concurrency.

00:07:56.196 --> 00:07:58.456 A:middle
So, concurrency.

00:07:59.586 --> 00:08:00.886 A:middle
Let's image you're writing a

00:08:00.886 --> 00:08:01.776 A:middle
simple news app.

00:08:02.896 --> 00:08:03.656 A:middle
How would you structure it?

00:08:03.856 --> 00:08:05.696 A:middle
Well, you start by breaking it

00:08:05.696 --> 00:08:06.776 A:middle
up into the independent

00:08:06.776 --> 00:08:08.456 A:middle
subsystems that make up the app.

00:08:09.236 --> 00:08:10.216 A:middle
Thinking about how you might

00:08:10.216 --> 00:08:11.766 A:middle
break up a news app into its

00:08:11.766 --> 00:08:13.236 A:middle
independent subsystems, you

00:08:13.236 --> 00:08:14.796 A:middle
might have a UI component that

00:08:14.796 --> 00:08:15.806 A:middle
renders the UI, that's the main

00:08:15.806 --> 00:08:16.116 A:middle
thread.

00:08:16.706 --> 00:08:18.266 A:middle
You might also have a database

00:08:18.626 --> 00:08:20.336 A:middle
that stores those articles.

00:08:20.736 --> 00:08:21.826 A:middle
And you might have a networking

00:08:21.826 --> 00:08:22.926 A:middle
subsystem that fetches those

00:08:22.926 --> 00:08:23.796 A:middle
articles from the network.

00:08:23.796 --> 00:08:25.606 A:middle
To give you a better picture of

00:08:25.736 --> 00:08:26.926 A:middle
how this app works and breaking

00:08:26.926 --> 00:08:28.466 A:middle
it up into subsystems gives you

00:08:28.466 --> 00:08:30.176 A:middle
an advantage, let's visualize

00:08:30.616 --> 00:08:31.906 A:middle
how that executes concurrently

00:08:31.956 --> 00:08:32.746 A:middle
on a modern system.

00:08:33.426 --> 00:08:36.626 A:middle
So, let's say here's a timeline

00:08:36.786 --> 00:08:38.826 A:middle
that shows at the top the CPU

00:08:38.826 --> 00:08:39.156 A:middle
track.

00:08:39.156 --> 00:08:40.176 A:middle
Let's image that we only have

00:08:40.176 --> 00:08:41.076 A:middle
one CPU remaining.

00:08:41.076 --> 00:08:42.216 A:middle
The other CPUs are busy for some

00:08:42.216 --> 00:08:42.446 A:middle
reason.

00:08:43.146 --> 00:08:44.276 A:middle
We only have one core available.

00:08:44.736 --> 00:08:46.386 A:middle
At any time only one of these

00:08:46.386 --> 00:08:47.696 A:middle
threads can run on that CPU.

00:08:48.526 --> 00:08:50.116 A:middle
So, what happens when a user

00:08:50.116 --> 00:08:51.696 A:middle
clicks the button and refreshes

00:08:51.696 --> 00:08:53.356 A:middle
the article list in the news

00:08:53.356 --> 00:08:53.526 A:middle
app?

00:08:54.126 --> 00:08:55.286 A:middle
Well, these interface renders

00:08:55.286 --> 00:08:56.676 A:middle
the response to that button and

00:08:56.946 --> 00:08:58.026 A:middle
then sends an asynchronous

00:08:58.026 --> 00:08:58.876 A:middle
across the database.

00:09:00.136 --> 00:09:01.346 A:middle
And then the database decides it

00:09:01.346 --> 00:09:02.736 A:middle
needs to refresh the articles,

00:09:02.976 --> 00:09:04.266 A:middle
which it chooses another command

00:09:04.846 --> 00:09:05.946 A:middle
to the networking subsystem.

00:09:06.886 --> 00:09:08.096 A:middle
However, at this point, the user

00:09:08.096 --> 00:09:08.956 A:middle
touches the app again.

00:09:09.936 --> 00:09:12.146 A:middle
And because the database is done

00:09:12.216 --> 00:09:13.086 A:middle
off the main thread of the

00:09:13.086 --> 00:09:14.896 A:middle
application, the OS can

00:09:14.896 --> 00:09:16.236 A:middle
immediately switch the CPU to

00:09:16.236 --> 00:09:18.026 A:middle
working on the UI thread, and it

00:09:18.026 --> 00:09:19.126 A:middle
can respond immediately to the

00:09:19.126 --> 00:09:20.696 A:middle
user without having to wait for

00:09:20.886 --> 00:09:21.986 A:middle
the database thread to complete.

00:09:23.616 --> 00:09:25.126 A:middle
This is the advantage of moving

00:09:25.236 --> 00:09:26.386 A:middle
work off the main thread.

00:09:28.366 --> 00:09:30.016 A:middle
When the user interface is done

00:09:30.016 --> 00:09:32.296 A:middle
responding, the CPU can then

00:09:32.296 --> 00:09:33.266 A:middle
switch back to the database

00:09:33.316 --> 00:09:34.326 A:middle
thread, and then finish the

00:09:34.326 --> 00:09:35.296 A:middle
networking task as well.

00:09:36.496 --> 00:09:37.776 A:middle
So, taking advantage of

00:09:37.776 --> 00:09:39.476 A:middle
concurrency like this lets you

00:09:39.476 --> 00:09:40.696 A:middle
build responsive apps.

00:09:40.736 --> 00:09:42.616 A:middle
The main thread can always

00:09:42.616 --> 00:09:43.806 A:middle
respond to the user's action

00:09:44.076 --> 00:09:45.256 A:middle
without having to wait for other

00:09:45.256 --> 00:09:46.146 A:middle
parts of your application to

00:09:46.146 --> 00:09:46.516 A:middle
complete.

00:09:46.806 --> 00:09:48.886 A:middle
So, let's take a look at what

00:09:48.956 --> 00:09:50.376 A:middle
that looks like to the CPU.

00:09:51.416 --> 00:09:52.716 A:middle
These white lines above here

00:09:52.896 --> 00:09:54.266 A:middle
show the content switches

00:09:54.316 --> 00:09:55.206 A:middle
between the subsystems.

00:09:55.946 --> 00:09:57.616 A:middle
A contact switch is when the CPU

00:09:57.616 --> 00:09:58.686 A:middle
switches between these different

00:09:58.686 --> 00:10:00.356 A:middle
subsystems or threads that make

00:10:00.356 --> 00:10:01.146 A:middle
up your application.

00:10:02.066 --> 00:10:03.146 A:middle
If you want to visualize what

00:10:03.196 --> 00:10:04.226 A:middle
this looks like to your

00:10:04.226 --> 00:10:05.636 A:middle
application, you can use

00:10:05.636 --> 00:10:07.226 A:middle
instrument system trace, which

00:10:07.226 --> 00:10:08.856 A:middle
shows you what the CPUs and the

00:10:08.856 --> 00:10:10.016 A:middle
threads are doing when they're

00:10:10.016 --> 00:10:11.026 A:middle
running in your application.

00:10:11.446 --> 00:10:12.806 A:middle
If you want to learn more about

00:10:12.806 --> 00:10:14.316 A:middle
this, you can watch the "System

00:10:14.316 --> 00:10:15.716 A:middle
Trace In-Depth" Talk from last

00:10:15.716 --> 00:10:16.636 A:middle
year where the instrument's team

00:10:16.636 --> 00:10:17.946 A:middle
described how you use system

00:10:17.946 --> 00:10:18.226 A:middle
trace.

00:10:19.276 --> 00:10:21.186 A:middle
So, this concept of context

00:10:21.186 --> 00:10:22.576 A:middle
switching is where the power of

00:10:22.576 --> 00:10:23.596 A:middle
concurrency comes from.

00:10:24.096 --> 00:10:25.546 A:middle
Let's look at when these context

00:10:25.546 --> 00:10:27.006 A:middle
switch might happen and what

00:10:27.006 --> 00:10:27.496 A:middle
causes them.

00:10:28.366 --> 00:10:30.646 A:middle
Well, they can start when a high

00:10:30.646 --> 00:10:32.226 A:middle
priority thread needs the CPU as

00:10:32.226 --> 00:10:33.686 A:middle
we saw earlier, with the UI

00:10:33.686 --> 00:10:34.806 A:middle
thread pre-empting the database

00:10:34.806 --> 00:10:35.056 A:middle
thread.

00:10:35.966 --> 00:10:37.366 A:middle
It can also happen when a thread

00:10:37.366 --> 00:10:39.646 A:middle
finishes its current work, or

00:10:39.826 --> 00:10:40.796 A:middle
it's waiting to acquire

00:10:40.796 --> 00:10:41.356 A:middle
resource.

00:10:41.736 --> 00:10:42.506 A:middle
Or it's waiting for an

00:10:42.506 --> 00:10:43.406 A:middle
asynchronous request to

00:10:43.406 --> 00:10:43.736 A:middle
complete.

00:10:44.856 --> 00:10:46.446 A:middle
However, with this great power

00:10:46.446 --> 00:10:48.406 A:middle
of concurrency comes great

00:10:48.406 --> 00:10:49.576 A:middle
responsibility as well.

00:10:49.766 --> 00:10:51.216 A:middle
You can have too much of a good

00:10:51.216 --> 00:10:51.436 A:middle
thing.

00:10:52.896 --> 00:10:54.266 A:middle
Let's say you're switching

00:10:54.266 --> 00:10:56.116 A:middle
between the network and database

00:10:56.116 --> 00:10:57.666 A:middle
threads on your CPU.

00:10:58.386 --> 00:10:59.626 A:middle
A few context switches is fine,

00:10:59.626 --> 00:11:00.586 A:middle
that's the power of concurrency

00:11:00.586 --> 00:11:01.236 A:middle
you're switching between

00:11:01.236 --> 00:11:01.936 A:middle
different tasks.

00:11:02.616 --> 00:11:04.146 A:middle
However, if you're doing this

00:11:04.146 --> 00:11:05.686 A:middle
thousands of times in really

00:11:05.816 --> 00:11:07.706 A:middle
rapid succession, you run into

00:11:07.706 --> 00:11:08.046 A:middle
trouble.

00:11:08.126 --> 00:11:08.726 A:middle
You're starting to lose

00:11:08.786 --> 00:11:10.776 A:middle
performance because each white

00:11:10.776 --> 00:11:12.656 A:middle
bar here is a context switch.

00:11:13.066 --> 00:11:14.066 A:middle
And the overhead of a context

00:11:14.066 --> 00:11:14.726 A:middle
switch adds up.

00:11:14.726 --> 00:11:16.076 A:middle
It's not just the time we spend

00:11:16.076 --> 00:11:17.156 A:middle
executing the context switch,

00:11:17.486 --> 00:11:18.606 A:middle
it's also that history that the

00:11:18.606 --> 00:11:19.816 A:middle
core has built up, it has to

00:11:19.846 --> 00:11:21.076 A:middle
regain that history after every

00:11:21.076 --> 00:11:22.306 A:middle
contact switch.

00:11:22.996 --> 00:11:24.666 A:middle
There are also other affects you

00:11:24.666 --> 00:11:25.276 A:middle
might experience.

00:11:25.556 --> 00:11:26.626 A:middle
For example, there might be

00:11:26.626 --> 00:11:28.566 A:middle
others ahead of you in line for

00:11:28.566 --> 00:11:29.506 A:middle
access to the CPU.

00:11:30.486 --> 00:11:32.356 A:middle
You have to wait each time you

00:11:32.356 --> 00:11:33.966 A:middle
context switch for the rest of

00:11:33.966 --> 00:11:35.316 A:middle
the queue to drain out and so

00:11:35.316 --> 00:11:37.996 A:middle
you may be delayed by somebody

00:11:37.996 --> 00:11:38.926 A:middle
else ahead of you in line.

00:11:39.616 --> 00:11:41.026 A:middle
So, let's look about what might

00:11:41.056 --> 00:11:42.336 A:middle
cause excessive context

00:11:42.336 --> 00:11:42.576 A:middle
switching.

00:11:43.696 --> 00:11:45.446 A:middle
So, there's three main causes

00:11:45.446 --> 00:11:46.376 A:middle
we're going to talk about today.

00:11:46.966 --> 00:11:48.416 A:middle
First, repeatedly waiting for

00:11:48.416 --> 00:11:49.786 A:middle
exclusive access to contended

00:11:49.786 --> 00:11:50.336 A:middle
resources.

00:11:50.896 --> 00:11:52.086 A:middle
Repeatedly switching between

00:11:52.086 --> 00:11:53.836 A:middle
independent operations, and

00:11:53.836 --> 00:11:55.306 A:middle
repeatedly bouncing an operation

00:11:55.446 --> 00:11:56.136 A:middle
between threads.

00:11:56.956 --> 00:11:57.936 A:middle
You note, that I repeated the

00:11:57.936 --> 00:11:59.846 A:middle
word repeatedly several times.

00:12:00.596 --> 00:12:01.376 A:middle
That's intentional.

00:12:03.336 --> 00:12:04.856 A:middle
Context switching a few times is

00:12:04.856 --> 00:12:06.396 A:middle
okay, that's how concurrency

00:12:06.396 --> 00:12:07.436 A:middle
works, that's the power that

00:12:07.436 --> 00:12:07.986 A:middle
we're giving you.

00:12:08.646 --> 00:12:10.206 A:middle
However, when you repeat it too

00:12:10.206 --> 00:12:11.746 A:middle
many times, the cost start to

00:12:11.746 --> 00:12:12.126 A:middle
add up.

00:12:13.376 --> 00:12:14.576 A:middle
So, let's start by looking at

00:12:14.576 --> 00:12:15.796 A:middle
the first case, which is

00:12:15.796 --> 00:12:17.176 A:middle
exclusive access to contended

00:12:17.176 --> 00:12:17.826 A:middle
resources.

00:12:18.786 --> 00:12:19.546 A:middle
When can this happen?

00:12:20.306 --> 00:12:22.696 A:middle
Well, the primary case in which

00:12:22.696 --> 00:12:24.176 A:middle
this happens is when you have a

00:12:24.176 --> 00:12:26.046 A:middle
lock and a bunch of threads are

00:12:26.046 --> 00:12:28.176 A:middle
all trying to acquire that lock.

00:12:29.486 --> 00:12:30.716 A:middle
So, how can you tell if this is

00:12:30.716 --> 00:12:31.686 A:middle
occurring in your application?

00:12:31.896 --> 00:12:33.426 A:middle
Well, we can go back to system

00:12:33.426 --> 00:12:33.786 A:middle
trace.

00:12:34.346 --> 00:12:35.736 A:middle
We can visualize what it looks

00:12:35.736 --> 00:12:36.466 A:middle
like in instruments.

00:12:37.246 --> 00:12:38.776 A:middle
So, let's say this shows us that

00:12:38.776 --> 00:12:40.306 A:middle
we have many threads running for

00:12:40.306 --> 00:12:41.386 A:middle
a very short time and they're

00:12:41.386 --> 00:12:42.616 A:middle
all handing off to each other in

00:12:42.616 --> 00:12:43.376 A:middle
a little cascade.

00:12:44.276 --> 00:12:45.446 A:middle
Let's focus on the first thread

00:12:45.446 --> 00:12:46.306 A:middle
and see what instruments it's

00:12:46.306 --> 00:12:46.756 A:middle
telling us.

00:12:47.896 --> 00:12:49.746 A:middle
We have this blue track, which

00:12:49.746 --> 00:12:51.846 A:middle
shows when a thread is on CPU.

00:12:52.526 --> 00:12:53.856 A:middle
And the red track shows when

00:12:53.856 --> 00:12:54.686 A:middle
it's making a sys call.

00:12:55.136 --> 00:12:56.776 A:middle
In this case, it's making

00:12:56.776 --> 00:12:58.586 A:middle
[inaudible].

00:12:58.586 --> 00:13:00.336 A:middle
This shows that most of its time

00:13:00.336 --> 00:13:01.276 A:middle
is waiting for the [inaudible]

00:13:01.276 --> 00:13:02.216 A:middle
to become available.

00:13:02.216 --> 00:13:04.536 A:middle
And the on core time is very

00:13:04.536 --> 00:13:06.096 A:middle
short at only 10 microseconds.

00:13:06.996 --> 00:13:08.316 A:middle
And there are a lot of context

00:13:08.316 --> 00:13:09.596 A:middle
switches going on on the system,

00:13:09.926 --> 00:13:10.596 A:middle
which it shows you on the

00:13:10.596 --> 00:13:11.566 A:middle
context switches track at the

00:13:11.566 --> 00:13:11.836 A:middle
top.

00:13:13.806 --> 00:13:15.636 A:middle
So, what's causing this?

00:13:15.856 --> 00:13:17.006 A:middle
Let's go back to look at our

00:13:17.006 --> 00:13:19.456 A:middle
simple timeline and see how you

00:13:19.736 --> 00:13:23.636 A:middle
excess contingent could be

00:13:23.636 --> 00:13:24.146 A:middle
playing out.

00:13:25.056 --> 00:13:25.956 A:middle
So, you see this sort of

00:13:25.956 --> 00:13:27.526 A:middle
staircase pattern in time.

00:13:27.996 --> 00:13:29.056 A:middle
Where each thread is running for

00:13:29.056 --> 00:13:30.416 A:middle
a short time, and then giving up

00:13:30.416 --> 00:13:31.446 A:middle
the CPU to the next thread,

00:13:31.626 --> 00:13:32.976 A:middle
rinse and repeat for a long

00:13:32.976 --> 00:13:33.196 A:middle
time.

00:13:33.906 --> 00:13:35.266 A:middle
You want your work to look more

00:13:35.266 --> 00:13:35.826 A:middle
like this.

00:13:36.696 --> 00:13:38.456 A:middle
Where you have the CPU can focus

00:13:38.456 --> 00:13:39.926 A:middle
on one thing at a time, get it

00:13:39.926 --> 00:13:41.096 A:middle
done, and then work on the next

00:13:41.186 --> 00:13:41.376 A:middle
task.

00:13:42.336 --> 00:13:43.526 A:middle
So, what's going on here that

00:13:43.526 --> 00:13:44.536 A:middle
causes that staircase?

00:13:44.706 --> 00:13:45.876 A:middle
Let's zoom in to one of these

00:13:45.876 --> 00:13:46.566 A:middle
stair steps.

00:13:47.616 --> 00:13:49.476 A:middle
So, here we're focusing on two

00:13:49.476 --> 00:13:50.666 A:middle
threads, the green thread and

00:13:50.666 --> 00:13:51.226 A:middle
the blue thread.

00:13:51.776 --> 00:13:53.546 A:middle
And we have a CPU on top.

00:13:54.246 --> 00:13:55.476 A:middle
We've added a new lock track

00:13:55.566 --> 00:13:56.806 A:middle
here that shows the state of the

00:13:56.806 --> 00:13:58.106 A:middle
lock and what thread owns it.

00:13:58.336 --> 00:14:00.126 A:middle
In this case, the blue thread

00:14:00.126 --> 00:14:01.676 A:middle
owns the block, and the green

00:14:01.676 --> 00:14:02.206 A:middle
thread is waiting.

00:14:03.456 --> 00:14:04.366 A:middle
So, when the blue thread

00:14:04.506 --> 00:14:06.166 A:middle
unlocks, the ownership of that

00:14:06.166 --> 00:14:07.296 A:middle
lock is transferred to the green

00:14:07.296 --> 00:14:08.276 A:middle
thread, because it's next in

00:14:08.276 --> 00:14:08.556 A:middle
line.

00:14:09.446 --> 00:14:11.246 A:middle
However, when the blue thread

00:14:11.676 --> 00:14:12.926 A:middle
turns around and grabs the lock

00:14:12.926 --> 00:14:14.856 A:middle
again, it can't because the lock

00:14:14.856 --> 00:14:15.706 A:middle
is reserved for the green

00:14:15.706 --> 00:14:15.966 A:middle
thread.

00:14:16.666 --> 00:14:18.216 A:middle
It forces at context switch

00:14:18.216 --> 00:14:19.436 A:middle
because we now have to do

00:14:19.436 --> 00:14:20.106 A:middle
something else.

00:14:20.486 --> 00:14:21.436 A:middle
And we switch to the green

00:14:21.436 --> 00:14:23.496 A:middle
thread, and the CPU can then

00:14:24.106 --> 00:14:25.346 A:middle
finish the lock and we can

00:14:25.346 --> 00:14:25.696 A:middle
repeat.

00:14:27.056 --> 00:14:28.056 A:middle
Sometimes this is useful.

00:14:28.276 --> 00:14:29.376 A:middle
You want every thread that's

00:14:29.376 --> 00:14:30.256 A:middle
waiting on the lock to get a

00:14:30.256 --> 00:14:31.886 A:middle
chance to acquire the resource,

00:14:32.606 --> 00:14:34.756 A:middle
however, what if you had a lock

00:14:34.806 --> 00:14:35.746 A:middle
that works a different way.

00:14:36.536 --> 00:14:38.696 A:middle
Let's start again by looking at

00:14:38.696 --> 00:14:39.856 A:middle
what an unfair lock does.

00:14:40.866 --> 00:14:43.006 A:middle
So, this time when blue thread

00:14:43.006 --> 00:14:45.006 A:middle
unlocks, the lock isn't

00:14:45.056 --> 00:14:45.456 A:middle
reserved.

00:14:45.856 --> 00:14:46.946 A:middle
The ownership of the lock is up

00:14:46.946 --> 00:14:47.616 A:middle
for grabs.

00:14:48.616 --> 00:14:50.156 A:middle
Blue can take the lock again,

00:14:50.536 --> 00:14:52.026 A:middle
and it can immediately reacquire

00:14:52.026 --> 00:14:54.066 A:middle
and stay on CPU without forcing

00:14:54.066 --> 00:14:54.786 A:middle
a context switch.

00:14:55.716 --> 00:14:56.876 A:middle
This might make it difficult for

00:14:56.876 --> 00:14:57.896 A:middle
the green thread to actually get

00:14:57.896 --> 00:14:59.786 A:middle
a chance at the lock, but it

00:14:59.786 --> 00:15:00.966 A:middle
reduces the number of context

00:15:00.966 --> 00:15:02.346 A:middle
switches the blue thread has to

00:15:02.886 --> 00:15:06.466 A:middle
have in order to reacquire the

00:15:06.466 --> 00:15:06.636 A:middle
lock.

00:15:08.016 --> 00:15:09.106 A:middle
So, to recap when we're talking

00:15:09.106 --> 00:15:10.276 A:middle
about lock contention, you

00:15:10.276 --> 00:15:11.716 A:middle
actually want to make sure to

00:15:11.716 --> 00:15:12.986 A:middle
measure your application and

00:15:12.986 --> 00:15:14.616 A:middle
system trace and see if you have

00:15:14.616 --> 00:15:15.036 A:middle
an issue.

00:15:15.496 --> 00:15:17.586 A:middle
If you do, often the unfair lock

00:15:17.866 --> 00:15:19.296 A:middle
works best for objects,

00:15:19.646 --> 00:15:21.046 A:middle
properties, for global state in

00:15:21.046 --> 00:15:22.266 A:middle
your application that may have

00:15:22.266 --> 00:15:23.926 A:middle
taken a drop many, many times.

00:15:25.526 --> 00:15:26.486 A:middle
There's one other thing I want

00:15:26.486 --> 00:15:27.186 A:middle
to talk about when we're

00:15:27.186 --> 00:15:28.326 A:middle
mentioning locks, and that is

00:15:28.326 --> 00:15:29.096 A:middle
lock ownership.

00:15:29.866 --> 00:15:31.276 A:middle
So, remember the lock track we

00:15:31.276 --> 00:15:33.386 A:middle
had earlier, the runtime knows

00:15:33.386 --> 00:15:34.386 A:middle
which thread will unlock the

00:15:34.386 --> 00:15:34.876 A:middle
lock next.

00:15:36.016 --> 00:15:37.256 A:middle
We can take advantage of that

00:15:37.256 --> 00:15:38.796 A:middle
power to automatically result

00:15:38.796 --> 00:15:40.056 A:middle
priority inversions in your app

00:15:40.496 --> 00:15:41.666 A:middle
between the waiters and the

00:15:41.666 --> 00:15:42.356 A:middle
owners of the lock.

00:15:42.776 --> 00:15:44.216 A:middle
And even enable other

00:15:44.216 --> 00:15:46.056 A:middle
optimizations, like directed CPU

00:15:46.056 --> 00:15:47.166 A:middle
handoff to the owning thread.

00:15:47.756 --> 00:15:48.866 A:middle
Pierre is going to discuss this

00:15:49.156 --> 00:15:50.356 A:middle
later in our talk, when talking

00:15:50.356 --> 00:15:51.096 A:middle
about dispatch sync.

00:15:52.196 --> 00:15:54.286 A:middle
We often get the question, which

00:15:54.346 --> 00:15:55.726 A:middle
primitives have this power and

00:15:55.726 --> 00:15:56.426 A:middle
which ones don't.

00:15:57.476 --> 00:15:58.736 A:middle
Let's take a look at which

00:15:58.736 --> 00:15:59.776 A:middle
low-level primitives do this

00:15:59.836 --> 00:16:00.106 A:middle
today.

00:16:01.506 --> 00:16:03.096 A:middle
So, primitives with a single

00:16:03.146 --> 00:16:04.536 A:middle
known owner have this power.

00:16:04.926 --> 00:16:06.536 A:middle
Things like serial queues and OS

00:16:06.536 --> 00:16:07.096 A:middle
unfair lock.

00:16:08.186 --> 00:16:10.616 A:middle
However, asymmetric primitives,

00:16:10.616 --> 00:16:11.976 A:middle
like dispatch semaphore and

00:16:11.976 --> 00:16:13.466 A:middle
dispatch group don't have this

00:16:13.536 --> 00:16:14.666 A:middle
power, because the runtime

00:16:14.666 --> 00:16:15.826 A:middle
doesn't know what thread will

00:16:15.826 --> 00:16:16.886 A:middle
single the sub primitive.

00:16:18.636 --> 00:16:20.286 A:middle
Finally, primitives with

00:16:20.286 --> 00:16:22.106 A:middle
multiple owners like private,

00:16:22.106 --> 00:16:23.416 A:middle
concurrent queues and read or

00:16:23.416 --> 00:16:24.736 A:middle
writer locks, the systems

00:16:24.736 --> 00:16:25.726 A:middle
doesn't take advantage of that

00:16:25.776 --> 00:16:26.626 A:middle
today, because there isn't a

00:16:26.626 --> 00:16:27.236 A:middle
single owner.

00:16:27.236 --> 00:16:29.516 A:middle
When you're picking a primitive

00:16:30.036 --> 00:16:31.576 A:middle
consider whether or not your use

00:16:31.646 --> 00:16:32.936 A:middle
case involves threads of

00:16:32.936 --> 00:16:33.656 A:middle
different priorities

00:16:33.656 --> 00:16:34.226 A:middle
interacting.

00:16:35.096 --> 00:16:37.096 A:middle
In like a high party UI thread

00:16:37.096 --> 00:16:38.416 A:middle
with a lower priority background

00:16:38.416 --> 00:16:38.636 A:middle
thread.

00:16:39.836 --> 00:16:41.456 A:middle
If so, you might want to take

00:16:41.456 --> 00:16:42.416 A:middle
advantage of a primitive

00:16:42.456 --> 00:16:44.736 A:middle
ownership that ensures that your

00:16:44.886 --> 00:16:46.416 A:middle
UI thread doesn't get delayed by

00:16:46.416 --> 00:16:47.336 A:middle
waiting on a lower priority

00:16:47.336 --> 00:16:48.606 A:middle
background thread.

00:16:49.256 --> 00:16:51.056 A:middle
So, in summary, these

00:16:51.126 --> 00:16:52.526 A:middle
inefficient behaviors often

00:16:52.526 --> 00:16:53.496 A:middle
emerge in properties of your

00:16:53.496 --> 00:16:54.126 A:middle
application.

00:16:54.486 --> 00:16:55.806 A:middle
It's not easy to find these

00:16:55.846 --> 00:16:56.976 A:middle
problems just by looking at your

00:16:56.976 --> 00:16:57.336 A:middle
code.

00:16:57.816 --> 00:16:59.196 A:middle
You should observe it in

00:16:59.196 --> 00:17:00.846 A:middle
instrument system trace to

00:17:00.846 --> 00:17:02.446 A:middle
visualize your apps true, real

00:17:02.446 --> 00:17:04.426 A:middle
behavior and so you can use the

00:17:04.486 --> 00:17:05.526 A:middle
right lock for the job.

00:17:06.526 --> 00:17:07.416 A:middle
So, I've just discussed the

00:17:07.516 --> 00:17:09.016 A:middle
first cause on our context

00:17:09.016 --> 00:17:10.166 A:middle
switching list, which is

00:17:10.166 --> 00:17:11.246 A:middle
exclusive access.

00:17:12.566 --> 00:17:13.926 A:middle
To discuss some other ways your

00:17:13.926 --> 00:17:15.256 A:middle
apps can experience excessive

00:17:15.256 --> 00:17:16.446 A:middle
context switching, I'm going to

00:17:16.446 --> 00:17:18.726 A:middle
bring out my Daniel Steffen to

00:17:19.056 --> 00:17:20.476 A:middle
talk to you about how you can

00:17:20.526 --> 00:17:21.856 A:middle
organize your concurrency with

00:17:21.856 --> 00:17:23.886 A:middle
GCD, to avoid these pitfalls.

00:17:26.516 --> 00:17:31.126 A:middle
[ Applause ]

00:17:31.626 --> 00:17:31.866 A:middle
&gt;&gt; All right.

00:17:32.076 --> 00:17:32.666 A:middle
Thank you, Daniel.

00:17:34.336 --> 00:17:35.486 A:middle
So, we've got a lot to cover

00:17:35.486 --> 00:17:37.036 A:middle
today, so I won't be able to go

00:17:37.036 --> 00:17:38.556 A:middle
into too many details on the

00:17:38.556 --> 00:17:39.856 A:middle
fundamentals of GCD.

00:17:40.406 --> 00:17:41.966 A:middle
If you're new to the technology,

00:17:42.376 --> 00:17:43.686 A:middle
or need a bit of a refresher,

00:17:43.796 --> 00:17:44.936 A:middle
here are some of the sessions at

00:17:44.936 --> 00:17:47.286 A:middle
previous WWDC conferences that

00:17:47.286 --> 00:17:48.746 A:middle
covered GCD and the enhancements

00:17:48.746 --> 00:17:49.626 A:middle
that we've made to it over the

00:17:49.626 --> 00:17:50.106 A:middle
years.

00:17:50.686 --> 00:17:51.866 A:middle
So, I encourage you to go and

00:17:51.866 --> 00:17:52.806 A:middle
see those on video.

00:17:53.496 --> 00:17:55.266 A:middle
We do need a few of the basic

00:17:55.266 --> 00:17:56.876 A:middle
concepts of GCD today however,

00:17:56.876 --> 00:17:58.776 A:middle
starting with the serial

00:17:58.926 --> 00:17:59.566 A:middle
dispatch queue.

00:18:00.566 --> 00:18:01.936 A:middle
This is really our fundamental

00:18:02.446 --> 00:18:03.746 A:middle
synchronization primitive in

00:18:03.746 --> 00:18:04.086 A:middle
GCD.

00:18:04.086 --> 00:18:06.266 A:middle
It provides you with mutual

00:18:06.266 --> 00:18:07.706 A:middle
exclusion as well as FIFO

00:18:07.736 --> 00:18:07.996 A:middle
ordering.

00:18:07.996 --> 00:18:09.836 A:middle
This is one of these ordered and

00:18:10.106 --> 00:18:11.426 A:middle
fair primitives that Daniel just

00:18:11.426 --> 00:18:11.796 A:middle
mentioned.

00:18:13.296 --> 00:18:15.196 A:middle
And it has a concurrent atomic

00:18:15.196 --> 00:18:16.406 A:middle
in queue operation, so it's find

00:18:16.406 --> 00:18:17.406 A:middle
for multiple threads to in

00:18:17.406 --> 00:18:18.736 A:middle
queue, operations into the queue

00:18:18.736 --> 00:18:20.396 A:middle
at the same time, as well as a

00:18:20.396 --> 00:18:21.706 A:middle
single DQI thread that the

00:18:21.706 --> 00:18:23.216 A:middle
system provides to execute

00:18:23.216 --> 00:18:24.376 A:middle
asynchronous work out of the

00:18:24.376 --> 00:18:24.676 A:middle
queue.

00:18:25.416 --> 00:18:26.746 A:middle
So, let's look at an example of

00:18:26.846 --> 00:18:27.496 A:middle
this in action.

00:18:27.496 --> 00:18:29.436 A:middle
Here we're creating a serial

00:18:29.466 --> 00:18:30.926 A:middle
queue by calling the dispatch

00:18:30.926 --> 00:18:33.256 A:middle
queue constructor and that will

00:18:33.256 --> 00:18:34.976 A:middle
give you a piece of memory that

00:18:34.976 --> 00:18:36.426 A:middle
as long as you haven't used it

00:18:36.426 --> 00:18:37.506 A:middle
yet, it's just in your

00:18:37.506 --> 00:18:38.066 A:middle
application.

00:18:38.826 --> 00:18:40.006 A:middle
Now, imagine there's two threads

00:18:40.006 --> 00:18:41.046 A:middle
that come along in call D

00:18:41.046 --> 00:18:43.086 A:middle
queue.async method to submit

00:18:43.086 --> 00:18:44.416 A:middle
some asynchronous work into this

00:18:44.416 --> 00:18:44.736 A:middle
queue.

00:18:45.396 --> 00:18:46.336 A:middle
As mentioned, it's find for

00:18:46.336 --> 00:18:47.646 A:middle
multiple threads to do this, and

00:18:47.646 --> 00:18:49.546 A:middle
the items will just get in queue

00:18:49.546 --> 00:18:50.726 A:middle
in the order that they appeared.

00:18:52.296 --> 00:18:53.186 A:middle
And because this is the

00:18:53.186 --> 00:18:54.946 A:middle
asynchronous method, this method

00:18:54.946 --> 00:18:57.846 A:middle
returns and the threads can go

00:18:57.846 --> 00:18:59.486 A:middle
on their way, so maybe this

00:18:59.656 --> 00:19:00.776 A:middle
first thread eventually calls

00:19:00.776 --> 00:19:01.526 A:middle
queue.sync.

00:19:01.966 --> 00:19:02.886 A:middle
This is the way you interact

00:19:02.886 --> 00:19:03.936 A:middle
synchronously with the queue.

00:19:04.316 --> 00:19:05.356 A:middle
And because this is an ordered

00:19:05.356 --> 00:19:06.526 A:middle
primitive here, what this does

00:19:06.526 --> 00:19:07.566 A:middle
is it will in queue a

00:19:07.566 --> 00:19:09.726 A:middle
placeholder into the queue so

00:19:09.726 --> 00:19:12.716 A:middle
that the thread can wait until

00:19:12.716 --> 00:19:13.526 A:middle
it is its turn.

00:19:14.556 --> 00:19:16.876 A:middle
And now, there's this automatic

00:19:17.136 --> 00:19:18.506 A:middle
worker thread that will come

00:19:18.506 --> 00:19:19.826 A:middle
along to execute the

00:19:19.826 --> 00:19:21.556 A:middle
asynchronous work items, until

00:19:21.556 --> 00:19:22.896 A:middle
you get to that placeholder at

00:19:22.896 --> 00:19:24.446 A:middle
which point the ownership of the

00:19:24.446 --> 00:19:25.686 A:middle
queue will transfer to the

00:19:25.746 --> 00:19:27.136 A:middle
thread waiting in queue.sync so

00:19:27.136 --> 00:19:29.056 A:middle
that it can execute its block.

00:19:30.126 --> 00:19:32.746 A:middle
So, the next concept that we'll

00:19:32.746 --> 00:19:34.876 A:middle
need is the dispatch source.

00:19:35.106 --> 00:19:36.286 A:middle
This is our event monitoring

00:19:36.286 --> 00:19:37.456 A:middle
primitive in GCD.

00:19:37.846 --> 00:19:39.446 A:middle
Here we are setting one up to

00:19:39.446 --> 00:19:40.536 A:middle
monitor a default descriptive

00:19:40.536 --> 00:19:42.646 A:middle
for readability if you make read

00:19:42.646 --> 00:19:43.436 A:middle
source constructor.

00:19:43.806 --> 00:19:45.656 A:middle
You pass it in a queue which is

00:19:45.686 --> 00:19:46.996 A:middle
the target queue of the source,

00:19:47.336 --> 00:19:48.906 A:middle
which is where we execute the

00:19:48.906 --> 00:19:50.126 A:middle
event handle of the source,

00:19:50.446 --> 00:19:51.496 A:middle
which here just reads from the

00:19:51.496 --> 00:19:52.246 A:middle
default descriptor.

00:19:53.046 --> 00:19:54.166 A:middle
This target queue is also where

00:19:54.166 --> 00:19:55.406 A:middle
you might put other work that

00:19:55.406 --> 00:19:56.646 A:middle
should be serialized with this

00:19:56.646 --> 00:19:58.426 A:middle
operation, such as processing

00:19:58.426 --> 00:19:59.656 A:middle
the data that was read.

00:20:00.816 --> 00:20:02.206 A:middle
Then, we set the cancel handler

00:20:02.206 --> 00:20:03.396 A:middle
for the source, which is how

00:20:03.396 --> 00:20:04.786 A:middle
sources implement the

00:20:04.816 --> 00:20:06.326 A:middle
invalidation pattern.

00:20:07.056 --> 00:20:08.066 A:middle
And finally, when everything is

00:20:08.096 --> 00:20:09.166 A:middle
set up, you call source and

00:20:09.166 --> 00:20:10.566 A:middle
activate to start monitoring.

00:20:11.196 --> 00:20:12.736 A:middle
So, it's worth noting that

00:20:12.826 --> 00:20:14.546 A:middle
sources are really just an

00:20:14.546 --> 00:20:15.806 A:middle
instance of a more general

00:20:15.806 --> 00:20:17.606 A:middle
pattern throughout the OS, where

00:20:17.706 --> 00:20:19.116 A:middle
you have objects that deliver

00:20:19.116 --> 00:20:20.566 A:middle
events to you on a target queue

00:20:20.566 --> 00:20:21.486 A:middle
that you specify.

00:20:22.086 --> 00:20:23.696 A:middle
So, if you're familiar with XPC,

00:20:23.696 --> 00:20:25.476 A:middle
that would be another example of

00:20:25.546 --> 00:20:26.666 A:middle
that XPC connections.

00:20:27.986 --> 00:20:30.246 A:middle
And, it's worth noting that all

00:20:30.246 --> 00:20:31.086 A:middle
of everything we're telling you

00:20:31.086 --> 00:20:32.406 A:middle
today about sources really

00:20:32.406 --> 00:20:33.926 A:middle
applies to all such objects in

00:20:33.926 --> 00:20:34.266 A:middle
general.

00:20:36.286 --> 00:20:37.616 A:middle
So, putting these two concepts

00:20:37.616 --> 00:20:39.526 A:middle
together, we get what we call

00:20:39.526 --> 00:20:40.606 A:middle
the target queue hierarchy.

00:20:41.346 --> 00:20:46.156 A:middle
So, here we have two sources

00:20:46.156 --> 00:20:48.266 A:middle
with their associated target

00:20:48.296 --> 00:20:50.466 A:middle
queues, S1, S2 and the queue is

00:20:50.536 --> 00:20:50.886 A:middle
Q1 and Q2.

00:20:50.886 --> 00:20:52.416 A:middle
And we can form a little tree

00:20:52.416 --> 00:20:53.776 A:middle
out of this situation by adding

00:20:53.776 --> 00:20:54.856 A:middle
yet another serial queue to the

00:20:54.856 --> 00:20:57.296 A:middle
mix, by adding mutual exclusion

00:20:57.296 --> 00:20:58.706 A:middle
queue, EQ, at the bottom.

00:20:59.336 --> 00:21:00.636 A:middle
The way we do this is simply by

00:21:00.636 --> 00:21:02.006 A:middle
passing in the optional target

00:21:02.006 --> 00:21:03.486 A:middle
argument into the dispatch queue

00:21:03.486 --> 00:21:03.996 A:middle
constructor.

00:21:03.996 --> 00:21:06.786 A:middle
So, this gives you a shared

00:21:06.786 --> 00:21:08.216 A:middle
single mutual exclusion context

00:21:08.216 --> 00:21:09.096 A:middle
for this whole tree.

00:21:09.506 --> 00:21:11.466 A:middle
Only one of the sources or one

00:21:11.466 --> 00:21:12.636 A:middle
item in one of the queues can

00:21:12.636 --> 00:21:13.686 A:middle
execute at one time.

00:21:14.426 --> 00:21:16.086 A:middle
But it preserves the independent

00:21:16.086 --> 00:21:17.606 A:middle
individual queue order for queue

00:21:17.606 --> 00:21:18.756 A:middle
1 and queue 2.

00:21:19.216 --> 00:21:20.456 A:middle
So, let's look at what I mean by

00:21:20.456 --> 00:21:21.586 A:middle
that.

00:21:22.376 --> 00:21:23.876 A:middle
Here I have the two queues,

00:21:23.876 --> 00:21:25.806 A:middle
queue 1 and queue 2 with them

00:21:25.806 --> 00:21:27.036 A:middle
queued in a specific order.

00:21:27.796 --> 00:21:28.936 A:middle
And because we have this extra

00:21:28.936 --> 00:21:30.476 A:middle
serial queue at the bottom, and

00:21:30.476 --> 00:21:32.186 A:middle
the executes, they will execute

00:21:32.266 --> 00:21:34.516 A:middle
in EQ and there will be a single

00:21:34.516 --> 00:21:35.626 A:middle
worker thread executing these

00:21:35.626 --> 00:21:36.916 A:middle
items giving you that mutual

00:21:36.916 --> 00:21:38.386 A:middle
exclusion property, only one

00:21:38.386 --> 00:21:39.686 A:middle
item executing at one time.

00:21:39.736 --> 00:21:41.476 A:middle
But as you can see, the items

00:21:41.476 --> 00:21:42.756 A:middle
from both queues can execute

00:21:42.796 --> 00:21:44.736 A:middle
interleafed while preserving the

00:21:44.736 --> 00:21:45.996 A:middle
individual order that they had

00:21:45.996 --> 00:21:47.056 A:middle
in their original queues.

00:21:47.606 --> 00:21:51.236 A:middle
So, the last concept that we'll

00:21:51.236 --> 00:21:53.026 A:middle
need today, is the notion of

00:21:53.026 --> 00:21:54.026 A:middle
quality of service.

00:21:55.296 --> 00:21:56.906 A:middle
Here is a fairly deed concept

00:21:56.906 --> 00:21:57.876 A:middle
that was talked about in some

00:21:57.876 --> 00:21:58.886 A:middle
detail in the past.

00:21:58.886 --> 00:22:00.006 A:middle
In particular, in the power

00:22:00.006 --> 00:22:01.166 A:middle
performance and diagnostics

00:22:01.166 --> 00:22:03.726 A:middle
session in 2014.

00:22:03.726 --> 00:22:05.576 A:middle
So, if this is new to you, I

00:22:05.576 --> 00:22:07.066 A:middle
would encourage you to go and

00:22:07.066 --> 00:22:07.606 A:middle
watch that.

00:22:08.456 --> 00:22:09.826 A:middle
But what we'll need today from

00:22:09.826 --> 00:22:11.556 A:middle
this is really mostly it's

00:22:11.916 --> 00:22:13.226 A:middle
abstract notion of priority.

00:22:14.686 --> 00:22:16.486 A:middle
And we'll use the terms QOS and

00:22:16.486 --> 00:22:18.446 A:middle
priority somewhat

00:22:18.446 --> 00:22:19.456 A:middle
interchangeably in the rest of

00:22:19.496 --> 00:22:19.966 A:middle
the session.

00:22:21.266 --> 00:22:22.536 A:middle
We have four quality of service

00:22:22.536 --> 00:22:23.506 A:middle
classes on the system.

00:22:23.746 --> 00:22:25.056 A:middle
From the highest user

00:22:25.056 --> 00:22:27.136 A:middle
interactive UI to user

00:22:27.136 --> 00:22:30.216 A:middle
initiated, or IN, utility, UT to

00:22:30.366 --> 00:22:31.516 A:middle
background BG.

00:22:32.056 --> 00:22:32.866 A:middle
The lowest priority.

00:22:33.986 --> 00:22:35.366 A:middle
So, let's look at how we would

00:22:35.366 --> 00:22:36.876 A:middle
combine this concept of quality

00:22:36.876 --> 00:22:38.346 A:middle
of service with the target queue

00:22:38.346 --> 00:22:39.326 A:middle
hierarchy that we just looked

00:22:39.326 --> 00:22:39.516 A:middle
at.

00:22:40.286 --> 00:22:41.856 A:middle
In this hierarchy, every node in

00:22:41.856 --> 00:22:42.746 A:middle
the tree can actually have a

00:22:42.746 --> 00:22:43.826 A:middle
quality of service label

00:22:43.826 --> 00:22:44.646 A:middle
associated with it.

00:22:45.436 --> 00:22:47.086 A:middle
So, for instance the source 2

00:22:47.086 --> 00:22:48.146 A:middle
might be relevant to the user

00:22:48.146 --> 00:22:48.716 A:middle
interface.

00:22:49.096 --> 00:22:50.156 A:middle
It might be monitored for an

00:22:50.156 --> 00:22:51.376 A:middle
event where we should update the

00:22:51.376 --> 00:22:52.556 A:middle
UI as soon as the event

00:22:52.556 --> 00:22:52.876 A:middle
triggers.

00:22:52.876 --> 00:22:55.036 A:middle
So, it could be that we want to

00:22:55.036 --> 00:22:56.546 A:middle
put the UI label onto the

00:22:56.546 --> 00:22:57.046 A:middle
source.

00:22:57.916 --> 00:22:59.006 A:middle
Another common use source would

00:22:59.006 --> 00:23:01.546 A:middle
be to put a label on the mutual

00:23:01.546 --> 00:23:03.066 A:middle
exclusion queue to provide a

00:23:03.066 --> 00:23:04.866 A:middle
flow of execution so that

00:23:04.866 --> 00:23:06.296 A:middle
nothing in this tree can execute

00:23:06.296 --> 00:23:08.146 A:middle
below this level, so UT in this

00:23:08.146 --> 00:23:08.606 A:middle
example.

00:23:09.106 --> 00:23:11.946 A:middle
And now if anything else in this

00:23:11.946 --> 00:23:13.636 A:middle
queue fires, for instance source

00:23:13.636 --> 00:23:16.516 A:middle
1, we will be using this flow

00:23:16.516 --> 00:23:18.016 A:middle
for the tree if it doesn't have

00:23:18.016 --> 00:23:19.076 A:middle
its own quality of service

00:23:19.076 --> 00:23:19.626 A:middle
associated.

00:23:21.426 --> 00:23:23.816 A:middle
And source firing is really just

00:23:23.816 --> 00:23:26.116 A:middle
an async executes from the

00:23:26.116 --> 00:23:26.516 A:middle
kernel.

00:23:26.886 --> 00:23:28.576 A:middle
And the same as before happens,

00:23:28.576 --> 00:23:29.806 A:middle
we end queue the source handler

00:23:30.206 --> 00:23:31.366 A:middle
eventually into the mutual

00:23:31.366 --> 00:23:32.656 A:middle
exclusion queue for execution.

00:23:34.176 --> 00:23:36.536 A:middle
For asyncs from user space, your

00:23:36.536 --> 00:23:37.666 A:middle
quality of service is usually

00:23:37.666 --> 00:23:38.706 A:middle
determined from the thread that

00:23:38.706 --> 00:23:39.746 A:middle
called queueu.async.

00:23:39.816 --> 00:23:41.646 A:middle
Now, we have a user initiated

00:23:41.646 --> 00:23:44.696 A:middle
thread that makes item at IN

00:23:44.696 --> 00:23:46.586 A:middle
into the queue and for execution

00:23:46.586 --> 00:23:47.666 A:middle
into E queue eventually.

00:23:48.296 --> 00:23:49.626 A:middle
And now, maybe we have the

00:23:49.626 --> 00:23:50.876 A:middle
source 2 that flies with this

00:23:50.876 --> 00:23:53.086 A:middle
very high priority UI relevant

00:23:53.086 --> 00:23:54.836 A:middle
event that executes its event

00:23:54.836 --> 00:23:56.156 A:middle
handler, and queues its event

00:23:56.156 --> 00:23:57.216 A:middle
handler into EQ.

00:23:58.216 --> 00:23:59.306 A:middle
So, now you'll notice that we

00:23:59.306 --> 00:24:01.076 A:middle
have a priority inversion

00:24:01.076 --> 00:24:01.616 A:middle
situation.

00:24:01.616 --> 00:24:02.756 A:middle
We have three items in queue

00:24:02.806 --> 00:24:04.136 A:middle
with a very high priority item

00:24:04.136 --> 00:24:06.116 A:middle
at the end preceded by some low

00:24:06.156 --> 00:24:06.796 A:middle
priority items.

00:24:07.166 --> 00:24:08.216 A:middle
And these have to execute in

00:24:08.216 --> 00:24:08.506 A:middle
order.

00:24:09.716 --> 00:24:10.686 A:middle
The system resolves this

00:24:10.686 --> 00:24:12.036 A:middle
inversion for you by bringing up

00:24:12.036 --> 00:24:14.056 A:middle
a worker thread at the highest

00:24:14.306 --> 00:24:15.696 A:middle
priority of anything that is

00:24:15.766 --> 00:24:16.466 A:middle
currently in queue.

00:24:16.466 --> 00:24:19.116 A:middle
And it's worth keeping this

00:24:19.116 --> 00:24:20.196 A:middle
little tree on the right hand

00:24:20.196 --> 00:24:21.306 A:middle
side here in mind because it

00:24:21.306 --> 00:24:22.436 A:middle
comes up again later in the

00:24:22.436 --> 00:24:22.776 A:middle
session.

00:24:24.166 --> 00:24:28.376 A:middle
And with that let's move on to

00:24:28.376 --> 00:24:29.666 A:middle
our main topic of the section

00:24:29.666 --> 00:24:31.016 A:middle
which is how to use what we just

00:24:31.016 --> 00:24:32.216 A:middle
learned to express good

00:24:32.216 --> 00:24:34.956 A:middle
granularity of concurrency to

00:24:35.636 --> 00:24:35.726 A:middle
GCD.

00:24:35.956 --> 00:24:36.946 A:middle
Let's go back to our news

00:24:36.946 --> 00:24:37.836 A:middle
application that Daniel

00:24:37.836 --> 00:24:39.526 A:middle
introduced earlier and focus on

00:24:39.526 --> 00:24:40.806 A:middle
the networking subsystem for a

00:24:40.806 --> 00:24:43.626 A:middle
little bit.

00:24:43.626 --> 00:24:45.116 A:middle
In a networking subsystem,

00:24:45.116 --> 00:24:46.056 A:middle
you'll have to monitor some

00:24:46.056 --> 00:24:47.056 A:middle
network connections in the

00:24:47.056 --> 00:24:47.456 A:middle
kernel.

00:24:47.936 --> 00:24:49.246 A:middle
And with GCD you'll do that with

00:24:49.246 --> 00:24:50.256 A:middle
a dispatch source, and the

00:24:50.296 --> 00:24:51.326 A:middle
dispatch queue like you just

00:24:51.326 --> 00:24:51.596 A:middle
saw.

00:24:51.596 --> 00:24:53.426 A:middle
But of course in any networking

00:24:53.426 --> 00:24:54.706 A:middle
subsystem you usually not just

00:24:54.706 --> 00:24:55.746 A:middle
have one network connection,

00:24:55.746 --> 00:24:58.036 A:middle
you'll have many of them and

00:24:58.036 --> 00:24:59.276 A:middle
they will all replicate the same

00:24:59.276 --> 00:24:59.876 A:middle
setup.

00:25:00.716 --> 00:25:01.766 A:middle
So, let's focus on the right

00:25:01.766 --> 00:25:03.036 A:middle
hand side on the three

00:25:03.036 --> 00:25:04.806 A:middle
connections here and see how the

00:25:04.806 --> 00:25:05.306 A:middle
execute.

00:25:06.936 --> 00:25:07.896 A:middle
If the first connection

00:25:07.896 --> 00:25:09.736 A:middle
triggers, just like the same

00:25:09.736 --> 00:25:11.146 A:middle
thing we just saw happens, we

00:25:11.146 --> 00:25:12.496 A:middle
will end queue the event handler

00:25:12.496 --> 00:25:14.206 A:middle
for that source onto its target

00:25:14.206 --> 00:25:14.366 A:middle
queue.

00:25:14.456 --> 00:25:16.206 A:middle
Of course if the other two

00:25:16.386 --> 00:25:17.406 A:middle
connections fire at the same

00:25:17.406 --> 00:25:18.546 A:middle
time, they'll still replicated

00:25:18.546 --> 00:25:19.386 A:middle
and you'll end up with three

00:25:19.386 --> 00:25:21.056 A:middle
queues with an event handler end

00:25:21.056 --> 00:25:21.296 A:middle
queued.

00:25:22.026 --> 00:25:23.516 A:middle
And because you have these three

00:25:23.646 --> 00:25:24.846 A:middle
independent serial queues at the

00:25:24.846 --> 00:25:26.166 A:middle
bottom, you've really asked the

00:25:26.166 --> 00:25:27.606 A:middle
system to provide you with three

00:25:27.606 --> 00:25:28.646 A:middle
independent concurrency

00:25:28.646 --> 00:25:29.236 A:middle
contexts.

00:25:29.676 --> 00:25:30.806 A:middle
If all these become active at

00:25:30.806 --> 00:25:32.846 A:middle
once, the system will oblige and

00:25:32.846 --> 00:25:34.356 A:middle
create three threads for you to

00:25:34.356 --> 00:25:35.516 A:middle
execute the event handlers.

00:25:36.616 --> 00:25:37.616 A:middle
Now, this may be what you

00:25:37.616 --> 00:25:39.016 A:middle
wanted, and maybe exactly what

00:25:39.016 --> 00:25:40.856 A:middle
you were after, but it is quite

00:25:40.856 --> 00:25:42.786 A:middle
common for these event handlers

00:25:42.786 --> 00:25:45.236 A:middle
to be small and only read some

00:25:45.276 --> 00:25:46.576 A:middle
data from the network and in

00:25:46.576 --> 00:25:47.486 A:middle
queue it into a common data

00:25:47.486 --> 00:25:47.876 A:middle
structure.

00:25:48.696 --> 00:25:50.186 A:middle
Additionally, as we saw before,

00:25:50.186 --> 00:25:51.106 A:middle
you don't have just three

00:25:51.106 --> 00:25:52.326 A:middle
connections, you may have many,

00:25:52.326 --> 00:25:53.836 A:middle
many of them if you have a

00:25:53.836 --> 00:25:55.576 A:middle
number of network connections in

00:25:55.676 --> 00:25:56.336 A:middle
your subsystem.

00:25:57.096 --> 00:25:58.246 A:middle
So, this can leave to a

00:25:58.246 --> 00:25:59.436 A:middle
situation where you have this

00:25:59.506 --> 00:26:00.726 A:middle
kind of context switching

00:26:00.726 --> 00:26:02.086 A:middle
pattern, and excessive context

00:26:02.086 --> 00:26:03.006 A:middle
switching that Daniel talked

00:26:03.006 --> 00:26:04.636 A:middle
about where you execute a small

00:26:04.636 --> 00:26:06.196 A:middle
amount of work, context switch

00:26:06.196 --> 00:26:07.176 A:middle
to another thread and do that

00:26:07.176 --> 00:26:08.526 A:middle
again, and again, and again.

00:26:09.146 --> 00:26:10.816 A:middle
So, how can we improve on this

00:26:10.816 --> 00:26:12.466 A:middle
situation in this example here?

00:26:13.286 --> 00:26:15.066 A:middle
We can apply the single mutual

00:26:15.066 --> 00:26:16.326 A:middle
exclusion context idea that we

00:26:16.326 --> 00:26:18.076 A:middle
just talked about by simply

00:26:18.076 --> 00:26:19.426 A:middle
putting in an additional serial

00:26:19.426 --> 00:26:21.056 A:middle
queue at the bottom and forming

00:26:21.056 --> 00:26:23.436 A:middle
a hierarchy, you can get a

00:26:23.436 --> 00:26:24.776 A:middle
single mutual exclusion context

00:26:24.776 --> 00:26:26.006 A:middle
for all of these connections.

00:26:26.756 --> 00:26:27.906 A:middle
And if they fire at the same

00:26:27.906 --> 00:26:29.386 A:middle
time, the same thing as before

00:26:29.386 --> 00:26:30.436 A:middle
will happen, the event handlers

00:26:30.436 --> 00:26:31.446 A:middle
will get end queued onto the

00:26:31.446 --> 00:26:33.046 A:middle
target queues, but because

00:26:33.076 --> 00:26:33.986 A:middle
there's an additional serial

00:26:33.986 --> 00:26:35.526 A:middle
queue at the bottom here, it's a

00:26:35.526 --> 00:26:36.626 A:middle
single thread that will come and

00:26:36.626 --> 00:26:38.306 A:middle
execute them in order instead of

00:26:38.376 --> 00:26:39.516 A:middle
the multiple threads that we had

00:26:39.546 --> 00:26:39.966 A:middle
before.

00:26:41.126 --> 00:26:42.276 A:middle
So, this seems like a really

00:26:42.276 --> 00:26:44.236 A:middle
simple change but it is exactly

00:26:44.236 --> 00:26:45.816 A:middle
the type of change that lead to

00:26:45.816 --> 00:26:46.986 A:middle
the 1.3 X performance

00:26:46.986 --> 00:26:48.356 A:middle
improvement in some of our own

00:26:48.436 --> 00:26:50.706 A:middle
code that Daniel talked about

00:26:50.706 --> 00:26:52.246 A:middle
earlier in the session.

00:26:53.256 --> 00:26:57.436 A:middle
So, this is one example of how

00:26:57.436 --> 00:26:58.956 A:middle
we can avoid the problematic

00:26:58.956 --> 00:27:00.186 A:middle
pattern of repeatedly switching

00:27:00.186 --> 00:27:01.506 A:middle
between independent operations.

00:27:02.426 --> 00:27:03.616 A:middle
But it really comes under the

00:27:03.616 --> 00:27:04.836 A:middle
general heading of avoiding

00:27:05.146 --> 00:27:06.696 A:middle
unwanted and unbounded

00:27:06.696 --> 00:27:08.036 A:middle
concurrency in application.

00:27:09.346 --> 00:27:10.746 A:middle
One way you can get that is by

00:27:10.746 --> 00:27:11.916 A:middle
having many queues becoming

00:27:11.916 --> 00:27:12.806 A:middle
active all at once.

00:27:13.366 --> 00:27:15.196 A:middle
And one example of this is that

00:27:15.196 --> 00:27:16.366 A:middle
independent requiring source

00:27:16.396 --> 00:27:17.906 A:middle
pattern that we just say.

00:27:18.236 --> 00:27:19.196 A:middle
You can also get this if you

00:27:19.196 --> 00:27:20.356 A:middle
have independent or object

00:27:20.476 --> 00:27:21.036 A:middle
queues.

00:27:21.556 --> 00:27:22.806 A:middle
If many objects in your

00:27:22.806 --> 00:27:23.596 A:middle
application have their own

00:27:23.596 --> 00:27:24.866 A:middle
serial queues and you put

00:27:24.866 --> 00:27:26.076 A:middle
asynchronous work into them at

00:27:26.076 --> 00:27:27.276 A:middle
the same time you can get

00:27:27.276 --> 00:27:29.196 A:middle
exactly the same phenomenon.

00:27:31.046 --> 00:27:32.086 A:middle
You can also see this if you

00:27:32.086 --> 00:27:33.476 A:middle
have many work items submitted

00:27:33.476 --> 00:27:34.726 A:middle
to the global concurrent queue

00:27:34.726 --> 00:27:35.386 A:middle
at the same time.

00:27:36.406 --> 00:27:37.566 A:middle
In particular if there's work

00:27:37.566 --> 00:27:38.176 A:middle
items block.

00:27:38.726 --> 00:27:40.276 A:middle
The way the global concurrent

00:27:40.276 --> 00:27:41.496 A:middle
queue works is that it corrects

00:27:41.496 --> 00:27:42.966 A:middle
more threads when existing

00:27:42.966 --> 00:27:44.316 A:middle
threads block to give you a

00:27:44.316 --> 00:27:45.236 A:middle
continuing good level of

00:27:45.236 --> 00:27:46.566 A:middle
concurrency in your application.

00:27:47.026 --> 00:27:48.276 A:middle
But if those threads then block

00:27:48.276 --> 00:27:50.096 A:middle
again, you can get something

00:27:50.346 --> 00:27:51.276 A:middle
that we call the thread

00:27:51.276 --> 00:27:51.836 A:middle
explosion.

00:27:52.876 --> 00:27:53.986 A:middle
This is a topic that we went

00:27:53.986 --> 00:27:55.196 A:middle
into some detail in the

00:27:55.196 --> 00:27:56.256 A:middle
"Building Responses and

00:27:56.256 --> 00:27:57.186 A:middle
Efficient Apps with GCD" in

00:27:57.186 --> 00:27:59.146 A:middle
2015.

00:27:59.636 --> 00:28:01.516 A:middle
So, if this sounds new to you,

00:28:01.566 --> 00:28:02.506 A:middle
I'd encourage you to go and

00:28:02.506 --> 00:28:03.216 A:middle
watch that session.

00:28:04.826 --> 00:28:06.096 A:middle
So, how do you choose the right

00:28:06.096 --> 00:28:07.176 A:middle
amount of concurrency in your

00:28:07.176 --> 00:28:08.316 A:middle
application to avoid these

00:28:08.316 --> 00:28:09.116 A:middle
problematic patterns?

00:28:10.286 --> 00:28:11.606 A:middle
One idea that we've recommended

00:28:11.606 --> 00:28:13.556 A:middle
to you in the past is to use one

00:28:13.556 --> 00:28:14.536 A:middle
queue for subsystem.

00:28:15.816 --> 00:28:17.116 A:middle
So, here back in our news

00:28:17.116 --> 00:28:18.716 A:middle
application, we already have one

00:28:18.716 --> 00:28:19.816 A:middle
queue for the user interface,

00:28:19.816 --> 00:28:21.086 A:middle
the main queue and we could

00:28:21.086 --> 00:28:22.356 A:middle
choose one queue for the

00:28:22.356 --> 00:28:24.076 A:middle
networking and 1 queue for the

00:28:24.076 --> 00:28:25.776 A:middle
database subsystem in addition.

00:28:27.016 --> 00:28:28.666 A:middle
But what we've learned today a

00:28:28.666 --> 00:28:29.676 A:middle
more general way to think of

00:28:29.736 --> 00:28:31.036 A:middle
this is really to use one queue

00:28:31.036 --> 00:28:32.336 A:middle
hierarchy per subsystem.

00:28:33.656 --> 00:28:37.066 A:middle
This gives you a mutual

00:28:37.066 --> 00:28:37.996 A:middle
exclusion context for the

00:28:37.996 --> 00:28:39.806 A:middle
subsystem, and you can leave the

00:28:39.806 --> 00:28:41.516 A:middle
rest of the queue event sub

00:28:41.516 --> 00:28:42.936 A:middle
structing and subsystem alone

00:28:43.306 --> 00:28:45.106 A:middle
and just target that network

00:28:45.246 --> 00:28:47.406 A:middle
queue or database queue that

00:28:47.406 --> 00:28:49.486 A:middle
underlies the bottom of your

00:28:49.486 --> 00:28:50.406 A:middle
queue hierarchies.

00:28:53.296 --> 00:28:56.756 A:middle
But, that may be a bit too

00:28:56.756 --> 00:28:57.756 A:middle
simplistic a pattern for a

00:28:57.756 --> 00:28:59.226 A:middle
complex application or a complex

00:28:59.226 --> 00:28:59.766 A:middle
subsystem.

00:29:00.176 --> 00:29:01.306 A:middle
The main thing that is important

00:29:01.306 --> 00:29:02.476 A:middle
here is to have a fixed number

00:29:02.476 --> 00:29:03.526 A:middle
of serial queue hierarchies in

00:29:03.526 --> 00:29:04.146 A:middle
your application.

00:29:04.676 --> 00:29:05.706 A:middle
So, it may make sense to have

00:29:05.706 --> 00:29:07.236 A:middle
additional queue hierarchies for

00:29:07.236 --> 00:29:08.646 A:middle
a complicated subsystem, say a

00:29:08.646 --> 00:29:10.286 A:middle
secondary one for slower work,

00:29:10.286 --> 00:29:11.516 A:middle
or larger work items, so that

00:29:11.556 --> 00:29:13.286 A:middle
the first one, the primary one

00:29:13.286 --> 00:29:14.276 A:middle
can keep the subsystem

00:29:14.276 --> 00:29:15.796 A:middle
responsive to requests coming in

00:29:15.796 --> 00:29:16.366 A:middle
from outside.

00:29:17.396 --> 00:29:19.596 A:middle
Another thing that's important

00:29:19.596 --> 00:29:20.976 A:middle
to think about in this context

00:29:21.426 --> 00:29:23.166 A:middle
is the granularity of the work

00:29:23.306 --> 00:29:24.656 A:middle
submitted to those subsystems.

00:29:25.856 --> 00:29:26.936 A:middle
You want to use fairly large

00:29:26.936 --> 00:29:28.276 A:middle
work items when you move between

00:29:28.276 --> 00:29:30.146 A:middle
subsystems to get a picture like

00:29:30.146 --> 00:29:31.776 A:middle
what we say earlier in the

00:29:31.776 --> 00:29:34.176 A:middle
session, where the CP is able to

00:29:34.176 --> 00:29:35.536 A:middle
execute your subsystem for long

00:29:35.536 --> 00:29:37.726 A:middle
enough to reach an efficient

00:29:37.726 --> 00:29:38.396 A:middle
performance state.

00:29:39.986 --> 00:29:40.786 A:middle
Once you're inside the

00:29:40.786 --> 00:29:41.956 A:middle
subsystem, say the networking

00:29:41.956 --> 00:29:42.756 A:middle
subsystem here.

00:29:43.246 --> 00:29:44.736 A:middle
It may make sense to subdivide

00:29:44.986 --> 00:29:47.676 A:middle
into smaller block items and

00:29:47.676 --> 00:29:49.166 A:middle
have a finer granularity to

00:29:49.166 --> 00:29:50.326 A:middle
improve the responsiveness of

00:29:50.326 --> 00:29:51.156 A:middle
that subsystem.

00:29:51.606 --> 00:29:52.726 A:middle
For instance, you can to that by

00:29:52.726 --> 00:29:53.946 A:middle
splitting up your work and

00:29:53.946 --> 00:29:55.956 A:middle
re-asyncing to another queue in

00:29:55.956 --> 00:29:56.746 A:middle
your queue hierarchy.

00:29:56.746 --> 00:29:57.646 A:middle
And that doesn't introduce a

00:29:57.646 --> 00:29:58.686 A:middle
context switch because you're

00:29:58.686 --> 00:30:02.926 A:middle
already in that one subsystem.

00:30:03.426 --> 00:30:04.706 A:middle
So, in summary, what have we

00:30:04.706 --> 00:30:05.676 A:middle
looked at in this section?

00:30:06.956 --> 00:30:08.326 A:middle
We saw how we can organize

00:30:08.326 --> 00:30:09.956 A:middle
queues and sources into serial

00:30:09.956 --> 00:30:10.726 A:middle
queue hierarchies.

00:30:11.246 --> 00:30:12.946 A:middle
How to use a fixed number of the

00:30:12.946 --> 00:30:14.526 A:middle
queue hierarchies to give GCD a

00:30:14.526 --> 00:30:16.096 A:middle
good granularity of concurrency.

00:30:16.676 --> 00:30:18.796 A:middle
And how to size your work items

00:30:18.796 --> 00:30:20.406 A:middle
appropriately earlier in the

00:30:20.406 --> 00:30:22.176 A:middle
section for parallel work and

00:30:22.176 --> 00:30:24.806 A:middle
here for concurrent work inside

00:30:24.806 --> 00:30:26.346 A:middle
the subsystem as well as between

00:30:26.346 --> 00:30:26.916 A:middle
subsystems.

00:30:27.556 --> 00:30:29.186 A:middle
And with this, I'll hand it over

00:30:29.186 --> 00:30:30.866 A:middle
to Pierre to dive into how we

00:30:30.866 --> 00:30:32.746 A:middle
have improved GCD to always

00:30:32.746 --> 00:30:33.916 A:middle
execute the queue hierarchy on a

00:30:33.916 --> 00:30:35.216 A:middle
single thread and how you can

00:30:35.216 --> 00:30:36.926 A:middle
modernize your code to take

00:30:36.926 --> 00:30:37.686 A:middle
advantage of this.

00:30:38.516 --> 00:30:43.876 A:middle
[ Applause ]

00:30:44.376 --> 00:30:45.006 A:middle
&gt;&gt; Thank you Daniel.

00:30:46.506 --> 00:30:49.036 A:middle
So, indeed we have completely

00:30:49.036 --> 00:30:51.076 A:middle
reinvented the internals of GCD

00:30:51.076 --> 00:30:52.826 A:middle
this year to eliminate some

00:30:52.826 --> 00:30:54.936 A:middle
unwanted context switches and

00:30:54.936 --> 00:30:56.836 A:middle
execute single queue hierarchies

00:30:56.836 --> 00:30:58.266 A:middle
like the ones that Daniel showed

00:30:58.686 --> 00:30:59.456 A:middle
on the single thread.

00:31:00.476 --> 00:31:02.696 A:middle
To do so we have created a new

00:31:03.156 --> 00:31:04.476 A:middle
kind of concepts that we call

00:31:04.786 --> 00:31:06.626 A:middle
Unified Queue Identity that let

00:31:06.626 --> 00:31:07.296 A:middle
us do that.

00:31:07.296 --> 00:31:09.126 A:middle
And we will walk you through how

00:31:09.896 --> 00:31:10.716 A:middle
it works.

00:31:11.486 --> 00:31:16.046 A:middle
So, really this part of the talk

00:31:16.046 --> 00:31:17.626 A:middle
will focus on a single queue

00:31:17.626 --> 00:31:19.386 A:middle
hierarchy, like the ones Daniel

00:31:19.386 --> 00:31:19.956 A:middle
showed earlier.

00:31:20.516 --> 00:31:21.696 A:middle
However, we'll work on

00:31:21.696 --> 00:31:23.956 A:middle
simplified ones with the sources

00:31:23.956 --> 00:31:25.946 A:middle
at the top, and your mutual

00:31:25.946 --> 00:31:27.896 A:middle
exclusion context at the bottom.

00:31:27.896 --> 00:31:28.976 A:middle
The internal GCD notes are not

00:31:28.976 --> 00:31:31.966 A:middle
quite given for that part of the

00:31:33.236 --> 00:31:33.346 A:middle
talk.

00:31:33.676 --> 00:31:35.436 A:middle
So, when you create an

00:31:35.436 --> 00:31:36.196 A:middle
[inaudible] context you use to

00:31:36.196 --> 00:31:38.876 A:middle
dispatch queue constructor, that

00:31:38.906 --> 00:31:40.266 A:middle
creates just a piece of memory

00:31:40.266 --> 00:31:41.426 A:middle
in your application that is a

00:31:41.426 --> 00:31:41.706 A:middle
note.

00:31:42.306 --> 00:31:43.476 A:middle
And one of the first things that

00:31:43.476 --> 00:31:45.786 A:middle
you may do is to dispatch recent

00:31:45.786 --> 00:31:47.636 A:middle
coded items to it.

00:31:48.146 --> 00:31:49.496 A:middle
So, you will have code in your

00:31:49.496 --> 00:31:51.946 A:middle
application that will here and

00:31:51.946 --> 00:31:53.946 A:middle
queue a [inaudible] on the

00:31:53.946 --> 00:31:56.976 A:middle
queue, when that happened before

00:31:56.976 --> 00:31:58.836 A:middle
we used to request a thread

00:31:58.836 --> 00:32:01.486 A:middle
anonymously to the system.

00:32:01.666 --> 00:32:03.846 A:middle
And the resolution of what that

00:32:03.846 --> 00:32:05.686 A:middle
was meant to do happens late

00:32:05.776 --> 00:32:06.686 A:middle
inside your application.

00:32:08.246 --> 00:32:09.996 A:middle
In this case, we change that and

00:32:09.996 --> 00:32:11.836 A:middle
what we do is that we create our

00:32:11.876 --> 00:32:13.676 A:middle
counter object, the Unified

00:32:13.676 --> 00:32:15.536 A:middle
Queue Identity that is tied to

00:32:15.536 --> 00:32:17.716 A:middle
your queue and is exactly meant

00:32:17.716 --> 00:32:18.806 A:middle
to represent your queue in the

00:32:18.806 --> 00:32:19.156 A:middle
kernel.

00:32:20.076 --> 00:32:21.536 A:middle
We can tie that object with the

00:32:21.536 --> 00:32:23.026 A:middle
required hierarchy to execute to

00:32:23.026 --> 00:32:24.676 A:middle
work, which here is backup.

00:32:25.276 --> 00:32:27.276 A:middle
And that causes the system to

00:32:27.276 --> 00:32:28.036 A:middle
ask for a thread.

00:32:28.856 --> 00:32:31.066 A:middle
The thread request, that dotted

00:32:31.066 --> 00:32:33.656 A:middle
line on the slide, may not be

00:32:33.656 --> 00:32:35.886 A:middle
fulfilled for some time, because

00:32:35.886 --> 00:32:36.996 A:middle
here that's a background thread,

00:32:37.236 --> 00:32:38.506 A:middle
and maybe the system is loaded

00:32:38.506 --> 00:32:40.046 A:middle
enough that it's not even worth

00:32:40.046 --> 00:32:44.606 A:middle
giving you a thread for it.

00:32:44.606 --> 00:32:45.926 A:middle
Later on, some other path of

00:32:46.086 --> 00:32:49.176 A:middle
your application may actually

00:32:49.176 --> 00:32:50.726 A:middle
try to en queue more work.

00:32:50.726 --> 00:32:51.216 A:middle
Here a UT [inaudible] that is

00:32:51.216 --> 00:32:53.526 A:middle
slightly higher priority.

00:32:53.996 --> 00:32:55.956 A:middle
We can use the queue identity,

00:32:56.086 --> 00:32:57.496 A:middle
the unified identity in the

00:32:57.496 --> 00:32:58.586 A:middle
catalog to look and solve the

00:32:58.586 --> 00:32:59.866 A:middle
priority inversion, and elevate

00:32:59.866 --> 00:33:00.916 A:middle
the priority of that thread

00:33:00.916 --> 00:33:01.426 A:middle
request.

00:33:01.906 --> 00:33:03.196 A:middle
It may be that is the small

00:33:03.196 --> 00:33:04.846 A:middle
nudge that the system needed to

00:33:04.846 --> 00:33:06.206 A:middle
actually give you a thread here

00:33:06.206 --> 00:33:07.736 A:middle
to execute your work.

00:33:08.016 --> 00:33:09.116 A:middle
But this thread is in the

00:33:09.116 --> 00:33:10.406 A:middle
scheduler queues not yet on

00:33:10.406 --> 00:33:10.626 A:middle
call.

00:33:10.626 --> 00:33:11.356 A:middle
Not executing.

00:33:11.946 --> 00:33:13.326 A:middle
And the reason why is because

00:33:13.326 --> 00:33:14.456 A:middle
there is another thread in your

00:33:14.456 --> 00:33:15.676 A:middle
application that is interacting

00:33:15.676 --> 00:33:16.746 A:middle
with a queue and working

00:33:16.746 --> 00:33:18.046 A:middle
synchronously at a higher

00:33:18.046 --> 00:33:19.756 A:middle
priority, even, usually shaded.

00:33:20.286 --> 00:33:23.056 A:middle
Now that we have that Unified

00:33:23.056 --> 00:33:24.486 A:middle
Queue Identity, we can actually

00:33:24.736 --> 00:33:26.346 A:middle
since that thread has to block

00:33:26.566 --> 00:33:27.826 A:middle
to en queue the placeholder that

00:33:27.826 --> 00:33:29.716 A:middle
Daniel told you about a bit

00:33:29.716 --> 00:33:31.956 A:middle
earlier, we can block the

00:33:31.956 --> 00:33:33.726 A:middle
synchronous execution of that

00:33:33.836 --> 00:33:35.196 A:middle
thread on the Unified Queue

00:33:35.196 --> 00:33:35.676 A:middle
Identity.

00:33:35.676 --> 00:33:36.816 A:middle
The same on that we use for

00:33:36.816 --> 00:33:38.226 A:middle
asynchronous work, [inaudible].

00:33:38.226 --> 00:33:41.046 A:middle
But now that we unified the

00:33:41.046 --> 00:33:43.056 A:middle
asynchronous and the synchronous

00:33:43.266 --> 00:33:44.786 A:middle
part of the queue in a single

00:33:44.786 --> 00:33:46.386 A:middle
identity, we can apply an

00:33:46.866 --> 00:33:48.566 A:middle
optimization and delicately

00:33:48.566 --> 00:33:49.686 A:middle
switch the thread that's

00:33:49.686 --> 00:33:51.266 A:middle
blocking you by passing the

00:33:51.266 --> 00:33:52.536 A:middle
scheduler queue and registering

00:33:52.536 --> 00:33:54.246 A:middle
the queue delays that Daniel

00:33:54.406 --> 00:33:55.936 A:middle
introduced while talking about

00:33:55.936 --> 00:33:56.896 A:middle
the scheduler very early.

00:33:58.016 --> 00:33:59.826 A:middle
So, that's how the unified queue

00:33:59.826 --> 00:34:00.986 A:middle
identity is used for for

00:34:00.986 --> 00:34:02.226 A:middle
asynchronous and synchronous

00:34:02.226 --> 00:34:02.846 A:middle
work items.

00:34:05.396 --> 00:34:07.256 A:middle
Now, how did we use that for

00:34:07.256 --> 00:34:07.816 A:middle
events?

00:34:08.016 --> 00:34:08.906 A:middle
Why is it useful?

00:34:09.846 --> 00:34:11.606 A:middle
So, that is the small tree that

00:34:11.606 --> 00:34:13.766 A:middle
we've been using so far, let's

00:34:13.766 --> 00:34:15.506 A:middle
look at the creation of these

00:34:15.506 --> 00:34:16.066 A:middle
sources.

00:34:17.356 --> 00:34:18.516 A:middle
When you create the source using

00:34:18.516 --> 00:34:20.716 A:middle
the makeResource factory button,

00:34:20.716 --> 00:34:22.476 A:middle
you set a bunch of events, of

00:34:22.476 --> 00:34:23.396 A:middle
favorite handlers and

00:34:23.396 --> 00:34:24.036 A:middle
properties.

00:34:24.516 --> 00:34:25.536 A:middle
But what is really interesting

00:34:25.536 --> 00:34:26.576 A:middle
is what happens when you

00:34:26.576 --> 00:34:28.386 A:middle
activating the object.

00:34:29.336 --> 00:34:31.576 A:middle
This is actually at that moment,

00:34:31.966 --> 00:34:33.756 A:middle
that we will notice that utility

00:34:33.886 --> 00:34:35.546 A:middle
are QOS, at which the handler

00:34:35.546 --> 00:34:36.716 A:middle
for your source will always

00:34:36.716 --> 00:34:37.266 A:middle
execute.

00:34:37.496 --> 00:34:38.806 A:middle
Because it's inherited from your

00:34:38.806 --> 00:34:39.406 A:middle
queue hierarchy.

00:34:39.716 --> 00:34:42.096 A:middle
We will also know now, with the

00:34:42.096 --> 00:34:44.796 A:middle
new system, that the handler

00:34:44.796 --> 00:34:46.456 A:middle
will eventually execute that in

00:34:46.576 --> 00:34:49.396 A:middle
queue execution mature exclusion

00:34:49.396 --> 00:34:49.936 A:middle
context.

00:34:50.816 --> 00:34:52.996 A:middle
And will now register the source

00:34:52.996 --> 00:34:55.156 A:middle
at front with the sync unified

00:34:55.156 --> 00:34:57.136 A:middle
identity that I just talked

00:34:57.136 --> 00:34:59.296 A:middle
about a bit earlier.

00:34:59.606 --> 00:35:01.796 A:middle
If we look at the higher UI QOS

00:35:02.016 --> 00:35:04.506 A:middle
source that we have on the tree,

00:35:05.146 --> 00:35:06.696 A:middle
the way we are treated is very

00:35:06.696 --> 00:35:09.276 A:middle
similar of the first one, except

00:35:09.276 --> 00:35:10.526 A:middle
that when you're setting the

00:35:10.586 --> 00:35:12.746 A:middle
handler here you're specifying

00:35:12.746 --> 00:35:14.406 A:middle
the QOS that you actually want.

00:35:15.366 --> 00:35:16.576 A:middle
And again, what's interesting is

00:35:16.576 --> 00:35:18.126 A:middle
what happens at activation.

00:35:18.126 --> 00:35:19.886 A:middle
That is when we the snapshot and

00:35:19.886 --> 00:35:21.936 A:middle
like before when we got the

00:35:21.936 --> 00:35:24.146 A:middle
utility QOS from your hierarchy,

00:35:24.436 --> 00:35:25.876 A:middle
here we get it from your hint.

00:35:26.796 --> 00:35:27.946 A:middle
We still recall the fact that

00:35:27.986 --> 00:35:29.606 A:middle
they will execute both the

00:35:29.606 --> 00:35:31.296 A:middle
sources on the same execution

00:35:31.296 --> 00:35:31.836 A:middle
context.

00:35:31.836 --> 00:35:33.376 A:middle
And will register that second

00:35:33.376 --> 00:35:34.486 A:middle
source up front again, which

00:35:34.706 --> 00:35:36.506 A:middle
with some unified identity in

00:35:37.096 --> 00:35:39.366 A:middle
the kernel.

00:35:39.506 --> 00:35:41.746 A:middle
So, really what we're trying to

00:35:41.746 --> 00:35:43.866 A:middle
solve with that quite complex

00:35:43.956 --> 00:35:46.446 A:middle
identity is a problem that we

00:35:46.446 --> 00:35:48.136 A:middle
had in previous phases of the

00:35:48.206 --> 00:35:51.316 A:middle
OS, where related operations

00:35:51.316 --> 00:35:52.846 A:middle
would actually bounce off the

00:35:52.846 --> 00:35:53.466 A:middle
old threads.

00:35:53.606 --> 00:35:54.766 A:middle
Let's look at how it used to

00:35:54.766 --> 00:35:55.116 A:middle
work.

00:35:56.086 --> 00:35:58.436 A:middle
So, remember that's our queue

00:35:58.436 --> 00:36:01.326 A:middle
hierarchy, and let's bring up

00:36:01.406 --> 00:36:02.536 A:middle
the timeline that you've seen a

00:36:02.536 --> 00:36:05.146 A:middle
bunch of times now in our talk.

00:36:05.276 --> 00:36:07.346 A:middle
At the top, the CPU, but now

00:36:07.346 --> 00:36:08.896 A:middle
there is a new tack, the

00:36:08.896 --> 00:36:10.756 A:middle
exclusion queue card that will

00:36:10.756 --> 00:36:12.586 A:middle
show you what is executing at

00:36:12.586 --> 00:36:15.696 A:middle
any given moment on that queue.

00:36:15.926 --> 00:36:17.506 A:middle
So, that's really how the

00:36:17.556 --> 00:36:19.366 A:middle
runtime used to work before this

00:36:19.366 --> 00:36:22.036 A:middle
phase in macOS Sierra and iOS

00:36:22.036 --> 00:36:22.306 A:middle
10.

00:36:22.616 --> 00:36:24.616 A:middle
So, let's look at what happens

00:36:24.616 --> 00:36:25.966 A:middle
if the first source fails.

00:36:26.626 --> 00:36:28.286 A:middle
Before, like I said thread

00:36:28.286 --> 00:36:29.396 A:middle
requests were anonymous.

00:36:29.396 --> 00:36:30.646 A:middle
We would ask for an anonymous

00:36:30.646 --> 00:36:31.846 A:middle
thread, deliver the event on the

00:36:31.846 --> 00:36:33.656 A:middle
thread and then we would look at

00:36:33.656 --> 00:36:33.976 A:middle
the event.

00:36:34.856 --> 00:36:36.706 A:middle
And when we look at the event

00:36:36.706 --> 00:36:38.436 A:middle
inside your application, that is

00:36:38.436 --> 00:36:39.996 A:middle
only then that we realize that

00:36:39.996 --> 00:36:41.966 A:middle
this event is meant to run on a

00:36:41.966 --> 00:36:42.206 A:middle
queue.

00:36:42.206 --> 00:36:43.876 A:middle
We would then queue the event

00:36:43.876 --> 00:36:44.276 A:middle
handler.

00:36:44.416 --> 00:36:46.926 A:middle
But since the queue is

00:36:46.926 --> 00:36:48.156 A:middle
unclaimed, the thread could

00:36:48.156 --> 00:36:50.856 A:middle
actually become that queue and

00:36:50.856 --> 00:36:52.356 A:middle
start executing given handler

00:36:52.766 --> 00:36:53.596 A:middle
for your source.

00:36:54.306 --> 00:36:54.886 A:middle
And we do so.

00:36:55.486 --> 00:36:56.926 A:middle
Now, the interesting thing is

00:36:56.926 --> 00:36:58.236 A:middle
what happens when the second

00:36:58.236 --> 00:36:59.346 A:middle
source that is higher priority

00:36:59.346 --> 00:36:59.896 A:middle
fires?

00:37:00.716 --> 00:37:01.626 A:middle
The same actually.

00:37:02.116 --> 00:37:03.726 A:middle
Since it's a hierarchy QOS here,

00:37:03.906 --> 00:37:05.146 A:middle
higher priority that's what

00:37:05.146 --> 00:37:06.216 A:middle
you're executing right now.

00:37:07.426 --> 00:37:08.566 A:middle
We would bring up a new

00:37:08.626 --> 00:37:10.076 A:middle
anonymous thread deliver that

00:37:10.136 --> 00:37:11.256 A:middle
higher priority event on the

00:37:11.306 --> 00:37:11.566 A:middle
thread.

00:37:13.196 --> 00:37:14.416 A:middle
And look at what that event

00:37:14.416 --> 00:37:14.886 A:middle
means.

00:37:15.036 --> 00:37:16.136 A:middle
And we will notice that it is

00:37:16.136 --> 00:37:17.096 A:middle
for exactly the same queue

00:37:17.096 --> 00:37:17.966 A:middle
hierarchy only then.

00:37:18.036 --> 00:37:19.676 A:middle
And then queue the handler after

00:37:19.676 --> 00:37:20.756 A:middle
the one we just pre emptied.

00:37:21.596 --> 00:37:23.186 A:middle
As you see, we closed our first

00:37:23.606 --> 00:37:24.176 A:middle
context switch.

00:37:24.716 --> 00:37:26.176 A:middle
It was of that higher priority

00:37:26.176 --> 00:37:26.556 A:middle
event.

00:37:27.136 --> 00:37:28.616 A:middle
But, we cannot make for what

00:37:28.616 --> 00:37:29.636 A:middle
progress, because unlike the

00:37:29.636 --> 00:37:30.816 A:middle
first time, that second thread

00:37:30.816 --> 00:37:32.166 A:middle
cannot take over the queue it is

00:37:32.166 --> 00:37:33.156 A:middle
already associated with a

00:37:33.156 --> 00:37:33.676 A:middle
thread.

00:37:33.946 --> 00:37:34.906 A:middle
We cannot take it over.

00:37:35.476 --> 00:37:36.286 A:middle
So, the thread is done.

00:37:36.526 --> 00:37:38.126 A:middle
Which as Daniel explained one

00:37:38.126 --> 00:37:39.826 A:middle
reason why you context switch

00:37:39.826 --> 00:37:40.096 A:middle
again.

00:37:40.766 --> 00:37:41.676 A:middle
And that's what we do, we

00:37:41.676 --> 00:37:42.966 A:middle
context switch back to the first

00:37:42.966 --> 00:37:43.946 A:middle
thread that is the one that can

00:37:43.946 --> 00:37:44.886 A:middle
actually make progress.

00:37:44.886 --> 00:37:46.836 A:middle
We execute the rest of the first

00:37:46.836 --> 00:37:48.276 A:middle
handle and finally move to the

00:37:48.276 --> 00:37:48.696 A:middle
second one.

00:37:50.066 --> 00:37:52.446 A:middle
So, as you can see, we use two

00:37:52.536 --> 00:37:54.216 A:middle
threads and two context switches

00:37:54.286 --> 00:37:55.646 A:middle
that you really didn't want for

00:37:55.646 --> 00:37:56.956 A:middle
a single execution context.

00:37:57.476 --> 00:38:00.996 A:middle
We fixed that using Unified

00:38:01.036 --> 00:38:02.996 A:middle
Identity in macOS High Sierra

00:38:03.066 --> 00:38:04.686 A:middle
and iOS 11.

00:38:05.826 --> 00:38:09.266 A:middle
We got rid of that thread.

00:38:10.156 --> 00:38:12.566 A:middle
And we also, of course got rid

00:38:12.566 --> 00:38:14.846 A:middle
of the two context switches that

00:38:14.846 --> 00:38:16.416 A:middle
we had, that were unwanted.

00:38:17.396 --> 00:38:18.716 A:middle
And of course, its important

00:38:18.716 --> 00:38:20.726 A:middle
because unlike what happened

00:38:20.776 --> 00:38:22.106 A:middle
when Daniel showed you the

00:38:22.106 --> 00:38:24.916 A:middle
pre-emption with that UI touch

00:38:24.916 --> 00:38:26.996 A:middle
event, where we could take

00:38:26.996 --> 00:38:28.646 A:middle
advantage of the fact that we

00:38:28.756 --> 00:38:30.596 A:middle
actually had two threads that

00:38:30.596 --> 00:38:32.186 A:middle
were independent to be more

00:38:32.186 --> 00:38:33.266 A:middle
responsive for application.

00:38:33.626 --> 00:38:35.276 A:middle
Here, we didn't benefit from any

00:38:35.276 --> 00:38:36.276 A:middle
of these context switches,

00:38:36.566 --> 00:38:38.206 A:middle
because these event handler, S1

00:38:38.206 --> 00:38:40.586 A:middle
and M2 had to execute in order

00:38:40.586 --> 00:38:41.126 A:middle
anyways.

00:38:41.126 --> 00:38:42.506 A:middle
So, knowing about that event

00:38:42.506 --> 00:38:43.546 A:middle
early was not useful.

00:38:43.546 --> 00:38:46.046 A:middle
And if you look at how this

00:38:46.046 --> 00:38:48.006 A:middle
actually, what the flow is

00:38:48.006 --> 00:38:49.916 A:middle
today, it looks more like this.

00:38:50.816 --> 00:38:53.026 A:middle
What happened here?

00:38:54.936 --> 00:38:56.926 A:middle
The most important thing on that

00:38:56.926 --> 00:38:58.346 A:middle
flow is that now if you look at

00:38:58.346 --> 00:39:00.106 A:middle
the thread, it's called EQ,

00:39:00.386 --> 00:39:01.516 A:middle
because that's the part of the

00:39:01.516 --> 00:39:03.206 A:middle
unified identity, the thread and

00:39:03.206 --> 00:39:04.636 A:middle
the EQ are basically the same

00:39:04.636 --> 00:39:05.096 A:middle
object.

00:39:05.386 --> 00:39:06.696 A:middle
And the kernel knows that it's

00:39:06.696 --> 00:39:08.476 A:middle
really executing a queue, which

00:39:08.476 --> 00:39:09.976 A:middle
is reflected on the CPU tab, you

00:39:09.976 --> 00:39:11.186 A:middle
don't see the events anymore,

00:39:11.186 --> 00:39:12.286 A:middle
it's just running your queue.

00:39:14.476 --> 00:39:16.256 A:middle
However, you might ask, how did

00:39:16.256 --> 00:39:19.206 A:middle
we manage to deliver the event,

00:39:19.456 --> 00:39:20.896 A:middle
that second event without

00:39:20.896 --> 00:39:21.726 A:middle
requiring a hamper.

00:39:21.846 --> 00:39:23.566 A:middle
That is actually a good

00:39:24.696 --> 00:39:24.916 A:middle
question.

00:39:25.446 --> 00:39:27.266 A:middle
When the event fires, now we

00:39:27.266 --> 00:39:28.756 A:middle
know where it will execute,

00:39:28.756 --> 00:39:29.936 A:middle
where you will handle it.

00:39:30.326 --> 00:39:31.686 A:middle
We just mark the thread.

00:39:32.486 --> 00:39:33.416 A:middle
No helper needed.

00:39:34.226 --> 00:39:38.266 A:middle
And at the first possible time,

00:39:38.986 --> 00:39:40.786 A:middle
we will notice that thread was

00:39:40.786 --> 00:39:42.006 A:middle
marked with you have pending

00:39:42.006 --> 00:39:42.486 A:middle
events.

00:39:42.966 --> 00:39:44.356 A:middle
And when we de-queue the events,

00:39:44.356 --> 00:39:46.596 A:middle
one needs to hide time, hide

00:39:46.596 --> 00:39:47.556 A:middle
after the first handler

00:39:47.556 --> 00:39:48.116 A:middle
finishes.

00:39:48.696 --> 00:39:50.066 A:middle
We can grab the events from the

00:39:50.066 --> 00:39:51.566 A:middle
kernel, look at them, and then

00:39:51.606 --> 00:39:53.346 A:middle
queue their handlers on your

00:39:54.006 --> 00:39:54.246 A:middle
hierarchy.

00:39:54.796 --> 00:39:57.726 A:middle
So, why did we go through that

00:39:57.726 --> 00:39:59.016 A:middle
quite complex explanation?

00:40:00.046 --> 00:40:01.856 A:middle
That's so that you can

00:40:01.856 --> 00:40:03.146 A:middle
understand how to best take

00:40:03.146 --> 00:40:04.676 A:middle
advantage of the runtime

00:40:04.676 --> 00:40:05.126 A:middle
behavior.

00:40:06.086 --> 00:40:07.366 A:middle
Because clearly, the runtime

00:40:07.366 --> 00:40:08.986 A:middle
uses every possible hint you're

00:40:08.986 --> 00:40:10.996 A:middle
giving us to optimize behavior

00:40:10.996 --> 00:40:11.756 A:middle
in your application.

00:40:12.766 --> 00:40:14.716 A:middle
And admittance buttons to know

00:40:14.716 --> 00:40:17.356 A:middle
how to hint and when to hint the

00:40:17.356 --> 00:40:18.866 A:middle
runtime correctly so that we

00:40:18.866 --> 00:40:19.886 A:middle
make the right decisions.

00:40:20.386 --> 00:40:24.196 A:middle
Which brings me to what should

00:40:24.196 --> 00:40:26.226 A:middle
you do to existing code bases to

00:40:26.226 --> 00:40:28.896 A:middle
take advantage of all that core

00:40:28.896 --> 00:40:32.966 A:middle
technology that we rebuilt.

00:40:33.156 --> 00:40:35.966 A:middle
Now, actually two steps to

00:40:35.966 --> 00:40:37.156 A:middle
follow to take the full

00:40:37.156 --> 00:40:38.706 A:middle
advantage of that technology.

00:40:38.936 --> 00:40:41.116 A:middle
The first one is no mutation

00:40:41.116 --> 00:40:41.966 A:middle
after activation.

00:40:42.666 --> 00:40:44.036 A:middle
And the second one is paying

00:40:44.276 --> 00:40:46.796 A:middle
extra care with extra attention

00:40:46.796 --> 00:40:47.566 A:middle
to your target queue

00:40:47.566 --> 00:40:48.126 A:middle
hierarchies.

00:40:49.126 --> 00:40:49.856 A:middle
So, what does that mean?

00:40:51.236 --> 00:40:52.576 A:middle
No mutation past activation

00:40:52.656 --> 00:40:53.806 A:middle
really means that when you have

00:40:53.806 --> 00:40:55.396 A:middle
any kind of property on a

00:40:55.396 --> 00:40:57.216 A:middle
dispatch object, you can send

00:40:57.216 --> 00:40:58.446 A:middle
them, well as soon as you

00:40:58.446 --> 00:40:59.816 A:middle
activate the object, you should

00:40:59.816 --> 00:41:01.056 A:middle
stop mutating them.

00:41:01.636 --> 00:41:04.786 A:middle
The second example, that's our

00:41:04.786 --> 00:41:05.976 A:middle
source that we've seen quite a

00:41:05.976 --> 00:41:07.466 A:middle
few times already in the talk.

00:41:07.956 --> 00:41:08.636 A:middle
That [inaudible] for the

00:41:08.636 --> 00:41:09.836 A:middle
ability.

00:41:09.836 --> 00:41:12.686 A:middle
And you're setting a bunch of

00:41:12.686 --> 00:41:14.606 A:middle
properties, handlers; the event

00:41:14.606 --> 00:41:15.806 A:middle
handler, the consent handler.

00:41:15.806 --> 00:41:16.826 A:middle
You may have registration

00:41:16.826 --> 00:41:17.406 A:middle
handlers.

00:41:18.196 --> 00:41:19.536 A:middle
You can even change them a few

00:41:19.536 --> 00:41:20.826 A:middle
times, that's fine, you can

00:41:20.826 --> 00:41:21.496 A:middle
change your mind.

00:41:21.946 --> 00:41:23.956 A:middle
And then you activate the

00:41:23.956 --> 00:41:24.346 A:middle
source.

00:41:25.706 --> 00:41:27.496 A:middle
The contact here is that you

00:41:27.496 --> 00:41:29.556 A:middle
should stop mutate your objects.

00:41:30.246 --> 00:41:31.376 A:middle
It's very tempting to,

00:41:31.706 --> 00:41:33.076 A:middle
after-the-fact, for example

00:41:33.076 --> 00:41:33.976 A:middle
change the target queue of your

00:41:33.976 --> 00:41:34.386 A:middle
source.

00:41:34.386 --> 00:41:35.486 A:middle
That will cause problems.

00:41:35.786 --> 00:41:37.356 A:middle
And the reason why is exactly

00:41:37.356 --> 00:41:38.956 A:middle
what I showed a bit earlier, at

00:41:38.956 --> 00:41:40.876 A:middle
activate time we take a snapshot

00:41:40.916 --> 00:41:42.006 A:middle
of the properties of your

00:41:42.006 --> 00:41:43.306 A:middle
objects, and we will take

00:41:43.306 --> 00:41:44.906 A:middle
decisions in the future based on

00:41:44.906 --> 00:41:45.556 A:middle
that snapshot.

00:41:45.686 --> 00:41:48.486 A:middle
And if you change the target

00:41:48.486 --> 00:41:50.196 A:middle
queue hierarchy after-the-fact,

00:41:50.476 --> 00:41:51.756 A:middle
it will hinder that snapshot

00:41:51.756 --> 00:41:54.256 A:middle
stale and that will defeat a

00:41:54.256 --> 00:41:55.536 A:middle
bunch of very important

00:41:55.536 --> 00:41:56.846 A:middle
optimization such as the

00:41:56.846 --> 00:41:59.726 A:middle
priority inversion avoidance

00:41:59.726 --> 00:42:01.096 A:middle
[inaudible] the direct handoff

00:42:01.186 --> 00:42:02.306 A:middle
that we have for the dispatch

00:42:02.306 --> 00:42:03.686 A:middle
sync that I presented earlier,

00:42:03.686 --> 00:42:05.756 A:middle
are all defensive and

00:42:05.756 --> 00:42:07.056 A:middle
deliverable optimizations that

00:42:07.056 --> 00:42:09.976 A:middle
we just went through.

00:42:10.896 --> 00:42:12.586 A:middle
And I insist on the points that

00:42:12.586 --> 00:42:13.966 A:middle
Daniel made early on, which is

00:42:13.966 --> 00:42:16.476 A:middle
that many of you probably never

00:42:16.886 --> 00:42:18.476 A:middle
had to create a dispatch source

00:42:18.476 --> 00:42:19.196 A:middle
in your application.

00:42:19.196 --> 00:42:20.576 A:middle
And this is fine, this is really

00:42:20.576 --> 00:42:21.396 A:middle
how it's supposed to work.

00:42:22.236 --> 00:42:23.846 A:middle
You probably actually use them a

00:42:23.846 --> 00:42:25.906 A:middle
lot of them through system

00:42:25.906 --> 00:42:26.476 A:middle
frameworks.

00:42:26.476 --> 00:42:27.286 A:middle
It's a shame you have a

00:42:27.286 --> 00:42:28.696 A:middle
framework that you have to then

00:42:28.696 --> 00:42:30.666 A:middle
dispatch queue to because they

00:42:30.666 --> 00:42:33.166 A:middle
are asyncing some notifications

00:42:33.166 --> 00:42:34.606 A:middle
on the queue on your behalf.

00:42:34.706 --> 00:42:36.106 A:middle
Behind the scenes, they have one

00:42:36.106 --> 00:42:36.886 A:middle
of these sources.

00:42:37.216 --> 00:42:38.056 A:middle
So, if you're changing the

00:42:38.056 --> 00:42:39.766 A:middle
assumptions of the system, you

00:42:39.766 --> 00:42:42.106 A:middle
will actually break all of these

00:42:42.106 --> 00:42:45.666 A:middle
optimizations as well.

00:42:46.546 --> 00:42:48.806 A:middle
So, I hope a made a point really

00:42:48.806 --> 00:42:50.176 A:middle
clear that to target your

00:42:50.176 --> 00:42:52.396 A:middle
hierarchy is essential and you

00:42:52.396 --> 00:42:53.266 A:middle
have to protect it.

00:42:54.656 --> 00:42:55.226 A:middle
What does that mean?

00:42:56.466 --> 00:42:57.256 A:middle
And how to do that?

00:42:58.756 --> 00:43:00.156 A:middle
The first way, which is a very

00:43:00.156 --> 00:43:01.386 A:middle
simple device, is that when

00:43:01.386 --> 00:43:03.796 A:middle
you're building one, start from

00:43:03.796 --> 00:43:05.876 A:middle
the bottom and build it toward

00:43:06.496 --> 00:43:07.306 A:middle
the top.

00:43:07.496 --> 00:43:09.016 A:middle
When you show that card from the

00:43:09.016 --> 00:43:11.706 A:middle
slide build up, as you see,

00:43:12.086 --> 00:43:13.906 A:middle
these wider holes there, they

00:43:13.906 --> 00:43:14.846 A:middle
are your target queue

00:43:14.846 --> 00:43:15.516 A:middle
relationships.

00:43:15.766 --> 00:43:18.146 A:middle
None of them have to be mutated

00:43:18.146 --> 00:43:19.886 A:middle
if you [inaudible] in that

00:43:20.566 --> 00:43:20.956 A:middle
order.

00:43:21.036 --> 00:43:22.656 A:middle
However, when you have a large

00:43:22.656 --> 00:43:24.156 A:middle
application, or you're hiding

00:43:24.156 --> 00:43:25.486 A:middle
your frameworks and you're

00:43:25.486 --> 00:43:26.996 A:middle
bending one of these queues to

00:43:26.996 --> 00:43:30.056 A:middle
another part of your engineering

00:43:30.166 --> 00:43:32.406 A:middle
company, you may want to have

00:43:32.406 --> 00:43:33.706 A:middle
stronger guarantees than that.

00:43:34.256 --> 00:43:35.516 A:middle
You may want to lockdown these

00:43:35.516 --> 00:43:36.756 A:middle
relationships, so that really no

00:43:36.756 --> 00:43:37.726 A:middle
one can mutate them

00:43:37.726 --> 00:43:39.026 A:middle
after-the-fact.

00:43:39.576 --> 00:43:41.846 A:middle
This is actually something that

00:43:41.846 --> 00:43:43.306 A:middle
you can do with the technology

00:43:43.306 --> 00:43:44.746 A:middle
that we call set a queue

00:43:44.746 --> 00:43:45.256 A:middle
hierarchy.

00:43:45.416 --> 00:43:47.236 A:middle
We introduced it last year, and

00:43:47.736 --> 00:43:49.456 A:middle
actually if you are using Swift

00:43:49.456 --> 00:43:50.876 A:middle
3, then you can stop listening

00:43:50.876 --> 00:43:51.976 A:middle
to me, because you're already in

00:43:51.976 --> 00:43:53.146 A:middle
that form and that the only

00:43:53.146 --> 00:43:54.616 A:middle
world you're living.

00:43:55.606 --> 00:43:57.066 A:middle
However, if you have an existing

00:43:57.066 --> 00:43:58.186 A:middle
cloud based, or you use older

00:43:58.186 --> 00:44:01.056 A:middle
versions than of Swift, you need

00:44:01.056 --> 00:44:03.076 A:middle
to do some extra steps.

00:44:03.736 --> 00:44:06.756 A:middle
So, let's focus on the

00:44:06.756 --> 00:44:08.626 A:middle
relationship between Q1 and EQ

00:44:08.896 --> 00:44:09.046 A:middle
here.

00:44:09.776 --> 00:44:12.266 A:middle
When you created that with

00:44:12.266 --> 00:44:13.886 A:middle
Objective-C you probably hold

00:44:13.886 --> 00:44:15.356 A:middle
code that looks like this.

00:44:15.436 --> 00:44:17.346 A:middle
You create your queue and then

00:44:17.406 --> 00:44:19.216 A:middle
in the second step, you will set

00:44:19.406 --> 00:44:21.816 A:middle
your target queue of Q1 to EQ.

00:44:22.156 --> 00:44:23.916 A:middle
That is not protecting your

00:44:23.916 --> 00:44:24.566 A:middle
queue hierarchy.

00:44:24.566 --> 00:44:26.416 A:middle
Anyone can come along and call

00:44:26.416 --> 00:44:27.666 A:middle
dispatch target queue again and

00:44:27.666 --> 00:44:28.826 A:middle
break all your assumptions.

00:44:29.056 --> 00:44:30.126 A:middle
That's not totally great.

00:44:30.906 --> 00:44:32.986 A:middle
There is a simple step to just

00:44:32.986 --> 00:44:34.316 A:middle
fix that code into a way that is

00:44:34.316 --> 00:44:37.206 A:middle
safe, which is to adopt a new

00:44:37.206 --> 00:44:38.536 A:middle
API we introduced last year,

00:44:38.736 --> 00:44:39.966 A:middle
which is dispatch queue create

00:44:39.966 --> 00:44:42.636 A:middle
with target, which in a single

00:44:42.636 --> 00:44:44.476 A:middle
automatic step will create the

00:44:44.476 --> 00:44:46.606 A:middle
queue, set the queue hierarchy

00:44:46.606 --> 00:44:48.116 A:middle
height, and protect it.

00:44:48.676 --> 00:44:50.066 A:middle
And that's it.

00:44:50.536 --> 00:44:51.706 A:middle
These were the two steps to

00:44:51.706 --> 00:44:53.526 A:middle
follow for you to really work

00:44:53.526 --> 00:44:54.386 A:middle
with the [inaudible] well.

00:44:54.386 --> 00:44:58.306 A:middle
Other, a bit like the mutated

00:44:58.306 --> 00:45:00.296 A:middle
case that Daniel walked you

00:45:00.296 --> 00:45:02.566 A:middle
through early on, finding when

00:45:02.566 --> 00:45:04.316 A:middle
you're doing one of these things

00:45:04.316 --> 00:45:05.836 A:middle
wrong is fairly challenging,

00:45:05.836 --> 00:45:07.226 A:middle
especially on the large cloud

00:45:07.226 --> 00:45:07.646 A:middle
base.

00:45:07.646 --> 00:45:09.256 A:middle
Finding that in an existing

00:45:09.256 --> 00:45:10.826 A:middle
cloud base full code inspection

00:45:10.886 --> 00:45:11.436 A:middle
is hard.

00:45:12.356 --> 00:45:14.736 A:middle
This is why we created a new GCD

00:45:14.736 --> 00:45:16.626 A:middle
performance instruments tool to

00:45:16.626 --> 00:45:18.346 A:middle
find problem spots in an

00:45:18.346 --> 00:45:19.406 A:middle
existing application.

00:45:19.976 --> 00:45:21.096 A:middle
And I will call Daniel back to

00:45:21.096 --> 00:45:23.806 A:middle
the stage to demo for you.

00:45:24.516 --> 00:45:28.866 A:middle
[ Applause ]

00:45:29.366 --> 00:45:29.896 A:middle
&gt;&gt; Thank you, Pierre.

00:45:30.426 --> 00:45:32.766 A:middle
All right to start out with

00:45:32.766 --> 00:45:34.166 A:middle
please note that this GCD

00:45:34.166 --> 00:45:35.216 A:middle
performance instrument that

00:45:35.216 --> 00:45:37.156 A:middle
we'll see is not yet present in

00:45:37.156 --> 00:45:38.396 A:middle
the version of XCode 9 that you

00:45:38.396 --> 00:45:39.746 A:middle
have, but it will be available

00:45:39.746 --> 00:45:41.996 A:middle
in an upcoming seed of XCode 9.

00:45:41.996 --> 00:45:44.566 A:middle
So, for this demo, let's analyze

00:45:44.596 --> 00:45:46.176 A:middle
the execution of our sample news

00:45:46.176 --> 00:45:47.486 A:middle
application in some detail.

00:45:48.596 --> 00:45:49.566 A:middle
So, what happens here if you

00:45:49.566 --> 00:45:51.146 A:middle
click this connect button at the

00:45:51.146 --> 00:45:53.046 A:middle
bottom, is that this app creates

00:45:53.046 --> 00:45:54.376 A:middle
a number of network connections

00:45:54.486 --> 00:45:56.336 A:middle
to a server, to read lists of

00:45:56.336 --> 00:45:57.736 A:middle
URLs from, which are then

00:45:57.736 --> 00:45:59.196 A:middle
displayed in the WebViews

00:45:59.196 --> 00:46:00.246 A:middle
whenever the refresh button is

00:46:00.246 --> 00:46:00.386 A:middle
hit.

00:46:01.146 --> 00:46:02.776 A:middle
So, let's jump into XCode to see

00:46:02.776 --> 00:46:03.866 A:middle
how we are setting up those

00:46:03.866 --> 00:46:04.576 A:middle
network connections.

00:46:05.446 --> 00:46:07.686 A:middle
So, here we are in XCode in the

00:46:07.686 --> 00:46:09.806 A:middle
create connections method, which

00:46:09.806 --> 00:46:10.956 A:middle
does just that.

00:46:11.376 --> 00:46:12.006 A:middle
It's very simple.

00:46:12.006 --> 00:46:13.716 A:middle
We have a for loop, maybe just

00:46:13.716 --> 00:46:15.436 A:middle
create some sockets and connect

00:46:15.436 --> 00:46:16.336 A:middle
them to our server.

00:46:17.266 --> 00:46:18.946 A:middle
And we monitor that socket for

00:46:18.946 --> 00:46:20.086 A:middle
readability with one of these

00:46:20.146 --> 00:46:21.696 A:middle
dispatch read sources that we've

00:46:21.696 --> 00:46:22.896 A:middle
seen so many times already in

00:46:22.896 --> 00:46:23.396 A:middle
this session.

00:46:23.396 --> 00:46:24.796 A:middle
And here it is the trusted the

00:46:24.796 --> 00:46:25.506 A:middle
see API.

00:46:26.546 --> 00:46:27.946 A:middle
We then set up the event handler

00:46:27.946 --> 00:46:29.506 A:middle
block for that dispatch source

00:46:29.906 --> 00:46:30.216 A:middle
here.

00:46:30.366 --> 00:46:32.146 A:middle
And when the socket becomes

00:46:32.146 --> 00:46:33.346 A:middle
readable, we just read from it

00:46:33.346 --> 00:46:34.756 A:middle
with the read system call until

00:46:34.756 --> 00:46:36.016 A:middle
there is no more data available.

00:46:36.756 --> 00:46:38.416 A:middle
Once we have the data, we pass

00:46:38.416 --> 00:46:40.586 A:middle
it to our database, subsystem in

00:46:40.586 --> 00:46:41.576 A:middle
the application with this

00:46:41.606 --> 00:46:42.556 A:middle
process 0 method.

00:46:43.706 --> 00:46:45.076 A:middle
So, let's build and run, and

00:46:45.076 --> 00:46:46.206 A:middle
take a system trace of this

00:46:46.206 --> 00:46:47.416 A:middle
application and see how it

00:46:47.416 --> 00:46:48.016 A:middle
executes.

00:46:48.016 --> 00:46:52.246 A:middle
So here we are in instruments,

00:46:52.286 --> 00:46:54.146 A:middle
in system trace, and in addition

00:46:54.146 --> 00:46:55.256 A:middle
to the usual tacks in system

00:46:55.256 --> 00:46:56.736 A:middle
trace, we've added this new GCD

00:46:56.736 --> 00:46:57.686 A:middle
performance instrument.

00:46:58.096 --> 00:46:59.436 A:middle
When we click on there, we see a

00:46:59.436 --> 00:47:01.056 A:middle
number of performance events

00:47:01.056 --> 00:47:02.456 A:middle
that have been reported for

00:47:02.456 --> 00:47:03.346 A:middle
performance problems.

00:47:03.746 --> 00:47:05.336 A:middle
One of these is this mutation

00:47:05.336 --> 00:47:06.456 A:middle
after activation event, that we

00:47:06.456 --> 00:47:08.256 A:middle
can also see when we go and mass

00:47:08.256 --> 00:47:08.886 A:middle
over the timeline.

00:47:09.316 --> 00:47:10.576 A:middle
You can also click on one of the

00:47:10.576 --> 00:47:12.176 A:middle
other events here, such as this,

00:47:12.176 --> 00:47:13.486 A:middle
re-target after activation

00:47:13.486 --> 00:47:13.836 A:middle
event.

00:47:14.506 --> 00:47:15.846 A:middle
And the list will take us

00:47:15.846 --> 00:47:16.626 A:middle
directly there.

00:47:16.626 --> 00:47:18.036 A:middle
If you want more details on

00:47:18.036 --> 00:47:19.646 A:middle
this, we can disclose the

00:47:19.646 --> 00:47:20.806 A:middle
backtrace on the right hand side

00:47:20.806 --> 00:47:22.306 A:middle
is instruments which will show

00:47:22.306 --> 00:47:23.636 A:middle
us where exactly this event

00:47:23.636 --> 00:47:24.736 A:middle
occurred in your application.

00:47:25.166 --> 00:47:26.416 A:middle
So, here for instance it is in

00:47:26.416 --> 00:47:28.226 A:middle
our create connections method.

00:47:29.546 --> 00:47:30.956 A:middle
If we double click on this

00:47:30.956 --> 00:47:32.306 A:middle
frame, instruments will show us

00:47:32.306 --> 00:47:33.386 A:middle
directly the line of code where

00:47:33.766 --> 00:47:34.696 A:middle
the problem occurred.

00:47:35.396 --> 00:47:36.786 A:middle
This is actually a target queue

00:47:36.786 --> 00:47:38.176 A:middle
call here that indeed occurs

00:47:38.176 --> 00:47:38.966 A:middle
after activate.

00:47:39.416 --> 00:47:40.606 A:middle
Like, this is the pattern up

00:47:40.606 --> 00:47:41.476 A:middle
here just told you about.

00:47:41.476 --> 00:47:43.006 A:middle
To go and fix that, we can jump

00:47:43.136 --> 00:47:44.376 A:middle
directly into XCode with the

00:47:44.376 --> 00:47:45.676 A:middle
open file and XCode button and

00:47:45.676 --> 00:47:46.196 A:middle
instruments.

00:47:46.676 --> 00:47:48.416 A:middle
So, here we are at that dispatch

00:47:48.416 --> 00:47:50.336 A:middle
the target queue line and indeed

00:47:50.396 --> 00:47:51.716 A:middle
it, as well as the dispatch

00:47:51.716 --> 00:47:53.816 A:middle
source at event handler set up

00:47:53.816 --> 00:47:54.936 A:middle
happens after activate.

00:47:55.486 --> 00:47:56.896 A:middle
So, here in this example, it's

00:47:56.896 --> 00:47:57.636 A:middle
really easy to fix.

00:47:57.636 --> 00:47:58.936 A:middle
We just move these two lines

00:47:59.356 --> 00:48:00.206 A:middle
down below.

00:48:00.206 --> 00:48:01.706 A:middle
And we have fixed the problem.

00:48:01.706 --> 00:48:03.386 A:middle
We have activate after we set up

00:48:03.426 --> 00:48:04.856 A:middle
the source, and not before.

00:48:05.526 --> 00:48:06.616 A:middle
So, let's jump back into

00:48:06.616 --> 00:48:08.156 A:middle
instruments and see what we can

00:48:08.156 --> 00:48:09.556 A:middle
see in the system trace now.

00:48:09.856 --> 00:48:11.176 A:middle
It looks the same as before,

00:48:11.176 --> 00:48:12.696 A:middle
except when you click on the GCD

00:48:12.696 --> 00:48:14.196 A:middle
performance track, you will see

00:48:14.196 --> 00:48:15.336 A:middle
there is no more significant

00:48:15.336 --> 00:48:16.476 A:middle
performance problems detected.

00:48:16.476 --> 00:48:17.836 A:middle
And that's what you ought to see

00:48:17.836 --> 00:48:18.686 A:middle
if you use this instrument.

00:48:18.836 --> 00:48:20.466 A:middle
So, of course this was very

00:48:20.466 --> 00:48:21.686 A:middle
simple in this application.

00:48:21.686 --> 00:48:22.686 A:middle
You may have to do some work.

00:48:24.566 --> 00:48:25.806 A:middle
So, let's focus on the points

00:48:25.806 --> 00:48:26.916 A:middle
track in the application.

00:48:26.916 --> 00:48:28.096 A:middle
This shows us a number of

00:48:28.146 --> 00:48:29.366 A:middle
network event handlers.

00:48:29.816 --> 00:48:31.106 A:middle
And these are the source event

00:48:31.106 --> 00:48:32.166 A:middle
handlers in our application.

00:48:32.666 --> 00:48:34.066 A:middle
How did you manage to make these

00:48:34.066 --> 00:48:35.006 A:middle
show up in instruments?

00:48:35.606 --> 00:48:36.246 A:middle
That's actually really

00:48:36.246 --> 00:48:37.356 A:middle
interesting to understand

00:48:37.356 --> 00:48:38.386 A:middle
because it's something you can

00:48:38.386 --> 00:48:39.916 A:middle
apply to your own code to

00:48:39.916 --> 00:48:41.646 A:middle
understand how it executes in

00:48:41.676 --> 00:48:42.176 A:middle
instruments.

00:48:43.806 --> 00:48:45.556 A:middle
Well, going back to XCode in our

00:48:45.556 --> 00:48:47.486 A:middle
create connections method, when

00:48:47.486 --> 00:48:49.516 A:middle
we set up our source and its

00:48:49.516 --> 00:48:50.456 A:middle
source event handlers, we are

00:48:50.456 --> 00:48:51.976 A:middle
interested in the execution of

00:48:52.046 --> 00:48:53.806 A:middle
that event handler, and try to

00:48:53.806 --> 00:48:54.926 A:middle
understand its timing.

00:48:55.506 --> 00:48:57.016 A:middle
To see that instruments, we've

00:48:57.016 --> 00:48:59.156 A:middle
added the kdebug signpost start

00:48:59.156 --> 00:49:00.696 A:middle
function at the beginning of the

00:49:00.696 --> 00:49:02.776 A:middle
handler, and the kdebug signpost

00:49:02.886 --> 00:49:03.936 A:middle
end function at the end.

00:49:03.936 --> 00:49:05.836 A:middle
And that is all it takes for the

00:49:05.836 --> 00:49:07.346 A:middle
section of code to appear

00:49:07.346 --> 00:49:08.486 A:middle
highlighted in the points track

00:49:08.946 --> 00:49:10.096 A:middle
in instrument system trace.

00:49:10.396 --> 00:49:11.836 A:middle
So, if you switch back to

00:49:11.836 --> 00:49:13.766 A:middle
instruments, that is these red

00:49:13.866 --> 00:49:15.436 A:middle
dots at the pop in the points

00:49:15.436 --> 00:49:16.826 A:middle
track and we can see in the back

00:49:16.826 --> 00:49:18.706 A:middle
trace that it matches our event

00:49:18.706 --> 00:49:20.486 A:middle
handler for one of these events.

00:49:21.566 --> 00:49:22.726 A:middle
If you zoom in on one of these

00:49:22.726 --> 00:49:24.416 A:middle
interesting looking areas in the

00:49:24.416 --> 00:49:26.226 A:middle
points track, here, you can see

00:49:26.226 --> 00:49:27.956 A:middle
that there is a number of event

00:49:27.956 --> 00:49:29.876 A:middle
handlers that are occurring very

00:49:29.876 --> 00:49:30.946 A:middle
close together.

00:49:31.156 --> 00:49:33.276 A:middle
And by mousing over we can

00:49:33.276 --> 00:49:34.066 A:middle
actually see that they're

00:49:34.066 --> 00:49:35.426 A:middle
execute for very short amounts

00:49:35.426 --> 00:49:35.836 A:middle
of time.

00:49:36.356 --> 00:49:38.286 A:middle
The pop-up will tell us the

00:49:38.286 --> 00:49:39.746 A:middle
amount of time it has executed

00:49:39.946 --> 00:49:40.826 A:middle
and we can even see that

00:49:40.826 --> 00:49:42.186 A:middle
sometimes we have overlapping

00:49:42.186 --> 00:49:43.226 A:middle
event handlers that are all

00:49:43.226 --> 00:49:44.886 A:middle
executing concurrently at the

00:49:44.926 --> 00:49:45.506 A:middle
same time.

00:49:45.506 --> 00:49:47.766 A:middle
So, this is one of the symptoms

00:49:47.766 --> 00:49:48.856 A:middle
of potentially unwanted

00:49:48.856 --> 00:49:50.056 A:middle
concurrency in our application,

00:49:50.376 --> 00:49:51.546 A:middle
where something that didn't look

00:49:51.546 --> 00:49:53.346 A:middle
like it would cause concurrency

00:49:53.556 --> 00:49:55.926 A:middle
in your code, actually does run

00:49:55.926 --> 00:49:57.146 A:middle
in a concurrent way or multiple

00:49:57.146 --> 00:49:58.906 A:middle
threads and cause potentially

00:49:58.906 --> 00:49:59.876 A:middle
extra context switches.

00:50:01.466 --> 00:50:03.076 A:middle
So, to understand this better,

00:50:03.076 --> 00:50:04.586 A:middle
let's bring up the threads in

00:50:04.586 --> 00:50:05.136 A:middle
instruments.

00:50:05.426 --> 00:50:06.556 A:middle
And the system trace that are

00:50:06.556 --> 00:50:07.506 A:middle
executing this code.

00:50:12.446 --> 00:50:13.726 A:middle
So, here I've highlighted the

00:50:13.726 --> 00:50:14.716 A:middle
three worker threads that are

00:50:14.716 --> 00:50:16.026 A:middle
executing these event handlers.

00:50:16.496 --> 00:50:17.856 A:middle
And we can see as before that

00:50:17.856 --> 00:50:19.366 A:middle
they are executing on call

00:50:19.556 --> 00:50:20.376 A:middle
during this time.

00:50:20.926 --> 00:50:22.316 A:middle
And the time they were running.

00:50:22.316 --> 00:50:23.846 A:middle
But here we can see they were

00:50:23.846 --> 00:50:25.866 A:middle
again, running for a very short

00:50:25.866 --> 00:50:27.566 A:middle
amount of time in this area.

00:50:27.926 --> 00:50:30.386 A:middle
And we can verify that they are

00:50:30.386 --> 00:50:31.686 A:middle
making these read system calls

00:50:31.686 --> 00:50:33.146 A:middle
that we saw earlier in the event

00:50:33.146 --> 00:50:33.416 A:middle
handler.

00:50:34.136 --> 00:50:35.766 A:middle
And we can get some more detail

00:50:35.766 --> 00:50:36.856 A:middle
by looking at the back trace

00:50:36.856 --> 00:50:38.246 A:middle
again, and seeing, yes it is us

00:50:38.246 --> 00:50:39.276 A:middle
that is calling that read system

00:50:39.276 --> 00:50:41.246 A:middle
call and here it reads 97 bytes

00:50:41.576 --> 00:50:42.366 A:middle
from our socket.

00:50:44.216 --> 00:50:45.246 A:middle
And looking at the other

00:50:45.246 --> 00:50:46.206 A:middle
threads, the same pattern

00:50:46.206 --> 00:50:46.766 A:middle
repeats.

00:50:46.766 --> 00:50:47.786 A:middle
You can see it's the same read

00:50:47.786 --> 00:50:49.206 A:middle
system calls occurring there,

00:50:49.206 --> 00:50:49.986 A:middle
more or less at the same

00:50:49.986 --> 00:50:52.466 A:middle
timeframe and so on the second

00:50:52.466 --> 00:50:53.496 A:middle
thread here or on the first

00:50:53.496 --> 00:50:53.736 A:middle
thread.

00:50:53.996 --> 00:50:54.856 A:middle
They're really all doing the

00:50:54.856 --> 00:50:56.736 A:middle
same thing, and overlapping.

00:50:57.886 --> 00:50:59.156 A:middle
It would be much better for our

00:50:59.156 --> 00:51:01.806 A:middle
program if these things executed

00:51:01.806 --> 00:51:02.556 A:middle
on a single thread.

00:51:02.556 --> 00:51:03.736 A:middle
Here we don't really get any

00:51:03.736 --> 00:51:05.046 A:middle
benefit from the concurrency

00:51:05.316 --> 00:51:06.456 A:middle
because we are executing such

00:51:06.456 --> 00:51:07.436 A:middle
short pieces of code.

00:51:07.896 --> 00:51:09.716 A:middle
And we are probably getting more

00:51:09.716 --> 00:51:11.236 A:middle
harm than good from adding these

00:51:11.236 --> 00:51:12.216 A:middle
extra context switches.

00:51:13.036 --> 00:51:14.496 A:middle
So, let's apply the patterns

00:51:14.496 --> 00:51:15.776 A:middle
that we saw earlier to fix this

00:51:15.776 --> 00:51:16.666 A:middle
problem in this sample

00:51:16.666 --> 00:51:17.216 A:middle
application.

00:51:17.806 --> 00:51:19.446 A:middle
Jumping back into XCode, let's

00:51:19.446 --> 00:51:20.576 A:middle
see how we set up the target

00:51:20.576 --> 00:51:21.616 A:middle
queue for this source that we

00:51:21.616 --> 00:51:21.836 A:middle
have.

00:51:23.056 --> 00:51:24.096 A:middle
So, that's sort of when you

00:51:24.096 --> 00:51:25.766 A:middle
create this queue at the top of

00:51:25.836 --> 00:51:27.256 A:middle
this function framework and as

00:51:27.256 --> 00:51:29.186 A:middle
you can see, we do it simply by

00:51:29.186 --> 00:51:30.046 A:middle
calling this batch queue

00:51:30.046 --> 00:51:30.566 A:middle
correct.

00:51:31.446 --> 00:51:32.846 A:middle
And that creates an independent

00:51:32.846 --> 00:51:34.016 A:middle
serial queue that isn't

00:51:34.016 --> 00:51:35.346 A:middle
connected to anything else in

00:51:35.346 --> 00:51:36.046 A:middle
our application.

00:51:36.046 --> 00:51:37.886 A:middle
This is exactly like the case we

00:51:37.886 --> 00:51:40.036 A:middle
had earlier in my example of the

00:51:40.036 --> 00:51:40.936 A:middle
networking subsystem.

00:51:41.636 --> 00:51:43.356 A:middle
So, let's fix that by adding a

00:51:43.356 --> 00:51:44.616 A:middle
mutual exclusion context at the

00:51:44.616 --> 00:51:46.196 A:middle
bottom of all of these queues

00:51:46.196 --> 00:51:47.106 A:middle
for all of these connections.

00:51:47.606 --> 00:51:49.326 A:middle
And we do that by adding the, or

00:51:49.326 --> 00:51:50.666 A:middle
by switching to the dispatch

00:51:50.666 --> 00:51:51.606 A:middle
queue create with target

00:51:51.606 --> 00:51:53.256 A:middle
function up here introduced to

00:51:53.256 --> 00:51:53.776 A:middle
you earlier.

00:51:54.416 --> 00:51:58.996 A:middle
So, here we add dispatch queue,

00:51:58.996 --> 00:51:59.746 A:middle
create this target.

00:52:00.206 --> 00:52:01.716 A:middle
And we use a single mutual

00:52:01.716 --> 00:52:02.906 A:middle
exclusion queue as the target

00:52:02.906 --> 00:52:03.756 A:middle
queue for all of these.

00:52:04.196 --> 00:52:05.246 A:middle
And this is a serial queue that

00:52:05.246 --> 00:52:06.596 A:middle
we created somewhere else.

00:52:07.416 --> 00:52:09.036 A:middle
And with that, we build and run

00:52:09.036 --> 00:52:09.976 A:middle
again and look at the system

00:52:09.976 --> 00:52:10.546 A:middle
trace again.

00:52:11.576 --> 00:52:12.846 A:middle
And now it looks very different.

00:52:13.466 --> 00:52:15.436 A:middle
Here we have still the same

00:52:15.436 --> 00:52:16.616 A:middle
points track and we still see

00:52:16.616 --> 00:52:18.136 A:middle
the same network events that

00:52:18.136 --> 00:52:19.426 A:middle
occur, but as you can see,

00:52:19.656 --> 00:52:20.596 A:middle
there's no more overlapping

00:52:20.596 --> 00:52:21.686 A:middle
events in that track, and

00:52:21.906 --> 00:52:23.066 A:middle
there's a single worker thread

00:52:23.066 --> 00:52:24.226 A:middle
that executes this code.

00:52:24.306 --> 00:52:26.376 A:middle
And if we zoom in on one of

00:52:26.426 --> 00:52:27.726 A:middle
these clusters we can see this

00:52:27.726 --> 00:52:29.066 A:middle
is actually many instances of

00:52:29.066 --> 00:52:30.996 A:middle
that event handler executing in

00:52:30.996 --> 00:52:32.306 A:middle
rapid succession, which is

00:52:32.306 --> 00:52:33.686 A:middle
exactly what we expected.

00:52:34.216 --> 00:52:36.376 A:middle
And when you zoom in more on one

00:52:36.376 --> 00:52:37.746 A:middle
particular event, you can see

00:52:37.746 --> 00:52:38.896 A:middle
it's still executing for a

00:52:38.896 --> 00:52:40.676 A:middle
fairly short amount of time, and

00:52:40.676 --> 00:52:41.716 A:middle
making those same read sys

00:52:41.716 --> 00:52:42.116 A:middle
calls.

00:52:42.786 --> 00:52:44.216 A:middle
But now that is much less

00:52:44.216 --> 00:52:45.266 A:middle
problematic because it's all

00:52:45.266 --> 00:52:46.986 A:middle
happening on a single thread.

00:52:49.636 --> 00:52:51.886 A:middle
So, this may seem like a very

00:52:51.886 --> 00:52:53.626 A:middle
simple and trivial change, but

00:52:53.626 --> 00:52:54.546 A:middle
it's worth pointing out that

00:52:54.546 --> 00:52:55.926 A:middle
it's exactly this type of small

00:52:55.926 --> 00:52:57.906 A:middle
tweak that led to the 1.3X

00:52:57.906 --> 00:52:59.306 A:middle
performance improvement in some

00:52:59.306 --> 00:53:00.776 A:middle
of our own framework code that

00:53:00.776 --> 00:53:02.016 A:middle
Daniel pointed out at the

00:53:02.016 --> 00:53:02.936 A:middle
beginning of the session.

00:53:03.426 --> 00:53:04.736 A:middle
So, very small changes like this

00:53:04.736 --> 00:53:05.596 A:middle
can make a significant

00:53:05.596 --> 00:53:06.036 A:middle
difference.

00:53:07.476 --> 00:53:12.256 A:middle
All right so, let's look back at

00:53:12.256 --> 00:53:13.166 A:middle
what we've covered today.

00:53:13.166 --> 00:53:15.156 A:middle
Daniel, at the beginning went

00:53:15.156 --> 00:53:16.606 A:middle
with you over the details of how

00:53:16.606 --> 00:53:18.736 A:middle
not to go off core unnecessarily

00:53:18.736 --> 00:53:19.976 A:middle
is ever more important for

00:53:19.976 --> 00:53:21.406 A:middle
modern CPUs so that it can reach

00:53:21.406 --> 00:53:22.456 A:middle
the most efficient performance

00:53:22.456 --> 00:53:22.676 A:middle
state.

00:53:23.506 --> 00:53:25.106 A:middle
We looked at the importance of

00:53:25.106 --> 00:53:26.686 A:middle
sizing the workforce of power

00:53:26.686 --> 00:53:28.586 A:middle
workloads and for work moving

00:53:28.586 --> 00:53:29.726 A:middle
between subsystems in your

00:53:29.726 --> 00:53:31.456 A:middle
application as well as inside

00:53:31.536 --> 00:53:32.266 A:middle
those subsystems.

00:53:33.166 --> 00:53:34.446 A:middle
We talked about how to choose

00:53:34.446 --> 00:53:36.476 A:middle
good granularity of concurrency

00:53:36.476 --> 00:53:37.916 A:middle
with GCD by using a fixed number

00:53:37.916 --> 00:53:38.946 A:middle
of serial queue hierarchies in

00:53:38.946 --> 00:53:39.596 A:middle
your application.

00:53:40.096 --> 00:53:41.056 A:middle
And Pierre walked you through

00:53:41.056 --> 00:53:42.956 A:middle
how to modernize your GCD usage

00:53:43.256 --> 00:53:44.356 A:middle
to take full advantage of

00:53:44.356 --> 00:53:46.186 A:middle
improvements in the OS, in our

00:53:46.186 --> 00:53:46.626 A:middle
hardware.

00:53:47.596 --> 00:53:49.096 A:middle
And finally, we saw how we can

00:53:49.096 --> 00:53:50.486 A:middle
use instruments to find problems

00:53:50.486 --> 00:53:51.886 A:middle
spots in our application and how

00:53:52.206 --> 00:53:54.826 A:middle
to fix them.

00:53:55.186 --> 00:53:56.256 A:middle
For more information on this

00:53:56.256 --> 00:53:57.926 A:middle
session, I will direct you to

00:53:57.926 --> 00:54:00.196 A:middle
this URL where the documentation

00:54:00.196 --> 00:54:02.116 A:middle
links for GCD are as well as the

00:54:02.116 --> 00:54:04.176 A:middle
movie for the session, and we

00:54:04.176 --> 00:54:05.386 A:middle
have some related sessions this

00:54:05.386 --> 00:54:06.566 A:middle
week that might be worthwhile

00:54:06.876 --> 00:54:07.616 A:middle
going to.

00:54:07.746 --> 00:54:09.726 A:middle
Introducing Core ML already

00:54:09.726 --> 00:54:11.226 A:middle
having happened, the other two

00:54:11.226 --> 00:54:12.386 A:middle
are going to help you with

00:54:12.386 --> 00:54:13.636 A:middle
parallel and computing

00:54:13.686 --> 00:54:14.176 A:middle
[inaudible] task in your

00:54:14.336 --> 00:54:15.746 A:middle
application like we talked about

00:54:15.746 --> 00:54:16.346 A:middle
at the beginning.

00:54:16.946 --> 00:54:19.426 A:middle
And the last two are going to

00:54:19.426 --> 00:54:20.566 A:middle
help you with more performance

00:54:20.566 --> 00:54:21.656 A:middle
analysis and improvements of

00:54:21.696 --> 00:54:23.186 A:middle
different aspects of your app.

00:54:23.186 --> 00:54:25.216 A:middle
And with that, I'd like to thank

00:54:25.216 --> 00:54:25.836 A:middle
you for coming.

00:54:26.176 --> 00:54:26.986 A:middle
If you have any questions,

00:54:26.986 --> 00:54:27.966 A:middle
please come and see us at the

00:54:27.966 --> 00:54:28.246 A:middle
labs.

00:54:29.508 --> 00:54:31.508 A:middle
[ Applause ]