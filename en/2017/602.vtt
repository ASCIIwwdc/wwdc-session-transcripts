WEBVTT

00:00:18.066 --> 00:00:18.596 A:middle
&gt;&gt; Good afternoon.

00:00:19.516 --> 00:00:23.776 A:middle
[ Applause ]

00:00:24.276 --> 00:00:25.326 A:middle
Welcome to our session

00:00:25.326 --> 00:00:26.716 A:middle
introducing ARKit.

00:00:27.096 --> 00:00:27.806 A:middle
My name is Mike.

00:00:27.916 --> 00:00:29.526 A:middle
I'm an engineer from ARKit team.

00:00:29.676 --> 00:00:31.056 A:middle
And today I'm thrilled to talk

00:00:31.056 --> 00:00:32.356 A:middle
to you about the concepts as

00:00:32.646 --> 00:00:34.296 A:middle
well as the code that go into

00:00:34.296 --> 00:00:35.736 A:middle
creating your very own augmented

00:00:35.736 --> 00:00:37.636 A:middle
reality experience on iOS.

00:00:38.341 --> 00:00:40.341 A:middle
[ Cheering and Applause ]

00:00:40.666 --> 00:00:41.016 A:middle
Thank you.

00:00:41.336 --> 00:00:42.876 A:middle
I know many of you are eager to

00:00:42.876 --> 00:00:43.946 A:middle
get started with augmented

00:00:43.946 --> 00:00:44.336 A:middle
reality.

00:00:44.336 --> 00:00:46.166 A:middle
Let's show you just how easy it

00:00:46.166 --> 00:00:47.156 A:middle
is using ARKit.

00:00:48.206 --> 00:00:50.756 A:middle
But first, what is augmented

00:00:50.756 --> 00:00:51.236 A:middle
reality?

00:00:52.056 --> 00:00:53.616 A:middle
Augmented reality is creating

00:00:53.616 --> 00:00:54.816 A:middle
the illusion that virtual

00:00:54.816 --> 00:00:56.346 A:middle
objects are placed in a physical

00:00:56.346 --> 00:00:56.686 A:middle
world.

00:00:57.096 --> 00:00:58.706 A:middle
It's using your iPhone or your

00:00:58.706 --> 00:01:00.716 A:middle
iPad as a lens into a virtual

00:01:00.716 --> 00:01:02.116 A:middle
world based on what your camera

00:01:02.116 --> 00:01:02.416 A:middle
sees.

00:01:03.376 --> 00:01:04.446 A:middle
Let's take a look at some

00:01:04.446 --> 00:01:04.856 A:middle
examples.

00:01:05.826 --> 00:01:07.436 A:middle
We gave a group of developers

00:01:07.496 --> 00:01:08.856 A:middle
early access to ARKit.

00:01:09.276 --> 00:01:10.186 A:middle
And here's what they made.

00:01:10.436 --> 00:01:12.116 A:middle
This is a sneak peek at some

00:01:12.116 --> 00:01:13.266 A:middle
things you might see in the near

00:01:13.266 --> 00:01:14.000 A:middle
future.

00:01:17.536 --> 00:01:19.506 A:middle
Within, a company focused on

00:01:19.506 --> 00:01:20.676 A:middle
immersive storytelling,

00:01:21.046 --> 00:01:22.276 A:middle
tells the story of Goldilocks

00:01:22.846 --> 00:01:23.660 A:middle
using AR.

00:01:26.186 --> 00:01:27.646 A:middle
Transforming a bedroom into a

00:01:27.746 --> 00:01:29.426 A:middle
virtual storybook, they allow

00:01:29.426 --> 00:01:30.896 A:middle
you to progress a story by

00:01:30.896 --> 00:01:32.896 A:middle
reciting the text, but even more

00:01:32.896 --> 00:01:34.246 A:middle
importantly, they allow you to

00:01:34.366 --> 00:01:35.596 A:middle
explore the scene from any

00:01:35.596 --> 00:01:36.000 A:middle
angle.

00:01:39.046 --> 00:01:40.876 A:middle
This level of interactivity

00:01:40.876 --> 00:01:42.596 A:middle
really helps bring your virtual

00:01:42.596 --> 00:01:43.500 A:middle
scene alive.

00:01:48.196 --> 00:01:51.136 A:middle
Next, Ikea used ARKit in order

00:01:51.136 --> 00:01:52.316 A:middle
to redesign your living room.

00:01:54.516 --> 00:01:58.046 A:middle
[ Applause ]

00:01:58.546 --> 00:02:00.066 A:middle
By being able to place virtual

00:02:00.066 --> 00:02:01.396 A:middle
content next to physical

00:02:01.396 --> 00:02:03.196 A:middle
objects, you open up a world of

00:02:03.196 --> 00:02:05.366 A:middle
possibilities to your users.

00:02:07.806 --> 00:02:09.776 A:middle
And last, games.

00:02:10.276 --> 00:02:12.456 A:middle
Pokemon Go, an app that you've

00:02:12.456 --> 00:02:14.806 A:middle
probably already heard of, used

00:02:14.806 --> 00:02:16.286 A:middle
ARKit to take catching Pokemon

00:02:16.516 --> 00:02:17.536 A:middle
to the next level.

00:02:18.906 --> 00:02:20.486 A:middle
By being able to anchor your

00:02:20.486 --> 00:02:22.116 A:middle
virtual content in the real

00:02:22.116 --> 00:02:23.516 A:middle
world, you really allow for a

00:02:23.516 --> 00:02:25.376 A:middle
more immersive experience than

00:02:25.376 --> 00:02:26.276 A:middle
previously possible.

00:02:26.806 --> 00:02:28.626 A:middle
But it doesn't stop there.

00:02:28.626 --> 00:02:30.046 A:middle
There are a multitude of ways

00:02:30.046 --> 00:02:31.206 A:middle
that you can use augmented

00:02:31.206 --> 00:02:32.896 A:middle
reality to enhance your user

00:02:32.896 --> 00:02:33.516 A:middle
experience.

00:02:34.236 --> 00:02:35.106 A:middle
So let's see what goes into

00:02:35.106 --> 00:02:35.926 A:middle
that.

00:02:38.756 --> 00:02:40.446 A:middle
There's a large amount of domain

00:02:40.446 --> 00:02:41.556 A:middle
knowledge that goes into

00:02:41.556 --> 00:02:42.976 A:middle
creating augmented reality.

00:02:43.456 --> 00:02:44.896 A:middle
Everything from computer vision,

00:02:45.146 --> 00:02:46.936 A:middle
to sensor fusion, to talking to

00:02:46.936 --> 00:02:48.216 A:middle
hardware in order to get camera

00:02:48.216 --> 00:02:49.236 A:middle
calibrations and camera

00:02:49.236 --> 00:02:49.766 A:middle
intrinsics.

00:02:50.436 --> 00:02:51.516 A:middle
We wanted to make this all

00:02:51.516 --> 00:02:52.156 A:middle
easier for you.

00:02:52.646 --> 00:02:54.736 A:middle
So today we're introducing

00:02:54.876 --> 00:02:55.506 A:middle
ARKit.

00:02:57.516 --> 00:03:02.226 A:middle
[ Applause ]

00:03:02.726 --> 00:03:04.686 A:middle
ARKit is a mobile AR platform

00:03:04.686 --> 00:03:06.136 A:middle
for developing augmented reality

00:03:06.136 --> 00:03:07.576 A:middle
apps on iOS.

00:03:07.896 --> 00:03:09.696 A:middle
It is a high level API providing

00:03:09.696 --> 00:03:11.696 A:middle
a simple interface to a powerful

00:03:11.696 --> 00:03:12.326 A:middle
set of features.

00:03:12.886 --> 00:03:14.256 A:middle
But more importantly, it's

00:03:14.256 --> 00:03:15.626 A:middle
rolling out supporting hundreds

00:03:15.626 --> 00:03:17.326 A:middle
of millions of existing iOS

00:03:17.326 --> 00:03:17.786 A:middle
devices.

00:03:18.486 --> 00:03:19.596 A:middle
In order to get the full set of

00:03:19.676 --> 00:03:21.236 A:middle
features for ARKit, you're going

00:03:21.376 --> 00:03:22.796 A:middle
to want an A9 and up.

00:03:22.966 --> 00:03:24.796 A:middle
This is most iOS 11 devices,

00:03:24.796 --> 00:03:26.486 A:middle
including the iPhone 6S.

00:03:28.146 --> 00:03:28.736 A:middle
Now let's talk about the

00:03:28.736 --> 00:03:29.306 A:middle
features.

00:03:29.896 --> 00:03:31.336 A:middle
So what does ARKit provide?

00:03:32.146 --> 00:03:33.536 A:middle
ARKit can be broken up into

00:03:33.676 --> 00:03:35.516 A:middle
three distinct layers, the first

00:03:35.516 --> 00:03:37.006 A:middle
of which is tracking.

00:03:38.476 --> 00:03:39.676 A:middle
Tracking is the core

00:03:39.676 --> 00:03:40.946 A:middle
functionality of ARKit.

00:03:40.946 --> 00:03:42.846 A:middle
It is the ability to track your

00:03:42.846 --> 00:03:44.316 A:middle
device in real time.

00:03:44.806 --> 00:03:46.436 A:middle
With world tracking we provide

00:03:46.436 --> 00:03:47.636 A:middle
you the ability to get your

00:03:47.636 --> 00:03:49.486 A:middle
device's relative position in

00:03:49.486 --> 00:03:50.496 A:middle
the physical environment.

00:03:51.136 --> 00:03:53.236 A:middle
We use visual inertial odometry,

00:03:53.596 --> 00:03:55.216 A:middle
which is using camera images, as

00:03:55.216 --> 00:03:56.396 A:middle
well as motion data from your

00:03:56.396 --> 00:03:58.226 A:middle
device in order to get a precise

00:03:58.226 --> 00:03:59.896 A:middle
view of where your device is

00:03:59.896 --> 00:04:01.326 A:middle
located as well as how it is

00:04:01.326 --> 00:04:01.866 A:middle
oriented.

00:04:02.906 --> 00:04:03.766 A:middle
But also, more importantly,

00:04:04.126 --> 00:04:05.316 A:middle
there's no external setup

00:04:05.316 --> 00:04:07.066 A:middle
required, no pre-existing

00:04:07.066 --> 00:04:07.756 A:middle
knowledge about your

00:04:07.756 --> 00:04:09.116 A:middle
environment, as well as no

00:04:09.116 --> 00:04:10.196 A:middle
additional sensors that you

00:04:10.196 --> 00:04:11.526 A:middle
don't already have on your

00:04:11.526 --> 00:04:11.986 A:middle
device.

00:04:13.366 --> 00:04:15.386 A:middle
Next, building upon tracking we

00:04:15.386 --> 00:04:16.646 A:middle
provide scene understanding.

00:04:19.386 --> 00:04:20.606 A:middle
Scene understanding is the

00:04:20.606 --> 00:04:23.276 A:middle
ability to determine attributes

00:04:23.276 --> 00:04:24.316 A:middle
or properties about the

00:04:24.316 --> 00:04:25.656 A:middle
environment around your device.

00:04:26.136 --> 00:04:27.416 A:middle
It's providing things like plane

00:04:27.416 --> 00:04:27.846 A:middle
detection.

00:04:28.476 --> 00:04:29.586 A:middle
Plane detection is the ability

00:04:29.586 --> 00:04:31.556 A:middle
to determine surfaces or planes

00:04:31.556 --> 00:04:32.676 A:middle
in the physical environment.

00:04:33.206 --> 00:04:34.366 A:middle
This is things like the ground

00:04:34.366 --> 00:04:35.706 A:middle
floor or maybe a table.

00:04:37.036 --> 00:04:38.206 A:middle
In order to place your virtual

00:04:38.206 --> 00:04:39.576 A:middle
objects, we provide hit testing

00:04:39.576 --> 00:04:40.126 A:middle
functionality.

00:04:40.726 --> 00:04:41.646 A:middle
So this is getting an

00:04:41.646 --> 00:04:43.226 A:middle
intersection with the real world

00:04:43.226 --> 00:04:44.736 A:middle
topology so that you can place

00:04:44.736 --> 00:04:46.066 A:middle
your virtual object in the

00:04:46.066 --> 00:04:46.886 A:middle
physical world.

00:04:47.616 --> 00:04:49.656 A:middle
And last, scene understanding

00:04:49.656 --> 00:04:51.026 A:middle
provides light estimation.

00:04:51.636 --> 00:04:54.146 A:middle
So light estimation is used to

00:04:54.146 --> 00:04:56.176 A:middle
render or correctly light your

00:04:56.176 --> 00:04:58.006 A:middle
virtual geometry to match that

00:04:58.006 --> 00:04:59.016 A:middle
of the physical world.

00:04:59.916 --> 00:05:01.116 A:middle
Using all of these together we

00:05:01.116 --> 00:05:03.386 A:middle
can seamlessly integrate virtual

00:05:03.386 --> 00:05:05.046 A:middle
content into your physical

00:05:05.206 --> 00:05:05.786 A:middle
environment.

00:05:06.586 --> 00:05:08.326 A:middle
And so the last layer of ARKit

00:05:08.586 --> 00:05:09.176 A:middle
is rendering.

00:05:11.256 --> 00:05:13.016 A:middle
For rendering we provide easy

00:05:13.016 --> 00:05:14.426 A:middle
integration into any renderer.

00:05:14.636 --> 00:05:15.926 A:middle
We provide a constant stream of

00:05:15.926 --> 00:05:17.476 A:middle
camera images, tracking

00:05:17.476 --> 00:05:18.906 A:middle
information as well as scene

00:05:18.906 --> 00:05:20.346 A:middle
understanding that can be

00:05:20.346 --> 00:05:21.536 A:middle
inputted into any renderer.

00:05:23.206 --> 00:05:24.806 A:middle
For those of you using SceneKit

00:05:24.806 --> 00:05:26.716 A:middle
or SpriteKit, we provide custom

00:05:26.716 --> 00:05:28.416 A:middle
AR views, which implement most

00:05:28.416 --> 00:05:29.446 A:middle
of the rendering for you.

00:05:29.736 --> 00:05:30.826 A:middle
So it's really easy to get

00:05:30.826 --> 00:05:31.186 A:middle
started.

00:05:32.246 --> 00:05:33.246 A:middle
And for those of you doing

00:05:33.246 --> 00:05:34.436 A:middle
custom rendering, we provide a

00:05:34.436 --> 00:05:35.966 A:middle
metal template through Xcode,

00:05:36.636 --> 00:05:37.446 A:middle
which gets you started

00:05:37.446 --> 00:05:39.166 A:middle
integrating ARKit into your

00:05:39.166 --> 00:05:39.946 A:middle
custom renderer.

00:05:39.946 --> 00:05:43.986 A:middle
And one more thing, Unity and

00:05:43.986 --> 00:05:45.356 A:middle
UnReal will be supporting the

00:05:45.356 --> 00:05:47.126 A:middle
full set of features from ARKit.

00:05:48.516 --> 00:05:53.626 A:middle
[ Applause ]

00:05:54.126 --> 00:05:56.106 A:middle
So, are you guys ready?

00:05:56.106 --> 00:05:56.736 A:middle
Let's get started.

00:05:57.426 --> 00:05:59.366 A:middle
How do I use ARKit in my

00:05:59.366 --> 00:05:59.986 A:middle
application?

00:06:01.216 --> 00:06:02.346 A:middle
ARKit is a framework that

00:06:02.346 --> 00:06:03.776 A:middle
handles all of the processing

00:06:03.996 --> 00:06:05.266 A:middle
that goes into creating an

00:06:05.266 --> 00:06:06.776 A:middle
augmented reality experience.

00:06:07.636 --> 00:06:08.746 A:middle
With the renderer of my choice,

00:06:09.116 --> 00:06:11.626 A:middle
I can simply use ARKit to do the

00:06:11.626 --> 00:06:12.236 A:middle
processing.

00:06:12.366 --> 00:06:13.606 A:middle
And it will provide everything

00:06:13.606 --> 00:06:14.626 A:middle
that I need to render my

00:06:14.626 --> 00:06:15.836 A:middle
augmented reality scene.

00:06:16.716 --> 00:06:19.006 A:middle
In addition to processing, ARKit

00:06:19.006 --> 00:06:20.746 A:middle
also handles the capturing that

00:06:20.746 --> 00:06:22.776 A:middle
is done in order to do augmented

00:06:22.776 --> 00:06:23.116 A:middle
reality.

00:06:23.216 --> 00:06:25.246 A:middle
So using AVFoundation and Core

00:06:25.246 --> 00:06:27.156 A:middle
Motion under the hood, we

00:06:27.426 --> 00:06:29.306 A:middle
capture images as well as get

00:06:29.746 --> 00:06:31.106 A:middle
motion data from your device in

00:06:31.106 --> 00:06:32.656 A:middle
order to do tracking and provide

00:06:32.656 --> 00:06:33.726 A:middle
those camera images to your

00:06:33.726 --> 00:06:34.016 A:middle
renderer.

00:06:34.566 --> 00:06:36.786 A:middle
So now how do I use ARKit?

00:06:37.576 --> 00:06:39.396 A:middle
ARKit is a session-based API.

00:06:39.896 --> 00:06:40.806 A:middle
The first thing you need to do

00:06:40.806 --> 00:06:42.496 A:middle
to get started is simply create

00:06:42.496 --> 00:06:43.156 A:middle
an ARSession.

00:06:44.116 --> 00:06:45.406 A:middle
ARSession is the object that

00:06:45.406 --> 00:06:46.816 A:middle
controls all of the processing

00:06:46.816 --> 00:06:48.756 A:middle
that goes into creating your

00:06:48.756 --> 00:06:50.386 A:middle
augmented reality app.

00:06:50.676 --> 00:06:51.826 A:middle
But first I need to determine

00:06:51.826 --> 00:06:53.426 A:middle
what kind of tracking I want to

00:06:53.516 --> 00:06:55.626 A:middle
do for my augmented reality app.

00:06:55.626 --> 00:06:56.926 A:middle
So, to determine this we're

00:06:56.926 --> 00:06:58.466 A:middle
going to create an AR session

00:06:58.466 --> 00:06:59.136 A:middle
configuration.

00:06:59.716 --> 00:07:02.586 A:middle
AR session configuration, and

00:07:02.586 --> 00:07:04.006 A:middle
its subclasses determine what

00:07:04.006 --> 00:07:05.516 A:middle
tracking you want to run on your

00:07:05.516 --> 00:07:05.896 A:middle
session.

00:07:06.856 --> 00:07:07.956 A:middle
By enabling and disabling

00:07:07.956 --> 00:07:09.276 A:middle
properties, you can get

00:07:09.276 --> 00:07:10.086 A:middle
different kinds of scene

00:07:10.086 --> 00:07:11.366 A:middle
understanding and have your

00:07:11.366 --> 00:07:12.256 A:middle
ARSession do different

00:07:12.256 --> 00:07:12.756 A:middle
processing.

00:07:13.826 --> 00:07:15.786 A:middle
In order to run my session, I

00:07:15.786 --> 00:07:17.776 A:middle
simply call the Run method on

00:07:17.866 --> 00:07:18.946 A:middle
ARSession providing the

00:07:18.946 --> 00:07:20.266 A:middle
configuration I want to run.

00:07:20.266 --> 00:07:23.886 A:middle
And with that, processing

00:07:23.886 --> 00:07:24.806 A:middle
immediately starts.

00:07:24.806 --> 00:07:26.706 A:middle
And we also set up the capturing

00:07:26.706 --> 00:07:27.146 A:middle
underneath.

00:07:27.286 --> 00:07:28.516 A:middle
So under the hood you'll see

00:07:28.516 --> 00:07:30.156 A:middle
there's an AV capture session

00:07:30.156 --> 00:07:32.116 A:middle
and a CM motion manager that get

00:07:32.116 --> 00:07:32.886 A:middle
created for you.

00:07:32.886 --> 00:07:35.446 A:middle
We use these to get image data

00:07:35.536 --> 00:07:36.616 A:middle
as well as the motion data

00:07:36.616 --> 00:07:37.476 A:middle
that's going to be used for

00:07:37.606 --> 00:07:38.176 A:middle
tracking.

00:07:38.226 --> 00:07:39.386 A:middle
Once processing is done,

00:07:39.716 --> 00:07:41.786 A:middle
ARSession will output ARFrames.

00:07:42.486 --> 00:07:44.356 A:middle
So an ARFrame is a snapshot in

00:07:44.356 --> 00:07:46.146 A:middle
time, including all of the state

00:07:46.146 --> 00:07:47.366 A:middle
of your session, everything

00:07:47.366 --> 00:07:49.256 A:middle
needed to render your augmented

00:07:49.256 --> 00:07:49.816 A:middle
reality scene.

00:07:51.016 --> 00:07:52.946 A:middle
In order to access ARFrame, you

00:07:52.946 --> 00:07:54.886 A:middle
can simply call or pull the

00:07:54.886 --> 00:07:56.286 A:middle
current frame property from you

00:07:56.286 --> 00:07:56.816 A:middle
ARSession.

00:07:57.516 --> 00:07:58.586 A:middle
Or, you can set yourself as the

00:07:58.586 --> 00:08:00.256 A:middle
delegate to receive updates when

00:08:00.256 --> 00:08:01.726 A:middle
new ARFrames are available.

00:08:01.726 --> 00:08:04.946 A:middle
So let's take a closer look at

00:08:04.946 --> 00:08:05.936 A:middle
ARSessionConfiguration.

00:08:09.516 --> 00:08:10.836 A:middle
ARSession configuration

00:08:10.836 --> 00:08:12.126 A:middle
determines what kind of tracking

00:08:12.286 --> 00:08:13.256 A:middle
you want to run on your session.

00:08:13.966 --> 00:08:15.316 A:middle
So it provides different

00:08:15.316 --> 00:08:16.666 A:middle
configuration classes.

00:08:17.606 --> 00:08:18.406 A:middle
The base class,

00:08:18.406 --> 00:08:20.316 A:middle
ARSessionConfiguration, provides

00:08:20.446 --> 00:08:21.446 A:middle
three degrees of freedom

00:08:21.446 --> 00:08:22.826 A:middle
tracking, which is just the

00:08:22.826 --> 00:08:24.246 A:middle
orientation of your device.

00:08:25.296 --> 00:08:27.506 A:middle
Its subclass, ARWorldTracking

00:08:27.506 --> 00:08:28.896 A:middle
Session Configuration provides

00:08:29.036 --> 00:08:30.566 A:middle
six degrees of freedom tracking.

00:08:30.816 --> 00:08:32.276 A:middle
So this is using our core

00:08:32.276 --> 00:08:33.566 A:middle
functionality world tracking in

00:08:33.806 --> 00:08:34.756 A:middle
order to get not only your

00:08:34.756 --> 00:08:36.726 A:middle
device's orientation, but also a

00:08:36.726 --> 00:08:38.066 A:middle
relative position of your

00:08:38.066 --> 00:08:38.536 A:middle
device.

00:08:39.386 --> 00:08:40.356 A:middle
With this we also get

00:08:40.356 --> 00:08:41.566 A:middle
information about the scene.

00:08:41.936 --> 00:08:42.606 A:middle
So we provide scene

00:08:42.606 --> 00:08:44.316 A:middle
understanding like feature

00:08:44.316 --> 00:08:46.196 A:middle
points as well as physical

00:08:46.196 --> 00:08:48.226 A:middle
positions in your world.

00:08:49.376 --> 00:08:50.636 A:middle
In order to enable and disable

00:08:50.636 --> 00:08:52.006 A:middle
features, you simply set

00:08:52.006 --> 00:08:53.216 A:middle
properties on your session

00:08:53.216 --> 00:08:54.000 A:middle
configuration classes.

00:08:58.196 --> 00:09:00.366 A:middle
And session configurations also

00:09:00.366 --> 00:09:01.506 A:middle
provide availability.

00:09:02.276 --> 00:09:03.516 A:middle
So if you want to check if world

00:09:03.516 --> 00:09:04.586 A:middle
tracking is supported on your

00:09:04.586 --> 00:09:06.436 A:middle
device, you simply need to call

00:09:06.716 --> 00:09:08.316 A:middle
the class property isSupported

00:09:08.316 --> 00:09:09.726 A:middle
on ARWorldTracking Session

00:09:09.726 --> 00:09:10.306 A:middle
Configuration.

00:09:11.186 --> 00:09:12.646 A:middle
With this you can then use your

00:09:12.646 --> 00:09:13.456 A:middle
World Tracking Session

00:09:13.456 --> 00:09:15.046 A:middle
Configuration or fall back to

00:09:15.046 --> 00:09:16.576 A:middle
the base class, which will only

00:09:16.576 --> 00:09:17.586 A:middle
provide you with three degrees

00:09:17.586 --> 00:09:18.006 A:middle
of freedom.

00:09:18.386 --> 00:09:20.006 A:middle
It's important to note here that

00:09:20.006 --> 00:09:21.546 A:middle
because the base class doesn't

00:09:21.546 --> 00:09:22.656 A:middle
have any scene understanding

00:09:22.986 --> 00:09:24.256 A:middle
functionality like hit tests

00:09:24.256 --> 00:09:25.306 A:middle
won't be available on this

00:09:25.306 --> 00:09:25.636 A:middle
device.

00:09:25.636 --> 00:09:27.556 A:middle
So we're also going to provide a

00:09:27.556 --> 00:09:29.486 A:middle
UI required device capability

00:09:29.486 --> 00:09:30.886 A:middle
that you set in your app so that

00:09:30.886 --> 00:09:32.266 A:middle
your app only appears in the App

00:09:32.266 --> 00:09:33.796 A:middle
Store on devices that support

00:09:33.796 --> 00:09:34.536 A:middle
World Tracking.

00:09:36.036 --> 00:09:39.966 A:middle
Next, let's look at ARSession.

00:09:39.966 --> 00:09:41.586 A:middle
ARSession, again, is the class

00:09:41.586 --> 00:09:42.446 A:middle
that manages all of the

00:09:42.446 --> 00:09:44.046 A:middle
processing for your augmented

00:09:44.046 --> 00:09:45.286 A:middle
reality app.

00:09:46.556 --> 00:09:48.226 A:middle
In addition to calling Run with

00:09:48.226 --> 00:09:49.766 A:middle
a configuration, you can also

00:09:49.766 --> 00:09:50.506 A:middle
call Pause.

00:09:51.426 --> 00:09:52.366 A:middle
So Pause allows you to

00:09:52.366 --> 00:09:54.046 A:middle
temporarily stop all processing

00:09:54.046 --> 00:09:55.236 A:middle
happening on your session.

00:09:55.366 --> 00:09:56.456 A:middle
So if your view is no longer

00:09:56.456 --> 00:09:57.906 A:middle
visible, you may want to stop

00:09:57.906 --> 00:10:01.126 A:middle
processing to stop using CPU and

00:10:01.126 --> 00:10:02.436 A:middle
no tracking will occur during

00:10:02.436 --> 00:10:03.026 A:middle
this pause.

00:10:03.266 --> 00:10:05.286 A:middle
In order to resume tracking

00:10:05.286 --> 00:10:07.006 A:middle
after a pause, you can simply

00:10:07.006 --> 00:10:08.656 A:middle
call Run again with the stored

00:10:08.656 --> 00:10:09.886 A:middle
configuration on your session.

00:10:11.376 --> 00:10:12.576 A:middle
And last, you can call Run

00:10:12.576 --> 00:10:14.196 A:middle
multiple times in order to

00:10:14.196 --> 00:10:15.506 A:middle
transition between different

00:10:15.506 --> 00:10:16.166 A:middle
configurations.

00:10:16.616 --> 00:10:18.036 A:middle
So say I wanted to enable plane

00:10:18.036 --> 00:10:19.946 A:middle
detection, I can change my

00:10:19.946 --> 00:10:21.286 A:middle
configuration to enable plane

00:10:21.286 --> 00:10:23.146 A:middle
detection, call Run again on my

00:10:23.146 --> 00:10:23.536 A:middle
session.

00:10:23.796 --> 00:10:25.336 A:middle
My session will automatically

00:10:25.336 --> 00:10:27.176 A:middle
transition seamlessly between

00:10:27.176 --> 00:10:28.306 A:middle
one configuration and another

00:10:28.516 --> 00:10:29.816 A:middle
without dropping any camera

00:10:29.816 --> 00:10:30.136 A:middle
images.

00:10:32.836 --> 00:10:34.536 A:middle
So with the Run command we also

00:10:34.536 --> 00:10:36.376 A:middle
provide resetting of tracking.

00:10:36.546 --> 00:10:37.716 A:middle
So there's Run options that you

00:10:37.716 --> 00:10:39.446 A:middle
can provide on the Run command

00:10:40.076 --> 00:10:41.486 A:middle
in order to reset tracking.

00:10:41.486 --> 00:10:42.756 A:middle
It'll reinitialize all of the

00:10:42.756 --> 00:10:43.686 A:middle
tracking that's going on.

00:10:43.896 --> 00:10:44.856 A:middle
And your camera position will

00:10:44.856 --> 00:10:46.056 A:middle
start out again at 000.

00:10:46.056 --> 00:10:48.116 A:middle
So this is useful for your

00:10:48.116 --> 00:10:49.306 A:middle
application if you want to reset

00:10:49.306 --> 00:10:50.696 A:middle
it to some starting point.

00:10:51.246 --> 00:10:54.426 A:middle
So how do I make use of

00:10:54.426 --> 00:10:55.556 A:middle
ARSessions processing?

00:10:56.256 --> 00:10:57.286 A:middle
There's session updates

00:10:57.286 --> 00:10:58.626 A:middle
available by setting yourself as

00:10:58.686 --> 00:10:59.296 A:middle
the delegate.

00:11:00.456 --> 00:11:02.206 A:middle
So in order to get the last

00:11:02.206 --> 00:11:03.496 A:middle
frame that was processed, I

00:11:03.576 --> 00:11:04.796 A:middle
could implement session

00:11:04.876 --> 00:11:05.696 A:middle
didUpdate Frame.

00:11:05.896 --> 00:11:07.906 A:middle
And this will give me the latest

00:11:07.906 --> 00:11:08.136 A:middle
frame.

00:11:08.356 --> 00:11:09.726 A:middle
For error handling, you can also

00:11:09.726 --> 00:11:11.666 A:middle
implement things like session

00:11:11.666 --> 00:11:12.646 A:middle
DidFailWithError.

00:11:12.646 --> 00:11:13.656 A:middle
So this is in the case of the

00:11:13.656 --> 00:11:14.246 A:middle
fatal error.

00:11:14.526 --> 00:11:16.096 A:middle
Maybe you're running a device

00:11:16.096 --> 00:11:17.076 A:middle
that doesn't support World

00:11:17.076 --> 00:11:17.506 A:middle
Tracking.

00:11:17.616 --> 00:11:18.706 A:middle
You'll get an error like this.

00:11:18.706 --> 00:11:19.926 A:middle
And your session will be paused.

00:11:21.266 --> 00:11:22.466 A:middle
The other way to make use of

00:11:22.466 --> 00:11:25.026 A:middle
ARSessions processing is to pull

00:11:25.026 --> 00:11:26.176 A:middle
the current frame property.

00:11:26.886 --> 00:11:29.346 A:middle
So now, what does an ARFrame

00:11:29.346 --> 00:11:29.806 A:middle
contain?

00:11:30.846 --> 00:11:32.806 A:middle
Each ARFrame contains everything

00:11:32.806 --> 00:11:34.056 A:middle
you need to render your

00:11:34.056 --> 00:11:35.146 A:middle
augmented reality scene.

00:11:35.146 --> 00:11:37.686 A:middle
The first thing it provides is a

00:11:37.686 --> 00:11:38.246 A:middle
camera image.

00:11:38.876 --> 00:11:39.796 A:middle
So this is what you're going to

00:11:39.796 --> 00:11:41.586 A:middle
use to render the background of

00:11:41.626 --> 00:11:42.176 A:middle
your scene.

00:11:43.636 --> 00:11:44.826 A:middle
Next, it provides tracking

00:11:44.826 --> 00:11:47.226 A:middle
information, or my device's

00:11:47.226 --> 00:11:48.786 A:middle
orientation as well as location

00:11:49.106 --> 00:11:50.276 A:middle
and even tracking state.

00:11:51.256 --> 00:11:52.776 A:middle
And last, it provides scene

00:11:52.776 --> 00:11:53.316 A:middle
understanding.

00:11:54.206 --> 00:11:55.576 A:middle
So, information about the scene

00:11:55.856 --> 00:11:57.806 A:middle
like feature points, physical

00:11:57.806 --> 00:11:59.186 A:middle
locations in space as well as

00:11:59.186 --> 00:12:00.826 A:middle
light estimation, or a light

00:12:01.596 --> 00:12:01.826 A:middle
estimate.

00:12:02.866 --> 00:12:04.476 A:middle
So, physical locations in space,

00:12:05.086 --> 00:12:07.746 A:middle
the way that ARKit represents

00:12:07.746 --> 00:12:10.516 A:middle
these is by using ARFrames -- or

00:12:10.516 --> 00:12:11.546 A:middle
ARAnchors, sorry.

00:12:12.176 --> 00:12:14.276 A:middle
An ARAnchor is a relative or a

00:12:14.276 --> 00:12:15.746 A:middle
real-world position and

00:12:15.746 --> 00:12:17.796 A:middle
orientation in space.

00:12:17.796 --> 00:12:21.306 A:middle
ARAnchors can be added and

00:12:21.306 --> 00:12:22.746 A:middle
removed from your scene.

00:12:23.166 --> 00:12:24.556 A:middle
And they're used to basically

00:12:24.556 --> 00:12:27.566 A:middle
represent a virtual content

00:12:27.566 --> 00:12:28.666 A:middle
anchored to your physical

00:12:28.666 --> 00:12:29.076 A:middle
environment.

00:12:29.826 --> 00:12:31.146 A:middle
So, if you want to add a custom

00:12:31.146 --> 00:12:31.996 A:middle
anchor, you can do that by

00:12:31.996 --> 00:12:32.866 A:middle
adding it to your session.

00:12:33.066 --> 00:12:34.126 A:middle
It'll persist through the

00:12:34.126 --> 00:12:35.286 A:middle
lifetime of your session.

00:12:36.026 --> 00:12:37.736 A:middle
But an added thing is if you're

00:12:37.736 --> 00:12:38.576 A:middle
running things like plane

00:12:38.576 --> 00:12:40.236 A:middle
detection, ARAnchors will be

00:12:40.236 --> 00:12:41.416 A:middle
added automatically to your

00:12:41.416 --> 00:12:41.786 A:middle
session.

00:12:42.416 --> 00:12:43.746 A:middle
So, in order to respond to this,

00:12:44.396 --> 00:12:46.576 A:middle
you can get them as a full list

00:12:46.576 --> 00:12:47.796 A:middle
in your current ARFrame.

00:12:48.166 --> 00:12:49.086 A:middle
So that'll have all of the

00:12:49.086 --> 00:12:50.136 A:middle
anchors that your session is

00:12:50.136 --> 00:12:50.856 A:middle
currently tracking.

00:12:51.356 --> 00:12:53.066 A:middle
Or you can respond to delegate

00:12:53.066 --> 00:12:55.796 A:middle
methods like add, update, and

00:12:55.796 --> 00:12:57.206 A:middle
remove, which will notify you if

00:12:57.206 --> 00:12:59.056 A:middle
anchors were added, updated, or

00:12:59.056 --> 00:13:00.746 A:middle
removed from your session.

00:13:01.206 --> 00:13:04.276 A:middle
So that concludes the four main

00:13:04.276 --> 00:13:05.366 A:middle
classes that you're going to use

00:13:05.366 --> 00:13:06.546 A:middle
to create augmented reality

00:13:06.546 --> 00:13:07.146 A:middle
experience.

00:13:07.246 --> 00:13:10.676 A:middle
Now let's talk about tracking in

00:13:10.676 --> 00:13:11.156 A:middle
particular.

00:13:13.316 --> 00:13:15.636 A:middle
So, tracking is the ability to

00:13:15.636 --> 00:13:17.096 A:middle
determine a physical location in

00:13:17.096 --> 00:13:18.356 A:middle
space in real time.

00:13:19.836 --> 00:13:20.476 A:middle
This isn't easy.

00:13:20.856 --> 00:13:22.206 A:middle
So, but it's essential for

00:13:22.206 --> 00:13:25.016 A:middle
augmented reality to find your

00:13:25.016 --> 00:13:25.926 A:middle
device's position.

00:13:25.926 --> 00:13:27.246 A:middle
So not any position, but the

00:13:27.246 --> 00:13:28.456 A:middle
position of your device and the

00:13:28.456 --> 00:13:30.036 A:middle
orientation in order to render

00:13:30.036 --> 00:13:30.646 A:middle
things correctly.

00:13:31.136 --> 00:13:31.866 A:middle
So let's take a look at an

00:13:31.866 --> 00:13:32.196 A:middle
example.

00:13:33.266 --> 00:13:34.836 A:middle
Here I've placed a virtual chair

00:13:34.836 --> 00:13:36.646 A:middle
and a virtual table in a

00:13:36.646 --> 00:13:37.546 A:middle
physical environment.

00:13:38.236 --> 00:13:40.966 A:middle
You'll notice that if I pan

00:13:40.966 --> 00:13:43.026 A:middle
around it or reorient to my

00:13:43.026 --> 00:13:44.366 A:middle
device, that they'll stay fixed

00:13:44.366 --> 00:13:45.006 A:middle
in space.

00:13:45.316 --> 00:13:46.796 A:middle
But more importantly, as I walk

00:13:46.796 --> 00:13:48.576 A:middle
around the scene they also stay

00:13:48.616 --> 00:13:49.176 A:middle
fixed in space.

00:13:50.056 --> 00:13:51.596 A:middle
So this is because we're using,

00:13:52.096 --> 00:13:53.446 A:middle
constantly updating the

00:13:53.446 --> 00:13:55.006 A:middle
projection transform, or the

00:13:55.006 --> 00:13:55.896 A:middle
projection matrix that we're

00:13:55.896 --> 00:13:57.606 A:middle
using to render this virtual

00:13:57.606 --> 00:13:59.216 A:middle
content so that it appears

00:13:59.216 --> 00:14:00.966 A:middle
correct from any perspective.

00:14:02.916 --> 00:14:04.276 A:middle
So now how do we do this?

00:14:05.696 --> 00:14:07.276 A:middle
ARKit provides world tracking.

00:14:07.276 --> 00:14:09.206 A:middle
This is our technology that uses

00:14:09.206 --> 00:14:10.546 A:middle
visual inertial odometry.

00:14:10.896 --> 00:14:11.836 A:middle
It's your camera images.

00:14:11.836 --> 00:14:12.966 A:middle
It's the motion of your device.

00:14:12.966 --> 00:14:14.726 A:middle
And it provides to you a

00:14:14.726 --> 00:14:16.826 A:middle
rotation as well as a position

00:14:17.026 --> 00:14:18.536 A:middle
or relative position, of your

00:14:18.536 --> 00:14:18.986 A:middle
device.

00:14:19.496 --> 00:14:22.456 A:middle
But more importantly, it

00:14:22.456 --> 00:14:24.016 A:middle
provides real world scale.

00:14:24.636 --> 00:14:26.006 A:middle
So all your virtual content is

00:14:26.006 --> 00:14:27.416 A:middle
actually going to be to scale

00:14:27.656 --> 00:14:29.556 A:middle
rendered in your physical scene.

00:14:30.196 --> 00:14:32.946 A:middle
It also means that motion of

00:14:32.946 --> 00:14:34.346 A:middle
your device correlates to

00:14:34.346 --> 00:14:35.676 A:middle
physical distance traveled

00:14:36.016 --> 00:14:37.626 A:middle
measured in meters.

00:14:40.516 --> 00:14:42.036 A:middle
And all the positions given by

00:14:42.036 --> 00:14:43.586 A:middle
tracking are relative to the

00:14:43.586 --> 00:14:44.646 A:middle
starting position of your

00:14:44.646 --> 00:14:45.026 A:middle
session.

00:14:46.896 --> 00:14:48.476 A:middle
So one more function of how

00:14:48.476 --> 00:14:49.536 A:middle
World Tracking works.

00:14:50.156 --> 00:14:51.716 A:middle
We provide 3-D feature points.

00:14:52.486 --> 00:14:54.046 A:middle
So, here's a representation of

00:14:54.436 --> 00:14:55.416 A:middle
how World Tracking works.

00:14:55.566 --> 00:14:56.956 A:middle
It works by detecting features,

00:14:56.956 --> 00:14:57.996 A:middle
which are unique pieces of

00:14:57.996 --> 00:14:59.836 A:middle
information, in a camera image.

00:15:00.616 --> 00:15:01.486 A:middle
So you'll see the axes

00:15:01.486 --> 00:15:03.486 A:middle
represents my device's position

00:15:03.486 --> 00:15:04.236 A:middle
and orientation.

00:15:04.376 --> 00:15:05.796 A:middle
It's creating a path as I move

00:15:05.796 --> 00:15:06.366 A:middle
about my world.

00:15:06.406 --> 00:15:07.756 A:middle
But you also see all these dots

00:15:07.756 --> 00:15:08.036 A:middle
up here.

00:15:08.406 --> 00:15:09.936 A:middle
These represent 3-D feature

00:15:09.936 --> 00:15:11.226 A:middle
points that I've detected in my

00:15:11.226 --> 00:15:11.556 A:middle
scene.

00:15:11.916 --> 00:15:13.386 A:middle
I've been able to triangulate

00:15:13.386 --> 00:15:15.166 A:middle
them by moving about the scene

00:15:15.536 --> 00:15:17.206 A:middle
and then using these, matching

00:15:17.206 --> 00:15:19.276 A:middle
these features, you'll see that

00:15:19.276 --> 00:15:20.606 A:middle
I draw a line when I match an

00:15:20.606 --> 00:15:22.106 A:middle
existing feature that I've seen

00:15:22.106 --> 00:15:22.496 A:middle
before.

00:15:22.936 --> 00:15:24.166 A:middle
And using all of this

00:15:24.166 --> 00:15:25.616 A:middle
information and our motion data,

00:15:26.076 --> 00:15:27.796 A:middle
we're able to precisely provide

00:15:28.966 --> 00:15:30.616 A:middle
a device orientation and

00:15:30.826 --> 00:15:31.296 A:middle
location.

00:15:31.886 --> 00:15:33.666 A:middle
So that might look hard.

00:15:33.666 --> 00:15:35.636 A:middle
Let's look at the code on how we

00:15:35.636 --> 00:15:36.766 A:middle
run World Tracking.

00:15:37.276 --> 00:15:39.696 A:middle
First thing you need to do is

00:15:39.696 --> 00:15:40.976 A:middle
simply create an ARSession.

00:15:40.976 --> 00:15:42.266 A:middle
Because again, it's going to

00:15:42.266 --> 00:15:43.506 A:middle
manage all of the processing

00:15:43.616 --> 00:15:44.846 A:middle
that's going to happen for World

00:15:44.846 --> 00:15:45.196 A:middle
Tracking.

00:15:46.016 --> 00:15:47.306 A:middle
Next, you'll set yourself as the

00:15:47.306 --> 00:15:49.396 A:middle
delegate of the session so that

00:15:49.396 --> 00:15:50.696 A:middle
you can receive updates on when

00:15:50.696 --> 00:15:51.746 A:middle
new frames are available.

00:15:53.146 --> 00:15:54.306 A:middle
By creating a World Tracking

00:15:54.306 --> 00:15:55.166 A:middle
session configuration you're

00:15:55.166 --> 00:15:56.266 A:middle
saying, "I want to use World

00:15:56.266 --> 00:15:56.656 A:middle
Tracking.

00:15:56.656 --> 00:15:58.096 A:middle
I want my session to run this

00:15:58.096 --> 00:15:58.566 A:middle
processing."

00:15:59.316 --> 00:16:00.476 A:middle
Then by simply calling Run,

00:16:00.916 --> 00:16:01.956 A:middle
immediately processing will

00:16:01.956 --> 00:16:02.366 A:middle
happen.

00:16:02.366 --> 00:16:03.656 A:middle
Capturing will begin.

00:16:04.316 --> 00:16:05.636 A:middle
So, under the hood, our session

00:16:05.916 --> 00:16:08.266 A:middle
creates an AVCaptureSession --

00:16:08.476 --> 00:16:09.916 A:middle
sorry, as well as a

00:16:09.996 --> 00:16:12.136 A:middle
CMMotionManager in order to get

00:16:12.136 --> 00:16:13.436 A:middle
image and motion data.

00:16:14.476 --> 00:16:15.546 A:middle
We use the images to detect

00:16:15.546 --> 00:16:16.396 A:middle
features in the scene.

00:16:16.976 --> 00:16:18.336 A:middle
And we use the motion data at a

00:16:18.496 --> 00:16:19.506 A:middle
higher rate in order to

00:16:19.506 --> 00:16:21.046 A:middle
integrate it over time to get

00:16:21.046 --> 00:16:21.916 A:middle
your device's motion.

00:16:23.076 --> 00:16:24.886 A:middle
Using these together we're able

00:16:24.886 --> 00:16:26.566 A:middle
to use sensor fusion in order to

00:16:26.566 --> 00:16:27.846 A:middle
provide a precise pose.

00:16:27.846 --> 00:16:29.776 A:middle
So these are returned in

00:16:29.776 --> 00:16:30.336 A:middle
ARFrames.

00:16:30.906 --> 00:16:34.986 A:middle
Each ARFrame is going to include

00:16:34.986 --> 00:16:35.666 A:middle
an ARCamera.

00:16:36.266 --> 00:16:39.406 A:middle
So an ARCamera is the object

00:16:39.406 --> 00:16:40.876 A:middle
that represents a virtual

00:16:40.876 --> 00:16:41.136 A:middle
camera.

00:16:41.136 --> 00:16:42.106 A:middle
Or you can use it for a virtual

00:16:42.106 --> 00:16:42.386 A:middle
camera.

00:16:42.546 --> 00:16:43.826 A:middle
It represents your device's

00:16:43.826 --> 00:16:45.326 A:middle
orientation as well as location.

00:16:45.816 --> 00:16:47.196 A:middle
So it provides a transform.

00:16:47.776 --> 00:16:49.426 A:middle
Transform is a matrix or a

00:16:49.426 --> 00:16:51.216 A:middle
[inaudible] float 4 by 4 which

00:16:51.216 --> 00:16:52.956 A:middle
provides the orientation or the

00:16:52.956 --> 00:16:54.706 A:middle
rotation as well as translation

00:16:55.136 --> 00:16:56.576 A:middle
of your physical device from the

00:16:56.576 --> 00:16:57.836 A:middle
starting point of the session.

00:16:59.026 --> 00:17:00.156 A:middle
In addition to this we provide a

00:17:00.156 --> 00:17:02.026 A:middle
tracking state, which informs

00:17:02.026 --> 00:17:03.076 A:middle
you on how you can use the

00:17:03.076 --> 00:17:03.596 A:middle
transform.

00:17:04.576 --> 00:17:06.586 A:middle
And last, we provide camera

00:17:06.586 --> 00:17:07.276 A:middle
intrinsics.

00:17:07.986 --> 00:17:09.216 A:middle
So camera intrinsics are really

00:17:09.216 --> 00:17:10.806 A:middle
important that we get them each

00:17:10.806 --> 00:17:12.476 A:middle
frame because it matches that of

00:17:12.476 --> 00:17:13.716 A:middle
the physical camera on your

00:17:13.716 --> 00:17:14.146 A:middle
device.

00:17:14.726 --> 00:17:15.926 A:middle
This information like focal

00:17:15.926 --> 00:17:17.096 A:middle
length and principal point,

00:17:17.356 --> 00:17:18.436 A:middle
which are used to find a

00:17:18.436 --> 00:17:19.226 A:middle
projection matrix.

00:17:20.096 --> 00:17:21.876 A:middle
The projection matrix is also a

00:17:21.876 --> 00:17:23.096 A:middle
convenience method on ARCamera.

00:17:23.096 --> 00:17:24.886 A:middle
So you can easily use that to

00:17:24.886 --> 00:17:26.406 A:middle
render your virtual geometry.

00:17:26.946 --> 00:17:30.516 A:middle
So with that, that is tracking

00:17:30.516 --> 00:17:31.416 A:middle
that ARKit provides.

00:17:31.526 --> 00:17:32.326 A:middle
Let's go ahead and look at a

00:17:32.326 --> 00:17:34.036 A:middle
demo using World Tracking and

00:17:34.036 --> 00:17:35.136 A:middle
create your first ARKit

00:17:35.136 --> 00:17:35.776 A:middle
application.

00:17:36.516 --> 00:17:42.116 A:middle
[ Applause ]

00:17:42.616 --> 00:17:43.506 A:middle
So, the first thing that you

00:17:43.506 --> 00:17:45.506 A:middle
notice when you open new Xcode 9

00:17:45.786 --> 00:17:47.046 A:middle
is that there's a new template

00:17:47.046 --> 00:17:48.586 A:middle
available for creating augmented

00:17:48.586 --> 00:17:49.296 A:middle
reality apps.

00:17:49.296 --> 00:17:50.526 A:middle
So let's go ahead and select

00:17:50.526 --> 00:17:51.146 A:middle
that.

00:17:51.326 --> 00:17:52.596 A:middle
I'm going to create an augmented

00:17:52.596 --> 00:17:53.356 A:middle
reality app.

00:17:53.356 --> 00:17:55.246 A:middle
Hit Next. After giving my

00:17:55.246 --> 00:17:57.816 A:middle
project a name like MyARApp, I

00:17:58.416 --> 00:17:59.666 A:middle
can choose between the language,

00:18:00.386 --> 00:18:01.186 A:middle
which here I have the option

00:18:01.186 --> 00:18:02.456 A:middle
between Swift as well as

00:18:02.456 --> 00:18:04.626 A:middle
ObjectiveC as well as the

00:18:04.626 --> 00:18:05.576 A:middle
content technology.

00:18:05.776 --> 00:18:07.536 A:middle
So the content technology is

00:18:07.536 --> 00:18:08.686 A:middle
what you're going to use to

00:18:08.686 --> 00:18:10.126 A:middle
render your augmented reality

00:18:10.126 --> 00:18:10.256 A:middle
scene.

00:18:10.256 --> 00:18:11.876 A:middle
You have the option between

00:18:11.876 --> 00:18:14.016 A:middle
SceneKit, SpriteKit as well as

00:18:14.016 --> 00:18:14.286 A:middle
Metal.

00:18:14.336 --> 00:18:16.366 A:middle
I'm going to use SceneKit for

00:18:16.366 --> 00:18:16.936 A:middle
this example.

00:18:17.386 --> 00:18:20.146 A:middle
So after hitting Next and

00:18:20.146 --> 00:18:21.546 A:middle
creating my workspace, it looks

00:18:21.546 --> 00:18:22.286 A:middle
something like this.

00:18:23.216 --> 00:18:24.286 A:middle
Here I have a view controller

00:18:24.356 --> 00:18:25.526 A:middle
that I've created.

00:18:25.716 --> 00:18:26.646 A:middle
You'll see that it has an

00:18:26.646 --> 00:18:27.496 A:middle
ARSCNView.

00:18:28.066 --> 00:18:31.196 A:middle
So this ARSCNView is a custom AR

00:18:31.196 --> 00:18:32.466 A:middle
subclass that implements all the

00:18:32.466 --> 00:18:33.696 A:middle
rendering -- or most of the

00:18:33.696 --> 00:18:34.386 A:middle
rendering for me.

00:18:35.096 --> 00:18:36.426 A:middle
So it'll handle updating my

00:18:36.426 --> 00:18:38.046 A:middle
virtual camera based on the

00:18:38.046 --> 00:18:39.506 A:middle
ARFrames that get returned to

00:18:39.506 --> 00:18:39.576 A:middle
it.

00:18:40.116 --> 00:18:42.366 A:middle
As a property of ARSCNView, or

00:18:42.366 --> 00:18:44.536 A:middle
my sceneView, it has a session.

00:18:45.276 --> 00:18:47.676 A:middle
So you see that my sceneView, I

00:18:47.676 --> 00:18:49.116 A:middle
set a scene, which is going to

00:18:49.116 --> 00:18:50.376 A:middle
be a ship that's translated a

00:18:50.376 --> 00:18:51.756 A:middle
little bit in front of the world

00:18:51.756 --> 00:18:53.656 A:middle
origin along the z-axis.

00:18:54.096 --> 00:18:55.596 A:middle
And then the most important part

00:18:55.596 --> 00:18:57.366 A:middle
is I'm accessing the session --

00:18:57.956 --> 00:19:00.436 A:middle
I'm accessing the session and

00:19:00.436 --> 00:19:01.986 A:middle
calling Run with a World

00:19:01.986 --> 00:19:03.396 A:middle
Tracking session configuration.

00:19:03.906 --> 00:19:05.156 A:middle
So this will run World Tracking.

00:19:05.156 --> 00:19:06.456 A:middle
And automatically the view will

00:19:06.456 --> 00:19:07.676 A:middle
handle updating my virtual

00:19:07.676 --> 00:19:08.646 A:middle
camera for me.

00:19:09.766 --> 00:19:10.586 A:middle
So let's go ahead and give that

00:19:10.586 --> 00:19:10.956 A:middle
a try.

00:19:11.356 --> 00:19:12.806 A:middle
Maybe I'm going to change our

00:19:12.806 --> 00:19:15.086 A:middle
standard ship to use arship.

00:19:16.936 --> 00:19:19.926 A:middle
So let's run this on the device.

00:19:25.336 --> 00:19:26.526 A:middle
So after installing, the first

00:19:26.526 --> 00:19:27.856 A:middle
thing that you'll notice is that

00:19:27.856 --> 00:19:28.846 A:middle
it's going to ask for camera

00:19:28.846 --> 00:19:29.176 A:middle
permission.

00:19:29.546 --> 00:19:30.626 A:middle
This is a required to use

00:19:30.626 --> 00:19:32.006 A:middle
tracking as well as render the

00:19:32.006 --> 00:19:32.926 A:middle
backdrop of your scene.

00:19:33.796 --> 00:19:34.786 A:middle
Next, as you'll see, I get a

00:19:34.786 --> 00:19:35.306 A:middle
camera feed.

00:19:35.306 --> 00:19:36.706 A:middle
And right in front of me there's

00:19:36.706 --> 00:19:37.176 A:middle
a spaceship.

00:19:37.916 --> 00:19:39.236 A:middle
You'll see as I change the

00:19:39.236 --> 00:19:40.516 A:middle
orientation of my device, it

00:19:40.516 --> 00:19:41.996 A:middle
stays fixed in space.

00:19:42.626 --> 00:19:44.236 A:middle
But more importantly, as I move

00:19:44.236 --> 00:19:46.696 A:middle
about the spaceship, you'll see

00:19:46.696 --> 00:19:48.196 A:middle
that it actually is anchored in

00:19:48.196 --> 00:19:49.036 A:middle
the physical world.

00:19:49.686 --> 00:19:51.476 A:middle
So this is using both my

00:19:51.476 --> 00:19:52.856 A:middle
device's orientation as well as

00:19:52.856 --> 00:19:54.556 A:middle
a relative position to update a

00:19:54.556 --> 00:19:57.586 A:middle
virtual camera and look at the

00:19:57.586 --> 00:19:58.226 A:middle
spaceship.

00:19:59.016 --> 00:20:00.326 A:middle
[ Applause ]

00:20:00.326 --> 00:20:00.856 A:middle
Thank you.

00:20:02.516 --> 00:20:06.696 A:middle
[ Applause ]

00:20:07.196 --> 00:20:08.566 A:middle
So, if that's not interesting

00:20:08.566 --> 00:20:09.756 A:middle
enough for you, maybe we want to

00:20:09.756 --> 00:20:10.946 A:middle
add something to the scene every

00:20:10.946 --> 00:20:11.876 A:middle
time we tap the screen.

00:20:12.546 --> 00:20:13.206 A:middle
Let's try that out.

00:20:13.206 --> 00:20:14.486 A:middle
Let's try adding something to

00:20:14.486 --> 00:20:14.996 A:middle
this example.

00:20:14.996 --> 00:20:18.426 A:middle
So as I said, I want to add

00:20:18.746 --> 00:20:20.036 A:middle
geometry to the scene every time

00:20:20.036 --> 00:20:20.956 A:middle
I tap the screen.

00:20:21.696 --> 00:20:22.626 A:middle
First thing I need to do to do

00:20:22.626 --> 00:20:25.266 A:middle
that is add a tap gesture

00:20:25.266 --> 00:20:25.796 A:middle
recognizer.

00:20:26.016 --> 00:20:28.766 A:middle
So after adding that to my scene

00:20:28.806 --> 00:20:30.766 A:middle
view, every time I call the

00:20:30.766 --> 00:20:32.766 A:middle
handle tap method, or every time

00:20:32.766 --> 00:20:33.946 A:middle
I tap the screen, the handle tap

00:20:33.946 --> 00:20:34.816 A:middle
method will get called.

00:20:35.696 --> 00:20:39.416 A:middle
So let's implement that.

00:20:39.556 --> 00:20:40.546 A:middle
So, if I want to create some

00:20:40.546 --> 00:20:41.896 A:middle
geometry, let's say I'm going to

00:20:41.896 --> 00:20:43.706 A:middle
create a plane or an image

00:20:43.706 --> 00:20:43.946 A:middle
plane.

00:20:44.546 --> 00:20:47.886 A:middle
So the first thing I do here is

00:20:47.886 --> 00:20:49.346 A:middle
create an SCNPlane with a width

00:20:49.346 --> 00:20:49.676 A:middle
and height.

00:20:49.676 --> 00:20:51.676 A:middle
But then, the tricky part, I'm

00:20:51.676 --> 00:20:52.736 A:middle
actually going to set the

00:20:52.796 --> 00:20:54.816 A:middle
contents -- or the material, to

00:20:54.816 --> 00:20:57.016 A:middle
be a snapshot of my view.

00:20:57.016 --> 00:20:59.796 A:middle
So what do you think this is

00:20:59.796 --> 00:21:00.826 A:middle
going to be?

00:21:00.986 --> 00:21:02.076 A:middle
Well, this actually going to

00:21:02.076 --> 00:21:03.286 A:middle
take a snapshot or a rendering

00:21:03.286 --> 00:21:04.746 A:middle
of my view including the

00:21:04.916 --> 00:21:07.306 A:middle
backdrop camera image as well as

00:21:07.306 --> 00:21:08.606 A:middle
the virtual geometry that I've

00:21:08.706 --> 00:21:09.446 A:middle
placed in front of it.

00:21:10.136 --> 00:21:11.416 A:middle
I'm setting my lighting model to

00:21:11.416 --> 00:21:12.886 A:middle
constant so that the light

00:21:12.886 --> 00:21:14.266 A:middle
estimate provided by ARKit

00:21:14.516 --> 00:21:15.446 A:middle
doesn't get applied to this

00:21:15.446 --> 00:21:16.746 A:middle
camera image because it's

00:21:16.746 --> 00:21:17.646 A:middle
already going to match the

00:21:17.646 --> 00:21:18.330 A:middle
environment.

00:21:20.146 --> 00:21:21.346 A:middle
Next, I need to add this to the

00:21:21.346 --> 00:21:21.696 A:middle
scene.

00:21:22.126 --> 00:21:22.946 A:middle
So in order to do that, I'm

00:21:22.946 --> 00:21:24.926 A:middle
going to create a plane node.

00:21:28.116 --> 00:21:29.776 A:middle
So, after creating an SCNode

00:21:29.776 --> 00:21:31.686 A:middle
that encapsulates this geometry,

00:21:31.686 --> 00:21:32.576 A:middle
I add it to the scene.

00:21:33.306 --> 00:21:34.566 A:middle
So already here, every time I

00:21:34.566 --> 00:21:35.766 A:middle
tap the screen, it's going to

00:21:35.766 --> 00:21:37.296 A:middle
add an image plane to my scene.

00:21:37.296 --> 00:21:38.656 A:middle
But the problem is it's always

00:21:38.656 --> 00:21:39.806 A:middle
going to be at 000.

00:21:40.546 --> 00:21:41.336 A:middle
So how do I make this more

00:21:41.336 --> 00:21:41.756 A:middle
interesting?

00:21:42.546 --> 00:21:44.756 A:middle
Well, we have provided to us a

00:21:44.756 --> 00:21:46.256 A:middle
current frame, which contains an

00:21:46.256 --> 00:21:46.676 A:middle
AR Camera.

00:21:47.806 --> 00:21:49.316 A:middle
Which I could probably use the

00:21:49.746 --> 00:21:51.386 A:middle
camera's transform in order to

00:21:51.386 --> 00:21:52.446 A:middle
update the plane node's

00:21:52.446 --> 00:21:54.306 A:middle
transform so that the plane node

00:21:54.996 --> 00:21:56.436 A:middle
is where my camera currently is

00:21:56.436 --> 00:21:57.226 A:middle
located in space.

00:21:58.446 --> 00:21:59.546 A:middle
To do that, I'm going to first

00:21:59.546 --> 00:22:01.296 A:middle
get the current frame from my

00:22:01.296 --> 00:22:02.206 A:middle
SceneView session.

00:22:04.116 --> 00:22:05.066 A:middle
Next, I'm going to update the

00:22:05.146 --> 00:22:06.096 A:middle
plane node's transform

00:22:08.296 --> 00:22:10.156 A:middle
in order to use the transform of

00:22:10.216 --> 00:22:11.000 A:middle
my camera.

00:22:15.076 --> 00:22:16.346 A:middle
So here you'll notice the first

00:22:16.346 --> 00:22:17.606 A:middle
thing I do I actually create the

00:22:17.606 --> 00:22:18.546 A:middle
translation matrix.

00:22:19.036 --> 00:22:20.096 A:middle
Because I don't want to put the

00:22:20.096 --> 00:22:20.966 A:middle
image plane right where the

00:22:20.966 --> 00:22:22.406 A:middle
camera's located and obstruct my

00:22:22.406 --> 00:22:23.586 A:middle
view, I want to place it in

00:22:23.586 --> 00:22:24.296 A:middle
front of the camera.

00:22:24.796 --> 00:22:25.716 A:middle
So for this I'm going to use the

00:22:25.716 --> 00:22:27.576 A:middle
negative z-axis as a

00:22:27.576 --> 00:22:28.286 A:middle
translation.

00:22:29.276 --> 00:22:30.686 A:middle
You'll also see that in order to

00:22:30.686 --> 00:22:32.456 A:middle
get some scale, everything is in

00:22:32.456 --> 00:22:32.826 A:middle
meters.

00:22:32.826 --> 00:22:34.636 A:middle
So I'm going to use .1 to

00:22:34.636 --> 00:22:36.296 A:middle
represent 10 centimeters in

00:22:36.296 --> 00:22:37.426 A:middle
front of my camera.

00:22:37.956 --> 00:22:39.126 A:middle
By multiplying this together

00:22:39.276 --> 00:22:41.036 A:middle
with my camera's transform and

00:22:41.036 --> 00:22:42.746 A:middle
applying this to my plane node,

00:22:43.286 --> 00:22:44.446 A:middle
this will be an image plane

00:22:44.816 --> 00:22:46.206 A:middle
located 10 centimeters in front

00:22:46.206 --> 00:22:46.616 A:middle
of the camera.

00:22:47.836 --> 00:22:48.936 A:middle
So let's try this out and see

00:22:48.936 --> 00:22:50.000 A:middle
what it looks like.

00:22:58.416 --> 00:23:00.046 A:middle
So, as you see here again, I

00:23:00.046 --> 00:23:01.876 A:middle
have the camera scene running.

00:23:01.876 --> 00:23:03.666 A:middle
And I have my spaceship floating

00:23:03.666 --> 00:23:04.156 A:middle
in space.

00:23:06.456 --> 00:23:07.936 A:middle
Now, if I tap the screen maybe

00:23:08.006 --> 00:23:10.486 A:middle
here, here and here, you'll see

00:23:10.486 --> 00:23:12.086 A:middle
that it leaves a snapshot or an

00:23:12.086 --> 00:23:13.536 A:middle
image floating in space where I

00:23:13.536 --> 00:23:13.976 A:middle
took it.

00:23:14.516 --> 00:23:21.846 A:middle
[ Applause ]

00:23:22.346 --> 00:23:23.276 A:middle
This shows just one of the

00:23:23.346 --> 00:23:24.716 A:middle
possibilities that you can use

00:23:24.826 --> 00:23:25.466 A:middle
ARKit for.

00:23:25.556 --> 00:23:27.496 A:middle
And it really makes for a cool

00:23:27.656 --> 00:23:28.356 A:middle
experience.

00:23:28.746 --> 00:23:30.996 A:middle
Thank you.

00:23:30.996 --> 00:23:32.136 A:middle
And that's using ARKit.

00:23:33.516 --> 00:23:40.706 A:middle
[ Applause ]

00:23:41.206 --> 00:23:43.026 A:middle
So, now that you've seen a demo

00:23:43.026 --> 00:23:44.746 A:middle
using ARKit's tracking, let's

00:23:44.746 --> 00:23:45.916 A:middle
talk about getting the best

00:23:45.916 --> 00:23:47.086 A:middle
quality from your tracking

00:23:47.086 --> 00:23:47.546 A:middle
results.

00:23:49.016 --> 00:23:50.386 A:middle
First thing to note is that

00:23:50.386 --> 00:23:51.956 A:middle
tracking relies on uninterrupted

00:23:51.956 --> 00:23:52.486 A:middle
sensor data.

00:23:52.836 --> 00:23:54.256 A:middle
This just means if camera images

00:23:54.256 --> 00:23:55.466 A:middle
are no longer being provided to

00:23:55.466 --> 00:23:57.046 A:middle
your session, tracking will

00:23:57.046 --> 00:23:57.396 A:middle
stop.

00:23:57.776 --> 00:24:00.616 A:middle
We'll be unable to track.

00:24:00.616 --> 00:24:02.116 A:middle
Next, tracking works best in

00:24:02.116 --> 00:24:03.386 A:middle
well-textured environments.

00:24:04.056 --> 00:24:05.486 A:middle
This means we need enough visual

00:24:05.486 --> 00:24:07.026 A:middle
complexity in order to find

00:24:07.026 --> 00:24:08.246 A:middle
features from your camera

00:24:08.246 --> 00:24:08.556 A:middle
images.

00:24:09.236 --> 00:24:11.036 A:middle
So if I'm facing a white wall or

00:24:11.036 --> 00:24:11.976 A:middle
if there's not enough light in

00:24:11.976 --> 00:24:13.366 A:middle
the room, I will be unable to

00:24:13.406 --> 00:24:14.616 A:middle
find features.

00:24:14.876 --> 00:24:15.966 A:middle
And tracking will be limited.

00:24:16.356 --> 00:24:19.056 A:middle
Next, tracking also works best

00:24:19.056 --> 00:24:20.026 A:middle
in static scenes.

00:24:20.416 --> 00:24:21.556 A:middle
So if too much of what my camera

00:24:21.556 --> 00:24:23.676 A:middle
sees is moving, visual data

00:24:23.676 --> 00:24:25.086 A:middle
won't correspond to motion data,

00:24:25.426 --> 00:24:27.056 A:middle
which may result in drift, which

00:24:27.056 --> 00:24:28.506 A:middle
is also a limited tracking

00:24:28.506 --> 00:24:28.826 A:middle
state.

00:24:29.796 --> 00:24:31.576 A:middle
So to help with these, ARCamera

00:24:31.676 --> 00:24:33.716 A:middle
provides a tracking state

00:24:33.766 --> 00:24:34.156 A:middle
property.

00:24:35.786 --> 00:24:37.116 A:middle
Tracking state has three

00:24:37.116 --> 00:24:39.406 A:middle
possible values: Not Available,

00:24:39.986 --> 00:24:41.226 A:middle
Normal, and Limited.

00:24:42.036 --> 00:24:42.916 A:middle
When you first start your

00:24:42.916 --> 00:24:44.886 A:middle
session, it begins in Not

00:24:44.886 --> 00:24:45.306 A:middle
Available.

00:24:45.826 --> 00:24:46.546 A:middle
This just means that your

00:24:46.546 --> 00:24:48.016 A:middle
camera's transform has not yet

00:24:48.016 --> 00:24:49.616 A:middle
been populated and is the

00:24:49.616 --> 00:24:50.466 A:middle
identity matrix.

00:24:51.896 --> 00:24:53.446 A:middle
Soon after, once we find our

00:24:53.446 --> 00:24:55.076 A:middle
first tracking pose, the state

00:24:55.076 --> 00:24:56.326 A:middle
will change from Not Available

00:24:56.866 --> 00:24:57.286 A:middle
to Normal.

00:24:58.226 --> 00:24:59.376 A:middle
This signifies that you can now

00:24:59.376 --> 00:25:00.956 A:middle
use your camera's transform.

00:25:01.336 --> 00:25:04.596 A:middle
If at any later point after this

00:25:04.726 --> 00:25:05.896 A:middle
tracing becomes limited,

00:25:06.066 --> 00:25:07.376 A:middle
tracking state will change from

00:25:07.376 --> 00:25:09.786 A:middle
Normal to Limited, and also

00:25:09.786 --> 00:25:10.576 A:middle
provide a reason.

00:25:11.086 --> 00:25:12.106 A:middle
So, the reason in this case,

00:25:12.106 --> 00:25:13.356 A:middle
because I'm facing a white wall

00:25:13.356 --> 00:25:14.786 A:middle
or there's not enough light, is

00:25:14.836 --> 00:25:15.896 A:middle
Insufficient Features.

00:25:15.896 --> 00:25:18.776 A:middle
It's helpful to notify your

00:25:18.776 --> 00:25:19.926 A:middle
users when this happens.

00:25:20.156 --> 00:25:21.816 A:middle
So, to do that, we're providing

00:25:22.466 --> 00:25:23.736 A:middle
a session delegate method that

00:25:23.736 --> 00:25:24.276 A:middle
you can implement:

00:25:24.726 --> 00:25:26.126 A:middle
cameraDidChangeTrackingState.

00:25:26.956 --> 00:25:27.996 A:middle
So when this happens, you can

00:25:27.996 --> 00:25:29.686 A:middle
get the tracking state, if it's

00:25:29.686 --> 00:25:31.296 A:middle
limited, as well as the reason.

00:25:32.436 --> 00:25:33.716 A:middle
And from this you'll notify your

00:25:33.716 --> 00:25:34.086 A:middle
users.

00:25:34.126 --> 00:25:35.216 A:middle
Because they're the only ones

00:25:35.266 --> 00:25:36.676 A:middle
that can actually fix the

00:25:36.676 --> 00:25:38.316 A:middle
tracking situation by either

00:25:38.316 --> 00:25:39.996 A:middle
turning the lights up or not

00:25:39.996 --> 00:25:40.836 A:middle
facing a white wall.

00:25:41.376 --> 00:25:46.006 A:middle
The other part is if sensor data

00:25:46.006 --> 00:25:46.856 A:middle
becomes unavailable.

00:25:47.896 --> 00:25:49.246 A:middle
So, for this, we handle this by

00:25:49.246 --> 00:25:50.286 A:middle
session interruptions.

00:25:51.446 --> 00:25:52.706 A:middle
So, if your camera input is

00:25:52.706 --> 00:25:54.396 A:middle
unavailable due to -- the main

00:25:54.396 --> 00:25:55.416 A:middle
reasons being your app gets

00:25:55.416 --> 00:25:56.906 A:middle
backgrounded or maybe you're

00:25:56.906 --> 00:25:59.146 A:middle
doing multitasking on an iPad,

00:25:59.146 --> 00:26:00.576 A:middle
camera images also won't be

00:26:00.576 --> 00:26:01.506 A:middle
provided to your session.

00:26:02.226 --> 00:26:03.376 A:middle
In this case tracking will

00:26:03.376 --> 00:26:05.456 A:middle
become unavailable or stopped

00:26:05.586 --> 00:26:06.846 A:middle
and your session will be

00:26:06.846 --> 00:26:07.366 A:middle
interrupted.

00:26:07.736 --> 00:26:09.006 A:middle
So, to deal with this, we also

00:26:09.006 --> 00:26:10.996 A:middle
provide delegate methods to make

00:26:10.996 --> 00:26:11.656 A:middle
it really easy.

00:26:12.666 --> 00:26:15.086 A:middle
Here it's a good idea to present

00:26:15.086 --> 00:26:16.226 A:middle
an overlay or maybe blur your

00:26:16.226 --> 00:26:17.696 A:middle
screen to signify to the user

00:26:18.016 --> 00:26:18.876 A:middle
that your experience is

00:26:18.876 --> 00:26:20.626 A:middle
currently paused and no tracking

00:26:20.626 --> 00:26:21.166 A:middle
is occurring.

00:26:22.056 --> 00:26:23.636 A:middle
During an interruption, it's

00:26:23.636 --> 00:26:26.006 A:middle
also important to note that

00:26:26.156 --> 00:26:26.996 A:middle
because no tracking is

00:26:26.996 --> 00:26:28.696 A:middle
happening, the relative position

00:26:28.696 --> 00:26:29.656 A:middle
of your device won't be

00:26:29.656 --> 00:26:30.076 A:middle
available.

00:26:30.696 --> 00:26:32.406 A:middle
So if you had anchors or

00:26:32.406 --> 00:26:33.866 A:middle
physical locations in the scene,

00:26:34.286 --> 00:26:35.806 A:middle
they may no longer be aligned if

00:26:35.806 --> 00:26:36.966 A:middle
there was movement during this

00:26:36.966 --> 00:26:37.486 A:middle
interruption.

00:26:38.696 --> 00:26:39.916 A:middle
So for this, you may want to

00:26:40.096 --> 00:26:41.046 A:middle
optionally restart your

00:26:41.046 --> 00:26:42.406 A:middle
experience when you come back

00:26:42.406 --> 00:26:43.096 A:middle
from an interruption.

00:26:43.096 --> 00:26:47.026 A:middle
And so that's tracking.

00:26:47.026 --> 00:26:49.396 A:middle
Let's go ahead and hand it over

00:26:49.396 --> 00:26:50.586 A:middle
to Stefan to talk about scene

00:26:50.586 --> 00:26:51.086 A:middle
understanding.

00:26:51.086 --> 00:26:51.476 A:middle
Thank you.

00:26:52.516 --> 00:26:57.396 A:middle
[ Applause ]

00:26:57.896 --> 00:26:58.346 A:middle
&gt;&gt; Thank you, Mike.

00:26:59.696 --> 00:27:00.726 A:middle
Good afternoon everyone.

00:27:01.316 --> 00:27:02.456 A:middle
My name is Stefan Misslinger.

00:27:02.636 --> 00:27:03.966 A:middle
I'm an engineer on the ARKit

00:27:03.966 --> 00:27:04.316 A:middle
team.

00:27:04.726 --> 00:27:05.716 A:middle
And next we're going to talk

00:27:05.716 --> 00:27:06.856 A:middle
about scene understanding.

00:27:07.246 --> 00:27:08.476 A:middle
So the goal of scene

00:27:08.476 --> 00:27:09.776 A:middle
understanding is to find out

00:27:09.826 --> 00:27:11.586 A:middle
more about our environment in

00:27:11.586 --> 00:27:13.196 A:middle
order to place virtual objects

00:27:13.276 --> 00:27:14.346 A:middle
into this environment.

00:27:15.116 --> 00:27:16.686 A:middle
This includes information like

00:27:16.746 --> 00:27:18.186 A:middle
the 3-D topology of our

00:27:18.186 --> 00:27:19.806 A:middle
environment as well as the

00:27:19.806 --> 00:27:21.706 A:middle
lighting situation in order to

00:27:22.016 --> 00:27:24.256 A:middle
realistically place an object

00:27:24.256 --> 00:27:24.466 A:middle
there.

00:27:24.536 --> 00:27:27.646 A:middle
Let's look at an example of this

00:27:27.646 --> 00:27:28.236 A:middle
table here.

00:27:29.176 --> 00:27:30.626 A:middle
If you want to place an object,

00:27:30.726 --> 00:27:32.086 A:middle
a virtual object, onto this

00:27:32.086 --> 00:27:33.496 A:middle
table, the first thing we need

00:27:33.496 --> 00:27:35.006 A:middle
to know is that there is a

00:27:35.006 --> 00:27:36.366 A:middle
surface on which we can place

00:27:36.366 --> 00:27:36.766 A:middle
something.

00:27:37.516 --> 00:27:39.386 A:middle
And this is done by using plane

00:27:39.386 --> 00:27:39.846 A:middle
detection.

00:27:41.356 --> 00:27:43.626 A:middle
Second, we need to figure out a

00:27:43.626 --> 00:27:46.236 A:middle
3-D coordinate on which we place

00:27:46.236 --> 00:27:47.146 A:middle
our virtual object.

00:27:47.726 --> 00:27:49.296 A:middle
In order to find this we are

00:27:49.296 --> 00:27:50.426 A:middle
using hit-testing.

00:27:51.006 --> 00:27:52.736 A:middle
This involves sending a ray from

00:27:52.736 --> 00:27:54.556 A:middle
our device and intersecting it

00:27:54.556 --> 00:27:55.776 A:middle
with the real world in order to

00:27:55.776 --> 00:27:56.846 A:middle
find this coordinate.

00:27:57.316 --> 00:28:01.286 A:middle
And third, in order to place

00:28:01.506 --> 00:28:03.406 A:middle
this object in a realistic way

00:28:03.756 --> 00:28:06.076 A:middle
we need a light estimation to

00:28:06.076 --> 00:28:07.416 A:middle
match the lighting of our

00:28:07.416 --> 00:28:07.986 A:middle
environment.

00:28:08.896 --> 00:28:10.106 A:middle
Let's have a look at each one of

00:28:10.106 --> 00:28:11.886 A:middle
those three things starting with

00:28:11.886 --> 00:28:12.576 A:middle
plane detection.

00:28:13.066 --> 00:28:15.806 A:middle
So, plane detection provides you

00:28:15.806 --> 00:28:17.556 A:middle
with horizontal planes with

00:28:17.556 --> 00:28:18.636 A:middle
respect to gravity.

00:28:19.526 --> 00:28:20.816 A:middle
This includes planes like the

00:28:20.816 --> 00:28:22.406 A:middle
ground plane as well as any

00:28:22.406 --> 00:28:25.146 A:middle
parallel planes like tables.

00:28:25.586 --> 00:28:28.536 A:middle
ARKit does this by aggregating

00:28:28.536 --> 00:28:30.356 A:middle
information over multiple frames

00:28:30.876 --> 00:28:32.116 A:middle
so it runs in the background.

00:28:32.666 --> 00:28:34.346 A:middle
And as the user moves their

00:28:34.346 --> 00:28:35.746 A:middle
device around the scene, it

00:28:35.746 --> 00:28:37.336 A:middle
learns more about this plane.

00:28:38.816 --> 00:28:42.216 A:middle
This also allows us to retrieve

00:28:42.216 --> 00:28:44.006 A:middle
an aligned extent of this plane,

00:28:44.106 --> 00:28:45.766 A:middle
which means that we're fitting a

00:28:45.766 --> 00:28:47.716 A:middle
rectangle around all detected

00:28:47.836 --> 00:28:50.166 A:middle
parts of this plane and align it

00:28:50.236 --> 00:28:51.326 A:middle
with the major extent.

00:28:51.606 --> 00:28:54.046 A:middle
So this gives you an idea of the

00:28:54.046 --> 00:28:55.886 A:middle
major orientation of a physical

00:28:55.916 --> 00:28:56.216 A:middle
plane.

00:28:58.096 --> 00:28:59.936 A:middle
Furthermore, if there are

00:28:59.936 --> 00:29:01.626 A:middle
multiple virtual planes detected

00:29:01.626 --> 00:29:02.896 A:middle
for the same physical plane,

00:29:02.956 --> 00:29:04.626 A:middle
ARKit will handle merging those

00:29:04.626 --> 00:29:05.036 A:middle
together.

00:29:06.276 --> 00:29:08.356 A:middle
Then the combined plane will

00:29:08.356 --> 00:29:11.456 A:middle
grow to the extent of both

00:29:11.456 --> 00:29:13.436 A:middle
planes, hence the newer plane

00:29:13.436 --> 00:29:14.306 A:middle
will be removed from the

00:29:14.306 --> 00:29:14.686 A:middle
session.

00:29:15.226 --> 00:29:17.146 A:middle
Let's have a look at how it's

00:29:17.146 --> 00:29:17.946 A:middle
used as in code.

00:29:19.936 --> 00:29:21.986 A:middle
The first thing you want to do

00:29:22.166 --> 00:29:23.626 A:middle
is create an ARWorldTracking

00:29:23.626 --> 00:29:24.676 A:middle
session configuration.

00:29:25.666 --> 00:29:26.636 A:middle
And plane detection is a

00:29:26.636 --> 00:29:28.216 A:middle
property you can set on an

00:29:28.216 --> 00:29:29.476 A:middle
ARWorldTracking session

00:29:29.476 --> 00:29:30.206 A:middle
configuration.

00:29:30.576 --> 00:29:31.996 A:middle
So, to enable plane detection,

00:29:32.396 --> 00:29:33.716 A:middle
you simple set the plane

00:29:33.716 --> 00:29:34.876 A:middle
detection property to

00:29:34.876 --> 00:29:35.496 A:middle
Horizontal.

00:29:36.746 --> 00:29:38.506 A:middle
After that, you pass the

00:29:38.506 --> 00:29:40.106 A:middle
configuration back to the

00:29:40.166 --> 00:29:41.336 A:middle
ARSession by calling the Run

00:29:41.336 --> 00:29:41.756 A:middle
method.

00:29:42.096 --> 00:29:43.636 A:middle
And it will start detecting

00:29:43.636 --> 00:29:44.836 A:middle
planes in your environment.

00:29:47.176 --> 00:29:48.686 A:middle
If you want to turn off plane

00:29:48.686 --> 00:29:51.996 A:middle
detection, we simply set the

00:29:51.996 --> 00:29:53.306 A:middle
plane detection property to

00:29:53.306 --> 00:29:53.666 A:middle
None.

00:29:54.176 --> 00:29:56.406 A:middle
And then call the Run method on

00:29:56.466 --> 00:29:57.266 A:middle
ARSession again.

00:29:58.076 --> 00:29:59.586 A:middle
Any previously detected planes

00:29:59.746 --> 00:30:01.116 A:middle
in the session will remain.

00:30:01.306 --> 00:30:03.666 A:middle
That means they will be still

00:30:03.666 --> 00:30:06.226 A:middle
present in our ARFrames anchors.

00:30:07.916 --> 00:30:10.226 A:middle
So whenever a new plane has been

00:30:10.226 --> 00:30:12.306 A:middle
detected, they will be surfaced

00:30:12.306 --> 00:30:13.756 A:middle
to you as ARPlaneAnchors.

00:30:15.046 --> 00:30:17.156 A:middle
An ARPlaneAnchor is a subclass

00:30:17.156 --> 00:30:18.866 A:middle
of an ARAnchor, which means it

00:30:18.866 --> 00:30:20.636 A:middle
represents a real-world position

00:30:20.636 --> 00:30:21.476 A:middle
and orientation.

00:30:23.196 --> 00:30:24.766 A:middle
Whenever a new anchor is being

00:30:24.766 --> 00:30:26.646 A:middle
detected you will receive a

00:30:26.646 --> 00:30:28.596 A:middle
delegate call session didAdd

00:30:28.596 --> 00:30:29.056 A:middle
anchor.

00:30:29.716 --> 00:30:31.056 A:middle
And you can use that, for

00:30:31.056 --> 00:30:32.256 A:middle
example, to visualize your

00:30:32.256 --> 00:30:32.606 A:middle
plane.

00:30:34.056 --> 00:30:35.426 A:middle
The extent of the plane will be

00:30:35.426 --> 00:30:40.056 A:middle
surfaced to you as the extent,

00:30:40.056 --> 00:30:41.786 A:middle
which is in respect to a center

00:30:41.786 --> 00:30:42.366 A:middle
property.

00:30:42.966 --> 00:30:46.256 A:middle
So as the user moves the device

00:30:46.256 --> 00:30:47.886 A:middle
around the scene, we'll learn

00:30:47.886 --> 00:30:49.266 A:middle
more about this plane and can

00:30:49.266 --> 00:30:50.186 A:middle
update its extent.

00:30:50.186 --> 00:30:53.676 A:middle
When this happens you will

00:30:53.676 --> 00:30:55.316 A:middle
receive a delegate session

00:30:55.316 --> 00:30:57.316 A:middle
didUpdate frame -- or didUpdate

00:30:57.316 --> 00:30:57.676 A:middle
anchor.

00:30:58.796 --> 00:31:00.726 A:middle
And you can use that to update

00:31:00.726 --> 00:31:01.556 A:middle
your visualization.

00:31:02.566 --> 00:31:04.096 A:middle
Notice how the center property

00:31:04.096 --> 00:31:06.306 A:middle
actually moved because the plane

00:31:06.306 --> 00:31:07.656 A:middle
grew more into one direction

00:31:07.656 --> 00:31:08.126 A:middle
than another.

00:31:11.016 --> 00:31:13.156 A:middle
Whenever an anchor is being

00:31:13.156 --> 00:31:14.636 A:middle
removed from the session, you

00:31:14.636 --> 00:31:16.076 A:middle
will receive a delegate called

00:31:16.076 --> 00:31:17.486 A:middle
session didRemove anchor.

00:31:18.566 --> 00:31:21.216 A:middle
This can happen if ARKits merges

00:31:21.356 --> 00:31:22.986 A:middle
planes together and removes one

00:31:22.986 --> 00:31:23.906 A:middle
of them as a result.

00:31:24.646 --> 00:31:26.876 A:middle
In that case, you will receive a

00:31:26.876 --> 00:31:28.616 A:middle
delegate call session didRemove

00:31:28.616 --> 00:31:30.176 A:middle
anchor, and you can update your

00:31:30.176 --> 00:31:31.406 A:middle
visualization accordingly.

00:31:31.986 --> 00:31:35.286 A:middle
So now that we have an idea of

00:31:35.356 --> 00:31:36.626 A:middle
where there are planes in our

00:31:36.626 --> 00:31:38.066 A:middle
environment, let's have a look

00:31:38.066 --> 00:31:39.216 A:middle
at how to actually place

00:31:39.276 --> 00:31:40.116 A:middle
something into this.

00:31:40.536 --> 00:31:42.216 A:middle
And for this we provide

00:31:42.276 --> 00:31:42.876 A:middle
hit-testing.

00:31:43.426 --> 00:31:47.166 A:middle
So hit-testing involves sending

00:31:47.166 --> 00:31:48.406 A:middle
or intersecting a ray

00:31:48.406 --> 00:31:49.906 A:middle
originating from your device

00:31:49.906 --> 00:31:52.016 A:middle
with the real world and finding

00:31:52.016 --> 00:31:52.926 A:middle
the intersection point.

00:31:55.316 --> 00:31:56.926 A:middle
ARKit uses all the scene

00:31:56.926 --> 00:31:58.676 A:middle
information available, which

00:31:58.676 --> 00:32:01.006 A:middle
includes any detected planes as

00:32:01.006 --> 00:32:02.476 A:middle
well as the 3-D feature points

00:32:02.546 --> 00:32:04.846 A:middle
that ARWorldTracking is using to

00:32:04.966 --> 00:32:06.056 A:middle
figure out its position.

00:32:06.516 --> 00:32:10.926 A:middle
ARKit will then intersect our

00:32:10.926 --> 00:32:15.596 A:middle
ray with all information that is

00:32:15.596 --> 00:32:17.556 A:middle
available and return all

00:32:17.556 --> 00:32:19.196 A:middle
intersection points as an array

00:32:19.196 --> 00:32:21.616 A:middle
which is sorted by distance.

00:32:22.226 --> 00:32:23.676 A:middle
So the first entry in this array

00:32:23.676 --> 00:32:25.116 A:middle
will be the closest intersection

00:32:25.116 --> 00:32:25.646 A:middle
to the camera.

00:32:25.736 --> 00:32:30.266 A:middle
And there are different ways on

00:32:30.626 --> 00:32:31.796 A:middle
how you can perform this

00:32:31.796 --> 00:32:32.456 A:middle
intersection.

00:32:32.976 --> 00:32:35.336 A:middle
And you can define this by

00:32:35.536 --> 00:32:37.286 A:middle
providing a hit-test type.

00:32:38.276 --> 00:32:39.816 A:middle
So there are four ways on how to

00:32:39.816 --> 00:32:40.676 A:middle
do this.

00:32:40.676 --> 00:32:43.576 A:middle
Let's have a look.

00:32:43.576 --> 00:32:44.436 A:middle
If you are running plane

00:32:44.436 --> 00:32:46.446 A:middle
detection and ARKit has detected

00:32:46.446 --> 00:32:48.496 A:middle
a plane in our environment, we

00:32:48.496 --> 00:32:50.746 A:middle
can make use of that.

00:32:51.536 --> 00:32:53.376 A:middle
And here you have the choice of

00:32:53.376 --> 00:32:55.296 A:middle
using the extent of the plane or

00:32:55.296 --> 00:32:55.886 A:middle
ignoring it.

00:32:56.946 --> 00:32:59.676 A:middle
So if you want your user to be

00:33:00.246 --> 00:33:03.916 A:middle
able to move an object just on a

00:33:03.916 --> 00:33:05.616 A:middle
plane, you can take the extent

00:33:05.616 --> 00:33:07.366 A:middle
into account, which will mean

00:33:07.366 --> 00:33:09.836 A:middle
that if a ray intersects within

00:33:09.836 --> 00:33:11.316 A:middle
its extent, it will provide you

00:33:11.316 --> 00:33:12.216 A:middle
with an intersection.

00:33:12.936 --> 00:33:14.766 A:middle
If the ray hits outside of this,

00:33:15.206 --> 00:33:16.006 A:middle
it will not give you an

00:33:16.006 --> 00:33:16.586 A:middle
intersection.

00:33:17.156 --> 00:33:21.016 A:middle
In the case of, for example,

00:33:21.016 --> 00:33:23.296 A:middle
moving furniture around, or when

00:33:23.296 --> 00:33:24.836 A:middle
you only have detected a small

00:33:24.836 --> 00:33:26.666 A:middle
part of the ground plane, we can

00:33:26.666 --> 00:33:28.386 A:middle
choose to ignore this extent and

00:33:28.386 --> 00:33:29.896 A:middle
treat an existing plane as

00:33:29.896 --> 00:33:30.736 A:middle
infinite plane.

00:33:31.916 --> 00:33:33.136 A:middle
In that case you will always

00:33:33.136 --> 00:33:34.256 A:middle
receive an intersection.

00:33:34.726 --> 00:33:37.676 A:middle
And you can just use a patch of

00:33:37.676 --> 00:33:39.636 A:middle
the real world, but let your

00:33:39.636 --> 00:33:43.886 A:middle
users move an object along this

00:33:45.296 --> 00:33:45.436 A:middle
plane.

00:33:45.606 --> 00:33:46.626 A:middle
If you're not running plane

00:33:46.626 --> 00:33:47.966 A:middle
detection or we have not

00:33:47.966 --> 00:33:50.906 A:middle
detected any planes yet, we can

00:33:50.906 --> 00:33:52.846 A:middle
also estimate a plane based on

00:33:52.846 --> 00:33:54.126 A:middle
the 3-D feature points that we

00:33:54.126 --> 00:33:54.786 A:middle
have available.

00:33:56.276 --> 00:33:57.886 A:middle
In that case, ARKit will look

00:33:57.886 --> 00:33:59.606 A:middle
for coplanar points in our

00:33:59.606 --> 00:34:01.366 A:middle
environment and fit a plane into

00:34:01.366 --> 00:34:01.596 A:middle
that.

00:34:02.746 --> 00:34:04.066 A:middle
And after that it will return

00:34:04.066 --> 00:34:05.096 A:middle
you with the intersection of

00:34:05.096 --> 00:34:05.596 A:middle
this plane.

00:34:06.156 --> 00:34:09.736 A:middle
In case you want to place

00:34:09.736 --> 00:34:10.906 A:middle
something on a very small

00:34:10.906 --> 00:34:12.856 A:middle
surface, which does not form a

00:34:12.856 --> 00:34:14.326 A:middle
plane, or you have a very

00:34:14.406 --> 00:34:16.296 A:middle
irregular environment, you can

00:34:16.296 --> 00:34:17.586 A:middle
also choose to intersect with

00:34:17.586 --> 00:34:18.906 A:middle
the feature points directly.

00:34:20.796 --> 00:34:22.726 A:middle
This means that we will find an

00:34:22.726 --> 00:34:24.496 A:middle
intersection along our ray,

00:34:24.716 --> 00:34:26.076 A:middle
which is closest to an existing

00:34:26.076 --> 00:34:27.686 A:middle
feature point, and return this

00:34:27.866 --> 00:34:28.736 A:middle
as the result.

00:34:29.246 --> 00:34:31.566 A:middle
Let's have a look at how this is

00:34:31.796 --> 00:34:32.386 A:middle
done in code.

00:34:32.926 --> 00:34:36.066 A:middle
So the first thing we need to do

00:34:36.416 --> 00:34:37.936 A:middle
is define our ray.

00:34:38.726 --> 00:34:41.536 A:middle
And it intersects on our device.

00:34:42.116 --> 00:34:45.286 A:middle
You provide this as a CG point,

00:34:45.286 --> 00:34:46.586 A:middle
which is represented in

00:34:46.586 --> 00:34:47.736 A:middle
normalized image space

00:34:47.736 --> 00:34:48.346 A:middle
coordinates.

00:34:48.436 --> 00:34:50.166 A:middle
This means the top left of our

00:34:50.166 --> 00:34:51.866 A:middle
image is 0, 0, whereas the

00:34:51.866 --> 00:34:53.326 A:middle
bottom right is 1, 1.

00:34:53.946 --> 00:34:57.616 A:middle
So if we want to send a ray or

00:34:58.016 --> 00:34:59.066 A:middle
find an intersection in the

00:34:59.146 --> 00:35:00.706 A:middle
center of our screen, we would

00:35:00.706 --> 00:35:04.416 A:middle
define as CG points with 0.5 for

00:35:04.416 --> 00:35:05.026 A:middle
x and y.

00:35:05.526 --> 00:35:07.556 A:middle
If you're using SceneKit or

00:35:07.556 --> 00:35:08.846 A:middle
SpriteKit, we're providing a

00:35:08.846 --> 00:35:10.976 A:middle
custom overlay that you can

00:35:10.976 --> 00:35:15.446 A:middle
simply pass a CG point in a few

00:35:15.446 --> 00:35:16.256 A:middle
coordinates.

00:35:16.256 --> 00:35:18.796 A:middle
So you can use the result of a

00:35:18.796 --> 00:35:22.356 A:middle
UI tap over touch gesture as

00:35:22.356 --> 00:35:23.616 A:middle
inputs to define this ray.

00:35:24.126 --> 00:35:27.206 A:middle
So let's pass this point onto

00:35:27.206 --> 00:35:29.486 A:middle
the hit-test method and define

00:35:29.826 --> 00:35:31.116 A:middle
the hit-test types that we want

00:35:31.116 --> 00:35:31.566 A:middle
to use.

00:35:31.786 --> 00:35:33.286 A:middle
In this case we're using exiting

00:35:33.286 --> 00:35:34.456 A:middle
planes, which means it will

00:35:34.456 --> 00:35:36.436 A:middle
intersect with any existing

00:35:36.436 --> 00:35:37.816 A:middle
planes that ARKit has already

00:35:37.816 --> 00:35:39.916 A:middle
detected, as well as estimated

00:35:39.916 --> 00:35:40.846 A:middle
horizontal planes.

00:35:41.126 --> 00:35:42.466 A:middle
So this can be used as a

00:35:42.466 --> 00:35:44.466 A:middle
fallback case in case there are

00:35:44.466 --> 00:35:46.216 A:middle
no planes detected yet.

00:35:46.806 --> 00:35:50.086 A:middle
After that, ARKit will return an

00:35:50.086 --> 00:35:53.796 A:middle
array of results.

00:35:53.796 --> 00:35:55.636 A:middle
And you can access the first

00:35:55.636 --> 00:35:56.676 A:middle
result, which will be the

00:35:56.676 --> 00:35:58.636 A:middle
closest intersection to your

00:35:58.636 --> 00:35:58.976 A:middle
camera.

00:36:01.856 --> 00:36:03.736 A:middle
The intersection points is

00:36:03.736 --> 00:36:05.186 A:middle
contained in the worldTransform

00:36:05.186 --> 00:36:07.096 A:middle
property of our hit-test result.

00:36:07.586 --> 00:36:09.166 A:middle
And we can create a new ARAnchor

00:36:09.166 --> 00:36:11.276 A:middle
based on this result and pass it

00:36:11.276 --> 00:36:12.936 A:middle
back to the session because we

00:36:12.936 --> 00:36:14.566 A:middle
want to keep track of it.

00:36:16.096 --> 00:36:18.126 A:middle
So if we take this code and

00:36:18.126 --> 00:36:20.626 A:middle
would apply it to the scene here

00:36:20.916 --> 00:36:21.976 A:middle
where we point our phone at a

00:36:21.976 --> 00:36:25.046 A:middle
table, it would return us the

00:36:25.046 --> 00:36:26.726 A:middle
intersection points on this

00:36:26.726 --> 00:36:28.046 A:middle
table in the center of the

00:36:28.046 --> 00:36:28.456 A:middle
screen.

00:36:28.686 --> 00:36:30.836 A:middle
And we can place a virtual cup

00:36:30.836 --> 00:36:31.816 A:middle
at this location.

00:36:33.816 --> 00:36:35.866 A:middle
By default, your rendering

00:36:35.866 --> 00:36:37.046 A:middle
engine will assume that your

00:36:37.046 --> 00:36:38.596 A:middle
background image is perfectly

00:36:38.596 --> 00:36:38.806 A:middle
lit.

00:36:39.226 --> 00:36:41.526 A:middle
So your augmentation looks like

00:36:41.526 --> 00:36:42.496 A:middle
it really belongs there.

00:36:43.226 --> 00:36:44.596 A:middle
However, if you're in a darker

00:36:44.596 --> 00:36:47.396 A:middle
environment, then your camera

00:36:47.396 --> 00:36:49.126 A:middle
image is darker, and it means

00:36:49.286 --> 00:36:50.726 A:middle
that your augmentation will look

00:36:50.726 --> 00:36:52.106 A:middle
out of place and it appears to

00:36:52.106 --> 00:36:52.406 A:middle
glow.

00:36:53.016 --> 00:36:56.506 A:middle
In order to fix this, we need to

00:36:56.506 --> 00:36:57.956 A:middle
adjust the relative brightness

00:36:58.426 --> 00:37:00.526 A:middle
of our virtual object.

00:37:00.696 --> 00:37:03.896 A:middle
And for this, we are providing

00:37:03.896 --> 00:37:04.646 A:middle
light estimation.

00:37:05.216 --> 00:37:09.516 A:middle
So light estimation operates on

00:37:09.516 --> 00:37:10.546 A:middle
our camera image.

00:37:10.926 --> 00:37:12.156 A:middle
And it uses its exposure

00:37:12.156 --> 00:37:13.936 A:middle
information to determine the

00:37:13.936 --> 00:37:15.646 A:middle
relative brightness of it.

00:37:16.436 --> 00:37:18.046 A:middle
For a well-lit image, this

00:37:18.046 --> 00:37:19.556 A:middle
defaults to 1000 lumen.

00:37:20.096 --> 00:37:21.726 A:middle
For a brighter environment, you

00:37:21.726 --> 00:37:23.146 A:middle
will get a higher value.

00:37:23.146 --> 00:37:24.536 A:middle
For a darker environment, a

00:37:24.536 --> 00:37:25.566 A:middle
lower value.

00:37:26.636 --> 00:37:27.976 A:middle
You can also assign this value

00:37:27.976 --> 00:37:30.846 A:middle
directly to an SEN light as its

00:37:30.846 --> 00:37:32.266 A:middle
ambient intensity property.

00:37:32.866 --> 00:37:34.266 A:middle
Hence, if you're using

00:37:34.266 --> 00:37:35.656 A:middle
physically-based lighting, it

00:37:35.656 --> 00:37:36.656 A:middle
will automatically take

00:37:36.656 --> 00:37:39.276 A:middle
advantage of this.

00:37:39.486 --> 00:37:40.796 A:middle
Light estimation is enabled by

00:37:40.796 --> 00:37:41.416 A:middle
default.

00:37:41.416 --> 00:37:43.746 A:middle
And you can configure this by

00:37:43.746 --> 00:37:44.306 A:middle
setting the

00:37:44.306 --> 00:37:47.176 A:middle
isLightEstimationEnabled

00:37:47.176 --> 00:37:48.736 A:middle
property on an ARSession

00:37:48.736 --> 00:37:49.456 A:middle
configuration.

00:37:50.426 --> 00:37:51.946 A:middle
The results of light estimation

00:37:52.566 --> 00:37:54.256 A:middle
are provided to you in the Light

00:37:54.256 --> 00:37:56.036 A:middle
Estimate property on the ARFrame

00:37:56.366 --> 00:37:59.036 A:middle
as its ambient intensity value.

00:37:59.686 --> 00:38:03.286 A:middle
So with that, let's dive into a

00:38:03.286 --> 00:38:04.886 A:middle
demo and look how we're using

00:38:04.886 --> 00:38:06.326 A:middle
scene understanding with ARKit.

00:38:07.516 --> 00:38:16.636 A:middle
[ Applause ]

00:38:17.136 --> 00:38:18.516 A:middle
So the application that I'm

00:38:18.516 --> 00:38:20.836 A:middle
going to show you is the ARKit

00:38:20.896 --> 00:38:21.826 A:middle
Sample application.

00:38:22.136 --> 00:38:22.976 A:middle
Which means you can also

00:38:22.976 --> 00:38:25.186 A:middle
download it from our developer

00:38:25.186 --> 00:38:25.646 A:middle
website.

00:38:27.076 --> 00:38:29.156 A:middle
It's used to place objects into

00:38:29.156 --> 00:38:29.866 A:middle
our environment.

00:38:30.386 --> 00:38:31.576 A:middle
And it's using scene

00:38:31.576 --> 00:38:33.366 A:middle
understanding in order to do

00:38:33.366 --> 00:38:33.576 A:middle
that.

00:38:33.956 --> 00:38:36.686 A:middle
So, let's bring it right up

00:38:37.676 --> 00:38:37.776 A:middle
here.

00:38:37.986 --> 00:38:39.616 A:middle
And if I move it around here,

00:38:39.996 --> 00:38:41.966 A:middle
what you see in front of me is

00:38:42.966 --> 00:38:44.376 A:middle
our focus square.

00:38:44.676 --> 00:38:46.896 A:middle
And we're placing this by doing

00:38:46.896 --> 00:38:48.616 A:middle
hit-testing in the center of our

00:38:48.616 --> 00:38:51.366 A:middle
scene and finding on placing the

00:38:51.366 --> 00:38:52.626 A:middle
object at its intersection

00:38:52.626 --> 00:38:52.946 A:middle
point.

00:38:53.776 --> 00:38:55.536 A:middle
So if I move this along our

00:38:55.536 --> 00:38:57.276 A:middle
table, you see that it basically

00:38:57.276 --> 00:38:58.556 A:middle
slides along this table.

00:39:00.046 --> 00:39:02.736 A:middle
It's also using plane detection

00:39:02.806 --> 00:39:03.616 A:middle
in parallel.

00:39:03.616 --> 00:39:05.396 A:middle
And we can visualize this to see

00:39:05.396 --> 00:39:06.086 A:middle
what's going on.

00:39:06.356 --> 00:39:08.326 A:middle
So let's bring up our Debug menu

00:39:08.326 --> 00:39:10.606 A:middle
here and activate the second

00:39:10.606 --> 00:39:11.966 A:middle
option here, which is Debug

00:39:11.966 --> 00:39:12.846 A:middle
Visualizations.

00:39:13.736 --> 00:39:14.306 A:middle
Let's close it.

00:39:15.376 --> 00:39:16.416 A:middle
And what you see here is the

00:39:16.416 --> 00:39:17.646 A:middle
plane that it has detected.

00:39:18.356 --> 00:39:21.986 A:middle
To give you a better idea, let's

00:39:21.986 --> 00:39:27.016 A:middle
restart this and see how it

00:39:27.016 --> 00:39:27.846 A:middle
finds new planes.

00:39:27.846 --> 00:39:29.266 A:middle
So if I'm moving it around here,

00:39:29.546 --> 00:39:30.716 A:middle
you see it has detected a new

00:39:30.716 --> 00:39:31.056 A:middle
plane.

00:39:32.106 --> 00:39:33.036 A:middle
Let's quickly point it at

00:39:33.036 --> 00:39:34.516 A:middle
another part of this table, and

00:39:34.516 --> 00:39:35.966 A:middle
it has found another plane.

00:39:36.596 --> 00:39:38.296 A:middle
And if I'm moving this along

00:39:38.296 --> 00:39:41.706 A:middle
this table, it eventually merges

00:39:41.816 --> 00:39:42.736 A:middle
both of them together.

00:39:42.876 --> 00:39:43.946 A:middle
And it figured out that there's

00:39:43.976 --> 00:39:45.396 A:middle
just one plane there.

00:39:47.516 --> 00:39:53.856 A:middle
[ Applause ]

00:39:54.356 --> 00:39:56.006 A:middle
So next, let's place some actual

00:39:56.006 --> 00:39:56.756 A:middle
objects here.

00:39:59.256 --> 00:40:01.076 A:middle
My daughter asked to bring some

00:40:01.076 --> 00:40:02.746 A:middle
flowers to the presentation.

00:40:02.746 --> 00:40:03.976 A:middle
And I don't want to disappoint

00:40:03.976 --> 00:40:04.166 A:middle
her.

00:40:05.036 --> 00:40:07.196 A:middle
So, let's make this more

00:40:07.196 --> 00:40:09.206 A:middle
romantic here and place a nice

00:40:09.206 --> 00:40:09.446 A:middle
vase.

00:40:10.026 --> 00:40:13.286 A:middle
In that case, we again hit-test

00:40:13.476 --> 00:40:15.126 A:middle
against the center of our screen

00:40:15.776 --> 00:40:17.116 A:middle
and find the intersection the

00:40:17.116 --> 00:40:21.436 A:middle
point to place the object.

00:40:21.596 --> 00:40:22.996 A:middle
One important aspect here is

00:40:23.566 --> 00:40:25.356 A:middle
that this vase actually appears

00:40:25.356 --> 00:40:26.486 A:middle
in real-world scale.

00:40:26.726 --> 00:40:28.156 A:middle
And this is possible due to two

00:40:28.156 --> 00:40:28.486 A:middle
things.

00:40:29.446 --> 00:40:31.136 A:middle
One is that WorldTracking

00:40:31.136 --> 00:40:34.646 A:middle
provides us with the pose to

00:40:34.846 --> 00:40:35.346 A:middle
scale.

00:40:35.396 --> 00:40:38.006 A:middle
And the second thing is that our

00:40:38.006 --> 00:40:39.856 A:middle
3-D model is actually modeled in

00:40:39.856 --> 00:40:41.566 A:middle
3-D in real-world coordinates.

00:40:41.746 --> 00:40:43.166 A:middle
So this is really important if

00:40:43.166 --> 00:40:44.756 A:middle
you're creating content for

00:40:44.756 --> 00:40:46.596 A:middle
augmented reality that you take

00:40:46.596 --> 00:40:49.136 A:middle
this into account that this vase

00:40:49.136 --> 00:40:51.756 A:middle
should not appear as high as

00:40:51.756 --> 00:40:53.036 A:middle
building or too small.

00:40:53.456 --> 00:40:57.366 A:middle
So let's go ahead and place a

00:40:57.366 --> 00:40:59.906 A:middle
more interactive object, which

00:40:59.906 --> 00:41:01.096 A:middle
is my chameleon friend here.

00:41:02.196 --> 00:41:04.196 A:middle
[ Applause ]

00:41:04.376 --> 00:41:07.096 A:middle
And one nice thing -- thank you

00:41:07.806 --> 00:41:08.856 A:middle
-- and one nice thing is that

00:41:09.616 --> 00:41:11.106 A:middle
you always know the position of

00:41:11.106 --> 00:41:14.546 A:middle
the user when you're running

00:41:14.546 --> 00:41:15.246 A:middle
WorldTracking.

00:41:15.686 --> 00:41:17.436 A:middle
So you can have your virtual

00:41:17.436 --> 00:41:19.486 A:middle
content interact with the user

00:41:19.806 --> 00:41:21.636 A:middle
in the real world.

00:41:23.516 --> 00:41:29.086 A:middle
[ Applause ]

00:41:29.586 --> 00:41:32.506 A:middle
So, if I move over here, it

00:41:32.786 --> 00:41:35.406 A:middle
might eventually turn to me, if

00:41:35.406 --> 00:41:36.086 A:middle
he's not scared.

00:41:36.306 --> 00:41:37.966 A:middle
Yeah, there we go.

00:41:38.516 --> 00:41:43.546 A:middle
[ Applause ]

00:41:44.046 --> 00:41:45.296 A:middle
And if I get even closer he

00:41:45.296 --> 00:41:46.486 A:middle
might react in even different

00:41:46.486 --> 00:41:46.686 A:middle
ways.

00:41:47.616 --> 00:41:48.066 A:middle
Let's see.

00:41:48.526 --> 00:41:49.606 A:middle
It's a bit -- oh!

00:41:49.606 --> 00:41:52.526 A:middle
There we go.

00:41:53.856 --> 00:41:54.946 A:middle
Another thing that chameleons

00:41:54.946 --> 00:41:56.976 A:middle
can do is change their color.

00:41:57.156 --> 00:42:00.966 A:middle
And if I tap him, he adjusts the

00:42:00.966 --> 00:42:01.326 A:middle
color.

00:42:03.556 --> 00:42:05.926 A:middle
So let's give it a green.

00:42:07.976 --> 00:42:09.236 A:middle
And one nice feature that we put

00:42:09.236 --> 00:42:11.996 A:middle
in here is I can move him along

00:42:11.996 --> 00:42:15.076 A:middle
the table, and he will adapt to

00:42:15.076 --> 00:42:16.636 A:middle
the background color of the

00:42:16.636 --> 00:42:18.076 A:middle
table in order to blend in

00:42:18.076 --> 00:42:18.526 A:middle
nicely.

00:42:19.516 --> 00:42:28.546 A:middle
[ Applause ]

00:42:29.046 --> 00:42:30.606 A:middle
So this is our sample

00:42:30.606 --> 00:42:31.206 A:middle
application.

00:42:31.576 --> 00:42:32.906 A:middle
You can download it from the

00:42:32.906 --> 00:42:35.216 A:middle
website and put in your own

00:42:35.216 --> 00:42:37.416 A:middle
contents and play around with

00:42:38.016 --> 00:42:39.686 A:middle
it, basically.

00:42:39.686 --> 00:42:41.816 A:middle
So next, we're going to have a

00:42:41.816 --> 00:42:43.916 A:middle
look at rendering with ARKit.

00:42:47.496 --> 00:42:49.516 A:middle
Rendering brings tracking and

00:42:49.566 --> 00:42:51.076 A:middle
scene understanding together

00:42:51.266 --> 00:42:52.046 A:middle
with your content.

00:42:52.946 --> 00:42:54.156 A:middle
And in order to render with

00:42:54.156 --> 00:42:56.016 A:middle
ARKit, you need to process all

00:42:56.016 --> 00:42:57.656 A:middle
the information that we provide

00:42:57.656 --> 00:42:58.696 A:middle
you in an ARFrame.

00:42:59.826 --> 00:43:01.616 A:middle
For those of you using SceneKit

00:43:01.616 --> 00:43:03.686 A:middle
and SpriteKit, we have already

00:43:03.866 --> 00:43:05.566 A:middle
created customized views that

00:43:05.566 --> 00:43:07.146 A:middle
take care of rending ARFrames

00:43:07.186 --> 00:43:07.566 A:middle
for you.

00:43:08.166 --> 00:43:11.686 A:middle
If you're using Metal, and want

00:43:11.686 --> 00:43:13.056 A:middle
to create your own rendering

00:43:13.056 --> 00:43:15.226 A:middle
engine or integrate ARKit into

00:43:15.226 --> 00:43:16.616 A:middle
your existing rendering engine,

00:43:16.996 --> 00:43:19.256 A:middle
we're providing a template that

00:43:19.356 --> 00:43:20.596 A:middle
gives you an idea of how to do

00:43:20.596 --> 00:43:22.186 A:middle
this and provides a good

00:43:22.186 --> 00:43:22.866 A:middle
starting point.

00:43:23.966 --> 00:43:25.266 A:middle
Let's have a look at each one of

00:43:25.266 --> 00:43:27.626 A:middle
those, starting with SceneKit.

00:43:28.336 --> 00:43:30.136 A:middle
For SceneKit we're providing an

00:43:30.136 --> 00:43:31.946 A:middle
ARSCNView, which is a subclass

00:43:31.946 --> 00:43:33.166 A:middle
of an SCNView.

00:43:34.376 --> 00:43:36.216 A:middle
It contains an ARSession that it

00:43:36.216 --> 00:43:38.146 A:middle
uses to update its rendering.

00:43:39.036 --> 00:43:40.246 A:middle
So this includes drawing the

00:43:40.246 --> 00:43:41.526 A:middle
camera image in the background,

00:43:42.646 --> 00:43:44.496 A:middle
taking into account the rotation

00:43:44.496 --> 00:43:46.466 A:middle
of the device as well as any

00:43:46.466 --> 00:43:47.036 A:middle
[inaudible] changes.

00:43:47.486 --> 00:43:51.946 A:middle
Next, it updates an SCNCamera

00:43:51.946 --> 00:43:53.596 A:middle
based on the tracking transforms

00:43:53.596 --> 00:43:55.196 A:middle
that we provide in an ARCamera.

00:43:55.786 --> 00:43:58.706 A:middle
So your scene stays intact and

00:43:58.846 --> 00:44:00.386 A:middle
ARKit simply controls an

00:44:00.516 --> 00:44:02.096 A:middle
SCNCamera by moving it around

00:44:02.096 --> 00:44:03.426 A:middle
the scene the way you move

00:44:03.426 --> 00:44:05.426 A:middle
around your device in the real

00:44:05.976 --> 00:44:06.106 A:middle
world.

00:44:07.076 --> 00:44:08.186 A:middle
If you're using Light

00:44:08.186 --> 00:44:09.676 A:middle
Estimation, we automatically

00:44:09.676 --> 00:44:12.786 A:middle
place an SCN light probe into

00:44:12.786 --> 00:44:15.936 A:middle
your scene so if you use objects

00:44:15.936 --> 00:44:17.606 A:middle
with physically-based lighting

00:44:17.766 --> 00:44:20.106 A:middle
enabled you can already take

00:44:20.106 --> 00:44:21.496 A:middle
advantage or automatically take

00:44:21.496 --> 00:44:23.006 A:middle
advantage of Light Estimation.

00:44:23.546 --> 00:44:28.276 A:middle
And one thing that ARCNView does

00:44:28.616 --> 00:44:32.626 A:middle
is map SCNNotes to ARAnchors so

00:44:32.626 --> 00:44:33.966 A:middle
you don't actually need to

00:44:33.966 --> 00:44:35.536 A:middle
interface with ARAnchors

00:44:35.576 --> 00:44:37.526 A:middle
directly, but can continue to

00:44:37.526 --> 00:44:38.686 A:middle
use SCNNotes.

00:44:39.616 --> 00:44:40.646 A:middle
This means whenever a new

00:44:40.646 --> 00:44:42.026 A:middle
ARAnchor is being added to the

00:44:42.026 --> 00:44:44.686 A:middle
session, ARSCNView will create a

00:44:44.686 --> 00:44:45.336 A:middle
node for you.

00:44:45.986 --> 00:44:47.946 A:middle
And every time we update the

00:44:47.946 --> 00:44:50.336 A:middle
ARAnchor, like its transform, we

00:44:50.336 --> 00:44:51.816 A:middle
update the nodes transform

00:44:51.816 --> 00:44:52.436 A:middle
automatically.

00:44:52.976 --> 00:44:56.366 A:middle
And this is handled through the

00:44:56.366 --> 00:44:57.516 A:middle
ARSCNView delegate.

00:45:00.116 --> 00:45:02.226 A:middle
So every time we add a new

00:45:02.496 --> 00:45:06.026 A:middle
anchor to the session, ARSCNView

00:45:06.026 --> 00:45:08.116 A:middle
will create a new SCNNode for

00:45:08.116 --> 00:45:08.286 A:middle
you.

00:45:09.216 --> 00:45:10.366 A:middle
If you want to provide your own

00:45:10.366 --> 00:45:12.276 A:middle
nodes, you can implement

00:45:12.626 --> 00:45:14.396 A:middle
renderer nodeFor anchor and

00:45:14.396 --> 00:45:15.686 A:middle
return to your custom node for

00:45:15.686 --> 00:45:15.986 A:middle
this.

00:45:16.666 --> 00:45:18.896 A:middle
After this, the SCNNode will be

00:45:19.206 --> 00:45:21.346 A:middle
added to the scene graph.

00:45:21.976 --> 00:45:23.316 A:middle
And you will receive another

00:45:23.316 --> 00:45:25.616 A:middle
delegate call renderer didAdd

00:45:25.696 --> 00:45:26.506 A:middle
node for anchor.

00:45:27.056 --> 00:45:29.796 A:middle
The same holds true for whenever

00:45:29.796 --> 00:45:33.076 A:middle
a node is being updated.

00:45:34.276 --> 00:45:37.096 A:middle
So in that case, DSCNNodes

00:45:37.096 --> 00:45:38.496 A:middle
transform will be automatically

00:45:38.496 --> 00:45:40.066 A:middle
updated with the ARAnchors

00:45:40.066 --> 00:45:41.906 A:middle
transform and you will receive

00:45:41.966 --> 00:45:44.246 A:middle
two callbacks when this happens.

00:45:44.806 --> 00:45:46.326 A:middle
One before we update its

00:45:46.326 --> 00:45:48.826 A:middle
transform, and another one after

00:45:48.826 --> 00:45:49.916 A:middle
we update the transform.

00:45:52.296 --> 00:45:54.186 A:middle
Whenever an ARAnchor is being

00:45:54.186 --> 00:45:56.846 A:middle
removed from the session, we

00:45:56.846 --> 00:45:57.936 A:middle
automatically remove the

00:45:57.936 --> 00:45:59.486 A:middle
corresponding SCNNode from the

00:45:59.486 --> 00:46:01.186 A:middle
scene graph and provide you with

00:46:01.186 --> 00:46:03.006 A:middle
the callback renderer didRemove

00:46:03.056 --> 00:46:03.946 A:middle
node for anchor.

00:46:04.446 --> 00:46:07.836 A:middle
So this is SceneKit with ARKit.

00:46:08.726 --> 00:46:10.866 A:middle
Next, let's have a look at

00:46:12.736 --> 00:46:13.006 A:middle
SpriteKit.

00:46:13.006 --> 00:46:14.536 A:middle
For SpriteKit we're providing an

00:46:14.536 --> 00:46:16.726 A:middle
ARSKview, which is a subclass of

00:46:16.726 --> 00:46:17.266 A:middle
SKView.

00:46:18.426 --> 00:46:20.316 A:middle
It contains an ARSession, which

00:46:20.316 --> 00:46:22.896 A:middle
it uses to update its rendering.

00:46:23.106 --> 00:46:24.596 A:middle
This includes drawing the camera

00:46:24.596 --> 00:46:27.196 A:middle
image in the background, and in

00:46:27.196 --> 00:46:29.476 A:middle
this case, mapping SKNodes to

00:46:29.476 --> 00:46:30.106 A:middle
ARAnchors.

00:46:30.636 --> 00:46:31.856 A:middle
So it provides a very similar

00:46:31.856 --> 00:46:33.176 A:middle
set of delegate methods to

00:46:33.176 --> 00:46:34.906 A:middle
SceneKit, which it can use.

00:46:36.066 --> 00:46:37.366 A:middle
One major difference is that

00:46:37.436 --> 00:46:38.996 A:middle
SpriteKit is a 2-D rendering

00:46:38.996 --> 00:46:39.356 A:middle
engine.

00:46:39.696 --> 00:46:41.026 A:middle
So that means we cannot simply

00:46:41.026 --> 00:46:43.036 A:middle
update a camera that is being

00:46:43.116 --> 00:46:43.506 A:middle
moved around.

00:46:44.286 --> 00:46:46.706 A:middle
So what ARKit does here is

00:46:46.996 --> 00:46:49.276 A:middle
project our ARAnchor's positions

00:46:49.956 --> 00:46:52.446 A:middle
into the SpriteKit view.

00:46:53.036 --> 00:46:54.616 A:middle
And then render the Sprites as

00:46:54.676 --> 00:46:56.746 A:middle
billboards at these locations,

00:46:56.746 --> 00:46:57.956 A:middle
at the projected locations.

00:46:58.706 --> 00:47:00.186 A:middle
This means that the Sprites will

00:47:00.186 --> 00:47:04.036 A:middle
always be facing the camera.

00:47:04.036 --> 00:47:05.506 A:middle
If you want to learn more about

00:47:05.506 --> 00:47:06.956 A:middle
this, there a session from the

00:47:06.956 --> 00:47:09.146 A:middle
SpriteKit team, "Going beyond

00:47:09.146 --> 00:47:11.286 A:middle
2-D in SpriteKit" which will

00:47:11.286 --> 00:47:13.316 A:middle
focus on how to integrate ARKit

00:47:13.446 --> 00:47:14.086 A:middle
with SpriteKit.

00:47:14.686 --> 00:47:19.396 A:middle
And next, let's have a look at

00:47:19.396 --> 00:47:20.876 A:middle
custom rendering with ARKit

00:47:21.106 --> 00:47:21.666 A:middle
using Metal.

00:47:23.136 --> 00:47:24.446 A:middle
There are four things that you

00:47:24.446 --> 00:47:26.126 A:middle
need to do in order to render

00:47:26.326 --> 00:47:27.456 A:middle
with ARKit.

00:47:28.566 --> 00:47:29.896 A:middle
The first is draw the camera

00:47:29.896 --> 00:47:30.916 A:middle
image in the background.

00:47:31.806 --> 00:47:34.306 A:middle
You usually create a texture for

00:47:34.306 --> 00:47:35.426 A:middle
this and draw it in a

00:47:35.426 --> 00:47:35.906 A:middle
background.

00:47:37.176 --> 00:47:39.056 A:middle
The next thing is to update our

00:47:39.056 --> 00:47:40.896 A:middle
virtual camera based on our

00:47:40.896 --> 00:47:41.396 A:middle
ARCamera.

00:47:42.306 --> 00:47:44.036 A:middle
This contains setting the view

00:47:44.036 --> 00:47:45.616 A:middle
matrix as well as the projection

00:47:45.616 --> 00:47:46.146 A:middle
matrix.

00:47:48.296 --> 00:47:50.246 A:middle
Third item is to update the

00:47:50.246 --> 00:47:52.786 A:middle
lighting situation or the light

00:47:52.786 --> 00:47:54.246 A:middle
in your scene based on our light

00:47:54.246 --> 00:47:54.706 A:middle
estimate.

00:47:55.986 --> 00:47:57.406 A:middle
And finally, if you have placed

00:47:57.536 --> 00:47:59.226 A:middle
geometry based on scene

00:47:59.226 --> 00:48:01.936 A:middle
understanding, then you would

00:48:01.936 --> 00:48:04.086 A:middle
use the ARAnchors in order to

00:48:04.276 --> 00:48:06.596 A:middle
set the transforms correctly.

00:48:07.816 --> 00:48:09.296 A:middle
All this information is

00:48:09.296 --> 00:48:10.616 A:middle
contained in an ARFrame.

00:48:11.146 --> 00:48:12.486 A:middle
And you have two ways of how to

00:48:12.486 --> 00:48:13.586 A:middle
access this ARFrame.

00:48:14.136 --> 00:48:17.576 A:middle
One is by polling the current

00:48:17.576 --> 00:48:19.026 A:middle
frame property on ARSession.

00:48:19.996 --> 00:48:21.396 A:middle
So, if you have your own render

00:48:21.396 --> 00:48:24.126 A:middle
loop you would use -- well, you

00:48:24.126 --> 00:48:25.646 A:middle
could use this method to access

00:48:25.646 --> 00:48:26.336 A:middle
the current frame.

00:48:27.036 --> 00:48:28.316 A:middle
And then you should also take

00:48:28.316 --> 00:48:30.726 A:middle
advantage of the timestamp

00:48:30.726 --> 00:48:32.796 A:middle
property on ARFrame in order to

00:48:32.796 --> 00:48:34.326 A:middle
avoid rendering the same frame

00:48:34.326 --> 00:48:35.056 A:middle
multiple times.

00:48:35.636 --> 00:48:38.456 A:middle
An alternative is to use our

00:48:38.456 --> 00:48:40.536 A:middle
Session Delegate, which provides

00:48:40.536 --> 00:48:42.606 A:middle
you with session didUpdate frame

00:48:42.676 --> 00:48:43.966 A:middle
every time a new frame has been

00:48:43.966 --> 00:48:44.566 A:middle
calculated.

00:48:45.106 --> 00:48:47.806 A:middle
In that case, you can just

00:48:47.806 --> 00:48:49.406 A:middle
simply take it and then update

00:48:49.406 --> 00:48:49.956 A:middle
your rendering.

00:48:51.006 --> 00:48:52.806 A:middle
By default, this is called on

00:48:52.806 --> 00:48:53.776 A:middle
the main [inaudible], but you

00:48:53.776 --> 00:48:54.876 A:middle
can also provide your own

00:48:54.876 --> 00:48:56.366 A:middle
dispatch queue, which we will

00:48:56.366 --> 00:48:58.826 A:middle
use to call this method.

00:48:58.826 --> 00:49:02.846 A:middle
So let's look into what Update

00:49:02.846 --> 00:49:04.856 A:middle
Rendering contains.

00:49:05.506 --> 00:49:08.616 A:middle
So the first thing is to draw

00:49:08.616 --> 00:49:09.466 A:middle
the camera image in the

00:49:09.466 --> 00:49:10.016 A:middle
background.

00:49:10.556 --> 00:49:12.046 A:middle
And you can access the captured

00:49:12.106 --> 00:49:13.766 A:middle
image property on an ARFrame,

00:49:14.166 --> 00:49:15.496 A:middle
which is the CV Pixel Buffer.

00:49:16.796 --> 00:49:18.546 A:middle
You can generate Metal texture

00:49:18.796 --> 00:49:20.126 A:middle
based on this Pixel Buffer and

00:49:20.456 --> 00:49:22.246 A:middle
then draw in a quad in the

00:49:22.246 --> 00:49:22.756 A:middle
background.

00:49:23.306 --> 00:49:26.766 A:middle
Note that this is a Pixel Buffer

00:49:26.766 --> 00:49:28.716 A:middle
that is vended to us through AV

00:49:28.716 --> 00:49:30.156 A:middle
Foundation, so you should not

00:49:30.186 --> 00:49:33.136 A:middle
hold on to too many of those

00:49:33.196 --> 00:49:34.756 A:middle
frames for too long, otherwise

00:49:34.756 --> 00:49:36.146 A:middle
you will stop receiving updates.

00:49:36.756 --> 00:49:40.606 A:middle
The next item is to update our

00:49:40.606 --> 00:49:42.266 A:middle
virtual camera based on our

00:49:42.266 --> 00:49:42.796 A:middle
ARCamera.

00:49:43.376 --> 00:49:45.126 A:middle
For this we have to determine

00:49:45.126 --> 00:49:46.726 A:middle
the view matrix as well as the

00:49:46.726 --> 00:49:47.726 A:middle
protection matrix.

00:49:49.066 --> 00:49:50.876 A:middle
The view matrix is simply the

00:49:50.876 --> 00:49:52.616 A:middle
inverse of our camera transform.

00:49:53.886 --> 00:49:55.266 A:middle
And in order to generate the

00:49:55.266 --> 00:49:56.536 A:middle
projection matrix, we are

00:49:56.536 --> 00:49:57.846 A:middle
offering you a convenience

00:49:57.846 --> 00:49:59.666 A:middle
method on the ARCamera, which

00:49:59.666 --> 00:50:00.726 A:middle
provides you with a projection

00:50:00.726 --> 00:50:01.196 A:middle
matrix.

00:50:03.656 --> 00:50:05.006 A:middle
The third step would be to

00:50:05.006 --> 00:50:05.966 A:middle
update the lighting.

00:50:06.546 --> 00:50:08.976 A:middle
So for this, simply access the

00:50:08.976 --> 00:50:10.816 A:middle
Light Estimate property and use

00:50:10.816 --> 00:50:12.446 A:middle
its ambient intensity in order

00:50:12.446 --> 00:50:15.426 A:middle
to update your lighting model.

00:50:16.076 --> 00:50:18.896 A:middle
And finally would be to iterate

00:50:19.156 --> 00:50:20.686 A:middle
over the anchors and its 3-D

00:50:20.686 --> 00:50:22.226 A:middle
locations in order to update the

00:50:22.226 --> 00:50:23.706 A:middle
transform of the geometries.

00:50:24.176 --> 00:50:25.356 A:middle
So any anchor that you have

00:50:25.526 --> 00:50:27.846 A:middle
added manually to the session or

00:50:27.926 --> 00:50:28.986 A:middle
any anchor that has been

00:50:28.986 --> 00:50:30.596 A:middle
detected or that has been added

00:50:30.766 --> 00:50:33.276 A:middle
to plane detection will be part

00:50:33.276 --> 00:50:34.396 A:middle
of these frame anchors.

00:50:37.156 --> 00:50:40.246 A:middle
Then are a few things to note

00:50:40.246 --> 00:50:41.636 A:middle
when rendering based on a camera

00:50:41.636 --> 00:50:42.026 A:middle
image.

00:50:42.976 --> 00:50:44.366 A:middle
We want to have a look at those.

00:50:45.486 --> 00:50:47.916 A:middle
So one thing is that the

00:50:47.916 --> 00:50:49.736 A:middle
captured image that is contained

00:50:49.736 --> 00:50:51.706 A:middle
in an ARFrame is always provided

00:50:51.706 --> 00:50:52.956 A:middle
in the same orientation.

00:50:53.776 --> 00:50:55.316 A:middle
However, if you rotate your

00:50:55.346 --> 00:50:57.566 A:middle
physical device, it might not

00:50:57.566 --> 00:50:59.756 A:middle
line up with your user interface

00:50:59.756 --> 00:51:00.376 A:middle
orientation.

00:51:00.676 --> 00:51:02.056 A:middle
And a transform needs to be

00:51:02.056 --> 00:51:04.946 A:middle
applied in order to render this

00:51:06.236 --> 00:51:06.556 A:middle
correctly.

00:51:06.556 --> 00:51:08.166 A:middle
Another thing is that the aspect

00:51:08.166 --> 00:51:09.726 A:middle
ratio of the camera image might

00:51:09.766 --> 00:51:11.496 A:middle
not necessarily line up with

00:51:11.526 --> 00:51:12.156 A:middle
your device.

00:51:13.106 --> 00:51:14.256 A:middle
And this means that we have to

00:51:14.256 --> 00:51:15.706 A:middle
take this into account in order

00:51:15.706 --> 00:51:18.356 A:middle
to properly render our camera

00:51:18.406 --> 00:51:19.476 A:middle
image in the screen.

00:51:20.066 --> 00:51:22.626 A:middle
To fix this or to make this

00:51:22.626 --> 00:51:24.206 A:middle
easier for you, we're providing

00:51:24.206 --> 00:51:25.126 A:middle
you with helper methods.

00:51:25.126 --> 00:51:28.926 A:middle
So there's one method on

00:51:28.926 --> 00:51:31.126 A:middle
ARFrame, which is the Display

00:51:31.126 --> 00:51:31.736 A:middle
Transform.

00:51:32.646 --> 00:51:34.286 A:middle
The Display Transform transforms

00:51:34.286 --> 00:51:35.636 A:middle
from frame space into view

00:51:35.636 --> 00:51:36.126 A:middle
space.

00:51:36.746 --> 00:51:38.426 A:middle
And you simply provide it with

00:51:38.596 --> 00:51:40.976 A:middle
your view port size as well as

00:51:40.976 --> 00:51:43.116 A:middle
your interface orientation, and

00:51:43.116 --> 00:51:44.096 A:middle
you will get an according

00:51:44.096 --> 00:51:44.656 A:middle
transform.

00:51:45.456 --> 00:51:46.776 A:middle
In our Metal example, we are

00:51:46.776 --> 00:51:47.966 A:middle
using the inverse of this

00:51:47.966 --> 00:51:49.946 A:middle
transform to adjust the texture

00:51:49.946 --> 00:51:51.016 A:middle
coordinates of our camera

00:51:51.016 --> 00:51:51.506 A:middle
background.

00:51:52.076 --> 00:51:55.276 A:middle
And to go with this is the

00:51:55.276 --> 00:51:58.036 A:middle
projection matrix variance that

00:51:58.036 --> 00:51:59.276 A:middle
takes into account the user

00:51:59.276 --> 00:52:00.836 A:middle
interface orientation as well as

00:52:00.836 --> 00:52:01.716 A:middle
the view port size.

00:52:02.226 --> 00:52:03.746 A:middle
So you pass those along with

00:52:03.746 --> 00:52:05.356 A:middle
clipping planes limits and you

00:52:05.356 --> 00:52:07.596 A:middle
can use this projection matrix

00:52:07.656 --> 00:52:10.586 A:middle
in order to correctly draw your

00:52:10.586 --> 00:52:12.266 A:middle
virtual content on top of the

00:52:12.266 --> 00:52:12.916 A:middle
camera image.

00:52:13.486 --> 00:52:17.746 A:middle
So this is ARKit.

00:52:18.676 --> 00:52:21.226 A:middle
To summarize, ARKit is a high

00:52:21.336 --> 00:52:23.916 A:middle
level API designed for creating

00:52:23.916 --> 00:52:25.536 A:middle
augmented reality applications

00:52:25.536 --> 00:52:26.346 A:middle
on iOS.

00:52:26.896 --> 00:52:29.056 A:middle
We provide you with World

00:52:29.056 --> 00:52:30.796 A:middle
Tracking, which gives you the

00:52:30.796 --> 00:52:32.666 A:middle
relative position of your device

00:52:33.156 --> 00:52:34.036 A:middle
to a starting point.

00:52:35.766 --> 00:52:37.376 A:middle
In order to place objects into

00:52:37.376 --> 00:52:38.916 A:middle
the real world, we provide you

00:52:38.916 --> 00:52:39.956 A:middle
with Scene Understanding.

00:52:41.306 --> 00:52:42.806 A:middle
Scene Understanding provides you

00:52:42.806 --> 00:52:44.556 A:middle
with Plane Detection as well as

00:52:44.556 --> 00:52:46.236 A:middle
the ability to hit-test the real

00:52:46.236 --> 00:52:47.616 A:middle
world in order to find 3-D

00:52:47.616 --> 00:52:49.226 A:middle
coordinates and place objects

00:52:49.226 --> 00:52:49.386 A:middle
there.

00:52:50.686 --> 00:52:51.886 A:middle
And in order to improve the

00:52:51.886 --> 00:52:53.886 A:middle
realism of our augmented

00:52:53.886 --> 00:52:55.026 A:middle
content, we're providing you

00:52:55.026 --> 00:52:56.786 A:middle
with a light estimate based on

00:52:56.786 --> 00:52:57.536 A:middle
the camera image.

00:52:58.096 --> 00:53:00.856 A:middle
We provide custom integration

00:53:00.856 --> 00:53:03.126 A:middle
into SceneKit and SpriteKit as

00:53:03.126 --> 00:53:05.136 A:middle
well as a template for Metal if

00:53:05.136 --> 00:53:06.016 A:middle
you want to get started

00:53:06.266 --> 00:53:08.406 A:middle
integrating ARKit into your own

00:53:08.406 --> 00:53:09.056 A:middle
rendering engine.

00:53:09.616 --> 00:53:13.016 A:middle
You can find more information on

00:53:13.016 --> 00:53:14.456 A:middle
the website of our talk here.

00:53:14.926 --> 00:53:17.346 A:middle
And there are a couple of

00:53:17.346 --> 00:53:18.976 A:middle
related sessions from the

00:53:18.976 --> 00:53:20.656 A:middle
SceneKit team who will also have

00:53:20.656 --> 00:53:21.986 A:middle
a look at how to use dynamic

00:53:21.986 --> 00:53:24.216 A:middle
shadows with ARKit and Sprite

00:53:24.216 --> 00:53:26.236 A:middle
and SceneKit as well as a

00:53:26.236 --> 00:53:27.676 A:middle
session from the SpriteKit team

00:53:27.886 --> 00:53:31.346 A:middle
who will focus on using ARKit

00:53:31.426 --> 00:53:32.586 A:middle
with SpriteKit.

00:53:33.186 --> 00:53:34.826 A:middle
So, we're really excited of

00:53:34.866 --> 00:53:35.946 A:middle
bringing this out into your

00:53:35.946 --> 00:53:36.306 A:middle
hands.

00:53:36.596 --> 00:53:38.836 A:middle
And we are looking forward to

00:53:38.836 --> 00:53:40.186 A:middle
see the first applications that

00:53:40.186 --> 00:53:41.036 A:middle
you're going to build with it.

00:53:41.616 --> 00:53:42.826 A:middle
So please go ahead and download

00:53:42.976 --> 00:53:44.126 A:middle
the sample code, the sample

00:53:44.126 --> 00:53:45.526 A:middle
application from our website.

00:53:45.906 --> 00:53:48.006 A:middle
Put your own content into it and

00:53:48.126 --> 00:53:49.296 A:middle
show it around.

00:53:49.596 --> 00:53:51.336 A:middle
And be happy.

00:53:51.836 --> 00:53:53.096 A:middle
Thank you.

00:53:54.516 --> 00:54:00.300 A:middle
[ Applause ]