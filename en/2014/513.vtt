WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:00.506 --> 00:00:09.516 A:middle
[ Silence ]

00:00:10.016 --> 00:00:16.000 A:middle
[ Applause ]

00:00:16.366 --> 00:00:17.086 A:middle
&gt;&gt; Hi everyone.

00:00:17.086 --> 00:00:18.016 A:middle
Thanks for coming today.

00:00:18.456 --> 00:00:19.586 A:middle
My name is David Eldred.

00:00:19.586 --> 00:00:22.056 A:middle
This is session 513
and we're going to talk

00:00:22.056 --> 00:00:25.156 A:middle
about Video Encoders
and Decoders today.

00:00:25.866 --> 00:00:26.296 A:middle
All right.

00:00:26.716 --> 00:00:28.916 A:middle
We want to make sure that
no matter what you're doing

00:00:28.916 --> 00:00:31.216 A:middle
with the video in your
application, you have access

00:00:31.596 --> 00:00:33.416 A:middle
to hardware encoders
and decoders.

00:00:34.256 --> 00:00:36.136 A:middle
This will help users.

00:00:36.136 --> 00:00:38.596 A:middle
This will improve user
experience in a number of ways.

00:00:39.426 --> 00:00:41.196 A:middle
Obviously, they'll
get better performance

00:00:41.196 --> 00:00:46.176 A:middle
and they will be far more
efficient, but most importantly,

00:00:46.176 --> 00:00:47.616 A:middle
this will extend battery life.

00:00:48.236 --> 00:00:53.456 A:middle
Users will really appreciate it
if their OS X, their portables

00:00:53.736 --> 00:00:56.616 A:middle
as well as their iOS devices
have improved battery life.

00:00:57.356 --> 00:01:00.486 A:middle
And as an added bonus, people
with portables will love it


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:57.356 --> 00:01:00.486 A:middle
And as an added bonus, people
with portables will love it

00:01:00.486 --> 00:01:02.096 A:middle
if their fans don't kick

00:01:02.096 --> 00:01:03.916 A:middle
in every time they're
doing video processing.

00:01:05.256 --> 00:01:09.366 A:middle
So today, we're going
to break this --

00:01:09.366 --> 00:01:11.396 A:middle
first, we're going to break this
down into a few case studies.

00:01:11.396 --> 00:01:13.806 A:middle
We're going to look at
some common user scenarios.

00:01:14.546 --> 00:01:16.696 A:middle
The first scenario we're going
to talk about is the case

00:01:16.696 --> 00:01:19.706 A:middle
where you have a stream of H.264
data coming in over the network

00:01:20.056 --> 00:01:21.406 A:middle
and you want to display
that inside

00:01:21.406 --> 00:01:22.766 A:middle
of a layer in your application.

00:01:23.356 --> 00:01:25.556 A:middle
The next one we're going
to talk about is the case

00:01:25.556 --> 00:01:28.746 A:middle
where you have a stream of H.264
data coming in over the network,

00:01:29.016 --> 00:01:30.186 A:middle
but you don't just
want to display

00:01:30.186 --> 00:01:33.026 A:middle
that in your application, but
you actually want to get access

00:01:33.026 --> 00:01:34.736 A:middle
to those decoded
CV pixel buffers.

00:01:36.646 --> 00:01:39.686 A:middle
Next, we'll be talking
about when the case

00:01:39.686 --> 00:01:42.596 A:middle
where you have a sequence of
images coming in from the camera

00:01:42.596 --> 00:01:44.086 A:middle
or someplace else and you'd

00:01:44.086 --> 00:01:46.316 A:middle
like to compress those
directly into a movie file.

00:01:48.086 --> 00:01:51.826 A:middle
And accompanying that, there's
the case where you have a stream

00:01:51.826 --> 00:01:54.326 A:middle
of images coming in from
the camera or someplace else

00:01:54.906 --> 00:01:57.186 A:middle
and you'd like to compress
those but get direct access

00:01:57.186 --> 00:01:58.726 A:middle
to those compressed
sample buffers

00:01:59.066 --> 00:02:00.616 A:middle
so that you can send
them out over the network


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:01:59.066 --> 00:02:00.616 A:middle
so that you can send
them out over the network

00:02:00.996 --> 00:02:02.356 A:middle
or do whatever you
like with them.

00:02:03.336 --> 00:02:05.906 A:middle
And then finally, we're
going to give you an intro

00:02:05.906 --> 00:02:07.486 A:middle
to our new multi-pass APIs

00:02:07.486 --> 00:02:11.136 A:middle
that we're introducing
in iOS8 and Yosemite.

00:02:11.446 --> 00:02:15.836 A:middle
All right, let's
do a quick overview

00:02:15.836 --> 00:02:17.166 A:middle
of our media interface stack.

00:02:17.406 --> 00:02:19.976 A:middle
You've seen stuff like
this earlier this week,

00:02:20.026 --> 00:02:23.796 A:middle
but we'll do it once more, and
there's a little focus on video

00:02:23.796 --> 00:02:27.296 A:middle
in my view of this, because
we're talking about video.

00:02:28.116 --> 00:02:30.496 A:middle
So at the top we have AVKit.

00:02:30.496 --> 00:02:35.196 A:middle
AVKit provides very easy-to-use
high level view level interfaces

00:02:35.196 --> 00:02:36.056 A:middle
for dealing with media.

00:02:37.496 --> 00:02:39.316 A:middle
Below that, we have
AVFoundation.

00:02:39.686 --> 00:02:42.226 A:middle
AVFoundation provides an
easy-to-use objective C

00:02:42.226 --> 00:02:45.026 A:middle
interface for a wide
range of media tasks.

00:02:46.186 --> 00:02:48.726 A:middle
And below that, we
have Video Toolbox.

00:02:49.076 --> 00:02:51.796 A:middle
Video Toolbox has been
there on OS X for a while,

00:02:51.796 --> 00:02:55.006 A:middle
but now it's finally
populated with headers on iOS.

00:02:55.676 --> 00:02:57.996 A:middle
This provides direct
access to encoders

00:02:57.996 --> 00:02:58.646 A:middle
and decoders [applause].


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:01.306 --> 00:03:05.926 A:middle
And below that we have
Core Media Core Video.

00:03:06.246 --> 00:03:09.226 A:middle
These frameworks provide
many of the necessary types

00:03:09.226 --> 00:03:10.246 A:middle
that you'll see throughout
the --

00:03:10.346 --> 00:03:14.236 A:middle
in the interfaces in
the rest of the stack.

00:03:15.076 --> 00:03:18.326 A:middle
So today, we're going
to focus on AVFoundation

00:03:18.326 --> 00:03:19.456 A:middle
and the Video Toolbox.

00:03:19.896 --> 00:03:22.596 A:middle
In AVFoundation, we'll be
looking at some interfaces

00:03:22.596 --> 00:03:25.616 A:middle
that allow you to decode
video directly into a layer

00:03:25.616 --> 00:03:30.676 A:middle
in your application or compress
frames directly into a file.

00:03:30.676 --> 00:03:34.156 A:middle
And the Video Toolbox we'll
be looking at these interfaces

00:03:34.156 --> 00:03:37.216 A:middle
to give you more direct access
to encoders and decoders

00:03:37.756 --> 00:03:40.186 A:middle
so you can decompress
directly to CV pixel buffers

00:03:40.186 --> 00:03:42.836 A:middle
or compress directly
to CM sample buffers.

00:03:44.376 --> 00:03:48.676 A:middle
So a quick note on
using these frameworks.

00:03:48.676 --> 00:03:50.896 A:middle
A lot of people think they have
to dive down to the lowest level

00:03:50.896 --> 00:03:52.286 A:middle
and use the Video
Toolbox in order

00:03:52.286 --> 00:03:56.026 A:middle
to get hardware acceleration,
but that's really not true.

00:03:57.366 --> 00:03:59.806 A:middle
On iOS, AVKit, AVFoundation

00:03:59.806 --> 00:04:02.666 A:middle
and Video Toolbox will
all use hardware codec.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:59.806 --> 00:04:02.666 A:middle
and Video Toolbox will
all use hardware codec.

00:04:04.046 --> 00:04:07.236 A:middle
On OS X, AVKit and AVFoundation
will use hardware codec

00:04:07.236 --> 00:04:09.596 A:middle
when they're available on
the system and when you --

00:04:09.756 --> 00:04:10.876 A:middle
when it's appropriate.

00:04:11.706 --> 00:04:14.146 A:middle
And Video Toolbox will
use hardware codec

00:04:14.296 --> 00:04:17.976 A:middle
when it's available on system
and when you request it.

00:04:19.026 --> 00:04:19.375 A:middle
All right.

00:04:20.646 --> 00:04:23.056 A:middle
So before we dive into
more stuff, we're going --

00:04:23.206 --> 00:04:25.866 A:middle
I'm going to do a quick look
at this cast of characters.

00:04:25.866 --> 00:04:27.126 A:middle
These are some of
the common types

00:04:27.126 --> 00:04:29.486 A:middle
that you'll encounter
in these interfaces.

00:04:31.606 --> 00:04:33.436 A:middle
First off, there's
CVPixelBuffer.

00:04:33.816 --> 00:04:39.476 A:middle
CVPixelBuffer contains a block
of image data and wrapping

00:04:39.476 --> 00:04:42.906 A:middle
that buffer of data is the
CVPixelBuffer wrapping.

00:04:43.286 --> 00:04:45.656 A:middle
And the CVPixelBuffer
wrapping tells you how

00:04:45.656 --> 00:04:46.716 A:middle
to access that data.

00:04:46.816 --> 00:04:49.506 A:middle
It's got the dimensions,
the width and the height.

00:04:49.506 --> 00:04:52.166 A:middle
It's got the pixel format,
everything you need in order

00:04:52.166 --> 00:04:55.916 A:middle
to correctly interpret
the pixel data.

00:04:56.636 --> 00:04:58.436 A:middle
Next, we've got the
CVPixelBufferPool.

00:04:58.436 --> 00:05:00.306 A:middle
The CVPixelBufferPool allows you


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:58.436 --> 00:05:00.306 A:middle
The CVPixelBufferPool allows you

00:05:00.306 --> 00:05:03.136 A:middle
to efficiently recycle
CVPixelBuffer back ends.

00:05:03.826 --> 00:05:07.496 A:middle
Those data buffers can be very
expensive to constantly allocate

00:05:07.496 --> 00:05:08.266 A:middle
and de-allocate,

00:05:08.356 --> 00:05:11.996 A:middle
so PixelBufferPool allows
you to recycle them.

00:05:12.766 --> 00:05:15.726 A:middle
The way a PixelBufferPool works
is you allocate a CVPixelBuffer

00:05:15.726 --> 00:05:18.946 A:middle
from the pool and the
CVPixelBuffer is a ref

00:05:18.946 --> 00:05:19.656 A:middle
counted object.

00:05:19.976 --> 00:05:22.116 A:middle
When everyone releases
that CVPixelBuffer,

00:05:22.436 --> 00:05:25.016 A:middle
the data back end goes back
into the pool and it's available

00:05:25.016 --> 00:05:30.266 A:middle
for reuse next time you allocate
a PixelBuffer from that pool.

00:05:31.266 --> 00:05:34.336 A:middle
Next thing is
pixelBufferAttributes.

00:05:34.456 --> 00:05:36.636 A:middle
This isn't actually a type
like the rest of the things

00:05:36.636 --> 00:05:40.576 A:middle
in this list, but it's a
common object you'll see listed

00:05:40.576 --> 00:05:41.446 A:middle
in our interfaces.

00:05:41.446 --> 00:05:42.526 A:middle
You'll see requests

00:05:42.526 --> 00:05:44.266 A:middle
for pixelBufferAttributes
dictionaries.

00:05:44.996 --> 00:05:47.336 A:middle
pixelBufferAttributes are a
CF dictionary containing a set

00:05:47.336 --> 00:05:50.106 A:middle
of requirements for
either a CVPixelBuffer

00:05:50.106 --> 00:05:51.136 A:middle
or a PixelBufferPool.

00:05:52.646 --> 00:05:56.096 A:middle
This includes the -- this
can include several things.

00:05:56.096 --> 00:05:57.206 A:middle
This can include dimensions

00:05:57.206 --> 00:05:58.906 A:middle
that you're requesting,
the width and height.

00:05:59.436 --> 00:06:02.076 A:middle
This can include a specific
pixel format or a list


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:05:59.436 --> 00:06:02.076 A:middle
This can include a specific
pixel format or a list

00:06:02.076 --> 00:06:04.886 A:middle
of pixel formats that
you'd like to receive.

00:06:05.926 --> 00:06:09.586 A:middle
And you can include specific
compatibility flags requesting

00:06:09.586 --> 00:06:12.636 A:middle
compatibility with specific
display technologies

00:06:12.636 --> 00:06:16.336 A:middle
such as OpenGL, OpenGL
ES or Core Animation.

00:06:19.316 --> 00:06:19.696 A:middle
All right.

00:06:19.696 --> 00:06:20.996 A:middle
Next, we've got CMTime.

00:06:21.626 --> 00:06:24.716 A:middle
CMTime is the basic
description of time

00:06:24.716 --> 00:06:26.006 A:middle
that you'll see in
your interfaces.

00:06:26.506 --> 00:06:29.716 A:middle
This is a rational
representation of a time value.

00:06:29.716 --> 00:06:33.656 A:middle
It contains a 64 byte time
value that's the numerator,

00:06:34.216 --> 00:06:36.676 A:middle
and a 32 byte time scale,
which is the denominator.

00:06:37.326 --> 00:06:39.096 A:middle
We use the sort of
rational representation

00:06:39.096 --> 00:06:41.966 A:middle
so that these time values can
be passed throughout your media

00:06:41.966 --> 00:06:46.816 A:middle
pipeline and you won't have to
do any sort of rounding on them.

00:06:47.436 --> 00:06:47.886 A:middle
All right.

00:06:48.406 --> 00:06:50.446 A:middle
Next, CMVideoFormatDescription.

00:06:50.746 --> 00:06:52.516 A:middle
You'll see this in a
bunch of our interfaces,

00:06:52.576 --> 00:06:55.626 A:middle
and a CMVideoFormatDescription
is basically a description

00:06:55.626 --> 00:06:56.276 A:middle
of video data.

00:06:56.866 --> 00:06:58.346 A:middle
This contains the dimensions.

00:06:58.786 --> 00:07:03.446 A:middle
This includes the pixel format
and there's a set of extensions


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:58.786 --> 00:07:03.446 A:middle
This includes the pixel format
and there's a set of extensions

00:07:03.446 --> 00:07:07.546 A:middle
that go along with the
CMVideoFormatDescription.

00:07:07.936 --> 00:07:11.186 A:middle
These extensions can
include information to --

00:07:11.866 --> 00:07:15.696 A:middle
information used for
displaying that video data just

00:07:15.696 --> 00:07:16.896 A:middle
as pixel aspect ratio,

00:07:17.356 --> 00:07:19.546 A:middle
and it can include
color space information.

00:07:19.866 --> 00:07:24.766 A:middle
And in the case of H.264 data,
the parameter sets are included

00:07:24.766 --> 00:07:26.746 A:middle
in these extensions
and we'll talk

00:07:26.746 --> 00:07:29.536 A:middle
about that more a
little bit later.

00:07:30.536 --> 00:07:32.116 A:middle
All right, next is
CMBlockBuffer.

00:07:32.626 --> 00:07:37.076 A:middle
CMBlockBuffer is the basic way
that we wrap arbitrary blocks

00:07:37.076 --> 00:07:38.096 A:middle
of data in core media.

00:07:39.096 --> 00:07:41.506 A:middle
In general, when you
encounter video data,

00:07:41.646 --> 00:07:43.586 A:middle
compressed video
data in our pipeline,

00:07:43.586 --> 00:07:45.346 A:middle
it will be wrapped
in a CMBlockBuffer.

00:07:45.916 --> 00:07:50.286 A:middle
All right, now we
have CMSampleBuffer.

00:07:50.596 --> 00:07:53.776 A:middle
You'll see CMSampleBuffer show
up a lot in our interfaces.

00:07:54.266 --> 00:07:55.726 A:middle
These wrap samples of data.

00:07:56.056 --> 00:07:58.356 A:middle
In the case of video,

00:07:58.446 --> 00:08:02.006 A:middle
CMSampleBuffer's can wrap
either compressed video frames


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:07:58.446 --> 00:08:02.006 A:middle
CMSampleBuffer's can wrap
either compressed video frames

00:08:02.006 --> 00:08:05.536 A:middle
or uncompressed video frames
and CMSampleBuffer's build

00:08:05.536 --> 00:08:07.366 A:middle
on several of the types that
we've talked about here.

00:08:08.226 --> 00:08:09.796 A:middle
They contain a CMTime.

00:08:09.916 --> 00:08:12.056 A:middle
This is the presentation
time for the sample.

00:08:12.646 --> 00:08:15.706 A:middle
They contain a
CMVideoFormatDescription.

00:08:15.816 --> 00:08:18.446 A:middle
This describes the data
inside of the CMSampleBuffer.

00:08:19.826 --> 00:08:21.746 A:middle
And finally, in the case
of compressed video,

00:08:21.746 --> 00:08:23.236 A:middle
they contain a CMBlockBuffer

00:08:23.236 --> 00:08:25.586 A:middle
and the CMBlockBuffer has
the compressed video data.

00:08:26.446 --> 00:08:29.346 A:middle
And if it's an uncompressed
image in the CMSampleBuffer,

00:08:29.846 --> 00:08:32.426 A:middle
the uncompressed image
may be in a CVPixelBuffer

00:08:32.816 --> 00:08:34.385 A:middle
or it may be in a CMBlockBuffer.

00:08:34.956 --> 00:08:37.056 A:middle
All right.

00:08:37.056 --> 00:08:38.346 A:middle
Next, we've got CMClock.

00:08:39.576 --> 00:08:43.385 A:middle
CMClock is the core media
wrapper around a source of time

00:08:43.936 --> 00:08:46.636 A:middle
and like the clock on a
wall, there's no clocks

00:08:46.636 --> 00:08:48.426 A:middle
on the wall here, but
like a clock on the wall,

00:08:48.896 --> 00:08:52.226 A:middle
time is always moving and it's
always increasing on a CMClock.

00:08:53.506 --> 00:08:55.246 A:middle
One of the common clocks

00:08:55.246 --> 00:08:57.556 A:middle
that you'll see used
is the HostTimeClock.

00:08:58.026 --> 00:09:03.546 A:middle
So CMClockgetHostTimeClock will
return a clock which is based


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:08:58.026 --> 00:09:03.546 A:middle
So CMClockgetHostTimeClock will
return a clock which is based

00:09:03.696 --> 00:09:06.016 A:middle
on mach absolute time.

00:09:08.096 --> 00:09:10.516 A:middle
So CMClocks are hard to control.

00:09:10.516 --> 00:09:12.156 A:middle
You can't really control them.

00:09:12.466 --> 00:09:14.526 A:middle
As I mentioned, they're
always moving

00:09:14.896 --> 00:09:16.306 A:middle
and always at a constant rate.

00:09:16.896 --> 00:09:20.606 A:middle
So CMTimebase provides a more
controlled view onto a CMClock.

00:09:22.156 --> 00:09:25.606 A:middle
So if we go ahead and
create a CMClock based --

00:09:25.826 --> 00:09:27.956 A:middle
CMTimebase based on
the host time clock,

00:09:28.346 --> 00:09:31.196 A:middle
we could then set the time to
time zero on our time base.

00:09:32.966 --> 00:09:37.606 A:middle
Now, time zero on our time
base maps to the current time

00:09:37.656 --> 00:09:42.006 A:middle
on the CMClock, and you
can control the rate

00:09:42.096 --> 00:09:43.246 A:middle
of your time base.

00:09:43.346 --> 00:09:46.206 A:middle
So if you were then to go and
set your time base rate to one,

00:09:46.376 --> 00:09:48.866 A:middle
time will begin advancing on
your time base at the same rate

00:09:48.916 --> 00:09:50.596 A:middle
at which the clock is advancing.

00:09:51.036 --> 00:09:54.916 A:middle
And CMTimebases can be
created based on CMClocks

00:09:54.916 --> 00:09:57.216 A:middle
or they can be created
based on other CMTimebases.

00:09:58.836 --> 00:09:59.736 A:middle
All right.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:00.576 --> 00:10:02.376 A:middle
Let's hop into our
first use case.

00:10:02.936 --> 00:10:05.156 A:middle
This is the case where you
have a stream of data coming

00:10:05.156 --> 00:10:08.746 A:middle
in over the network and
since its video data coming

00:10:08.746 --> 00:10:10.986 A:middle
over the network, we can
safely assume it's a cat video,

00:10:12.246 --> 00:10:16.916 A:middle
and so we've got
AVSampleBufferDisplayLayer,

00:10:16.916 --> 00:10:21.086 A:middle
which takes -- which can take
a sequence of compressed frames

00:10:21.476 --> 00:10:23.566 A:middle
and display it in a layer
inside of your application.

00:10:24.666 --> 00:10:26.846 A:middle
AVSampleBufferDisplayLayer
shipped

00:10:27.016 --> 00:10:29.906 A:middle
in Mavericks, and
it's new in iOS8.

00:10:31.026 --> 00:10:33.806 A:middle
So let's take a look inside
AVSampleBufferDisplayLayer.

00:10:34.846 --> 00:10:39.256 A:middle
As I mentioned, it takes a
sequence of compressed frames

00:10:39.256 --> 00:10:41.706 A:middle
as input and these need
to be in CMSampleBuffers.

00:10:42.796 --> 00:10:44.776 A:middle
Internally, it's going
to have a video decoder

00:10:45.656 --> 00:10:49.006 A:middle
and it will decode the
frames into CVPixelBuffers

00:10:49.006 --> 00:10:51.806 A:middle
and it will have a sequence
of CVPixelBuffers queued up

00:10:51.876 --> 00:10:53.996 A:middle
and ready to display
in your application

00:10:53.996 --> 00:10:54.976 A:middle
at the appropriate time.

00:10:55.546 --> 00:11:00.966 A:middle
But, I mentioned we were getting
our data off of the network.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:55.546 --> 00:11:00.966 A:middle
But, I mentioned we were getting
our data off of the network.

00:11:01.186 --> 00:11:03.646 A:middle
A lot of times, when
you're getting a stream

00:11:03.646 --> 00:11:06.176 A:middle
of compressed video off the
network, it's going to be

00:11:06.176 --> 00:11:07.746 A:middle
in the form of an
elementary stream.

00:11:08.886 --> 00:11:10.686 A:middle
And I mentioned that CMSample --

00:11:10.796 --> 00:11:14.566 A:middle
AVSampleBufferDisplayLayer wants
CMSampleBuffers as its input.

00:11:15.836 --> 00:11:18.256 A:middle
Well, there's a little bit of
work that has to happen here

00:11:18.256 --> 00:11:20.036 A:middle
to convert your elementary
screen data

00:11:20.036 --> 00:11:21.276 A:middle
into CMSampleBuffers.

00:11:21.276 --> 00:11:23.766 A:middle
So let's talk about this.

00:11:23.766 --> 00:11:28.176 A:middle
H.264 defines a couple
of ways of packaging --

00:11:28.176 --> 00:11:33.226 A:middle
the H.264 spec defines a couple
of ways of packaging H.264 data.

00:11:33.226 --> 00:11:34.386 A:middle
The first one I'm going to refer

00:11:34.386 --> 00:11:35.996 A:middle
to is Elementary
Stream packaging.

00:11:36.506 --> 00:11:38.986 A:middle
This is used in elementary
streams, transport streams,

00:11:38.986 --> 00:11:41.966 A:middle
a lot of things with
streams in their name.

00:11:41.966 --> 00:11:43.596 A:middle
Next, is MPEG-4 packaging.

00:11:44.056 --> 00:11:47.596 A:middle
This is used in movie
files and MP4 files.

00:11:48.786 --> 00:11:52.516 A:middle
And in our interfaces that deal
with CMSampleBuffers, core media

00:11:52.516 --> 00:11:56.376 A:middle
and AVFoundation exclusively
want the data packaged

00:11:56.616 --> 00:11:58.656 A:middle
in MPEG-4 packaging.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:00.006 --> 00:12:03.496 A:middle
So let's look closer
at an H.264 stream.

00:12:04.066 --> 00:12:08.336 A:middle
An H.264 stream consists
of a sequence of blocks

00:12:08.336 --> 00:12:10.356 A:middle
of data packaged in NAL Units.

00:12:10.836 --> 00:12:13.546 A:middle
These NAL Units can
contain several --

00:12:13.996 --> 00:12:15.566 A:middle
so this is the network
abstraction layer,

00:12:16.126 --> 00:12:18.416 A:middle
and these are Network
Abstraction Layer units.

00:12:19.266 --> 00:12:20.956 A:middle
These can contain a
few different things.

00:12:21.436 --> 00:12:23.446 A:middle
First off, they can
contain sample data.

00:12:25.846 --> 00:12:30.976 A:middle
So you could have a single
frame of video could be packaged

00:12:30.976 --> 00:12:36.016 A:middle
in one NAL Unit or a frame
of video could be spread

00:12:36.016 --> 00:12:37.386 A:middle
across several NAL Units.

00:12:38.286 --> 00:12:43.116 A:middle
The other thing that NAL Units
can contain is parameter sets.

00:12:43.446 --> 00:12:45.686 A:middle
The parameter sets, the
Sequence Parameter Set

00:12:45.686 --> 00:12:49.416 A:middle
and Picture Parameter
Set are chunks of data

00:12:49.416 --> 00:12:51.856 A:middle
of which the decoder holds
on to and these apply

00:12:51.856 --> 00:12:55.916 A:middle
to all subsequent frames; well,

00:12:55.916 --> 00:12:57.316 A:middle
until a new parameter
set arrives.

00:12:59.226 --> 00:13:01.536 A:middle
So let's look at
Elementary Stream packaging.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:59.226 --> 00:13:01.536 A:middle
So let's look at
Elementary Stream packaging.

00:13:01.976 --> 00:13:04.786 A:middle
Elementary Stream packaging,
in Elementary Stream packaging,

00:13:05.126 --> 00:13:06.366 A:middle
the parameter sets are included

00:13:06.366 --> 00:13:08.206 A:middle
in NAL Units right
inside the stream.

00:13:08.396 --> 00:13:10.296 A:middle
This is great if you're
doing sequential playback.

00:13:10.866 --> 00:13:13.196 A:middle
You read in your parameter
sets and they apply

00:13:13.196 --> 00:13:16.156 A:middle
to all subsequent frames until
a new frame or sets arrive.

00:13:17.556 --> 00:13:21.036 A:middle
MPEG-4 packaging has the NAL
Units pulled out and it's

00:13:21.036 --> 00:13:24.616 A:middle
in a separate block of data,
and this block of data is stored

00:13:24.616 --> 00:13:26.236 A:middle
in the CMVideoFormatDescription.

00:13:26.786 --> 00:13:27.586 A:middle
So as I mentioned,

00:13:27.666 --> 00:13:32.346 A:middle
each CMSampleBuffer references
this CMVideoFormatDescription.

00:13:32.476 --> 00:13:35.666 A:middle
That means each frame
of data has access

00:13:35.756 --> 00:13:37.146 A:middle
to the parameter sets.

00:13:38.106 --> 00:13:40.826 A:middle
This sort of packaging
is superior

00:13:40.826 --> 00:13:42.246 A:middle
for random access in a file.

00:13:42.306 --> 00:13:44.836 A:middle
It allows you to jump anywhere

00:13:44.836 --> 00:13:47.106 A:middle
and begin decoding
at an I frame.

00:13:49.066 --> 00:13:50.356 A:middle
So what do you have to do

00:13:50.356 --> 00:13:52.076 A:middle
if you have an Elementary
Stream coming in?

00:13:52.986 --> 00:13:55.046 A:middle
Well, we've got --
you've got a couple --

00:13:55.276 --> 00:13:58.276 A:middle
you've got your parameter sets
and NAL Units and you're going

00:13:58.276 --> 00:14:01.276 A:middle
to have to package those in
a CMVideoFormatDescription.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:13:58.276 --> 00:14:01.276 A:middle
to have to package those in
a CMVideoFormatDescription.

00:14:02.086 --> 00:14:05.096 A:middle
Well, we provide a handy
utility that does this for you;

00:14:05.246 --> 00:14:07.976 A:middle
CMVideoFormatDescription
CreatefromH264ParameterSets.

00:14:08.516 --> 00:14:12.956 A:middle
[ Applause ]

00:14:13.456 --> 00:14:17.396 A:middle
All right, so the next
difference that we're going

00:14:17.396 --> 00:14:19.536 A:middle
to talk about between
an Elementary Stream

00:14:19.536 --> 00:14:23.306 A:middle
and MPEG-4 packaging
is in NAL Unit headers.

00:14:24.086 --> 00:14:25.286 A:middle
So each NAL Unit

00:14:25.286 --> 00:14:27.736 A:middle
in an Elementary
Stream will have a three

00:14:27.736 --> 00:14:33.166 A:middle
or four bytes start code as the
header and in MPEG-4 packaging,

00:14:33.256 --> 00:14:34.786 A:middle
we have a length code.

00:14:35.456 --> 00:14:37.616 A:middle
So for each NAL Unit in your
stream, they're going --

00:14:38.156 --> 00:14:41.026 A:middle
you have to strip
off that start code

00:14:41.026 --> 00:14:42.426 A:middle
and replace it with
a length code.

00:14:42.766 --> 00:14:44.066 A:middle
That's the length
of the NAL Unit.

00:14:45.256 --> 00:14:46.126 A:middle
It's not that hard.

00:14:48.096 --> 00:14:50.226 A:middle
So let's talk about
building a CMSampleBuffer

00:14:50.876 --> 00:14:52.626 A:middle
from your Elementary Stream.

00:14:52.916 --> 00:14:55.096 A:middle
First thing you're going to
have to do is take your NAL Unit

00:14:55.476 --> 00:15:00.496 A:middle
or NAL Units and replace the
start code with a length code.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:14:55.476 --> 00:15:00.496 A:middle
or NAL Units and replace the
start code with a length code.

00:15:02.436 --> 00:15:05.986 A:middle
And you'll wrap that NAL
Unit in a CMBlockBuffer.

00:15:06.646 --> 00:15:09.776 A:middle
One note here, for simplicity,
I'm showing a single NAL Unit

00:15:09.776 --> 00:15:12.326 A:middle
but if you have a frame that
consists of several NAL Units,

00:15:12.716 --> 00:15:14.506 A:middle
you need to include
all of the NAL Units

00:15:14.506 --> 00:15:15.746 A:middle
in your CMSampleBuffer.

00:15:16.876 --> 00:15:18.486 A:middle
So you have a CMBlockBuffer.

00:15:18.786 --> 00:15:20.306 A:middle
You have your
CMVideoFormatDescription

00:15:20.306 --> 00:15:21.556 A:middle
that you created
from your initial --

00:15:21.626 --> 00:15:25.286 A:middle
from your parameter sets,
and throw in a CMTime value,

00:15:25.286 --> 00:15:27.016 A:middle
that's the presentation
time of your frame,

00:15:27.646 --> 00:15:29.876 A:middle
and you have everything
you need in order

00:15:29.876 --> 00:15:33.696 A:middle
to create CMSampleBuffer
using CMSampleBufferCreate.

00:15:34.536 --> 00:15:38.256 A:middle
All right, let's talk

00:15:38.256 --> 00:15:40.336 A:middle
about AVSampleBufferDisplayLayer
in time.

00:15:41.086 --> 00:15:41.936 A:middle
So as we saw,

00:15:41.936 --> 00:15:44.826 A:middle
all CMSampleBuffers have an
associated presentation time

00:15:44.826 --> 00:15:48.176 A:middle
stamp, and our video
decoder's going to be spitting

00:15:48.176 --> 00:15:52.226 A:middle
out CVPixelBuffers each with
an associated presentation

00:15:52.226 --> 00:15:52.796 A:middle
time stamp.

00:15:53.646 --> 00:15:55.556 A:middle
Well, how does it know when
to display these frames?

00:15:56.516 --> 00:15:59.286 A:middle
By default, it will be driven
off of the host time clock.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:00.466 --> 00:16:02.426 A:middle
Well, that can be a
little bit hard to manager.

00:16:02.426 --> 00:16:05.266 A:middle
The host time clock isn't
really under your control.

00:16:06.126 --> 00:16:08.796 A:middle
So we allow you to
replace the host time clock

00:16:08.796 --> 00:16:10.936 A:middle
with your own time base.

00:16:11.816 --> 00:16:14.826 A:middle
To do this you set the time --
you know in the example here,

00:16:15.026 --> 00:16:18.566 A:middle
we're creating a time base
based on the host time clock

00:16:18.986 --> 00:16:21.096 A:middle
and we're setting that
as the control time base

00:16:21.096 --> 00:16:22.716 A:middle
on our
AVSampleBufferDisplayLayer.

00:16:24.056 --> 00:16:26.016 A:middle
Here, we're setting the
time base time to five,

00:16:26.056 --> 00:16:29.146 A:middle
which would mean our frame
whose time stamp is five will be

00:16:29.146 --> 00:16:31.916 A:middle
displayed in our layer,
and then we go ahead

00:16:31.916 --> 00:16:33.676 A:middle
and set the time
base rate to one,

00:16:34.046 --> 00:16:36.266 A:middle
and now our time base begins
moving at the same rate

00:16:36.266 --> 00:16:38.936 A:middle
as the host time clock,

00:16:39.476 --> 00:16:42.186 A:middle
and subsequent frames
will be displayed

00:16:42.186 --> 00:16:44.616 A:middle
at the appropriate time.

00:16:45.636 --> 00:16:46.466 A:middle
All right.

00:16:47.706 --> 00:16:50.956 A:middle
So providing the
CMSampleBuffers,

00:16:50.956 --> 00:16:52.426 A:middle
the SampleBufferDisplayLayer,

00:16:52.626 --> 00:16:54.826 A:middle
there's really two
major scenarios

00:16:54.826 --> 00:16:55.746 A:middle
that can describe this.

00:16:56.446 --> 00:16:58.226 A:middle
First off, there's
the periodic source.

00:16:58.486 --> 00:16:59.966 A:middle
This is the case where
you're getting frames

00:16:59.966 --> 00:17:03.026 A:middle
in at basically the same rate
at which they're being displayed


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:59.966 --> 00:17:03.026 A:middle
in at basically the same rate
at which they're being displayed

00:17:03.026 --> 00:17:05.556 A:middle
in the
AVSampleBufferDisplayLayer.

00:17:06.086 --> 00:17:08.336 A:middle
This would be the case
for a live streaming app

00:17:08.896 --> 00:17:12.195 A:middle
or live streaming
app with low latency

00:17:12.195 --> 00:17:14.066 A:middle
or video conferencing scenario.

00:17:15.175 --> 00:17:17.626 A:middle
The next case is the
unconstrained source.

00:17:18.056 --> 00:17:22.215 A:middle
This is the case where you have
a large set of CMSampleBuffers

00:17:22.215 --> 00:17:23.576 A:middle
at your disposal ready to feed

00:17:23.576 --> 00:17:26.415 A:middle
into the
AVSampleBufferDisplayLayer

00:17:26.756 --> 00:17:27.445 A:middle
at one time.

00:17:28.756 --> 00:17:31.076 A:middle
This would be the case
if you have a large cache

00:17:31.076 --> 00:17:32.446 A:middle
of buffered network data

00:17:32.816 --> 00:17:35.136 A:middle
or if you're reading the
CMSampleBuffers from a file.

00:17:35.926 --> 00:17:38.246 A:middle
All right, let's talk
about the first case.

00:17:39.066 --> 00:17:40.066 A:middle
This is really simple.

00:17:40.166 --> 00:17:41.366 A:middle
Frames are coming
in at the same rate

00:17:41.366 --> 00:17:42.456 A:middle
at which they're
being displayed.

00:17:42.786 --> 00:17:45.306 A:middle
You can go ahead and just
enqueue the sample buffers

00:17:45.446 --> 00:17:47.446 A:middle
with your
AVSampleBufferDisplayLayer

00:17:47.446 --> 00:17:48.206 A:middle
as they arrive.

00:17:50.166 --> 00:17:52.096 A:middle
You use the enqueueSampleBuffer
column.

00:17:52.576 --> 00:17:53.756 A:middle
All right.

00:17:53.756 --> 00:17:56.006 A:middle
The unconstrained source is a
little bit more complicated.

00:17:56.206 --> 00:17:59.056 A:middle
You don't want to just shove
all of those CMSampleBuffers

00:17:59.056 --> 00:18:00.446 A:middle
into the
AVSampleBufferDisplayLayer


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:17:59.056 --> 00:18:00.446 A:middle
into the
AVSampleBufferDisplayLayer

00:18:00.446 --> 00:18:00.836 A:middle
at once.

00:18:01.456 --> 00:18:02.956 A:middle
No one will be happy with that.

00:18:03.706 --> 00:18:05.136 A:middle
What you want to do,

00:18:05.226 --> 00:18:10.416 A:middle
the AVSampleBufferDisplayLayer
can tell you when its buffers,

00:18:10.996 --> 00:18:13.196 A:middle
internal buffers are low
and it needs more data

00:18:13.776 --> 00:18:15.806 A:middle
and you can ask it when
it has enough data.

00:18:16.856 --> 00:18:20.946 A:middle
The way you do this is
using the requestMediaData

00:18:20.946 --> 00:18:22.076 A:middle
WhenReadyOnQueue.

00:18:23.236 --> 00:18:26.716 A:middle
You provide a block
in this interface

00:18:27.136 --> 00:18:31.156 A:middle
and AVSampleBufferDisplayLayer
will call your block every time

00:18:31.216 --> 00:18:34.346 A:middle
its internal queue's are
low and it needs more data.

00:18:36.576 --> 00:18:38.646 A:middle
Inside of that block,
you can go ahead

00:18:38.646 --> 00:18:43.096 A:middle
and loop while you're asking
whether it has enough data.

00:18:43.206 --> 00:18:45.816 A:middle
You use isReadyForMoreMediaData
column.

00:18:46.296 --> 00:18:49.166 A:middle
If it returns true, that means
it wants for SampleBuffers,

00:18:49.306 --> 00:18:51.126 A:middle
so you keep on feeding
SampleBuffers in.

00:18:51.316 --> 00:18:53.246 A:middle
As soon as it returns false,

00:18:53.246 --> 00:18:55.226 A:middle
that means it has
enough and you can stop.

00:18:56.226 --> 00:18:58.656 A:middle
So it's a pretty
simple loop to write.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:00.276 --> 00:19:01.456 A:middle
All right.

00:19:02.476 --> 00:19:04.466 A:middle
Let's do a quick
summary of what we talked

00:19:04.466 --> 00:19:06.106 A:middle
about with
AVSampleBufferDisplayLayer.

00:19:06.226 --> 00:19:08.356 A:middle
At this point, you
should be able

00:19:08.356 --> 00:19:10.426 A:middle
to create an
AVSampleBufferDisplayLayer.

00:19:11.716 --> 00:19:14.396 A:middle
You've learned how to
convert your Elementary Stream

00:19:14.616 --> 00:19:17.676 A:middle
to H.264 data into
CMSampleBuffers

00:19:17.726 --> 00:19:20.376 A:middle
that will happily
be decompressed

00:19:20.376 --> 00:19:21.926 A:middle
by your
AVSampleBufferDisplayLayer.

00:19:23.886 --> 00:19:26.006 A:middle
We've talked about a
couple of scenarios

00:19:26.286 --> 00:19:28.796 A:middle
about how you would provide
these CMSampleBuffers

00:19:28.836 --> 00:19:31.406 A:middle
to your layer,
AVSampleBufferDisplayLayer.

00:19:31.786 --> 00:19:34.386 A:middle
And finally, we talked about
using a custom time base

00:19:34.386 --> 00:19:35.966 A:middle
with the
AVSampleBufferDisplayLayer.

00:19:36.596 --> 00:19:37.626 A:middle
All right.

00:19:38.476 --> 00:19:40.116 A:middle
So let's dive into
our second case.

00:19:40.436 --> 00:19:43.296 A:middle
This is the case where you have
a stream of H.264 data coming

00:19:43.296 --> 00:19:44.946 A:middle
in over the network,
but you don't want

00:19:44.946 --> 00:19:46.296 A:middle
to just display it
in your application.

00:19:46.296 --> 00:19:48.066 A:middle
You want to actually
decode those frames

00:19:48.066 --> 00:19:50.766 A:middle
and get the decompressed
pixel buffers.

00:19:52.416 --> 00:19:55.666 A:middle
So what we had

00:19:55.666 --> 00:19:57.886 A:middle
in AVSampleBufferDisplayLayer
contains a lot

00:19:57.886 --> 00:19:58.756 A:middle
of the pieces we need.

00:19:59.656 --> 00:20:01.886 A:middle
But instead of accessing
the video decoder


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:59.656 --> 00:20:01.886 A:middle
But instead of accessing
the video decoder

00:20:01.886 --> 00:20:03.646 A:middle
through the
AVSampleBufferDisplayLayer,

00:20:04.166 --> 00:20:06.616 A:middle
we'll access it through
the VTDecompressionSession.

00:20:07.386 --> 00:20:10.126 A:middle
Like the
AVSampleBufferDisplayLayer,

00:20:10.236 --> 00:20:13.836 A:middle
VTDecompressionSession wants
CMSampleBuffers as its input.

00:20:15.946 --> 00:20:18.196 A:middle
And it will decode
the CMSampleBuffers

00:20:18.196 --> 00:20:20.796 A:middle
to CVPixelBuffers
and receive those

00:20:20.796 --> 00:20:22.866 A:middle
in the output callback
that you implement.

00:20:24.166 --> 00:20:26.766 A:middle
So in order to create a
VTDecompressionSession,

00:20:26.766 --> 00:20:27.796 A:middle
you'll need a few things.

00:20:28.626 --> 00:20:30.376 A:middle
First, you need to
provide a description

00:20:30.376 --> 00:20:32.506 A:middle
of the source buffers that
you'll be decompressing.

00:20:33.386 --> 00:20:35.256 A:middle
This is a
CMVideoFormatDescription.

00:20:35.306 --> 00:20:39.426 A:middle
If you're decompressing from an
Elementary Stream you've created

00:20:39.426 --> 00:20:40.576 A:middle
this from your parameter sets,

00:20:41.006 --> 00:20:43.046 A:middle
if you just have a
CMSampleBuffer that you want

00:20:43.046 --> 00:20:46.026 A:middle
to decompress you can pull it
right off the CMSampleBuffer.

00:20:47.916 --> 00:20:49.726 A:middle
Next, you need to
describe your requirements

00:20:49.726 --> 00:20:51.306 A:middle
for your output pixel buffers.

00:20:51.986 --> 00:20:55.086 A:middle
You use a pixelBufferAttributes
dictionary for this.

00:20:56.696 --> 00:20:57.706 A:middle
And finally, you need

00:20:57.706 --> 00:21:00.406 A:middle
to implement a
VTDecompressionOutputCallback.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:20:57.706 --> 00:21:00.406 A:middle
to implement a
VTDecompressionOutputCallback.

00:21:01.226 --> 00:21:02.346 A:middle
All right.

00:21:02.566 --> 00:21:04.446 A:middle
Let's talk about
describing your requirements

00:21:04.446 --> 00:21:06.286 A:middle
for the Output PixelBuffers.

00:21:07.006 --> 00:21:08.906 A:middle
Here, you need to create
a PixelBufferAttributes

00:21:08.906 --> 00:21:09.426 A:middle
dictionary.

00:21:09.926 --> 00:21:12.726 A:middle
So let's look at a
scenario where we want

00:21:12.886 --> 00:21:14.936 A:middle
to use the Output CVPixelBuffers

00:21:14.936 --> 00:21:16.886 A:middle
in an open GLS ES
render pipeline.

00:21:18.406 --> 00:21:20.336 A:middle
Really, the only
requirement here that we have

00:21:20.336 --> 00:21:21.796 A:middle
for our Output PixelBuffers is

00:21:21.796 --> 00:21:23.746 A:middle
that they be OpenGL
ES compatible.

00:21:24.416 --> 00:21:28.336 A:middle
So we can go ahead and
just create a CF dictionary

00:21:28.336 --> 00:21:32.016 A:middle
or NS dictionary specifying
the kCVPixelBufferOpen

00:21:32.016 --> 00:21:37.976 A:middle
GLESCompatibilityKey
and set it to true.

00:21:38.826 --> 00:21:40.826 A:middle
So it can be very tempting

00:21:41.046 --> 00:21:42.926 A:middle
to when you're creating
these PixelBufferAttributes

00:21:42.926 --> 00:21:44.636 A:middle
dictionaries to be
very specific.

00:21:45.226 --> 00:21:47.256 A:middle
That way, there's no
surprises about what you get

00:21:47.256 --> 00:21:48.786 A:middle
out of the
VTDecompressionSession,

00:21:49.126 --> 00:21:50.326 A:middle
but there's some pitfalls here.

00:21:50.966 --> 00:21:52.506 A:middle
So let's look at this case

00:21:52.506 --> 00:21:56.446 A:middle
where we had kCVPixelBufferOpen
GLESCompatibilityKey set

00:21:56.446 --> 00:21:56.876 A:middle
to true.

00:21:58.126 --> 00:22:00.936 A:middle
Here, our decompression
session, the decoder inside


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:21:58.126 --> 00:22:00.936 A:middle
Here, our decompression
session, the decoder inside

00:22:00.936 --> 00:22:03.256 A:middle
of our decompression session is
going to be decoding the frames

00:22:03.256 --> 00:22:05.736 A:middle
and outputting YUV
CVPixelBuffers.

00:22:06.966 --> 00:22:10.736 A:middle
In the VTDecompressionSession
will then ask is this --

00:22:11.146 --> 00:22:14.006 A:middle
well, it'll ask itself, is
this PixelBuffer compatible

00:22:14.006 --> 00:22:16.066 A:middle
with those requested attributes.

00:22:16.696 --> 00:22:17.686 A:middle
And the answer is yes.

00:22:17.876 --> 00:22:21.016 A:middle
That YUV frame is OpenGL ES
compatible so it can return

00:22:21.016 --> 00:22:22.336 A:middle
that directly to your callback.

00:22:23.596 --> 00:22:28.796 A:middle
But let's say you were
possessed to add BGRA request

00:22:28.896 --> 00:22:30.536 A:middle
to your PixelBufferAttributes.

00:22:31.446 --> 00:22:35.086 A:middle
So just like before,
the decoder inside

00:22:35.086 --> 00:22:38.066 A:middle
of our VTDecompressionSession
will decode to a YUV format

00:22:38.066 --> 00:22:42.336 A:middle
and will ask whether this
CVPixelBuffer is compatible

00:22:42.336 --> 00:22:44.186 A:middle
with the requested
output requirements.

00:22:44.986 --> 00:22:48.626 A:middle
And it is OpenGL ES compatible,
but it's certainly not BGRA.

00:22:49.716 --> 00:22:52.616 A:middle
So it will need to do an
extra buffer copy to convert

00:22:52.616 --> 00:22:54.446 A:middle
that YUV data to BGRA data.

00:22:56.616 --> 00:22:59.056 A:middle
So extra buffer copies are bad.

00:22:59.296 --> 00:23:02.856 A:middle
They decrease efficiency
and they can lead


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:59.296 --> 00:23:02.856 A:middle
They decrease efficiency
and they can lead

00:23:02.986 --> 00:23:04.686 A:middle
to decreased battery life.

00:23:05.086 --> 00:23:08.456 A:middle
So the moral story here is
be it -- don't over specify.

00:23:09.796 --> 00:23:12.776 A:middle
All right, so let's talk
about your Output Callback.

00:23:14.276 --> 00:23:15.956 A:middle
So the Output Callback is

00:23:15.956 --> 00:23:18.576 A:middle
where you'll receive the
decoded CVPixelBuffers

00:23:19.736 --> 00:23:23.196 A:middle
and CVPixelBuffers don't
have a built in time stamp,

00:23:23.196 --> 00:23:25.496 A:middle
so you'll receive the
presentation time stamp

00:23:26.356 --> 00:23:27.726 A:middle
for that PixelBuffer here.

00:23:28.876 --> 00:23:32.426 A:middle
And if there are errors or the
frame is dropped for any reason,

00:23:32.426 --> 00:23:34.556 A:middle
you'll receive that information
in the Output Callback.

00:23:34.696 --> 00:23:35.866 A:middle
And it's important to note

00:23:35.866 --> 00:23:38.786 A:middle
that the Output Callback will
be called for every single frame

00:23:38.786 --> 00:23:41.786 A:middle
that you push into the
VTDecompressionSession even

00:23:41.786 --> 00:23:43.556 A:middle
if there's an error,
even if it's dropped.

00:23:45.556 --> 00:23:48.386 A:middle
All right, let's talk
about providing frames

00:23:48.436 --> 00:23:50.106 A:middle
to your VTDecompressionSession.

00:23:50.746 --> 00:23:53.666 A:middle
To do that, you call
VTDecompression

00:23:53.666 --> 00:23:54.896 A:middle
SessionDecodeFrame.

00:23:56.336 --> 00:23:58.236 A:middle
Just like
AVSampleBufferDisplayLayer,

00:23:58.526 --> 00:24:03.306 A:middle
you need to provide these as
CMSampleBuffers, and you need


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:23:58.526 --> 00:24:03.306 A:middle
you need to provide these as
CMSampleBuffers, and you need

00:24:03.306 --> 00:24:05.196 A:middle
to provide these
frames in decode order.

00:24:07.726 --> 00:24:08.906 A:middle
And by default,

00:24:08.906 --> 00:24:11.256 A:middle
VTDecompressionSession
DecodeFrame will

00:24:11.256 --> 00:24:12.416 A:middle
operate synchronously.

00:24:12.736 --> 00:24:15.906 A:middle
This means that your Output
Callback will be called before

00:24:15.906 --> 00:24:18.976 A:middle
VTDecompression
SessionDecodeFrame returns.

00:24:20.526 --> 00:24:22.746 A:middle
If you want a synchronous
operation, you can pass

00:24:22.746 --> 00:24:25.556 A:middle
in the flag requesting
EnableASynchronous

00:24:25.586 --> 00:24:26.346 A:middle
Decompression.

00:24:26.896 --> 00:24:32.256 A:middle
All right, let's talk about
Asynchronous Decompression then.

00:24:32.256 --> 00:24:33.546 A:middle
With ASynchronousDecompression,

00:24:33.856 --> 00:24:34.346 A:middle
the call

00:24:34.346 --> 00:24:37.696 A:middle
to VTDecompressionSession
DecodeFrame returns as soon

00:24:37.696 --> 00:24:40.196 A:middle
as it hands the frame
off to the decoder.

00:24:40.656 --> 00:24:44.726 A:middle
But decoders often have limited
pipelines for decoding frames.

00:24:45.446 --> 00:24:48.566 A:middle
So when the decoders
internal pipeline is full,

00:24:48.566 --> 00:24:51.966 A:middle
the call to VTDecompression
SessionDecodeFrame will block

00:24:52.306 --> 00:24:54.656 A:middle
until space opens up in
the decoders pipeline.

00:24:56.246 --> 00:24:57.756 A:middle
We call this decoder
back pressure.

00:24:58.896 --> 00:25:01.996 A:middle
So what this means is that
even though you're calling


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:24:58.896 --> 00:25:01.996 A:middle
So what this means is that
even though you're calling

00:25:02.086 --> 00:25:04.186 A:middle
VTDecompressionSession
DecodeFrame

00:25:04.186 --> 00:25:06.096 A:middle
and requesting Asynchronous
Decompression,

00:25:06.356 --> 00:25:09.316 A:middle
we will be doing the
decompression asynchronously

00:25:09.396 --> 00:25:14.336 A:middle
but the call can still block in
some cases, so be aware of that.

00:25:14.336 --> 00:25:15.796 A:middle
You're doing
ASynchronousDecompression

00:25:15.796 --> 00:25:19.546 A:middle
but the call can block, so don't
perform UI tasks on that thread.

00:25:20.766 --> 00:25:24.616 A:middle
All right, if you find yourself
in a situation where you want

00:25:24.616 --> 00:25:26.746 A:middle
to ensure that all asynchronous
frames have been cleared

00:25:26.746 --> 00:25:31.416 A:middle
out of the decoder, you can call
VTDecompressionSession and wait

00:25:31.416 --> 00:25:32.496 A:middle
for asynchronous frames.

00:25:32.996 --> 00:25:35.666 A:middle
This call will not return until
all frames have been omitted

00:25:35.666 --> 00:25:36.996 A:middle
from the decompression session.

00:25:39.876 --> 00:25:43.956 A:middle
So sometimes, we'll be decode
in a sequence of video frames.

00:25:44.466 --> 00:25:46.956 A:middle
There will be a change in
the CMVideoFormatDescription,

00:25:47.156 --> 00:25:50.086 A:middle
so let's look at the case
where we had a sequence

00:25:50.086 --> 00:25:51.666 A:middle
of an Elementary Stream

00:25:51.666 --> 00:25:53.946 A:middle
and we created the
first format description

00:25:53.946 --> 00:25:56.186 A:middle
out of the first parameter
sets that we encountered.

00:25:56.386 --> 00:25:58.166 A:middle
So now we have format
description one

00:25:58.306 --> 00:25:59.946 A:middle
with our first SPS and PPS.

00:25:59.946 --> 00:26:04.126 A:middle
We can go ahead and create
our VTDecompressionSession


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:25:59.946 --> 00:26:04.126 A:middle
We can go ahead and create
our VTDecompressionSession

00:26:04.126 --> 00:26:07.856 A:middle
with that format description and
decode all the subsequent frames

00:26:08.036 --> 00:26:10.706 A:middle
with that format description
attached to the CMSampleBuffer

00:26:11.956 --> 00:26:16.826 A:middle
until we encounter a new
SPS and PPS in the stream.

00:26:17.886 --> 00:26:20.266 A:middle
Then, we need to create
a new format description

00:26:20.266 --> 00:26:24.496 A:middle
with the new SPS and PPS
and we have to make sure

00:26:24.496 --> 00:26:26.726 A:middle
that the decompression
session can switch

00:26:26.726 --> 00:26:28.186 A:middle
between these format
descriptions.

00:26:29.316 --> 00:26:32.966 A:middle
So to do that, you call
VTDecompressionSession

00:26:32.966 --> 00:26:34.596 A:middle
CanAcceptFormatDescription.

00:26:35.296 --> 00:26:37.926 A:middle
This will ensure -- ask the
decoder whether it's able

00:26:37.926 --> 00:26:39.856 A:middle
to transition from
FormatDescription one

00:26:39.856 --> 00:26:42.826 A:middle
to FormatDescription two.

00:26:43.366 --> 00:26:46.116 A:middle
If the answer is true, yes,

00:26:46.116 --> 00:26:49.776 A:middle
it can handle the new
accepted FormatDescription.

00:26:50.146 --> 00:26:52.226 A:middle
That means you can
pass subsequent samples

00:26:52.226 --> 00:26:54.346 A:middle
with that new FormatDescription
attached to them

00:26:54.946 --> 00:26:57.806 A:middle
into the Decompression Session
and everything will work fine.

00:26:58.186 --> 00:27:02.066 A:middle
If it returns false that
means the decompressor cannot


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:26:58.186 --> 00:27:02.066 A:middle
If it returns false that
means the decompressor cannot

00:27:02.066 --> 00:27:04.696 A:middle
transition from that
first format description

00:27:04.946 --> 00:27:07.236 A:middle
to the second format
description, and you'll need

00:27:07.236 --> 00:27:09.236 A:middle
to create a new
VTDecompressionSession

00:27:09.966 --> 00:27:13.566 A:middle
and be sure and pass the
new frames into that one.

00:27:14.326 --> 00:27:17.266 A:middle
And be sure to release that
old VTDecompressionSession

00:27:17.796 --> 00:27:20.256 A:middle
when you're no longer using it.

00:27:20.816 --> 00:27:21.296 A:middle
All right.

00:27:21.976 --> 00:27:23.076 A:middle
Quick summary of what we talked

00:27:23.076 --> 00:27:24.746 A:middle
about with the
VTDecompressionSession.

00:27:25.586 --> 00:27:30.166 A:middle
We talked creating the
VTDecompressionSession and how

00:27:30.166 --> 00:27:31.446 A:middle
to make optimal decisions

00:27:31.446 --> 00:27:35.356 A:middle
when creating the
PixelBufferAttributes dictionary

00:27:36.326 --> 00:27:38.996 A:middle
for specifying your
output requirements.

00:27:39.616 --> 00:27:43.046 A:middle
We talked about running your
decompression session both

00:27:43.046 --> 00:27:46.426 A:middle
synchronously and
asynchronously and we talked

00:27:46.426 --> 00:27:49.106 A:middle
about handing changes in
CMVideo FormatDescription.

00:27:50.846 --> 00:27:53.886 A:middle
So with that, let's
hop into case three.

00:27:54.446 --> 00:27:59.686 A:middle
This is the case where you
have a stream of CVPixelBuffers

00:27:59.686 --> 00:28:02.566 A:middle
or frames coming in from a
camera or another source,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:27:59.686 --> 00:28:02.566 A:middle
or frames coming in from a
camera or another source,

00:28:03.296 --> 00:28:05.786 A:middle
and you want to compress those
directly into a movie file.

00:28:07.136 --> 00:28:10.216 A:middle
Well, for this, you may be
familiar with this already.

00:28:10.326 --> 00:28:11.726 A:middle
We have AVAssetWriter.

00:28:13.306 --> 00:28:16.626 A:middle
AVAssetWriter has an encoder
internally, and it's going

00:28:16.626 --> 00:28:19.196 A:middle
to be encoding those
frames into CMSampleBuffers

00:28:20.046 --> 00:28:22.086 A:middle
and it's got some
file writing smarts,

00:28:22.196 --> 00:28:25.066 A:middle
so it can write these
optimally into a movie file.

00:28:25.896 --> 00:28:30.056 A:middle
We're not actually going
to talk more at this point

00:28:30.056 --> 00:28:34.326 A:middle
about AVAssetWriter, but
it's an important concept

00:28:34.326 --> 00:28:36.396 A:middle
and an important thing to bring
up in the context of this talk,

00:28:36.596 --> 00:28:39.446 A:middle
so if you want more information
on the AVAssetWriter,

00:28:39.546 --> 00:28:45.506 A:middle
you can go back to WWDC 2013
and the talk Moving to AVKit

00:28:45.506 --> 00:28:48.086 A:middle
and AVFoundation or 2011,

00:28:48.766 --> 00:28:50.736 A:middle
Working with Media
and AVFoundation.

00:28:51.756 --> 00:28:53.856 A:middle
All right.

00:28:54.236 --> 00:28:56.086 A:middle
Let's just hop straight
into case four.

00:28:56.466 --> 00:28:59.886 A:middle
This is the case where you
have that stream of data coming

00:28:59.886 --> 00:29:03.156 A:middle
in from your camera and
you want to compress it,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:28:59.886 --> 00:29:03.156 A:middle
in from your camera and
you want to compress it,

00:29:03.156 --> 00:29:04.906 A:middle
but you don't want to
write into a movie file.

00:29:05.046 --> 00:29:07.656 A:middle
You want direct access to
those compresses SampleBuffers.

00:29:08.896 --> 00:29:11.486 A:middle
So we want to approach
our video encoder

00:29:11.986 --> 00:29:14.446 A:middle
through a VTCompressionSession
rather

00:29:14.446 --> 00:29:15.706 A:middle
than through the AVAssetWriter.

00:29:17.316 --> 00:29:18.976 A:middle
So just like AVAssetWriter,

00:29:18.976 --> 00:29:21.946 A:middle
VTCompressionSession takes
CVPixelBuffers as its input,

00:29:22.726 --> 00:29:25.586 A:middle
and it's going to compress those
and return CMSampleBuffers,

00:29:25.876 --> 00:29:27.336 A:middle
and we can go ahead and send

00:29:27.716 --> 00:29:29.376 A:middle
that compressed data
out over the network.

00:29:30.736 --> 00:29:34.156 A:middle
So to create a
VTCompressionSession,

00:29:34.156 --> 00:29:36.826 A:middle
you'll need a few things,
and this is really simple.

00:29:37.206 --> 00:29:39.296 A:middle
You just need to specify
the dimensions you want

00:29:39.296 --> 00:29:40.516 A:middle
for your compressed output.

00:29:41.616 --> 00:29:44.816 A:middle
You need to tell us what format
you want to compress to such

00:29:44.816 --> 00:29:51.826 A:middle
as kCMVideoCodecTypeH.264 and
you can optionally provide a set

00:29:51.826 --> 00:29:54.316 A:middle
of PixelBufferAttributes
describing your source

00:29:54.476 --> 00:29:56.326 A:middle
CVPixelBuffers that
you'll be sending

00:29:56.326 --> 00:29:56.976 A:middle
to the VTCompressionSession.

00:29:57.106 --> 00:29:59.966 A:middle
And finally, you need

00:29:59.966 --> 00:30:02.346 A:middle
to implement a
VTCompressionOutput Callback.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:59.966 --> 00:30:02.346 A:middle
to implement a
VTCompressionOutput Callback.

00:30:04.386 --> 00:30:07.336 A:middle
So you've created a
VTCompressionSession.

00:30:07.626 --> 00:30:09.356 A:middle
Now you want to configure it.

00:30:10.386 --> 00:30:12.476 A:middle
You configure a
VTCompressionSession using

00:30:12.476 --> 00:30:14.166 A:middle
VTSession SetProperty.

00:30:14.666 --> 00:30:17.316 A:middle
In fact, you can
have a whole sequence

00:30:17.316 --> 00:30:19.516 A:middle
of VTSessionSetProperty calls.

00:30:19.596 --> 00:30:24.076 A:middle
So I'm going to go through a
few common properties here and

00:30:24.676 --> 00:30:26.226 A:middle
but this is not an
exhaustive list.

00:30:26.876 --> 00:30:29.216 A:middle
The first one I'm going to
mention is AllowFrameReordering.

00:30:29.216 --> 00:30:33.816 A:middle
By default, H.264 encoder will
allow frames to be reordered.

00:30:34.286 --> 00:30:36.826 A:middle
That means the presentation
time stamp that you pass them

00:30:36.826 --> 00:30:41.116 A:middle
in will not necessarily
equal the decode order

00:30:41.376 --> 00:30:42.576 A:middle
in which they're admitted.

00:30:43.446 --> 00:30:46.926 A:middle
If you want to disable this
behavior, you can pass false

00:30:47.266 --> 00:30:48.456 A:middle
to allow frame reordering.

00:30:50.426 --> 00:30:51.936 A:middle
Next one, average byte rate.

00:30:52.386 --> 00:30:54.916 A:middle
This is how you set a target
byte rate for the compressor.

00:30:56.186 --> 00:31:03.416 A:middle
H.264EntropyMode; using this,
you can specify CALV compression


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:56.186 --> 00:31:03.416 A:middle
H.264EntropyMode; using this,
you can specify CALV compression

00:31:03.416 --> 00:31:06.616 A:middle
or KVTH compression
for your H.264 encoder.

00:31:07.436 --> 00:31:10.306 A:middle
All right, and then there's
the RealTime property.

00:31:10.956 --> 00:31:13.396 A:middle
The RealTime property allows
you to tell the encoder

00:31:13.396 --> 00:31:16.786 A:middle
that this is a real time
encoding operation such as

00:31:16.786 --> 00:31:22.166 A:middle
in a live streaming case,
conferencing case as opposed

00:31:22.166 --> 00:31:26.636 A:middle
to more of a background activity
like a transcode operation.

00:31:27.426 --> 00:31:30.256 A:middle
And the final one I'm going

00:31:30.256 --> 00:31:32.276 A:middle
to mention here is
the ProfileLevelKey.

00:31:32.756 --> 00:31:35.726 A:middle
This allows you to specify
specific profiles and levels

00:31:35.826 --> 00:31:39.236 A:middle
or specific profiles and allow
us to choose the correct level.

00:31:39.816 --> 00:31:43.366 A:middle
And this is definitely
not an exhaustive list.

00:31:43.456 --> 00:31:48.006 A:middle
There's a lot of these options
available, so go ahead and look

00:31:48.006 --> 00:31:52.316 A:middle
in VTCompressionProperties.H
and see what we have for you.

00:31:52.316 --> 00:31:57.006 A:middle
All right, let's talk about
providing CVPixelBuffers

00:31:57.006 --> 00:31:58.376 A:middle
to your VTCompressionSession.

00:31:59.406 --> 00:32:01.576 A:middle
Use
VTCompressionSessionEncodeFrame


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:31:59.406 --> 00:32:01.576 A:middle
Use
VTCompressionSessionEncodeFrame

00:32:01.576 --> 00:32:07.556 A:middle
to do this, and you'll need
to provide CVPixelBuffers

00:32:08.106 --> 00:32:10.066 A:middle
and as I've mentioned,

00:32:10.066 --> 00:32:14.076 A:middle
CVPixelBuffers don't have a
presentation timestamp built

00:32:14.076 --> 00:32:16.286 A:middle
into them, so as a
separate parameter,

00:32:16.286 --> 00:32:18.096 A:middle
you'll provide the
presentation timestamp.

00:32:19.626 --> 00:32:23.576 A:middle
You need to feed the frames
in in presentation order.

00:32:25.996 --> 00:32:30.746 A:middle
And it's one more note about
the presentation order, they --

00:32:31.106 --> 00:32:33.496 A:middle
the presentation timestamps
must be increasing.

00:32:33.926 --> 00:32:36.236 A:middle
No duplicate presentation
timestamps,

00:32:36.576 --> 00:32:38.066 A:middle
no timestamps that go backwards.

00:32:39.736 --> 00:32:42.146 A:middle
And so compression sessions,

00:32:42.326 --> 00:32:45.866 A:middle
compressions operations usually
require a window or frames

00:32:45.866 --> 00:32:49.046 A:middle
that they'll operate on, so
your output may be delayed.

00:32:49.756 --> 00:32:52.916 A:middle
So you may not receive
a compressed frame

00:32:52.916 --> 00:32:54.716 A:middle
in your Output Callback
until a certain number

00:32:54.716 --> 00:32:56.556 A:middle
of frames have been
pushed into the encoder.

00:32:57.116 --> 00:32:59.476 A:middle
All right.

00:32:59.476 --> 00:33:01.946 A:middle
And finally, if you've
reached the end of the frames


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:59.476 --> 00:33:01.946 A:middle
And finally, if you've
reached the end of the frames

00:33:01.946 --> 00:33:04.196 A:middle
that you're passing to the
compression session and you want

00:33:04.876 --> 00:33:07.606 A:middle
to have it emit all of the
frames that it's received

00:33:07.606 --> 00:33:10.106 A:middle
so far, you can use
VTCompressionSession

00:33:10.106 --> 00:33:11.096 A:middle
CompleteFrames.

00:33:11.436 --> 00:33:12.956 A:middle
All pending frames
will be omitted.

00:33:14.896 --> 00:33:15.376 A:middle
All right.

00:33:15.706 --> 00:33:17.336 A:middle
Let's talk about
your Output Callback.

00:33:19.296 --> 00:33:20.426 A:middle
So your Output Callback is

00:33:20.426 --> 00:33:23.276 A:middle
where you'll receive your
output CMSampleBuffers.

00:33:23.426 --> 00:33:25.126 A:middle
These contain the
compressed frames.

00:33:25.976 --> 00:33:29.476 A:middle
If there were any errors or
dropped frames, you'll receive

00:33:29.476 --> 00:33:30.526 A:middle
that information here.

00:33:31.466 --> 00:33:34.786 A:middle
And final thing, frames will
be omitted in decode order.

00:33:35.006 --> 00:33:37.436 A:middle
So you provided frames to
the VTCompressionSession

00:33:37.436 --> 00:33:38.446 A:middle
in presentation order

00:33:38.856 --> 00:33:40.716 A:middle
and they'll be omitted
in decode order.

00:33:41.456 --> 00:33:44.486 A:middle
All right.

00:33:45.176 --> 00:33:48.136 A:middle
Well, so you've compressed
a bunch of frames.

00:33:48.306 --> 00:33:51.516 A:middle
They're now compressed
in CMSampleBuffers,

00:33:51.516 --> 00:33:54.876 A:middle
which means that they're
using MPEG-4 packaging.

00:33:55.646 --> 00:33:57.696 A:middle
And you want to send that
out over the network,

00:33:58.036 --> 00:34:01.576 A:middle
which means you may
need to switch these


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:33:58.036 --> 00:34:01.576 A:middle
which means you may
need to switch these

00:34:01.576 --> 00:34:03.416 A:middle
over to Elementary
Stream packaging.

00:34:04.346 --> 00:34:05.866 A:middle
Well, once again,
you're going to have

00:34:05.866 --> 00:34:08.025 A:middle
to do a little bit of work.

00:34:09.096 --> 00:34:12.196 A:middle
So we talked about the
parameter sets before.

00:34:13.025 --> 00:34:16.626 A:middle
So the parameters sets will
in your MPEG-4 package,

00:34:16.626 --> 00:34:20.315 A:middle
H.264 will be in the
CMVideoFormatDescription.

00:34:21.076 --> 00:34:22.335 A:middle
So the first thing
you're going to have

00:34:22.335 --> 00:34:25.866 A:middle
to do is extract those
parameter sets and package them

00:34:25.866 --> 00:34:27.766 A:middle
as NAL Units to send
out over the network.

00:34:29.716 --> 00:34:33.686 A:middle
Well, we provide a handy
utility for that too.

00:34:34.186 --> 00:34:38.176 A:middle
CMVideoFormatDescription
GetH.264ParameterSetAtIndex.

00:34:39.696 --> 00:34:44.686 A:middle
All right, and the next thing
you need to do is the opposite

00:34:44.686 --> 00:34:46.795 A:middle
of what we did with
AVSampleBufferDisplayLayer.

00:34:47.616 --> 00:34:51.666 A:middle
Our NAL Units are all going
to have length headers

00:34:52.585 --> 00:34:53.636 A:middle
and you're going to need

00:34:53.636 --> 00:34:56.835 A:middle
to convert those length
headers into start codes.

00:34:58.816 --> 00:35:00.966 A:middle
So as you extract each NAL Unit


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:58.816 --> 00:35:00.966 A:middle
So as you extract each NAL Unit

00:35:00.966 --> 00:35:03.576 A:middle
from the compressed data
inside the CMSampleBuffer,

00:35:04.206 --> 00:35:06.106 A:middle
convert those headers
on the NAL Units.

00:35:07.736 --> 00:35:08.236 A:middle
All right.

00:35:08.536 --> 00:35:10.136 A:middle
Quick summary of what we talked

00:35:10.136 --> 00:35:11.776 A:middle
about with the
VTCompressionSession.

00:35:12.636 --> 00:35:15.026 A:middle
We talked about creating
the VTCompressionSession.

00:35:16.216 --> 00:35:17.086 A:middle
We've talked about how

00:35:17.086 --> 00:35:19.766 A:middle
to configure it using the
VTSessionSetProperty column.

00:35:21.886 --> 00:35:24.676 A:middle
And we talked about how you
would provide CVPixelBuffers

00:35:24.676 --> 00:35:25.996 A:middle
to the compression session.

00:35:27.816 --> 00:35:31.316 A:middle
And finally, we talked about
converting those CMSampleBuffers

00:35:31.316 --> 00:35:34.736 A:middle
into an H.264 Elementary
Stream packaging.

00:35:35.796 --> 00:35:36.436 A:middle
All right.

00:35:36.436 --> 00:35:39.126 A:middle
And with that, I'd like
to hand things off to Eric

00:35:39.126 --> 00:35:40.546 A:middle
so he can talk about Multi-Pass.

00:35:40.996 --> 00:35:43.806 A:middle
&gt;&gt; Good morning everyone.

00:35:43.996 --> 00:35:45.326 A:middle
My name is Eric Turnquist.

00:35:45.326 --> 00:35:47.486 A:middle
I'm the Core Media Engineer,
and today, I want to talk to you

00:35:47.486 --> 00:35:48.636 A:middle
about Multi-Pass Encoding.

00:35:49.606 --> 00:35:53.096 A:middle
So as a media engineer, we often
deal with two opposing forces;

00:35:53.326 --> 00:35:54.936 A:middle
quality versus bit rate.

00:35:55.536 --> 00:35:58.256 A:middle
So quality is how pristine
the image is, and we all know

00:35:58.256 --> 00:36:01.076 A:middle
and we've seen great quality
video and we really don't


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:35:58.256 --> 00:36:01.076 A:middle
and we've seen great quality
video and we really don't

00:36:01.076 --> 00:36:02.596 A:middle
like seeing bad quality video.

00:36:03.476 --> 00:36:05.436 A:middle
Bit rate is how much
data per time is

00:36:05.436 --> 00:36:06.536 A:middle
in the output media file.

00:36:07.076 --> 00:36:08.956 A:middle
So let's say we're
preparing some content.

00:36:10.636 --> 00:36:13.436 A:middle
If you're like me, you go
for high quality first.

00:36:13.776 --> 00:36:15.116 A:middle
So great, we have high quality.

00:36:16.076 --> 00:36:17.996 A:middle
Now in this case, what
happens with the bit rate?

00:36:18.806 --> 00:36:21.476 A:middle
Well unfortunately, if you have
high quality, you also tend

00:36:21.476 --> 00:36:22.436 A:middle
to have a high bit rate.

00:36:22.436 --> 00:36:25.116 A:middle
Now that's okay,
but not what we want

00:36:25.116 --> 00:36:27.486 A:middle
if we're streaming this content
or storing it on a server.

00:36:28.606 --> 00:36:30.446 A:middle
So in that case we
want to a low bit rate

00:36:30.756 --> 00:36:33.046 A:middle
but the quality isn't
going to stay this high.

00:36:33.826 --> 00:36:35.916 A:middle
Unfortunately, that's also
going to go down as well.

00:36:37.086 --> 00:36:39.936 A:middle
So we've all seen this as
block encoder artifacts

00:36:39.936 --> 00:36:41.846 A:middle
or an output image that
doesn't really even look

00:36:41.846 --> 00:36:42.626 A:middle
like the source.

00:36:42.716 --> 00:36:43.586 A:middle
We don't want this either.

00:36:44.246 --> 00:36:45.786 A:middle
Ideally, we want
something like this;

00:36:46.126 --> 00:36:47.856 A:middle
high quality and low bit rate.

00:36:48.426 --> 00:36:51.236 A:middle
In order to achieve that goal,
we've added Multi-Pass Encoding

00:36:51.236 --> 00:36:53.166 A:middle
to AVFoundation and
Video Toolbox.

00:36:53.706 --> 00:37:02.266 A:middle
Yeah, so first off, what
is Multi-Pass Encoding?


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:36:53.706 --> 00:37:02.266 A:middle
Yeah, so first off, what
is Multi-Pass Encoding?

00:37:02.716 --> 00:37:05.786 A:middle
Well, let's do a review of what
Single-Pass Encoding is first.

00:37:05.786 --> 00:37:07.956 A:middle
So this is what David covered
in his portion of the talk.

00:37:09.146 --> 00:37:11.306 A:middle
With Single-Pass Encoding,
you have frames coming in,

00:37:11.456 --> 00:37:13.186 A:middle
going into the encoder
and being admitted.

00:37:13.466 --> 00:37:14.926 A:middle
In this case, we're
going to a movie file.

00:37:16.206 --> 00:37:18.996 A:middle
Then once you're done appending
all the samples, we're finished,

00:37:20.356 --> 00:37:21.966 A:middle
and we're left with
our output movie file.

00:37:22.246 --> 00:37:22.826 A:middle
Simple enough.

00:37:24.066 --> 00:37:25.616 A:middle
Let's see how Multi-Pass
differs.

00:37:25.796 --> 00:37:27.746 A:middle
So you have uncompressed
frames coming in going

00:37:27.746 --> 00:37:29.826 A:middle
into the compression
session, being admitted

00:37:29.826 --> 00:37:30.946 A:middle
as compressed samples.

00:37:30.946 --> 00:37:32.566 A:middle
Now we're going to change
things up a little bit.

00:37:33.206 --> 00:37:35.126 A:middle
So we're going to have
our frame database.

00:37:35.446 --> 00:37:37.076 A:middle
This will store the
compressed samples

00:37:37.076 --> 00:37:39.766 A:middle
and allow us random access in
replacement, which is important

00:37:39.766 --> 00:37:42.726 A:middle
for Multi-Pass, and we're going
to have our encoder database.

00:37:43.226 --> 00:37:44.976 A:middle
This will store frame analysis.

00:37:46.876 --> 00:37:49.066 A:middle
So we're done appending
for one pass

00:37:49.066 --> 00:37:52.036 A:middle
and the encoder will decide I
think I can actually do better

00:37:52.036 --> 00:37:54.266 A:middle
in another pass, so I can tweak
the parameters a little bit

00:37:54.266 --> 00:37:55.156 A:middle
to get better quality.

00:37:57.536 --> 00:37:59.896 A:middle
It will request some
samples and you'll go through

00:37:59.896 --> 00:38:01.736 A:middle
and send those samples
again to the encoder,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:37:59.896 --> 00:38:01.736 A:middle
and send those samples
again to the encoder,

00:38:02.306 --> 00:38:06.596 A:middle
and then it may decide I'm
done or I'm actually --

00:38:06.596 --> 00:38:07.766 A:middle
or I want more passes.

00:38:07.766 --> 00:38:09.466 A:middle
In this case, let's
assume that we're finished.

00:38:11.016 --> 00:38:13.326 A:middle
So we no longer need
the encoder database

00:38:13.326 --> 00:38:14.896 A:middle
or the compression
session, but we're left

00:38:14.896 --> 00:38:17.246 A:middle
with this Frame Database
and we want a movie file,

00:38:17.546 --> 00:38:18.606 A:middle
so we need one more step.

00:38:19.856 --> 00:38:22.326 A:middle
There's a final copy
from the Frame Database

00:38:22.326 --> 00:38:25.356 A:middle
to the output movie
file and that's it.

00:38:25.356 --> 00:38:28.576 A:middle
We have a Multi-Pass encoded
video track on a movie file.

00:38:29.986 --> 00:38:32.466 A:middle
Cool. Let's go over
some encoder features.

00:38:33.556 --> 00:38:36.826 A:middle
So my first point is I want to
make a note of is David said

00:38:36.826 --> 00:38:38.716 A:middle
that Single-Pass is
hardware accelerated

00:38:39.056 --> 00:38:41.166 A:middle
and Multi-Pass is also
hardware accelerated,

00:38:41.366 --> 00:38:43.296 A:middle
so you're not losing any
hardware acceleration there.

00:38:46.536 --> 00:38:49.486 A:middle
Second point is that Multi-Pass
has knowledge of the future.

00:38:50.046 --> 00:38:52.446 A:middle
Now it's not some crazy time
traveling video encoder.

00:38:53.016 --> 00:38:55.226 A:middle
Bonus points whoever filed
that enhancement request.

00:38:55.766 --> 00:38:59.696 A:middle
It allows or is able to
see your entire content.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:39:00.216 --> 00:39:03.196 A:middle
So in Single-Pass, as frames
come in, the encoder has

00:39:03.226 --> 00:39:05.166 A:middle
to make assumptions about
what might come next.

00:39:05.786 --> 00:39:07.996 A:middle
In Multi-Pass, it's already
seen all your content

00:39:07.996 --> 00:39:09.626 A:middle
so it can make much
better decisions there.

00:39:11.996 --> 00:39:14.456 A:middle
Third, it can change
decision that it's made.

00:39:14.716 --> 00:39:18.406 A:middle
So in Single-Pass, as soon as
the frame is emitted, that's it.

00:39:18.406 --> 00:39:20.066 A:middle
It can't -- it can
no longer change.

00:39:20.806 --> 00:39:23.986 A:middle
It can no longer change its
mind about what it's emitted.

00:39:24.986 --> 00:39:27.966 A:middle
In Multi-Pass, because the frame
database supports replacement,

00:39:28.316 --> 00:39:30.686 A:middle
each pass you can go through
and change its mind about how

00:39:30.686 --> 00:39:32.006 A:middle
to achieve optimal quality.

00:39:32.566 --> 00:39:35.046 A:middle
And as a result of this,

00:39:35.046 --> 00:39:37.476 A:middle
you really get optimal
quality per bit, so it's sort

00:39:37.476 --> 00:39:40.906 A:middle
of like having a very awesome
custom encoder for your content.

00:39:41.916 --> 00:39:45.246 A:middle
So that's how Multi-Pass
works and some more features.

00:39:45.296 --> 00:39:46.736 A:middle
Let's talk about new APIs.

00:39:47.966 --> 00:39:49.976 A:middle
So first off, let's
talk about AVFoundation.

00:39:50.636 --> 00:39:54.646 A:middle
In AVFoundation, we have a new
AVAssetExport Session property.

00:39:55.046 --> 00:39:57.366 A:middle
We have new pass descriptions
for AVAssetWriterInput

00:39:57.766 --> 00:39:59.696 A:middle
and we have reuse on
AVAssetReaderOutput.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:40:00.596 --> 00:40:02.276 A:middle
So first, let's go
over an overview

00:40:02.276 --> 00:40:03.586 A:middle
of AVAssetExport Session.

00:40:04.766 --> 00:40:07.296 A:middle
In AVAsset ExportSession,
you're going from a source file,

00:40:07.836 --> 00:40:10.556 A:middle
decoding them then
performing some operation

00:40:10.556 --> 00:40:12.856 A:middle
on those uncompressed
buffers, something like scaling

00:40:12.856 --> 00:40:15.236 A:middle
or color conversion,
and you're encoding them

00:40:15.236 --> 00:40:16.496 A:middle
and writing them
to a movie file.

00:40:17.036 --> 00:40:19.476 A:middle
So in this case, what does
AVAsset ExportSession provide?

00:40:20.376 --> 00:40:21.726 A:middle
Well, it does all this for you.

00:40:21.896 --> 00:40:26.456 A:middle
It's the easiest way to
transcode media on iOS and OS X.

00:40:26.686 --> 00:40:27.906 A:middle
So let's see what
we've added here.

00:40:29.246 --> 00:40:31.696 A:middle
So in AVAssetExportSession
multiple passes are taken care

00:40:31.696 --> 00:40:33.156 A:middle
of for you automatically.

00:40:33.236 --> 00:40:34.836 A:middle
There's no work you have to do

00:40:34.836 --> 00:40:36.546 A:middle
to send the samples
between passes.

00:40:37.066 --> 00:40:39.926 A:middle
And also, it falls
back to Single-Pass

00:40:39.926 --> 00:40:41.206 A:middle
if Multi-Pass isn't supported.

00:40:41.586 --> 00:40:44.156 A:middle
So if you choose a
preset that uses a codec

00:40:44.156 --> 00:40:46.256 A:middle
where Multi-Pass isn't
supported, don't worry,

00:40:46.296 --> 00:40:47.296 A:middle
it'll use Single-Pass.

00:40:48.566 --> 00:40:50.536 A:middle
And we have one new
property, Set SDS

00:40:50.536 --> 00:40:53.196 A:middle
and you're automatically opted
into Multi-Task, and that's it.

00:40:53.666 --> 00:40:56.426 A:middle
So for a large majority of
you, this is all you need.

00:40:57.616 --> 00:40:59.466 A:middle
Next, let's talk
about AVSWriter.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:41:00.356 --> 00:41:03.136 A:middle
So AVSWriter, you're coming
from uncompressed samples.

00:41:03.136 --> 00:41:05.126 A:middle
You want to compress them and
write them to a movie file.

00:41:06.356 --> 00:41:09.486 A:middle
You might be coming from an
OpenGL or OpenGL ES context.

00:41:09.826 --> 00:41:11.766 A:middle
In this case, what
does AVSWriter provide?

00:41:13.106 --> 00:41:15.686 A:middle
Well, it wraps this portion
going from the encoder

00:41:15.846 --> 00:41:17.186 A:middle
to the output movie file.

00:41:19.686 --> 00:41:23.406 A:middle
Another use case, it's
similar to AVSExportSession

00:41:23.446 --> 00:41:25.276 A:middle
where you're going from
a source movie file

00:41:25.346 --> 00:41:26.836 A:middle
to a destination app movie file

00:41:26.836 --> 00:41:28.636 A:middle
and modifying the
buffers in some way.

00:41:29.536 --> 00:41:32.116 A:middle
Well in this case, you're
going to use an AVSReaderOutput

00:41:32.116 --> 00:41:33.486 A:middle
and an AVSWriterInput.

00:41:33.486 --> 00:41:36.156 A:middle
You're responsible for sending
samples from one to the other.

00:41:36.686 --> 00:41:42.356 A:middle
Let's go over a new
AVSWriterInput APIs.

00:41:42.486 --> 00:41:45.566 A:middle
So like AVAssetExportSession,
you need to enable Multi-Pass,

00:41:46.036 --> 00:41:48.226 A:middle
so set SDS and you're
automatically opted in.

00:41:48.806 --> 00:41:52.356 A:middle
Then after you're done
appending samples,

00:41:52.726 --> 00:41:54.636 A:middle
you need to mark the
current pass as finished.

00:41:55.366 --> 00:41:56.326 A:middle
So what does this do?

00:41:56.676 --> 00:41:58.456 A:middle
Well, this triggers
the encoder analysis.

00:41:58.696 --> 00:42:01.756 A:middle
The encoder needs to decide if I
need to perform multiple passes


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:41:58.696 --> 00:42:01.756 A:middle
The encoder needs to decide if I
need to perform multiple passes

00:42:02.296 --> 00:42:04.916 A:middle
and if so, what time ranges.

00:42:05.026 --> 00:42:07.936 A:middle
So the encoder might say I want
to see the entire sequence again

00:42:08.156 --> 00:42:10.086 A:middle
or I want to see
subsets of the sequence.

00:42:11.126 --> 00:42:12.316 A:middle
So how does the encoder talk

00:42:12.316 --> 00:42:15.876 A:middle
about what time ranges it
wants for the next pass?

00:42:16.196 --> 00:42:18.576 A:middle
Well, that's through
AVSWriterInput PassDescription.

00:42:19.016 --> 00:42:21.826 A:middle
So in this case, we have
time from zero to three,

00:42:22.006 --> 00:42:25.596 A:middle
but not the sample at time
three, and samples from five

00:42:25.596 --> 00:42:27.606 A:middle
to seven, but not the
sample at time seven.

00:42:28.376 --> 00:42:32.136 A:middle
So a pass description is the
encoder's request for media

00:42:32.136 --> 00:42:35.686 A:middle
in the next pass, and it may
contain the entire sequence

00:42:35.756 --> 00:42:37.156 A:middle
or subsets of the sequence.

00:42:37.536 --> 00:42:41.316 A:middle
On a pass description, you
can query the time ranges

00:42:41.316 --> 00:42:44.046 A:middle
that the encoder has requested
by calling sourceTimeRanges.

00:42:47.616 --> 00:42:50.526 A:middle
All right, let's talk
about how AVSWriter uses

00:42:50.526 --> 00:42:51.496 A:middle
pass descriptions.

00:42:52.896 --> 00:42:55.626 A:middle
So when you trigger the encoder
analysis, the encoder needs

00:42:55.626 --> 00:42:57.836 A:middle
to reply with what
decisions it's made.

00:42:57.926 --> 00:43:01.396 A:middle
So you provide a block on this
method to allow the encoder


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:42:57.926 --> 00:43:01.396 A:middle
So you provide a block on this
method to allow the encoder

00:43:01.396 --> 00:43:02.926 A:middle
to give you that answer.

00:43:03.226 --> 00:43:05.396 A:middle
So this block is called when
the encoder makes a decision

00:43:05.396 --> 00:43:07.796 A:middle
about the next pass.

00:43:08.076 --> 00:43:10.396 A:middle
In that block, you can get
the new pass description,

00:43:10.396 --> 00:43:11.256 A:middle
the encoder's decision

00:43:11.256 --> 00:43:13.216 A:middle
about what content it
wants for the next pass.

00:43:13.506 --> 00:43:15.026 A:middle
Let's see how that
works all in a sample.

00:43:15.586 --> 00:43:18.606 A:middle
So here's our sample.

00:43:19.286 --> 00:43:21.116 A:middle
We have our block
callback that your provide.

00:43:23.036 --> 00:43:25.676 A:middle
Inside that callback you call
current pass description.

00:43:25.676 --> 00:43:27.876 A:middle
This asks the encoder
what time ranges it wants

00:43:27.876 --> 00:43:30.726 A:middle
for the next pass.

00:43:30.846 --> 00:43:33.626 A:middle
If the pass is none nil,
meaning the encoder wants data

00:43:33.626 --> 00:43:36.566 A:middle
for another pass, you
reconfigure your source.

00:43:36.656 --> 00:43:38.966 A:middle
So this is where the
source will send samples

00:43:39.316 --> 00:43:43.686 A:middle
to the AVSWriterInput, and then
you prepare the AVSWriterInput

00:43:43.736 --> 00:43:44.766 A:middle
for the next pass.

00:43:44.856 --> 00:43:45.516 A:middle
You're already familiar

00:43:45.516 --> 00:43:47.666 A:middle
with requestMediaDataWhen
ReadyOnQueue.

00:43:48.276 --> 00:43:53.036 A:middle
If the pass is nil, that means
the encoder has finished passes.

00:43:53.366 --> 00:43:53.916 A:middle
Then you're done.

00:43:53.986 --> 00:43:55.616 A:middle
You can mark your
input as finished.

00:43:56.136 --> 00:44:00.686 A:middle
All right, let's say you're
going from a source media file.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:43:56.136 --> 00:44:00.686 A:middle
All right, let's say you're
going from a source media file.

00:44:00.686 --> 00:44:01.996 A:middle
That was in our second example.

00:44:02.486 --> 00:44:05.036 A:middle
So we have new APIs
for AVSReaderOutput.

00:44:05.696 --> 00:44:07.726 A:middle
You can prepare your
source for Multi-Pass

00:44:07.726 --> 00:44:10.246 A:middle
by saying supportsRandomAccess
equals yes.

00:44:10.816 --> 00:44:14.276 A:middle
Then when the encoder
wants new time ranges,

00:44:14.276 --> 00:44:16.296 A:middle
you need to reconfigure
your AVSReaderOutput

00:44:16.376 --> 00:44:17.676 A:middle
to deliver those time ranges.

00:44:18.126 --> 00:44:20.106 A:middle
So that's
resetForReadingTimeRanges

00:44:20.106 --> 00:44:21.696 A:middle
with an NSArray of time ranges.

00:44:23.056 --> 00:44:25.226 A:middle
Finally, when all
passes have completed you

00:44:25.226 --> 00:44:26.826 A:middle
callMarkConfigurationAsFinal.

00:44:27.256 --> 00:44:30.016 A:middle
This allows the AVSReaderOutput
to transition

00:44:30.016 --> 00:44:34.006 A:middle
to its completed state so it
can start tearing itself down.

00:44:34.036 --> 00:44:36.026 A:middle
Right. Now there's a couple
short cuts you can use

00:44:36.026 --> 00:44:38.696 A:middle
if you're using AVSReader
and AVSWriter

00:44:38.696 --> 00:44:39.796 A:middle
in combination together.

00:44:41.256 --> 00:44:44.076 A:middle
So you can enable
AVSReaderOutput

00:44:44.076 --> 00:44:46.766 A:middle
if the AVSWriterInput
supports Multi-Pass.

00:44:47.086 --> 00:44:49.086 A:middle
So if the encoder
supports Multi-Pass,

00:44:49.696 --> 00:44:51.836 A:middle
we need to support random
access on the source.

00:44:52.366 --> 00:44:56.776 A:middle
Then you can reconfigure your
source to deliver samples

00:44:56.776 --> 00:44:58.236 A:middle
for the AVSWriterInput.

00:44:58.496 --> 00:45:01.266 A:middle
So with your readerOutput
call resetForReadingTimeRanges


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:44:58.496 --> 00:45:01.266 A:middle
So with your readerOutput
call resetForReadingTimeRanges

00:45:01.476 --> 00:45:03.276 A:middle
with the pass description's
time ranges.

00:45:03.746 --> 00:45:06.026 A:middle
Let's go over that
in the sample.

00:45:07.046 --> 00:45:09.266 A:middle
So instead of delivering
for an arbitrary source,

00:45:09.266 --> 00:45:11.706 A:middle
we now want to deliver for
our AVS at ReaderOuput.

00:45:11.706 --> 00:45:13.576 A:middle
So we call
resetForReadingTimeRanges

00:45:13.576 --> 00:45:16.206 A:middle
with the pass description
source time ranges.

00:45:20.976 --> 00:45:24.416 A:middle
Great. So that's the new API
and AVFoundation for Multi-Pass.

00:45:24.416 --> 00:45:26.196 A:middle
Let's talk next about
Video Toolbox.

00:45:27.146 --> 00:45:30.336 A:middle
So in Video Toolbox, our encoder
frame analysis data base,

00:45:30.836 --> 00:45:33.746 A:middle
we like to call this
our VTMultiPassStorage.

00:45:34.776 --> 00:45:37.266 A:middle
We also have additions
to VTCompressionSession,

00:45:37.266 --> 00:45:39.166 A:middle
which David introduced in
his portion of the talk,

00:45:39.776 --> 00:45:43.866 A:middle
and decompressed database, or
as we call it, the VTFrameSilo.

00:45:44.306 --> 00:45:46.576 A:middle
So let's go over
the architecture,

00:45:47.426 --> 00:45:50.176 A:middle
but this time replacing
the frame database

00:45:50.176 --> 00:45:51.406 A:middle
and the encoder database

00:45:51.406 --> 00:45:53.296 A:middle
with the objects
that we actually use.

00:45:54.066 --> 00:45:55.996 A:middle
So in this case, we
have our VTFrameSilo

00:45:55.996 --> 00:45:57.676 A:middle
and our VTMultiPassStorage.

00:45:59.766 --> 00:46:00.826 A:middle
We're done with this pass.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:45:59.766 --> 00:46:00.826 A:middle
We're done with this pass.

00:46:00.826 --> 00:46:02.596 A:middle
The encoder wants to
see samples again.

00:46:04.276 --> 00:46:06.606 A:middle
We're sending in those
samples that it requests.

00:46:09.556 --> 00:46:12.856 A:middle
Then we're finished and we can
tear down the VTMultiPassStorage

00:46:12.856 --> 00:46:19.006 A:middle
and the compression session and
we're left with our FrameSilo.

00:46:19.066 --> 00:46:20.646 A:middle
So this is where we
need to perform the copy

00:46:20.646 --> 00:46:22.566 A:middle
from the FrameSilo to
the output movie file.

00:46:23.096 --> 00:46:26.966 A:middle
Great, we have our
output movie file.

00:46:28.276 --> 00:46:31.476 A:middle
So first off, let's go over
what the VTMultiPassStorage is.

00:46:31.476 --> 00:46:33.256 A:middle
So this is the encoder analysis.

00:46:33.476 --> 00:46:35.276 A:middle
This is a pretty simple API.

00:46:35.416 --> 00:46:37.036 A:middle
First you create the storage

00:46:38.296 --> 00:46:40.606 A:middle
and then you close the
file once you're finished.

00:46:40.876 --> 00:46:43.996 A:middle
So that's all the API
that you need to use.

00:46:44.406 --> 00:46:46.566 A:middle
The data that's stored in
this is private to the encoder

00:46:46.566 --> 00:46:48.486 A:middle
and you don't have
to worry about it.

00:46:49.626 --> 00:46:52.256 A:middle
Next, let's talk about additions
to VTCompressionSession.

00:46:53.906 --> 00:46:56.336 A:middle
So first, you need to tell
the VTCompressionSession

00:46:56.336 --> 00:46:59.426 A:middle
and the encoder about
your VTMultiPassStorage.

00:46:59.546 --> 00:47:01.796 A:middle
So you can do that by
setting a property.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:46:59.546 --> 00:47:01.796 A:middle
So you can do that by
setting a property.

00:47:02.246 --> 00:47:04.386 A:middle
This will tell the
encoder to use MultiPass

00:47:04.386 --> 00:47:08.036 A:middle
and use this VTMultiPassStorage
for its frame analysis.

00:47:08.506 --> 00:47:12.706 A:middle
Next, we've added a couple
functions for MultiPass.

00:47:13.856 --> 00:47:18.506 A:middle
So you call begin pass before
you've appended any frames then

00:47:18.506 --> 00:47:19.946 A:middle
after you're done
appending frames

00:47:19.946 --> 00:47:21.776 A:middle
for that pass, you
call end pass.

00:47:22.456 --> 00:47:24.386 A:middle
End pass also asks the encoder

00:47:24.386 --> 00:47:25.796 A:middle
if another pass can
be performed.

00:47:27.816 --> 00:47:30.156 A:middle
So if another -- if the
encoder wants another pass

00:47:30.156 --> 00:47:32.446 A:middle
to be performed then you need
to ask it what time ranges

00:47:32.446 --> 00:47:34.156 A:middle
of samples it wants
for the next pass.

00:47:34.746 --> 00:47:37.006 A:middle
That's called
VTCompressionSession

00:47:37.006 --> 00:47:39.436 A:middle
GetTimeRangesFor NextPass
and you're given a count

00:47:39.436 --> 00:47:40.816 A:middle
and a C array of time ranges.

00:47:41.046 --> 00:47:44.776 A:middle
Now let's talk about
the VTFrameSilo.

00:47:44.776 --> 00:47:46.716 A:middle
So this is the compressed
frame store.

00:47:48.416 --> 00:47:52.776 A:middle
So like the other objects you
created, and then you want

00:47:52.776 --> 00:47:55.566 A:middle
to add samples to
this VTFrameSilo.

00:47:57.226 --> 00:47:59.796 A:middle
So frames will automatically
be replaced

00:47:59.796 --> 00:48:01.996 A:middle
if they have the same
presentation timestamp


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:47:59.796 --> 00:48:01.996 A:middle
if they have the same
presentation timestamp

00:48:01.996 --> 00:48:05.036 A:middle
and how this data is stored
is abstracted away from you

00:48:05.036 --> 00:48:06.446 A:middle
and you don't need
to worry about it.

00:48:06.446 --> 00:48:09.766 A:middle
It's a convenient
database for you to use.

00:48:09.886 --> 00:48:12.656 A:middle
Then you can prepare the
VTFrameSilo for the next pass.

00:48:12.736 --> 00:48:16.826 A:middle
This optimizes the
storage for the next pass.

00:48:19.756 --> 00:48:23.146 A:middle
Finally, let's talk about
the copy from the VTFrameSilo

00:48:23.286 --> 00:48:24.456 A:middle
to the output movie file.

00:48:25.766 --> 00:48:28.976 A:middle
So you can retrieve samples
for a given time range.

00:48:29.286 --> 00:48:32.086 A:middle
This allows you to get a
sample in a block callback

00:48:32.086 --> 00:48:34.496 A:middle
that you provide and add it
to your output movie file.

00:48:35.156 --> 00:48:38.166 A:middle
Right, that's the new
Video Toolbox APIs.

00:48:38.356 --> 00:48:40.456 A:middle
So I want to close with
a couple considerations.

00:48:41.756 --> 00:48:44.256 A:middle
So we've talked about
how MultiPass works

00:48:44.256 --> 00:48:47.546 A:middle
and what APIs you can use in
AVFoundation and Video Toolbox,

00:48:47.826 --> 00:48:49.556 A:middle
but we need to talk
about your use cases

00:48:49.556 --> 00:48:51.976 A:middle
and your priority in your app.

00:48:52.226 --> 00:48:54.236 A:middle
So if you're performing
real time encoding,

00:48:55.396 --> 00:48:56.856 A:middle
you should be using Single-Pass.

00:48:57.066 --> 00:48:59.256 A:middle
Real time encoding has
very specific deadlines

00:48:59.256 --> 00:49:01.046 A:middle
of how much compression can take


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:48:59.256 --> 00:49:01.046 A:middle
of how much compression can take

00:49:01.456 --> 00:49:04.486 A:middle
and Multi-Pass will perform
more passes over the time range,

00:49:04.516 --> 00:49:06.176 A:middle
so use Single-Pass
in these cases.

00:49:08.996 --> 00:49:11.416 A:middle
If you're concerned about
using the minimum amount

00:49:11.416 --> 00:49:14.696 A:middle
of power during encoding,
use Single-Pass.

00:49:15.076 --> 00:49:17.286 A:middle
Multiple passes will
take more power

00:49:17.286 --> 00:49:19.406 A:middle
and as will the encoder
analysis.

00:49:20.756 --> 00:49:23.186 A:middle
If you're concerned with
using the minimum amount

00:49:23.186 --> 00:49:25.046 A:middle
of temporary storage
during the encode

00:49:25.046 --> 00:49:28.466 A:middle
or transcode operation,
use Single-Pass.

00:49:28.636 --> 00:49:30.046 A:middle
The encoder analysis storage

00:49:30.046 --> 00:49:32.126 A:middle
and the frame database
will use more storage

00:49:32.126 --> 00:49:33.206 A:middle
than the output medial file.

00:49:34.856 --> 00:49:37.906 A:middle
However, if you're concerned
about having the best quality

00:49:37.906 --> 00:49:40.876 A:middle
for your content,
Multi-Pass is a great option.

00:49:41.496 --> 00:49:45.386 A:middle
If you want to be as close to
the target bit rate you set

00:49:45.386 --> 00:49:47.566 A:middle
on the VTCompressionSession
or AssetWriter

00:49:47.566 --> 00:49:50.346 A:middle
as possible, use Multi-Pass.

00:49:50.346 --> 00:49:54.176 A:middle
Multi-Pass can see all of the
portions of your source media

00:49:54.176 --> 00:49:56.496 A:middle
and so it can allocate bits
only where it needs to.

00:49:56.596 --> 00:49:57.926 A:middle
It's very smart in this sense.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:50:00.676 --> 00:50:04.046 A:middle
If it's okay to take longer
in your app, so if it's okay

00:50:04.046 --> 00:50:06.426 A:middle
for the encoder transfer
operation to take longer

00:50:06.426 --> 00:50:09.586 A:middle
for better quality,
Multi-Pass is a good option.

00:50:10.136 --> 00:50:13.176 A:middle
But the biggest takeaway
is that in your app,

00:50:13.566 --> 00:50:14.636 A:middle
you need to experiment.

00:50:14.636 --> 00:50:17.816 A:middle
So you need to think about
your use cases and your users

00:50:17.816 --> 00:50:19.846 A:middle
and if they're willing to wait
longer for better quality.

00:50:20.286 --> 00:50:24.896 A:middle
Next, let's talk about content.

00:50:27.376 --> 00:50:29.576 A:middle
So if you, if your
app has low quality

00:50:29.576 --> 00:50:32.856 A:middle
or low complexity content, think
of this like a title sequence

00:50:32.856 --> 00:50:34.416 A:middle
or a static image sequence.

00:50:36.676 --> 00:50:38.786 A:middle
Both Single-Pass and
Multi-Pass are going

00:50:38.786 --> 00:50:40.416 A:middle
to both give you
great quality here,

00:50:40.706 --> 00:50:42.516 A:middle
but Multi-Pass won't give
you much better quality

00:50:42.516 --> 00:50:43.256 A:middle
than Single-Pass.

00:50:43.256 --> 00:50:44.766 A:middle
These are both pretty
easy to encode.

00:50:46.136 --> 00:50:48.516 A:middle
Next, let's talk about
high complexity content.

00:50:48.646 --> 00:50:51.376 A:middle
So think of this as classic
encoder stress tests;

00:50:51.376 --> 00:50:53.066 A:middle
water, fire, explosions.

00:50:53.656 --> 00:50:56.856 A:middle
We all love to do
this, but Single-Pass

00:50:57.086 --> 00:50:59.376 A:middle
and Multi-Pass are
both going to do well,

00:50:59.376 --> 00:51:01.916 A:middle
but Multi-Pass probably won't
do much better than Single-Pass.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:50:59.376 --> 00:51:01.916 A:middle
but Multi-Pass probably won't
do much better than Single-Pass.

00:51:01.916 --> 00:51:04.566 A:middle
These are -- this kind of
content is hard for encoders

00:51:08.406 --> 00:51:10.346 A:middle
to encode -- or is
Multi-Pass a better decision?

00:51:11.396 --> 00:51:13.666 A:middle
Well, that's in varying
complexity, so think of this

00:51:13.666 --> 00:51:16.036 A:middle
as a feature-length
movie or a documentary

00:51:16.036 --> 00:51:18.276 A:middle
in Final Cut Pro or
an iMovie Trailer.

00:51:18.636 --> 00:51:21.816 A:middle
Might have low complexity
regions, a title sequence,

00:51:21.816 --> 00:51:23.326 A:middle
high complexity transitions.

00:51:23.786 --> 00:51:25.716 A:middle
Because there's a lot of
different kinds of content,

00:51:25.876 --> 00:51:28.056 A:middle
Multi-Pass is able to
analyze those sections

00:51:28.056 --> 00:51:30.446 A:middle
and really give you the
best quality per bit.

00:51:30.956 --> 00:51:34.146 A:middle
But again, the message
is with your content,

00:51:34.786 --> 00:51:35.846 A:middle
you need to experiment.

00:51:35.966 --> 00:51:38.106 A:middle
So you know your content
and you should know

00:51:38.106 --> 00:51:41.046 A:middle
if Multi-Pass will give you a
good benefit in these cases.

00:51:41.586 --> 00:51:45.586 A:middle
So let's go over what
we've talked about today.

00:51:45.586 --> 00:51:48.446 A:middle
AVFoundation provides powerful
APIs to operate on media,

00:51:48.516 --> 00:51:51.506 A:middle
and for most of you, these are
the APIs you will be using.

00:51:52.136 --> 00:51:55.336 A:middle
And when you need
the extra power,

00:51:55.426 --> 00:51:58.626 A:middle
Video Toolbox APIs provide
you direct media access.

00:51:58.626 --> 00:52:01.456 A:middle
If you fall into one of the use
cases that David talked about,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:51:58.626 --> 00:52:01.456 A:middle
If you fall into one of the use
cases that David talked about,

00:52:01.526 --> 00:52:04.926 A:middle
this is a good way
to use Video Toolbox.

00:52:06.696 --> 00:52:09.596 A:middle
Finally, Multi-Pass can
provide substantial quality

00:52:09.596 --> 00:52:11.976 A:middle
improvements, but you need
to think about your app,

00:52:12.206 --> 00:52:15.466 A:middle
your use cases and your
users before you enable it.

00:52:16.796 --> 00:52:19.886 A:middle
So for more information,
here's our Evangelism email.

00:52:20.076 --> 00:52:21.686 A:middle
You have AVFoundation
Documentation

00:52:21.686 --> 00:52:22.636 A:middle
and a programming guide.

00:52:23.056 --> 00:52:25.516 A:middle
We can answer your questions
on the developer forums.

00:52:26.296 --> 00:52:28.336 A:middle
For those of you that
are watching online,

00:52:28.336 --> 00:52:29.906 A:middle
a lot of these talks
have already happened.

00:52:29.906 --> 00:52:32.196 A:middle
If you're here live, so these
are the talks you might be

00:52:32.196 --> 00:52:32.836 A:middle
interested in.

00:52:33.156 --> 00:52:34.926 A:middle
Thanks everyone and have
a good rest of your day.

00:52:35.516 --> 00:52:42.300 A:middle
[ Applause ]

