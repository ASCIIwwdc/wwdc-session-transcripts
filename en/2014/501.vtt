WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:13.046 --> 00:00:14.086 A:middle
&gt;&gt; Good morning everyone.

00:00:14.436 --> 00:00:17.996 A:middle
And welcome to Session 501,
"What's New with Core Audio".

00:00:18.026 --> 00:00:19.766 A:middle
I'm the first emcee
on the mic today.

00:00:19.766 --> 00:00:20.556 A:middle
My name is Torrey.

00:00:20.996 --> 00:00:23.246 A:middle
And we have been very busy.

00:00:23.246 --> 00:00:25.456 A:middle
We have a lot of interesting
things to share with you today.

00:00:26.026 --> 00:00:29.056 A:middle
We're going to start off by
talking about some enhancements

00:00:29.056 --> 00:00:30.516 A:middle
that we've made to
Core MIDI and how

00:00:30.516 --> 00:00:32.555 A:middle
that affects you and your apps.

00:00:32.946 --> 00:00:34.856 A:middle
Then we'll move on to
Inter-App Audio views,

00:00:35.426 --> 00:00:38.576 A:middle
and then we will have a large
section on the new and improved

00:00:38.576 --> 00:00:41.316 A:middle
and Enhanced AV Foundation
audio.

00:00:41.316 --> 00:00:44.246 A:middle
And that will include a talk
about the Audio Unit Manager,

00:00:44.766 --> 00:00:47.606 A:middle
AVAudioSession, some
Utility classes,

00:00:47.896 --> 00:00:50.086 A:middle
and that last bullet point
there, AVAudioEngine,

00:00:50.086 --> 00:00:53.706 A:middle
is such a large topic
that it gets a session all

00:00:53.706 --> 00:00:55.426 A:middle
to itself directly
following this one

00:00:55.426 --> 00:00:58.676 A:middle
in the same room
starting at 10:15 a.m.

00:00:59.036 --> 00:01:00.516 A:middle
So without further ado,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:59.036 --> 00:01:00.516 A:middle
So without further ado,

00:01:01.566 --> 00:01:03.436 A:middle
let's talk about what's
new with Core MIDI.

00:01:03.846 --> 00:01:08.146 A:middle
If you have a studio, a
music studio, that you use

00:01:08.146 --> 00:01:11.116 A:middle
to make music, it may
look something like this.

00:01:11.836 --> 00:01:15.096 A:middle
So maybe there's a Mac in the
center of it, or an iOS device,

00:01:15.096 --> 00:01:17.946 A:middle
they're also very capable to
be the center of your studio.

00:01:18.476 --> 00:01:21.066 A:middle
And connected to it may be
several USB MIDI devices,

00:01:21.216 --> 00:01:23.796 A:middle
controllers, break out
boxes that are connected

00:01:24.136 --> 00:01:29.146 A:middle
by a 5-pin DIN to legacy
equipment, musical instruments,

00:01:29.206 --> 00:01:31.506 A:middle
and then also you may have
a network session going.

00:01:32.296 --> 00:01:35.896 A:middle
Well, beginning in iOS
8 and Mac OS X Yosemite,

00:01:36.096 --> 00:01:38.176 A:middle
your studio can start
to look like this.

00:01:38.956 --> 00:01:42.216 A:middle
So imagine after making a very
quick Bluetooth connection

00:01:42.216 --> 00:01:44.436 A:middle
and sitting down on a couch
on the other side of the room

00:01:44.436 --> 00:01:46.836 A:middle
of your studio and
controlling all of your music.

00:01:47.226 --> 00:01:49.966 A:middle
That's what you'll be able to
do with MIDI over Bluetooth.

00:01:51.026 --> 00:01:54.986 A:middle
So starting in iOS 8 and in Mac
OS X Yosemite, you'll be able

00:01:54.986 --> 00:01:57.466 A:middle
to send and receive MIDI data

00:01:57.466 --> 00:02:01.666 A:middle
over Bluetooth Low Energy
connections on any device or Mac


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:01:57.466 --> 00:02:01.666 A:middle
over Bluetooth Low Energy
connections on any device or Mac

00:02:01.736 --> 00:02:03.906 A:middle
that has native Bluetooth
Low Energy support.

00:02:05.206 --> 00:02:07.176 A:middle
The connections you
established is secure meaning

00:02:07.176 --> 00:02:08.446 A:middle
that pairing is enforced.

00:02:08.675 --> 00:02:10.175 A:middle
No one can connect
to your devices

00:02:10.175 --> 00:02:11.426 A:middle
without your explicit consent,

00:02:12.266 --> 00:02:15.706 A:middle
and after the connection is
established, it just appears

00:02:15.706 --> 00:02:18.426 A:middle
as an ordinary MIDI device that
any application that knows how

00:02:18.426 --> 00:02:20.536 A:middle
to communicate with a
MIDI device can talk to.

00:02:20.536 --> 00:02:23.996 A:middle
So to talk a little bit more
about how this connection works

00:02:23.996 --> 00:02:27.216 A:middle
over Bluetooth, I want to talk
about the two key roles involved

00:02:27.216 --> 00:02:28.086 A:middle
in a Bluetooth connection.

00:02:28.916 --> 00:02:30.716 A:middle
There's the Central
and the Peripheral.

00:02:31.256 --> 00:02:33.586 A:middle
You already have some
familiarity with this.

00:02:33.746 --> 00:02:35.166 A:middle
Maybe not with these names.

00:02:35.516 --> 00:02:37.906 A:middle
You can view your Central
as like your iPhone

00:02:37.946 --> 00:02:40.036 A:middle
and your Peripheral as like
your Bluetooth earpiece.

00:02:40.706 --> 00:02:44.716 A:middle
The Peripheral's job is to
become discoverable and say,

00:02:44.716 --> 00:02:45.526 A:middle
"Hey, I can do something.

00:02:45.526 --> 00:02:46.256 A:middle
You can connect to me."

00:02:47.076 --> 00:02:48.596 A:middle
So for Bluetooth MIDI,

00:02:48.796 --> 00:02:53.416 A:middle
the peripheral side will
advertise the MIDI capabilities.

00:02:53.416 --> 00:02:54.536 A:middle
It'll say, "Hey, I can do MIDI.

00:02:54.536 --> 00:02:55.586 A:middle
You can connect to me now."

00:02:55.886 --> 00:02:57.076 A:middle
And then that side waits.

00:02:57.716 --> 00:03:00.316 A:middle
The Central can scan
for a device


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:02:57.716 --> 00:03:00.316 A:middle
The Central can scan
for a device

00:03:00.516 --> 00:03:03.626 A:middle
that says they can do MIDI and
then establish a connection.

00:03:04.756 --> 00:03:07.216 A:middle
After that Bluetooth
connection has been established,

00:03:07.676 --> 00:03:10.656 A:middle
MIDI data can be
shuttled bi-directionally

00:03:10.656 --> 00:03:11.616 A:middle
between both of these.

00:03:12.476 --> 00:03:14.296 A:middle
Now in order to have a
Bluetooth connection you have

00:03:14.296 --> 00:03:16.706 A:middle
to have one Central, and you
have to have one Peripheral.

00:03:16.976 --> 00:03:20.806 A:middle
And we allow Macs and iOS
devices to play either role.

00:03:20.866 --> 00:03:23.716 A:middle
So you can connect Mac
to Mac, iOS to iOS,

00:03:24.026 --> 00:03:25.736 A:middle
Mac to iOS, and vice versa.

00:03:27.306 --> 00:03:29.396 A:middle
So what does this mean for
you and your application?

00:03:29.806 --> 00:03:32.586 A:middle
If you are writing a
Mac OS X application,

00:03:32.586 --> 00:03:37.116 A:middle
the good news is you are
already ready, already ready.

00:03:37.866 --> 00:03:40.466 A:middle
This is the MIDI Studio
Panel from Audio MIDI Setup,

00:03:40.466 --> 00:03:42.076 A:middle
which I'm sure you're
all familiar with.

00:03:42.316 --> 00:03:44.806 A:middle
If you look there
you'll see a new icon,

00:03:45.196 --> 00:03:46.746 A:middle
the Bluetooth Configuration
icon.

00:03:47.216 --> 00:03:48.876 A:middle
If you double click that icon,

00:03:49.006 --> 00:03:50.496 A:middle
you are going to
get a new window.

00:03:51.156 --> 00:03:55.116 A:middle
And this window will allow
you to play either the Central

00:03:55.116 --> 00:03:56.156 A:middle
or the Peripheral role.

00:03:56.406 --> 00:03:58.706 A:middle
If you look at kind of the
top third of the window,

00:03:58.706 --> 00:04:00.846 A:middle
you'll see where there's a
button that says Advertise.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:58.706 --> 00:04:00.846 A:middle
you'll see where there's a
button that says Advertise.

00:04:00.846 --> 00:04:04.026 A:middle
And click Advertise to become
discoverable as Fresh Air.

00:04:04.026 --> 00:04:05.386 A:middle
That's a name that
you can modify.

00:04:05.696 --> 00:04:08.516 A:middle
Fresh Air is the name of my
MacBook Air because it's fresh.

00:04:09.446 --> 00:04:13.076 A:middle
Then the bottom two thirds
of it is the central view.

00:04:13.456 --> 00:04:16.016 A:middle
If someone is advertising, "Hey,
I can do MIDI," it will show

00:04:16.016 --> 00:04:17.836 A:middle
up in the bottom,
you click Connect

00:04:17.836 --> 00:04:18.986 A:middle
to establish the connection.

00:04:19.416 --> 00:04:20.386 A:middle
The pairing will happen,

00:04:20.386 --> 00:04:22.766 A:middle
and then a new MIDI device
will appear in the setup

00:04:22.766 --> 00:04:25.496 A:middle
that any application that
uses MIDI devices can see

00:04:25.636 --> 00:04:26.346 A:middle
and communicate will.

00:04:27.276 --> 00:04:30.016 A:middle
Now on iOS, there is
no audio MIDI setup.

00:04:30.126 --> 00:04:32.306 A:middle
So how do you manage your
Bluetooth MIDI connections?

00:04:32.786 --> 00:04:35.776 A:middle
You'll be using new
CoreAudioKit View Controllers.

00:04:36.626 --> 00:04:39.486 A:middle
There are 2 new CoreAudioKit
View Controllers

00:04:39.486 --> 00:04:40.756 A:middle
that you can add to
your application.

00:04:41.056 --> 00:04:43.636 A:middle
One of them that allows you to
play the role of the Central,

00:04:43.636 --> 00:04:46.616 A:middle
which means you scan and connect
and another that allows you

00:04:46.616 --> 00:04:47.746 A:middle
to play the role of Peripheral,

00:04:47.816 --> 00:04:49.386 A:middle
which means you advertise
and wait.

00:04:49.386 --> 00:04:52.936 A:middle
If you establish a
connection between 2 devices

00:04:52.936 --> 00:04:55.656 A:middle
over Bluetooth MIDI, and they're
not communicating for a while

00:04:55.656 --> 00:04:57.186 A:middle
and they are unused
by the application,

00:04:57.356 --> 00:04:59.506 A:middle
after several minutes we
will terminate the Bluetooth

00:04:59.506 --> 00:05:01.036 A:middle
connection to save power.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:59.506 --> 00:05:01.036 A:middle
connection to save power.

00:05:02.106 --> 00:05:04.716 A:middle
So what does all of this
look like in practice?

00:05:05.286 --> 00:05:07.216 A:middle
I'm going to show
you a short UI demo

00:05:08.136 --> 00:05:11.846 A:middle
of how users would use
this in their studios.

00:05:12.326 --> 00:05:14.896 A:middle
OK. I've got my demo
machine ready here.

00:05:15.406 --> 00:05:18.306 A:middle
And what I'm going
to do is I'm going

00:05:18.306 --> 00:05:21.266 A:middle
to launch audio MIDI setup.

00:05:23.836 --> 00:05:25.706 A:middle
This is the audio window.

00:05:25.706 --> 00:05:28.506 A:middle
We'll close this, and we
will go to the MIDI window.

00:05:28.506 --> 00:05:31.626 A:middle
Now if you'll notice here

00:05:31.626 --> 00:05:33.146 A:middle
in the MIDI window
there's this new Bluetooth

00:05:33.146 --> 00:05:34.336 A:middle
Configuration panel.

00:05:34.666 --> 00:05:37.046 A:middle
So if I double click
this, then I will see

00:05:37.366 --> 00:05:40.186 A:middle
that there are currently
no advertising Bluetooth

00:05:40.186 --> 00:05:40.886 A:middle
MIDI devices.

00:05:42.356 --> 00:05:44.326 A:middle
I want my Mac to play
the role of Central.

00:05:44.536 --> 00:05:46.056 A:middle
So I'm going to wait for someone

00:05:46.056 --> 00:05:47.336 A:middle
to become available
to connect to.

00:05:48.406 --> 00:05:51.606 A:middle
And I'm going to use
my iPad for that.

00:05:54.016 --> 00:05:55.396 A:middle
So here's my iPad.

00:05:55.496 --> 00:05:59.146 A:middle
And this is a little test
application that we wrote

00:05:59.146 --> 00:06:02.146 A:middle
to implement the
CoreAudioKit View Controllers


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:05:59.146 --> 00:06:02.146 A:middle
to implement the
CoreAudioKit View Controllers

00:06:02.146 --> 00:06:03.086 A:middle
that I talked about earlier.

00:06:03.286 --> 00:06:05.236 A:middle
I am going to go to
Advertisement Setup,

00:06:05.236 --> 00:06:06.786 A:middle
and this will give me
the Peripheral view.

00:06:07.166 --> 00:06:09.606 A:middle
If you look here at the
top, you see the name

00:06:09.606 --> 00:06:12.246 A:middle
of this iPad Air
is iPad Air MIDI.

00:06:12.696 --> 00:06:14.716 A:middle
If I want to change this
name I could tap the "i",

00:06:15.496 --> 00:06:16.476 A:middle
but I'm OK with that name.

00:06:17.226 --> 00:06:19.526 A:middle
And then I will say
Advertise the MIDI Service.

00:06:20.386 --> 00:06:22.836 A:middle
Now after I'm advertising
the MIDI service,

00:06:23.836 --> 00:06:27.376 A:middle
back on the Mac OS X machine
you'll see iPad Air MIDI has

00:06:27.376 --> 00:06:28.086 A:middle
shown up here.

00:06:28.086 --> 00:06:32.866 A:middle
If I click connect, after a few
minutes you'll see a new device

00:06:32.866 --> 00:06:33.886 A:middle
appear in the MIDI setup.

00:06:34.556 --> 00:06:38.636 A:middle
I'm going to launch Main Stage

00:06:38.636 --> 00:06:43.476 A:middle
because Main Stage can receive
MIDI notes and play back audio.

00:06:46.316 --> 00:06:47.936 A:middle
Go into Performance
Mode [music playing].

00:06:48.436 --> 00:06:53.816 A:middle
OK. So a big confession
here, I don't play keys.

00:06:54.326 --> 00:06:55.856 A:middle
But I do have an application

00:06:55.856 --> 00:06:59.476 A:middle
that plays keys really well
called Arpeggionome Pro.

00:06:59.806 --> 00:07:03.496 A:middle
So I'm going to launch that,
and I'm going to use it


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:59.806 --> 00:07:03.496 A:middle
So I'm going to launch that,
and I'm going to use it

00:07:03.496 --> 00:07:11.996 A:middle
to send MIDI data over
to the Main Stage 3.

00:07:13.206 --> 00:07:15.066 A:middle
OK. Now one thing I want

00:07:15.066 --> 00:07:18.656 A:middle
to do really quickly here is
check my connection status

00:07:18.656 --> 00:07:21.196 A:middle
because I left it inactive
for quite a while here.

00:07:21.406 --> 00:07:27.916 A:middle
So I'm going to go back and make
myself advertise one more time.

00:07:28.516 --> 00:07:30.546 A:middle
[ Music Playing ]

00:07:31.046 --> 00:07:40.096 A:middle
So now this is live MIDI data
being sent over Bluetooth.

00:07:40.096 --> 00:07:43.916 A:middle
If I could get that volume
a little louder please.

00:07:45.426 --> 00:07:47.596 A:middle
Thank you.

00:07:48.726 --> 00:07:52.606 A:middle
So if I wanted to do this
preset, it's called Epic Fall.

00:07:54.336 --> 00:07:56.386 A:middle
And it is epic.

00:07:57.066 --> 00:08:00.646 A:middle
So that's Bluetooth
being sent over MIDI.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:07:57.066 --> 00:08:00.646 A:middle
So that's Bluetooth
being sent over MIDI.

00:08:00.886 --> 00:08:03.656 A:middle
And also this sends not
only the controller data,

00:08:04.006 --> 00:08:07.836 A:middle
but it also sends the SISX
data that you may have

00:08:07.906 --> 00:08:09.256 A:middle
or any other type of MIDI.

00:08:09.846 --> 00:08:13.066 A:middle
A few final words before
I turn the mic over.

00:08:13.766 --> 00:08:16.426 A:middle
This Bluetooth, being
able to connect

00:08:16.846 --> 00:08:21.086 A:middle
with Bluetooth MIDI connections
will work on both OS X Yosemite

00:08:21.086 --> 00:08:24.166 A:middle
and iOS 8 using those
view controllers

00:08:24.166 --> 00:08:25.886 A:middle
that I told you about.

00:08:25.886 --> 00:08:27.616 A:middle
And it will work
on any Mac, iPhone,

00:08:27.616 --> 00:08:30.066 A:middle
or iPad that has native
Bluetooth Low Energy support.

00:08:30.496 --> 00:08:31.996 A:middle
So now I'm going to tell
you which ones those are.

00:08:31.996 --> 00:08:36.626 A:middle
For Macs, any Mac that was
manufactured in 2012 or later

00:08:36.946 --> 00:08:38.586 A:middle
and a mixed bag of
Macs that were released

00:08:38.586 --> 00:08:41.116 A:middle
in 2011 also have native
Bluetooth Low Energy support.

00:08:41.956 --> 00:08:45.086 A:middle
For the iPhone, the iPhone 4S
and greater have Bluetooth LE.

00:08:45.186 --> 00:08:48.916 A:middle
For the iPad, the first iPad
with the Retina display has LE

00:08:48.916 --> 00:08:50.396 A:middle
and the ones from that point

00:08:50.806 --> 00:08:53.826 A:middle
and all iPad Minis have native
Bluetooth Low Energy support.

00:08:54.336 --> 00:08:56.036 A:middle
So this will work on
all of those systems.

00:08:56.886 --> 00:08:59.636 A:middle
Also, the connection
is really low latency.

00:08:59.636 --> 00:09:00.516 A:middle
It's very sensitive.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:08:59.636 --> 00:09:00.516 A:middle
It's very sensitive.

00:09:01.356 --> 00:09:05.676 A:middle
And the Bluetooth LE bandwidth
greatly exceeds the minimum MIDI

00:09:05.676 --> 00:09:09.546 A:middle
bandwidth requirement for MIDI
of 3,125 bytes per second.

00:09:10.116 --> 00:09:11.806 A:middle
Standardization is in the works.

00:09:11.806 --> 00:09:14.286 A:middle
We're working with standards
bodies to standardize this

00:09:14.286 --> 00:09:16.316 A:middle
so more people can get in on it.

00:09:16.316 --> 00:09:17.686 A:middle
And the key takeaway for you is

00:09:17.686 --> 00:09:19.896 A:middle
if you're making your
iOS applications,

00:09:20.296 --> 00:09:24.246 A:middle
please start adding these
Bluetooth UI View controllers

00:09:24.666 --> 00:09:26.206 A:middle
immediately to your applications

00:09:26.236 --> 00:09:30.256 A:middle
so that users can manage
Bluetooth MIDI connections using

00:09:30.256 --> 00:09:31.126 A:middle
your app.

00:09:31.436 --> 00:09:32.896 A:middle
And the person who is
going to show you how to do

00:09:32.896 --> 00:09:36.296 A:middle
that is my colleague and
homeboy Michael Hopkins.

00:09:36.526 --> 00:09:37.696 A:middle
And I'll turn the
mic over to him.

00:09:38.436 --> 00:09:39.556 A:middle
&gt;&gt; Thank you very much, Torrey.

00:09:40.196 --> 00:09:43.806 A:middle
I'd like to talk to you this
morning about a new framework

00:09:44.186 --> 00:09:46.636 A:middle
for iOS called CoreAudioKit.

00:09:47.096 --> 00:09:50.996 A:middle
This framework provides
standardized user interface

00:09:50.996 --> 00:09:55.416 A:middle
elements for you to add to
your application to do things

00:09:55.416 --> 00:09:59.136 A:middle
like show the MIDI
over Bluetooth LE UI

00:09:59.136 --> 00:10:03.536 A:middle
that Torrey just demonstrated as
well as some new views for those


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:09:59.136 --> 00:10:03.536 A:middle
that Torrey just demonstrated as
well as some new views for those

00:10:03.536 --> 00:10:05.306 A:middle
of you that are doing
Inter-App Audio.

00:10:06.436 --> 00:10:09.746 A:middle
We've designed these so that
we do all the heavy lifting

00:10:09.746 --> 00:10:12.236 A:middle
so that you don't have to worry
about rolling your own UI,

00:10:12.236 --> 00:10:15.566 A:middle
and you can just concentrate
on what makes your app unique.

00:10:16.166 --> 00:10:18.856 A:middle
Therefore, they are very easy
to adopt with a minimal amount

00:10:18.856 --> 00:10:24.126 A:middle
of source code, and they
work on both iPhone and iPad.

00:10:26.006 --> 00:10:29.736 A:middle
Looking specifically about these
interface elements for MIDI

00:10:29.736 --> 00:10:37.366 A:middle
over Bluetooth LE, as Torrey
showed you we have separated

00:10:37.366 --> 00:10:39.436 A:middle
these into two different
view controllers

00:10:39.436 --> 00:10:41.766 A:middle
so that you can choose
which one is appropriate

00:10:41.766 --> 00:10:44.606 A:middle
for your own application
or you can use both.

00:10:45.046 --> 00:10:48.466 A:middle
For example, if you use the UI
split view controller you can

00:10:48.466 --> 00:10:50.536 A:middle
have those both visible
at the same time.

00:10:51.136 --> 00:10:53.806 A:middle
The first one is
the CABTMIDILocal

00:10:53.806 --> 00:10:55.096 A:middle
PeripheralViewController.

00:10:55.226 --> 00:10:57.116 A:middle
That's quite a mouthful
this early in the morning.

00:10:58.636 --> 00:11:01.646 A:middle
If you want to advertise
your iOS device


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:58.636 --> 00:11:01.646 A:middle
If you want to advertise
your iOS device

00:11:01.646 --> 00:11:04.486 A:middle
as a Peripheral,
you use this class.

00:11:06.076 --> 00:11:09.676 A:middle
The source code for adopting
this is very straightforward.

00:11:10.306 --> 00:11:12.536 A:middle
You create a new instance
of that view controller,

00:11:13.266 --> 00:11:18.556 A:middle
get the navigation controller
object for your app and push

00:11:18.556 --> 00:11:20.966 A:middle
that view controller
onto the stack.

00:11:22.856 --> 00:11:27.696 A:middle
The CABTMIDICentral
ViewController is required

00:11:27.696 --> 00:11:28.926 A:middle
if you want to discover

00:11:28.926 --> 00:11:31.326 A:middle
and connect two Bluetooth
Peripherals.

00:11:32.566 --> 00:11:34.486 A:middle
And you use that
in the same way.

00:11:34.566 --> 00:11:37.456 A:middle
You create the view
controller and push it

00:11:37.456 --> 00:11:38.986 A:middle
onto your view controller stack.

00:11:40.026 --> 00:11:43.386 A:middle
Now I'd like to switch over
and talk about Inter-App Audio.

00:11:44.086 --> 00:11:47.576 A:middle
For those of you that weren't
present last year at WWDC,

00:11:47.576 --> 00:11:51.086 A:middle
we had a session talking
about this new technology

00:11:51.086 --> 00:11:52.916 A:middle
that we released with iOS 7.

00:11:53.976 --> 00:11:57.526 A:middle
In review, Inter-App Audio
allows you to stream audio

00:11:57.526 --> 00:11:59.986 A:middle
between one or more
apps in real time.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:00.556 --> 00:12:05.766 A:middle
A host application can discover
available node apps even

00:12:05.766 --> 00:12:06.676 A:middle
if they are not running.

00:12:08.046 --> 00:12:10.356 A:middle
And please refer to
last year's session,

00:12:11.516 --> 00:12:15.026 A:middle
"What's New in Core Audio"
Session 206 for further details.

00:12:16.506 --> 00:12:18.656 A:middle
But looking at how this
works with the Host App

00:12:18.656 --> 00:12:22.086 A:middle
and a connected Node App, the
Node App can be an instrument,

00:12:22.086 --> 00:12:23.816 A:middle
an effect, or a generator.

00:12:24.546 --> 00:12:27.526 A:middle
And the Host App and Node App
can send audio back and forth.

00:12:28.036 --> 00:12:30.846 A:middle
In the case of an instrument,

00:12:30.846 --> 00:12:34.336 A:middle
the Host App can also send a
MIDI to that instrument app

00:12:34.916 --> 00:12:36.306 A:middle
and receive audio back.

00:12:36.916 --> 00:12:43.176 A:middle
The two user interface
elements that we provide

00:12:43.416 --> 00:12:48.206 A:middle
in iOS 8 are firstly the
Inter-App Audio switch review,

00:12:48.706 --> 00:12:52.186 A:middle
which provides an easy way to
see all the Inter-App Audio apps

00:12:52.186 --> 00:12:55.046 A:middle
that are connected
together and switch

00:12:55.046 --> 00:12:57.176 A:middle
between them using a
simple tap gesture.

00:12:59.516 --> 00:13:03.766 A:middle
We also provide an Inter-App
Audio Host Transport view.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:59.516 --> 00:13:03.766 A:middle
We also provide an Inter-App
Audio Host Transport view.

00:13:04.576 --> 00:13:07.346 A:middle
This displays the transport
of the host you're connected

00:13:07.346 --> 00:13:09.696 A:middle
to in your Node App
and allows you

00:13:09.696 --> 00:13:13.136 A:middle
to control the transport
playback, rewind,

00:13:13.806 --> 00:13:16.376 A:middle
and record in addition
to displaying

00:13:16.376 --> 00:13:21.156 A:middle
where in the Host Transport you
are via that numeric time code.

00:13:21.656 --> 00:13:25.026 A:middle
And I'd like to show a
demo of this in action.

00:13:25.746 --> 00:13:28.086 A:middle
I have 3 different
applications here

00:13:28.086 --> 00:13:31.106 A:middle
that we'll be using together in
our Inter-App Audio Scenario.

00:13:31.616 --> 00:13:33.616 A:middle
The first of which
is GarageBand,

00:13:33.616 --> 00:13:35.876 A:middle
which is the current
version of that application

00:13:35.876 --> 00:13:38.046 A:middle
that I've downloaded
from the iTunes store.

00:13:39.086 --> 00:13:43.596 A:middle
I also have a Delay
application and a Sampler.

00:13:44.256 --> 00:13:46.186 A:middle
Let's take a look at
the Sampler first.

00:13:47.336 --> 00:13:51.166 A:middle
This allows me to trigger sample
playback via the keyboard.

00:13:52.516 --> 00:13:56.706 A:middle
[ Music ]

00:13:57.206 --> 00:13:59.616 A:middle
So now let's go ahead and
connect this to GarageBand.

00:13:59.806 --> 00:14:01.226 A:middle
I'm going to launch GarageBand.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:13:59.806 --> 00:14:01.226 A:middle
I'm going to launch GarageBand.

00:14:07.796 --> 00:14:11.236 A:middle
I'm going to connect
to that Sampler app,

00:14:11.366 --> 00:14:13.876 A:middle
and now this is connected
to GarageBand.

00:14:14.556 --> 00:14:17.096 A:middle
So the first thing I'd like to
demonstrate is the Inter-App

00:14:17.096 --> 00:14:19.136 A:middle
Audio Switch Review in action,

00:14:19.726 --> 00:14:21.946 A:middle
which this application
has implemented

00:14:22.136 --> 00:14:24.286 A:middle
as visible via a button.

00:14:25.076 --> 00:14:27.016 A:middle
I press that, and
you can see now

00:14:27.016 --> 00:14:29.746 A:middle
that we have two Nodes shown.

00:14:30.116 --> 00:14:33.176 A:middle
The Host, as well as
our current application.

00:14:33.176 --> 00:14:36.816 A:middle
And I can switch over to
GarageBand simply by tapping.

00:14:37.856 --> 00:14:38.826 A:middle
I'm going to add

00:14:38.826 --> 00:14:44.426 A:middle
in an additional Inter-App
Audio App, the Delay effect.

00:14:44.426 --> 00:14:51.106 A:middle
And now if I was to switch
over to this application

00:14:51.106 --> 00:14:53.996 A:middle
without using the Switch
Review, I could double tap

00:14:53.996 --> 00:14:58.476 A:middle
on my Home key, look, and
try to find that application.

00:14:58.476 --> 00:14:59.246 A:middle
Where is it?

00:14:59.246 --> 00:15:00.616 A:middle
It's difficult to find.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:14:59.246 --> 00:15:00.616 A:middle
It's difficult to find.

00:15:00.996 --> 00:15:04.906 A:middle
And that's why we've provided
the Inter-App Switch Review.

00:15:05.466 --> 00:15:07.066 A:middle
In this application, the Delay,

00:15:07.066 --> 00:15:09.016 A:middle
you can see that on the
lower right-hand corner.

00:15:09.506 --> 00:15:13.726 A:middle
And now that is showing
our Host, the Sampler,

00:15:13.726 --> 00:15:15.486 A:middle
as well as our current effect.

00:15:16.226 --> 00:15:20.766 A:middle
So it's very easy to
switch back and forth.

00:15:20.766 --> 00:15:22.846 A:middle
And you can see that it
just showed up there.

00:15:23.156 --> 00:15:25.166 A:middle
So that's the first view
I'd like to demonstrate.

00:15:25.796 --> 00:15:27.606 A:middle
And if I play back
on my keyboard,

00:15:29.416 --> 00:15:31.346 A:middle
we can hear that we're
now getting that Delay.

00:15:31.346 --> 00:15:36.136 A:middle
And this is interesting because
we have, we're sending audio

00:15:36.136 --> 00:15:39.536 A:middle
from the host to our Sampler,
and then through an effect

00:15:39.796 --> 00:15:41.326 A:middle
to playing that delay,
and then back.

00:15:42.246 --> 00:15:44.896 A:middle
Now the second view, the
Transport view, you'll see just

00:15:44.896 --> 00:15:48.826 A:middle
above that view, let me hide
that for you, and that allows me

00:15:48.826 --> 00:15:50.626 A:middle
to control the transport of
the Host [music playing].

00:15:50.626 --> 00:15:55.976 A:middle
I can do recording.

00:15:56.516 --> 00:15:59.786 A:middle
[ Music Playing ]


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:00.286 --> 00:16:01.506 A:middle
Sorry. I'm no Dr. Dre.

00:16:01.506 --> 00:16:04.476 A:middle
It's too early in the morning
for that, but you get the idea.

00:16:04.476 --> 00:16:06.366 A:middle
And these are the views

00:16:06.366 --> 00:16:08.346 A:middle
that we're providing
for your benefit.

00:16:08.346 --> 00:16:09.396 A:middle
So please adopt those

00:16:09.396 --> 00:16:11.556 A:middle
to add this functionality
to your application.

00:16:12.416 --> 00:16:15.836 A:middle
OK. So the goal between these
user interface elements are

00:16:15.836 --> 00:16:19.936 A:middle
to provide a consistent
experience for your customers.

00:16:20.156 --> 00:16:22.586 A:middle
You do have some flexibility
in controlling some

00:16:22.586 --> 00:16:25.416 A:middle
of the visual appearances
of those controls.

00:16:25.946 --> 00:16:28.066 A:middle
They support a number
of different sizes.

00:16:28.066 --> 00:16:31.526 A:middle
So if you want a ginormous
UI you can have that,

00:16:31.526 --> 00:16:33.666 A:middle
or if you want them very
small you can do that.

00:16:34.126 --> 00:16:36.656 A:middle
The source code, as I'm going
to show you, is very easy

00:16:36.656 --> 00:16:37.926 A:middle
to add to your application.

00:16:38.336 --> 00:16:41.846 A:middle
And because these are subclasses
of UIView, you can choose

00:16:41.846 --> 00:16:44.366 A:middle
to create a view controller
if you want to add them

00:16:44.366 --> 00:16:48.176 A:middle
to a UI popover view
on your iPad, or if,

00:16:48.176 --> 00:16:51.046 A:middle
the example demonstrated it, if
you want to embed that directly

00:16:51.046 --> 00:16:53.486 A:middle
in the content of your app
you can do that as well.

00:16:54.116 --> 00:16:56.216 A:middle
Let's take a look at the code.

00:16:56.566 --> 00:16:59.006 A:middle
We import the umbrella header.

00:16:59.436 --> 00:17:01.326 A:middle
In this case, I'm
demonstrating how


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:59.436 --> 00:17:01.326 A:middle
In this case, I'm
demonstrating how

00:17:01.326 --> 00:17:03.856 A:middle
to add the Switcher
View from a nib file.

00:17:03.856 --> 00:17:06.906 A:middle
So you go into IV,
drag out your UI view,

00:17:07.016 --> 00:17:10.715 A:middle
assign that to be the class of
the CAInterAppAudioSwitcherView,

00:17:11.146 --> 00:17:13.106 A:middle
create an outlet for that view,

00:17:13.215 --> 00:17:19.296 A:middle
and then in the viewDidLoad
method we specified a visual

00:17:19.296 --> 00:17:20.685 A:middle
appearance of that view.

00:17:20.866 --> 00:17:25.406 A:middle
And then we need to associate
an audio unit with that view

00:17:25.616 --> 00:17:28.046 A:middle
so that it can automatically
find the other apps

00:17:28.046 --> 00:17:28.986 A:middle
that are connected.

00:17:29.616 --> 00:17:34.026 A:middle
And that's all there is to it.

00:17:34.026 --> 00:17:36.686 A:middle
And creating the Transport
view programmatically,

00:17:36.686 --> 00:17:41.556 A:middle
as this example shows, we create
the view, specify initial size

00:17:41.556 --> 00:17:42.956 A:middle
and location of that view,

00:17:43.956 --> 00:17:46.546 A:middle
configure it's visual
appearances,

00:17:47.046 --> 00:17:49.886 A:middle
associate an output
audio unit with a view,

00:17:49.936 --> 00:17:53.106 A:middle
and then finally we
add that transport view

00:17:53.106 --> 00:17:57.806 A:middle
as a subview of our
main content.

00:17:58.576 --> 00:18:01.936 A:middle
OK. Now I'd like to switch
gears a little bit now back


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:17:58.576 --> 00:18:01.936 A:middle
OK. Now I'd like to switch
gears a little bit now back

00:18:01.936 --> 00:18:03.406 A:middle
to AV Foundation.

00:18:03.826 --> 00:18:06.766 A:middle
The rest of my presenters
including myself will be

00:18:06.856 --> 00:18:10.016 A:middle
focusing on this framework and
some of the new enhancements

00:18:10.016 --> 00:18:12.076 A:middle
and abilities that
we've added for you

00:18:12.356 --> 00:18:13.726 A:middle
to add to your application.

00:18:14.386 --> 00:18:17.706 A:middle
The first new feature is
for Audio Unit Management.

00:18:17.706 --> 00:18:21.336 A:middle
And that's the
AVAudioUnitComponentManager.

00:18:22.416 --> 00:18:28.416 A:middle
This is a Mac OS X Yosemite
API, Objective C-based.

00:18:28.416 --> 00:18:33.446 A:middle
And it's primarily designed for
Audio Unit host applications.

00:18:33.726 --> 00:18:34.746 A:middle
However, as you'll see,

00:18:34.746 --> 00:18:37.106 A:middle
we do have some end-user
features as well.

00:18:37.836 --> 00:18:40.496 A:middle
We provide a number of
different querying methods,

00:18:40.496 --> 00:18:43.706 A:middle
which enable your host
to find the Audio Units

00:18:43.706 --> 00:18:46.506 A:middle
on the system given some
criteria, for example,

00:18:46.506 --> 00:18:47.866 A:middle
number of supported channels.

00:18:48.816 --> 00:18:51.356 A:middle
We have a simple API
for getting information

00:18:51.356 --> 00:18:53.206 A:middle
about each individual
Audio Unit.

00:18:53.926 --> 00:18:55.926 A:middle
We have some new
tagging facilities

00:18:55.926 --> 00:18:57.606 A:middle
that I'll demonstrate
in a moment.

00:18:58.146 --> 00:19:01.676 A:middle
And finally we have a
centralized Audio Unit cache


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:18:58.146 --> 00:19:01.676 A:middle
And finally we have a
centralized Audio Unit cache

00:19:02.086 --> 00:19:04.816 A:middle
so that if you have
multiple host applications

00:19:04.816 --> 00:19:08.686 A:middle
on your system, once one
host has scanned Audio Units,

00:19:08.686 --> 00:19:11.396 A:middle
and for a lot of people they
have a large number of them

00:19:11.396 --> 00:19:14.306 A:middle
so this can take quite some
time, all the other hosts

00:19:14.306 --> 00:19:18.396 A:middle
on the system share that
information so they don't have

00:19:18.396 --> 00:19:20.576 A:middle
to perform that exhaustive
scan again.

00:19:21.126 --> 00:19:25.106 A:middle
Let's take a look at
the API in more detail.

00:19:25.876 --> 00:19:28.486 A:middle
As I said, these are in AV
Foundation, and they're new.

00:19:29.446 --> 00:19:32.736 A:middle
The first class is the
AVAudioUnitComponentManager.

00:19:33.036 --> 00:19:36.176 A:middle
And this provides three
different search mechanisms

00:19:36.176 --> 00:19:37.976 A:middle
for finding Audio Units.

00:19:38.006 --> 00:19:41.036 A:middle
The first of which is
based on the NSPredicates.

00:19:41.616 --> 00:19:45.296 A:middle
We can use a SQL-based
language to provide strings,

00:19:45.296 --> 00:19:49.376 A:middle
which I'll show you in a
source code example later

00:19:49.746 --> 00:19:52.436 A:middle
for finding audio units
matching the given criteria.

00:19:53.156 --> 00:19:55.176 A:middle
We also have a block-based
mechanism

00:19:55.246 --> 00:19:57.136 A:middle
for finer programmatic control.

00:19:57.536 --> 00:20:00.246 A:middle
And for those of you
using older host apps


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:57.536 --> 00:20:00.246 A:middle
And for those of you
using older host apps

00:20:00.626 --> 00:20:02.696 A:middle
with our current
audio component API,

00:20:03.246 --> 00:20:05.626 A:middle
we have a backwards-compatible
mode as well.

00:20:06.806 --> 00:20:12.266 A:middle
Each of these search
methodologies return an NSArray

00:20:12.266 --> 00:20:14.186 A:middle
of AVAudioUnitComponents.

00:20:14.556 --> 00:20:15.866 A:middle
And that class can be used

00:20:15.866 --> 00:20:19.376 A:middle
to get information
about the audio unit.

00:20:20.016 --> 00:20:23.076 A:middle
Now using our prior API,
if I wanted to do something

00:20:23.076 --> 00:20:27.966 A:middle
like find all stereo effects
that support two-channel input

00:20:27.966 --> 00:20:32.706 A:middle
and two-channel output, I'd have
to write a great deal of code.

00:20:33.026 --> 00:20:33.876 A:middle
That's OK.

00:20:33.876 --> 00:20:38.386 A:middle
But now with this new API we can
reduce all that to this simple,

00:20:38.386 --> 00:20:39.836 A:middle
elegant four lines of code.

00:20:40.496 --> 00:20:42.846 A:middle
The first of which is
retrieving an instance

00:20:42.846 --> 00:20:45.076 A:middle
of the sharedAudioUnitManager.

00:20:45.806 --> 00:20:50.246 A:middle
And here I'm using the
block-based search mechanism

00:20:50.246 --> 00:20:54.086 A:middle
to find all components
that pass a specific test.

00:20:54.776 --> 00:20:58.726 A:middle
And in this block I'm checking
to see if the type name

00:20:58.766 --> 00:21:00.406 A:middle
of that audio unit is equal


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:20:58.766 --> 00:21:00.406 A:middle
of that audio unit is equal

00:21:00.406 --> 00:21:05.606 A:middle
to the preset string
AVAudioUnitTypeEffect.

00:21:05.606 --> 00:21:08.326 A:middle
And then furthermore
we're checking to see

00:21:08.326 --> 00:21:11.886 A:middle
if that Audio Unit supports
stereo input and output.

00:21:12.976 --> 00:21:16.146 A:middle
You'll notice there is a stop
parameter, so if you wanted

00:21:16.146 --> 00:21:19.806 A:middle
to return only the
first instance

00:21:19.806 --> 00:21:22.396 A:middle
of the audio component
matching this criteria,

00:21:22.756 --> 00:21:25.686 A:middle
you could return yes
and the stop would,

00:21:25.686 --> 00:21:27.126 A:middle
and it would stop immediately.

00:21:30.366 --> 00:21:33.436 A:middle
OK. Now I'd like to move
on to talk about tagging.

00:21:34.156 --> 00:21:36.646 A:middle
A lot of people,
especially Dr. Dre

00:21:36.646 --> 00:21:39.876 A:middle
in his studio has a large
number of Audio Units.

00:21:39.876 --> 00:21:43.456 A:middle
So finding the right one
can be a bit challenging

00:21:43.866 --> 00:21:46.146 A:middle
because they're sorted
alphabetically

00:21:46.146 --> 00:21:48.216 A:middle
or by manufacturer.

00:21:48.636 --> 00:21:51.376 A:middle
And there's a lot
easier way for users

00:21:51.406 --> 00:21:53.556 A:middle
to find these Audio
Units now with tagging.

00:21:53.556 --> 00:21:56.596 A:middle
It's very similar to what
we have done with a finder

00:21:56.596 --> 00:21:58.386 A:middle
of the previous Mac
OS X release.

00:21:59.036 --> 00:22:03.606 A:middle
Users can now specify their own
tags with an audio unit in order


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:21:59.036 --> 00:22:03.606 A:middle
Users can now specify their own
tags with an audio unit in order

00:22:03.606 --> 00:22:07.376 A:middle
to create broad categories
or even specific categories

00:22:07.736 --> 00:22:10.736 A:middle
of how they want to
organize their audio units.

00:22:11.336 --> 00:22:14.986 A:middle
They can apply one or more tags
in two different categories.

00:22:14.986 --> 00:22:16.806 A:middle
The first of which
is a system tag.

00:22:17.736 --> 00:22:21.416 A:middle
This is defined by the
creator of the audio unit.

00:22:21.416 --> 00:22:25.286 A:middle
And, for example, in Mavericks,
excuse me, in Yosemite,

00:22:25.286 --> 00:22:28.556 A:middle
I have to get that name in my
head, I personally liked Weed,

00:22:28.556 --> 00:22:32.266 A:middle
but I didn't get to vote.

00:22:32.376 --> 00:22:35.576 A:middle
The system tags are
defined by the creator.

00:22:35.576 --> 00:22:39.076 A:middle
And we at Apple have
added standard tags

00:22:39.076 --> 00:22:41.486 A:middle
to all the Audio Units that
we feel would be useful

00:22:41.486 --> 00:22:42.716 A:middle
to most of our users.

00:22:42.796 --> 00:22:45.666 A:middle
You can also have user tags.

00:22:46.066 --> 00:22:49.366 A:middle
These are specified by each
individual user on the system.

00:22:49.366 --> 00:22:52.216 A:middle
So if you have three users they
can each have their own set

00:22:52.216 --> 00:22:52.716 A:middle
of tags.

00:22:53.426 --> 00:22:58.156 A:middle
A tag is a localized string
in the user's own language.

00:22:58.636 --> 00:23:00.246 A:middle
Swedish, Swahili,
it doesn't matter.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:58.636 --> 00:23:00.246 A:middle
Swedish, Swahili,
it doesn't matter.

00:23:00.336 --> 00:23:03.676 A:middle
They can be arbitrary, or they
can be a pre-defined type.

00:23:03.676 --> 00:23:04.506 A:middle
And these are all

00:23:04.506 --> 00:23:09.576 A:middle
in AudioComponent.h. They can
be either based on the type

00:23:09.576 --> 00:23:12.966 A:middle
of Audio Unit, for example a
filter or a distortion effect,

00:23:13.506 --> 00:23:16.036 A:middle
or they can be based
on the intended usage,

00:23:16.326 --> 00:23:21.046 A:middle
for example an audio unit useful
in a guitar or vocal track.

00:23:21.766 --> 00:23:27.796 A:middle
Now I'd like to show
a demo of tagging

00:23:27.796 --> 00:23:31.986 A:middle
in action using a
modified version of AU Lab.

00:23:32.296 --> 00:23:37.676 A:middle
So in AU Lab we can look
at all the tags associated

00:23:37.676 --> 00:23:39.366 A:middle
with all the built-in
audio units.

00:23:39.926 --> 00:23:41.886 A:middle
And here you see
that, for example,

00:23:41.886 --> 00:23:46.716 A:middle
the AU time pitch
has two standard tags

00:23:46.906 --> 00:23:49.306 A:middle
that are associated with
it, time effect and pitch.

00:23:49.626 --> 00:23:51.146 A:middle
And those are defined by us.

00:23:51.736 --> 00:23:55.006 A:middle
In addition you can see

00:23:55.006 --> 00:23:59.646 A:middle
that this distortion effect has
two user tags, one specifying

00:23:59.646 --> 00:24:01.706 A:middle
that it's useful
for a drum track


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:23:59.646 --> 00:24:01.706 A:middle
that it's useful
for a drum track

00:24:01.706 --> 00:24:03.306 A:middle
and another one for
a guitar track.

00:24:04.256 --> 00:24:08.376 A:middle
The API also provides developers
the ability to get a list

00:24:08.376 --> 00:24:12.576 A:middle
of all the system-defined
tags localized in the language

00:24:12.576 --> 00:24:15.486 A:middle
of the running host
as you can see here.

00:24:15.986 --> 00:24:19.176 A:middle
And I can also see
all of the user tags

00:24:19.246 --> 00:24:23.216 A:middle
that the users assigned to all
the Audio Units on this system.

00:24:25.216 --> 00:24:28.216 A:middle
Adding tags are as simple
as typing a new one.

00:24:28.966 --> 00:24:33.796 A:middle
Now that's been added
to that Audio Unit.

00:24:33.796 --> 00:24:38.956 A:middle
And I can do a search
using this predicate-based

00:24:38.956 --> 00:24:40.356 A:middle
and other search mechanisms.

00:24:41.856 --> 00:24:43.796 A:middle
And it will search all
the audience looking

00:24:43.796 --> 00:24:45.086 A:middle
for that particular tag.

00:24:45.676 --> 00:24:47.446 A:middle
So this is something
that is really exciting,

00:24:47.446 --> 00:24:52.256 A:middle
and we hope that you'll use this
API to add tagging functionality

00:24:52.256 --> 00:24:53.736 A:middle
to your own host application.

00:24:54.276 --> 00:24:56.126 A:middle
Let's take a look
now at the API.

00:24:57.416 --> 00:24:59.936 A:middle
To find an Audio Unit
with a specific tag,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:25:00.176 --> 00:25:01.366 A:middle
in this example I'm going

00:25:01.366 --> 00:25:05.606 A:middle
to use the NSPredicate
filtering mechanism.

00:25:05.956 --> 00:25:07.376 A:middle
Here I'm defining a predicate.

00:25:07.376 --> 00:25:12.336 A:middle
It says that the component has

00:25:12.336 --> 00:25:16.556 A:middle
to have the old tag name's
property containing a particular

00:25:16.556 --> 00:25:18.736 A:middle
string, in this case,
"My Favorite Tag",

00:25:19.236 --> 00:25:21.156 A:middle
and this is the identical
searching

00:25:21.156 --> 00:25:22.696 A:middle
that you just saw in my demo.

00:25:24.166 --> 00:25:26.606 A:middle
Once you've defined the
predicate you get an instance

00:25:26.606 --> 00:25:28.926 A:middle
of the shared AU Manager,

00:25:30.426 --> 00:25:32.606 A:middle
and then call
componentsMatchingPredicate,

00:25:32.606 --> 00:25:33.986 A:middle
which returns an array.

00:25:37.816 --> 00:25:42.036 A:middle
To get a list of
the tags associated

00:25:42.036 --> 00:25:44.666 A:middle
with this particular
AVAudioUnitComponent,

00:25:44.666 --> 00:25:46.616 A:middle
you use the userTags
named property.

00:25:47.766 --> 00:25:49.446 A:middle
You can assign to that as well.

00:25:49.446 --> 00:25:53.486 A:middle
And in this example I'm adding
two tags to the audio Unit.

00:25:54.256 --> 00:25:57.946 A:middle
We could get all tags
for a specific component,

00:25:57.946 --> 00:26:01.196 A:middle
and these will include the user
tags as well as the system tags.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:25:57.946 --> 00:26:01.196 A:middle
and these will include the user
tags as well as the system tags.

00:26:02.106 --> 00:26:03.426 A:middle
All tagNames property.

00:26:05.016 --> 00:26:08.356 A:middle
We can get a localized list of
all the standard system tags

00:26:08.356 --> 00:26:09.896 A:middle
by getting the Component Manager

00:26:09.896 --> 00:26:12.466 A:middle
and then calling the
standardLocalizedTagNames

00:26:12.496 --> 00:26:13.006 A:middle
property.

00:26:13.786 --> 00:26:16.846 A:middle
This is what I was displaying
in the pop up in my demo.

00:26:17.746 --> 00:26:21.246 A:middle
And finally I can get a list
of all the localized tags

00:26:21.246 --> 00:26:22.766 A:middle
that this user has assigned

00:26:22.766 --> 00:26:24.736 A:middle
across all the audio
units on the system.

00:26:25.226 --> 00:26:26.926 A:middle
And that, again,
you saw in my demo.

00:26:27.626 --> 00:26:32.976 A:middle
For those of you that ship
Audio Units, and you want

00:26:32.976 --> 00:26:35.486 A:middle
to add your own built-in
tags to those Audio Units,

00:26:35.866 --> 00:26:39.336 A:middle
you need to go into your
AudioComponent bundle.

00:26:39.336 --> 00:26:43.486 A:middle
And in your info.plist, look at
your Audio Component Dictionary

00:26:43.486 --> 00:26:45.066 A:middle
and add a tag section.

00:26:46.076 --> 00:26:50.626 A:middle
These first two items are
examples of using standard tags,

00:26:51.286 --> 00:26:53.806 A:middle
and the third item
is a custom tag.

00:26:54.186 --> 00:26:57.206 A:middle
So you can have that
be something meaningful

00:26:57.206 --> 00:26:59.316 A:middle
to your own company,
for example,

00:26:59.316 --> 00:27:02.606 A:middle
if you have like the
Silver Effect Package,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:26:59.316 --> 00:27:02.606 A:middle
if you have like the
Silver Effect Package,

00:27:02.606 --> 00:27:03.646 A:middle
you could add that tag.

00:27:05.076 --> 00:27:08.336 A:middle
If you do so, you can
also localize that tag

00:27:08.406 --> 00:27:10.746 A:middle
by adding an
AudioUnitsTag.strings file

00:27:10.746 --> 00:27:14.926 A:middle
into your bundle and then adding
localizations for each language

00:27:14.926 --> 00:27:16.266 A:middle
that you wish to support.

00:27:16.766 --> 00:27:20.136 A:middle
And please do not localize any
of our standard system tags.

00:27:20.136 --> 00:27:21.466 A:middle
We've already done so for you.

00:27:22.746 --> 00:27:27.706 A:middle
So, in summary, if you're a
host developer please adopt the

00:27:27.706 --> 00:27:29.896 A:middle
AVAudioComponentManager API,

00:27:29.896 --> 00:27:33.606 A:middle
so your users can tag
all their Audio Units.

00:27:33.666 --> 00:27:35.846 A:middle
And if you're an
Audio Unit developer,

00:27:35.846 --> 00:27:38.346 A:middle
please add system tags
to your audio units.

00:27:38.876 --> 00:27:41.976 A:middle
So without further
ado I'd like to turn

00:27:41.976 --> 00:27:43.946 A:middle
over this session
to Eric Johnson.

00:27:43.946 --> 00:27:47.056 A:middle
He'll be discussing tips and
tricks and new functionality

00:27:47.056 --> 00:27:48.176 A:middle
in the AVAudioSession.

00:27:48.796 --> 00:27:48.976 A:middle
Eric?

00:27:49.516 --> 00:27:54.126 A:middle
[ Applause ]

00:27:54.626 --> 00:27:55.006 A:middle
&gt;&gt; Good morning.

00:27:55.006 --> 00:27:58.086 A:middle
So I'll be continuing on with
the AV Foundation framework.

00:27:58.166 --> 00:28:02.376 A:middle
This time we're on iOS
only with AVAudioSession.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:27:58.166 --> 00:28:02.376 A:middle
This time we're on iOS
only with AVAudioSession.

00:28:02.866 --> 00:28:05.756 A:middle
So today we're just going to
spend a few minutes talking

00:28:05.756 --> 00:28:08.396 A:middle
about some best practices
focusing

00:28:08.396 --> 00:28:11.196 A:middle
on managing your
session's activation state,

00:28:11.746 --> 00:28:13.456 A:middle
and then also talking
about just a little bit

00:28:13.456 --> 00:28:15.066 A:middle
of new things in iOS 8.

00:28:16.676 --> 00:28:19.126 A:middle
Before we dive in I wanted
to call your attention

00:28:19.166 --> 00:28:22.016 A:middle
to an updated Audio Session
Programming Guide that's

00:28:22.016 --> 00:28:25.686 A:middle
available on
developer.apple.com.

00:28:25.686 --> 00:28:28.256 A:middle
Since we saw you all
last year at this time,

00:28:28.256 --> 00:28:31.976 A:middle
this guide has been updated
so that it has been rewritten

00:28:32.436 --> 00:28:35.296 A:middle
in terms of AVAudioSession,
so it's no longer referring

00:28:35.296 --> 00:28:36.856 A:middle
to the deprecated C API.

00:28:37.806 --> 00:28:39.066 A:middle
That's a really great update.

00:28:39.356 --> 00:28:42.356 A:middle
And for those of you who
are maybe not that familiar

00:28:42.356 --> 00:28:46.466 A:middle
with Audio Session, there
was a talk from two years ago

00:28:46.696 --> 00:28:49.476 A:middle
where Torrey talked
about Audio Session

00:28:49.476 --> 00:28:51.546 A:middle
and also Multi-Route
Audio in iOS.

00:28:53.126 --> 00:28:53.916 A:middle
All right.

00:28:53.916 --> 00:28:55.646 A:middle
So let's dive into talking

00:28:55.646 --> 00:28:58.606 A:middle
about managing your
session's activation state.

00:28:59.636 --> 00:29:02.296 A:middle
So there's your application
state.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:28:59.636 --> 00:29:02.296 A:middle
So there's your application
state.

00:29:02.466 --> 00:29:04.596 A:middle
And then there's
Audio Session state.

00:29:04.596 --> 00:29:05.866 A:middle
And they're separate things.

00:29:05.866 --> 00:29:07.276 A:middle
They're managed independently
of each other.

00:29:08.126 --> 00:29:09.726 A:middle
So if you've been
doing development

00:29:09.886 --> 00:29:12.716 A:middle
for iOS you are probably
familiar with app states.

00:29:12.716 --> 00:29:15.926 A:middle
So this is whether your app is
running or not, whether it's

00:29:15.926 --> 00:29:17.576 A:middle
in the foreground
or the background,

00:29:17.696 --> 00:29:18.596 A:middle
if it's been suspended.

00:29:19.806 --> 00:29:22.626 A:middle
Your Audio Session
activation state is binary.

00:29:23.206 --> 00:29:25.266 A:middle
It's either inactive or active.

00:29:26.366 --> 00:29:29.016 A:middle
Once you've made your
session active you do need

00:29:29.016 --> 00:29:31.976 A:middle
to be prepared to handle
interruptions, and we'll talk

00:29:31.976 --> 00:29:32.866 A:middle
about what that means.

00:29:33.726 --> 00:29:35.736 A:middle
So let's look at an example

00:29:35.736 --> 00:29:39.446 A:middle
of how an Audio Session
state changes over time.

00:29:39.836 --> 00:29:42.386 A:middle
So here we're on an iPhone.

00:29:42.556 --> 00:29:45.506 A:middle
We have our application
on top, our Audio Session.

00:29:46.096 --> 00:29:48.586 A:middle
Let's say that we're
developing a game app.

00:29:48.586 --> 00:29:51.036 A:middle
And then on the bottom we have
the phone's Audio Session.

00:29:51.746 --> 00:29:54.546 A:middle
And right now the user
is not in a phone call,

00:29:54.856 --> 00:29:56.426 A:middle
and they haven't
launched their app yet,

00:29:56.426 --> 00:29:59.476 A:middle
so both sessions
are idle, inactive.

00:29:59.606 --> 00:30:02.286 A:middle
So now the user launches
our app.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:59.606 --> 00:30:02.286 A:middle
So now the user launches
our app.

00:30:03.796 --> 00:30:06.796 A:middle
When we first come into the
foreground our Audio Session is

00:30:06.796 --> 00:30:07.586 A:middle
still inactive.

00:30:08.316 --> 00:30:11.296 A:middle
And because we're a game app, we
want to make our session active

00:30:11.556 --> 00:30:12.556 A:middle
when we're in the foreground

00:30:12.556 --> 00:30:13.966 A:middle
so that we can be
ready to play audio.

00:30:13.966 --> 00:30:14.696 A:middle
So we'll do that.

00:30:15.806 --> 00:30:17.556 A:middle
And we're going to
just play some music,

00:30:17.556 --> 00:30:20.136 A:middle
so we're now happily playing
music in the foreground

00:30:20.136 --> 00:30:21.286 A:middle
with an active Audio Session.

00:30:23.056 --> 00:30:27.506 A:middle
So then the phone
starts ringing.

00:30:27.506 --> 00:30:29.246 A:middle
We get interrupted by,

00:30:29.246 --> 00:30:32.406 A:middle
the system sends us
an interruption event.

00:30:33.356 --> 00:30:36.066 A:middle
The phone's Audio
Session becomes active

00:30:36.066 --> 00:30:37.306 A:middle
and plays the ringtone.

00:30:38.086 --> 00:30:40.726 A:middle
And the user decides
to accept the call.

00:30:41.436 --> 00:30:43.596 A:middle
So the phone's Audio
Session stays active,

00:30:43.996 --> 00:30:47.616 A:middle
and our Audio Session has been
interrupted, so we're inactive.

00:30:47.616 --> 00:30:52.236 A:middle
And then the user ends the
call, hangs up, says goodbye,

00:30:53.456 --> 00:30:54.636 A:middle
and now the system is going

00:30:54.636 --> 00:30:57.876 A:middle
to deliver an end interruption
event to our Audio Session.

00:30:57.876 --> 00:31:01.576 A:middle
And we're going to
use that as a signal


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:57.876 --> 00:31:01.576 A:middle
And we're going to
use that as a signal

00:31:01.576 --> 00:31:04.426 A:middle
to make our session active
again and presume playback.

00:31:05.866 --> 00:31:07.086 A:middle
And we continue in this state.

00:31:07.686 --> 00:31:11.666 A:middle
So this is a typical
example of how something

00:31:11.666 --> 00:31:14.346 A:middle
like a game application
interacts with the phones,

00:31:14.726 --> 00:31:16.816 A:middle
the phone app's Audio
Session on an iPhone.

00:31:19.096 --> 00:31:20.776 A:middle
So the way that you need

00:31:20.776 --> 00:31:25.176 A:middle
to manage your application's
Audio Session state is actually

00:31:25.176 --> 00:31:26.816 A:middle
going to depend on
how you use audio.

00:31:27.446 --> 00:31:30.266 A:middle
We've identified a number of
different types of applications

00:31:30.526 --> 00:31:33.046 A:middle
that commonly use audio on iOS.

00:31:33.686 --> 00:31:36.376 A:middle
And we don't have time to talk
about all of these this morning,

00:31:36.376 --> 00:31:38.076 A:middle
and you'd probably be
bored to death if we did.

00:31:38.436 --> 00:31:42.576 A:middle
So we're just going to
talk about a few of these.

00:31:42.576 --> 00:31:44.006 A:middle
So let's continue
on with the idea

00:31:44.006 --> 00:31:45.696 A:middle
that we're developing
a game app.

00:31:46.136 --> 00:31:49.756 A:middle
So for game apps usually what
we recommend is that when you're

00:31:49.756 --> 00:31:51.106 A:middle
in the foreground, you'll want

00:31:51.106 --> 00:31:53.806 A:middle
to have your Audio
Session active.

00:31:53.806 --> 00:31:57.246 A:middle
So a good place to make
your Audio Session active is

00:31:57.246 --> 00:31:59.836 A:middle
in the app delegate's
applicationDidBecomeActive

00:31:59.876 --> 00:32:00.236 A:middle
method.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:31:59.876 --> 00:32:00.236 A:middle
method.

00:32:00.816 --> 00:32:03.446 A:middle
So that will cover the case
when you're being launched.

00:32:03.826 --> 00:32:06.636 A:middle
If you're coming from the
background into the foreground,

00:32:07.246 --> 00:32:08.956 A:middle
or if you are already
in the foreground

00:32:09.186 --> 00:32:12.676 A:middle
and the user had swiped
up the control panel

00:32:12.676 --> 00:32:15.196 A:middle
and then dismissed it, you'll be
covered in each of those cases.

00:32:16.336 --> 00:32:19.466 A:middle
So once you've made your session
active you can leave it active,

00:32:19.806 --> 00:32:22.746 A:middle
but you do need to be prepared
to deal with interruptions.

00:32:23.866 --> 00:32:25.966 A:middle
So if you get a begin
interruption event,

00:32:26.336 --> 00:32:28.446 A:middle
you should update
your internal state

00:32:28.446 --> 00:32:29.956 A:middle
so that you know
that you're paused.

00:32:31.266 --> 00:32:33.196 A:middle
And then if you get an
end interruption event,

00:32:33.956 --> 00:32:36.166 A:middle
that's your opportunity to
make your session active

00:32:36.446 --> 00:32:37.626 A:middle
and to resume audio playback.

00:32:37.716 --> 00:32:40.446 A:middle
And this is just like the
example that we looked

00:32:40.446 --> 00:32:44.156 A:middle
at just a few minutes ago.

00:32:44.226 --> 00:32:45.476 A:middle
Media playback apps need

00:32:45.476 --> 00:32:48.116 A:middle
to manage their Audio Session
state a little bit differently.

00:32:48.776 --> 00:32:50.536 A:middle
So I'm talking about
applications

00:32:50.536 --> 00:32:53.856 A:middle
like the built-in music app
or podcast or streaming radio.

00:32:53.896 --> 00:32:55.726 A:middle
And these are the
types of applications

00:32:55.726 --> 00:32:58.206 A:middle
that we usually have
a play/pause button,

00:32:58.326 --> 00:33:01.396 A:middle
and they're what we refer
to as non-mixable meaning


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:58.326 --> 00:33:01.396 A:middle
and they're what we refer
to as non-mixable meaning

00:33:02.236 --> 00:33:03.796 A:middle
that they'll interrupt the audio

00:33:03.796 --> 00:33:06.296 A:middle
of other non-mixable
Audio Sessions.

00:33:07.416 --> 00:33:09.926 A:middle
So for these types of
applications we recommend

00:33:10.086 --> 00:33:12.906 A:middle
that instead of making your
session active immediately

00:33:12.906 --> 00:33:14.556 A:middle
when you enter the
foreground that you wait

00:33:14.886 --> 00:33:16.516 A:middle
until a user presses
thePplay button.

00:33:17.336 --> 00:33:18.586 A:middle
And the reason that we give you

00:33:18.586 --> 00:33:21.446 A:middle
that advice is sometimes
the user brings your app

00:33:21.526 --> 00:33:22.696 A:middle
into the foreground just to see

00:33:22.696 --> 00:33:25.786 A:middle
if they have a particular
podcast episode downloaded

00:33:25.786 --> 00:33:27.556 A:middle
or to see if they have
a song in their library.

00:33:27.556 --> 00:33:28.936 A:middle
And they don't necessarily want

00:33:28.936 --> 00:33:31.096 A:middle
to interrupt other
audio that was playing.

00:33:31.496 --> 00:33:33.016 A:middle
So it's good to wait
until they press Play.

00:33:34.666 --> 00:33:37.306 A:middle
So like in the case of a game
app once you've made your

00:33:37.306 --> 00:33:39.536 A:middle
session active you
can leave it active.

00:33:40.236 --> 00:33:41.936 A:middle
But, again, you need
to be prepared

00:33:41.936 --> 00:33:42.856 A:middle
to handle interruptions.

00:33:44.076 --> 00:33:45.896 A:middle
So if you get a begin
interruption event,

00:33:46.396 --> 00:33:47.816 A:middle
you should update your UI.

00:33:47.816 --> 00:33:50.176 A:middle
So if you have a play/pause
button it's a good time

00:33:50.176 --> 00:33:53.026 A:middle
to change that state
and also keep track

00:33:53.026 --> 00:33:54.966 A:middle
of your internal states so that
you know that you're paused.

00:33:56.286 --> 00:33:58.596 A:middle
One thing you do not need
to do is you do not need

00:33:58.596 --> 00:33:59.836 A:middle
to make your session inactive


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:00.056 --> 00:34:02.476 A:middle
because the system has
already done that for you.

00:34:03.006 --> 00:34:04.236 A:middle
That's what the interruption is.

00:34:06.006 --> 00:34:08.496 A:middle
So then if you get an
end interruption event,

00:34:09.036 --> 00:34:12.646 A:middle
we ask that you honor
the ShouldResume option.

00:34:13.045 --> 00:34:16.386 A:middle
So if this option is part of
the info dictionary that's part

00:34:16.386 --> 00:34:19.775 A:middle
of that notification, that's
the system giving you a hint

00:34:19.826 --> 00:34:21.516 A:middle
that it's OK to make
your session active

00:34:21.616 --> 00:34:23.216 A:middle
and to immediately
resume playback.

00:34:23.216 --> 00:34:26.936 A:middle
If you don't see that option
as part of the notification,

00:34:26.936 --> 00:34:28.946 A:middle
then you should wait for the
user to press play again.

00:34:31.616 --> 00:34:35.416 A:middle
OK. So we talked about for game
apps and media playback apps

00:34:35.815 --> 00:34:37.226 A:middle
when you would make
your session active.

00:34:37.315 --> 00:34:38.916 A:middle
What about making
your session inactive.

00:34:40.436 --> 00:34:44.426 A:middle
So if you are something like
a navigation or a fitness app,

00:34:44.946 --> 00:34:49.376 A:middle
you're typically going to be
playing short prompts of audio.

00:34:50.045 --> 00:34:54.646 A:middle
And you're going to be using
the duck others category option

00:34:55.085 --> 00:34:56.406 A:middle
which will lower the volume

00:34:56.516 --> 00:34:58.606 A:middle
of other audio applications
on the system.

00:34:58.896 --> 00:35:02.186 A:middle
So it's important when you're
done playing your short prompts


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:58.896 --> 00:35:02.186 A:middle
So it's important when you're
done playing your short prompts

00:35:02.236 --> 00:35:03.676 A:middle
that you make your
session inactive

00:35:04.236 --> 00:35:06.946 A:middle
so that the other audio is
able to resume at full volume.

00:35:08.076 --> 00:35:14.376 A:middle
If you're a voiceover IP app
or a chat app or maybe one

00:35:14.376 --> 00:35:19.446 A:middle
of these apps that has like
kind of like a browser view

00:35:19.446 --> 00:35:21.006 A:middle
where you're playing
short videos,

00:35:21.706 --> 00:35:25.356 A:middle
then you are usually going to be
what we refer to as non-mixable,

00:35:25.356 --> 00:35:27.586 A:middle
meaning that you're going
to interrupt other audio.

00:35:28.536 --> 00:35:30.906 A:middle
And so it's important that
when you're done playing audio

00:35:30.906 --> 00:35:32.866 A:middle
that you make your
session inactive

00:35:33.456 --> 00:35:36.146 A:middle
so that other sessions
are able to resume.

00:35:37.866 --> 00:35:42.346 A:middle
And it's a good idea to use
the NotifyOthersOnDeactivation

00:35:42.466 --> 00:35:44.446 A:middle
option when you make
your session inactive.

00:35:44.646 --> 00:35:47.086 A:middle
And that way the system is able

00:35:47.086 --> 00:35:50.536 A:middle
to tell an interrupted
Audio Session

00:35:50.536 --> 00:35:52.246 A:middle
that it's OK for them to resume.

00:35:52.246 --> 00:35:52.966 A:middle
All right.

00:35:53.936 --> 00:35:58.416 A:middle
So now let's shift gears
a little bit and talk

00:35:58.416 --> 00:36:02.946 A:middle
about managing your secondary
audio in response to other audio


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:35:58.416 --> 00:36:02.946 A:middle
about managing your secondary
audio in response to other audio

00:36:02.946 --> 00:36:03.896 A:middle
on the system playing.

00:36:04.696 --> 00:36:06.966 A:middle
So first let me explain
what I mean

00:36:06.966 --> 00:36:08.886 A:middle
by secondary audio
and primary audio.

00:36:09.886 --> 00:36:12.356 A:middle
So let's say we're
developing a game application.

00:36:12.876 --> 00:36:16.426 A:middle
Our primary audio is going
to be our sound effects,

00:36:16.426 --> 00:36:19.936 A:middle
our explosions, beeps and
bloops, short bits of dialog.

00:36:20.586 --> 00:36:23.576 A:middle
And it's the kind of audio that
really enhances the gameplay.

00:36:24.366 --> 00:36:28.356 A:middle
And it's also the kind of audio
that, if the user was listening

00:36:28.356 --> 00:36:30.926 A:middle
to music when they launched your
app, you still want it to play.

00:36:31.336 --> 00:36:35.576 A:middle
And it's OK that it mixes
in with the other music.

00:36:35.626 --> 00:36:38.196 A:middle
By secondary audio, I am really
talking about your soundtrack.

00:36:38.856 --> 00:36:41.776 A:middle
This is the audio where it
also enhances the gameplay,

00:36:42.326 --> 00:36:45.436 A:middle
but if the user was previously
listening to their music

00:36:45.436 --> 00:36:46.966 A:middle
or their podcast, you'd just

00:36:46.966 --> 00:36:48.556 A:middle
as soon have your
soundtrack be muted.

00:36:49.586 --> 00:36:53.366 A:middle
And then if the user
stops their music playback

00:36:53.366 --> 00:36:55.986 A:middle
on their podcast then you'd like
to have your soundtrack resume.

00:36:57.146 --> 00:37:01.876 A:middle
So in iOS 8 we've added a bit
of new API to help you do this.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:36:57.146 --> 00:37:01.876 A:middle
So in iOS 8 we've added a bit
of new API to help you do this.

00:37:02.336 --> 00:37:04.626 A:middle
We've added a new property
and a new notification.

00:37:05.686 --> 00:37:08.166 A:middle
The property is called
secondaryAudio

00:37:08.166 --> 00:37:09.356 A:middle
ShouldBeSilencedHint.

00:37:09.356 --> 00:37:13.456 A:middle
As the name implies, it's a hint
that the system is giving you

00:37:13.966 --> 00:37:16.736 A:middle
that it's a good time to
mute your secondary audio.

00:37:17.746 --> 00:37:20.806 A:middle
So this is meant to be used by
apps that are in the foreground.

00:37:21.976 --> 00:37:24.606 A:middle
And we recommend that you
would check this property

00:37:24.606 --> 00:37:26.656 A:middle
in applicationDidBecomeActive.

00:37:27.286 --> 00:37:30.366 A:middle
Going along with the
new property is our

00:37:30.366 --> 00:37:31.336 A:middle
new notification.

00:37:32.506 --> 00:37:35.886 A:middle
This is the AVAudioSession
SilenceSecondary

00:37:35.886 --> 00:37:37.086 A:middle
AudioHintNotification.

00:37:37.206 --> 00:37:39.546 A:middle
Another mouthful for this
early in the morning.

00:37:40.256 --> 00:37:43.506 A:middle
So this notification will be
delivered to apps that are

00:37:43.506 --> 00:37:45.436 A:middle
in the foreground with
active Audio Sessions.

00:37:46.406 --> 00:37:47.776 A:middle
And it's kind of similar

00:37:47.776 --> 00:37:50.696 A:middle
to our interruption notification
that it's two-sided.

00:37:50.786 --> 00:37:54.586 A:middle
There's a begin event, there's
an end event all wrapped

00:37:54.586 --> 00:37:56.056 A:middle
up in the same notification.

00:37:57.066 --> 00:38:00.656 A:middle
So when you get a
begin SilenceSecondary


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:37:57.066 --> 00:38:00.656 A:middle
So when you get a
begin SilenceSecondary

00:38:00.656 --> 00:38:03.446 A:middle
AudioHintNotification that
means that it's a good time

00:38:03.446 --> 00:38:04.856 A:middle
to mute your secondary audio.

00:38:05.266 --> 00:38:07.326 A:middle
And if you get the end
event it's a good time

00:38:07.326 --> 00:38:08.696 A:middle
to resume your soundtrack.

00:38:09.526 --> 00:38:11.306 A:middle
So let's look at what
this looks like in action.

00:38:12.696 --> 00:38:15.716 A:middle
So on the far right we have
the built-in music app,

00:38:15.716 --> 00:38:17.546 A:middle
and it's currently
in the background.

00:38:17.546 --> 00:38:18.506 A:middle
It's not playing audio.

00:38:19.826 --> 00:38:22.676 A:middle
On the far left we have our
game app that we're developing.

00:38:23.346 --> 00:38:26.126 A:middle
So we're playing our primary
audio, the sound effects,

00:38:26.126 --> 00:38:27.616 A:middle
and we're also playing
our soundtrack

00:38:27.906 --> 00:38:29.736 A:middle
because there was no
other music playing.

00:38:30.816 --> 00:38:33.776 A:middle
And in the middle we have iOS
helping to negotiate things.

00:38:34.886 --> 00:38:38.736 A:middle
So the user has his
headphones plugged in,

00:38:38.736 --> 00:38:40.306 A:middle
and he presses that
middle button.

00:38:41.026 --> 00:38:43.556 A:middle
And the music app responds
to remote control events.

00:38:43.556 --> 00:38:46.556 A:middle
So it uses that as a
signal to begin playback.

00:38:47.906 --> 00:38:50.556 A:middle
The music app also informs iOS

00:38:50.556 --> 00:38:52.556 A:middle
that it's using its
audio output.

00:38:53.496 --> 00:38:57.376 A:middle
And so then the system is able
to send a begin notification

00:38:57.376 --> 00:38:58.856 A:middle
to our app that's
in the foreground.

00:38:59.606 --> 00:39:02.076 A:middle
And in response to that we
can mute our soundtrack.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:38:59.606 --> 00:39:02.076 A:middle
And in response to that we
can mute our soundtrack.

00:39:02.846 --> 00:39:04.946 A:middle
So our app is still
in the foreground.

00:39:04.946 --> 00:39:06.426 A:middle
The only thing that's
really changed is

00:39:06.426 --> 00:39:11.246 A:middle
that the user used their middle
button to play their music.

00:39:12.656 --> 00:39:14.816 A:middle
And we've responded
to the notification

00:39:14.816 --> 00:39:15.746 A:middle
that we got from the system.

00:39:17.576 --> 00:39:18.816 A:middle
So now some time passes.

00:39:18.896 --> 00:39:20.246 A:middle
We're in this state for a while,

00:39:20.246 --> 00:39:22.416 A:middle
and the user presses
the middle button again.

00:39:22.856 --> 00:39:26.916 A:middle
So the music app responds
by pausing its playback

00:39:27.216 --> 00:39:29.866 A:middle
and telling the system that
it's pausing its audio output.

00:39:29.866 --> 00:39:33.906 A:middle
And then the system is able
to send the end notification

00:39:33.906 --> 00:39:35.966 A:middle
to our app that's still
in the foreground.

00:39:35.966 --> 00:39:39.066 A:middle
And in response to that,
we resume our soundtrack.

00:39:40.046 --> 00:39:45.286 A:middle
So hopefully this will
be pretty easy to use.

00:39:45.286 --> 00:39:48.596 A:middle
There's one new property and
then the two-sided notification

00:39:48.596 --> 00:39:50.186 A:middle
that you can use to
manage your soundtrack.

00:39:51.876 --> 00:39:56.976 A:middle
So kind of on a similar thread,
in the past we've given advice

00:39:57.056 --> 00:40:00.916 A:middle
about how you could manage
your secondary audio based


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:39:57.056 --> 00:40:00.916 A:middle
about how you could manage
your secondary audio based

00:40:00.916 --> 00:40:03.016 A:middle
on the isOtherAudioPlaying
property.

00:40:03.796 --> 00:40:07.066 A:middle
And we had given
advice about choosing

00:40:07.066 --> 00:40:10.536 A:middle
between the ambient category
or solo ambient based

00:40:10.536 --> 00:40:12.246 A:middle
on the state of this property.

00:40:13.046 --> 00:40:15.846 A:middle
What we're recommending now
is that if you're this type

00:40:15.846 --> 00:40:18.336 A:middle
of application, that you
just use the ambient category

00:40:18.336 --> 00:40:21.396 A:middle
and then use the new property
and the new notification

00:40:21.556 --> 00:40:22.586 A:middle
to manage your soundtrack.

00:40:23.246 --> 00:40:23.396 A:middle
All right.

00:40:23.396 --> 00:40:25.206 A:middle
I'm going to hand things
over to Doug Wyatt.

00:40:25.256 --> 00:40:27.146 A:middle
He's going to tell us about
some new utility classes

00:40:27.146 --> 00:40:27.896 A:middle
in AV Foundation.

00:40:28.686 --> 00:40:29.276 A:middle
&gt;&gt; Thank you.

00:40:29.276 --> 00:40:29.796 A:middle
Good morning.

00:40:29.796 --> 00:40:30.506 A:middle
I'm Doug Wyatt.

00:40:30.506 --> 00:40:32.186 A:middle
I'm an engineer in
the Core Audio Group,

00:40:32.816 --> 00:40:35.276 A:middle
and I'd like to talk to you
about some new audio classes

00:40:35.326 --> 00:40:37.016 A:middle
in the AV Foundation framework.

00:40:38.596 --> 00:40:41.986 A:middle
I'll give you, we'll start
out with some background

00:40:41.986 --> 00:40:43.676 A:middle
and tell you what
we're up to and why.

00:40:44.856 --> 00:40:47.266 A:middle
Then we'll start looking through
these classes one by one.

00:40:47.356 --> 00:40:49.846 A:middle
And I'll tie things up at
the end with an example.

00:40:50.666 --> 00:40:54.596 A:middle
So in the past our CoreAudio
and AudioToolbox APIs,

00:40:54.596 --> 00:40:57.746 A:middle
they're very powerful, but
they're not always easy

00:40:57.856 --> 00:41:01.066 A:middle
for developers to get their
hands around at the beginning.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:40:57.856 --> 00:41:01.066 A:middle
for developers to get their
hands around at the beginning.

00:41:01.706 --> 00:41:03.086 A:middle
We've tried to work around this

00:41:03.166 --> 00:41:07.206 A:middle
by providing some C++
utility classes in our SDK,

00:41:07.206 --> 00:41:09.756 A:middle
and that's helped
to some extent,

00:41:10.356 --> 00:41:13.786 A:middle
but example code
gets copied around.

00:41:13.786 --> 00:41:14.996 A:middle
It evolves over time.

00:41:15.536 --> 00:41:18.256 A:middle
And we think it's best in
the long run if we sort

00:41:18.256 --> 00:41:20.956 A:middle
of solidify these things
in the form of API,

00:41:20.956 --> 00:41:23.746 A:middle
and that's what we're
providing now with these classes

00:41:23.746 --> 00:41:26.006 A:middle
in the AV Foundation
framework starting

00:41:26.006 --> 00:41:30.766 A:middle
with Mac OS X 10.10 and iOS 8.

00:41:31.496 --> 00:41:34.676 A:middle
So our goals here, we don't want

00:41:34.676 --> 00:41:36.366 A:middle
to make a complete
break with the past.

00:41:36.616 --> 00:41:40.916 A:middle
We want to build on
what we've already got.

00:41:41.106 --> 00:41:44.716 A:middle
So we're going to,
in many cases,

00:41:44.716 --> 00:41:47.596 A:middle
wrap our existing
low-level C structures inside

00:41:47.596 --> 00:41:48.966 A:middle
Objective-C objects.

00:41:49.576 --> 00:41:53.006 A:middle
And in doing so, these lower
level C structures become easier

00:41:53.006 --> 00:41:53.446 A:middle
to build.

00:41:53.446 --> 00:41:57.326 A:middle
But we can also extract them
from our Objective-C objects

00:41:57.326 --> 00:42:00.726 A:middle
and pass them to the low-level
APIs we might already be using.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:41:57.326 --> 00:42:00.726 A:middle
and pass them to the low-level
APIs we might already be using.

00:42:02.006 --> 00:42:05.786 A:middle
And this is a philosophy we used
also with the AVAudioEngine,

00:42:06.386 --> 00:42:09.866 A:middle
which we'll be examining in more
detail in the next session here.

00:42:10.496 --> 00:42:13.486 A:middle
And I should also mention an
overriding goal here is for us

00:42:13.516 --> 00:42:14.956 A:middle
to stay real-time safe,

00:42:14.956 --> 00:42:17.046 A:middle
which isn't always
easy with Objective-C.

00:42:17.476 --> 00:42:21.336 A:middle
We can't access methods
for properties

00:42:21.646 --> 00:42:23.146 A:middle
on the audio rendering thread.

00:42:23.826 --> 00:42:25.726 A:middle
So we've taken some
great care to do

00:42:25.726 --> 00:42:29.476 A:middle
that in our implementations and
as we go I'll give you a couple

00:42:29.476 --> 00:42:33.726 A:middle
of examples of places where
you need to do this to be aware

00:42:33.726 --> 00:42:35.966 A:middle
of real-time issues when
you're using these classes.

00:42:36.536 --> 00:42:40.386 A:middle
OK. So here are the
classes we'll be looking

00:42:40.386 --> 00:42:42.756 A:middle
at today in this session.

00:42:43.286 --> 00:42:47.026 A:middle
At the bottom in green
we've got AVAudioFormat,

00:42:47.766 --> 00:42:49.606 A:middle
which has an
AVAudioChannelLayout.

00:42:51.556 --> 00:42:53.706 A:middle
In blue we have
AVAudioPCMBuffer,

00:42:53.706 --> 00:42:55.316 A:middle
which has an audio format.

00:42:55.316 --> 00:42:58.186 A:middle
Every buffer has a
format describing it.

00:42:58.666 --> 00:43:01.346 A:middle
And finally we'll be
talking about AVAudioFile,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:42:58.666 --> 00:43:01.346 A:middle
And finally we'll be
talking about AVAudioFile,

00:43:01.536 --> 00:43:04.276 A:middle
which uses AVAudioPCMBuffer
for I/O

00:43:04.736 --> 00:43:07.916 A:middle
and as you would expect the
file also has format objects

00:43:08.056 --> 00:43:10.586 A:middle
describing the file's
data format.

00:43:11.176 --> 00:43:16.056 A:middle
So first let's look
at AVAudioFormat.

00:43:17.186 --> 00:43:21.266 A:middle
This class describes the actual
format of data you might find

00:43:21.266 --> 00:43:25.476 A:middle
in an audio file or stream
and also the audio you,

00:43:25.476 --> 00:43:28.446 A:middle
the format of the audio
you might be passing

00:43:28.446 --> 00:43:29.766 A:middle
to and from APIs.

00:43:30.326 --> 00:43:32.386 A:middle
So our low-level structure here

00:43:32.386 --> 00:43:34.476 A:middle
for describing an
audio format is an

00:43:34.476 --> 00:43:36.166 A:middle
AudioStreamBasicDescription,

00:43:36.686 --> 00:43:39.486 A:middle
which in retrospect might have
been called "audio stream not

00:43:39.486 --> 00:43:41.976 A:middle
so basic" or "audio stream
complete description"

00:43:42.476 --> 00:43:44.036 A:middle
because there's a
lot of fields there,

00:43:44.036 --> 00:43:46.536 A:middle
and it can be a little
challenging to get them all set

00:43:46.536 --> 00:43:49.066 A:middle
up consistently especially
for PCM formats.

00:43:49.606 --> 00:43:52.166 A:middle
But, you know, the beauty
of this structure is

00:43:52.226 --> 00:43:57.546 A:middle
that it describes just about
everything we would want to use

00:43:57.596 --> 00:43:59.206 A:middle
to describe an audio format.

00:43:59.856 --> 00:44:01.576 A:middle
But, again, it's a
little challenging.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:43:59.856 --> 00:44:01.576 A:middle
But, again, it's a
little challenging.

00:44:02.066 --> 00:44:05.476 A:middle
But, in any case, you can
always create an AVAudioFormat

00:44:05.736 --> 00:44:07.526 A:middle
from an
AudioStreamBasicDescription,

00:44:07.526 --> 00:44:09.556 A:middle
which you might have
obtained from a low-level API.

00:44:10.246 --> 00:44:12.846 A:middle
And you can always access
a stream description

00:44:13.246 --> 00:44:14.636 A:middle
from an AVAudioFormat.

00:44:15.346 --> 00:44:18.666 A:middle
But now we can move
on to other ways

00:44:18.726 --> 00:44:20.396 A:middle
to interact with AVAudioFormat.

00:44:22.416 --> 00:44:28.976 A:middle
So in the past we've had this
concept of canonical formats.

00:44:29.616 --> 00:44:32.426 A:middle
And this concept goes
back to about 2002

00:44:32.426 --> 00:44:34.956 A:middle
in Mac OS 10.0 or 10.1 or so.

00:44:35.766 --> 00:44:39.736 A:middle
So this format was
floating-point, 32-bit,

00:44:40.036 --> 00:44:43.116 A:middle
de-interleaved, but then
we got along to iOS,

00:44:43.356 --> 00:44:46.696 A:middle
and we couldn't really
recommend using float everywhere

00:44:46.696 --> 00:44:48.496 A:middle
because we didn't have the
greatest floating-point

00:44:48.496 --> 00:44:49.576 A:middle
performance initially.

00:44:50.026 --> 00:44:54.866 A:middle
So for a while canonical
was 8.24 fixed-point.

00:44:55.986 --> 00:44:58.646 A:middle
But because of that
schism we want to reunite

00:44:58.646 --> 00:45:00.166 A:middle
under something new now.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:44:58.646 --> 00:45:00.166 A:middle
under something new now.

00:45:00.456 --> 00:45:03.266 A:middle
We've deprecated the
concept of canonical formats.

00:45:03.666 --> 00:45:05.516 A:middle
Now we have what we
call a standard format.

00:45:05.856 --> 00:45:09.776 A:middle
We're back to non-interleaved
32-bit floats on both platforms.

00:45:10.136 --> 00:45:12.556 A:middle
So this is the simplest way

00:45:12.556 --> 00:45:15.296 A:middle
to construct an AVAudioFormat
now is with,

00:45:16.166 --> 00:45:17.856 A:middle
you can create a standard format

00:45:17.906 --> 00:45:20.316 A:middle
by specifying just a sample
rate and a channel count.

00:45:21.776 --> 00:45:24.926 A:middle
You can also query any
AVAudioFormat you might come

00:45:24.926 --> 00:45:28.416 A:middle
across and find out if it is
a standard format using the

00:45:28.416 --> 00:45:29.346 A:middle
standard property.

00:45:32.166 --> 00:45:38.336 A:middle
We've also provided for
using Common Formats

00:45:38.816 --> 00:45:40.276 A:middle
with AVAudioFormat.

00:45:40.406 --> 00:45:43.726 A:middle
And we define Common Formats
as formats you would often use

00:45:43.726 --> 00:45:46.726 A:middle
in signal processing
such as 16-bit integers

00:45:47.236 --> 00:45:50.216 A:middle
if you've been using that
on iOS or other platforms.

00:45:50.786 --> 00:45:52.866 A:middle
We also provide for
64-bit floats.

00:45:53.126 --> 00:45:56.436 A:middle
And it's very easy to create
an AVAudioFormat in one

00:45:56.436 --> 00:45:59.646 A:middle
of these formats by
specifying which one you want,

00:45:59.776 --> 00:46:01.936 A:middle
the sample rate channel count,
and whether it's inter-leaved.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:45:59.776 --> 00:46:01.936 A:middle
the sample rate channel count,
and whether it's inter-leaved.

00:46:02.606 --> 00:46:05.936 A:middle
You can query any format to
see if it is some common format

00:46:06.356 --> 00:46:10.246 A:middle
or something else using
the Common Format property.

00:46:10.916 --> 00:46:15.826 A:middle
OK. So that's AVAudioFormat.

00:46:15.826 --> 00:46:17.586 A:middle
Let's look at
AVAudioChannelLayout.

00:46:19.866 --> 00:46:22.936 A:middle
Briefly here, this describes
the ordering or the roles

00:46:22.936 --> 00:46:25.376 A:middle
of multiple channels, which
is especially important,

00:46:25.606 --> 00:46:27.006 A:middle
for example, in surround sound.

00:46:27.416 --> 00:46:30.246 A:middle
You might have left, right,
center, or you might have left,

00:46:30.246 --> 00:46:32.376 A:middle
center, right, and so on.

00:46:32.376 --> 00:46:34.866 A:middle
It's important to know the
actual order of the channels.

00:46:35.446 --> 00:46:39.226 A:middle
So every AVAudioFormat may
have an AVAudioChannelLayout.

00:46:39.226 --> 00:46:42.216 A:middle
And, in fact, when
constructing the AVAudioFormat,

00:46:42.806 --> 00:46:45.556 A:middle
if you were describing three
or more channels you have

00:46:45.586 --> 00:46:46.966 A:middle
to tell us what the layout is.

00:46:47.356 --> 00:46:51.096 A:middle
So it becomes unambiguous to
anyplace else in the system

00:46:51.096 --> 00:46:53.386 A:middle
that sees that AVAudioFormat
what the order

00:46:53.386 --> 00:46:54.546 A:middle
of the channels are.

00:46:55.656 --> 00:46:59.126 A:middle
So the underlying
AudioChannelLayout object is

00:46:59.316 --> 00:47:00.966 A:middle
pretty much exposed
the way it is here.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:46:59.316 --> 00:47:00.966 A:middle
pretty much exposed
the way it is here.

00:47:00.966 --> 00:47:03.386 A:middle
You can go look at that
in the CoreAudioTypes.h,

00:47:03.476 --> 00:47:04.976 A:middle
but we have wrapped that up

00:47:04.976 --> 00:47:07.276 A:middle
in the AVAudioChannelLayout
for you.

00:47:08.006 --> 00:47:14.466 A:middle
OK. Moving on let's look
at AVAudioPCMBuffer.

00:47:20.026 --> 00:47:24.106 A:middle
So buffer can be a sort of
funny term when we're dealing

00:47:24.106 --> 00:47:25.376 A:middle
with de-interleaved audio

00:47:25.376 --> 00:47:27.686 A:middle
because of the audioBufferList
structure,

00:47:28.196 --> 00:47:32.076 A:middle
but that aside you can
think of it simply as memory

00:47:32.136 --> 00:47:33.476 A:middle
for storing your audio data

00:47:33.566 --> 00:47:36.336 A:middle
in any format including
non-interleaved formats.

00:47:36.646 --> 00:47:40.816 A:middle
And here at the low-level
structures, which these ones

00:47:40.816 --> 00:47:43.856 A:middle
in particular can also be
a bit of a bother to deal

00:47:43.856 --> 00:47:46.836 A:middle
with because AudioBufferList
is variable length.

00:47:47.396 --> 00:47:50.226 A:middle
So you can simply create
an AVAudioPCMBuffer.

00:47:50.506 --> 00:47:54.256 A:middle
It'll create an audioBufferList
for you of the right size.

00:47:54.906 --> 00:47:58.186 A:middle
And you can always fetch it back
out of the AVAudioPCMBuffer.

00:47:58.776 --> 00:48:02.526 A:middle
Here's the initializer.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:47:58.776 --> 00:48:02.526 A:middle
Here's the initializer.

00:48:03.096 --> 00:48:06.206 A:middle
So to create a buffer
you specify the format

00:48:06.476 --> 00:48:09.016 A:middle
and a capacity in
audio sample frames.

00:48:10.166 --> 00:48:14.186 A:middle
You can always fetch back the
buffer's format and the capacity

00:48:14.186 --> 00:48:15.586 A:middle
with which it was constructed.

00:48:16.506 --> 00:48:21.086 A:middle
And unlike audioBufferList,
which has a simple byte size

00:48:21.216 --> 00:48:24.496 A:middle
for every buffer, here
we've separated the concept

00:48:24.496 --> 00:48:25.686 A:middle
of capacity and length.

00:48:26.206 --> 00:48:28.916 A:middle
So there's the fixed
capacity it was created with

00:48:29.456 --> 00:48:32.006 A:middle
and the frame length,
which expresses the number

00:48:32.006 --> 00:48:36.226 A:middle
of currently valid
frames in the buffer.

00:48:36.776 --> 00:48:38.486 A:middle
Some more methods here.

00:48:38.646 --> 00:48:42.516 A:middle
To get to the underlying samples
we provide these simple type

00:48:42.516 --> 00:48:43.856 A:middle
safe assessors.

00:48:45.566 --> 00:48:49.326 A:middle
And this is a good
time now to say a word

00:48:49.326 --> 00:48:52.376 A:middle
about real-time safety
because these are properties.

00:48:52.376 --> 00:48:55.026 A:middle
And as useful as they may be for
actually getting to the data,

00:48:55.426 --> 00:48:58.196 A:middle
since they're properties they
may involve a method lookup,

00:48:58.866 --> 00:49:04.006 A:middle
which can, in principle,
take a miss on the lookup


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:48:58.866 --> 00:49:04.006 A:middle
which can, in principle,
take a miss on the lookup

00:49:04.416 --> 00:49:06.456 A:middle
and cause you to block.

00:49:06.676 --> 00:49:09.986 A:middle
So if you're going to be
using AVAudioPCMBuffers

00:49:09.986 --> 00:49:13.966 A:middle
on audio real-time threads,
it's best to cache these members

00:49:14.536 --> 00:49:17.286 A:middle
in some safe context when you're
first looking at the buffer

00:49:18.136 --> 00:49:22.526 A:middle
and use those cached members
on the real-time thread.

00:49:23.416 --> 00:49:27.316 A:middle
OK. That's PCM Buffer.

00:49:27.316 --> 00:49:28.776 A:middle
Now we can look at AudioFile,

00:49:28.816 --> 00:49:31.216 A:middle
which wraps all these
other classes together.

00:49:33.376 --> 00:49:35.886 A:middle
So here we let you
read and write files

00:49:35.886 --> 00:49:37.866 A:middle
of any CoreAudio
supported format.

00:49:37.906 --> 00:49:42.546 A:middle
This ranges from .M4A,
.MP4, .WAV, .CAF, .AIFF,

00:49:42.546 --> 00:49:45.816 A:middle
and more I can't
think of right now.

00:49:46.106 --> 00:49:51.266 A:middle
So in accessing the file, here
we give you a single way to read

00:49:51.266 --> 00:49:54.396 A:middle
and write the file
completely independent

00:49:54.396 --> 00:49:56.176 A:middle
of the file's actual
data format.

00:49:56.586 --> 00:50:00.766 A:middle
So if it's an encoded format
like AAC or Apple Lossless


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:49:56.586 --> 00:50:00.766 A:middle
So if it's an encoded format
like AAC or Apple Lossless

00:50:00.766 --> 00:50:04.406 A:middle
or MP3, if there's a
codec on the system,

00:50:04.406 --> 00:50:07.766 A:middle
and in most cases there is,
we will, transparently to you,

00:50:07.766 --> 00:50:11.206 A:middle
decode from that format
as you read the file.

00:50:12.676 --> 00:50:15.806 A:middle
Similarly when you're writing
an audio file we will encode

00:50:15.806 --> 00:50:19.106 A:middle
from PCM into that encoded
format if we have an encoder.

00:50:21.146 --> 00:50:23.696 A:middle
So to do this, the
file has this concept

00:50:23.696 --> 00:50:25.146 A:middle
of the processing format.

00:50:25.696 --> 00:50:28.766 A:middle
And the processing format
is simply the PCM format

00:50:29.086 --> 00:50:31.236 A:middle
with which you will
interact with the file.

00:50:32.076 --> 00:50:35.736 A:middle
So you specify the PCM format
when you create the file,

00:50:35.816 --> 00:50:38.646 A:middle
and it has to be either a
standard or common format.

00:50:39.676 --> 00:50:41.066 A:middle
The only limitation here is

00:50:41.156 --> 00:50:44.046 A:middle
that we don't permit sample
rate conversion as you read

00:50:44.046 --> 00:50:45.826 A:middle
from or write to a file.

00:50:46.076 --> 00:50:47.716 A:middle
Your processing format
needs to be

00:50:47.716 --> 00:50:50.466 A:middle
at the same sample rate
as the file itself.

00:50:51.006 --> 00:50:53.996 A:middle
Now, if you're familiar with
the Audio Toolbox Extended Audio

00:50:53.996 --> 00:50:56.426 A:middle
File API, this is
functionally very similar,

00:50:56.766 --> 00:50:59.906 A:middle
and it's just a bit
simpler to use.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:51:00.556 --> 00:51:04.446 A:middle
So I'm looking now
at the initializers

00:51:05.046 --> 00:51:07.776 A:middle
and some assessors
for AVAudioFile.

00:51:07.896 --> 00:51:10.366 A:middle
Here's the initializer
for reading from a file.

00:51:10.626 --> 00:51:14.246 A:middle
If you don't specify a
processing format you simply

00:51:14.246 --> 00:51:18.436 A:middle
are, you get the
default behavior,

00:51:18.436 --> 00:51:20.456 A:middle
which is that your
processing format will be a

00:51:20.456 --> 00:51:21.466 A:middle
standard format.

00:51:23.796 --> 00:51:27.476 A:middle
Very similarly to creating
an AVAudioFile for writing,

00:51:27.536 --> 00:51:29.236 A:middle
the only extra information
you need

00:51:29.236 --> 00:51:30.916 A:middle
to give us is a settings
dictionary.

00:51:31.326 --> 00:51:33.516 A:middle
This is the same
settings dictionary passed

00:51:33.516 --> 00:51:35.006 A:middle
to AV Audio Recorder.

00:51:35.536 --> 00:51:37.226 A:middle
And in there there are keys,

00:51:37.646 --> 00:51:41.366 A:middle
which specify the file format
you want to use, and in the case

00:51:41.366 --> 00:51:45.036 A:middle
of example, for example AAC
you can specify the bit rate

00:51:45.446 --> 00:51:46.966 A:middle
and any other encoder settings.

00:51:47.016 --> 00:51:48.836 A:middle
Those are in the
settings dictionary.

00:51:50.776 --> 00:51:55.726 A:middle
So once you've built a file
you can always access back the

00:51:55.726 --> 00:51:57.826 A:middle
actual file format on disk.

00:51:58.186 --> 00:52:03.026 A:middle
So that might be, for example,
AAC, 44 kHz, two channels.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:51:58.186 --> 00:52:03.026 A:middle
So that might be, for example,
AAC, 44 kHz, two channels.

00:52:03.396 --> 00:52:06.446 A:middle
But you can also query
the processing format

00:52:07.056 --> 00:52:08.476 A:middle
with which you created the file.

00:52:08.756 --> 00:52:12.726 A:middle
And in the case of the
two simplest initializers,

00:52:13.446 --> 00:52:16.716 A:middle
this would be floating-point,
32-bit,

00:52:16.866 --> 00:52:18.316 A:middle
same sample rate as the file.

00:52:18.446 --> 00:52:20.176 A:middle
Same channel count as the file.

00:52:22.726 --> 00:52:24.826 A:middle
OK. So to read and write

00:52:24.886 --> 00:52:28.506 A:middle
from AVAudioFiles there's a
simple method, readIntoBuffer,

00:52:28.656 --> 00:52:31.596 A:middle
and that will simply
fill the AVAudioPCMBuffer

00:52:31.686 --> 00:52:33.806 A:middle
to its capacity assuming
you have,

00:52:33.876 --> 00:52:34.996 A:middle
you don't hit the end of file.

00:52:36.986 --> 00:52:39.256 A:middle
writeFromBuffer is a
little in that it looks

00:52:39.256 --> 00:52:43.546 A:middle
like the buffer is frame length
rather than the capacity,

00:52:43.546 --> 00:52:45.716 A:middle
so it writes all
of the valid frames

00:52:46.346 --> 00:52:47.996 A:middle
from that buffer to the file.

00:52:49.886 --> 00:52:53.816 A:middle
And you can do random access I/O
when reading from audio files.

00:52:54.486 --> 00:52:57.496 A:middle
So this is like the
standard C-library's seek

00:52:57.496 --> 00:53:00.946 A:middle
and tell functions,
F seek and F tell.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:52:57.496 --> 00:53:00.946 A:middle
and tell functions,
F seek and F tell.

00:53:01.786 --> 00:53:04.346 A:middle
You can query the frame
position to see where you are

00:53:04.346 --> 00:53:05.586 A:middle
when reading an audio file.

00:53:06.126 --> 00:53:09.946 A:middle
And you can also seek to a
different position in the file

00:53:09.946 --> 00:53:13.596 A:middle
by setting the frame position
pointer before you read.

00:53:14.026 --> 00:53:17.416 A:middle
And the next read will proceed
sequentially from that point.

00:53:18.216 --> 00:53:24.846 A:middle
OK. I'd like to tie all
these classes together now

00:53:24.846 --> 00:53:25.896 A:middle
with this short example.

00:53:26.186 --> 00:53:27.526 A:middle
And I've got four screens here.

00:53:27.526 --> 00:53:31.476 A:middle
We'll see what it's like
to open an audio file,

00:53:31.476 --> 00:53:34.866 A:middle
extract some basic
information from it and read

00:53:34.866 --> 00:53:36.576 A:middle
through every sample
in the file.

00:53:36.966 --> 00:53:39.406 A:middle
So here we have initForReading.

00:53:39.956 --> 00:53:41.396 A:middle
We simply pass the URL.

00:53:41.936 --> 00:53:44.626 A:middle
I'm using the variant
here that's explicit,

00:53:44.626 --> 00:53:47.416 A:middle
but I'm passing PCM
Float 32 always.

00:53:47.786 --> 00:53:50.736 A:middle
I could have left those off
and gotten a standard format.

00:53:53.676 --> 00:53:56.296 A:middle
I'm going to fetch some basic
information from the file

00:53:56.296 --> 00:54:00.356 A:middle
and print it, including
the files on disk format


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:53:56.296 --> 00:54:00.356 A:middle
and print it, including
the files on disk format

00:54:00.496 --> 00:54:01.926 A:middle
and the processing format.

00:54:03.056 --> 00:54:05.326 A:middle
I can query the audio
file's length

00:54:05.326 --> 00:54:07.326 A:middle
and frames, sample frames.

00:54:08.166 --> 00:54:12.306 A:middle
And I can convert that length in
frames to a duration by dividing

00:54:12.306 --> 00:54:13.596 A:middle
by the file's sample rate.

00:54:14.006 --> 00:54:17.016 A:middle
OK. Next I'm going to create
a PCM Buffer to read from.

00:54:17.676 --> 00:54:20.286 A:middle
Since the file might be
large, I don't want to try

00:54:20.286 --> 00:54:21.906 A:middle
to read it all into
memory at once.

00:54:22.046 --> 00:54:25.546 A:middle
So I'm going to loop through it
128K sample frames at a time.

00:54:26.336 --> 00:54:28.656 A:middle
So I'm going to create a
buffer with that capacity.

00:54:30.216 --> 00:54:31.176 A:middle
And notice I'm just going

00:54:31.176 --> 00:54:33.646 A:middle
to pass the audio files
processing format.

00:54:34.596 --> 00:54:36.856 A:middle
When allocating this
buffer, and that ensures

00:54:36.856 --> 00:54:38.616 A:middle
that the buffer is
the same format

00:54:38.616 --> 00:54:42.036 A:middle
that the file will be giving me.

00:54:43.226 --> 00:54:47.276 A:middle
And here I'm ready to start
reading through the file.

00:54:47.516 --> 00:54:51.346 A:middle
And I'm going to read one buffer
at a time until I get to the end

00:54:51.876 --> 00:54:55.066 A:middle
so I can query the current frame
position and to see if it's less

00:54:55.166 --> 00:54:57.516 A:middle
than the length I
discovered earlier.

00:54:58.476 --> 00:55:00.016 A:middle
I can read into buffer,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:54:58.476 --> 00:55:00.016 A:middle
I can read into buffer,

00:55:00.016 --> 00:55:02.706 A:middle
which will again fill
the buffer to capacity.

00:55:03.896 --> 00:55:06.456 A:middle
I can double check to
see if I'm done by seeing

00:55:06.456 --> 00:55:07.946 A:middle
if I got a zero length buffer.

00:55:10.306 --> 00:55:15.766 A:middle
And this is a lot of code, but
it boils down to two for loops.

00:55:15.996 --> 00:55:19.316 A:middle
The outer one is walking
through all of the channels

00:55:19.316 --> 00:55:21.146 A:middle
in the buffer if it's
a multichannel file.

00:55:22.676 --> 00:55:25.426 A:middle
And then the inner-loop
will look

00:55:25.426 --> 00:55:27.576 A:middle
at every sample in that buffer.

00:55:29.456 --> 00:55:32.856 A:middle
So given every sample, I can
look at its absolute level

00:55:32.856 --> 00:55:35.826 A:middle
and see if it's the
loudest, or if it's louder

00:55:35.826 --> 00:55:38.266 A:middle
than the loudest sample I've
found so far, and if so,

00:55:38.266 --> 00:55:41.066 A:middle
I can record that level and
where I found it in the file.

00:55:41.736 --> 00:55:45.056 A:middle
So there, in about four screens
of code, I opened an audio file.

00:55:45.056 --> 00:55:49.356 A:middle
I read through the whole
thing one sample at a time.

00:55:49.776 --> 00:55:53.686 A:middle
OK. So moving on I'd like to
just sort of foreshadow the uses

00:55:53.686 --> 00:55:59.796 A:middle
of these classes in the
AVAudioEngine session,

00:55:59.996 --> 00:56:01.636 A:middle
which will follow this one.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:55:59.996 --> 00:56:01.636 A:middle
which will follow this one.

00:56:02.266 --> 00:56:04.706 A:middle
So at the bottom
we see AVAudioFile

00:56:04.706 --> 00:56:05.606 A:middle
and AVAudioPCMBuffer.

00:56:05.916 --> 00:56:06.936 A:middle
And those are both used

00:56:06.976 --> 00:56:09.266 A:middle
by something called
AVAudioPlayerNode,

00:56:09.846 --> 00:56:11.676 A:middle
which will be your
basic mechanism

00:56:11.726 --> 00:56:13.686 A:middle
for scheduling audio
to play back.

00:56:14.846 --> 00:56:17.696 A:middle
If the AudioPlayerNode
is a subclass

00:56:18.116 --> 00:56:22.056 A:middle
of a more generic AVAudioNode
class, which is some unit

00:56:22.056 --> 00:56:26.976 A:middle
of audio processing, and we'll
see how AVAudioFormats are used

00:56:26.976 --> 00:56:29.606 A:middle
when describing how to
connect AVAudioNodes.

00:56:32.696 --> 00:56:35.366 A:middle
So that brings us to the end
of my section of this talk.

00:56:35.676 --> 00:56:38.016 A:middle
We saw the AVAudioFormat
ChannelLayout,

00:56:38.256 --> 00:56:40.156 A:middle
PCM Buffer and file classes.

00:56:40.616 --> 00:56:44.206 A:middle
You can use these without
AVAudioEngine using your

00:56:44.206 --> 00:56:46.906 A:middle
existing code with the
Core Audio, Audio Toolbox,

00:56:46.906 --> 00:56:48.516 A:middle
and Audio Unit C APIs.

00:56:48.996 --> 00:56:51.176 A:middle
If you're careful, just
do real-time saves,

00:56:51.626 --> 00:56:53.496 A:middle
and you can use those
assessor methods

00:56:53.956 --> 00:56:57.226 A:middle
to extract the low
level C structures.

00:56:57.996 --> 00:57:00.786 A:middle
And, again, we'll be seeing how
these are used in more detail


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:56:57.996 --> 00:57:00.786 A:middle
And, again, we'll be seeing how
these are used in more detail

00:57:00.786 --> 00:57:03.136 A:middle
in the next session
on AVAudioEngine.

00:57:03.996 --> 00:57:06.806 A:middle
And that's the end
of our hour here.

00:57:07.196 --> 00:57:08.696 A:middle
We've looked at MIDI
over Bluetooth,

00:57:09.086 --> 00:57:12.366 A:middle
the Inter-App Audio UI
Views, lots of features

00:57:12.366 --> 00:57:16.676 A:middle
of AV Foundation audio,
and we hope you'll stick

00:57:16.676 --> 00:57:18.686 A:middle
around for the next
session on AVAudioEngine.

00:57:21.496 --> 00:57:24.076 A:middle
If you need more information,
Filip is our Evangelist,

00:57:24.076 --> 00:57:25.586 A:middle
and there are the
developer forums.

00:57:27.686 --> 00:57:30.566 A:middle
Here's the next session
I keep talking about.

