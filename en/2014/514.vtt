WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:12.046 --> 00:00:13.986 A:middle
&gt;&gt; My name is David Hayward
and welcome to our first

00:00:13.986 --> 00:00:16.206 A:middle
of two discussions
about Core Image.

00:00:16.206 --> 00:00:18.036 A:middle
And we'll be talking
today about what's new

00:00:18.036 --> 00:00:23.356 A:middle
in Core Image on
both iOS and OS X.

00:00:23.356 --> 00:00:24.736 A:middle
So what is Core Image?

00:00:25.126 --> 00:00:28.626 A:middle
Core Image is a fast,
easy, flexible framework

00:00:28.626 --> 00:00:29.946 A:middle
for doing image processing.

00:00:30.466 --> 00:00:31.726 A:middle
And it supports all

00:00:31.726 --> 00:00:35.476 A:middle
of our supported devices
on both iOS and OS X.

00:00:35.886 --> 00:00:39.996 A:middle
It's also used by several of our
key applications such as photos

00:00:40.966 --> 00:00:42.906 A:middle
on both platforms
and it allows you

00:00:42.906 --> 00:00:44.736 A:middle
to get very good
performance results

00:00:44.736 --> 00:00:46.466 A:middle
and very flexible output.

00:00:46.956 --> 00:00:49.906 A:middle
For those of you who may
be new to Core Image,

00:00:49.966 --> 00:00:51.856 A:middle
I just want to take a few
slides to talk about some

00:00:51.856 --> 00:00:53.786 A:middle
of the key concepts because
those will be relevant

00:00:53.786 --> 00:00:55.216 A:middle
for the rest of the
discussion today.

00:00:56.766 --> 00:00:59.736 A:middle
So first off, filters --
Core Image filters allow you

00:00:59.736 --> 00:01:03.036 A:middle
to perform per-pixel
operations on an image.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:59.736 --> 00:01:03.036 A:middle
to perform per-pixel
operations on an image.

00:01:03.516 --> 00:01:06.736 A:middle
In a simple example, you have
an original image and you want

00:01:06.736 --> 00:01:08.726 A:middle
to apply a sepia
tone filter to it.

00:01:09.056 --> 00:01:10.326 A:middle
And you'll get a
resulting image.

00:01:11.026 --> 00:01:13.196 A:middle
Obviously, that's fun
but where things start

00:01:13.196 --> 00:01:15.756 A:middle
to get interesting is where
you combine multiple filters

00:01:15.756 --> 00:01:18.586 A:middle
in either chains
or complex graphs.

00:01:18.666 --> 00:01:21.676 A:middle
And here an example, you can see
a very interesting result you

00:01:21.676 --> 00:01:24.166 A:middle
can get by just chaining
three filters together,

00:01:24.226 --> 00:01:26.846 A:middle
sepia tone plus a hue
rotation to turn it

00:01:26.846 --> 00:01:29.556 A:middle
into a blue tone
image plus a contrast

00:01:29.556 --> 00:01:30.886 A:middle
to make it more dramatic.

00:01:32.316 --> 00:01:35.246 A:middle
One thing to keep in mind is
these intermediate images are

00:01:35.246 --> 00:01:36.606 A:middle
actually lightweight objects.

00:01:36.936 --> 00:01:39.396 A:middle
So there need not necessarily
even be memory associated

00:01:39.396 --> 00:01:41.816 A:middle
with these of any
significant amount.

00:01:43.216 --> 00:01:44.476 A:middle
Another thing that's
important to keep

00:01:44.476 --> 00:01:49.086 A:middle
in mind is each filter may have
one or more kernels associated.

00:01:49.086 --> 00:01:51.626 A:middle
So these kernels are
the actual algorithm

00:01:51.626 --> 00:01:53.606 A:middle
that implements each
filter's effect.

00:01:54.676 --> 00:01:55.616 A:middle
And one of the great things

00:01:55.616 --> 00:01:58.436 A:middle
about Core Image is we
can take these kernels

00:01:58.706 --> 00:02:01.656 A:middle
and concatenate them into
programs and this allows us


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:01:58.706 --> 00:02:01.656 A:middle
and concatenate them into
programs and this allows us

00:02:01.656 --> 00:02:04.896 A:middle
at runtime to minimize the
amount of intermediate results

00:02:04.996 --> 00:02:07.516 A:middle
and with some great
compiler technology,

00:02:07.906 --> 00:02:11.406 A:middle
both at the image processing and
at the low-level compiler level,

00:02:11.576 --> 00:02:13.616 A:middle
we're able to get the
best possible performance

00:02:13.746 --> 00:02:14.996 A:middle
out of a complex graph.

00:02:15.496 --> 00:02:18.586 A:middle
So that's the basics in
terms of how it works.

00:02:18.886 --> 00:02:21.136 A:middle
These are the four key
object types that you need

00:02:21.136 --> 00:02:23.116 A:middle
to be familiar with if you
want to use Core Image.

00:02:23.696 --> 00:02:26.286 A:middle
The first which we'll be talking
about a lot today is CIKernel.

00:02:26.836 --> 00:02:28.956 A:middle
And this represents a
program that's written in CI's

00:02:28.956 --> 00:02:30.936 A:middle
or Core Image's Kernel language.

00:02:31.876 --> 00:02:36.056 A:middle
Second object type is a
CIFilter and this is an object

00:02:36.056 --> 00:02:38.536 A:middle
that has mutable
input parameters

00:02:38.536 --> 00:02:40.956 A:middle
and those parameters
can be images or numbers

00:02:40.956 --> 00:02:42.846 A:middle
or vectors or other types.

00:02:43.016 --> 00:02:46.166 A:middle
And it also allows you to
use one or more kernels

00:02:46.456 --> 00:02:49.286 A:middle
to create a new image based on
the current state of the output

00:02:49.286 --> 00:02:51.156 A:middle
or of the input parameters.

00:02:52.826 --> 00:02:56.556 A:middle
Third key type is a CIImage
and this is an immutable object

00:02:56.556 --> 00:02:59.416 A:middle
that represents the
recipe to produce an image.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:00.036 --> 00:03:03.246 A:middle
Just the act of creating an
image does not necessarily do

00:03:03.246 --> 00:03:03.966 A:middle
any real work.

00:03:04.226 --> 00:03:06.596 A:middle
The actual work occurs
when you render a CIImage

00:03:06.596 --> 00:03:08.896 A:middle
into a CIContext and
that's the object

00:03:08.896 --> 00:03:10.316 A:middle
through which you
render results.

00:03:11.296 --> 00:03:12.896 A:middle
So those are the basics.

00:03:13.476 --> 00:03:15.476 A:middle
What I want to talk
about today is what's new

00:03:15.476 --> 00:03:17.656 A:middle
in Core Image this year and
we have a lot to talk about.

00:03:18.096 --> 00:03:20.276 A:middle
We have a bunch of new
things that are on iOS.

00:03:20.386 --> 00:03:23.276 A:middle
For example, we have our
most requested feature

00:03:23.386 --> 00:03:24.886 A:middle
which is Custom CIKernels.

00:03:25.456 --> 00:03:28.236 A:middle
We also like to talk about
how you can do Photo Editing

00:03:28.236 --> 00:03:29.546 A:middle
Extensions using Core Image

00:03:29.936 --> 00:03:33.226 A:middle
and also how we can now
support large images on iOS.

00:03:33.386 --> 00:03:36.696 A:middle
We also made some improvements
to how the GPU render is used.

00:03:38.086 --> 00:03:40.026 A:middle
We also have some
API modernization.

00:03:40.566 --> 00:03:42.166 A:middle
We have some new
built-in filters.

00:03:42.506 --> 00:03:45.406 A:middle
We have some new CIDetectors
and then lastly, we will talk

00:03:45.406 --> 00:03:50.006 A:middle
about some new things that
we have on the Mac OS X side,

00:03:50.356 --> 00:03:52.946 A:middle
improve RAW support and
how to use a second GPU.

00:03:54.716 --> 00:03:56.926 A:middle
So first and most interesting,

00:03:56.926 --> 00:03:59.236 A:middle
I think is Custom
CIKernels on iOS.

00:03:59.236 --> 00:04:01.466 A:middle
As I mentioned, this has been
our top requested feature.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:59.236 --> 00:04:01.466 A:middle
As I mentioned, this has been
our top requested feature.

00:04:02.146 --> 00:04:06.146 A:middle
Core Image already has 115
great built-in filters on iOS.

00:04:06.536 --> 00:04:08.346 A:middle
But now you can easily
create your own.

00:04:08.686 --> 00:04:11.246 A:middle
So this is a terrific
feature for developers.

00:04:12.076 --> 00:04:14.656 A:middle
When you're writing
CIKernels on iOS,

00:04:14.656 --> 00:04:16.346 A:middle
you can use the same
CIKernel language

00:04:16.346 --> 00:04:18.336 A:middle
that you use today on OS X.

00:04:18.926 --> 00:04:20.185 A:middle
There are a few extensions

00:04:20.245 --> 00:04:23.526 A:middle
which allow making
typical kernels even easier

00:04:23.706 --> 00:04:25.486 A:middle
and we'll talk about
that in much more detail

00:04:25.486 --> 00:04:26.596 A:middle
in our next presentation.

00:04:27.856 --> 00:04:30.076 A:middle
Where can your CIKernels live?

00:04:30.456 --> 00:04:32.056 A:middle
Well, they can live
in your application.

00:04:32.386 --> 00:04:35.016 A:middle
The kernel code can
either be a text resource

00:04:35.116 --> 00:04:36.966 A:middle
or it can just be an
NSString, if you'd like.

00:04:37.476 --> 00:04:41.356 A:middle
The kernel is wrapped
up in CIFilter subclass

00:04:41.356 --> 00:04:43.496 A:middle
that you provide that
applies to kernels

00:04:43.496 --> 00:04:44.636 A:middle
to produce an output image.

00:04:45.996 --> 00:04:48.246 A:middle
Another great place for
your Custom CIKernels

00:04:48.246 --> 00:04:50.426 A:middle
to go is inside an
App Extension.

00:04:50.426 --> 00:04:53.986 A:middle
For example, Photo Editing
Extensions can use CIKernels

00:04:53.986 --> 00:04:56.116 A:middle
and CIFilter subclasses
very effectively.

00:04:56.636 --> 00:05:00.486 A:middle
And you can use them to modify
either photos or videos.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:56.636 --> 00:05:00.486 A:middle
And you can use them to modify
either photos or videos.

00:05:02.736 --> 00:05:05.396 A:middle
So again, we'll be talking
our next presentation

00:05:05.576 --> 00:05:09.376 A:middle
in much more detail about
how to use CIKernels on iOS

00:05:09.406 --> 00:05:11.076 A:middle
but let me just give
you a little teaser now

00:05:11.176 --> 00:05:12.276 A:middle
of how simple it is.

00:05:12.766 --> 00:05:14.836 A:middle
Here we have in just
basically two lines of code,

00:05:15.316 --> 00:05:17.216 A:middle
how to use a Custom CIKernel.

00:05:17.606 --> 00:05:22.036 A:middle
We create an NSString which has
some CI Core Image source code

00:05:22.036 --> 00:05:22.276 A:middle
in it.

00:05:22.646 --> 00:05:24.766 A:middle
This is a very simple kernel

00:05:24.766 --> 00:05:27.546 A:middle
that takes a pixel
value and inverts it.

00:05:27.896 --> 00:05:30.486 A:middle
You'll notice it's actually
subtracting it not from 1

00:05:30.486 --> 00:05:31.576 A:middle
but from the alpha value.

00:05:31.576 --> 00:05:34.746 A:middle
That's the correct way to invert
if you've got premultiplied data

00:05:34.856 --> 00:05:36.766 A:middle
which is what Core
Image receives.

00:05:37.766 --> 00:05:40.166 A:middle
Once you have the program
written then all you need

00:05:40.166 --> 00:05:42.716 A:middle
to do is create a
CIKernel object

00:05:42.716 --> 00:05:45.416 A:middle
from the string and
then apply it.

00:05:45.776 --> 00:05:47.456 A:middle
You can specify two things.

00:05:47.456 --> 00:05:51.366 A:middle
One is the resulting
extent of the produced image

00:05:51.786 --> 00:05:55.816 A:middle
and also the arguments that
will be passed to that kernel.

00:05:56.286 --> 00:05:58.836 A:middle
In this particular example,
there is only a single argument

00:05:58.836 --> 00:06:02.196 A:middle
which is the input image and
so as a result, our arguments


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:05:58.836 --> 00:06:02.196 A:middle
which is the input image and
so as a result, our arguments

00:06:02.336 --> 00:06:06.686 A:middle
down below is just an array
with a single image in it.

00:06:07.636 --> 00:06:10.636 A:middle
So to give you a little bit
of idea of what that looks

00:06:10.636 --> 00:06:12.156 A:middle
like in practice, I
have a quick demo.

00:06:12.546 --> 00:06:14.556 A:middle
This is a fun example
that we wrote.

00:06:15.496 --> 00:06:18.016 A:middle
And it's kind of an
example of something

00:06:18.016 --> 00:06:20.776 A:middle
that you wouldn't necessarily
have as a built-in filter.

00:06:22.296 --> 00:06:22.716 A:middle
Let's see.

00:06:23.846 --> 00:06:27.216 A:middle
But it would be fun for
a presentation like this.

00:06:27.296 --> 00:06:30.016 A:middle
So we have an application
called Core Image Funhouse

00:06:30.596 --> 00:06:33.656 A:middle
and this allows you to explore
all the built-in filters

00:06:33.936 --> 00:06:37.276 A:middle
and also allows you to see
some sample code for how

00:06:37.416 --> 00:06:38.676 A:middle
to write Custom CIKernels.

00:06:39.226 --> 00:06:40.786 A:middle
So the image starts out as gray.

00:06:41.346 --> 00:06:44.116 A:middle
The first thing we need to do is
provide an image to start with.

00:06:44.376 --> 00:06:46.936 A:middle
And we're going to say that we
want the video feed to come in.

00:06:47.456 --> 00:06:51.146 A:middle
And then I'm going to add
a filter and you can see,

00:06:51.146 --> 00:06:53.056 A:middle
we're seeing a list
of all the filters

00:06:53.056 --> 00:06:54.556 A:middle
that are part of Core Image.

00:06:55.066 --> 00:06:58.416 A:middle
And we created one down
here called WWDC 2014

00:06:59.056 --> 00:07:01.366 A:middle
and I hope you can see this
so that I can kind of wave


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:59.056 --> 00:07:01.366 A:middle
and I hope you can see this
so that I can kind of wave

00:07:01.366 --> 00:07:03.316 A:middle
in front of the camera.

00:07:03.316 --> 00:07:07.706 A:middle
What we're doing here is
actually algorithmically taking

00:07:07.706 --> 00:07:10.426 A:middle
the luminance from the
video feed and then using

00:07:10.426 --> 00:07:11.736 A:middle
that to control the size

00:07:11.736 --> 00:07:15.856 A:middle
of the geometrically
generated rounded rectangle.

00:07:16.376 --> 00:07:20.676 A:middle
And we can change the size
of that larger or smaller

00:07:21.776 --> 00:07:24.446 A:middle
or we can change the amount
of the rounded radius here.

00:07:24.846 --> 00:07:28.686 A:middle
It's actually a little easier
to see that it's a video feed

00:07:28.686 --> 00:07:34.076 A:middle
when it's smaller but it looks
more cool when it's bigger.

00:07:34.206 --> 00:07:38.086 A:middle
So and we're getting about
30 frames per second on that

00:07:38.086 --> 00:07:40.816 A:middle
which is probably the frame
rate of the camera right now.

00:07:41.406 --> 00:07:44.956 A:middle
So that's our short example and
we'll have that code available

00:07:45.236 --> 00:07:46.426 A:middle
for download at some point soon.

00:07:47.646 --> 00:07:50.326 A:middle
So again, that's Custom
CIKernels and please come

00:07:50.326 --> 00:07:53.366 A:middle
to our second session to see
all you can learn about that.

00:07:54.296 --> 00:07:55.516 A:middle
The next thing I'd like to talk

00:07:55.516 --> 00:07:59.176 A:middle
about briefly is the Photo
Editing Extensions on iOS.

00:07:59.236 --> 00:08:02.206 A:middle
There are whole talks on
that this year at WWDC.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:07:59.236 --> 00:08:02.206 A:middle
There are whole talks on
that this year at WWDC.

00:08:02.446 --> 00:08:05.256 A:middle
I'd like to talk a little
bit about how that works

00:08:05.346 --> 00:08:06.706 A:middle
in relationship to Core Image.

00:08:07.326 --> 00:08:08.956 A:middle
So here's just a
little short video run

00:08:08.956 --> 00:08:11.156 A:middle
through of how this
works in practice.

00:08:11.946 --> 00:08:14.586 A:middle
What we have is an image
the user wanted to edit.

00:08:14.876 --> 00:08:16.996 A:middle
They brought up a
list of extensions.

00:08:16.996 --> 00:08:18.186 A:middle
We picked the Core Image one

00:08:18.966 --> 00:08:22.196 A:middle
and this particular Core Image
based extension has two sliders.

00:08:22.196 --> 00:08:25.396 A:middle
One is the amount of sepia
tone which we can slide

00:08:25.806 --> 00:08:27.526 A:middle
and we're getting
very good frame rates

00:08:27.526 --> 00:08:29.516 A:middle
to the screen as we do this.

00:08:30.046 --> 00:08:33.866 A:middle
And then the second slider
is a vignette amount.

00:08:34.126 --> 00:08:36.056 A:middle
So it starts out with
a large radius and then

00:08:36.056 --> 00:08:38.066 A:middle
as you bring the radius
smaller, you get more

00:08:38.306 --> 00:08:41.926 A:middle
of the vignette effect
as you bring it down.

00:08:42.116 --> 00:08:44.246 A:middle
And all of this is
happening right now

00:08:44.246 --> 00:08:45.596 A:middle
on a display-sized image.

00:08:45.916 --> 00:08:48.236 A:middle
Later on, when you
hit Save, it's applied

00:08:48.236 --> 00:08:51.206 A:middle
on a full-sized image which
is the 12 megapixel image

00:08:51.206 --> 00:08:51.736 A:middle
in this case.

00:08:52.266 --> 00:08:54.276 A:middle
And it goes back into your
library with your edits.

00:08:54.956 --> 00:08:56.436 A:middle
So that's how it
looks in practice.

00:08:56.746 --> 00:08:59.206 A:middle
I'm not going to go into too
much detail on how to code this

00:08:59.276 --> 00:09:01.166 A:middle
but I'll give you
some good advice here.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:08:59.276 --> 00:09:01.166 A:middle
but I'll give you
some good advice here.

00:09:01.796 --> 00:09:05.106 A:middle
First off, you can start to
create a Photo Editing Extension

00:09:05.106 --> 00:09:06.916 A:middle
by going into the
templates in Xcode.

00:09:07.516 --> 00:09:09.956 A:middle
We'll also provide some
sample code as well

00:09:09.956 --> 00:09:11.216 A:middle
so that'll be a good
starting point.

00:09:11.766 --> 00:09:13.316 A:middle
But as I said, I
wanted to talk a bit

00:09:13.316 --> 00:09:15.426 A:middle
about how you can use
Core Image effectively

00:09:15.726 --> 00:09:17.366 A:middle
within Photo Editing Extensions.

00:09:18.316 --> 00:09:20.106 A:middle
There's basically three steps.

00:09:20.196 --> 00:09:22.916 A:middle
The first step is when your
extension is initialized,

00:09:23.446 --> 00:09:26.486 A:middle
what you want to do is you want
to ask the editing input object

00:09:26.486 --> 00:09:28.466 A:middle
for a display-sized image.

00:09:29.046 --> 00:09:31.256 A:middle
Initially, that is a UI
image object and from

00:09:31.256 --> 00:09:34.446 A:middle
that you can create a CGImage
and then from that CIImage.

00:09:34.446 --> 00:09:36.496 A:middle
That sounds like
a couple of steps

00:09:36.496 --> 00:09:39.226 A:middle
but it's actually those are
just lightweight wrappers.

00:09:39.896 --> 00:09:41.876 A:middle
Once you've created that
CIImage, we're going to store

00:09:41.876 --> 00:09:44.516 A:middle
that in a property
for our delegate.

00:09:45.206 --> 00:09:47.756 A:middle
The other thing, it's a good
time to do at that time is

00:09:47.756 --> 00:09:49.756 A:middle
to create your view that you're
going to be rendering into.

00:09:49.756 --> 00:09:53.736 A:middle
We recommend using a GLKView
and also create a CIContext

00:09:53.736 --> 00:09:56.116 A:middle
that is associated
with that view.

00:09:56.116 --> 00:09:58.466 A:middle
And it's good to store that
away in the property as well.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:00.326 --> 00:10:04.516 A:middle
Step two is what you do every
time the user makes an edit

00:10:04.516 --> 00:10:07.316 A:middle
in your extension so every
time the slider moves.

00:10:07.866 --> 00:10:09.136 A:middle
And this is very simple.

00:10:09.236 --> 00:10:12.166 A:middle
What you do is you recall
the display-sized CIImage

00:10:12.166 --> 00:10:13.386 A:middle
that we created in step one.

00:10:14.146 --> 00:10:16.096 A:middle
We apply the filters
that correspond

00:10:16.096 --> 00:10:17.836 A:middle
to those slider adjustments.

00:10:17.886 --> 00:10:21.696 A:middle
So in that previous example,
it was the sepia tone filter

00:10:21.696 --> 00:10:23.276 A:middle
and the vignette effect filter.

00:10:24.076 --> 00:10:25.416 A:middle
And then once you've
chained those together,

00:10:25.416 --> 00:10:26.856 A:middle
you get the output
image from that.

00:10:27.466 --> 00:10:29.876 A:middle
And then you're going to
draw that using the CIContext

00:10:29.876 --> 00:10:31.776 A:middle
that we also created
in step one.

00:10:32.326 --> 00:10:34.566 A:middle
And Step three is what happens

00:10:34.566 --> 00:10:36.086 A:middle
when the user clicks
the Done button.

00:10:36.086 --> 00:10:38.826 A:middle
And this is slightly
different because in this case,

00:10:38.826 --> 00:10:40.956 A:middle
you want to apply the effect
on the full-sized image.

00:10:41.516 --> 00:10:44.826 A:middle
So what we have here is we can
ask the editing input object

00:10:44.826 --> 00:10:46.676 A:middle
for its fullSizeImageURL.

00:10:46.876 --> 00:10:48.836 A:middle
From that, we create a CIImage

00:10:49.376 --> 00:10:51.196 A:middle
and we apply the
filters to this as well.

00:10:51.606 --> 00:10:54.386 A:middle
Now, for the most part, this is
the same as we did in step two.

00:10:54.676 --> 00:10:57.696 A:middle
Some parameters however such as
radiuses may need to be scaled

00:10:58.176 --> 00:11:00.116 A:middle
in accordance to the fact
that you're now working


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:58.176 --> 00:11:00.116 A:middle
in accordance to the fact
that you're now working

00:11:00.116 --> 00:11:01.076 A:middle
on a full-sized image.

00:11:02.106 --> 00:11:04.266 A:middle
Once you have chained
together your filters,

00:11:04.266 --> 00:11:06.486 A:middle
you ask the output
image and then you --

00:11:06.936 --> 00:11:10.526 A:middle
the way this API works is you
return the CGImage so you can do

00:11:10.526 --> 00:11:11.926 A:middle
that very easily
with Core Image.

00:11:12.286 --> 00:11:16.606 A:middle
You ask a CIContext to create a
CGImage and this will work even

00:11:16.606 --> 00:11:18.166 A:middle
on the full-sized image.

00:11:19.876 --> 00:11:22.446 A:middle
So that brings me to the
next subject I want to talk

00:11:22.446 --> 00:11:25.426 A:middle
about today which is working
on large images on iOS.

00:11:25.556 --> 00:11:28.646 A:middle
So we've made some great
improvements here in addition

00:11:28.646 --> 00:11:31.436 A:middle
to the supporting kernels, this
is I think our second key thing

00:11:31.436 --> 00:11:33.026 A:middle
that we've added
this year on iOS.

00:11:34.456 --> 00:11:38.116 A:middle
So now you can -- we have
full support for images

00:11:38.116 --> 00:11:40.096 A:middle
that are larger than
the GPU texture limits.

00:11:40.716 --> 00:11:43.716 A:middle
And this means that input
images can now be larger than 4K

00:11:44.186 --> 00:11:46.966 A:middle
and output renders
can be larger than 4K.

00:11:47.436 --> 00:11:50.336 A:middle
We refer to this as large
images but in practice,

00:11:50.386 --> 00:11:52.506 A:middle
4K images are not
that large these days.

00:11:52.506 --> 00:11:56.076 A:middle
Many of our devices'
cameras are bigger than that.

00:11:56.466 --> 00:11:58.256 A:middle
So this is actually a
really critical feature

00:11:58.256 --> 00:11:59.916 A:middle
to support this size
image as well.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:00.956 --> 00:12:03.516 A:middle
The way we achieve
this automatically is

00:12:03.516 --> 00:12:05.656 A:middle
that we have automatic
tiling support in Core Image.

00:12:06.196 --> 00:12:08.486 A:middle
And this among other
things leverages some great

00:12:08.486 --> 00:12:11.496 A:middle
improvements that were made
in ImageIO and they're JPEG

00:12:11.496 --> 00:12:14.096 A:middle
to improve how the
decoder and encoder works.

00:12:14.876 --> 00:12:17.056 A:middle
And also, there's
some great features

00:12:17.056 --> 00:12:20.346 A:middle
in the Core Image language
that allows supporting

00:12:20.346 --> 00:12:21.416 A:middle
of large image as well.

00:12:22.176 --> 00:12:24.516 A:middle
So let me talk about that last
item in a little bit of detail.

00:12:25.276 --> 00:12:28.006 A:middle
So the CIKernel language
allows your kernels

00:12:28.006 --> 00:12:30.016 A:middle
to just work automatically
regardless

00:12:30.016 --> 00:12:33.416 A:middle
of whether tiling happens
or at what size it happens.

00:12:33.846 --> 00:12:34.876 A:middle
So this is a great feature

00:12:34.876 --> 00:12:38.226 A:middle
that makes writing
CIKernels very flexible.

00:12:39.306 --> 00:12:43.286 A:middle
The way this is achieved is by
two key extensions that we have

00:12:43.286 --> 00:12:45.086 A:middle
in our language and
these are available both

00:12:45.086 --> 00:12:47.466 A:middle
on OS X and on iOS now.

00:12:48.096 --> 00:12:50.886 A:middle
The first is a function called
desk coordinate or deskCoord

00:12:51.566 --> 00:12:53.216 A:middle
and that allows Core Image

00:12:53.516 --> 00:12:55.486 A:middle
to support tiled
output automatically.

00:12:56.286 --> 00:12:59.176 A:middle
It basically allows your kernel
to see the desk coordinate

00:12:59.456 --> 00:13:02.136 A:middle
in the native images space even
though we may only be rendering


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:59.456 --> 00:13:02.136 A:middle
in the native images space even
though we may only be rendering

00:13:02.136 --> 00:13:03.866 A:middle
a given tile at a time.

00:13:05.026 --> 00:13:08.656 A:middle
Similarly, there's a function
called samplerTransform

00:13:08.956 --> 00:13:11.356 A:middle
and that allows Core
Image to support tiling

00:13:11.356 --> 00:13:13.776 A:middle
of large input images
automatically.

00:13:14.456 --> 00:13:17.616 A:middle
So this is the two key things
about the CIKernel language

00:13:17.616 --> 00:13:20.186 A:middle
that we'll talk about
in much more detail

00:13:20.186 --> 00:13:21.246 A:middle
in our second presentation.

00:13:23.736 --> 00:13:27.466 A:middle
So another great thing about our
large image support is how we

00:13:27.466 --> 00:13:30.486 A:middle
work together with CGImageRef

00:13:30.556 --> 00:13:32.686 A:middle
and how we get some
great improvements

00:13:32.686 --> 00:13:35.106 A:middle
on iOS 8 by being lazy.

00:13:36.066 --> 00:13:37.656 A:middle
So one thing to keep in mind is

00:13:37.656 --> 00:13:39.686 A:middle
if you have a small
input CGImage

00:13:39.716 --> 00:13:44.096 A:middle
that you create a CIImage from,
then this image is fully decoded

00:13:44.096 --> 00:13:46.926 A:middle
at the time you call
CIImage initWith CGImage.

00:13:48.026 --> 00:13:50.356 A:middle
And that's actually usually
the right thing to do

00:13:50.356 --> 00:13:53.176 A:middle
for small images
because you may be using

00:13:53.176 --> 00:13:55.076 A:middle
that image multiple
times and you want

00:13:55.076 --> 00:14:00.896 A:middle
to take the performance impact
of decoding the JPEG once early.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:13:55.076 --> 00:14:00.896 A:middle
to take the performance impact
of decoding the JPEG once early.

00:14:01.976 --> 00:14:05.156 A:middle
However, for large images,
that's not a good strategy

00:14:05.246 --> 00:14:08.106 A:middle
because you don't want to
require all of that memory

00:14:08.656 --> 00:14:10.496 A:middle
to be -- for that JPEG

00:14:10.496 --> 00:14:12.346 A:middle
to be compressed unless
you know you need it.

00:14:13.156 --> 00:14:17.566 A:middle
So if you have a large
input CGImage, that image,

00:14:18.026 --> 00:14:21.516 A:middle
that JPEG image behind that
CGImage is decoded only

00:14:21.516 --> 00:14:24.596 A:middle
as needed when you
call CIContext render.

00:14:25.186 --> 00:14:29.966 A:middle
So that's a very
important detail.

00:14:30.216 --> 00:14:33.466 A:middle
Similarly, when you're
producing a CGImage as an output

00:14:33.466 --> 00:14:38.556 A:middle
of CIImage, when you call
CIContext createCGImage,

00:14:38.556 --> 00:14:42.706 A:middle
if the output CGImage is small,
then the image is fully rendered

00:14:42.706 --> 00:14:43.956 A:middle
when CGImage is called.

00:14:44.746 --> 00:14:47.856 A:middle
However, if you're producing
a large CGImage as an output

00:14:48.286 --> 00:14:51.376 A:middle
such as an example of
the photo extensions,

00:14:51.816 --> 00:14:54.536 A:middle
the image is only
rendered as needed

00:14:54.536 --> 00:14:56.166 A:middle
when the CGImage is rendered.

00:14:57.286 --> 00:15:00.596 A:middle
This is also important because
a very common situation is you


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:14:57.286 --> 00:15:00.596 A:middle
This is also important because
a very common situation is you

00:15:00.596 --> 00:15:04.106 A:middle
pass the CGImage, the
CGImage DestinationFinalize

00:15:04.356 --> 00:15:08.106 A:middle
to encode it back as a JPEG.

00:15:08.316 --> 00:15:12.406 A:middle
So what all this means is that
if you have a very large JPEG,

00:15:12.856 --> 00:15:16.706 A:middle
you can take that large JPEG,
decode it, apply a filter to it

00:15:16.856 --> 00:15:20.196 A:middle
and re-encode it back into
a JPEG with minimal memory

00:15:20.596 --> 00:15:22.786 A:middle
and great performance
and this is a huge win

00:15:23.146 --> 00:15:24.496 A:middle
for Core Image on iOS.

00:15:25.036 --> 00:15:26.316 A:middle
So let's take a quick example.

00:15:26.636 --> 00:15:31.016 A:middle
You're applying a sepia tone
effect to a 4K by 6K JPEG,

00:15:31.886 --> 00:15:33.726 A:middle
so 100 megabytes of image.

00:15:33.896 --> 00:15:38.606 A:middle
That on iOS 7 took 17 seconds
to decode, apply the filter

00:15:38.606 --> 00:15:39.876 A:middle
and re-encode it as a JPEG.

00:15:40.666 --> 00:15:42.316 A:middle
On iOS 8, that's 1 second.

00:15:43.516 --> 00:15:46.756 A:middle
[ Applause ]

00:15:47.256 --> 00:15:50.316 A:middle
And just as important on iOS
is the memory high water mark

00:15:50.396 --> 00:15:52.786 A:middle
because that can really
force your application

00:15:52.786 --> 00:15:54.366 A:middle
into an unhappy place.

00:15:54.506 --> 00:15:58.016 A:middle
And our high water mark
on iOS 7 was 200 megabytes

00:15:58.016 --> 00:15:58.736 A:middle
which makes sense.

00:15:58.736 --> 00:16:01.696 A:middle
We have a source image that was
fully decompressed and we need


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:15:58.736 --> 00:16:01.696 A:middle
We have a source image that was
fully decompressed and we need

00:16:01.696 --> 00:16:03.956 A:middle
to produce a whole new image
which is the same size.

00:16:04.836 --> 00:16:06.286 A:middle
However because we
now have tiling,

00:16:06.286 --> 00:16:09.576 A:middle
our high water mark
is now 25 megabytes.

00:16:10.516 --> 00:16:15.026 A:middle
[ Applause ]

00:16:15.526 --> 00:16:19.456 A:middle
And just to summarize, on iOS
7, we worked on the full image

00:16:19.456 --> 00:16:21.786 A:middle
at a time and because it
was large, we often had

00:16:21.786 --> 00:16:22.916 A:middle
to use a CPU renderer.

00:16:23.566 --> 00:16:27.286 A:middle
On iOS 8, we have automatic
tiling and as a result,

00:16:27.286 --> 00:16:29.856 A:middle
we can use the GPU
which is a huge win.

00:16:31.516 --> 00:16:34.436 A:middle
So we've also made
some other improvements

00:16:34.436 --> 00:16:36.386 A:middle
to how GPU rendering
works with Core Image

00:16:36.386 --> 00:16:38.666 A:middle
on iOS which are important.

00:16:39.906 --> 00:16:42.146 A:middle
So your application
sometimes needs

00:16:42.146 --> 00:16:43.136 A:middle
to render in the background.

00:16:43.426 --> 00:16:46.006 A:middle
Often either when the app is
just transitioning to background

00:16:46.006 --> 00:16:48.266 A:middle
or when it's fully in
the background state.

00:16:48.666 --> 00:16:50.276 A:middle
On iOS 7, that is supported.

00:16:50.626 --> 00:16:53.946 A:middle
However all background renders
used the slower Core Image CPU

00:16:53.946 --> 00:16:54.566 A:middle
Rendering path.

00:16:55.606 --> 00:16:58.196 A:middle
On iOS 8, we have an improvement
in this regard which is

00:16:58.196 --> 00:17:00.106 A:middle
that renders that occur
within a short time


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:58.196 --> 00:17:00.106 A:middle
that renders that occur
within a short time

00:17:00.106 --> 00:17:03.836 A:middle
of switching the background will
now use the faster GPU renderer.

00:17:04.846 --> 00:17:07.996 A:middle
Now, it is serviced with a lower
GPU priority and the advantage

00:17:07.996 --> 00:17:10.306 A:middle
to that is that any
foreground renderers that happen

00:17:10.306 --> 00:17:11.736 A:middle
at that time will not be --

00:17:11.876 --> 00:17:13.266 A:middle
have any performance impact

00:17:13.685 --> 00:17:16.636 A:middle
because Core Image will be
using a lower priority renderer.

00:17:17.306 --> 00:17:18.636 A:middle
So this is another
great advantage.

00:17:19.806 --> 00:17:23.066 A:middle
There are some restrictions
on this GPU usage.

00:17:23.326 --> 00:17:27.076 A:middle
It is not allowed if you use
CIContext drawImage inRect

00:17:27.076 --> 00:17:29.956 A:middle
fromRect because in that case,
Core Image needs to render

00:17:29.956 --> 00:17:32.476 A:middle
into the client's
[inaudible] context.

00:17:32.826 --> 00:17:36.316 A:middle
However, any of the other render
methods calling createCGImage

00:17:36.316 --> 00:17:37.916 A:middle
or render toCVPixelBuffer

00:17:38.166 --> 00:17:43.506 A:middle
or render toBitmap will
all work in this way.

00:17:44.116 --> 00:17:47.676 A:middle
Another great improvement we
have is oftentimes you want

00:17:47.826 --> 00:17:50.246 A:middle
to do rendering in the
foreground when your app is

00:17:50.246 --> 00:17:52.146 A:middle
in the foreground but do it

00:17:52.196 --> 00:17:54.766 A:middle
from a secondary thread
in a polite manner.

00:17:55.246 --> 00:17:58.336 A:middle
So if your application
is showing one thing

00:17:58.336 --> 00:17:59.146 A:middle
and then doing something

00:17:59.146 --> 00:18:02.906 A:middle
on a secondary thread
using Core Image, on iOS 7,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:17:59.146 --> 00:18:02.906 A:middle
on a secondary thread
using Core Image, on iOS 7,

00:18:02.906 --> 00:18:05.826 A:middle
that required care
in order to avoid --

00:18:06.116 --> 00:18:10.386 A:middle
in order for the secondary
thread to avoid causing glitches

00:18:10.386 --> 00:18:11.266 A:middle
for the foreground thread.

00:18:12.106 --> 00:18:14.486 A:middle
And of course, the only
sure-fire way to avoid that was

00:18:14.486 --> 00:18:16.866 A:middle
to use Core Image's
slower CPU renderer.

00:18:17.486 --> 00:18:19.926 A:middle
On iOS 8, we have a new feature

00:18:20.226 --> 00:18:24.246 A:middle
which is the secondary thread
can now render into a context

00:18:24.246 --> 00:18:26.396 A:middle
that has had this
new option specified

00:18:26.436 --> 00:18:29.396 A:middle
which is CIContext
PriorityRequestLow.

00:18:30.256 --> 00:18:33.436 A:middle
And the idea now is that
context renders using

00:18:33.546 --> 00:18:37.486 A:middle
that context will not
interrupt any foreground higher

00:18:37.486 --> 00:18:38.426 A:middle
priority renders.

00:18:38.786 --> 00:18:40.486 A:middle
So this is also great
for your application.

00:18:41.246 --> 00:18:43.956 A:middle
So this brings me to
some final thoughts

00:18:43.956 --> 00:18:46.226 A:middle
on Core Image's CPU rendering.

00:18:46.956 --> 00:18:50.156 A:middle
Basically, there were three key
reasons why an app would need

00:18:50.156 --> 00:18:52.866 A:middle
to use the CPU renderer
on iOS 7.

00:18:52.866 --> 00:18:56.006 A:middle
For example, the CPU
renderer was used

00:18:56.006 --> 00:18:59.856 A:middle
when GPU texture
limits were exceeded.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:00.226 --> 00:19:04.066 A:middle
Well, starting on iOS 8, that's
no longer a limit in Core Image

00:19:04.066 --> 00:19:05.266 A:middle
so that's not a reason anymore.

00:19:06.086 --> 00:19:09.656 A:middle
Similarly, the application might
have needed to render briefly

00:19:09.656 --> 00:19:13.556 A:middle
when in the background, that's
also been improved in iOS 8.

00:19:14.756 --> 00:19:17.256 A:middle
And lastly, if your
application wanted to render

00:19:17.256 --> 00:19:19.516 A:middle
from a secondary thread
when in the foreground,

00:19:20.606 --> 00:19:22.606 A:middle
you might have used the
CPU renderer and now

00:19:22.606 --> 00:19:25.596 A:middle
that is no longer a limitation.

00:19:25.906 --> 00:19:28.476 A:middle
So we have some great
ways to keep us

00:19:28.476 --> 00:19:31.786 A:middle
on Core Image's much
faster GPU rendering path.

00:19:33.336 --> 00:19:36.396 A:middle
The next subject I want to
talk about this afternoon is

00:19:36.396 --> 00:19:38.326 A:middle
about some API modernizations

00:19:38.326 --> 00:19:41.286 A:middle
that have been made
both on OS X and on iOS.

00:19:41.856 --> 00:19:45.546 A:middle
These are small conveniences
but they add up in total.

00:19:45.816 --> 00:19:48.286 A:middle
First off, Core Image
filter subclasses

00:19:48.286 --> 00:19:51.156 A:middle
on OS X can now use
properties instead of ivars.

00:19:51.856 --> 00:19:54.026 A:middle
One thing to be aware of is

00:19:54.026 --> 00:19:57.976 A:middle
that Core Image filter
subclasses do not need

00:19:57.976 --> 00:20:02.956 A:middle
to release the object associated
with input ivars or properties.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:57.976 --> 00:20:02.956 A:middle
to release the object associated
with input ivars or properties.

00:20:03.156 --> 00:20:05.886 A:middle
So it's a little bit nonstandard
as a class in that regard.

00:20:07.136 --> 00:20:09.876 A:middle
By supporting properties,
that means that code that used

00:20:09.876 --> 00:20:12.656 A:middle
to look like this where you
have output image equals filter

00:20:12.986 --> 00:20:18.296 A:middle
valueForKey kCIOutputImageKey
can now be a little cleaner

00:20:18.296 --> 00:20:21.516 A:middle
and just look like outImage
equals filter.outputImage.

00:20:23.856 --> 00:20:26.986 A:middle
We also have a convenience
method if you want

00:20:26.986 --> 00:20:29.086 A:middle
to create a filter
and also set a bunch

00:20:29.086 --> 00:20:30.756 A:middle
of parameters all
in one fell swoop.

00:20:31.356 --> 00:20:34.086 A:middle
This can be now done by
saying filter, filterWithName

00:20:34.446 --> 00:20:37.936 A:middle
and then you could specify some
parameters at the same time.

00:20:38.576 --> 00:20:40.576 A:middle
And in those parameters
are a dictionary

00:20:40.576 --> 00:20:44.186 A:middle
where you can specify all the
inputs in one convenient manner.

00:20:45.876 --> 00:20:47.956 A:middle
There's an even slightly
simpler case

00:20:47.956 --> 00:20:50.736 A:middle
which is very commonly
usable where one

00:20:50.736 --> 00:20:53.006 A:middle
of your inputs is an input
image and you just want

00:20:53.006 --> 00:20:54.696 A:middle
to get the output of a filter.

00:20:55.056 --> 00:20:58.266 A:middle
So this means you can apply a
filter to an image with a set

00:20:58.266 --> 00:21:00.486 A:middle
of parameters without even
creating a filter object.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:20:58.266 --> 00:21:00.486 A:middle
of parameters without even
creating a filter object.

00:21:03.616 --> 00:21:05.546 A:middle
Lastly, one of the
common questions we get

00:21:05.546 --> 00:21:08.566 A:middle
from developers is, "How do
I correctly orient my image

00:21:08.566 --> 00:21:11.026 A:middle
so the orientation is
correctly upright?"

00:21:11.756 --> 00:21:15.286 A:middle
And the standard TIFF
specification has a set

00:21:15.286 --> 00:21:18.476 A:middle
of 8 possible values that tell
how the image should be flipped

00:21:18.476 --> 00:21:22.446 A:middle
or rotated and we've provided
a code snippet in the past

00:21:22.446 --> 00:21:25.626 A:middle
for that but much easier
is that we provided an API

00:21:25.626 --> 00:21:28.616 A:middle
for that now in iOS 8 and OS X.

00:21:28.976 --> 00:21:31.536 A:middle
So the simplest way
of calling it is

00:21:31.536 --> 00:21:34.266 A:middle
to say
imageByApplyingOrientation

00:21:34.766 --> 00:21:36.476 A:middle
and that gives you
back a new image.

00:21:36.906 --> 00:21:39.786 A:middle
And again, you're specifying
an integer orientation value.

00:21:40.326 --> 00:21:44.376 A:middle
As an alternative to doing the
same thing, we also have an API

00:21:44.376 --> 00:21:47.526 A:middle
that allows you to get
back the fine transform

00:21:47.526 --> 00:21:48.486 A:middle
that is equivalent to that.

00:21:49.296 --> 00:21:52.886 A:middle
And the reason why that's useful
is usually orienting your image

00:21:52.886 --> 00:21:57.066 A:middle
upright is only the
first of several affines

00:21:57.066 --> 00:21:58.486 A:middle
that you may apply
to your image.

00:21:58.486 --> 00:22:00.666 A:middle
You may also be scaling
it to fit or panning it.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:21:58.486 --> 00:22:00.666 A:middle
You may also be scaling
it to fit or panning it.

00:22:01.236 --> 00:22:05.376 A:middle
And so by getting this affine
matrix and concatenating

00:22:05.376 --> 00:22:06.706 A:middle
with any other affine matrix,

00:22:06.706 --> 00:22:08.616 A:middle
you can get a little better
performance out of Core Image.

00:22:12.156 --> 00:22:15.366 A:middle
So we've also made some
modernizations on OS X

00:22:15.366 --> 00:22:16.646 A:middle
with regard to color spaces.

00:22:17.146 --> 00:22:20.876 A:middle
The default RGB color space
is now sRGB which is great

00:22:20.876 --> 00:22:24.176 A:middle
because it matches with
the default RGB color space

00:22:24.176 --> 00:22:25.096 A:middle
that we have on iOS.

00:22:25.296 --> 00:22:29.376 A:middle
It also matches what most
modern applications expect

00:22:29.376 --> 00:22:31.326 A:middle
for untagged images.

00:22:33.106 --> 00:22:37.676 A:middle
Similarly, our default working
space has also changed on OS X.

00:22:37.806 --> 00:22:43.176 A:middle
It is now a linearized version
of the Rec.709 chromaticities

00:22:43.566 --> 00:22:45.676 A:middle
and again, this matches
the default we have

00:22:45.676 --> 00:22:47.686 A:middle
for our working space on iOS

00:22:47.866 --> 00:22:50.526 A:middle
and has a great performance
advantage which means

00:22:50.526 --> 00:22:52.046 A:middle
that in most typical scenarios

00:22:52.046 --> 00:22:55.286 A:middle
where you have sRGB
content going into a filter

00:22:55.286 --> 00:22:58.226 A:middle
in its working space and then
going back to sRGB output,

00:22:58.546 --> 00:23:00.226 A:middle
no matrix math is needed at all


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:58.546 --> 00:23:00.226 A:middle
no matrix math is needed at all

00:23:00.616 --> 00:23:02.256 A:middle
so this is a great,
great advantage.

00:23:02.496 --> 00:23:06.676 A:middle
Next subject, I'd like to talk

00:23:06.676 --> 00:23:10.506 A:middle
about today is some new
built-in Core Image filters.

00:23:11.836 --> 00:23:14.546 A:middle
So we have several I'd
like to talk about.

00:23:14.546 --> 00:23:18.756 A:middle
One is new to iOS 8 is
we've added CIAreaHistogram

00:23:18.756 --> 00:23:20.576 A:middle
and CIHistogramDisplayFilter.

00:23:21.196 --> 00:23:22.576 A:middle
The first filter,

00:23:22.576 --> 00:23:26.756 A:middle
CIAreaHistogram takes an
input image and the rectangle

00:23:26.756 --> 00:23:28.536 A:middle
that you want to generate
the histogram of it

00:23:28.966 --> 00:23:32.736 A:middle
and it'll produce an output
image that's typically 256

00:23:32.736 --> 00:23:33.856 A:middle
by 1 pixels.

00:23:34.386 --> 00:23:36.566 A:middle
So that image is useful
if you want to render

00:23:36.566 --> 00:23:37.826 A:middle
and get the pixel
values out of it

00:23:37.826 --> 00:23:41.296 A:middle
because that'll give you your
histogram data very efficiently.

00:23:42.196 --> 00:23:43.826 A:middle
However, oftentimes
you also want

00:23:43.826 --> 00:23:45.746 A:middle
to display this histogram
to the user.

00:23:46.146 --> 00:23:49.556 A:middle
So we have a second filter which
is CIHistogramDisplayFilter.

00:23:49.876 --> 00:23:53.286 A:middle
And it takes as an input
this 256 by 1 pixel image

00:23:53.696 --> 00:23:56.296 A:middle
and it produces a
pretty graph with red,

00:23:56.296 --> 00:23:57.856 A:middle
green and blue graphs
in it just like this.

00:23:58.956 --> 00:24:00.596 A:middle
It's very easy to use
in your application.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:23:58.956 --> 00:24:00.596 A:middle
It's very easy to use
in your application.

00:24:00.596 --> 00:24:02.066 A:middle
You just chain together
these two filters.

00:24:03.696 --> 00:24:06.676 A:middle
This is another great filter
that I'm really pleased with.

00:24:06.676 --> 00:24:10.166 A:middle
This is -- we've always had
filters for doing Gaussian blurs

00:24:10.166 --> 00:24:13.236 A:middle
on an image but we have a new
filter called MaskVariableBlur.

00:24:13.686 --> 00:24:16.016 A:middle
And the idea is you want
to apply a blur to an image

00:24:16.016 --> 00:24:17.976 A:middle
but you want to apply a
different amount of blur

00:24:17.976 --> 00:24:19.106 A:middle
at different locations.

00:24:19.276 --> 00:24:22.166 A:middle
So the way this filter works is
you start with an input image

00:24:22.716 --> 00:24:24.586 A:middle
and you provide a masked image.

00:24:24.896 --> 00:24:27.386 A:middle
In this example, we
have the mask is white

00:24:27.476 --> 00:24:31.846 A:middle
in the lower left-hand
corner, black in the center

00:24:32.086 --> 00:24:35.156 A:middle
and then white again the
upper right-hand corner.

00:24:35.656 --> 00:24:38.096 A:middle
And what this means when
we combine these two images

00:24:38.096 --> 00:24:41.146 A:middle
with masked variable blur
is we get a resulting image

00:24:41.506 --> 00:24:46.036 A:middle
that is defocused at the corners
and then gradually transitions

00:24:46.036 --> 00:24:47.596 A:middle
to a nice sharp image
in the center.

00:24:48.516 --> 00:24:51.216 A:middle
This is not just done with
blends but it's actually done

00:24:51.216 --> 00:24:53.716 A:middle
with variable radius blurs
which is quite a trick.

00:24:54.506 --> 00:24:56.726 A:middle
So there's a couple of
different ways you can use this.

00:24:56.726 --> 00:24:58.726 A:middle
You can use this to
achieve a sort of fake depth

00:24:58.726 --> 00:25:00.896 A:middle
of field effect where
the top and bottom


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:24:58.726 --> 00:25:00.896 A:middle
of field effect where
the top and bottom

00:25:00.896 --> 00:25:03.056 A:middle
of your image might be blurry
and the center may be sharp.

00:25:03.676 --> 00:25:07.836 A:middle
Or you can actually hand create
a masked image with a person

00:25:07.836 --> 00:25:10.396 A:middle
in the foreground and then
nicely blur the background

00:25:10.396 --> 00:25:11.416 A:middle
with a nice bokeh.

00:25:12.926 --> 00:25:15.466 A:middle
So I hope to see lots
of fun examples of that.

00:25:16.416 --> 00:25:19.926 A:middle
This is another fun one we added
which is AccordionfoldTransition

00:25:19.926 --> 00:25:22.346 A:middle
and this is something
we did for the mail team

00:25:22.346 --> 00:25:24.486 A:middle
but we've also provided
it as a public filter.

00:25:24.846 --> 00:25:27.896 A:middle
You provide two images, a
before and an after and a couple

00:25:27.896 --> 00:25:30.316 A:middle
of parameters like how many
folds and how many pixels

00:25:30.316 --> 00:25:31.616 A:middle
at the bottom are shared.

00:25:32.296 --> 00:25:34.996 A:middle
And what this filter looks
like in practice is this.

00:25:35.896 --> 00:25:37.596 A:middle
And if you actually
look carefully,

00:25:37.866 --> 00:25:39.986 A:middle
that's the actual entire
kernel for this filter.

00:25:41.596 --> 00:25:46.606 A:middle
So it's a nice bit of trickery.

00:25:47.236 --> 00:25:50.666 A:middle
Another filter we've
added, in prior releases,

00:25:50.666 --> 00:25:53.256 A:middle
we've had filters for
generating QR codes.

00:25:53.916 --> 00:25:58.076 A:middle
We've added a new one for
generating code 128 barcodes

00:25:58.396 --> 00:25:59.936 A:middle
and it works in a
similar fashion.

00:25:59.936 --> 00:26:03.846 A:middle
You specify an input message
as NSData and in this case,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:25:59.936 --> 00:26:03.846 A:middle
You specify an input message
as NSData and in this case,

00:26:03.846 --> 00:26:06.256 A:middle
there's an additional parameter
which says how many pixels

00:26:06.256 --> 00:26:07.316 A:middle
of quiet space you want

00:26:08.326 --> 00:26:10.276 A:middle
and it'll produce
an image like this.

00:26:10.796 --> 00:26:13.226 A:middle
We've also added another
one for Aztec codes.

00:26:13.626 --> 00:26:15.546 A:middle
Again the same kind
of idea for the API,

00:26:15.666 --> 00:26:17.666 A:middle
you just specify
the input message

00:26:18.056 --> 00:26:19.806 A:middle
and for this particular
generator,

00:26:19.806 --> 00:26:21.606 A:middle
it has an input correction level

00:26:21.606 --> 00:26:26.876 A:middle
which tells how many error
correction bits it will have.

00:26:26.916 --> 00:26:31.596 A:middle
Another new filter which is also
fun is CIPerspectiveCorrection.

00:26:32.066 --> 00:26:34.176 A:middle
And the idea behind this
is you have an input image

00:26:34.176 --> 00:26:38.156 A:middle
and you specify 4 points and
it will create a new image

00:26:38.216 --> 00:26:41.606 A:middle
that is cropped and undistorted
preserving the original

00:26:41.636 --> 00:26:45.126 A:middle
and intended aspect ratio
so this is again very nice

00:26:45.126 --> 00:26:52.166 A:middle
for capturing parts of an
image and distorting them.

00:26:52.646 --> 00:26:55.726 A:middle
We've added a handful of
new blend filters, linear,

00:26:55.726 --> 00:26:58.136 A:middle
dodge and burn, pin
lights, subtract, divide.

00:26:58.826 --> 00:27:03.206 A:middle
Also just to be aware, we've
made a fix to SoftLightBlendMode


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:26:58.826 --> 00:27:03.206 A:middle
Also just to be aware, we've
made a fix to SoftLightBlendMode

00:27:03.206 --> 00:27:06.606 A:middle
so it better matches the spec.

00:27:06.606 --> 00:27:09.456 A:middle
And then there's a few other new
ones we've added that are new

00:27:09.456 --> 00:27:12.276 A:middle
on iOS such as GlassDistortion,

00:27:12.276 --> 00:27:14.736 A:middle
StretchCrop for anamorphic
correction,

00:27:15.066 --> 00:27:16.846 A:middle
Droste which is a great demo

00:27:16.846 --> 00:27:20.966 A:middle
from our conference show two
years ago, and then who knows,

00:27:20.966 --> 00:27:22.756 A:middle
if we have some more time,
we'll get a few more in.

00:27:23.136 --> 00:27:26.676 A:middle
But what that brings us to today
is over 115 built-in filters

00:27:26.676 --> 00:27:29.666 A:middle
on iOS and of course, that
really is an infinite number now

00:27:29.666 --> 00:27:31.986 A:middle
that you guys can create
your own custom filters.

00:27:32.386 --> 00:27:34.516 A:middle
So we're excited to see
all sorts of new things.

00:27:35.916 --> 00:27:37.516 A:middle
Another area we've
made some improvements

00:27:37.516 --> 00:27:39.966 A:middle
in Core Image is CIDetectors.

00:27:40.186 --> 00:27:41.926 A:middle
So what is a CIDetector?

00:27:41.926 --> 00:27:44.666 A:middle
Well, CIDetector is an
abstract class that allows you

00:27:44.666 --> 00:27:46.276 A:middle
to help find things
within an image.

00:27:47.106 --> 00:27:51.606 A:middle
And prior to iOS 8, we had just
one type which was TypeFace.

00:27:52.186 --> 00:27:53.216 A:middle
But we've added two more.

00:27:53.306 --> 00:27:55.796 A:middle
So we now have
CIDetectorTypeRectangle

00:27:55.846 --> 00:27:57.886 A:middle
and CIDetectorTypeQRCode.

00:27:59.126 --> 00:28:00.986 A:middle
So how does this work?


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:27:59.126 --> 00:28:00.986 A:middle
So how does this work?

00:28:00.986 --> 00:28:03.686 A:middle
Well, creating a detector is
largely the same regardless

00:28:03.686 --> 00:28:05.206 A:middle
of what type of detector
you are creating.

00:28:05.596 --> 00:28:08.566 A:middle
Here we have an example of
creating a detector of TypeFace

00:28:08.696 --> 00:28:10.736 A:middle
where we say detector,
detector of TypeFace

00:28:10.736 --> 00:28:12.536 A:middle
and we can also specify
some options.

00:28:13.146 --> 00:28:14.926 A:middle
There are a couple of
options that are very useful

00:28:14.926 --> 00:28:16.076 A:middle
for all the detectors.

00:28:16.076 --> 00:28:19.856 A:middle
One is you could say whether
you want to have high accuracy

00:28:19.856 --> 00:28:23.126 A:middle
or low accuracy which depending
on your need might allow you

00:28:23.126 --> 00:28:25.416 A:middle
to trade off performance
versus precision.

00:28:26.606 --> 00:28:29.646 A:middle
Also, you can tell a detector
what the smallest feature

00:28:29.646 --> 00:28:33.296 A:middle
to detect is and that also can
greatly improve performance.

00:28:33.826 --> 00:28:37.996 A:middle
And of course, now that we've
added these new detectors,

00:28:38.286 --> 00:28:40.066 A:middle
you can just use
DetectorTypeRectangle

00:28:40.776 --> 00:28:42.286 A:middle
or DetectorTypeQRCode as well.

00:28:44.256 --> 00:28:48.036 A:middle
So just as a reminder, so when
you're using the FaceDetector,

00:28:48.686 --> 00:28:51.116 A:middle
there's a couple of options
that you want to pass

00:28:51.116 --> 00:28:53.346 A:middle
in when you're asking for the
actual features in an image.

00:28:53.766 --> 00:28:56.476 A:middle
One is you can specify what the
orientation of the image is.

00:28:56.716 --> 00:28:58.986 A:middle
That's important because
the FaceDetector looks

00:28:58.986 --> 00:28:59.946 A:middle
for upright faces.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:00.746 --> 00:29:02.736 A:middle
Also you can specify
options to say I want to look

00:29:02.736 --> 00:29:06.456 A:middle
for eye blinks or smiles
and that's specified

00:29:06.456 --> 00:29:07.566 A:middle
in the same options dictionary.

00:29:07.566 --> 00:29:10.946 A:middle
And let me show you
a little bit of code

00:29:10.946 --> 00:29:14.016 A:middle
about how we can now use this
detector to create a sort

00:29:14.016 --> 00:29:16.276 A:middle
of augmented reality
example here.

00:29:16.636 --> 00:29:18.396 A:middle
And the idea we wanted
for this little bit

00:29:18.396 --> 00:29:20.806 A:middle
of a sample code is we wanted
to start with the input image,

00:29:20.806 --> 00:29:24.246 A:middle
find the faces in it
and then put squares

00:29:24.246 --> 00:29:25.996 A:middle
over the image where
we find them.

00:29:25.996 --> 00:29:28.646 A:middle
And so this is a little
clever bit of sample code.

00:29:28.646 --> 00:29:32.536 A:middle
First off, for each face that
we detect in the features array,

00:29:33.266 --> 00:29:35.626 A:middle
we're going to check to see if
the eyes were closed or not.

00:29:36.346 --> 00:29:38.486 A:middle
Then we're going to
create a CIImage WithColor.

00:29:39.216 --> 00:29:41.746 A:middle
And we're going to have
a different color based

00:29:41.746 --> 00:29:43.546 A:middle
on whether the eyes
are closed or not

00:29:43.546 --> 00:29:45.536 A:middle
or whether face is
smiling or not.

00:29:46.096 --> 00:29:48.796 A:middle
Now that API actually
returns an infinite image

00:29:49.766 --> 00:29:53.156 A:middle
so what we then need to do is
to crop that image to the bounds

00:29:53.156 --> 00:29:54.366 A:middle
of the feature that
was detected.

00:29:55.406 --> 00:29:59.826 A:middle
We then take that cropped
image color and we composite

00:29:59.826 --> 00:30:01.676 A:middle
over the previous
resulting image.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:59.826 --> 00:30:01.676 A:middle
over the previous
resulting image.

00:30:02.156 --> 00:30:04.106 A:middle
And this is also a new
API that we've provided.

00:30:04.106 --> 00:30:07.456 A:middle
It's basically convenience
API that's equivalent

00:30:07.456 --> 00:30:10.296 A:middle
to using the Core Image source
over compositing filter.

00:30:10.776 --> 00:30:12.866 A:middle
And this is what it
looks like in practice.

00:30:12.866 --> 00:30:14.326 A:middle
Here's a little sample
video we shot

00:30:14.326 --> 00:30:18.516 A:middle
where we are detecting
the faces in real time

00:30:18.516 --> 00:30:22.316 A:middle
and then coloring them based
on whether the face is smiling

00:30:22.316 --> 00:30:23.696 A:middle
or blinking or combinations.

00:30:24.116 --> 00:30:26.626 A:middle
And we're getting about
25 frames per second.

00:30:27.136 --> 00:30:32.096 A:middle
We could do something similar
also for rectangle features.

00:30:32.096 --> 00:30:36.426 A:middle
So the idea behind rectangle
features is we understand

00:30:36.426 --> 00:30:40.446 A:middle
that in a lot of cases,
the first step in looking

00:30:40.486 --> 00:30:43.116 A:middle
in an image for something
interesting is to look

00:30:43.116 --> 00:30:44.256 A:middle
for something like a rectangle.

00:30:44.386 --> 00:30:47.006 A:middle
For example, if you're looking
for a sign or if you're looking

00:30:47.006 --> 00:30:49.886 A:middle
for a business card or if you're
looking for a piece of paper,

00:30:50.116 --> 00:30:52.846 A:middle
oftentimes looking for the
rectangle first is a great place

00:30:52.846 --> 00:30:53.246 A:middle
to start.

00:30:53.576 --> 00:30:56.676 A:middle
So we've created a generic
rectangle detector object

00:30:57.236 --> 00:31:00.176 A:middle
and it takes one
option parameter


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:57.236 --> 00:31:00.176 A:middle
and it takes one
option parameter

00:31:00.176 --> 00:31:02.356 A:middle
which is the aspect ratio
that we want to search for.

00:31:03.086 --> 00:31:05.496 A:middle
And again, you can
ask the detector

00:31:05.496 --> 00:31:07.236 A:middle
to return the features array.

00:31:07.796 --> 00:31:09.706 A:middle
Now right now, it just
returns one rectangle

00:31:09.706 --> 00:31:11.056 A:middle
but that may change
in the future.

00:31:12.066 --> 00:31:14.476 A:middle
So here again, we wanted
to do a little sample here,

00:31:14.476 --> 00:31:16.666 A:middle
a little bit fancier
because we want to,

00:31:16.666 --> 00:31:19.336 A:middle
instead of just doing
the bounding box overlay,

00:31:19.646 --> 00:31:21.316 A:middle
we want to make it a
little bit prettier.

00:31:21.746 --> 00:31:24.546 A:middle
So again, we're looping over
all the features in the image.

00:31:25.366 --> 00:31:29.736 A:middle
We're creating a CIImage
WithColor which is infinite.

00:31:30.626 --> 00:31:33.846 A:middle
But we're going to take that
infinite color image and run it

00:31:33.846 --> 00:31:36.286 A:middle
through the
CIPerspectiveTransform

00:31:36.416 --> 00:31:37.796 A:middle
WithExtent filter.

00:31:38.366 --> 00:31:40.456 A:middle
And that filter does two things.

00:31:40.456 --> 00:31:42.196 A:middle
First of all, you
specify an extent

00:31:42.576 --> 00:31:45.586 A:middle
which in this case
we're specifying 0011

00:31:45.936 --> 00:31:48.396 A:middle
so now effectively, we
have a unit square image.

00:31:49.246 --> 00:31:51.816 A:middle
And then the other parameters,
take that unit square

00:31:51.816 --> 00:31:56.456 A:middle
and stretch it to the top-left,
top-right, bottom-left,

00:31:56.526 --> 00:31:57.656 A:middle
bottom-right coordinates.

00:31:58.226 --> 00:32:00.156 A:middle
And then we overlay that
on the previous result.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:31:58.226 --> 00:32:00.156 A:middle
And then we overlay that
on the previous result.

00:32:00.866 --> 00:32:02.556 A:middle
And here's what that
looks like in practice.

00:32:02.596 --> 00:32:06.176 A:middle
So this is the nameplate from
my office and we are taking,

00:32:06.326 --> 00:32:10.326 A:middle
running it through the Detector,
getting the detected rectangle

00:32:10.326 --> 00:32:12.676 A:middle
and then producing this
overlay tinted red image.

00:32:15.496 --> 00:32:18.676 A:middle
Lastly, we can do the
same thing with QR Codes.

00:32:19.036 --> 00:32:20.776 A:middle
The code here is
exactly the same.

00:32:21.196 --> 00:32:22.046 A:middle
The only difference is

00:32:22.046 --> 00:32:24.826 A:middle
that we're using the QR
Code feature instead.

00:32:25.486 --> 00:32:28.066 A:middle
This example, you could
have also gotten the message

00:32:28.066 --> 00:32:29.666 A:middle
from the QR Code
but in this case,

00:32:29.666 --> 00:32:31.336 A:middle
I'm just going to do an overlay.

00:32:32.016 --> 00:32:35.426 A:middle
So all I needed to do was
use the coordinates and again

00:32:35.426 --> 00:32:38.736 A:middle
as you see in the example,
we can detect this QR Code

00:32:38.736 --> 00:32:43.896 A:middle
and do an overlay in real time.

00:32:44.116 --> 00:32:46.946 A:middle
So that's the bulk of
my conversation there.

00:32:46.946 --> 00:32:49.936 A:middle
The last thing I want to
talk about is improvements

00:32:49.936 --> 00:32:53.086 A:middle
that we've made to
RAW support on OS X.

00:32:53.086 --> 00:32:55.766 A:middle
So let me talk a little
bit about our RAW support.

00:32:57.176 --> 00:33:00.066 A:middle
So I'll talk about our
history, the fundamentals


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:57.176 --> 00:33:00.066 A:middle
So I'll talk about our
history, the fundamentals

00:33:00.066 --> 00:33:03.616 A:middle
of RAW image processing,
some architectural overview

00:33:03.876 --> 00:33:05.836 A:middle
and how you can use this
great filter we have called

00:33:05.836 --> 00:33:06.766 A:middle
the CIRAWFilter.

00:33:07.846 --> 00:33:11.436 A:middle
So history first, so Apple
has been supporting RAW

00:33:11.436 --> 00:33:14.926 A:middle
since back in April of 2005.

00:33:15.096 --> 00:33:17.446 A:middle
Over those years, we have been
continuously adding support

00:33:17.446 --> 00:33:19.066 A:middle
for cameras and improving
the quality.

00:33:19.556 --> 00:33:22.696 A:middle
We have about 350
cameras supported today

00:33:22.696 --> 00:33:26.606 A:middle
and that's not including
all the DNG possibilities.

00:33:26.826 --> 00:33:30.486 A:middle
And one of the improvements
we've made in OS X this year is

00:33:30.486 --> 00:33:33.256 A:middle
that we support the latest
version of DNG specification

00:33:33.586 --> 00:33:34.966 A:middle
so that greatly improves
the number

00:33:34.966 --> 00:33:36.226 A:middle
of images that we can support.

00:33:36.706 --> 00:33:40.306 A:middle
And the other thing that's
wonderful about our support is

00:33:40.306 --> 00:33:42.476 A:middle
that it's provided to the
entire operating system

00:33:42.636 --> 00:33:45.126 A:middle
which means everything
from NSImages

00:33:45.126 --> 00:33:47.776 A:middle
to CGImages will
automatically support RAW files.

00:33:48.486 --> 00:33:52.316 A:middle
System services like Spotlight
and Quick Look support,

00:33:52.716 --> 00:33:56.456 A:middle
these key applications
like Preview, Finder,

00:33:56.456 --> 00:33:57.796 A:middle
even Mail support RAW.

00:33:58.456 --> 00:34:02.066 A:middle
Our photo applications
Aperture, iPhoto and Photos.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:33:58.456 --> 00:34:02.066 A:middle
Our photo applications
Aperture, iPhoto and Photos.

00:34:03.346 --> 00:34:06.176 A:middle
Also all third-party
app can also get this

00:34:06.176 --> 00:34:07.766 A:middle
for very little effort.

00:34:10.096 --> 00:34:12.446 A:middle
So what is involved in
processing a RAW image?

00:34:12.446 --> 00:34:16.596 A:middle
And this is why, you know, this
subject is actually very dear

00:34:16.596 --> 00:34:18.556 A:middle
to my heart because
it involves a lot

00:34:18.556 --> 00:34:19.946 A:middle
of very advanced
image processing

00:34:19.946 --> 00:34:20.976 A:middle
to produce a RAW file.

00:34:21.755 --> 00:34:22.936 A:middle
So you start off with the fact

00:34:22.936 --> 00:34:26.156 A:middle
that RAW files contain only
a minimally processed data

00:34:26.266 --> 00:34:27.786 A:middle
from the camera sensor image.

00:34:28.065 --> 00:34:32.676 A:middle
And in fact, the image is
actually missing typically 66%

00:34:32.676 --> 00:34:35.326 A:middle
of the actual data because
at each pixel location,

00:34:35.326 --> 00:34:37.406 A:middle
you only have a red or
a green or a blue value.

00:34:38.045 --> 00:34:40.966 A:middle
And that means to produce a
final image, we actually have

00:34:41.466 --> 00:34:45.696 A:middle
to make up good values for
those missing 60% of your data.

00:34:46.396 --> 00:34:49.235 A:middle
And that requires a lot of
advanced image processing

00:34:49.235 --> 00:34:52.266 A:middle
to produce a beautiful
image at the end.

00:34:52.545 --> 00:34:54.226 A:middle
There are several
steps in this process.

00:34:54.676 --> 00:34:57.196 A:middle
They involve extracting
critical metadata from the file,

00:34:57.316 --> 00:35:00.376 A:middle
decoding the raw sensor,
de-mosaic deconstruction


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:57.316 --> 00:35:00.376 A:middle
decoding the raw sensor,
de-mosaic deconstruction

00:35:00.376 --> 00:35:02.456 A:middle
which is a hugely complex task,

00:35:02.936 --> 00:35:04.996 A:middle
lens correction,
noise reduction.

00:35:05.366 --> 00:35:06.966 A:middle
And then there's a set
of operations that are

00:35:06.966 --> 00:35:10.626 A:middle
in the color domain such as
mapping scene-referred color

00:35:10.626 --> 00:35:14.176 A:middle
values to output-referred
and then adjusting exposure

00:35:14.176 --> 00:35:17.506 A:middle
and temperature and tint
and then adding contrast

00:35:17.506 --> 00:35:19.036 A:middle
and saturation to taste.

00:35:19.436 --> 00:35:22.236 A:middle
So it's a lot of steps and
we've made some significant

00:35:22.236 --> 00:35:26.736 A:middle
improvements to several
of these in OS X Yosemite.

00:35:27.076 --> 00:35:29.266 A:middle
So we've benefitted
for lens correction,

00:35:29.266 --> 00:35:31.506 A:middle
a great new noise reduction
which we'll show in a minute

00:35:32.006 --> 00:35:33.996 A:middle
and also some improvements
to color as well.

00:35:36.076 --> 00:35:39.926 A:middle
So as I said before,
APIs like NSImage

00:35:39.926 --> 00:35:42.486 A:middle
and CGImage will get
RAW support for free.

00:35:43.236 --> 00:35:47.236 A:middle
And that's because our support
provides that default rendering

00:35:47.786 --> 00:35:50.566 A:middle
which is processed according
to all of our parameters

00:35:50.796 --> 00:35:53.186 A:middle
and whatever our
latest algorithm is.

00:35:55.096 --> 00:35:59.186 A:middle
However, we have this API
which is called the CIRAWFilter

00:35:59.506 --> 00:36:01.666 A:middle
which gives your
application much more control.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:35:59.506 --> 00:36:01.666 A:middle
which gives your
application much more control.

00:36:01.666 --> 00:36:06.746 A:middle
And it allows you to get a
CIImage with extended range,

00:36:06.746 --> 00:36:10.146 A:middle
floating point precision
and also

00:36:10.146 --> 00:36:13.086 A:middle
on that object are
easy-to-use controls

00:36:13.086 --> 00:36:16.196 A:middle
to control how our RAW
imaging results are processed.

00:36:16.806 --> 00:36:18.866 A:middle
And it gives you fast
interactive performance all

00:36:18.866 --> 00:36:19.336 A:middle
in the GPU.

00:36:19.736 --> 00:36:22.056 A:middle
So it's some great stuff that
you can use in your application.

00:36:23.756 --> 00:36:26.456 A:middle
So this is sort of how it
works as a flow diagram.

00:36:26.736 --> 00:36:29.986 A:middle
You start out with a file
and that can be passed either

00:36:29.986 --> 00:36:32.196 A:middle
as a file URL or NSData.

00:36:32.616 --> 00:36:35.976 A:middle
And that's passed as an input
to create the CIRAWFilter.

00:36:37.066 --> 00:36:40.166 A:middle
Also it can be specified on
that RAW filter are several

00:36:40.166 --> 00:36:41.896 A:middle
of our processing parameters.

00:36:42.686 --> 00:36:46.526 A:middle
Once you've set those correctly,
you can get a CIImage output

00:36:47.056 --> 00:36:49.646 A:middle
which you can then
display on the screen.

00:36:49.946 --> 00:36:52.266 A:middle
And by default, it'll look just
like our default rendering.

00:36:53.316 --> 00:36:55.826 A:middle
However, the great thing
about the CIRAWFilter is

00:36:55.826 --> 00:36:57.276 A:middle
that once the user
has seen those

00:36:57.546 --> 00:36:59.316 A:middle
and if your application
has controls,

00:36:59.706 --> 00:37:05.096 A:middle
you can alter those values, send
them back into the CIRAWFilter


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:36:59.706 --> 00:37:05.096 A:middle
you can alter those values, send
them back into the CIRAWFilter

00:37:05.546 --> 00:37:09.376 A:middle
where it can be re-displayed
all in real time.

00:37:09.906 --> 00:37:13.996 A:middle
Another great feature we have on
this is we actually have a place

00:37:13.996 --> 00:37:16.896 A:middle
where you can insert a
custom CIFilter in the middle

00:37:16.896 --> 00:37:20.666 A:middle
of our RAW filter processing
before we've done anything

00:37:20.666 --> 00:37:23.126 A:middle
to change the data
from a linear space.

00:37:23.126 --> 00:37:24.776 A:middle
So this is very useful
if you want

00:37:24.776 --> 00:37:26.396 A:middle
to do certain types
of image processing.

00:37:26.396 --> 00:37:28.616 A:middle
Now of course, you
can also apply filters

00:37:28.616 --> 00:37:32.846 A:middle
after the CIRAWFilter but this
is a great set of functionality

00:37:32.846 --> 00:37:33.936 A:middle
for certain use cases.

00:37:35.276 --> 00:37:37.546 A:middle
And lastly, it doesn't
have to go to the display.

00:37:37.546 --> 00:37:40.706 A:middle
You can also take the CIImage,
create a CGImage from that

00:37:41.206 --> 00:37:44.136 A:middle
and produce a new CG, a
file on disk from that.

00:37:44.566 --> 00:37:47.476 A:middle
And this is an example

00:37:47.476 --> 00:37:49.566 A:middle
of how little code it
takes to use this filter.

00:37:50.256 --> 00:37:51.846 A:middle
Basically, we start
out with a URL.

00:37:52.176 --> 00:37:55.776 A:middle
We create a CIFilter
filterWithImageURL

00:37:55.776 --> 00:37:57.346 A:middle
and that'll return
to CIRAWFilter.

00:37:58.336 --> 00:38:00.266 A:middle
In this particular
example, we want to get


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:37:58.336 --> 00:38:00.266 A:middle
In this particular
example, we want to get

00:38:00.266 --> 00:38:02.286 A:middle
from that filter what
our default value

00:38:02.286 --> 00:38:03.986 A:middle
for the luminance
noise reduction was

00:38:04.286 --> 00:38:05.396 A:middle
that returns to us as an object.

00:38:06.046 --> 00:38:08.866 A:middle
We can then make slight changes
to that like say for example,

00:38:08.866 --> 00:38:11.876 A:middle
you want all of your images to
be slightly more noise-reduced.

00:38:12.126 --> 00:38:14.216 A:middle
You can take that
value, add a bit to it

00:38:14.396 --> 00:38:15.606 A:middle
and then set that
as a new value.

00:38:16.476 --> 00:38:18.016 A:middle
And then once you're
done setting values,

00:38:18.016 --> 00:38:19.086 A:middle
you can get an output image.

00:38:19.876 --> 00:38:21.266 A:middle
So with just a few
lines of code,

00:38:21.266 --> 00:38:24.166 A:middle
you can leverage all
of our RAW pipeline.

00:38:24.486 --> 00:38:27.576 A:middle
So to show this in
much more detail,

00:38:27.576 --> 00:38:29.086 A:middle
I'm going to pass the
stage over to Serhan

00:38:29.086 --> 00:38:30.526 A:middle
who will be giving
a live demo of this.

00:38:30.806 --> 00:38:31.096 A:middle
Thanks.

00:38:31.986 --> 00:38:34.456 A:middle
&gt;&gt; In this part of our talk,
I would like to show you some

00:38:34.456 --> 00:38:36.526 A:middle
of the great things
that you can also do

00:38:36.526 --> 00:38:39.666 A:middle
in your applications
using the CIRAWFilter

00:38:39.796 --> 00:38:43.136 A:middle
and OS X's built-in support
for RAW camera files.

00:38:44.056 --> 00:38:47.866 A:middle
To do that, we created a
very basic simple application

00:38:48.446 --> 00:38:52.556 A:middle
that simply puts
up an NSOpenGLView

00:38:52.556 --> 00:38:55.136 A:middle
which is tied up
to a CIRAWFilter.

00:38:55.776 --> 00:38:59.026 A:middle
And another NSView which is tied

00:38:59.026 --> 00:39:00.946 A:middle
up to the controls
of the CIRAWFilter.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:38:59.026 --> 00:39:00.946 A:middle
up to the controls
of the CIRAWFilter.

00:39:01.436 --> 00:39:05.866 A:middle
So let me run that and
point it to a RAW image.

00:39:09.776 --> 00:39:13.226 A:middle
Now, by default, when you
actually open up a RAW file,

00:39:13.286 --> 00:39:15.766 A:middle
we will tap into our
own calibration database

00:39:15.866 --> 00:39:18.036 A:middle
and make sure that we
apply the correct set

00:39:18.036 --> 00:39:21.606 A:middle
of calibration settings that
are specific to the make

00:39:21.606 --> 00:39:23.086 A:middle
and model for this RAW file.

00:39:23.926 --> 00:39:28.026 A:middle
And some of the settings are
for you under lens correction,

00:39:28.626 --> 00:39:33.176 A:middle
white balance settings,
noise reduction settings

00:39:33.176 --> 00:39:36.016 A:middle
that we will go into more
detail in just a second,

00:39:36.556 --> 00:39:39.386 A:middle
exposure and boost controls.

00:39:40.726 --> 00:39:42.896 A:middle
So there is not much going

00:39:43.246 --> 00:39:45.366 A:middle
on with this very good
image in the first place.

00:39:45.366 --> 00:39:49.566 A:middle
So let me pull up a
more challenging image

00:39:49.566 --> 00:39:54.856 A:middle
to show the great benefits
of using RAW files.

00:39:55.396 --> 00:39:58.576 A:middle
Now, on this image, by
default when you load it,

00:39:58.576 --> 00:40:01.046 A:middle
you see that parts
of the image is close


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:39:58.576 --> 00:40:01.046 A:middle
you see that parts
of the image is close

00:40:01.046 --> 00:40:04.636 A:middle
to clipping point especially the
sky and the mountainous region.

00:40:05.046 --> 00:40:08.146 A:middle
So we're probably losing some
color fidelity in this region.

00:40:08.736 --> 00:40:13.016 A:middle
What's more interesting
is the part of the trees

00:40:13.016 --> 00:40:16.036 A:middle
which are underexposed and we're
probably not getting the right

00:40:16.036 --> 00:40:16.866 A:middle
amount of detail.

00:40:17.406 --> 00:40:19.706 A:middle
So let's see if we can
actually improve this image.

00:40:20.506 --> 00:40:22.456 A:middle
The first thing that I would

00:40:22.456 --> 00:40:24.776 A:middle
like to try is setting
the exposure

00:40:24.826 --> 00:40:26.326 A:middle
to see how it actually
looks like.

00:40:27.216 --> 00:40:30.776 A:middle
Want to probably increase
the exposure to make sure

00:40:30.776 --> 00:40:33.426 A:middle
that I get the detail in
the tree part of the image.

00:40:33.546 --> 00:40:34.976 A:middle
But as you can quickly see,

00:40:34.976 --> 00:40:36.926 A:middle
we're losing all the
detail in the highlights.

00:40:38.016 --> 00:40:39.836 A:middle
And the opposite is also true.

00:40:39.896 --> 00:40:41.766 A:middle
Once you start decreasing
the exposure,

00:40:42.236 --> 00:40:44.086 A:middle
you're getting back
the color in the sky

00:40:44.456 --> 00:40:47.376 A:middle
but you're losing all the
detail in the low lights.

00:40:48.776 --> 00:40:52.876 A:middle
So there is something that can
be done better and the answer

00:40:52.876 --> 00:40:55.406 A:middle
to that is CI Highlights
and Shadows Filters.

00:40:56.186 --> 00:40:59.276 A:middle
Normally, if you were shooting
JPEG, you would tie the output

00:40:59.276 --> 00:41:02.276 A:middle
of the JPEG decoder to this
highlights and shadows filters.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:40:59.276 --> 00:41:02.276 A:middle
of the JPEG decoder to this
highlights and shadows filters.

00:41:02.506 --> 00:41:05.446 A:middle
But what's interesting
when you're shooting RAW is

00:41:05.446 --> 00:41:08.996 A:middle
that you can actually insert
this filter into the middle

00:41:09.036 --> 00:41:12.066 A:middle
of our RAW processing
pipeline and take advantage

00:41:12.066 --> 00:41:14.876 A:middle
of the linear input space
that we're operating in.

00:41:15.416 --> 00:41:16.826 A:middle
That means that you will be able

00:41:16.826 --> 00:41:18.726 A:middle
to better keep the
color fidelity.

00:41:18.726 --> 00:41:21.396 A:middle
You'll operate on a
linear 16-bit pipeline

00:41:21.816 --> 00:41:23.596 A:middle
and at the end, get
better results.

00:41:23.826 --> 00:41:25.626 A:middle
So let's try that.

00:41:26.356 --> 00:41:29.766 A:middle
The first thing that I want
to do is increase the shadows

00:41:30.306 --> 00:41:33.086 A:middle
and almost immediately I
can see that all the detail

00:41:33.086 --> 00:41:36.776 A:middle
in the shadow part is
kept, is brought back.

00:41:37.326 --> 00:41:38.486 A:middle
Same for the sky.

00:41:38.486 --> 00:41:40.276 A:middle
I want to bring it
down to make sure

00:41:40.276 --> 00:41:42.516 A:middle
that I can see more
of the sky colors.

00:41:43.526 --> 00:41:47.266 A:middle
And I can easily do that
without overblowing any part

00:41:47.266 --> 00:41:47.996 A:middle
of that image.

00:41:49.656 --> 00:41:52.106 A:middle
So that is a good example

00:41:52.106 --> 00:41:55.216 A:middle
of how you can actually use
the CIRAWFilter to make sure

00:41:55.216 --> 00:41:58.516 A:middle
that you can double up your
own images in the best way

00:41:58.516 --> 00:42:00.186 A:middle
that you think is appropriate.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:41:58.516 --> 00:42:00.186 A:middle
that you think is appropriate.

00:42:01.296 --> 00:42:07.236 A:middle
Next noise filter.

00:42:08.146 --> 00:42:11.526 A:middle
Now noise reduction is a
very challenging problem

00:42:11.526 --> 00:42:16.216 A:middle
and traditionally it
is very computationally

00:42:16.386 --> 00:42:18.336 A:middle
expensive algorithm.

00:42:18.986 --> 00:42:22.656 A:middle
We're very happy to offer you
a new noise reduction algorithm

00:42:22.656 --> 00:42:24.476 A:middle
starting in OS X Yosemite.

00:42:24.976 --> 00:42:28.206 A:middle
That doesn't compromise on the
quality and you can still use it

00:42:28.376 --> 00:42:30.696 A:middle
at an interactive 60
frames per second rate.

00:42:31.246 --> 00:42:34.296 A:middle
To show you that, we have
this very noisy image

00:42:35.456 --> 00:42:37.976 A:middle
of the Moscone Center
and I want to focus

00:42:37.976 --> 00:42:39.096 A:middle
on this part of the image.

00:42:40.016 --> 00:42:42.626 A:middle
Just for fun, I'm going to turn
off all the noise reduction

00:42:42.626 --> 00:42:44.556 A:middle
to see what we are
dealing with initially.

00:42:47.556 --> 00:42:49.186 A:middle
So this is the original --

00:42:49.236 --> 00:42:51.176 A:middle
this is how the original
image looks like.

00:42:51.966 --> 00:42:57.866 A:middle
And using the CIRAW LNR and
CNR noise filter settings,

00:42:57.866 --> 00:42:59.816 A:middle
I can get it to a
state where I feel

00:42:59.956 --> 00:43:02.336 A:middle
that is most comfortable
for my image.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:42:59.956 --> 00:43:02.336 A:middle
that is most comfortable
for my image.

00:43:02.926 --> 00:43:05.446 A:middle
So probably the first thing
that I want to do is get rid

00:43:05.446 --> 00:43:10.546 A:middle
of all the color noise and I'm
using the CNR slider to do that.

00:43:10.546 --> 00:43:12.726 A:middle
And look how interactive
this process is.

00:43:13.876 --> 00:43:17.016 A:middle
Same for LNR, you have a
wide variety of settings

00:43:17.016 --> 00:43:17.896 A:middle
that you can play with.

00:43:17.956 --> 00:43:21.266 A:middle
You can go with something that
is very smooth or something

00:43:21.266 --> 00:43:23.686 A:middle
which keeps all the
luminance noise.

00:43:24.076 --> 00:43:26.076 A:middle
So I want to probably hit
somewhere in the middle

00:43:26.076 --> 00:43:29.956 A:middle
where I got rid of most of
the noise but still kept some.

00:43:30.826 --> 00:43:34.006 A:middle
Another good thing that you
can do is brought back some

00:43:34.006 --> 00:43:36.746 A:middle
of the fine high
detail back to the image

00:43:36.746 --> 00:43:38.486 A:middle
after you clean up
all the bad noise.

00:43:38.576 --> 00:43:40.566 A:middle
So the detail slider is the one

00:43:40.566 --> 00:43:41.966 A:middle
that you would be
using for that.

00:43:42.756 --> 00:43:47.666 A:middle
And quickly you can get back to
this film grain type of look.

00:43:49.036 --> 00:43:52.456 A:middle
Same is true for high frequency
contrast and if you choose

00:43:52.456 --> 00:43:54.606 A:middle
to do that, you can also play

00:43:54.606 --> 00:43:57.166 A:middle
with it again 60
frames per second.

00:43:59.246 --> 00:44:01.006 A:middle
So that is the noise filter.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:43:59.246 --> 00:44:01.006 A:middle
So that is the noise filter.

00:44:01.426 --> 00:44:04.056 A:middle
Starting with OS X
Yosemite, you'll also be able

00:44:04.056 --> 00:44:08.446 A:middle
to use this filter for your
JPEG images and this is going

00:44:08.446 --> 00:44:11.646 A:middle
to be a really nice advancement
on top of our offerings.

00:44:12.446 --> 00:44:14.586 A:middle
The last thing that I want

00:44:14.586 --> 00:44:16.486 A:middle
to show you today
is lens correction.

00:44:17.406 --> 00:44:19.716 A:middle
So a lot of the point-and-shoot
cameras

00:44:19.716 --> 00:44:22.476 A:middle
in the market today
are actually relying

00:44:22.476 --> 00:44:26.676 A:middle
on digital signal processing
techniques to fix some

00:44:26.676 --> 00:44:30.386 A:middle
of the compromises that
are made in the lenses.

00:44:31.286 --> 00:44:34.226 A:middle
What I mean by that, the
input image as you can see

00:44:34.296 --> 00:44:36.986 A:middle
by default is looking
correct to us.

00:44:37.426 --> 00:44:39.806 A:middle
But actual, the RAW
image that is coming

00:44:39.806 --> 00:44:41.516 A:middle
in is looking like this.

00:44:43.006 --> 00:44:46.146 A:middle
So whenever that data is
available in the file,

00:44:46.146 --> 00:44:47.956 A:middle
RAW camera will try
to do the right thing

00:44:47.956 --> 00:44:50.546 A:middle
and actually correct
for this aberration.

00:44:51.326 --> 00:44:54.896 A:middle
But for your own application,
you may choose to skip this step

00:44:54.896 --> 00:44:57.416 A:middle
and actually do your
own set of filters

00:44:57.416 --> 00:44:58.806 A:middle
or your own lens correction.

00:44:59.346 --> 00:45:03.786 A:middle
And it's an easy way
to actually go back


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:44:59.346 --> 00:45:03.786 A:middle
And it's an easy way
to actually go back

00:45:03.786 --> 00:45:08.016 A:middle
to the actual RAW sample
of the file itself.

00:45:09.736 --> 00:45:12.836 A:middle
I'm going to now quickly turn
it back to David who's going

00:45:12.836 --> 00:45:16.266 A:middle
to talk about usages
of the second GPU.

00:45:17.041 --> 00:45:19.041 A:middle
[ Applause ]

00:45:19.066 --> 00:45:20.516 A:middle
&gt;&gt; Thank you, Serhan.

00:45:20.516 --> 00:45:23.136 A:middle
So as you saw, we have this
great new noise reduction

00:45:23.136 --> 00:45:26.836 A:middle
and it's a very complex Core
Image filter that we developed

00:45:26.836 --> 00:45:32.086 A:middle
and it makes great use of
the GPU which brings us

00:45:32.086 --> 00:45:33.576 A:middle
up to talking about
the second GPU.

00:45:34.336 --> 00:45:37.956 A:middle
So a year ago, we announced
at the WWDC our new Mac Pro

00:45:37.956 --> 00:45:41.306 A:middle
which has this great feature
of having a second GPU,

00:45:41.856 --> 00:45:43.346 A:middle
just waiting for
your application

00:45:43.346 --> 00:45:44.266 A:middle
to take advantage of it.

00:45:44.916 --> 00:45:49.056 A:middle
So let's talk a little
of how that can be used.

00:45:49.936 --> 00:45:54.756 A:middle
So we had some thoughts about
for Core Image and for RAWs.

00:45:54.756 --> 00:45:57.926 A:middle
When is a good time where you
might want to use a second GPU?

00:45:58.536 --> 00:46:00.366 A:middle
And a couple of scenarios
come to mind.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:45:58.536 --> 00:46:00.366 A:middle
And a couple of scenarios
come to mind.

00:46:00.706 --> 00:46:03.286 A:middle
One is if your application
has ability

00:46:03.286 --> 00:46:04.616 A:middle
to do speculative renders.

00:46:04.616 --> 00:46:07.346 A:middle
For example, you may have
a large list of images.

00:46:07.346 --> 00:46:10.676 A:middle
The user might be looking
at one but he may switch

00:46:10.676 --> 00:46:14.266 A:middle
to the previous or the
following image at any time.

00:46:14.846 --> 00:46:19.226 A:middle
Your application could be
speculatively rendering the next

00:46:19.226 --> 00:46:21.676 A:middle
or previous image
on a second thread.

00:46:22.566 --> 00:46:24.576 A:middle
Similarly, your application
may have the ability

00:46:24.576 --> 00:46:27.156 A:middle
to do a large batch
export and you want to do

00:46:27.156 --> 00:46:30.076 A:middle
that in the background and
you want to use the GPU

00:46:30.946 --> 00:46:33.716 A:middle
but you don't want
that background GPU

00:46:33.716 --> 00:46:35.746 A:middle
to affect your foreground
GPU usage.

00:46:36.016 --> 00:46:39.066 A:middle
So these are both great
reasons to use the second GPU

00:46:39.646 --> 00:46:42.836 A:middle
because it allows you to
get the best performance

00:46:42.956 --> 00:46:45.556 A:middle
without causing your
user interface

00:46:45.556 --> 00:46:47.506 A:middle
to stutter for its usage.

00:46:48.316 --> 00:46:50.426 A:middle
So how does one do that?

00:46:50.746 --> 00:46:53.236 A:middle
Well, you could do this
today on Mavericks.

00:46:53.416 --> 00:46:57.376 A:middle
It takes around 80 lines
of OpenGL code to tell,

00:46:57.726 --> 00:47:00.516 A:middle
to create a CIContext
that refers


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:46:57.726 --> 00:47:00.516 A:middle
to create a CIContext
that refers

00:47:00.516 --> 00:47:02.386 A:middle
to the second offline GPU.

00:47:03.446 --> 00:47:08.446 A:middle
However, we've added a simpler
API in Core Image on Yosemite

00:47:08.816 --> 00:47:11.976 A:middle
which is CIContext
offlineGPUAtIndex

00:47:11.976 --> 00:47:13.616 A:middle
and typically you
just specify zero.

00:47:13.986 --> 00:47:18.086 A:middle
So with one API call, you get
a CIContext and that when using

00:47:18.086 --> 00:47:20.476 A:middle
that all renders will
use the second GPU.

00:47:20.836 --> 00:47:22.106 A:middle
So it's very easy.

00:47:22.676 --> 00:47:25.216 A:middle
And to show that in action,
I'm going to bring Serhan back

00:47:25.216 --> 00:47:26.036 A:middle
up to do a quick demo.

00:47:27.876 --> 00:47:29.116 A:middle
&gt;&gt; Well, in our first demo,

00:47:29.176 --> 00:47:32.246 A:middle
we showed that even the most
computationally expensive noise

00:47:32.246 --> 00:47:35.086 A:middle
filter algorithm can be done
at 60 frames per second.

00:47:36.116 --> 00:47:38.986 A:middle
I'm going to bring that
application back and open

00:47:38.986 --> 00:47:40.296 A:middle
up a very noisy image.

00:47:49.046 --> 00:47:52.876 A:middle
So our LNR controls can be
done at 60 frames per second.

00:47:53.296 --> 00:47:57.176 A:middle
To show you that, we actually
wrote a little bit of code

00:47:57.346 --> 00:48:01.216 A:middle
to display the frames per second
when I'm actually sweeping


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:47:57.346 --> 00:48:01.216 A:middle
to display the frames per second
when I'm actually sweeping

00:48:01.216 --> 00:48:02.936 A:middle
through all the noise
filter settings.

00:48:03.386 --> 00:48:07.606 A:middle
And as you can see, I'm
getting 60 frames per second all

00:48:07.606 --> 00:48:07.896 A:middle
the time.

00:48:08.356 --> 00:48:10.856 A:middle
Now let's say that you
have a background trait

00:48:11.186 --> 00:48:13.416 A:middle
where you are constantly
exporting images

00:48:13.486 --> 00:48:15.096 A:middle
and for some reason you wanted

00:48:15.096 --> 00:48:19.096 A:middle
to do a GPU pipe
on your first GPU.

00:48:19.856 --> 00:48:22.786 A:middle
To simulate that, we
have written a little bit

00:48:23.106 --> 00:48:27.326 A:middle
of text application which
is using the first GPU.

00:48:27.926 --> 00:48:30.486 A:middle
And when I go back
to my own application

00:48:30.546 --> 00:48:32.666 A:middle
which is now also
using my first GPU,

00:48:32.736 --> 00:48:38.246 A:middle
I can see that the frame rate is
actually suffering a little bit.

00:48:38.616 --> 00:48:41.396 A:middle
I'm going to run my test shoot
one more time to see what type

00:48:41.396 --> 00:48:42.976 A:middle
of frame rate I'm
getting out of this.

00:48:43.756 --> 00:48:47.856 A:middle
And you can quickly see that
it has dropped down to 50%.

00:48:47.856 --> 00:48:50.476 A:middle
I'm getting 24 frames
per second.

00:48:51.026 --> 00:48:55.516 A:middle
So can we do something
better than that?

00:48:55.516 --> 00:48:56.656 A:middle
And the answer is yes.

00:48:57.576 --> 00:49:00.026 A:middle
If we can offload this work


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:48:57.576 --> 00:49:00.026 A:middle
If we can offload this work

00:49:00.026 --> 00:49:05.366 A:middle
to our second GPU using
the CIGLOfflineContext,

00:49:05.536 --> 00:49:11.176 A:middle
I will get back to my original
performance in my active app.

00:49:11.476 --> 00:49:14.216 A:middle
And to show you that,
here we go one more time.

00:49:15.056 --> 00:49:18.686 A:middle
I can see that the user controls
are once again very smooth

00:49:18.986 --> 00:49:22.896 A:middle
and the frame rate that I'm
going to get is close to 60.

00:49:28.896 --> 00:49:31.806 A:middle
So once again, this is a
great way to take advantage

00:49:31.806 --> 00:49:35.946 A:middle
of the second GPU if you are
constantly doing computationally

00:49:35.946 --> 00:49:37.516 A:middle
heavy algorithms
in the background.

00:49:38.506 --> 00:49:40.816 A:middle
I'm going to hand it
back once over to David.

00:49:42.036 --> 00:49:43.666 A:middle
&gt;&gt; So to summarize what
we've talked about today.

00:49:43.666 --> 00:49:45.966 A:middle
We've talked about
some key concepts

00:49:45.966 --> 00:49:47.276 A:middle
to understand about Core Image.

00:49:47.856 --> 00:49:50.426 A:middle
We've talked about what's
new in Core Image on iOS 8,

00:49:50.836 --> 00:49:53.856 A:middle
most notably Custom CIKernels
and large image support.

00:49:54.856 --> 00:49:57.206 A:middle
We talked about some
new things in Core Image

00:49:57.386 --> 00:50:01.896 A:middle
on Yosemite notably
some API modernization


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:49:57.386 --> 00:50:01.896 A:middle
on Yosemite notably
some API modernization

00:50:01.896 --> 00:50:05.196 A:middle
and some great new noise
reduction and RAW support.

00:50:05.306 --> 00:50:09.956 A:middle
We've also talked about how
to use the latest CIDetectors

00:50:11.016 --> 00:50:13.546 A:middle
and how to work with
RAW images in ways

00:50:13.546 --> 00:50:14.786 A:middle
that you may have
not imagined before.

00:50:15.366 --> 00:50:18.756 A:middle
So this is the usual information
about who to contact.

00:50:18.756 --> 00:50:20.026 A:middle
Allan's a great person to talk

00:50:20.026 --> 00:50:21.916 A:middle
to if you have a request
for more information.

00:50:22.486 --> 00:50:25.746 A:middle
Related sessions, there's one
I really hope you guys can come

00:50:25.746 --> 00:50:28.726 A:middle
to is our second session this
afternoon where we're going

00:50:28.726 --> 00:50:32.496 A:middle
to be talking about how to
write Custom CIKernels on iOS.

00:50:33.016 --> 00:50:35.656 A:middle
And also, we have a lab
session that follows that so

00:50:35.656 --> 00:50:38.846 A:middle
if you have coding questions,
please come and we would love

00:50:38.846 --> 00:50:40.976 A:middle
to hear your questions
or suggestions.

00:50:42.276 --> 00:50:42.906 A:middle
So that's all.

00:50:43.216 --> 00:50:44.166 A:middle
Thank you so much for coming.

00:50:45.516 --> 00:50:53.520 A:middle
[ Applause ]

