WEBVTT

00:00:00.506 --> 00:00:05.516 A:middle
[ Music ]

00:00:06.516 --> 00:00:13.566 A:middle
[ Applause ]

00:00:14.066 --> 00:00:15.986 A:middle
&gt;&gt; Hey, everyone.

00:00:16.436 --> 00:00:17.476 A:middle
My name is Michael Brennan.

00:00:17.576 --> 00:00:19.116 A:middle
I'm a software engineer here at

00:00:19.116 --> 00:00:20.386 A:middle
Apple working on Core ML.

00:00:21.336 --> 00:00:23.026 A:middle
And I'm thrilled to be able to

00:00:23.026 --> 00:00:23.996 A:middle
share with you some of the

00:00:23.996 --> 00:00:25.636 A:middle
amazing new features we've

00:00:25.636 --> 00:00:27.726 A:middle
introduced this year for Core ML

00:00:27.776 --> 00:00:27.976 A:middle
3.

00:00:30.336 --> 00:00:31.856 A:middle
Core ML makes it as easy as

00:00:31.856 --> 00:00:33.946 A:middle
possible to seamlessly integrate

00:00:33.946 --> 00:00:35.076 A:middle
machine learning into your

00:00:35.076 --> 00:00:37.156 A:middle
application allowing you to

00:00:37.156 --> 00:00:38.686 A:middle
create a wide variety of novel

00:00:39.136 --> 00:00:40.336 A:middle
and compelling experiences.

00:00:41.376 --> 00:00:43.156 A:middle
At the center of all of this is

00:00:43.246 --> 00:00:46.856 A:middle
the model itself.

00:00:47.046 --> 00:00:48.716 A:middle
You can get a model from a

00:00:48.716 --> 00:00:49.776 A:middle
number of supported training

00:00:49.776 --> 00:00:51.736 A:middle
libraries by converting them

00:00:51.736 --> 00:00:53.026 A:middle
using the converters we have as

00:00:53.546 --> 00:00:55.066 A:middle
a part of our Core ML tools

00:00:55.226 --> 00:00:57.146 A:middle
which we provide.

00:00:57.276 --> 00:00:59.966 A:middle
And with the addition of the new

00:00:59.966 --> 00:01:01.716 A:middle
Create ML app, we've made it

00:00:59.966 --> 00:01:01.716 A:middle
Create ML app, we've made it

00:01:01.716 --> 00:01:03.906 A:middle
even easier than before to get a

00:01:03.906 --> 00:01:04.256 A:middle
model.

00:01:06.596 --> 00:01:07.816 A:middle
So in this session we're going

00:01:07.816 --> 00:01:09.926 A:middle
to cover a number of topics from

00:01:10.006 --> 00:01:11.276 A:middle
personalizing those models on

00:01:11.276 --> 00:01:13.106 A:middle
device to additional support

00:01:13.106 --> 00:01:14.296 A:middle
we've added for neural networks

00:01:14.936 --> 00:01:16.196 A:middle
and even more.

00:01:17.476 --> 00:01:18.436 A:middle
So let's get started by talking

00:01:18.436 --> 00:01:20.116 A:middle
a little bit about personalizing

00:01:20.116 --> 00:01:21.496 A:middle
your models on-device.

00:01:24.396 --> 00:01:27.046 A:middle
Traditionally, these models are

00:01:27.046 --> 00:01:28.196 A:middle
either bundled with or

00:01:28.196 --> 00:01:29.506 A:middle
downloaded to your application.

00:01:30.066 --> 00:01:31.206 A:middle
And once on your device are

00:01:31.206 --> 00:01:33.136 A:middle
completely mutable being

00:01:33.136 --> 00:01:34.426 A:middle
optimized heavily for

00:01:34.426 --> 00:01:36.306 A:middle
performance within your app.

00:01:38.596 --> 00:01:39.506 A:middle
The great thing about

00:01:39.506 --> 00:01:40.596 A:middle
associating a model with your

00:01:40.596 --> 00:01:42.036 A:middle
app is it means you can provide

00:01:42.036 --> 00:01:43.756 A:middle
the same great experience across

00:01:43.756 --> 00:01:44.776 A:middle
all of your users.

00:01:45.326 --> 00:01:47.626 A:middle
But each user is unique.

00:01:48.206 --> 00:01:49.856 A:middle
They each have their own

00:01:49.856 --> 00:01:51.696 A:middle
specialized needs, their own

00:01:51.736 --> 00:01:53.526 A:middle
individual ways of interacting

00:01:53.526 --> 00:01:54.256 A:middle
with your application.

00:01:55.416 --> 00:01:56.366 A:middle
I think this creates an

00:01:56.366 --> 00:01:56.946 A:middle
opportunity.

00:01:57.506 --> 00:02:00.626 A:middle
What if each user could get a

00:01:57.506 --> 00:02:00.626 A:middle
What if each user could get a

00:02:00.626 --> 00:02:02.746 A:middle
model personalized specifically

00:02:02.836 --> 00:02:03.356 A:middle
for them?

00:02:03.906 --> 00:02:06.746 A:middle
Well, let's look at the case of

00:02:06.746 --> 00:02:07.966 A:middle
one user on how to do this.

00:02:08.955 --> 00:02:10.306 A:middle
We can take data from that user,

00:02:11.156 --> 00:02:12.226 A:middle
set up some sort of cloud

00:02:12.226 --> 00:02:14.636 A:middle
service, send that data to that

00:02:14.636 --> 00:02:17.026 A:middle
cloud service, and in the cloud

00:02:17.126 --> 00:02:18.216 A:middle
create that new model

00:02:18.446 --> 00:02:20.056 A:middle
personalized on that data which

00:02:20.056 --> 00:02:21.096 A:middle
will then deploy back to that

00:02:21.096 --> 00:02:21.386 A:middle
user.

00:02:23.276 --> 00:02:23.956 A:middle
This creates a number of

00:02:23.956 --> 00:02:25.076 A:middle
challenges, both to you, the

00:02:25.076 --> 00:02:26.956 A:middle
developers, and to our users.

00:02:28.486 --> 00:02:30.086 A:middle
For you, it creates the

00:02:30.086 --> 00:02:32.756 A:middle
challenge of added expenses with

00:02:32.756 --> 00:02:33.976 A:middle
making these cloud services

00:02:34.026 --> 00:02:35.886 A:middle
managing that service and

00:02:35.886 --> 00:02:36.836 A:middle
creating an infrastructure that

00:02:36.836 --> 00:02:38.316 A:middle
could scale to million of users.

00:02:38.976 --> 00:02:41.036 A:middle
And for the user, obviously they

00:02:41.036 --> 00:02:43.266 A:middle
have to expose all their data.

00:02:43.266 --> 00:02:43.976 A:middle
It's unwanted.

00:02:44.146 --> 00:02:44.856 A:middle
It's invasive.

00:02:44.856 --> 00:02:46.346 A:middle
They have to expose this and

00:02:46.346 --> 00:02:47.116 A:middle
send it up to the cloud where

00:02:47.116 --> 00:02:48.766 A:middle
it'll be managed by some other

00:02:48.766 --> 00:02:49.116 A:middle
party.

00:02:49.716 --> 00:02:53.786 A:middle
On Core ML 3, you can do this

00:02:53.786 --> 00:02:55.946 A:middle
kind of personalization all on

00:02:55.946 --> 00:02:56.376 A:middle
device.

00:02:57.516 --> 00:03:03.176 A:middle
[ Applause ]

00:02:57.516 --> 00:03:03.176 A:middle
[ Applause ]

00:03:03.676 --> 00:03:05.006 A:middle
Simply take that general model

00:03:05.566 --> 00:03:06.806 A:middle
and with the data the users

00:03:06.806 --> 00:03:09.186 A:middle
created or regenerated, you can

00:03:09.186 --> 00:03:10.676 A:middle
personalize that model with that

00:03:11.276 --> 00:03:14.756 A:middle
data for that user.

00:03:14.906 --> 00:03:16.376 A:middle
This means that the data stays

00:03:16.476 --> 00:03:16.816 A:middle
private.

00:03:17.426 --> 00:03:18.686 A:middle
It never leaves the device.

00:03:19.676 --> 00:03:20.856 A:middle
This means there's no need for a

00:03:20.856 --> 00:03:21.946 A:middle
server to do this kind of

00:03:21.946 --> 00:03:22.616 A:middle
interactivity.

00:03:22.616 --> 00:03:24.566 A:middle
And this means you can do it

00:03:24.566 --> 00:03:24.896 A:middle
anywhere.

00:03:25.356 --> 00:03:26.956 A:middle
You're not tying your users down

00:03:26.956 --> 00:03:29.426 A:middle
to Wi-Fi or some data plan just

00:03:29.426 --> 00:03:30.106 A:middle
to update their model.

00:03:33.306 --> 00:03:34.376 A:middle
Before we continue, let's look

00:03:34.376 --> 00:03:36.056 A:middle
inside one of these models and

00:03:36.496 --> 00:03:38.706 A:middle
see what's there today.

00:03:38.876 --> 00:03:40.176 A:middle
Currently, your model consists

00:03:40.176 --> 00:03:42.046 A:middle
of mostly parameters, things

00:03:42.046 --> 00:03:43.506 A:middle
like the weights of the layers

00:03:43.506 --> 00:03:44.346 A:middle
if it's a neural network for

00:03:44.346 --> 00:03:44.776 A:middle
example.

00:03:45.396 --> 00:03:46.556 A:middle
And some metadata describing

00:03:46.556 --> 00:03:48.196 A:middle
things like licensing and

00:03:48.196 --> 00:03:50.056 A:middle
authors, as well as an

00:03:50.056 --> 00:03:50.716 A:middle
interface.

00:03:50.716 --> 00:03:51.736 A:middle
And this where your app concerns

00:03:51.736 --> 00:03:52.226 A:middle
itself with.

00:03:52.776 --> 00:03:53.756 A:middle
It describes how you can

00:03:53.756 --> 00:03:55.736 A:middle
interact with this model.

00:03:56.516 --> 00:03:58.396 A:middle
On Core ML 3, we've added a new

00:03:58.436 --> 00:04:00.026 A:middle
set of parameters to help

00:03:58.436 --> 00:04:00.026 A:middle
set of parameters to help

00:04:00.026 --> 00:04:00.496 A:middle
updating.

00:04:00.496 --> 00:04:01.496 A:middle
It describes what parts of the

00:04:01.496 --> 00:04:02.986 A:middle
model are updatable and how it's

00:04:02.986 --> 00:04:03.446 A:middle
updatable.

00:04:03.976 --> 00:04:04.966 A:middle
We've added a new update

00:04:04.966 --> 00:04:06.146 A:middle
interface your app can leverage

00:04:06.146 --> 00:04:07.096 A:middle
to make these updates happen.

00:04:10.216 --> 00:04:11.396 A:middle
This means that all the

00:04:11.396 --> 00:04:13.206 A:middle
functionality is accessed

00:04:13.206 --> 00:04:14.396 A:middle
directly through that interface.

00:04:14.686 --> 00:04:16.136 A:middle
We encapsulate away a lot of

00:04:16.136 --> 00:04:18.366 A:middle
those heavy details and it's all

00:04:18.366 --> 00:04:19.755 A:middle
contained within that one model

00:04:19.755 --> 00:04:20.096 A:middle
file.

00:04:20.726 --> 00:04:23.166 A:middle
So just like in making a

00:04:23.166 --> 00:04:24.616 A:middle
prediction, we supply a set of

00:04:24.616 --> 00:04:25.446 A:middle
inputs and you get a

00:04:25.446 --> 00:04:26.756 A:middle
corresponding set of outputs.

00:04:27.756 --> 00:04:29.146 A:middle
Making an update is easy, you

00:04:29.146 --> 00:04:30.216 A:middle
just supply a set of training

00:04:30.216 --> 00:04:31.796 A:middle
examples and you'll get out a

00:04:31.796 --> 00:04:33.006 A:middle
new variant of that model that

00:04:33.106 --> 00:04:34.636 A:middle
was fit or fine-tuned to that

00:04:34.636 --> 00:04:34.856 A:middle
data.

00:04:38.096 --> 00:04:40.356 A:middle
For Core ML 3, we support making

00:04:40.356 --> 00:04:41.736 A:middle
updatable models of nearest

00:04:41.736 --> 00:04:43.586 A:middle
neighbor classifiers as well as

00:04:43.586 --> 00:04:44.416 A:middle
neural networks.

00:04:44.646 --> 00:04:45.496 A:middle
And we're going to support

00:04:45.496 --> 00:04:46.706 A:middle
embedding an updatable model

00:04:46.706 --> 00:04:48.296 A:middle
within your pipeline, meaning

00:04:48.296 --> 00:04:49.626 A:middle
your pipelines are updatable

00:04:49.626 --> 00:04:49.896 A:middle
too.

00:04:50.486 --> 00:04:54.576 A:middle
And with that, I think we should

00:04:54.576 --> 00:04:55.386 A:middle
see this in action.

00:04:55.746 --> 00:04:56.976 A:middle
So I'd like to hand it over to

00:04:56.976 --> 00:04:58.286 A:middle
my colleague Anil Katti.

00:04:59.016 --> 00:04:59.336 A:middle
Anil.

00:05:00.516 --> 00:05:06.176 A:middle
[ Applause ]

00:05:06.676 --> 00:05:07.516 A:middle
&gt;&gt; Thanks, Michael.

00:05:07.896 --> 00:05:11.756 A:middle
Hello. Today I show how I build

00:05:11.756 --> 00:05:12.846 A:middle
an experience that was

00:05:12.916 --> 00:05:15.536 A:middle
customized for my users using

00:05:15.906 --> 00:05:17.126 A:middle
model personalization.

00:05:17.716 --> 00:05:19.486 A:middle
For this I have an app that

00:05:19.486 --> 00:05:21.216 A:middle
helps teachers grade students'

00:05:21.216 --> 00:05:21.616 A:middle
homework.

00:05:22.536 --> 00:05:23.846 A:middle
I added a cool new feature to

00:05:23.846 --> 00:05:25.176 A:middle
this app using model

00:05:25.176 --> 00:05:25.826 A:middle
personalization.

00:05:26.046 --> 00:05:27.186 A:middle
But before we talk about the

00:05:27.186 --> 00:05:28.426 A:middle
feature, let's see what the app

00:05:28.426 --> 00:05:28.946 A:middle
does first.

00:05:28.946 --> 00:05:30.456 A:middle
Let me switch over to the demo

00:05:30.456 --> 00:05:30.976 A:middle
screen.

00:05:37.376 --> 00:05:40.136 A:middle
Great. So here's the app.

00:05:40.136 --> 00:05:41.306 A:middle
It's called a Personalized

00:05:41.306 --> 00:05:41.886 A:middle
Grading App.

00:05:42.396 --> 00:05:44.356 A:middle
What it allows you to do is take

00:05:44.356 --> 00:05:47.626 A:middle
a picture of the homework and

00:05:47.626 --> 00:05:49.896 A:middle
start grading the way our

00:05:49.896 --> 00:05:51.006 A:middle
teacher would on a sheet of

00:05:51.006 --> 00:05:51.396 A:middle
paper.

00:05:52.266 --> 00:05:53.846 A:middle
You'd mark something as correct

00:05:53.846 --> 00:05:55.556 A:middle
like that and something as wrong

00:05:55.856 --> 00:05:56.436 A:middle
like that.

00:05:56.736 --> 00:05:58.166 A:middle
It's pretty straightforward.

00:05:58.356 --> 00:05:59.626 A:middle
Pretty simple.

00:06:00.186 --> 00:06:02.416 A:middle
The app uses PencilKit to

00:06:02.416 --> 00:06:04.126 A:middle
capture the input and the

00:06:04.126 --> 00:06:05.736 A:middle
pretrained Core ML model to

00:06:05.736 --> 00:06:07.746 A:middle
recognize the grading samples.

00:06:08.856 --> 00:06:10.726 A:middle
Now recently, I added a new

00:06:10.726 --> 00:06:12.686 A:middle
feature that allows teachers

00:06:13.086 --> 00:06:14.556 A:middle
give something special for the

00:06:14.556 --> 00:06:16.026 A:middle
kids for encouragement.

00:06:17.216 --> 00:06:18.066 A:middle
And that is stickers.

00:06:19.136 --> 00:06:21.026 A:middle
Kids absolutely love collecting

00:06:21.026 --> 00:06:22.026 A:middle
stickers on their homework.

00:06:22.436 --> 00:06:23.306 A:middle
So we thought it might be a

00:06:23.306 --> 00:06:24.816 A:middle
really nice enhancement to the

00:06:25.006 --> 00:06:26.736 A:middle
app if they could allow-- if we

00:06:26.736 --> 00:06:27.566 A:middle
could allow them to give

00:06:27.566 --> 00:06:27.936 A:middle
stickers.

00:06:29.356 --> 00:06:31.056 A:middle
So to give a sticker, I could

00:06:31.056 --> 00:06:32.596 A:middle
tap on this plus button up here.

00:06:32.596 --> 00:06:35.396 A:middle
Scroll through the list of

00:06:35.396 --> 00:06:38.236 A:middle
stickers, maybe pick one, and

00:06:38.236 --> 00:06:40.466 A:middle
drag it to the right location

00:06:40.466 --> 00:06:40.726 A:middle
[inaudible].

00:06:40.726 --> 00:06:41.146 A:middle
This works.

00:06:41.146 --> 00:06:46.396 A:middle
But I think we can make the flow

00:06:46.396 --> 00:06:48.356 A:middle
even better and absolutely

00:06:48.356 --> 00:06:49.576 A:middle
magical for our users.

00:06:49.846 --> 00:06:52.266 A:middle
Let's think about it a little

00:06:52.766 --> 00:06:52.866 A:middle
bit.

00:06:53.776 --> 00:06:55.786 A:middle
The user is only using an Apple

00:06:55.786 --> 00:06:57.156 A:middle
Pencil for grading.

00:06:57.156 --> 00:06:59.296 A:middle
How cool would it be if they

00:06:59.296 --> 00:07:00.646 A:middle
could quickly sketch something

00:06:59.296 --> 00:07:00.646 A:middle
could quickly sketch something

00:07:01.046 --> 00:07:03.246 A:middle
anywhere on the entire screen

00:07:03.476 --> 00:07:04.936 A:middle
and the app automatically pick

00:07:04.936 --> 00:07:06.316 A:middle
the right sticker of the correct

00:07:06.316 --> 00:07:07.766 A:middle
size and place it at the right

00:07:07.766 --> 00:07:09.876 A:middle
location for them.

00:07:10.096 --> 00:07:11.656 A:middle
Well, we can definitely do

00:07:11.656 --> 00:07:12.806 A:middle
something like that with machine

00:07:12.806 --> 00:07:13.306 A:middle
learning, right?

00:07:13.306 --> 00:07:15.036 A:middle
So let's explore some options.

00:07:15.296 --> 00:07:16.686 A:middle
Let me switch over to the

00:07:16.686 --> 00:07:16.956 A:middle
slides.

00:07:17.666 --> 00:07:18.496 A:middle
Well, some of you who have

00:07:18.496 --> 00:07:20.646 A:middle
already worked on Core ML might

00:07:20.646 --> 00:07:21.826 A:middle
be thinking, well, we could

00:07:21.826 --> 00:07:25.426 A:middle
actually pre-train a model that

00:07:25.426 --> 00:07:27.286 A:middle
can recognize stickers and ship

00:07:27.286 --> 00:07:29.316 A:middle
it as part of the app.

00:07:29.406 --> 00:07:30.496 A:middle
Well, we could do that but there

00:07:30.496 --> 00:07:31.476 A:middle
are a few issues with this

00:07:31.476 --> 00:07:31.966 A:middle
approach.

00:07:32.586 --> 00:07:34.836 A:middle
For one, there are a lot of

00:07:34.836 --> 00:07:36.556 A:middle
stickers out there and we might

00:07:36.556 --> 00:07:37.746 A:middle
have to collect a lot of

00:07:37.746 --> 00:07:39.176 A:middle
training data in order to

00:07:39.176 --> 00:07:41.966 A:middle
pre-train these models, although

00:07:41.966 --> 00:07:43.326 A:middle
a particular user might only be

00:07:43.326 --> 00:07:46.026 A:middle
interested in a small subset of

00:07:46.756 --> 00:07:47.336 A:middle
these stickers.

00:07:47.336 --> 00:07:50.436 A:middle
Second, how does this pretrained

00:07:50.436 --> 00:07:52.196 A:middle
model work if I plan to

00:07:52.196 --> 00:07:53.426 A:middle
introduce a bunch of new

00:07:53.426 --> 00:07:55.826 A:middle
stickers in the future?

00:07:56.006 --> 00:07:57.386 A:middle
Well, I might have to re-train

00:07:57.386 --> 00:07:59.666 A:middle
the model and ship it as an app

00:07:59.666 --> 00:08:01.716 A:middle
update or maybe allow the app to

00:07:59.666 --> 00:08:01.716 A:middle
update or maybe allow the app to

00:08:01.716 --> 00:08:02.986 A:middle
download it.

00:08:04.136 --> 00:08:05.766 A:middle
Lastly, and I think this is the

00:08:05.766 --> 00:08:07.706 A:middle
most crucial point, how does

00:08:07.706 --> 00:08:08.956 A:middle
this pretrained model work for

00:08:08.956 --> 00:08:09.786 A:middle
different users?

00:08:12.316 --> 00:08:14.496 A:middle
Different users have different

00:08:14.496 --> 00:08:15.326 A:middle
ways of sketching.

00:08:16.376 --> 00:08:18.076 A:middle
If I went out and I asked a

00:08:18.076 --> 00:08:19.516 A:middle
hundred different people to

00:08:19.516 --> 00:08:20.896 A:middle
quickly sketch this mind-blowing

00:08:20.896 --> 00:08:22.606 A:middle
sticker, I'll get at least 50

00:08:22.606 --> 00:08:23.276 A:middle
different answers.

00:08:24.006 --> 00:08:25.476 A:middle
Now, it's truly mind-blowing how

00:08:25.476 --> 00:08:26.376 A:middle
different people are.

00:08:26.906 --> 00:08:28.546 A:middle
So what should the app do in

00:08:28.546 --> 00:08:29.626 A:middle
this case?

00:08:30.616 --> 00:08:32.856 A:middle
Should we-- Should the app train

00:08:32.856 --> 00:08:35.655 A:middle
the users on how to sketch

00:08:35.655 --> 00:08:39.626 A:middle
something, or should the users

00:08:39.626 --> 00:08:41.666 A:middle
train the app, enhance the model

00:08:41.876 --> 00:08:43.816 A:middle
how to recognize your sketches?

00:08:44.826 --> 00:08:46.516 A:middle
Well, that's exactly what model

00:08:46.516 --> 00:08:49.556 A:middle
personalization is all about.

00:08:49.756 --> 00:08:51.626 A:middle
What I did was use model

00:08:51.626 --> 00:08:53.926 A:middle
personalization to train-- to

00:08:53.926 --> 00:08:55.856 A:middle
define a model using the data

00:08:55.856 --> 00:08:56.866 A:middle
that I collected about the

00:08:56.866 --> 00:08:59.206 A:middle
user-- from the user to suit

00:08:59.206 --> 00:08:59.816 A:middle
their needs.

00:08:59.966 --> 00:09:01.246 A:middle
Let me show how that translates

00:08:59.966 --> 00:09:01.246 A:middle
Let me show how that translates

00:09:01.246 --> 00:09:02.536 A:middle
to user experience.

00:09:08.516 --> 00:09:09.636 A:middle
I'll switch back to the demo

00:09:09.636 --> 00:09:11.286 A:middle
screen to continue my grading.

00:09:12.046 --> 00:09:13.336 A:middle
So the third answer-- third

00:09:13.336 --> 00:09:14.666 A:middle
question there is pretty tricky

00:09:14.666 --> 00:09:15.846 A:middle
for kindergarten care, but I

00:09:15.846 --> 00:09:17.246 A:middle
think Jane got it spot on.

00:09:17.396 --> 00:09:18.796 A:middle
There are four triangles in that

00:09:18.796 --> 00:09:19.646 A:middle
diagram.

00:09:20.016 --> 00:09:20.996 A:middle
So, good job, Jane.

00:09:21.896 --> 00:09:23.856 A:middle
Well, now I want to give her a

00:09:23.856 --> 00:09:25.476 A:middle
sticker to recognize the

00:09:25.476 --> 00:09:26.716 A:middle
attention to detail, but I want

00:09:26.716 --> 00:09:27.946 A:middle
to do it by quickly sketching

00:09:27.946 --> 00:09:28.286 A:middle
something.

00:09:28.886 --> 00:09:29.956 A:middle
Let's try doing that.

00:09:30.466 --> 00:09:35.526 A:middle
So the app seems to tell me that

00:09:35.526 --> 00:09:36.826 A:middle
it could not recognize what I

00:09:36.826 --> 00:09:38.406 A:middle
sketch, which is pretty fair

00:09:38.406 --> 00:09:39.396 A:middle
because this is the first time

00:09:39.396 --> 00:09:40.176 A:middle
I'm using this app.

00:09:40.616 --> 00:09:42.406 A:middle
So let me try to add a sticker,

00:09:42.666 --> 00:09:43.946 A:middle
but this time I'll say I want to

00:09:43.946 --> 00:09:45.966 A:middle
create a shortcut, right.

00:09:45.966 --> 00:09:47.146 A:middle
And I'll pick the same sticker

00:09:47.146 --> 00:09:48.836 A:middle
that I used last time.

00:09:49.876 --> 00:09:52.446 A:middle
So now the app is asking me to

00:09:52.446 --> 00:09:54.646 A:middle
give an example of how I would

00:09:54.646 --> 00:09:55.896 A:middle
sketch this particular sticker.

00:09:56.616 --> 00:09:57.876 A:middle
It doesn't have to be perfect.

00:09:57.876 --> 00:09:59.466 A:middle
It doesn't even have to resemble

00:09:59.466 --> 00:09:59.926 A:middle
the sticker.

00:10:00.296 --> 00:10:02.566 A:middle
It's just my own representation

00:10:02.916 --> 00:10:05.336 A:middle
of how I would want to sketch

00:10:05.336 --> 00:10:05.976 A:middle
that sticker, right?

00:10:06.286 --> 00:10:09.516 A:middle
So I'll just use a single star

00:10:10.136 --> 00:10:13.576 A:middle
to represent that particular

00:10:13.576 --> 00:10:13.996 A:middle
sticker.

00:10:13.996 --> 00:10:16.926 A:middle
The app asked me for a couple of

00:10:16.926 --> 00:10:18.226 A:middle
more examples, which is pretty

00:10:18.226 --> 00:10:19.726 A:middle
fair, and it just took a few

00:10:19.726 --> 00:10:21.726 A:middle
seconds but now it looks like

00:10:21.726 --> 00:10:23.126 A:middle
the app-- the shortcut has been

00:10:23.126 --> 00:10:23.916 A:middle
registered.

00:10:24.586 --> 00:10:26.516 A:middle
Now I see the sticker as well as

00:10:26.516 --> 00:10:28.186 A:middle
examples I provided in the

00:10:28.186 --> 00:10:28.736 A:middle
screen.

00:10:29.866 --> 00:10:31.356 A:middle
Before I go back, let me add one

00:10:31.356 --> 00:10:33.416 A:middle
more sticker to my library.

00:10:34.536 --> 00:10:35.806 A:middle
So, there was this really nice

00:10:35.966 --> 00:10:37.616 A:middle
high five sticker that I wanted

00:10:37.616 --> 00:10:39.026 A:middle
to use, which is right here.

00:10:39.676 --> 00:10:42.236 A:middle
I wonder what I should use as

00:10:42.236 --> 00:10:42.976 A:middle
shortcut for this.

00:10:43.706 --> 00:10:45.186 A:middle
I wanted-- I want something that

00:10:45.186 --> 00:10:46.596 A:middle
is easy to remember, easy to

00:10:46.596 --> 00:10:47.076 A:middle
sketch.

00:10:47.426 --> 00:10:49.236 A:middle
How about the number 5, which

00:10:49.236 --> 00:10:52.406 A:middle
kind of says high five?

00:10:53.276 --> 00:10:55.926 A:middle
Great. So just two more examples

00:10:55.926 --> 00:10:56.576 A:middle
and I'm done.

00:10:58.006 --> 00:11:00.006 A:middle
Let's go back to the screen and

00:10:58.006 --> 00:11:00.006 A:middle
Let's go back to the screen and

00:11:00.006 --> 00:11:01.166 A:middle
try giving that sticker that

00:11:01.166 --> 00:11:02.456 A:middle
Jane has been desperately

00:11:02.456 --> 00:11:03.156 A:middle
waiting for.

00:11:04.626 --> 00:11:05.826 A:middle
Isn't that cool?

00:11:06.516 --> 00:11:10.966 A:middle
[ Applause ]

00:11:11.466 --> 00:11:12.986 A:middle
I'm so glad I didn't have the go

00:11:12.986 --> 00:11:14.656 A:middle
through the sticker picker and

00:11:14.656 --> 00:11:15.756 A:middle
move the sticker around and all

00:11:15.756 --> 00:11:16.746 A:middle
those mess.

00:11:17.736 --> 00:11:19.256 A:middle
Great. For the next one-- yeah,

00:11:19.256 --> 00:11:20.166 A:middle
that's right as well.

00:11:20.166 --> 00:11:21.526 A:middle
So let me give another small

00:11:21.526 --> 00:11:22.416 A:middle
star there.

00:11:23.176 --> 00:11:24.456 A:middle
I'm super happy with the way the

00:11:24.456 --> 00:11:26.256 A:middle
app behaves, so a big high five

00:11:26.256 --> 00:11:27.026 A:middle
at the top.

00:11:27.446 --> 00:11:28.976 A:middle
How about that?

00:11:29.516 --> 00:11:35.786 A:middle
[ Applause ]

00:11:36.286 --> 00:11:38.166 A:middle
So this was just an example.

00:11:38.166 --> 00:11:39.316 A:middle
You guys can think about really

00:11:39.316 --> 00:11:41.566 A:middle
amazing experiences that you can

00:11:41.566 --> 00:11:42.856 A:middle
kind of solve using this new

00:11:42.856 --> 00:11:43.226 A:middle
feature.

00:11:43.876 --> 00:11:45.516 A:middle
So before I wrap up, let me

00:11:45.516 --> 00:11:46.696 A:middle
quickly go with the things that

00:11:46.696 --> 00:11:47.856 A:middle
I had to do in order to

00:11:47.856 --> 00:11:48.736 A:middle
implement this feature.

00:11:49.856 --> 00:11:51.376 A:middle
So the first thing I had to do

00:11:51.866 --> 00:11:54.416 A:middle
was import an updatable Core ML

00:11:54.416 --> 00:11:56.366 A:middle
model into my project.

00:11:57.096 --> 00:11:58.186 A:middle
And this is how it looks in

00:11:58.186 --> 00:11:58.856 A:middle
Xcode.

00:12:00.656 --> 00:12:01.626 A:middle
Since I was trying to

00:12:01.626 --> 00:12:03.396 A:middle
personalize the model by adding

00:12:03.396 --> 00:12:05.776 A:middle
new stickers or classes, using

00:12:05.776 --> 00:12:07.046 A:middle
the nearest neighbor classifier

00:12:07.046 --> 00:12:10.356 A:middle
made a lot of sense, although

00:12:10.356 --> 00:12:12.176 A:middle
that is a pretrained neural

00:12:12.176 --> 00:12:14.046 A:middle
network feature extractor, that

00:12:14.046 --> 00:12:15.216 A:middle
is filling in into the nearest

00:12:15.216 --> 00:12:16.676 A:middle
neighbor classifier to help

00:12:16.676 --> 00:12:18.096 A:middle
improve the prediction

00:12:18.096 --> 00:12:19.116 A:middle
efficiency and robustness.

00:12:20.016 --> 00:12:21.696 A:middle
But that's it, you don't have to

00:12:21.696 --> 00:12:23.306 A:middle
worry about any of model details

00:12:23.666 --> 00:12:25.466 A:middle
since Core ML abstracts the way

00:12:25.866 --> 00:12:27.026 A:middle
all the model details from the

00:12:27.026 --> 00:12:27.946 A:middle
API surface.

00:12:31.576 --> 00:12:32.906 A:middle
You can use this model for

00:12:32.906 --> 00:12:33.276 A:middle
prediction.

00:12:33.276 --> 00:12:34.586 A:middle
There is no change there.

00:12:35.486 --> 00:12:36.606 A:middle
In Xcode you will see the

00:12:36.606 --> 00:12:37.976 A:middle
prediction inputs and outputs

00:12:37.976 --> 00:12:38.636 A:middle
like before.

00:12:40.096 --> 00:12:42.276 A:middle
But what's new this year is an

00:12:42.276 --> 00:12:43.066 A:middle
update section.

00:12:44.366 --> 00:12:45.666 A:middle
This describes the set of

00:12:45.666 --> 00:12:47.446 A:middle
inputs, yeah, this model

00:12:47.446 --> 00:12:48.656 A:middle
requires for personalization.

00:12:49.226 --> 00:12:50.646 A:middle
And as expected, it requires a

00:12:50.646 --> 00:12:51.896 A:middle
sticker which is a grayscale

00:12:51.896 --> 00:12:54.066 A:middle
image, and a corresponding

00:12:54.066 --> 00:12:55.086 A:middle
sketch which is a grayscale

00:12:55.086 --> 00:12:56.496 A:middle
image, and a corresponding

00:12:56.496 --> 00:12:57.856 A:middle
sticker which serves as a true

00:12:57.856 --> 00:12:59.346 A:middle
label in order to personalize.

00:13:00.326 --> 00:13:02.206 A:middle
In terms of code, you may recall

00:13:02.206 --> 00:13:04.326 A:middle
that Core ML auto-generates a

00:13:04.326 --> 00:13:06.196 A:middle
set of classes to help you with

00:13:06.196 --> 00:13:06.786 A:middle
the prediction.

00:13:07.296 --> 00:13:09.086 A:middle
And now it generates new class

00:13:09.596 --> 00:13:10.716 A:middle
that helps you provide the

00:13:10.716 --> 00:13:11.896 A:middle
training data in a [inaudible]

00:13:11.896 --> 00:13:12.246 A:middle
manner.

00:13:13.336 --> 00:13:14.606 A:middle
If you peek into this class,

00:13:14.986 --> 00:13:16.466 A:middle
you'll see a set of properties

00:13:16.676 --> 00:13:17.906 A:middle
which are in line with what you

00:13:17.906 --> 00:13:19.156 A:middle
saw in Xcode, right?

00:13:19.156 --> 00:13:21.646 A:middle
So we see the sketch and the

00:13:21.646 --> 00:13:22.596 A:middle
sticker here.

00:13:24.556 --> 00:13:26.986 A:middle
So once you have collected all

00:13:26.986 --> 00:13:29.056 A:middle
the training data from the user

00:13:29.556 --> 00:13:31.596 A:middle
that is required to personalize

00:13:31.596 --> 00:13:34.016 A:middle
a model for-- or for the user,

00:13:34.746 --> 00:13:36.076 A:middle
the actual personalization

00:13:36.076 --> 00:13:37.746 A:middle
itself can happen in three easy

00:13:37.746 --> 00:13:38.106 A:middle
steps.

00:13:38.106 --> 00:13:40.206 A:middle
First, you need to get the

00:13:40.206 --> 00:13:43.356 A:middle
updatable model URL that you

00:13:43.356 --> 00:13:44.886 A:middle
could get either from the bundle

00:13:45.136 --> 00:13:46.526 A:middle
or from a previous snapshot of

00:13:46.526 --> 00:13:47.576 A:middle
the updated model.

00:13:47.876 --> 00:13:50.616 A:middle
Next, you would prepare the

00:13:50.616 --> 00:13:52.056 A:middle
training data in the expected

00:13:52.056 --> 00:13:52.556 A:middle
format.

00:13:53.176 --> 00:13:55.236 A:middle
For this, you could either use

00:13:55.666 --> 00:13:57.786 A:middle
the origin rated class that I

00:13:57.786 --> 00:13:59.336 A:middle
showed or build a feature

00:13:59.336 --> 00:14:00.416 A:middle
provider of your own.

00:13:59.336 --> 00:14:00.416 A:middle
provider of your own.

00:14:01.616 --> 00:14:03.766 A:middle
And lastly, you would kick off

00:14:03.766 --> 00:14:04.596 A:middle
an update task.

00:14:05.176 --> 00:14:07.736 A:middle
Once the update is complete,

00:14:08.146 --> 00:14:09.686 A:middle
completion handler gets invoked

00:14:10.176 --> 00:14:11.636 A:middle
which provides you the updated

00:14:11.636 --> 00:14:13.666 A:middle
model that you can use for

00:14:13.666 --> 00:14:14.766 A:middle
predictions immediately.

00:14:15.236 --> 00:14:16.026 A:middle
It's that simple.

00:14:16.026 --> 00:14:18.246 A:middle
I can't wait to see all the cool

00:14:18.246 --> 00:14:19.446 A:middle
things that you will build on

00:14:19.446 --> 00:14:21.006 A:middle
top of this in your apps and

00:14:21.006 --> 00:14:21.576 A:middle
frameworks.

00:14:21.916 --> 00:14:23.016 A:middle
With that, let me hand it back

00:14:23.046 --> 00:14:24.756 A:middle
to Michael to recap and cover

00:14:24.756 --> 00:14:26.036 A:middle
some more complex scenarios and

00:14:26.036 --> 00:14:26.976 A:middle
model personalization.

00:14:27.236 --> 00:14:27.586 A:middle
Thank you.

00:14:28.516 --> 00:14:32.500 A:middle
[ Applause ]

00:14:36.526 --> 00:14:37.506 A:middle
&gt;&gt; All right.

00:14:37.586 --> 00:14:38.156 A:middle
Thanks, Anil.

00:14:41.436 --> 00:14:43.476 A:middle
So just a recap, Anil just

00:14:43.476 --> 00:14:44.396 A:middle
showed us, we took our base

00:14:44.396 --> 00:14:46.886 A:middle
model and we tried to make a

00:14:46.886 --> 00:14:48.066 A:middle
personal experience out of that

00:14:48.676 --> 00:14:50.306 A:middle
by supplying some drawings which

00:14:50.396 --> 00:14:52.706 A:middle
were just beautiful to our model

00:14:52.706 --> 00:14:53.566 A:middle
and seeing what we got as an

00:14:53.566 --> 00:14:53.936 A:middle
output.

00:14:54.946 --> 00:14:56.936 A:middle
Initially, we didn't get much.

00:14:58.016 --> 00:14:59.546 A:middle
That's because internally, even

00:14:59.546 --> 00:15:00.446 A:middle
though we have that pretrained

00:14:59.546 --> 00:15:00.446 A:middle
though we have that pretrained

00:15:00.446 --> 00:15:02.216 A:middle
neural network, it feeds into a

00:15:02.216 --> 00:15:02.996 A:middle
K-nearest neighbor base

00:15:02.996 --> 00:15:04.816 A:middle
classifier which is actually

00:15:04.816 --> 00:15:05.146 A:middle
empty.

00:15:05.146 --> 00:15:06.476 A:middle
It has no neighbors to classify

00:15:06.476 --> 00:15:06.596 A:middle
on.

00:15:10.046 --> 00:15:11.156 A:middle
So we actually update this and

00:15:11.156 --> 00:15:11.936 A:middle
give us some neighbors.

00:15:11.936 --> 00:15:13.896 A:middle
Well, as Anil showed us, we took

00:15:13.896 --> 00:15:15.516 A:middle
our training data, the stickers

00:15:15.516 --> 00:15:16.656 A:middle
we chose and the drawings we

00:15:16.656 --> 00:15:17.916 A:middle
drew to correspond with that,

00:15:17.916 --> 00:15:19.896 A:middle
and we feed those along with our

00:15:19.896 --> 00:15:22.186 A:middle
base model, with that updatable

00:15:22.186 --> 00:15:23.256 A:middle
K-nearest neighbor base model in

00:15:23.256 --> 00:15:24.696 A:middle
it to our update task.

00:15:25.966 --> 00:15:27.056 A:middle
And this gives us that new

00:15:27.056 --> 00:15:27.916 A:middle
variant of our model.

00:15:31.046 --> 00:15:32.216 A:middle
And this new variant can more

00:15:32.216 --> 00:15:34.136 A:middle
reliably recognize what it was

00:15:34.136 --> 00:15:36.866 A:middle
trained on while internally the

00:15:36.866 --> 00:15:38.196 A:middle
only thing that's changed was

00:15:38.196 --> 00:15:39.426 A:middle
that updatable K-nearest

00:15:39.426 --> 00:15:43.896 A:middle
neighbor base model.

00:15:44.056 --> 00:15:45.106 A:middle
So let's look at the ML update

00:15:45.106 --> 00:15:45.976 A:middle
task class, which we've

00:15:45.976 --> 00:15:47.576 A:middle
introduced this year to help

00:15:47.576 --> 00:15:48.536 A:middle
with managing these update

00:15:48.566 --> 00:15:49.146 A:middle
processes.

00:15:50.606 --> 00:15:52.066 A:middle
So it has a state associated

00:15:52.066 --> 00:15:53.006 A:middle
with it where it's at in the

00:15:53.006 --> 00:15:54.326 A:middle
process as well as the ability

00:15:54.326 --> 00:15:56.066 A:middle
to resume and cancel that task.

00:15:56.596 --> 00:15:58.566 A:middle
And to construct one you just

00:15:58.566 --> 00:16:00.756 A:middle
pass in that base URL for your

00:15:58.566 --> 00:16:00.756 A:middle
pass in that base URL for your

00:16:00.756 --> 00:16:03.246 A:middle
model along with configuration

00:16:03.416 --> 00:16:05.076 A:middle
and the training data.

00:16:05.656 --> 00:16:07.086 A:middle
And as Anil showed, you need to

00:16:07.086 --> 00:16:08.336 A:middle
pass in a completion handler as

00:16:08.336 --> 00:16:08.556 A:middle
well.

00:16:09.526 --> 00:16:11.096 A:middle
As completion handler, we'll

00:16:11.096 --> 00:16:11.926 A:middle
call when you're done with the

00:16:11.926 --> 00:16:13.106 A:middle
update task and it gives you an

00:16:13.106 --> 00:16:14.046 A:middle
update context.

00:16:14.736 --> 00:16:16.376 A:middle
And you can use this to write

00:16:16.376 --> 00:16:17.426 A:middle
out that model when you're done

00:16:17.426 --> 00:16:19.076 A:middle
with your update, to make

00:16:19.076 --> 00:16:20.746 A:middle
predictions on it, and query

00:16:20.746 --> 00:16:22.006 A:middle
other parts of that task which

00:16:22.006 --> 00:16:23.206 A:middle
allows us to get part of this

00:16:24.126 --> 00:16:26.436 A:middle
update context.

00:16:26.436 --> 00:16:27.616 A:middle
In code, as Anil showed us,

00:16:27.886 --> 00:16:28.696 A:middle
really straightforward to

00:16:28.696 --> 00:16:29.046 A:middle
implement.

00:16:29.746 --> 00:16:31.036 A:middle
You just construct an

00:16:31.036 --> 00:16:33.586 A:middle
MLupdateTask provided that URL,

00:16:33.636 --> 00:16:35.106 A:middle
your configuration, and your

00:16:35.106 --> 00:16:36.636 A:middle
completion handler, which here

00:16:36.636 --> 00:16:38.166 A:middle
we use to check for accuracy,

00:16:38.766 --> 00:16:40.056 A:middle
retain the model outside the

00:16:40.056 --> 00:16:42.266 A:middle
scope of this block and save out

00:16:42.266 --> 00:16:42.606 A:middle
that model.

00:16:43.286 --> 00:16:43.776 A:middle
This is great.

00:16:44.056 --> 00:16:45.556 A:middle
It works really well and it got

00:16:45.556 --> 00:16:46.216 A:middle
us through this demo.

00:16:46.766 --> 00:16:49.096 A:middle
But what about the more complex

00:16:49.096 --> 00:16:49.916 A:middle
use cases, right?

00:16:49.916 --> 00:16:51.146 A:middle
What about neural networks?

00:16:51.686 --> 00:16:53.756 A:middle
Well, a neural network in its

00:16:53.756 --> 00:16:55.066 A:middle
simplest case is just a

00:16:55.066 --> 00:16:57.046 A:middle
collection of layers, each with

00:16:57.096 --> 00:16:58.426 A:middle
some inputs and some weights

00:16:58.776 --> 00:17:00.146 A:middle
that it uses in combination to

00:16:58.776 --> 00:17:00.146 A:middle
that it uses in combination to

00:17:00.146 --> 00:17:02.376 A:middle
create an output.

00:17:02.556 --> 00:17:03.766 A:middle
To adjust that output, we'll

00:17:03.766 --> 00:17:04.836 A:middle
need to adjust the weights in

00:17:04.836 --> 00:17:05.536 A:middle
those layers.

00:17:05.786 --> 00:17:07.036 A:middle
And to do that, we need to mark

00:17:07.036 --> 00:17:08.215 A:middle
these layers as updatable.

00:17:08.726 --> 00:17:11.556 A:middle
And we need some way of telling

00:17:11.556 --> 00:17:12.886 A:middle
it by how much our output was

00:17:12.886 --> 00:17:13.215 A:middle
off.

00:17:13.715 --> 00:17:15.415 A:middle
If we expected a star smiley

00:17:15.415 --> 00:17:17.146 A:middle
face and we got a high five, we

00:17:17.146 --> 00:17:17.915 A:middle
need to correct for that.

00:17:17.915 --> 00:17:18.945 A:middle
And that's going to be done to

00:17:18.945 --> 00:17:20.366 A:middle
our loss functions, which

00:17:20.366 --> 00:17:21.586 A:middle
describes that delta there.

00:17:22.796 --> 00:17:23.816 A:middle
And finally we need to provide

00:17:23.816 --> 00:17:25.026 A:middle
this to our optimizer.

00:17:25.026 --> 00:17:26.536 A:middle
And this takes that loss, our

00:17:26.536 --> 00:17:27.876 A:middle
output, and it figures out by

00:17:27.876 --> 00:17:29.146 A:middle
how much to actually adjust the

00:17:29.146 --> 00:17:30.086 A:middle
weights in these layers.

00:17:30.616 --> 00:17:35.316 A:middle
On Core ML 3, we support

00:17:35.316 --> 00:17:37.406 A:middle
updating of convolution and

00:17:37.406 --> 00:17:38.956 A:middle
fully collect-- fully connected

00:17:38.956 --> 00:17:40.906 A:middle
layers as well as having the

00:17:40.906 --> 00:17:42.016 A:middle
ability to back-propagate

00:17:42.016 --> 00:17:42.606 A:middle
through many more.

00:17:43.166 --> 00:17:44.426 A:middle
And we support categorical

00:17:44.426 --> 00:17:46.256 A:middle
cross-entropy and mean squared

00:17:46.256 --> 00:17:46.986 A:middle
error loss types.

00:17:48.036 --> 00:17:49.436 A:middle
In addition, we support

00:17:49.436 --> 00:17:51.166 A:middle
stochastic gradient descent and

00:17:51.166 --> 00:17:52.646 A:middle
Adam optimization strategies.

00:17:53.166 --> 00:17:56.076 A:middle
This is awesome, right?

00:17:56.516 --> 00:17:58.316 A:middle
But there's other parameters

00:17:58.316 --> 00:17:59.536 A:middle
associated with neural networks,

00:17:59.946 --> 00:18:00.766 A:middle
like learning rate and the

00:17:59.946 --> 00:18:00.766 A:middle
like learning rate and the

00:18:00.766 --> 00:18:01.936 A:middle
number of epoch to run for.

00:18:02.816 --> 00:18:03.556 A:middle
This is all are going to be

00:18:03.556 --> 00:18:05.036 A:middle
encapsulated within that model.

00:18:06.436 --> 00:18:07.796 A:middle
We understand that some of you

00:18:07.796 --> 00:18:08.676 A:middle
may want to change that at

00:18:08.676 --> 00:18:09.746 A:middle
runtime though.

00:18:10.536 --> 00:18:12.126 A:middle
And you can do that.

00:18:12.206 --> 00:18:13.286 A:middle
By overriding the update

00:18:13.316 --> 00:18:14.866 A:middle
parameters dictionary and your

00:18:14.866 --> 00:18:16.476 A:middle
model configuration, you can

00:18:16.476 --> 00:18:17.736 A:middle
override those values within,

00:18:18.606 --> 00:18:20.096 A:middle
using MLParameterKey and just

00:18:20.096 --> 00:18:21.216 A:middle
specifying values for them,

00:18:21.746 --> 00:18:23.406 A:middle
giving you a lot of flexibility

00:18:24.006 --> 00:18:24.096 A:middle
here.

00:18:26.216 --> 00:18:27.936 A:middle
In addition, if you're wondering

00:18:27.936 --> 00:18:28.956 A:middle
what parameters are actually

00:18:28.956 --> 00:18:30.436 A:middle
embedded within my model anyway,

00:18:31.026 --> 00:18:32.136 A:middle
you can check out the parameter

00:18:32.136 --> 00:18:33.716 A:middle
section of that model view in

00:18:33.766 --> 00:18:35.106 A:middle
Xcode and it will give you

00:18:35.106 --> 00:18:36.606 A:middle
details for the values of those

00:18:36.636 --> 00:18:37.826 A:middle
parameters as well as what

00:18:37.826 --> 00:18:39.056 A:middle
parameters are actually defined

00:18:39.056 --> 00:18:39.646 A:middle
within that model.

00:18:43.676 --> 00:18:45.766 A:middle
You may want more flexibility

00:18:45.766 --> 00:18:47.136 A:middle
than the API we showed earlier

00:18:47.776 --> 00:18:48.576 A:middle
and we provide that.

00:18:49.666 --> 00:18:50.986 A:middle
In your MLUpdateTask, you can

00:18:50.986 --> 00:18:51.486 A:middle
provide an

00:18:51.486 --> 00:18:53.896 A:middle
MLupdateProgressHandler instead

00:18:53.896 --> 00:18:55.566 A:middle
of the completion handler and

00:18:55.566 --> 00:18:56.756 A:middle
supply progress handlers and

00:18:56.756 --> 00:18:58.356 A:middle
that completion handler that

00:18:58.356 --> 00:18:59.246 A:middle
will allow you to key in

00:18:59.246 --> 00:19:00.096 A:middle
specific events.

00:18:59.246 --> 00:19:00.096 A:middle
specific events.

00:19:00.176 --> 00:19:01.626 A:middle
So when your training began or

00:19:01.626 --> 00:19:03.896 A:middle
when an epoch ended, we'll call

00:19:03.896 --> 00:19:06.066 A:middle
your progress handler and we'll

00:19:06.066 --> 00:19:07.316 A:middle
provide you that update context

00:19:07.316 --> 00:19:08.536 A:middle
just as we did in the completion

00:19:09.006 --> 00:19:09.236 A:middle
handler.

00:19:10.696 --> 00:19:12.526 A:middle
In addition, we'll tell you what

00:19:12.526 --> 00:19:13.976 A:middle
event caused us to call that

00:19:13.976 --> 00:19:16.176 A:middle
callback as well as giving you

00:19:16.176 --> 00:19:17.416 A:middle
key metrics, so you can query

00:19:17.416 --> 00:19:19.126 A:middle
for your training loss as each

00:19:19.126 --> 00:19:20.446 A:middle
mini batch or each epoch gets

00:19:20.476 --> 00:19:20.936 A:middle
processed.

00:19:21.416 --> 00:19:24.546 A:middle
And in code, still really

00:19:24.546 --> 00:19:25.186 A:middle
straightforward.

00:19:25.536 --> 00:19:26.186 A:middle
You construct this

00:19:26.246 --> 00:19:28.126 A:middle
MLupdateProgressHandler, tell it

00:19:28.126 --> 00:19:29.046 A:middle
what events you're interested

00:19:29.046 --> 00:19:30.596 A:middle
in, and supply a block to be

00:19:30.596 --> 00:19:30.926 A:middle
called.

00:19:31.476 --> 00:19:33.666 A:middle
In addition, you'll just provide

00:19:33.666 --> 00:19:34.656 A:middle
the completion handler there as

00:19:34.656 --> 00:19:37.246 A:middle
well and the MLUpdateTask you

00:19:37.246 --> 00:19:38.696 A:middle
just provide the set of progress

00:19:38.696 --> 00:19:39.086 A:middle
handlers.

00:19:43.276 --> 00:19:44.456 A:middle
So we've talked about how to

00:19:44.456 --> 00:19:45.696 A:middle
update your models and what it

00:19:45.696 --> 00:19:46.556 A:middle
means to update them.

00:19:46.926 --> 00:19:47.746 A:middle
Well, we haven't really

00:19:47.746 --> 00:19:49.446 A:middle
discussed yet so far is when

00:19:49.446 --> 00:19:50.356 A:middle
it's appropriate to do that.

00:19:51.506 --> 00:19:52.446 A:middle
Now, on the grading app we

00:19:52.446 --> 00:19:53.666 A:middle
showed earlier, we're doing it

00:19:54.156 --> 00:19:55.246 A:middle
the second he interacted with

00:19:55.286 --> 00:19:56.756 A:middle
the app and drew a drawing.

00:19:57.126 --> 00:19:58.686 A:middle
And we took that data and sent

00:19:58.686 --> 00:19:59.266 A:middle
it off to the model.

00:19:59.266 --> 00:20:00.976 A:middle
But that may not be appropriate.

00:19:59.266 --> 00:20:00.976 A:middle
But that may not be appropriate.

00:20:01.116 --> 00:20:02.886 A:middle
What if you have thousands or

00:20:02.886 --> 00:20:03.936 A:middle
millions of data points?

00:20:04.946 --> 00:20:05.826 A:middle
And what if your model's

00:20:05.826 --> 00:20:06.896 A:middle
incredibly complicated?

00:20:07.966 --> 00:20:09.406 A:middle
Well, I'm thrilled to say that

00:20:09.406 --> 00:20:10.596 A:middle
using the BackgroundTask

00:20:10.596 --> 00:20:12.876 A:middle
framework will allot several

00:20:12.876 --> 00:20:13.956 A:middle
minutes of runtime to your

00:20:13.956 --> 00:20:14.566 A:middle
application.

00:20:15.076 --> 00:20:16.336 A:middle
Even if the user isn't using

00:20:16.336 --> 00:20:17.566 A:middle
your app or even if they're not

00:20:17.596 --> 00:20:19.636 A:middle
interacting with the device, you

00:20:19.636 --> 00:20:21.666 A:middle
just use the BGTaskScheduler and

00:20:21.666 --> 00:20:23.566 A:middle
make a BGProcessingTaskRequest

00:20:24.046 --> 00:20:24.726 A:middle
and we'll give you several

00:20:24.726 --> 00:20:26.216 A:middle
minutes to do further updates

00:20:26.586 --> 00:20:27.696 A:middle
and further computations.

00:20:29.016 --> 00:20:29.916 A:middle
And to see more about this--

00:20:29.916 --> 00:20:29.983 A:middle
Yeah

00:20:30.516 --> 00:20:33.506 A:middle
[ Applause ]

00:20:34.006 --> 00:20:34.726 A:middle
It's great.

00:20:34.796 --> 00:20:35.846 A:middle
And to see more about this, I

00:20:35.846 --> 00:20:37.746 A:middle
highly recommend you check out

00:20:37.746 --> 00:20:39.046 A:middle
Advances in App Background

00:20:39.046 --> 00:20:39.636 A:middle
Execution.

00:20:42.976 --> 00:20:44.276 A:middle
In addition, how do you get an

00:20:44.276 --> 00:20:44.956 A:middle
updatable model?

00:20:44.956 --> 00:20:46.246 A:middle
Well, as we talked about earlier

00:20:46.246 --> 00:20:47.766 A:middle
in the session, you can get a

00:20:47.766 --> 00:20:49.156 A:middle
model by converting them from a

00:20:49.156 --> 00:20:50.296 A:middle
number of supported training

00:20:50.296 --> 00:20:52.216 A:middle
libraries, that story has not

00:20:52.216 --> 00:20:52.586 A:middle
changed.

00:20:53.986 --> 00:20:55.186 A:middle
You simply pass the respect

00:20:55.186 --> 00:20:56.886 A:middle
trainable flag in when you're

00:20:56.886 --> 00:20:58.616 A:middle
converting your model and it'll

00:20:58.616 --> 00:20:59.986 A:middle
take those trainable parameters

00:20:59.986 --> 00:21:00.636 A:middle
- the things like what

00:20:59.986 --> 00:21:00.636 A:middle
- the things like what

00:21:00.636 --> 00:21:01.936 A:middle
optimization strategy you want,

00:21:02.376 --> 00:21:04.136 A:middle
what layers are updatable -- and

00:21:04.136 --> 00:21:05.366 A:middle
we'll take that and embed that

00:21:05.366 --> 00:21:06.096 A:middle
within your model.

00:21:06.516 --> 00:21:07.336 A:middle
And then the rest of it, it's

00:21:07.336 --> 00:21:08.256 A:middle
just as what it was before.

00:21:08.786 --> 00:21:11.036 A:middle
And for those of you who want to

00:21:11.036 --> 00:21:12.226 A:middle
modify the model itself

00:21:12.226 --> 00:21:13.886 A:middle
directly, that's still fully

00:21:13.886 --> 00:21:17.646 A:middle
supported as well.

00:21:18.056 --> 00:21:19.056 A:middle
So we've talked about how to

00:21:19.056 --> 00:21:20.496 A:middle
make a more personal experience

00:21:20.496 --> 00:21:22.386 A:middle
for a user in your application,

00:21:22.766 --> 00:21:24.066 A:middle
using on-device model

00:21:24.066 --> 00:21:26.376 A:middle
personalization, and you can do

00:21:26.376 --> 00:21:27.366 A:middle
that through our new flexible

00:21:27.366 --> 00:21:28.026 A:middle
yet simple API.

00:21:29.276 --> 00:21:29.716 A:middle
It's great.

00:21:30.046 --> 00:21:30.966 A:middle
You can do this completely

00:21:30.966 --> 00:21:31.546 A:middle
on-device.

00:21:32.206 --> 00:21:34.346 A:middle
And with that, I'd like to hand

00:21:34.346 --> 00:21:35.796 A:middle
it over to my colleague Aseem

00:21:35.796 --> 00:21:36.906 A:middle
Wadhwa to tell you more about

00:21:36.906 --> 00:21:37.906 A:middle
some of the amazing new features

00:21:37.906 --> 00:21:39.226 A:middle
we've added this year for neural

00:21:39.516 --> 00:21:39.976 A:middle
networks.

00:21:40.516 --> 00:21:47.376 A:middle
[ Applause ]

00:21:47.876 --> 00:21:49.566 A:middle
&gt;&gt; OK. So I'm very excited to

00:21:49.566 --> 00:21:52.256 A:middle
talk about what's new in Core ML

00:21:52.256 --> 00:21:53.906 A:middle
this year for neural networks.

00:21:54.676 --> 00:21:57.126 A:middle
But before we jump into that, I

00:21:57.126 --> 00:21:58.946 A:middle
do want to spend a few minutes

00:21:58.976 --> 00:22:01.016 A:middle
talking about neural networks in

00:21:58.976 --> 00:22:01.016 A:middle
talking about neural networks in

00:22:02.096 --> 00:22:02.346 A:middle
general.

00:22:02.866 --> 00:22:04.686 A:middle
Well, we all know that neural

00:22:04.686 --> 00:22:06.816 A:middle
networks are great at solving

00:22:06.816 --> 00:22:08.906 A:middle
challenging task, such as

00:22:08.906 --> 00:22:10.176 A:middle
understanding the content of an

00:22:10.176 --> 00:22:12.786 A:middle
image or a document or an audio

00:22:12.786 --> 00:22:13.096 A:middle
clip.

00:22:14.516 --> 00:22:17.006 A:middle
And we can use this capability

00:22:17.006 --> 00:22:18.436 A:middle
to build some amazing apps

00:22:18.436 --> 00:22:20.806 A:middle
around them.

00:22:21.836 --> 00:22:23.726 A:middle
Now, if you look inside a neural

00:22:23.726 --> 00:22:25.416 A:middle
network and try to see its

00:22:25.416 --> 00:22:27.646 A:middle
structure, we can maybe get a

00:22:27.646 --> 00:22:28.926 A:middle
better understanding about it.

00:22:29.746 --> 00:22:31.666 A:middle
So let's try to do that.

00:22:31.826 --> 00:22:33.176 A:middle
But instead of looking from a

00:22:33.176 --> 00:22:35.066 A:middle
point of view of a researcher,

00:22:35.416 --> 00:22:36.396 A:middle
let's try a different

00:22:36.396 --> 00:22:36.866 A:middle
perspective.

00:22:37.286 --> 00:22:39.276 A:middle
Let's try to look at it from a

00:22:39.636 --> 00:22:40.716 A:middle
programmer's perspective.

00:22:41.316 --> 00:22:43.576 A:middle
So if you visualize inside a

00:22:43.576 --> 00:22:45.966 A:middle
Core ML model, what we see is

00:22:45.966 --> 00:22:47.466 A:middle
something like a graph.

00:22:47.856 --> 00:22:50.056 A:middle
And if you look closely, we

00:22:50.056 --> 00:22:52.286 A:middle
realize that graph is just

00:22:52.286 --> 00:22:54.116 A:middle
another representation of a

00:22:54.116 --> 00:22:54.526 A:middle
program.

00:22:55.386 --> 00:22:57.766 A:middle
Let's look at it again.

00:22:58.446 --> 00:23:00.406 A:middle
So here is a very simple code

00:22:58.446 --> 00:23:00.406 A:middle
So here is a very simple code

00:23:00.406 --> 00:23:02.056 A:middle
snippet that we all understand.

00:23:02.766 --> 00:23:04.456 A:middle
And here is its corresponding

00:23:04.596 --> 00:23:05.536 A:middle
graph representation.

00:23:06.016 --> 00:23:07.806 A:middle
So as you might have noticed

00:23:07.806 --> 00:23:09.356 A:middle
that the operations in the code

00:23:09.736 --> 00:23:11.386 A:middle
have become these notes in the

00:23:11.386 --> 00:23:13.846 A:middle
graph and the readable such as

00:23:13.846 --> 00:23:16.786 A:middle
X, Y, Z, are these edges in the

00:23:16.786 --> 00:23:17.196 A:middle
graph.

00:23:18.026 --> 00:23:19.416 A:middle
Now, if you go back to a neural

00:23:19.416 --> 00:23:22.236 A:middle
network graph and now show a

00:23:22.236 --> 00:23:24.216 A:middle
corresponding code snippet, it

00:23:24.216 --> 00:23:25.616 A:middle
looks pretty similar to what we

00:23:25.616 --> 00:23:26.166 A:middle
had before.

00:23:26.586 --> 00:23:27.856 A:middle
But there are a couple of

00:23:27.886 --> 00:23:32.286 A:middle
differences I want to point out.

00:23:32.326 --> 00:23:35.206 A:middle
One, instead of those simple

00:23:35.396 --> 00:23:37.156 A:middle
numeric variables, we now have

00:23:37.186 --> 00:23:39.236 A:middle
these multidimensional variables

00:23:39.646 --> 00:23:41.096 A:middle
that have couple of attributes.

00:23:41.166 --> 00:23:43.226 A:middle
So it has an attribute called

00:23:43.226 --> 00:23:46.276 A:middle
shape and something called rank,

00:23:46.436 --> 00:23:47.596 A:middle
which is a number of dimensions

00:23:47.596 --> 00:23:48.056 A:middle
that it has.

00:23:48.476 --> 00:23:50.526 A:middle
And the second thing is the

00:23:50.526 --> 00:23:52.246 A:middle
functions operating on these

00:23:52.246 --> 00:23:53.866 A:middle
multidimensional variables are

00:23:53.866 --> 00:23:55.626 A:middle
now these specialized math

00:23:55.626 --> 00:23:57.276 A:middle
functions, which is sometimes

00:23:57.336 --> 00:23:59.236 A:middle
called as layers or operations.

00:24:00.546 --> 00:24:06.646 A:middle
So if you really look at the

00:24:07.406 --> 00:24:09.056 A:middle
neural network, we see that it's

00:24:09.056 --> 00:24:12.206 A:middle
essentially either a graph or a

00:24:12.206 --> 00:24:15.506 A:middle
program that involves these very

00:24:15.506 --> 00:24:17.426 A:middle
large multidimensional variables

00:24:17.746 --> 00:24:19.226 A:middle
and these very heavy

00:24:19.366 --> 00:24:20.336 A:middle
mathematical functions.

00:24:20.656 --> 00:24:21.806 A:middle
So essentially it's a very

00:24:21.806 --> 00:24:23.646 A:middle
compute and memory intensive

00:24:24.006 --> 00:24:24.986 A:middle
program.

00:24:24.986 --> 00:24:27.276 A:middle
And the nice thing about Core ML

00:24:27.276 --> 00:24:30.306 A:middle
is that it encapsulates all

00:24:30.306 --> 00:24:32.236 A:middle
these complexity into a single

00:24:32.236 --> 00:24:34.526 A:middle
file format, which the Core ML

00:24:34.526 --> 00:24:35.796 A:middle
framework and then sort of

00:24:35.796 --> 00:24:37.626 A:middle
optimize and execute very

00:24:37.626 --> 00:24:38.246 A:middle
efficiently.

00:24:39.516 --> 00:24:41.906 A:middle
So if we go back last year and

00:24:41.906 --> 00:24:43.286 A:middle
see what we had in Core ML 2,

00:24:43.286 --> 00:24:45.766 A:middle
well, we could easily represent

00:24:45.956 --> 00:24:47.856 A:middle
straight-line code using acyclic

00:24:47.856 --> 00:24:48.246 A:middle
graphs.

00:24:48.846 --> 00:24:50.976 A:middle
And we had about 40 different

00:24:50.976 --> 00:24:52.526 A:middle
layer types using which we could

00:24:52.526 --> 00:24:54.246 A:middle
represent most of the common

00:24:54.396 --> 00:24:56.436 A:middle
convolutional and recurrent

00:24:56.816 --> 00:24:57.726 A:middle
architectures.

00:24:58.496 --> 00:24:59.666 A:middle
So what's new this year?

00:25:00.356 --> 00:25:02.086 A:middle
Well, as you might have noticed

00:25:02.506 --> 00:25:05.806 A:middle
with my analogy to program, we

00:25:05.806 --> 00:25:07.376 A:middle
all know that code can be much

00:25:07.376 --> 00:25:08.516 A:middle
more complex than simple

00:25:08.516 --> 00:25:09.546 A:middle
straight-line code, right?

00:25:09.886 --> 00:25:12.556 A:middle
For instance, it's quite common

00:25:12.556 --> 00:25:14.996 A:middle
to use a control flow like a

00:25:14.996 --> 00:25:16.946 A:middle
branch as shown in the code

00:25:16.976 --> 00:25:17.636 A:middle
snippet here.

00:25:18.106 --> 00:25:19.966 A:middle
And now, in Core ML 3, what's

00:25:19.966 --> 00:25:21.356 A:middle
new is that we can represent the

00:25:21.446 --> 00:25:23.466 A:middle
same concept of a branch within

00:25:23.466 --> 00:25:24.006 A:middle
the neural network

00:25:24.006 --> 00:25:24.696 A:middle
specification.

00:25:25.516 --> 00:25:30.346 A:middle
[ Applause ]

00:25:30.846 --> 00:25:32.546 A:middle
So another common form of

00:25:32.576 --> 00:25:34.566 A:middle
control flow is obviously loops,

00:25:34.856 --> 00:25:36.356 A:middle
and that too can be really

00:25:36.356 --> 00:25:38.496 A:middle
easily expressed within a Core

00:25:38.496 --> 00:25:39.366 A:middle
ML network.

00:25:40.116 --> 00:25:42.046 A:middle
Moving on to another complex

00:25:42.046 --> 00:25:44.586 A:middle
feature of code, something we do

00:25:44.586 --> 00:25:45.806 A:middle
often when we're writing a

00:25:45.806 --> 00:25:49.026 A:middle
dynamic code is allocate memory

00:25:49.026 --> 00:25:49.646 A:middle
at runtime.

00:25:50.056 --> 00:25:51.356 A:middle
As shown in this code snippet,

00:25:51.356 --> 00:25:52.836 A:middle
we are allocating a memory that

00:25:52.836 --> 00:25:54.466 A:middle
depends on the input of the

00:25:54.466 --> 00:25:56.026 A:middle
program so it can change at

00:25:56.026 --> 00:25:56.406 A:middle
runtime.

00:25:56.856 --> 00:25:58.406 A:middle
Now we can do exactly the same

00:25:58.406 --> 00:26:00.696 A:middle
in Core ML this year using what

00:25:58.406 --> 00:26:00.696 A:middle
in Core ML this year using what

00:26:00.696 --> 00:26:03.796 A:middle
we call dynamic layers, which

00:26:03.796 --> 00:26:05.686 A:middle
allows us to change the shape of

00:26:05.686 --> 00:26:07.116 A:middle
the multi array based on the

00:26:07.116 --> 00:26:08.296 A:middle
input of the graph.

00:26:08.296 --> 00:26:09.486 A:middle
So you might be thinking that

00:26:09.486 --> 00:26:11.476 A:middle
why are we adding sort of these

00:26:11.476 --> 00:26:14.446 A:middle
new complex code constructs

00:26:14.446 --> 00:26:15.896 A:middle
within the Core ML graph, and

00:26:15.896 --> 00:26:17.336 A:middle
the answer is simple, because

00:26:17.476 --> 00:26:18.976 A:middle
neural networks research is

00:26:18.976 --> 00:26:20.986 A:middle
actively exploring these ideas

00:26:21.266 --> 00:26:22.916 A:middle
to make even more powerful

00:26:22.916 --> 00:26:24.006 A:middle
neural networks.

00:26:24.006 --> 00:26:25.546 A:middle
In fact, many state of the art

00:26:25.546 --> 00:26:28.286 A:middle
neural networks sort of-- have

00:26:28.286 --> 00:26:30.036 A:middle
some sort of control flow built

00:26:30.036 --> 00:26:31.346 A:middle
into them.

00:26:31.656 --> 00:26:33.136 A:middle
Another aspect that researchers

00:26:33.486 --> 00:26:36.376 A:middle
are constantly exploring is sort

00:26:36.376 --> 00:26:38.076 A:middle
of new operations.

00:26:38.436 --> 00:26:41.186 A:middle
And for that, we have added lots

00:26:41.186 --> 00:26:43.076 A:middle
of new layers to Core ML this

00:26:43.136 --> 00:26:43.356 A:middle
year.

00:26:43.986 --> 00:26:45.736 A:middle
Not only have we made the

00:26:45.736 --> 00:26:47.606 A:middle
existing layers more generic but

00:26:47.606 --> 00:26:49.756 A:middle
we have added lots of new basic

00:26:49.756 --> 00:26:50.876 A:middle
mathematical operations.

00:26:51.336 --> 00:26:53.186 A:middle
So, if you come across a new

00:26:53.186 --> 00:26:55.046 A:middle
layer, it's highly likely that

00:26:55.046 --> 00:26:56.556 A:middle
it can be expressed in terms of

00:26:56.556 --> 00:26:58.416 A:middle
the layers that are there in

00:26:58.416 --> 00:26:58.976 A:middle
Core ML 3.

00:26:59.516 --> 00:27:06.186 A:middle
[ Applause ]

00:26:59.516 --> 00:27:06.186 A:middle
[ Applause ]

00:27:06.686 --> 00:27:08.646 A:middle
So with all these features of

00:27:08.646 --> 00:27:11.076 A:middle
control flow, dynamic behavior,

00:27:11.076 --> 00:27:13.306 A:middle
and new layers, the Core ML

00:27:13.306 --> 00:27:14.826 A:middle
model has become much more

00:27:14.826 --> 00:27:16.006 A:middle
expressive than before.

00:27:16.586 --> 00:27:18.406 A:middle
And the great part of it is that

00:27:18.776 --> 00:27:20.466 A:middle
most of the popular

00:27:20.466 --> 00:27:21.816 A:middle
architectures out there can now

00:27:21.816 --> 00:27:23.686 A:middle
be easily expressed in the Core

00:27:23.686 --> 00:27:24.176 A:middle
ML format.

00:27:24.766 --> 00:27:26.006 A:middle
So as you can see on this slide,

00:27:26.006 --> 00:27:27.736 A:middle
we have listed a few of those.

00:27:28.066 --> 00:27:29.956 A:middle
And the ones highlighted have

00:27:29.956 --> 00:27:31.996 A:middle
really come in the last few

00:27:31.996 --> 00:27:33.016 A:middle
months and they're really

00:27:33.016 --> 00:27:33.956 A:middle
pushing the boundaries of

00:27:33.956 --> 00:27:34.996 A:middle
machine learning research.

00:27:35.296 --> 00:27:36.976 A:middle
And now you can easily express

00:27:37.026 --> 00:27:39.176 A:middle
them in Core ML and integrate

00:27:39.176 --> 00:27:40.636 A:middle
them in your apps.

00:27:40.756 --> 00:27:41.356 A:middle
So that's great.

00:27:42.516 --> 00:27:47.476 A:middle
[ Applause ]

00:27:47.976 --> 00:27:49.156 A:middle
So now you might be wondering

00:27:49.156 --> 00:27:50.836 A:middle
that how do I make use of these

00:27:51.066 --> 00:27:52.976 A:middle
new features within a Core ML

00:27:53.016 --> 00:27:53.416 A:middle
model.

00:27:53.656 --> 00:27:55.146 A:middle
Well, the answer is same as it

00:27:55.146 --> 00:27:55.876 A:middle
was last year.

00:27:56.326 --> 00:27:58.076 A:middle
There are two options to build a

00:27:58.076 --> 00:27:59.876 A:middle
Core ML model.

00:28:00.326 --> 00:28:02.626 A:middle
One, since Core ML is an open

00:28:02.626 --> 00:28:04.366 A:middle
source Protobuf specification,

00:28:04.746 --> 00:28:06.836 A:middle
we can always specify a model

00:28:06.976 --> 00:28:08.556 A:middle
programmatically using any

00:28:08.556 --> 00:28:09.536 A:middle
programming language of your

00:28:09.536 --> 00:28:09.946 A:middle
choice.

00:28:10.126 --> 00:28:12.026 A:middle
So that option is always

00:28:12.026 --> 00:28:13.066 A:middle
available to us.

00:28:13.506 --> 00:28:14.786 A:middle
But in the majority of the

00:28:14.786 --> 00:28:16.596 A:middle
cases, we like to use converters

00:28:16.666 --> 00:28:18.086 A:middle
that can automatically do that

00:28:18.086 --> 00:28:20.486 A:middle
for us by translating a graph

00:28:20.586 --> 00:28:22.186 A:middle
from a different representation

00:28:22.716 --> 00:28:24.276 A:middle
into the Core ML representation.

00:28:24.656 --> 00:28:25.996 A:middle
So let's look at both of these

00:28:25.996 --> 00:28:27.296 A:middle
approaches a little bit in

00:28:27.296 --> 00:28:27.626 A:middle
detail.

00:28:28.916 --> 00:28:30.876 A:middle
So here I'm showing a simple

00:28:30.976 --> 00:28:33.326 A:middle
neural network and how it can be

00:28:33.326 --> 00:28:35.996 A:middle
easily expressed using Core ML

00:28:35.996 --> 00:28:38.336 A:middle
tools, which is a simple Python

00:28:38.336 --> 00:28:40.096 A:middle
wrapper around the Protobuf

00:28:40.096 --> 00:28:40.776 A:middle
specification.

00:28:41.716 --> 00:28:43.366 A:middle
I personally like this approach,

00:28:43.536 --> 00:28:44.816 A:middle
especially when I'm converting a

00:28:44.816 --> 00:28:46.726 A:middle
model whose architecture I

00:28:46.726 --> 00:28:47.496 A:middle
understand well.

00:28:47.896 --> 00:28:49.616 A:middle
And if I have the pretrained

00:28:49.616 --> 00:28:51.206 A:middle
weights available to me in a

00:28:51.206 --> 00:28:54.166 A:middle
nice data such as numbered

00:28:54.166 --> 00:28:54.656 A:middle
arrays.

00:28:55.316 --> 00:28:57.316 A:middle
Having said that, neural

00:28:57.316 --> 00:28:58.906 A:middle
networks are often much more

00:28:58.906 --> 00:29:01.156 A:middle
complex, and we are better off

00:28:58.906 --> 00:29:01.156 A:middle
complex, and we are better off

00:29:01.296 --> 00:29:03.346 A:middle
using converters and we have a

00:29:03.346 --> 00:29:03.926 A:middle
few of them.

00:29:04.166 --> 00:29:06.256 A:middle
So we have a few converters

00:29:06.256 --> 00:29:08.406 A:middle
available on GitHub using which

00:29:08.406 --> 00:29:10.746 A:middle
you can target most of the

00:29:10.746 --> 00:29:11.906 A:middle
machine learning frameworks out

00:29:11.956 --> 00:29:12.136 A:middle
there.

00:29:12.666 --> 00:29:14.396 A:middle
And the great news is that with

00:29:14.396 --> 00:29:15.736 A:middle
the backing of Core ML 3

00:29:15.736 --> 00:29:17.416 A:middle
specification, all these

00:29:17.416 --> 00:29:19.146 A:middle
converters are getting updated

00:29:19.386 --> 00:29:20.556 A:middle
and much more robust.

00:29:21.316 --> 00:29:23.276 A:middle
So, for some of you who have

00:29:23.276 --> 00:29:24.686 A:middle
used our converters in the past,

00:29:25.186 --> 00:29:26.856 A:middle
you might have come across some

00:29:26.916 --> 00:29:28.666 A:middle
error messages like this, like

00:29:28.846 --> 00:29:29.956 A:middle
maybe it's complaining about a

00:29:29.956 --> 00:29:31.266 A:middle
missing layer or a missing

00:29:31.266 --> 00:29:32.256 A:middle
attribute in the layer.

00:29:33.166 --> 00:29:35.476 A:middle
Now, all of this will go away as

00:29:35.476 --> 00:29:36.986 A:middle
the converters are updated and

00:29:36.986 --> 00:29:39.016 A:middle
they make full use of the Core

00:29:39.016 --> 00:29:39.976 A:middle
ML 3 specification.

00:29:40.516 --> 00:29:46.156 A:middle
[ Applause ]

00:29:46.656 --> 00:29:50.086 A:middle
So, we went through a lot of

00:29:50.086 --> 00:29:50.616 A:middle
slides.

00:29:50.616 --> 00:29:51.756 A:middle
Now it's time to look at the

00:29:51.756 --> 00:29:52.706 A:middle
model in action.

00:29:52.906 --> 00:29:54.026 A:middle
And for that, I'll invite my

00:29:54.026 --> 00:29:54.676 A:middle
friend Allen.

00:29:56.056 --> 00:29:58.056 A:middle
[ Applause ]

00:29:58.136 --> 00:29:58.466 A:middle
&gt;&gt; Thank you.

00:29:59.096 --> 00:30:01.076 A:middle
Thank you, Aseem.

00:29:59.096 --> 00:30:01.076 A:middle
Thank you, Aseem.

00:30:01.836 --> 00:30:03.416 A:middle
Hi. I'm Allen.

00:30:03.786 --> 00:30:05.526 A:middle
Today, I'm going to show you how

00:30:05.526 --> 00:30:07.166 A:middle
to use the new features in Core

00:30:07.166 --> 00:30:09.436 A:middle
ML 3 to bring state of the art

00:30:09.436 --> 00:30:10.606 A:middle
machine learning models for

00:30:10.606 --> 00:30:12.196 A:middle
natural language processing into

00:30:12.196 --> 00:30:12.576 A:middle
our apps.

00:30:15.006 --> 00:30:16.736 A:middle
So, I love reading about

00:30:16.736 --> 00:30:17.126 A:middle
history.

00:30:17.836 --> 00:30:19.176 A:middle
Whenever I come across some

00:30:19.176 --> 00:30:20.276 A:middle
interesting articles about

00:30:20.276 --> 00:30:22.326 A:middle
history, I often have some

00:30:22.326 --> 00:30:23.786 A:middle
questions on top of my head and

00:30:23.786 --> 00:30:25.416 A:middle
I really like to get answers for

00:30:25.416 --> 00:30:25.546 A:middle
that.

00:30:26.316 --> 00:30:27.546 A:middle
But sometimes I'm just

00:30:27.546 --> 00:30:28.026 A:middle
impatient.

00:30:28.416 --> 00:30:29.486 A:middle
I don't want to read through the

00:30:29.486 --> 00:30:30.156 A:middle
entire article.

00:30:30.866 --> 00:30:33.256 A:middle
So, wouldn't it be nice if I can

00:30:33.256 --> 00:30:35.086 A:middle
build an app that scan through

00:30:35.086 --> 00:30:36.826 A:middle
the document and then give the

00:30:36.826 --> 00:30:37.496 A:middle
answers for me?

00:30:38.186 --> 00:30:40.186 A:middle
So then I started out build this

00:30:40.186 --> 00:30:41.746 A:middle
app with the new features in

00:30:41.746 --> 00:30:42.266 A:middle
Core ML 3.

00:30:42.656 --> 00:30:43.286 A:middle
And let me show you.

00:30:51.416 --> 00:30:52.806 A:middle
OK. So, here's my app.

00:30:54.056 --> 00:30:56.266 A:middle
As you can see, it shows article

00:30:56.266 --> 00:30:57.866 A:middle
about history of a company

00:30:57.866 --> 00:30:58.306 A:middle
called NeXT.

00:30:59.226 --> 00:31:01.456 A:middle
So, as you can see, this is a

00:30:59.226 --> 00:31:01.456 A:middle
So, as you can see, this is a

00:31:01.456 --> 00:31:02.976 A:middle
long article, and I certainly

00:31:02.976 --> 00:31:03.946 A:middle
don't have time to go through

00:31:03.946 --> 00:31:04.096 A:middle
it.

00:31:04.096 --> 00:31:05.706 A:middle
And I have some questions about

00:31:05.706 --> 00:31:05.773 A:middle
it.

00:31:06.276 --> 00:31:10.326 A:middle
So let me just ask this app.

00:31:10.586 --> 00:31:12.306 A:middle
Let's try my first question.

00:31:13.416 --> 00:31:16.046 A:middle
Who started NeXT?

00:31:19.076 --> 00:31:20.806 A:middle
&gt;&gt; Steve Jobs.

00:31:21.516 --> 00:31:26.186 A:middle
[ Applause ]

00:31:26.686 --> 00:31:28.666 A:middle
&gt;&gt; OK. I think that's right.

00:31:29.276 --> 00:31:33.966 A:middle
Let me try another one.

00:31:34.176 --> 00:31:35.756 A:middle
Where was the main office

00:31:35.756 --> 00:31:36.406 A:middle
located?

00:31:39.546 --> 00:31:41.536 A:middle
&gt;&gt; Redwood City, California

00:31:42.516 --> 00:31:45.716 A:middle
[ Applause ]

00:31:46.216 --> 00:31:48.036 A:middle
&gt;&gt; Now I also have a question

00:31:48.036 --> 00:31:49.136 A:middle
that I'm very interested in.

00:31:49.556 --> 00:31:50.906 A:middle
Let me try that.

00:31:52.876 --> 00:31:55.086 A:middle
How much were engineers paid?

00:31:58.286 --> 00:31:59.826 A:middle
&gt;&gt; Seventy-five thousand or

00:31:59.826 --> 00:32:02.826 A:middle
$50,000 [applause].

00:31:59.826 --> 00:32:02.826 A:middle
$50,000 [applause].

00:32:03.136 --> 00:32:03.466 A:middle
&gt;&gt; Interesting.

00:32:04.016 --> 00:32:06.000 A:middle
[ Applause ]

00:32:09.436 --> 00:32:11.126 A:middle
So, isn't this cool?

00:32:11.846 --> 00:32:16.886 A:middle
So now, let's get deeper into it

00:32:17.076 --> 00:32:18.176 A:middle
and see what the app really

00:32:18.176 --> 00:32:18.386 A:middle
does.

00:32:20.486 --> 00:32:22.146 A:middle
So, the central piece of this

00:32:22.146 --> 00:32:24.026 A:middle
app is a state of the art

00:32:24.106 --> 00:32:25.596 A:middle
machine learning model called

00:32:25.986 --> 00:32:27.406 A:middle
Bidirectional Encoder

00:32:27.406 --> 00:32:28.566 A:middle
Representation from

00:32:28.566 --> 00:32:29.156 A:middle
Transformers.

00:32:29.666 --> 00:32:30.876 A:middle
And this is a very long name.

00:32:31.236 --> 00:32:32.786 A:middle
So, let's just call it the BERT

00:32:32.786 --> 00:32:34.426 A:middle
model as other researchers do.

00:32:35.216 --> 00:32:37.656 A:middle
So, what does BERT model do?

00:32:38.186 --> 00:32:40.636 A:middle
Well, it is actually a-- it's

00:32:40.776 --> 00:32:42.796 A:middle
actually a neural network that

00:32:42.796 --> 00:32:47.436 A:middle
can perform multiple tasks for

00:32:47.436 --> 00:32:48.846 A:middle
natural language understanding.

00:32:49.466 --> 00:32:52.986 A:middle
But what's inside the BERT

00:32:52.986 --> 00:32:53.326 A:middle
model?

00:32:54.766 --> 00:32:55.536 A:middle
A bunch of modules.

00:32:56.096 --> 00:32:57.466 A:middle
And what's inside these modules?

00:32:58.586 --> 00:33:00.296 A:middle
Layers, many, many layers.

00:32:58.586 --> 00:33:00.296 A:middle
Layers, many, many layers.

00:33:01.316 --> 00:33:02.326 A:middle
So you can see, it's rather

00:33:02.326 --> 00:33:04.476 A:middle
complicated, but with the new

00:33:04.476 --> 00:33:06.106 A:middle
features and tools in Core ML 3,

00:33:06.476 --> 00:33:08.256 A:middle
I can easily bring this model

00:33:08.256 --> 00:33:09.506 A:middle
into my app.

00:33:10.896 --> 00:33:13.996 A:middle
But first, the question is, how

00:33:13.996 --> 00:33:14.676 A:middle
do I get the model?

00:33:15.406 --> 00:33:19.466 A:middle
Well, you can get a model on our

00:33:19.626 --> 00:33:22.976 A:middle
model gallery website, or you

00:33:22.976 --> 00:33:25.296 A:middle
can-- if you like, you can train

00:33:25.296 --> 00:33:26.806 A:middle
a model and then convert it.

00:33:28.016 --> 00:33:30.166 A:middle
For example, the other night I

00:33:30.166 --> 00:33:32.046 A:middle
trained my BERT model with

00:33:32.046 --> 00:33:32.566 A:middle
TensorFlow.

00:33:33.186 --> 00:33:35.336 A:middle
And here is a screenshot of my

00:33:35.486 --> 00:33:35.946 A:middle
workspace.

00:33:36.476 --> 00:33:38.286 A:middle
Sorry for me being very messy

00:33:38.286 --> 00:33:38.986 A:middle
with my workspace.

00:33:39.686 --> 00:33:41.916 A:middle
But to use new Core ML

00:33:42.426 --> 00:33:44.906 A:middle
converter, I just need to export

00:33:44.906 --> 00:33:47.606 A:middle
a model into the Protobuf format

00:33:48.146 --> 00:33:49.696 A:middle
right here.

00:33:50.936 --> 00:33:52.826 A:middle
And after that, all I need to do

00:33:53.086 --> 00:33:54.586 A:middle
is to type three lines of Python

00:33:54.586 --> 00:33:54.826 A:middle
code.

00:33:55.746 --> 00:33:57.436 A:middle
Import TF Core ML converter,

00:33:58.046 --> 00:33:59.086 A:middle
call the convert function, and

00:33:59.736 --> 00:34:02.966 A:middle
then save out as an ML model.

00:33:59.736 --> 00:34:02.966 A:middle
then save out as an ML model.

00:34:03.076 --> 00:34:04.476 A:middle
So as you can see, it's rather

00:34:04.476 --> 00:34:06.336 A:middle
easy to bring a model into the

00:34:06.336 --> 00:34:06.776 A:middle
app.

00:34:07.066 --> 00:34:08.116 A:middle
But to use the app for a

00:34:08.146 --> 00:34:09.735 A:middle
question and answering, there

00:34:09.735 --> 00:34:11.606 A:middle
are few more steps and I like to

00:34:11.606 --> 00:34:12.916 A:middle
explain a little further.

00:34:13.315 --> 00:34:15.795 A:middle
So to use the Q and A model, I

00:34:15.795 --> 00:34:17.916 A:middle
need to prepare a question and a

00:34:17.916 --> 00:34:19.956 A:middle
paragraph and then separate them

00:34:19.956 --> 00:34:20.906 A:middle
as work tokens.

00:34:21.366 --> 00:34:23.485 A:middle
What the model will predict is

00:34:23.596 --> 00:34:26.556 A:middle
the location of the answer

00:34:27.045 --> 00:34:28.146 A:middle
that's in the paragraph.

00:34:28.795 --> 00:34:30.186 A:middle
Think of it as a highlighter as

00:34:30.186 --> 00:34:33.275 A:middle
you just saw in the demo.

00:34:33.436 --> 00:34:34.775 A:middle
So from there, I can start

00:34:34.775 --> 00:34:35.735 A:middle
building up my app.

00:34:36.396 --> 00:34:37.626 A:middle
The model itself does not make

00:34:38.036 --> 00:34:38.706 A:middle
the app.

00:34:39.076 --> 00:34:40.856 A:middle
And in addition to that, I also

00:34:40.856 --> 00:34:43.676 A:middle
utilize many features from other

00:34:43.676 --> 00:34:45.335 A:middle
frameworks that makes this app.

00:34:45.775 --> 00:34:47.516 A:middle
For example, I use the

00:34:47.516 --> 00:34:49.525 A:middle
speech-to-text API from speech

00:34:49.525 --> 00:34:51.966 A:middle
framework to translate my voice

00:34:51.966 --> 00:34:52.516 A:middle
into text.

00:34:53.505 --> 00:34:56.536 A:middle
I use natural language API to

00:34:56.536 --> 00:34:58.066 A:middle
help me build the tokenizer.

00:34:58.756 --> 00:35:01.546 A:middle
And finally, I use the

00:34:58.756 --> 00:35:01.546 A:middle
And finally, I use the

00:35:01.936 --> 00:35:03.186 A:middle
text-to-speech API from the

00:35:03.186 --> 00:35:05.356 A:middle
AVFoundation to play out the

00:35:05.356 --> 00:35:06.266 A:middle
audio of an answer.

00:35:06.966 --> 00:35:08.316 A:middle
So, all these components

00:35:08.576 --> 00:35:09.986 A:middle
utilizes machine learning

00:35:10.046 --> 00:35:12.066 A:middle
on-device, so that to use this

00:35:12.066 --> 00:35:13.946 A:middle
app, no internet access is

00:35:13.946 --> 00:35:14.396 A:middle
required.

00:35:15.516 --> 00:35:17.776 A:middle
[ Applause ]

00:35:18.276 --> 00:35:19.456 A:middle
Thank you.

00:35:19.456 --> 00:35:21.636 A:middle
Just think about how much more

00:35:21.636 --> 00:35:24.126 A:middle
possibility of new ideas and new

00:35:24.246 --> 00:35:25.606 A:middle
user experience you can bring

00:35:25.606 --> 00:35:26.436 A:middle
into our app.

00:35:27.056 --> 00:35:27.646 A:middle
That's all.

00:35:27.646 --> 00:35:27.976 A:middle
Thank you.

00:35:28.516 --> 00:35:35.516 A:middle
[ Applause ]

00:35:36.016 --> 00:35:38.766 A:middle
&gt;&gt; OK. Thank you, Allen.

00:35:40.706 --> 00:35:42.876 A:middle
OK. So before we conclude the

00:35:42.876 --> 00:35:44.266 A:middle
session, I want to highlight

00:35:44.266 --> 00:35:45.416 A:middle
three more features that we

00:35:45.416 --> 00:35:48.096 A:middle
added this year in Core ML that

00:35:48.096 --> 00:35:50.086 A:middle
I'm sure a lot of Core ML users

00:35:50.086 --> 00:35:51.026 A:middle
will find really useful.

00:35:51.766 --> 00:35:56.926 A:middle
So let's look at the first one.

00:35:56.926 --> 00:35:58.876 A:middle
So consider a scenario shown in

00:35:58.876 --> 00:36:00.606 A:middle
the slide, let's say we have two

00:35:58.876 --> 00:36:00.606 A:middle
the slide, let's say we have two

00:36:00.606 --> 00:36:02.886 A:middle
models that classify different

00:36:02.886 --> 00:36:03.796 A:middle
breeds of animal.

00:36:04.516 --> 00:36:06.556 A:middle
And if you look inside, both

00:36:06.556 --> 00:36:09.086 A:middle
these models are pipeline models

00:36:09.586 --> 00:36:10.976 A:middle
that share a common feature

00:36:10.976 --> 00:36:11.456 A:middle
extractor.

00:36:12.136 --> 00:36:13.406 A:middle
Now this happens quite often.

00:36:13.576 --> 00:36:15.976 A:middle
It's quite common to share-- to

00:36:15.976 --> 00:36:18.256 A:middle
train deep neural network to get

00:36:18.256 --> 00:36:20.056 A:middle
features and those features can

00:36:20.056 --> 00:36:21.436 A:middle
be fed to different neural

00:36:21.436 --> 00:36:21.956 A:middle
networks.

00:36:22.816 --> 00:36:25.906 A:middle
So actually in the slide, we

00:36:25.906 --> 00:36:27.876 A:middle
note that we are using multiple

00:36:27.876 --> 00:36:29.736 A:middle
copies of the same model within

00:36:29.736 --> 00:36:30.716 A:middle
these two pipelines.

00:36:31.146 --> 00:36:32.296 A:middle
Now this is clearly not

00:36:32.296 --> 00:36:32.756 A:middle
efficient.

00:36:33.446 --> 00:36:35.036 A:middle
To get rid of this inefficiency,

00:36:35.296 --> 00:36:36.426 A:middle
we are launching a new model

00:36:36.466 --> 00:36:38.596 A:middle
type called linked model, as

00:36:38.596 --> 00:36:38.996 A:middle
shown here.

00:36:38.996 --> 00:36:42.266 A:middle
So just see, the idea is quite

00:36:42.316 --> 00:36:42.696 A:middle
simple.

00:36:43.016 --> 00:36:44.936 A:middle
Linked model is simply a

00:36:44.936 --> 00:36:47.236 A:middle
reference to a model sitting at

00:36:47.236 --> 00:36:47.606 A:middle
desk.

00:36:48.266 --> 00:36:50.376 A:middle
And this really makes it easy to

00:36:50.376 --> 00:36:51.876 A:middle
share a model across different

00:36:52.096 --> 00:36:52.896 A:middle
models.

00:36:54.876 --> 00:36:56.006 A:middle
Another way I like to think

00:36:56.006 --> 00:36:58.146 A:middle
about linked model is it behaves

00:36:58.146 --> 00:36:59.806 A:middle
like linking to a dynamic

00:37:00.126 --> 00:37:01.296 A:middle
library.

00:37:01.686 --> 00:37:03.436 A:middle
And it has only a couple of

00:37:03.436 --> 00:37:04.166 A:middle
parameters.

00:37:04.166 --> 00:37:05.636 A:middle
One, the name of the model that

00:37:05.636 --> 00:37:07.466 A:middle
it's linking to and a search

00:37:07.466 --> 00:37:07.816 A:middle
path.

00:37:08.826 --> 00:37:10.396 A:middle
So this would be very useful

00:37:10.396 --> 00:37:12.126 A:middle
for-- when we are using

00:37:12.126 --> 00:37:13.856 A:middle
updatable models or pipelines.

00:37:14.676 --> 00:37:17.446 A:middle
Let's look at the next feature.

00:37:17.726 --> 00:37:19.296 A:middle
Let's say you have a Core ML

00:37:19.296 --> 00:37:21.206 A:middle
model that takes an image as an

00:37:21.206 --> 00:37:21.586 A:middle
input.

00:37:22.136 --> 00:37:23.776 A:middle
Now as of now, Core ML expects

00:37:23.816 --> 00:37:26.066 A:middle
the image to be in the form of a

00:37:26.066 --> 00:37:27.716 A:middle
CVPixelBuffer.

00:37:27.716 --> 00:37:29.806 A:middle
But what happens if your image

00:37:29.806 --> 00:37:30.786 A:middle
is coming from a different

00:37:30.786 --> 00:37:32.076 A:middle
source and it's in a different

00:37:32.076 --> 00:37:32.516 A:middle
format?

00:37:33.466 --> 00:37:34.706 A:middle
Now, in most of the cases, you

00:37:35.276 --> 00:37:36.996 A:middle
could use the vision framework

00:37:37.276 --> 00:37:39.746 A:middle
so you can invoke Core ML via

00:37:39.746 --> 00:37:41.566 A:middle
the VNCoreMLRequest class.

00:37:42.156 --> 00:37:43.736 A:middle
And this has the advantage that

00:37:43.736 --> 00:37:45.646 A:middle
vision can handle many different

00:37:45.646 --> 00:37:47.686 A:middle
formats of images for us, and

00:37:47.686 --> 00:37:49.526 A:middle
they can also do preprocessing

00:37:49.526 --> 00:37:51.486 A:middle
like image scaling and cropping,

00:37:51.486 --> 00:37:53.016 A:middle
et cetera.

00:37:53.216 --> 00:37:54.796 A:middle
In some cases, though, we might

00:37:54.796 --> 00:37:56.756 A:middle
have to call the Core ML API

00:37:56.756 --> 00:37:58.926 A:middle
directly, for instance when we

00:37:58.926 --> 00:38:01.046 A:middle
are trying to invoke the update

00:37:58.926 --> 00:38:01.046 A:middle
are trying to invoke the update

00:38:01.046 --> 00:38:01.366 A:middle
APIs.

00:38:01.766 --> 00:38:04.146 A:middle
For such cases, we have launched

00:38:04.146 --> 00:38:05.576 A:middle
a couple of new initializer

00:38:05.576 --> 00:38:07.186 A:middle
methods, I showed on the slide.

00:38:07.546 --> 00:38:09.206 A:middle
So now we can directly get an

00:38:09.206 --> 00:38:11.906 A:middle
image from a URL or a CGimage.

00:38:12.516 --> 00:38:17.776 A:middle
[ Applause ]

00:38:18.276 --> 00:38:19.976 A:middle
So this should make it really

00:38:19.976 --> 00:38:21.886 A:middle
convenient to use images with

00:38:21.886 --> 00:38:23.886 A:middle
Core ML.

00:38:24.366 --> 00:38:25.506 A:middle
Moving on to the last feature I

00:38:25.506 --> 00:38:26.896 A:middle
want to highlight.

00:38:26.896 --> 00:38:28.256 A:middle
So there's a class in Core ML

00:38:28.256 --> 00:38:30.486 A:middle
API called MLModelConfiguration.

00:38:30.486 --> 00:38:33.536 A:middle
And it can be used to constrain

00:38:33.536 --> 00:38:35.566 A:middle
the set of devices on which a

00:38:35.566 --> 00:38:36.966 A:middle
Core ML model can execute.

00:38:37.246 --> 00:38:39.476 A:middle
For example, the default value

00:38:39.476 --> 00:38:41.056 A:middle
that the [inaudible] takes is

00:38:41.166 --> 00:38:44.616 A:middle
called all which gives all the

00:38:44.616 --> 00:38:45.736 A:middle
computer devices available

00:38:45.876 --> 00:38:47.326 A:middle
including the neural engine.

00:38:48.136 --> 00:38:49.756 A:middle
Now we have added a couple of

00:38:49.796 --> 00:38:52.026 A:middle
more options to this class.

00:38:52.756 --> 00:38:55.546 A:middle
The first one is the ability to

00:38:55.546 --> 00:38:58.336 A:middle
specify preferred metal device

00:38:59.166 --> 00:39:00.696 A:middle
on which the model can execute.

00:38:59.166 --> 00:39:00.696 A:middle
on which the model can execute.

00:39:01.236 --> 00:39:02.426 A:middle
So as you can imagine, this

00:39:02.426 --> 00:39:03.716 A:middle
would be really useful if you

00:39:03.716 --> 00:39:05.436 A:middle
are running a Core ML model on a

00:39:05.436 --> 00:39:06.846 A:middle
Mac which can have many

00:39:06.846 --> 00:39:09.706 A:middle
different GPUs attached to it.

00:39:10.106 --> 00:39:11.036 A:middle
The other option that we've

00:39:11.036 --> 00:39:13.066 A:middle
added this called low precision

00:39:13.066 --> 00:39:13.776 A:middle
accumulation.

00:39:13.776 --> 00:39:15.996 A:middle
And the idea here is that if

00:39:15.996 --> 00:39:17.576 A:middle
your model is learning on the

00:39:17.576 --> 00:39:19.906 A:middle
GPU, instead of doing

00:39:19.906 --> 00:39:21.766 A:middle
accumulation in float32, that

00:39:21.766 --> 00:39:22.946 A:middle
happens in float60.

00:39:23.296 --> 00:39:25.026 A:middle
Now this can offer some really

00:39:25.026 --> 00:39:27.566 A:middle
nice speed enhancement for your

00:39:27.566 --> 00:39:27.906 A:middle
model.

00:39:28.636 --> 00:39:29.896 A:middle
But whenever we reduce the

00:39:29.896 --> 00:39:31.616 A:middle
precision, always remember to

00:39:31.656 --> 00:39:33.416 A:middle
check the accuracy of the model,

00:39:33.826 --> 00:39:36.056 A:middle
which might degrade or not

00:39:36.056 --> 00:39:37.776 A:middle
degrade, depending on the model

00:39:37.776 --> 00:39:37.936 A:middle
type.

00:39:38.246 --> 00:39:41.436 A:middle
So always try to experiment

00:39:41.436 --> 00:39:43.266 A:middle
whenever you vary the precision

00:39:43.266 --> 00:39:43.726 A:middle
of the model.

00:39:43.866 --> 00:39:45.136 A:middle
So I would highly encourage you

00:39:45.136 --> 00:39:46.676 A:middle
to go and try out this option to

00:39:46.676 --> 00:39:49.706 A:middle
see if it helps with your model.

00:39:50.346 --> 00:39:52.306 A:middle
OK. So, we talked about a lot of

00:39:52.306 --> 00:39:53.276 A:middle
stuff in this session.

00:39:53.276 --> 00:39:55.206 A:middle
Let briefly summarize it for

00:39:55.206 --> 00:39:55.476 A:middle
you.

00:39:55.996 --> 00:39:58.976 A:middle
We discussed how it's really

00:39:58.976 --> 00:40:00.656 A:middle
easy to make a personalized

00:39:58.976 --> 00:40:00.656 A:middle
easy to make a personalized

00:40:00.656 --> 00:40:02.426 A:middle
experience for our users by

00:40:02.426 --> 00:40:03.646 A:middle
updating the Core ML model

00:40:03.736 --> 00:40:04.346 A:middle
on-device.

00:40:05.126 --> 00:40:07.006 A:middle
We discussed how we have added

00:40:07.066 --> 00:40:08.066 A:middle
many more features to our

00:40:08.066 --> 00:40:09.386 A:middle
specification and now we can

00:40:09.386 --> 00:40:11.156 A:middle
bring the state of the art

00:40:11.156 --> 00:40:12.296 A:middle
neural network architectures

00:40:12.646 --> 00:40:14.266 A:middle
into our apps.

00:40:14.266 --> 00:40:15.746 A:middle
And we talk about a few

00:40:16.026 --> 00:40:17.466 A:middle
convenience APIs and options

00:40:17.466 --> 00:40:18.036 A:middle
around GPU.

00:40:18.536 --> 00:40:21.366 A:middle
Here are a few sessions that you

00:40:21.366 --> 00:40:22.796 A:middle
might find interesting and

00:40:22.796 --> 00:40:23.786 A:middle
related to the session.

00:40:24.346 --> 00:40:25.656 A:middle
And thank you.

00:40:26.516 --> 00:40:31.500 A:middle
[ Applause ]
