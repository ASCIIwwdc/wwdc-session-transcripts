WEBVTT

00:00:00.506 --> 00:00:04.500 A:middle
[ Music ]

00:00:07.516 --> 00:00:11.286 A:middle
[ Applause ]

00:00:11.786 --> 00:00:12.636 A:middle
&gt;&gt; Hello and good afternoon

00:00:12.636 --> 00:00:13.076 A:middle
everyone.

00:00:13.546 --> 00:00:14.736 A:middle
Welcome to our session on

00:00:14.736 --> 00:00:15.976 A:middle
Natural Language Processing.

00:00:16.566 --> 00:00:18.266 A:middle
I'm Vivek, and I'll be jointly

00:00:18.266 --> 00:00:19.656 A:middle
presenting this session with my

00:00:19.656 --> 00:00:20.806 A:middle
colleague, Doug Davidson.

00:00:21.646 --> 00:00:23.086 A:middle
Let's get started.

00:00:23.716 --> 00:00:26.076 A:middle
As you know, text is ubiquitous.

00:00:26.836 --> 00:00:27.796 A:middle
You see it everywhere.

00:00:28.436 --> 00:00:29.826 A:middle
If you think of how users

00:00:29.826 --> 00:00:31.256 A:middle
interact with text in apps,

00:00:31.906 --> 00:00:33.286 A:middle
there are two primary modes in

00:00:33.286 --> 00:00:34.796 A:middle
which they interact.

00:00:34.796 --> 00:00:36.376 A:middle
One, is through Natural Language

00:00:36.456 --> 00:00:38.996 A:middle
input, wherein the user is

00:00:39.036 --> 00:00:41.036 A:middle
writing text or generating text

00:00:41.266 --> 00:00:42.296 A:middle
within the application.

00:00:43.176 --> 00:00:44.326 A:middle
For instance, the user may be

00:00:44.326 --> 00:00:46.136 A:middle
typing text on the keyboard

00:00:46.136 --> 00:00:48.266 A:middle
inside the app.

00:00:48.526 --> 00:00:49.996 A:middle
Examples of apps are, for

00:00:49.996 --> 00:00:51.506 A:middle
example, messages where you're

00:00:51.506 --> 00:00:53.566 A:middle
writing text and sharing it with

00:00:53.566 --> 00:00:55.456 A:middle
other people, notes, or any

00:00:55.456 --> 00:00:56.956 A:middle
productivity app where you're

00:00:56.956 --> 00:00:58.156 A:middle
writing text as part of the

00:00:58.156 --> 00:00:58.776 A:middle
application.

00:01:00.246 --> 00:01:01.136 A:middle
The other sort of user

00:01:01.136 --> 00:01:03.126 A:middle
interaction with text in apps is

00:01:03.126 --> 00:01:05.626 A:middle
through Natural Language output

00:01:06.046 --> 00:01:07.696 A:middle
wherein the app presents the

00:01:07.696 --> 00:01:09.126 A:middle
text content to the user, and

00:01:09.286 --> 00:01:11.176 A:middle
the user is consuming or reading

00:01:11.176 --> 00:01:11.706 A:middle
this text.

00:01:12.836 --> 00:01:14.256 A:middle
If you think of an application,

00:01:14.436 --> 00:01:17.346 A:middle
like Apple News, the information

00:01:17.346 --> 00:01:18.466 A:middle
or text is presented to the

00:01:18.466 --> 00:01:20.106 A:middle
user, and the user is reading

00:01:20.106 --> 00:01:20.796 A:middle
this information.

00:01:21.666 --> 00:01:24.116 A:middle
So, both in cases of text input

00:01:24.226 --> 00:01:26.686 A:middle
and text output, in order to

00:01:26.686 --> 00:01:28.366 A:middle
extract actionable intelligence

00:01:28.546 --> 00:01:30.346 A:middle
out of raw text, Natural

00:01:30.346 --> 00:01:31.686 A:middle
Language processing is really

00:01:31.686 --> 00:01:32.146 A:middle
important.

00:01:32.146 --> 00:01:34.816 A:middle
And last year, we introduced the

00:01:34.816 --> 00:01:36.086 A:middle
Natural Language Framework.

00:01:36.796 --> 00:01:38.236 A:middle
The Natural Language Framework

00:01:38.406 --> 00:01:41.016 A:middle
is the NLP workhorse for all

00:01:41.016 --> 00:01:42.346 A:middle
things across all Apple

00:01:42.346 --> 00:01:42.796 A:middle
platforms.

00:01:43.406 --> 00:01:44.476 A:middle
So, we provide several

00:01:44.546 --> 00:01:46.256 A:middle
fundamental NLP building blocks

00:01:46.696 --> 00:01:48.276 A:middle
such as language identification,

00:01:48.276 --> 00:01:49.796 A:middle
tokenization, part of speech

00:01:49.796 --> 00:01:51.666 A:middle
tagging, and so on, and we

00:01:51.666 --> 00:01:53.036 A:middle
present these functionalities

00:01:53.036 --> 00:01:54.846 A:middle
and provide this across several

00:01:54.846 --> 00:01:55.796 A:middle
different languages.

00:01:55.796 --> 00:01:58.456 A:middle
And we do this by seamlessly

00:01:58.456 --> 00:02:00.156 A:middle
blending linguistics and machine

00:01:58.456 --> 00:02:00.156 A:middle
blending linguistics and machine

00:02:00.156 --> 00:02:01.516 A:middle
learning so that you can just

00:02:01.516 --> 00:02:03.356 A:middle
focus on building your apps by

00:02:03.356 --> 00:02:05.526 A:middle
using these APIs, and we do all

00:02:05.526 --> 00:02:07.066 A:middle
of the heavy lifting under the

00:02:07.616 --> 00:02:07.706 A:middle
hood.

00:02:08.336 --> 00:02:09.955 A:middle
Now, if you step back and look

00:02:09.955 --> 00:02:11.306 A:middle
at all of these functionalities,

00:02:11.536 --> 00:02:13.466 A:middle
actually if you look at most NLP

00:02:13.466 --> 00:02:14.936 A:middle
functionalities, they can be

00:02:14.936 --> 00:02:16.676 A:middle
broken down into two broad

00:02:17.006 --> 00:02:19.176 A:middle
categories of tasks.

00:02:19.176 --> 00:02:20.936 A:middle
One is text classification.

00:02:21.066 --> 00:02:22.796 A:middle
And the objective in text

00:02:22.796 --> 00:02:24.866 A:middle
classification is given a piece

00:02:24.866 --> 00:02:26.286 A:middle
of text, and this text can

00:02:26.286 --> 00:02:28.266 A:middle
either be a sentence, can be a

00:02:28.266 --> 00:02:30.256 A:middle
paragraph, or a document, you

00:02:30.256 --> 00:02:31.566 A:middle
would like to assign labels to

00:02:31.566 --> 00:02:33.336 A:middle
this piece of text, and these

00:02:33.336 --> 00:02:35.096 A:middle
labels can be sentiment labels,

00:02:35.096 --> 00:02:36.486 A:middle
topic labels, or any labels that

00:02:36.486 --> 00:02:37.096 A:middle
you want to assign.

00:02:38.426 --> 00:02:40.036 A:middle
The other category of tasks by

00:02:40.036 --> 00:02:41.696 A:middle
NLP is called word tagging.

00:02:41.696 --> 00:02:43.576 A:middle
And the task here or the

00:02:43.576 --> 00:02:45.176 A:middle
objective here is given a

00:02:45.176 --> 00:02:46.756 A:middle
sequence of words or what we

00:02:46.756 --> 00:02:48.606 A:middle
call is tokens, we would like to

00:02:48.606 --> 00:02:50.796 A:middle
assign a label to every token in

00:02:50.796 --> 00:02:51.456 A:middle
this sequence.

00:02:51.656 --> 00:02:54.366 A:middle
And this year, we have exciting

00:02:54.366 --> 00:02:55.986 A:middle
new APIs in both text

00:02:55.986 --> 00:02:57.476 A:middle
classification as well as word

00:02:57.476 --> 00:02:57.776 A:middle
tagging.

00:02:57.776 --> 00:02:59.646 A:middle
Let's start off with the first

00:02:59.646 --> 00:03:00.976 A:middle
one, which is sentiment

00:02:59.646 --> 00:03:00.976 A:middle
one, which is sentiment

00:03:00.976 --> 00:03:01.616 A:middle
analysis.

00:03:02.356 --> 00:03:04.016 A:middle
Sentiment analysis is a text

00:03:04.016 --> 00:03:05.666 A:middle
classification API, this is a

00:03:05.666 --> 00:03:07.946 A:middle
new API, and it works this way.

00:03:08.536 --> 00:03:09.766 A:middle
What you do is you bring your

00:03:09.766 --> 00:03:11.496 A:middle
text, and you pass your text to

00:03:11.496 --> 00:03:14.016 A:middle
this API, and the API analyzes

00:03:14.046 --> 00:03:15.816 A:middle
the text and gives you out a

00:03:15.816 --> 00:03:16.656 A:middle
sentiment score.

00:03:17.466 --> 00:03:18.666 A:middle
Now this sentiment score

00:03:18.786 --> 00:03:20.536 A:middle
captures the degree of sentiment

00:03:20.536 --> 00:03:21.686 A:middle
that is contained in your text.

00:03:22.786 --> 00:03:24.106 A:middle
You provide a sentiment score

00:03:24.106 --> 00:03:26.626 A:middle
from -1 to +1, which indicates

00:03:26.626 --> 00:03:27.516 A:middle
the degree of sentiment.

00:03:28.216 --> 00:03:29.516 A:middle
For instance, if you have -1, it

00:03:29.516 --> 00:03:31.396 A:middle
indicates a very strong negative

00:03:31.396 --> 00:03:33.256 A:middle
sentiment, and +1 indicates a

00:03:33.256 --> 00:03:34.336 A:middle
very positive sentiment.

00:03:34.886 --> 00:03:36.056 A:middle
So, essentially we provide the

00:03:36.056 --> 00:03:37.506 A:middle
score and let you calibrate the

00:03:37.506 --> 00:03:38.846 A:middle
score for your application.

00:03:39.036 --> 00:03:41.356 A:middle
As an example, if you had a

00:03:41.356 --> 00:03:42.836 A:middle
sentence such as we had a fun

00:03:42.836 --> 00:03:44.386 A:middle
time in Hawaii with the family,

00:03:44.586 --> 00:03:45.946 A:middle
the API might give you a score

00:03:45.946 --> 00:03:48.166 A:middle
of 0.8, which shows that this

00:03:48.166 --> 00:03:50.476 A:middle
sentence is a positive sentence.

00:03:51.616 --> 00:03:52.756 A:middle
In contrast, if you had a

00:03:52.796 --> 00:03:54.266 A:middle
sentence such as we had a not so

00:03:54.266 --> 00:03:55.656 A:middle
fun time in Hawaii because mom

00:03:55.656 --> 00:03:57.166 A:middle
twisted her ankle, well that's

00:03:57.166 --> 00:03:59.156 A:middle
not positive, so you get a score

00:03:59.156 --> 00:04:00.956 A:middle
of minus 0.8, and you can

00:03:59.156 --> 00:04:00.956 A:middle
of minus 0.8, and you can

00:04:00.956 --> 00:04:02.446 A:middle
calibrate that to be a negative

00:04:02.446 --> 00:04:02.836 A:middle
sentiment.

00:04:04.126 --> 00:04:05.466 A:middle
This is great; how do you use

00:04:05.466 --> 00:04:05.576 A:middle
it?

00:04:06.376 --> 00:04:07.676 A:middle
It's really simple to use.

00:04:08.006 --> 00:04:09.646 A:middle
So those of you who are used to

00:04:09.646 --> 00:04:11.036 A:middle
using NaturalLanguage, this is

00:04:11.036 --> 00:04:11.886 A:middle
extremely easy.

00:04:12.416 --> 00:04:13.736 A:middle
You import NaturalLanguage.

00:04:14.236 --> 00:04:15.496 A:middle
You create an instance of

00:04:15.536 --> 00:04:17.766 A:middle
NLTagger and all that you do now

00:04:17.836 --> 00:04:19.646 A:middle
is specify a new tag scheme.

00:04:19.786 --> 00:04:21.676 A:middle
And the new tag scheme is called

00:04:21.676 --> 00:04:22.456 A:middle
sentiment score.

00:04:23.266 --> 00:04:25.116 A:middle
Once you do this, you attach the

00:04:25.116 --> 00:04:26.466 A:middle
string that you want to analyze

00:04:26.466 --> 00:04:28.256 A:middle
to the tagger, and you simply

00:04:28.256 --> 00:04:29.576 A:middle
ask for the sentiment score

00:04:29.906 --> 00:04:31.666 A:middle
either at the sentence level or

00:04:31.666 --> 00:04:32.446 A:middle
the paragraph level.

00:04:33.476 --> 00:04:34.996 A:middle
Now let's see this in action.

00:04:36.316 --> 00:04:37.576 A:middle
So what we have here is a

00:04:37.576 --> 00:04:38.516 A:middle
hypothetical app.

00:04:38.876 --> 00:04:40.106 A:middle
It's a cheese application.

00:04:40.596 --> 00:04:42.766 A:middle
And as part of this application,

00:04:42.766 --> 00:04:44.246 A:middle
users can do a bunch of things.

00:04:44.536 --> 00:04:45.726 A:middle
They can write notes about

00:04:45.726 --> 00:04:46.136 A:middle
cheese.

00:04:46.416 --> 00:04:47.946 A:middle
They can write reviews, express

00:04:47.946 --> 00:04:49.016 A:middle
their opinions about different

00:04:49.016 --> 00:04:49.756 A:middle
kinds of cheese.

00:04:50.176 --> 00:04:51.496 A:middle
So, even though this application

00:04:51.496 --> 00:04:53.156 A:middle
is about cheese, there's nothing

00:04:53.156 --> 00:04:53.886 A:middle
cheesy about it.

00:04:53.886 --> 00:04:55.436 A:middle
It really deals with the finer

00:04:55.436 --> 00:04:56.276 A:middle
points of cheese.

00:04:56.656 --> 00:04:57.846 A:middle
And what I'm going to show you

00:04:57.846 --> 00:05:00.646 A:middle
here is a user writing a review,

00:04:57.846 --> 00:05:00.646 A:middle
here is a user writing a review,

00:05:01.066 --> 00:05:03.006 A:middle
and as the user is writing the

00:05:03.006 --> 00:05:05.036 A:middle
review, the text gets passed to

00:05:05.036 --> 00:05:06.286 A:middle
the sentiment classification

00:05:06.286 --> 00:05:09.246 A:middle
API, we get a score, and we

00:05:09.316 --> 00:05:10.746 A:middle
color the text based on the

00:05:10.746 --> 00:05:11.416 A:middle
sentiment score.

00:05:11.726 --> 00:05:13.646 A:middle
So, let's see, if you were to

00:05:13.646 --> 00:05:15.496 A:middle
type something like fantastic

00:05:16.336 --> 00:05:19.016 A:middle
taste, really delicious, you can

00:05:19.016 --> 00:05:19.926 A:middle
see this is a positive

00:05:19.926 --> 00:05:20.386 A:middle
sentiment.

00:05:21.796 --> 00:05:24.886 A:middle
In contrast, if you said great

00:05:24.886 --> 00:05:28.306 A:middle
at first but a horrible

00:05:28.306 --> 00:05:30.296 A:middle
aftertaste, you see that this is

00:05:30.296 --> 00:05:32.006 A:middle
a negative sentiment, right.

00:05:32.276 --> 00:05:33.936 A:middle
And what you also realize here

00:05:33.936 --> 00:05:35.726 A:middle
is all of this can be happening

00:05:35.726 --> 00:05:36.386 A:middle
in real time.

00:05:36.746 --> 00:05:38.046 A:middle
That's because the API is

00:05:38.046 --> 00:05:39.156 A:middle
extremely performing.

00:05:39.556 --> 00:05:41.126 A:middle
It uses a Neural Network model

00:05:41.126 --> 00:05:43.206 A:middle
underneath, and it's hardware

00:05:43.206 --> 00:05:44.516 A:middle
activated across all Apple

00:05:44.516 --> 00:05:46.336 A:middle
platforms, so essentially, you

00:05:46.336 --> 00:05:47.616 A:middle
can do this in real time.

00:05:48.756 --> 00:05:49.846 A:middle
And we support the sentiment

00:05:49.846 --> 00:05:51.936 A:middle
analysis API in seven different

00:05:51.936 --> 00:05:53.966 A:middle
languages, English, French,

00:05:54.016 --> 00:05:55.596 A:middle
Italian, German, Spanish,

00:05:55.636 --> 00:05:57.176 A:middle
Portuguese, and simplified

00:05:57.176 --> 00:05:57.646 A:middle
Chinese.

00:05:58.176 --> 00:05:58.916 A:middle
I think you're really going to

00:05:58.916 --> 00:05:59.436 A:middle
like this.

00:06:00.516 --> 00:06:06.546 A:middle
[ Applause ]

00:06:07.046 --> 00:06:08.126 A:middle
And, of course, all of this is

00:06:08.126 --> 00:06:09.656 A:middle
happening completely on device,

00:06:09.656 --> 00:06:11.026 A:middle
and the user data never has to

00:06:11.026 --> 00:06:11.536 A:middle
leave the device.

00:06:11.896 --> 00:06:13.216 A:middle
We bring all that power on

00:06:13.216 --> 00:06:13.786 A:middle
device to you.

00:06:14.756 --> 00:06:16.306 A:middle
I like to just spend a brief

00:06:16.306 --> 00:06:17.926 A:middle
moment on language assets.

00:06:18.296 --> 00:06:19.746 A:middle
As I mentioned, the NLP

00:06:19.746 --> 00:06:21.246 A:middle
functionalities are quite

00:06:21.896 --> 00:06:23.476 A:middle
diverse, and we provide this in

00:06:23.476 --> 00:06:24.646 A:middle
several different languages.

00:06:25.176 --> 00:06:26.186 A:middle
Now, for users of our

00:06:26.186 --> 00:06:28.006 A:middle
applications, we make sure that

00:06:28.006 --> 00:06:29.986 A:middle
they always have the assets in

00:06:29.986 --> 00:06:31.136 A:middle
the language they're interested

00:06:31.136 --> 00:06:31.286 A:middle
in.

00:06:31.856 --> 00:06:33.316 A:middle
But for you, for development

00:06:33.316 --> 00:06:34.686 A:middle
purposes, you might be

00:06:34.686 --> 00:06:36.546 A:middle
interested in getting assets on

00:06:36.546 --> 00:06:36.846 A:middle
demand.

00:06:36.846 --> 00:06:38.266 A:middle
This is in fact a very common

00:06:38.266 --> 00:06:39.286 A:middle
request that we've heard from

00:06:39.286 --> 00:06:40.716 A:middle
several of you, and we're

00:06:40.716 --> 00:06:42.746 A:middle
introducing a new convenience

00:06:42.746 --> 00:06:44.236 A:middle
API called Request Assets.

00:06:44.686 --> 00:06:46.076 A:middle
So, you can trigger off a

00:06:46.076 --> 00:06:48.336 A:middle
download for a particular asset

00:06:48.576 --> 00:06:49.216 A:middle
on demand.

00:06:49.436 --> 00:06:50.896 A:middle
You just specify the language

00:06:50.896 --> 00:06:51.836 A:middle
and the tag scheme that you're

00:06:51.836 --> 00:06:53.306 A:middle
interested in, and we'll fork

00:06:53.306 --> 00:06:54.076 A:middle
off a download in the

00:06:54.076 --> 00:06:55.186 A:middle
background, and the next

00:06:55.276 --> 00:06:56.476 A:middle
opportune moment you're going to

00:06:56.476 --> 00:06:57.736 A:middle
get the assets on your device.

00:06:57.736 --> 00:06:59.376 A:middle
So, this is really going to help

00:06:59.376 --> 00:07:00.226 A:middle
you with development and

00:06:59.376 --> 00:07:00.226 A:middle
you with development and

00:07:00.226 --> 00:07:01.866 A:middle
increase your productivity as

00:07:01.866 --> 00:07:03.476 A:middle
you're building your apps.

00:07:05.156 --> 00:07:06.366 A:middle
So, we talked about text

00:07:06.366 --> 00:07:07.226 A:middle
classification.

00:07:07.226 --> 00:07:08.616 A:middle
Now let's shift our attention to

00:07:08.616 --> 00:07:09.856 A:middle
Word Tagging.

00:07:10.956 --> 00:07:12.486 A:middle
To just refresh your memory,

00:07:12.486 --> 00:07:14.616 A:middle
Word Tagging is a task where

00:07:14.616 --> 00:07:16.116 A:middle
given a sequence of tokens we'd

00:07:16.116 --> 00:07:17.576 A:middle
like to assign a label to every

00:07:17.576 --> 00:07:18.896 A:middle
single token in the sequence.

00:07:19.086 --> 00:07:21.776 A:middle
As an example here, we could

00:07:21.856 --> 00:07:23.056 A:middle
assign a bunch of tokens

00:07:23.056 --> 00:07:24.246 A:middle
different labels.

00:07:24.376 --> 00:07:25.546 A:middle
Timothy is a person name.

00:07:25.546 --> 00:07:27.326 A:middle
Switzerland is a location, and

00:07:27.326 --> 00:07:28.736 A:middle
we have a bunch of nouns here in

00:07:28.736 --> 00:07:29.366 A:middle
this sentence.

00:07:30.466 --> 00:07:31.226 A:middle
Now, this is great.

00:07:31.226 --> 00:07:32.736 A:middle
If you're just looking to do

00:07:32.736 --> 00:07:34.556 A:middle
named entity recognition using

00:07:34.556 --> 00:07:36.346 A:middle
our APIs or part of speech

00:07:36.346 --> 00:07:37.976 A:middle
tagging using our APIs, this is

00:07:37.976 --> 00:07:39.616 A:middle
fine, but there are several

00:07:39.616 --> 00:07:41.006 A:middle
instances where you want to do

00:07:41.006 --> 00:07:42.386 A:middle
something that's more customized

00:07:42.386 --> 00:07:43.096 A:middle
to your task.

00:07:43.826 --> 00:07:44.736 A:middle
You don't want to know just

00:07:44.736 --> 00:07:46.456 A:middle
Gruyere cheese are two nouns,

00:07:46.816 --> 00:07:48.296 A:middle
but what you want to do is you

00:07:48.296 --> 00:07:49.256 A:middle
want to know that it's Swiss

00:07:49.256 --> 00:07:49.626 A:middle
cheese.

00:07:49.736 --> 00:07:50.426 A:middle
Of course, we are building a

00:07:50.426 --> 00:07:52.106 A:middle
cheese application, you want to

00:07:52.106 --> 00:07:53.136 A:middle
get this information out.

00:07:53.856 --> 00:07:55.626 A:middle
But, the default tagger doesn't

00:07:55.626 --> 00:07:56.696 A:middle
have any information about

00:07:56.756 --> 00:07:57.966 A:middle
cheese, so how are we going to

00:07:57.966 --> 00:07:58.846 A:middle
provide this information?

00:07:59.446 --> 00:08:00.926 A:middle
So, we have a new functionality

00:07:59.446 --> 00:08:00.926 A:middle
So, we have a new functionality

00:08:01.336 --> 00:08:02.526 A:middle
in Natural Language Framework

00:08:02.526 --> 00:08:04.366 A:middle
that we call a Text Catalog.

00:08:05.646 --> 00:08:07.326 A:middle
A Text Catalog is very simple.

00:08:07.866 --> 00:08:09.446 A:middle
What you do is you provide your

00:08:09.446 --> 00:08:11.446 A:middle
custom list, and this can be a

00:08:11.446 --> 00:08:13.036 A:middle
very large list of entities.

00:08:13.276 --> 00:08:14.546 A:middle
For each of the entities in your

00:08:14.546 --> 00:08:15.666 A:middle
list, you have a label.

00:08:16.556 --> 00:08:18.476 A:middle
In practice, these lists can be

00:08:18.476 --> 00:08:20.026 A:middle
millions or even like, you know,

00:08:20.026 --> 00:08:21.046 A:middle
a couple of hundred millions.

00:08:21.856 --> 00:08:23.416 A:middle
What you do is you pass this

00:08:23.676 --> 00:08:25.646 A:middle
sort of a dictionary into Create

00:08:25.646 --> 00:08:27.596 A:middle
ML, create an instance of

00:08:27.596 --> 00:08:29.316 A:middle
MLGazetteer, and Gazetteer is

00:08:29.316 --> 00:08:30.746 A:middle
just a terminology that we use

00:08:31.026 --> 00:08:32.196 A:middle
interchangeably with Text

00:08:32.196 --> 00:08:34.015 A:middle
Catalog, and what you get as an

00:08:34.015 --> 00:08:35.436 A:middle
output is a Text Catalog.

00:08:35.785 --> 00:08:37.145 A:middle
Now, this is an extremely

00:08:37.216 --> 00:08:39.006 A:middle
compressed and efficient form of

00:08:39.006 --> 00:08:40.066 A:middle
the input dictionary that you

00:08:40.066 --> 00:08:40.456 A:middle
provided.

00:08:41.015 --> 00:08:43.736 A:middle
It's very simple to use.

00:08:43.856 --> 00:08:45.056 A:middle
What you do is you provide this

00:08:45.056 --> 00:08:45.486 A:middle
dictionary.

00:08:45.486 --> 00:08:46.956 A:middle
As I mentioned, we can't show

00:08:46.956 --> 00:08:48.066 A:middle
your million entries here.

00:08:48.066 --> 00:08:49.166 A:middle
We're just showing as an example

00:08:49.166 --> 00:08:50.546 A:middle
a few entries, but this can be

00:08:50.546 --> 00:08:52.086 A:middle
an extremely large dictionary.

00:08:53.406 --> 00:08:54.916 A:middle
Once you do that, you can create

00:08:54.916 --> 00:08:56.946 A:middle
an instance of MLGazetteer, pass

00:08:56.946 --> 00:08:58.846 A:middle
the dictionary, and you write it

00:08:58.846 --> 00:08:59.326 A:middle
out to disc.

00:08:59.776 --> 00:09:01.026 A:middle
It looks really innocuous.

00:08:59.776 --> 00:09:01.026 A:middle
It looks really innocuous.

00:09:01.026 --> 00:09:02.386 A:middle
You might be thinking, I'm just

00:09:02.386 --> 00:09:03.386 A:middle
writing a dictionary to disc.

00:09:03.386 --> 00:09:04.236 A:middle
What are you doing here?

00:09:05.176 --> 00:09:06.866 A:middle
Something magical happens when

00:09:06.866 --> 00:09:07.896 A:middle
you make the right call.

00:09:08.516 --> 00:09:10.536 A:middle
Create ML calls Natural Language

00:09:10.596 --> 00:09:12.246 A:middle
under the hood, and Natural

00:09:12.246 --> 00:09:13.916 A:middle
Language takes this very large

00:09:13.956 --> 00:09:15.566 A:middle
dictionary and compresses it

00:09:15.706 --> 00:09:17.306 A:middle
into a bloom filter, which is an

00:09:17.306 --> 00:09:18.286 A:middle
extremely compact

00:09:18.286 --> 00:09:19.946 A:middle
representation, and what you get

00:09:19.946 --> 00:09:21.586 A:middle
as an output is a Text Catalog.

00:09:22.426 --> 00:09:24.046 A:middle
In fact, we've used this to

00:09:24.046 --> 00:09:25.146 A:middle
create effect internally.

00:09:25.146 --> 00:09:27.466 A:middle
We've been able to compress

00:09:27.876 --> 00:09:29.166 A:middle
almost all the person,

00:09:29.166 --> 00:09:30.986 A:middle
organization, and location names

00:09:30.986 --> 00:09:32.536 A:middle
in Wikipedia, which is almost

00:09:32.536 --> 00:09:33.916 A:middle
two and a half million names,

00:09:34.306 --> 00:09:35.726 A:middle
into two megabytes on disc.

00:09:36.136 --> 00:09:39.206 A:middle
Sort of implicitly you've been

00:09:39.206 --> 00:09:40.136 A:middle
using this model.

00:09:40.356 --> 00:09:41.466 A:middle
When you call the named entity

00:09:41.466 --> 00:09:42.476 A:middle
recognition API in

00:09:42.476 --> 00:09:44.306 A:middle
NaturalLanguage, in conjunction

00:09:44.306 --> 00:09:45.386 A:middle
with the statistical model,

00:09:45.386 --> 00:09:47.146 A:middle
you're using this bloom filter

00:09:47.146 --> 00:09:48.636 A:middle
and Gazetteer and now we are

00:09:48.636 --> 00:09:51.816 A:middle
bringing that power to you.

00:09:51.896 --> 00:09:53.906 A:middle
Once you create a Gazetteer or a

00:09:53.906 --> 00:09:55.726 A:middle
Text Catalog, using it is

00:09:55.726 --> 00:09:57.276 A:middle
extremely easy.

00:09:58.116 --> 00:09:59.666 A:middle
You create an instance of

00:09:59.696 --> 00:10:01.376 A:middle
MLGazetteer by specifying the

00:09:59.696 --> 00:10:01.376 A:middle
MLGazetteer by specifying the

00:10:01.376 --> 00:10:03.576 A:middle
path to the Text Catalog that

00:10:03.576 --> 00:10:06.616 A:middle
you just wrote out to disc.

00:10:06.616 --> 00:10:08.036 A:middle
You can work with your favorite

00:10:08.036 --> 00:10:08.706 A:middle
tag scheme here.

00:10:08.706 --> 00:10:09.826 A:middle
It can be lexical class.

00:10:09.826 --> 00:10:11.246 A:middle
It can be name type, any tag

00:10:11.246 --> 00:10:12.836 A:middle
scheme, and you can simply

00:10:12.836 --> 00:10:14.286 A:middle
attach your Gazetteer to this

00:10:14.286 --> 00:10:14.756 A:middle
tag scheme.

00:10:15.636 --> 00:10:17.696 A:middle
Once you do this, every time you

00:10:17.696 --> 00:10:19.456 A:middle
have a piece of text, this

00:10:19.456 --> 00:10:20.976 A:middle
customized Gazetteer is going to

00:10:20.976 --> 00:10:22.736 A:middle
override the default tags that

00:10:22.736 --> 00:10:23.916 A:middle
NaturalLanguage provides.

00:10:25.246 --> 00:10:26.886 A:middle
Consequently, you can customize

00:10:26.886 --> 00:10:27.526 A:middle
your application.

00:10:28.646 --> 00:10:29.456 A:middle
Now, if you go back to the

00:10:29.486 --> 00:10:30.876 A:middle
cheese application, and if you

00:10:30.876 --> 00:10:32.626 A:middle
have a sentence such as lighter

00:10:32.626 --> 00:10:34.196 A:middle
than Camembert or Vacherin, you

00:10:34.196 --> 00:10:36.796 A:middle
can use your Text Catalog for

00:10:36.846 --> 00:10:39.956 A:middle
cheese and identify that one is

00:10:39.956 --> 00:10:41.116 A:middle
a French cheese, and the other

00:10:41.116 --> 00:10:42.596 A:middle
is a Swiss cheese, and you can

00:10:42.596 --> 00:10:44.076 A:middle
perhaps hyperlink it and create

00:10:44.076 --> 00:10:45.586 A:middle
a much more cooler application

00:10:45.586 --> 00:10:46.116 A:middle
out of this.

00:10:46.586 --> 00:10:49.306 A:middle
So that's one way to use Text

00:10:49.306 --> 00:10:51.686 A:middle
Catalog in a word tagger in

00:10:51.686 --> 00:10:52.726 A:middle
NaturalLanguage for this

00:10:52.726 --> 00:10:53.066 A:middle
release.

00:10:53.626 --> 00:10:56.386 A:middle
So we've talked about text

00:10:56.386 --> 00:10:57.246 A:middle
classification.

00:10:57.246 --> 00:10:58.676 A:middle
We've talked about word tagging.

00:10:59.356 --> 00:11:01.086 A:middle
But the field of NLP has moved

00:10:59.356 --> 00:11:01.086 A:middle
But the field of NLP has moved

00:11:01.086 --> 00:11:02.846 A:middle
significantly in the past few

00:11:02.846 --> 00:11:04.676 A:middle
years, and there have been the

00:11:04.676 --> 00:11:06.036 A:middle
without catalysts for this

00:11:06.126 --> 00:11:06.586 A:middle
change.

00:11:07.436 --> 00:11:08.916 A:middle
One is the notion of Word

00:11:08.916 --> 00:11:10.876 A:middle
Embeddings, and Word Embeddings

00:11:10.946 --> 00:11:12.006 A:middle
are nothing but vector

00:11:12.006 --> 00:11:13.206 A:middle
representation of words.

00:11:13.206 --> 00:11:15.876 A:middle
And the other one is the use of

00:11:15.876 --> 00:11:17.986 A:middle
Neural Networks in NLP.

00:11:19.056 --> 00:11:21.056 A:middle
We are delighted to tell you

00:11:21.386 --> 00:11:22.576 A:middle
that we are bringing both these

00:11:22.576 --> 00:11:24.056 A:middle
things to your apps in

00:11:24.056 --> 00:11:25.366 A:middle
NaturalLanguage this year.

00:11:25.946 --> 00:11:28.446 A:middle
So, let's start off with Word

00:11:28.446 --> 00:11:28.956 A:middle
Embeddings.

00:11:29.436 --> 00:11:30.166 A:middle
Thank you.

00:11:31.596 --> 00:11:33.606 A:middle
Before we jump or dive into Word

00:11:33.606 --> 00:11:34.996 A:middle
Embeddings, I'd like to spend a

00:11:34.996 --> 00:11:36.426 A:middle
couple of slides talking about

00:11:36.426 --> 00:11:37.726 A:middle
what an embedding is.

00:11:37.726 --> 00:11:40.336 A:middle
At a conceptual level, embedding

00:11:40.336 --> 00:11:41.896 A:middle
is nothing but a mapping from a

00:11:41.896 --> 00:11:43.946 A:middle
discrete set of objects into a

00:11:43.946 --> 00:11:44.726 A:middle
continuous vector

00:11:44.726 --> 00:11:45.376 A:middle
representation.

00:11:46.046 --> 00:11:47.186 A:middle
So, you have these bunch of

00:11:47.186 --> 00:11:48.026 A:middle
discrete objects.

00:11:48.466 --> 00:11:50.356 A:middle
Each object in this set can be

00:11:50.356 --> 00:11:51.816 A:middle
represented by some sort of a

00:11:51.816 --> 00:11:52.536 A:middle
finite vector.

00:11:52.536 --> 00:11:54.176 A:middle
In this example, we're showing

00:11:54.176 --> 00:11:55.466 A:middle
it with a 3-dimensional vector.

00:11:56.146 --> 00:11:57.096 A:middle
Three dimensions because it's

00:11:57.146 --> 00:11:59.236 A:middle
easy to plot and visualize, but

00:11:59.236 --> 00:12:01.176 A:middle
in reality, these vectors can be

00:11:59.236 --> 00:12:01.176 A:middle
in reality, these vectors can be

00:12:01.176 --> 00:12:02.476 A:middle
of arbitrary dimensions.

00:12:02.786 --> 00:12:04.556 A:middle
You can have 100 dimensions, 300

00:12:04.556 --> 00:12:05.966 A:middle
dimensions, or in some cases

00:12:06.266 --> 00:12:07.656 A:middle
even 1000 dimensional vector.

00:12:08.756 --> 00:12:10.146 A:middle
Now, the neat property about

00:12:10.146 --> 00:12:11.926 A:middle
these embeddings is that when

00:12:11.926 --> 00:12:13.326 A:middle
you plot these embeddings,

00:12:14.176 --> 00:12:15.456 A:middle
objects that are similar

00:12:15.556 --> 00:12:16.896 A:middle
semantically are clustered

00:12:16.896 --> 00:12:17.316 A:middle
together.

00:12:18.446 --> 00:12:19.976 A:middle
So, in this example, if you had

00:12:19.976 --> 00:12:21.306 A:middle
to look at the paint can and the

00:12:21.306 --> 00:12:22.826 A:middle
paint roller, they are clustered

00:12:22.826 --> 00:12:23.246 A:middle
together.

00:12:24.376 --> 00:12:25.716 A:middle
Or, if you had to look at the

00:12:25.716 --> 00:12:27.166 A:middle
sneakers and the high heels,

00:12:27.376 --> 00:12:28.276 A:middle
they are clustered together.

00:12:28.716 --> 00:12:30.206 A:middle
So, this is a very neat property

00:12:30.206 --> 00:12:30.896 A:middle
of embeddings.

00:12:31.096 --> 00:12:33.086 A:middle
And this property of embeddings

00:12:33.086 --> 00:12:34.806 A:middle
is not only proof of words but

00:12:34.806 --> 00:12:36.046 A:middle
actually across several

00:12:36.046 --> 00:12:37.126 A:middle
different modalities.

00:12:37.646 --> 00:12:38.576 A:middle
You can think of image

00:12:38.576 --> 00:12:39.066 A:middle
embeddings.

00:12:39.166 --> 00:12:40.826 A:middle
When you take an image and pass

00:12:40.826 --> 00:12:42.876 A:middle
it through a VGG network or any

00:12:42.876 --> 00:12:43.946 A:middle
sort of a convolution Neural

00:12:43.946 --> 00:12:45.456 A:middle
Network, the feature that you

00:12:45.456 --> 00:12:47.266 A:middle
get as an output is nothing but

00:12:47.266 --> 00:12:48.046 A:middle
an image embedding.

00:12:48.986 --> 00:12:49.836 A:middle
Similarly, you can have

00:12:49.836 --> 00:12:51.696 A:middle
embeddings for words, for

00:12:51.696 --> 00:12:54.016 A:middle
phrases, and when you work with

00:12:54.016 --> 00:12:55.676 A:middle
recommendation systems where

00:12:55.676 --> 00:12:57.136 A:middle
you're working with song titles

00:12:57.136 --> 00:12:58.656 A:middle
or product names, they are

00:12:58.656 --> 00:13:00.076 A:middle
represented by using a vector.

00:12:58.656 --> 00:13:00.076 A:middle
represented by using a vector.

00:13:00.526 --> 00:13:01.456 A:middle
So, they are nothing but just

00:13:01.506 --> 00:13:02.066 A:middle
embeddings.

00:13:02.926 --> 00:13:04.326 A:middle
So, in summary, embedding is

00:13:04.326 --> 00:13:06.506 A:middle
nothing but a mapping from a

00:13:06.506 --> 00:13:08.376 A:middle
string into a continuous

00:13:08.376 --> 00:13:09.996 A:middle
sequence of numbers or a vector

00:13:09.996 --> 00:13:10.556 A:middle
of numbers.

00:13:11.076 --> 00:13:15.026 A:middle
We've actually used these

00:13:15.066 --> 00:13:16.836 A:middle
embeddings very successfully in

00:13:16.836 --> 00:13:18.656 A:middle
iOS 12, and let me tell you how

00:13:18.656 --> 00:13:19.836 A:middle
we use this in Photos.

00:13:21.226 --> 00:13:23.236 A:middle
In Photos search, when you type

00:13:23.316 --> 00:13:24.426 A:middle
a particular term that you're

00:13:24.426 --> 00:13:26.366 A:middle
looking for, maybe pictures of a

00:13:26.416 --> 00:13:28.506 A:middle
thunderstorm, what we do

00:13:28.506 --> 00:13:29.936 A:middle
underneath the hood is all the

00:13:29.936 --> 00:13:31.756 A:middle
images in your photo library are

00:13:31.756 --> 00:13:33.086 A:middle
indexed by using a convolution

00:13:33.086 --> 00:13:33.626 A:middle
Neural Network.

00:13:33.626 --> 00:13:35.106 A:middle
And the output of the

00:13:35.106 --> 00:13:36.466 A:middle
convolution Neural Network is

00:13:36.466 --> 00:13:37.696 A:middle
fixed to some certain number of

00:13:37.696 --> 00:13:39.566 A:middle
classes, perhaps to 1000 classes

00:13:39.566 --> 00:13:40.556 A:middle
or 2000 classes.

00:13:41.426 --> 00:13:42.406 A:middle
Now, if your convolution Neural

00:13:42.406 --> 00:13:43.666 A:middle
Network doesn't know what

00:13:43.666 --> 00:13:45.506 A:middle
thunderstorm is, you will never

00:13:45.506 --> 00:13:46.716 A:middle
find the pictures that were

00:13:46.716 --> 00:13:48.476 A:middle
indexed because they didn't have

00:13:48.476 --> 00:13:50.396 A:middle
the term thunderstorm, but with

00:13:50.396 --> 00:13:52.466 A:middle
the power of Word Embeddings, we

00:13:52.466 --> 00:13:53.646 A:middle
know that thunderstorm is

00:13:53.646 --> 00:13:55.076 A:middle
actually related to sky and

00:13:55.076 --> 00:13:56.986 A:middle
cloudy, and those are labels

00:13:57.876 --> 00:13:58.936 A:middle
that your convolution Neural

00:13:58.936 --> 00:13:59.996 A:middle
Network understands.

00:14:00.386 --> 00:14:02.266 A:middle
So, by doing this, in iOS 12,

00:14:02.266 --> 00:14:04.366 A:middle
you're able to enable fuzzy

00:14:04.366 --> 00:14:06.416 A:middle
search in Photos search by using

00:14:06.416 --> 00:14:07.076 A:middle
Word Embeddings.

00:14:07.706 --> 00:14:09.396 A:middle
So, as a consequence of this,

00:14:09.666 --> 00:14:11.676 A:middle
you can find the images through

00:14:11.676 --> 00:14:12.876 A:middle
the power of Word Embeddings.

00:14:12.876 --> 00:14:14.006 A:middle
In fact, it can be applied to

00:14:14.006 --> 00:14:15.216 A:middle
any search application.

00:14:15.466 --> 00:14:16.716 A:middle
If you want to do fuzzy search

00:14:16.716 --> 00:14:18.226 A:middle
and you have a string, you can

00:14:18.226 --> 00:14:19.426 A:middle
use the Word Embedding to get

00:14:19.426 --> 00:14:20.756 A:middle
neighbors related to that

00:14:20.756 --> 00:14:21.946 A:middle
original word.

00:14:22.656 --> 00:14:24.826 A:middle
Having said that, what can you

00:14:24.826 --> 00:14:25.846 A:middle
do with an embedding?

00:14:26.676 --> 00:14:27.696 A:middle
There are four primary

00:14:27.696 --> 00:14:29.066 A:middle
operations that you can do with

00:14:29.066 --> 00:14:29.716 A:middle
Word Embeddings.

00:14:30.556 --> 00:14:32.486 A:middle
One is, given a word, you can

00:14:32.716 --> 00:14:33.926 A:middle
obviously get the vector for

00:14:33.926 --> 00:14:34.466 A:middle
that word.

00:14:35.576 --> 00:14:37.486 A:middle
Given two words, you can find

00:14:37.486 --> 00:14:38.716 A:middle
the distance between two words

00:14:39.116 --> 00:14:40.356 A:middle
because for each of those words,

00:14:40.356 --> 00:14:41.156 A:middle
you can look at the

00:14:41.156 --> 00:14:42.356 A:middle
corresponding vectors.

00:14:42.616 --> 00:14:44.446 A:middle
So, if I say dog and cat and ask

00:14:44.446 --> 00:14:45.576 A:middle
for the distance, I'm going to

00:14:45.576 --> 00:14:46.816 A:middle
get a distance, and that

00:14:46.816 --> 00:14:47.866 A:middle
distance is going to be pretty

00:14:47.866 --> 00:14:48.996 A:middle
close to each other.

00:14:49.886 --> 00:14:51.976 A:middle
If I say dog and a boot, those

00:14:51.976 --> 00:14:53.706 A:middle
are fairly distant in the

00:14:53.706 --> 00:14:55.246 A:middle
semantic space, and you're going

00:14:55.246 --> 00:14:56.426 A:middle
to get something that's much

00:14:56.606 --> 00:14:57.366 A:middle
higher distance.

00:14:58.546 --> 00:14:59.696 A:middle
The third thing that you can do

00:14:59.696 --> 00:15:01.086 A:middle
is get the nearest neighbors for

00:14:59.696 --> 00:15:01.086 A:middle
is get the nearest neighbors for

00:15:01.086 --> 00:15:02.916 A:middle
a word, and this probably is by

00:15:02.916 --> 00:15:04.676 A:middle
far the most popular way of

00:15:04.676 --> 00:15:06.106 A:middle
using word embeddings, and the

00:15:06.106 --> 00:15:07.516 A:middle
Photos search application that I

00:15:07.516 --> 00:15:08.886 A:middle
just showed you was doing

00:15:08.886 --> 00:15:10.236 A:middle
exactly that.

00:15:10.236 --> 00:15:11.736 A:middle
Given a word, you're looking for

00:15:11.736 --> 00:15:12.936 A:middle
nearest neighbors of a word.

00:15:12.936 --> 00:15:15.836 A:middle
Last but not the least is you

00:15:15.836 --> 00:15:17.056 A:middle
can also get the nearest

00:15:17.246 --> 00:15:19.376 A:middle
neighbors for a vector, so let's

00:15:19.376 --> 00:15:20.776 A:middle
assume that you have a sentence,

00:15:20.836 --> 00:15:22.116 A:middle
and you have multiple words in

00:15:22.116 --> 00:15:23.726 A:middle
the sentence, and for each of

00:15:23.726 --> 00:15:25.176 A:middle
the words in the sentence, you

00:15:25.176 --> 00:15:26.276 A:middle
can get the word embedding, you

00:15:26.326 --> 00:15:27.516 A:middle
can sum it up.

00:15:27.516 --> 00:15:28.886 A:middle
So what you get is a new vector,

00:15:28.886 --> 00:15:31.036 A:middle
and given that vector, you can

00:15:31.036 --> 00:15:32.466 A:middle
ask for all the words that are

00:15:32.466 --> 00:15:33.266 A:middle
close to that vector.

00:15:33.266 --> 00:15:35.046 A:middle
That's a neat way of using Word

00:15:35.046 --> 00:15:35.576 A:middle
Embeddings too.

00:15:35.576 --> 00:15:38.186 A:middle
So a lot of stuff about Word

00:15:38.186 --> 00:15:39.396 A:middle
Embeddings, but the most

00:15:39.396 --> 00:15:40.476 A:middle
important thing is we are

00:15:40.476 --> 00:15:42.436 A:middle
providing this easy for you to

00:15:42.436 --> 00:15:43.786 A:middle
use on the OS.

00:15:44.076 --> 00:15:45.326 A:middle
So, we're delighted to tell you

00:15:45.456 --> 00:15:46.906 A:middle
that these Word Embeddings come

00:15:46.906 --> 00:15:48.396 A:middle
on the OS in seven different

00:15:48.396 --> 00:15:50.206 A:middle
languages for you to use, and

00:15:50.206 --> 00:15:51.426 A:middle
all of the functionalities I

00:15:51.456 --> 00:15:53.366 A:middle
just mentioned, you can use it

00:15:53.496 --> 00:15:54.946 A:middle
with one or two lines of code.

00:15:55.386 --> 00:15:56.686 A:middle
So, we're supporting it in seven

00:15:56.686 --> 00:15:58.406 A:middle
languages from English, Spanish,

00:15:58.406 --> 00:15:59.686 A:middle
French, Italian, German,

00:15:59.766 --> 00:16:01.226 A:middle
Portuguese, and simplified

00:15:59.766 --> 00:16:01.226 A:middle
Portuguese, and simplified

00:16:01.226 --> 00:16:01.706 A:middle
Chinese.

00:16:02.986 --> 00:16:04.146 A:middle
Now, this is great.

00:16:04.146 --> 00:16:05.546 A:middle
The OS embeddings are generally

00:16:05.626 --> 00:16:07.536 A:middle
framed on general corpora, large

00:16:07.536 --> 00:16:09.016 A:middle
amounts of text, billions and

00:16:09.016 --> 00:16:09.866 A:middle
billions of words.

00:16:10.406 --> 00:16:11.936 A:middle
So, they have a general notion

00:16:12.056 --> 00:16:14.126 A:middle
of what a relationship with a

00:16:14.126 --> 00:16:15.156 A:middle
particular word is.

00:16:15.876 --> 00:16:17.226 A:middle
But many a time, you want to do

00:16:17.226 --> 00:16:18.216 A:middle
something that's even more

00:16:18.296 --> 00:16:18.716 A:middle
custom.

00:16:19.846 --> 00:16:21.016 A:middle
So, perhaps you're working with

00:16:21.216 --> 00:16:22.366 A:middle
different sort of domains,

00:16:22.926 --> 00:16:24.206 A:middle
something in the medical domain

00:16:24.206 --> 00:16:25.566 A:middle
or the legal domain or the

00:16:25.566 --> 00:16:26.316 A:middle
financial domain.

00:16:27.046 --> 00:16:28.286 A:middle
So, if your domain is very

00:16:28.286 --> 00:16:30.316 A:middle
different, and the vocabulary of

00:16:30.316 --> 00:16:31.916 A:middle
words that you want to use in

00:16:31.916 --> 00:16:33.076 A:middle
your application is extremely

00:16:33.076 --> 00:16:34.806 A:middle
different, or maybe you just

00:16:34.806 --> 00:16:36.076 A:middle
want to train a word embedding

00:16:36.076 --> 00:16:37.426 A:middle
for a language that's not

00:16:37.426 --> 00:16:39.746 A:middle
supported on the OS, how do you

00:16:39.746 --> 00:16:40.886 A:middle
do that?

00:16:40.886 --> 00:16:41.966 A:middle
We have a provision for that

00:16:42.076 --> 00:16:42.466 A:middle
too.

00:16:43.366 --> 00:16:45.096 A:middle
You can use and bring custom

00:16:45.096 --> 00:16:45.786 A:middle
word embeddings.

00:16:46.506 --> 00:16:47.246 A:middle
So, those of you who are

00:16:47.246 --> 00:16:48.466 A:middle
familiar with word embeddings

00:16:48.466 --> 00:16:50.166 A:middle
and have seen this field evolve,

00:16:50.166 --> 00:16:51.856 A:middle
there are many third-party tools

00:16:51.856 --> 00:16:53.576 A:middle
to train your own embedding such

00:16:53.576 --> 00:16:55.866 A:middle
as word2vec, GloVe, fasttext.

00:16:56.366 --> 00:16:57.906 A:middle
So, you can bring your own text

00:16:58.306 --> 00:16:59.666 A:middle
or you can even use a Custom

00:16:59.666 --> 00:17:01.726 A:middle
Neural Network that you train

00:16:59.666 --> 00:17:01.726 A:middle
Neural Network that you train

00:17:01.726 --> 00:17:01.793 A:middle
in Keras TensorFlow or PyTorch.

00:17:01.793 --> 00:17:04.756 A:middle
So, go from raw data, you can

00:17:04.756 --> 00:17:06.756 A:middle
build your own embeddings, or

00:17:06.756 --> 00:17:07.935 A:middle
you can go to any one of these

00:17:07.935 --> 00:17:09.256 A:middle
websites and download their

00:17:09.256 --> 00:17:10.526 A:middle
pretrained word embeddings.

00:17:11.205 --> 00:17:13.106 A:middle
Now, the challenge there is when

00:17:13.106 --> 00:17:14.185 A:middle
you download any of these

00:17:14.185 --> 00:17:15.425 A:middle
embeddings, they are very, very

00:17:15.425 --> 00:17:15.866 A:middle
large.

00:17:16.256 --> 00:17:17.336 A:middle
They're 1 gigabyte or 2

00:17:17.336 --> 00:17:18.306 A:middle
gigabytes in size.

00:17:18.695 --> 00:17:19.826 A:middle
But you want to use it in your

00:17:19.826 --> 00:17:20.896 A:middle
app in a very compact and

00:17:20.896 --> 00:17:22.945 A:middle
efficient way, and we do just

00:17:23.006 --> 00:17:23.266 A:middle
that.

00:17:23.266 --> 00:17:25.336 A:middle
When you bring these embeddings

00:17:25.606 --> 00:17:26.915 A:middle
from third-party applications

00:17:26.915 --> 00:17:28.406 A:middle
and they're really large, we

00:17:28.406 --> 00:17:30.076 A:middle
automatically compress them into

00:17:30.076 --> 00:17:32.296 A:middle
a very compact format, and once

00:17:32.296 --> 00:17:33.576 A:middle
you have this compact format,

00:17:33.746 --> 00:17:35.446 A:middle
you can use it just like how you

00:17:35.446 --> 00:17:36.716 A:middle
use the OS embeddings.

00:17:37.436 --> 00:17:38.666 A:middle
But to tell you how you use

00:17:38.666 --> 00:17:40.206 A:middle
these embeddings, both the OS as

00:17:40.206 --> 00:17:41.746 A:middle
well as the custom, I'm going to

00:17:41.746 --> 00:17:42.836 A:middle
turn it over to Doug, who is

00:17:42.936 --> 00:17:45.666 A:middle
going to do a demo and then walk

00:17:45.666 --> 00:17:46.426 A:middle
you through the rest of the

00:17:46.426 --> 00:17:46.786 A:middle
session.

00:17:47.426 --> 00:17:48.066 A:middle
Over to you, Doug.

00:17:49.516 --> 00:17:55.836 A:middle
[ Applause ]

00:17:56.336 --> 00:17:57.036 A:middle
&gt;&gt; All right.

00:17:57.036 --> 00:17:58.196 A:middle
So, let's go over to the demo

00:17:58.196 --> 00:18:00.066 A:middle
machine here, and let's see some

00:17:58.196 --> 00:18:00.066 A:middle
machine here, and let's see some

00:18:00.066 --> 00:18:00.976 A:middle
of this in action.

00:18:01.656 --> 00:18:02.986 A:middle
So, the first thing I've done

00:18:02.986 --> 00:18:04.796 A:middle
here is to write a very tiny

00:18:04.796 --> 00:18:06.496 A:middle
demo application that helps us

00:18:06.496 --> 00:18:08.566 A:middle
explore Word Embeddings.

00:18:08.606 --> 00:18:10.456 A:middle
So, I type a word in here, and

00:18:10.456 --> 00:18:11.636 A:middle
it shows us the nearest

00:18:11.636 --> 00:18:13.676 A:middle
neighbor, nearest neighbors of

00:18:13.676 --> 00:18:15.296 A:middle
that word in embedding space.

00:18:15.636 --> 00:18:16.826 A:middle
Let's start by using the

00:18:16.826 --> 00:18:18.976 A:middle
built-in OS Word Embeddings for

00:18:18.976 --> 00:18:19.456 A:middle
English.

00:18:19.806 --> 00:18:21.466 A:middle
So, I type a word like chair,

00:18:21.666 --> 00:18:23.076 A:middle
and we see the nearest neighbors

00:18:23.076 --> 00:18:24.476 A:middle
of chair are words that are

00:18:24.476 --> 00:18:25.886 A:middle
similar in meaning to chair,

00:18:25.886 --> 00:18:28.246 A:middle
sofa, couch, and so forth, or I

00:18:28.246 --> 00:18:29.636 A:middle
could type in something like

00:18:29.716 --> 00:18:31.116 A:middle
bicycle.

00:18:31.796 --> 00:18:33.466 A:middle
And the nearest neighbors, bike

00:18:33.466 --> 00:18:34.666 A:middle
and motorcycle and so forth,

00:18:34.666 --> 00:18:36.166 A:middle
these are words that are close

00:18:36.166 --> 00:18:38.596 A:middle
in meaning to bicycle or maybe

00:18:39.216 --> 00:18:39.596 A:middle
book.

00:18:40.406 --> 00:18:41.256 A:middle
And we get words that are

00:18:41.256 --> 00:18:42.576 A:middle
similar in meaning to book.

00:18:43.026 --> 00:18:44.616 A:middle
So, what we can see from this,

00:18:44.936 --> 00:18:46.746 A:middle
we can understand that the

00:18:46.746 --> 00:18:48.316 A:middle
built-in OS Word Embeddings

00:18:48.716 --> 00:18:50.826 A:middle
represent the ordinary meanings

00:18:50.826 --> 00:18:52.936 A:middle
of words and the language and

00:18:53.006 --> 00:18:54.736 A:middle
recognize the similarity of

00:18:54.776 --> 00:18:57.876 A:middle
meanings as expressed in general

00:18:57.876 --> 00:18:59.206 A:middle
text in that language.

00:19:00.206 --> 00:19:02.596 A:middle
But, of course, what I'm really

00:19:02.596 --> 00:19:04.686 A:middle
interested in here is knowing

00:19:05.066 --> 00:19:06.216 A:middle
what do these embeddings

00:19:06.216 --> 00:19:08.916 A:middle
understand about cheese, because

00:19:08.916 --> 00:19:09.976 A:middle
we're dealing with a cheese

00:19:09.976 --> 00:19:10.726 A:middle
application here.

00:19:11.426 --> 00:19:12.936 A:middle
So, let me type in a cheese

00:19:12.936 --> 00:19:13.246 A:middle
word.

00:19:14.556 --> 00:19:16.156 A:middle
And take a look here, and what I

00:19:16.156 --> 00:19:18.996 A:middle
can see right away is that these

00:19:18.996 --> 00:19:21.446 A:middle
built-in embeddings do know what

00:19:21.446 --> 00:19:23.846 A:middle
cheese is, but I'm very

00:19:23.846 --> 00:19:24.506 A:middle
disappointed.

00:19:24.966 --> 00:19:26.196 A:middle
I can see these embeddings know

00:19:26.196 --> 00:19:27.566 A:middle
nothing about the finer points

00:19:27.566 --> 00:19:28.206 A:middle
of cheese.

00:19:29.406 --> 00:19:31.086 A:middle
Otherwise, they would never have

00:19:31.086 --> 00:19:32.796 A:middle
put these particular cheeses and

00:19:32.796 --> 00:19:34.086 A:middle
cheese-related things together.

00:19:34.086 --> 00:19:35.436 A:middle
They don't go together at all.

00:19:36.236 --> 00:19:37.706 A:middle
What I really want here is

00:19:37.706 --> 00:19:39.136 A:middle
something that understands the

00:19:39.136 --> 00:19:40.486 A:middle
relationships of cheeses.

00:19:40.776 --> 00:19:42.046 A:middle
So, I've taken the opportunity

00:19:42.046 --> 00:19:44.316 A:middle
to train my own custom cheese

00:19:44.316 --> 00:19:46.446 A:middle
embedding that puts cheeses

00:19:46.446 --> 00:19:47.316 A:middle
together based on their

00:19:47.316 --> 00:19:48.016 A:middle
similarity.

00:19:48.936 --> 00:19:50.116 A:middle
And let's switch over to it.

00:19:51.436 --> 00:19:52.616 A:middle
So, here are the neighbors of

00:19:52.616 --> 00:19:54.276 A:middle
cheddar in my own custom cheese

00:19:54.276 --> 00:19:54.716 A:middle
embedding.

00:19:54.966 --> 00:19:55.806 A:middle
This is much better.

00:19:56.586 --> 00:19:57.786 A:middle
We can see that it puts near

00:19:57.786 --> 00:19:59.646 A:middle
cheddar, it puts some fine

00:20:00.216 --> 00:20:01.596 A:middle
cheeses that are similar to

00:20:01.596 --> 00:20:03.446 A:middle
cheddar in texture like our

00:20:03.446 --> 00:20:05.096 A:middle
Lancashires, Double Gloucester,

00:20:05.096 --> 00:20:05.676 A:middle
and Cheshire.

00:20:06.666 --> 00:20:07.826 A:middle
So this is something that we can

00:20:07.826 --> 00:20:09.356 A:middle
use in our cheese application.

00:20:09.946 --> 00:20:10.896 A:middle
So, let's take a look at the

00:20:10.896 --> 00:20:12.886 A:middle
cheese application now.

00:20:15.426 --> 00:20:16.476 A:middle
So, I've been trying out some

00:20:16.476 --> 00:20:17.646 A:middle
ideas for our cheese

00:20:17.646 --> 00:20:18.266 A:middle
application.

00:20:18.266 --> 00:20:20.676 A:middle
Let's see how this looks.

00:20:21.226 --> 00:20:22.276 A:middle
So, when the user types

00:20:22.276 --> 00:20:23.406 A:middle
something in, the first thing

00:20:23.406 --> 00:20:25.486 A:middle
I'm going to do is get a

00:20:25.486 --> 00:20:27.826 A:middle
sentiment score on it to see and

00:20:27.826 --> 00:20:30.066 A:middle
check does this represent a

00:20:30.066 --> 00:20:31.446 A:middle
sentence with a positive

00:20:31.446 --> 00:20:34.146 A:middle
sentiment, and if it does, then

00:20:34.146 --> 00:20:35.436 A:middle
I'm going to go through it using

00:20:35.436 --> 00:20:39.156 A:middle
my tagger using, of course, our

00:20:39.156 --> 00:20:41.776 A:middle
custom cheese Gazetteer to see

00:20:41.776 --> 00:20:43.116 A:middle
whether the user mentioned any

00:20:43.146 --> 00:20:44.656 A:middle
cheeses in it.

00:20:45.356 --> 00:20:47.076 A:middle
And so I'll look for a cheese,

00:20:47.126 --> 00:20:48.826 A:middle
and if the user did mention a

00:20:48.826 --> 00:20:50.736 A:middle
cheese, then I'm going to pass

00:20:50.736 --> 00:20:52.296 A:middle
it through my custom cheese

00:20:52.296 --> 00:20:55.146 A:middle
embedding to find similar

00:20:55.146 --> 00:20:56.366 A:middle
related cheeses.

00:20:57.426 --> 00:20:58.336 A:middle
Sounds plausible?

00:20:58.336 --> 00:21:01.386 A:middle
Let's try it out.

00:20:58.336 --> 00:21:01.386 A:middle
Let's try it out.

00:21:01.656 --> 00:21:02.726 A:middle
Let's bring up our cheese

00:21:02.726 --> 00:21:08.816 A:middle
application, and so I visited

00:21:08.816 --> 00:21:10.136 A:middle
the Netherlands last year, and I

00:21:10.136 --> 00:21:11.796 A:middle
fell in love with Dutch cheeses,

00:21:11.796 --> 00:21:15.826 A:middle
so I'm going to tell my app

00:21:16.636 --> 00:21:16.986 A:middle
that.

00:21:16.986 --> 00:21:19.616 A:middle
So, this is a certainly a

00:21:19.616 --> 00:21:20.686 A:middle
sentence with a positive

00:21:20.686 --> 00:21:22.716 A:middle
sentiment, and it does reference

00:21:22.716 --> 00:21:24.006 A:middle
a particular cheese.

00:21:24.416 --> 00:21:27.586 A:middle
So, I go through, and now my app

00:21:27.876 --> 00:21:29.336 A:middle
can make recommendations of

00:21:29.336 --> 00:21:31.216 A:middle
cheeses that are similar to the

00:21:31.216 --> 00:21:32.296 A:middle
one that I mentioned here.

00:21:33.376 --> 00:21:35.186 A:middle
So, this shows of the power of

00:21:35.226 --> 00:21:36.946 A:middle
Word Embeddings, but even more

00:21:36.946 --> 00:21:39.166 A:middle
than that, it shows how the

00:21:39.166 --> 00:21:40.626 A:middle
natural, various NaturalLanguage

00:21:40.626 --> 00:21:43.566 A:middle
APIs can come together for

00:21:43.566 --> 00:21:44.906 A:middle
application functionality.

00:21:46.516 --> 00:21:50.736 A:middle
[ Applause ]

00:21:51.236 --> 00:21:52.656 A:middle
So, now, let's go back to the

00:21:52.656 --> 00:21:54.976 A:middle
slides, and I want to review

00:21:54.976 --> 00:21:57.496 A:middle
briefly how this looks in API.

00:21:58.466 --> 00:22:00.546 A:middle
So, if you want to use a

00:21:58.466 --> 00:22:00.546 A:middle
So, if you want to use a

00:22:00.666 --> 00:22:02.926 A:middle
built-in OS Word Embedding, it's

00:22:02.926 --> 00:22:03.546 A:middle
very simple.

00:22:03.806 --> 00:22:04.996 A:middle
All you do is ask for it.

00:22:05.206 --> 00:22:06.696 A:middle
Ask for the word embedding for a

00:22:06.696 --> 00:22:07.876 A:middle
particular language, and we'll

00:22:07.876 --> 00:22:08.346 A:middle
give it to you.

00:22:08.346 --> 00:22:10.976 A:middle
Once you have one of these NL

00:22:10.976 --> 00:22:12.766 A:middle
embedding objects, there are

00:22:12.766 --> 00:22:13.936 A:middle
various things you can do with

00:22:13.936 --> 00:22:14.106 A:middle
it.

00:22:14.536 --> 00:22:15.736 A:middle
You can, of course, get the

00:22:15.736 --> 00:22:16.886 A:middle
components, the vector

00:22:16.886 --> 00:22:18.866 A:middle
components, corresponding to any

00:22:18.866 --> 00:22:19.856 A:middle
particular entry.

00:22:21.136 --> 00:22:22.476 A:middle
You can find the distance

00:22:22.476 --> 00:22:24.326 A:middle
between two words, be it short

00:22:24.326 --> 00:22:26.436 A:middle
or far, in embedding space.

00:22:27.346 --> 00:22:28.936 A:middle
And as we saw in our cheese

00:22:28.936 --> 00:22:30.676 A:middle
application, you can go through

00:22:30.676 --> 00:22:32.166 A:middle
and find the nearest neighbors

00:22:32.596 --> 00:22:35.296 A:middle
of any particular item in this

00:22:35.426 --> 00:22:37.186 A:middle
embedding space.

00:22:37.796 --> 00:22:40.436 A:middle
If you want to use a custom word

00:22:40.436 --> 00:22:43.346 A:middle
embedding, then to create it,

00:22:43.346 --> 00:22:46.496 A:middle
you go over to Create ML, and

00:22:46.546 --> 00:22:48.486 A:middle
you need, of course, all of the

00:22:48.486 --> 00:22:50.316 A:middle
vectors that represent your

00:22:50.316 --> 00:22:50.846 A:middle
embedding.

00:22:51.186 --> 00:22:52.596 A:middle
I can't really show them all to

00:22:52.596 --> 00:22:53.986 A:middle
you right here in the slide

00:22:53.986 --> 00:22:55.536 A:middle
because there are 50 or 100

00:22:55.856 --> 00:22:57.736 A:middle
components long, but here's an

00:22:57.736 --> 00:22:59.906 A:middle
example of what they look like.

00:22:59.906 --> 00:23:01.146 A:middle
In practice, you're probably

00:22:59.906 --> 00:23:01.146 A:middle
In practice, you're probably

00:23:01.176 --> 00:23:02.396 A:middle
going to be bringing them in

00:23:02.396 --> 00:23:04.486 A:middle
from a file using the various

00:23:04.486 --> 00:23:06.656 A:middle
Create ML facilities for loading

00:23:06.656 --> 00:23:07.746 A:middle
data from files.

00:23:08.076 --> 00:23:12.476 A:middle
And then you just create a word

00:23:12.476 --> 00:23:15.336 A:middle
embedding object from it and

00:23:15.336 --> 00:23:16.376 A:middle
write it out to disc.

00:23:16.376 --> 00:23:18.056 A:middle
Now, what's going on when you do

00:23:18.056 --> 00:23:18.376 A:middle
this?

00:23:19.036 --> 00:23:22.256 A:middle
Well, in practice, these

00:23:22.256 --> 00:23:23.796 A:middle
embeddings tend to be quite

00:23:23.796 --> 00:23:25.936 A:middle
large, hundreds of dimensions

00:23:25.936 --> 00:23:27.206 A:middle
times thousands of entries.

00:23:27.206 --> 00:23:30.066 A:middle
It could be huge, and they could

00:23:30.066 --> 00:23:32.206 A:middle
take a lot of space on disc,

00:23:32.776 --> 00:23:34.846 A:middle
naively and be expensive to

00:23:34.846 --> 00:23:35.286 A:middle
search.

00:23:35.856 --> 00:23:38.336 A:middle
But when you compile them into

00:23:38.336 --> 00:23:41.416 A:middle
our word embedding object, then

00:23:41.416 --> 00:23:43.836 A:middle
under the hood what we do is we

00:23:43.836 --> 00:23:46.346 A:middle
use a product quantization

00:23:46.346 --> 00:23:47.906 A:middle
technique to achieve a high

00:23:47.906 --> 00:23:50.856 A:middle
degree of compression, and we

00:23:50.856 --> 00:23:53.336 A:middle
add indexes so you can do fast

00:23:53.506 --> 00:23:55.456 A:middle
searching for nearest neighbors,

00:23:55.456 --> 00:23:56.926 A:middle
as you saw in our examples.

00:23:57.606 --> 00:23:59.196 A:middle
Just try this out.

00:23:59.626 --> 00:24:00.926 A:middle
We took some very large

00:23:59.626 --> 00:24:00.926 A:middle
We took some very large

00:24:00.926 --> 00:24:02.766 A:middle
embeddings that are readily

00:24:02.766 --> 00:24:04.256 A:middle
available as open source.

00:24:04.446 --> 00:24:06.456 A:middle
This is some GloVe and fasttext

00:24:06.456 --> 00:24:06.916 A:middle
embeddings.

00:24:06.916 --> 00:24:08.876 A:middle
These are a gigabyte or 2

00:24:08.876 --> 00:24:11.046 A:middle
gigabytes in uncompressed form.

00:24:11.686 --> 00:24:13.956 A:middle
When we put them into our NL

00:24:13.956 --> 00:24:15.606 A:middle
embedding compressed format,

00:24:16.206 --> 00:24:17.736 A:middle
they're only tens of megabytes,

00:24:18.136 --> 00:24:19.086 A:middle
and you can search through them

00:24:19.086 --> 00:24:20.146 A:middle
for nearest neighbors in just a

00:24:20.146 --> 00:24:21.176 A:middle
couple of milliseconds.

00:24:23.056 --> 00:24:23.976 A:middle
Closer to home--

00:24:24.516 --> 00:24:27.716 A:middle
[ Applause ]

00:24:28.216 --> 00:24:30.146 A:middle
For an example, closer to home,

00:24:30.266 --> 00:24:32.406 A:middle
Apple does a lot with podcasts,

00:24:32.536 --> 00:24:34.516 A:middle
so our podcast group, we talked

00:24:34.516 --> 00:24:36.616 A:middle
to them, and they, as it

00:24:36.616 --> 00:24:38.226 A:middle
happens, have an embedding for

00:24:38.226 --> 00:24:40.426 A:middle
podcasts that represents the

00:24:40.426 --> 00:24:42.786 A:middle
similarity of various podcasts,

00:24:42.786 --> 00:24:43.686 A:middle
one to another.

00:24:44.346 --> 00:24:46.196 A:middle
So, we thought we'd try it out

00:24:46.226 --> 00:24:48.186 A:middle
and see what would happen if we

00:24:48.186 --> 00:24:49.886 A:middle
took this embedding and put it

00:24:49.886 --> 00:24:51.826 A:middle
into our NL embedding format.

00:24:52.456 --> 00:24:54.156 A:middle
So this embedding represents

00:24:54.156 --> 00:24:57.466 A:middle
66,000 different podcasts, and

00:24:57.466 --> 00:24:59.486 A:middle
source form is 167 megabytes,

00:24:59.526 --> 00:25:00.906 A:middle
but we compress it down to just

00:24:59.526 --> 00:25:00.906 A:middle
but we compress it down to just

00:25:00.906 --> 00:25:02.976 A:middle
3 megabytes on disc.

00:25:03.326 --> 00:25:05.716 A:middle
So what NL embedding does is it

00:25:05.716 --> 00:25:08.246 A:middle
makes it practical to include

00:25:08.246 --> 00:25:10.376 A:middle
these embeddings and use them on

00:25:11.036 --> 00:25:12.616 A:middle
, on the device, in your

00:25:12.616 --> 00:25:13.236 A:middle
application.

00:25:16.716 --> 00:25:17.276 A:middle
All right.

00:25:17.996 --> 00:25:19.716 A:middle
So, next I want to switch and

00:25:19.716 --> 00:25:22.646 A:middle
talk about another thing that's

00:25:22.646 --> 00:25:24.976 A:middle
related to Word Embeddings, and

00:25:24.976 --> 00:25:26.886 A:middle
that is Transfer Learning for

00:25:26.956 --> 00:25:28.036 A:middle
Text Classification.

00:25:29.356 --> 00:25:31.886 A:middle
So, I'd like to start by talking

00:25:31.886 --> 00:25:33.516 A:middle
a little bit about what we do,

00:25:33.516 --> 00:25:36.806 A:middle
what it is we do when we train a

00:25:36.806 --> 00:25:37.936 A:middle
text classifier.

00:25:39.176 --> 00:25:40.886 A:middle
So, when we're training a text

00:25:40.886 --> 00:25:44.076 A:middle
classifier, we give it a set of

00:25:44.076 --> 00:25:47.096 A:middle
examples for various classes.

00:25:47.636 --> 00:25:50.476 A:middle
You can pass that in to Create

00:25:50.476 --> 00:25:50.826 A:middle
ML.

00:25:50.826 --> 00:25:52.346 A:middle
Create ML will call on Natural

00:25:52.346 --> 00:25:52.946 A:middle
Language.

00:25:53.506 --> 00:25:55.766 A:middle
We will trained a classifier and

00:25:55.876 --> 00:25:58.136 A:middle
out will come a Core ML model.

00:25:58.506 --> 00:26:00.686 A:middle
And what we hope is that these

00:25:58.506 --> 00:26:00.686 A:middle
And what we hope is that these

00:26:00.686 --> 00:26:04.256 A:middle
examples will give sufficient

00:26:04.576 --> 00:26:06.626 A:middle
information about the various

00:26:06.686 --> 00:26:08.546 A:middle
classes that the model can

00:26:08.546 --> 00:26:11.916 A:middle
generalize to classify examples

00:26:11.916 --> 00:26:12.926 A:middle
that it hasn't seen.

00:26:13.406 --> 00:26:15.126 A:middle
And, of course, we have already

00:26:15.366 --> 00:26:17.786 A:middle
shipped this last year, and we

00:26:17.786 --> 00:26:20.566 A:middle
have algorithms for training

00:26:20.566 --> 00:26:23.136 A:middle
these models, most notably our

00:26:23.136 --> 00:26:24.846 A:middle
standard algorithm is what we

00:26:24.846 --> 00:26:26.926 A:middle
call the maxEnt algorithm, based

00:26:26.926 --> 00:26:27.966 A:middle
on logistic compression.

00:26:28.336 --> 00:26:30.266 A:middle
It's very fast, robust, and

00:26:30.266 --> 00:26:30.816 A:middle
effective.

00:26:31.666 --> 00:26:35.126 A:middle
But one thing about it is it

00:26:35.126 --> 00:26:36.876 A:middle
doesn't know anything except

00:26:36.876 --> 00:26:39.076 A:middle
what it learns from the training

00:26:39.076 --> 00:26:41.846 A:middle
data that you give it.

00:26:42.116 --> 00:26:45.566 A:middle
So, you have to make sure that

00:26:45.566 --> 00:26:46.876 A:middle
the training material you give

00:26:46.876 --> 00:26:50.736 A:middle
it covers essentially all of the

00:26:50.736 --> 00:26:52.296 A:middle
sort of things that you expect

00:26:52.296 --> 00:26:55.156 A:middle
to see in examples in practice.

00:26:55.386 --> 00:26:57.336 A:middle
So, in some sense, we've done

00:26:57.336 --> 00:26:58.736 A:middle
the easy part of creating the

00:26:58.736 --> 00:27:00.136 A:middle
algorithm and left you the hard

00:26:58.736 --> 00:27:00.136 A:middle
algorithm and left you the hard

00:27:00.136 --> 00:27:02.276 A:middle
part of producing the training

00:27:02.966 --> 00:27:03.096 A:middle
data.

00:27:03.716 --> 00:27:06.916 A:middle
But, wouldn't it be nice if we

00:27:06.916 --> 00:27:09.216 A:middle
could take advantage of prior

00:27:09.216 --> 00:27:11.386 A:middle
knowledge of the language and

00:27:12.316 --> 00:27:14.736 A:middle
then maybe use that in

00:27:14.766 --> 00:27:16.966 A:middle
conjunction with some smaller

00:27:16.966 --> 00:27:18.526 A:middle
amount of training material that

00:27:18.526 --> 00:27:21.366 A:middle
you have to provide in order to

00:27:21.366 --> 00:27:24.616 A:middle
train a model that would combine

00:27:24.696 --> 00:27:26.886 A:middle
these two and so hopefully

00:27:26.886 --> 00:27:28.736 A:middle
understand more about the

00:27:28.736 --> 00:27:31.176 A:middle
examples it's going to see with

00:27:31.176 --> 00:27:32.496 A:middle
less in the way of training

00:27:32.496 --> 00:27:33.046 A:middle
material.

00:27:34.426 --> 00:27:36.686 A:middle
And so this is the promise of

00:27:36.856 --> 00:27:37.866 A:middle
Transfer Learning.

00:27:38.576 --> 00:27:41.036 A:middle
This is a highly active research

00:27:41.036 --> 00:27:43.876 A:middle
area in NLP, and I'm happy to

00:27:43.876 --> 00:27:45.786 A:middle
say we have a solution for this

00:27:46.136 --> 00:27:47.326 A:middle
that we're delivering now.

00:27:48.286 --> 00:27:50.426 A:middle
Again, NaturalLanguage trains a

00:27:50.426 --> 00:27:52.396 A:middle
model, and the outcome is a Core

00:27:52.396 --> 00:27:52.946 A:middle
ML model.

00:27:53.326 --> 00:27:54.916 A:middle
But how are we going to

00:27:54.916 --> 00:27:56.966 A:middle
incorporate previous knowledge

00:27:56.966 --> 00:27:57.696 A:middle
of the language?

00:27:58.026 --> 00:27:58.886 A:middle
Where are we going to get it?

00:27:59.946 --> 00:28:03.966 A:middle
Well, Word Embeddings provide a

00:27:59.946 --> 00:28:03.966 A:middle
Well, Word Embeddings provide a

00:28:04.006 --> 00:28:05.806 A:middle
great deal of knowledge of the

00:28:05.806 --> 00:28:06.376 A:middle
language.

00:28:06.376 --> 00:28:07.656 A:middle
In particular, they know quite a

00:28:07.656 --> 00:28:10.626 A:middle
bit about the meaning of words.

00:28:11.296 --> 00:28:13.996 A:middle
So, our solution uses Word

00:28:13.996 --> 00:28:16.026 A:middle
Embeddings, takes the training

00:28:16.026 --> 00:28:18.056 A:middle
material you provide, puts them

00:28:18.056 --> 00:28:19.466 A:middle
through the Word Embeddings, and

00:28:19.466 --> 00:28:21.686 A:middle
then on top of that we train a

00:28:21.686 --> 00:28:25.596 A:middle
Neural Network model, and that

00:28:26.096 --> 00:28:27.986 A:middle
is what we provide as a Transfer

00:28:27.986 --> 00:28:30.026 A:middle
Learning Text Classification

00:28:30.026 --> 00:28:30.456 A:middle
model.

00:28:31.556 --> 00:28:32.686 A:middle
Now, there's a lot of work going

00:28:32.686 --> 00:28:34.716 A:middle
on here, but if you want to use

00:28:34.716 --> 00:28:36.786 A:middle
it, all you have to do is ask

00:28:36.786 --> 00:28:37.156 A:middle
for it.

00:28:38.496 --> 00:28:42.416 A:middle
You just change one parameter in

00:28:42.416 --> 00:28:43.566 A:middle
the specification of the

00:28:43.566 --> 00:28:45.436 A:middle
algorithm that you want when

00:28:45.436 --> 00:28:46.516 A:middle
training a Transfer Learning

00:28:46.516 --> 00:28:46.876 A:middle
model.

00:28:47.216 --> 00:28:48.566 A:middle
Now, there are a few different

00:28:48.566 --> 00:28:49.366 A:middle
options here.

00:28:50.056 --> 00:28:52.776 A:middle
So, the first one, most obvious

00:28:52.776 --> 00:28:54.696 A:middle
is, you can use the built-in OS

00:28:54.696 --> 00:28:56.806 A:middle
Word Embeddings that represent

00:28:57.296 --> 00:29:00.486 A:middle
the ordinary meaning of words,

00:28:57.296 --> 00:29:00.486 A:middle
the ordinary meaning of words,

00:29:00.656 --> 00:29:02.696 A:middle
and if you have a custom Word

00:29:02.696 --> 00:29:03.936 A:middle
Embeddings, you could also use

00:29:03.936 --> 00:29:06.106 A:middle
that as well.

00:29:06.306 --> 00:29:10.066 A:middle
We know that a given word can

00:29:10.066 --> 00:29:11.236 A:middle
have very different meanings,

00:29:11.236 --> 00:29:12.456 A:middle
depending on how it appears in

00:29:12.456 --> 00:29:13.586 A:middle
the context of a sentence.

00:29:14.016 --> 00:29:15.316 A:middle
So, for example, Apple in these

00:29:15.316 --> 00:29:16.526 A:middle
two sentences has very different

00:29:16.526 --> 00:29:16.896 A:middle
meanings.

00:29:18.206 --> 00:29:20.586 A:middle
So, what we'd like is to have an

00:29:20.586 --> 00:29:22.356 A:middle
embedding for Transfer Learning

00:29:22.356 --> 00:29:24.766 A:middle
purposes that gives different

00:29:25.386 --> 00:29:28.816 A:middle
values for these words depending

00:29:28.816 --> 00:29:31.226 A:middle
on their meaning and context.

00:29:31.226 --> 00:29:32.366 A:middle
And, of course, an ordinary word

00:29:32.366 --> 00:29:34.966 A:middle
embedding, it just maps words to

00:29:34.966 --> 00:29:37.306 A:middle
vectors, and it will give the

00:29:37.306 --> 00:29:39.036 A:middle
same value for the word no

00:29:39.036 --> 00:29:40.076 A:middle
matter how it appears.

00:29:41.466 --> 00:29:44.876 A:middle
But, what we have done is

00:29:44.876 --> 00:29:46.866 A:middle
trained a specialized embedding

00:29:46.976 --> 00:29:50.356 A:middle
that gives different values for

00:29:50.356 --> 00:29:51.656 A:middle
the words depending on their

00:29:51.656 --> 00:29:52.866 A:middle
meaning and context.

00:29:53.446 --> 00:29:54.886 A:middle
Now, to give you some idea of

00:29:54.886 --> 00:29:56.086 A:middle
how fast the field is moving,

00:29:56.086 --> 00:29:57.456 A:middle
this is something that was just

00:29:57.456 --> 00:30:00.166 A:middle
researched a year ago, and we're

00:29:57.456 --> 00:30:00.166 A:middle
researched a year ago, and we're

00:30:00.166 --> 00:30:03.156 A:middle
delivering it now.

00:30:03.376 --> 00:30:04.796 A:middle
And again, if you want to use

00:30:04.796 --> 00:30:06.546 A:middle
it, you just ask for it.

00:30:07.076 --> 00:30:08.486 A:middle
You specify the dynamic

00:30:08.486 --> 00:30:08.956 A:middle
embedding.

00:30:09.186 --> 00:30:10.426 A:middle
So, the dynamic embedding

00:30:10.956 --> 00:30:13.366 A:middle
changes the value of the

00:30:13.366 --> 00:30:15.106 A:middle
embedding for words depending on

00:30:15.106 --> 00:30:17.766 A:middle
their sentence context, and this

00:30:17.766 --> 00:30:20.016 A:middle
is a very powerful technique for

00:30:20.016 --> 00:30:21.566 A:middle
doing Transfer Learning for Test

00:30:21.566 --> 00:30:22.296 A:middle
Classification.

00:30:23.546 --> 00:30:25.206 A:middle
Well, let's see it.

00:30:27.056 --> 00:30:27.676 A:middle
All right.

00:30:27.906 --> 00:30:30.716 A:middle
So, here what I have is some

00:30:30.716 --> 00:30:32.636 A:middle
fairly standard code for

00:30:32.676 --> 00:30:34.566 A:middle
training a Text Classifier using

00:30:34.566 --> 00:30:37.236 A:middle
Create ML, and what I'm going to

00:30:37.236 --> 00:30:39.056 A:middle
be training, this is based on a

00:30:39.056 --> 00:30:41.326 A:middle
dataset using an Open Source

00:30:41.766 --> 00:30:43.836 A:middle
encyclopedia called DBpedia.

00:30:44.676 --> 00:30:46.486 A:middle
It has short entries about many

00:30:46.486 --> 00:30:47.426 A:middle
different topics.

00:30:47.496 --> 00:30:49.456 A:middle
Some of them are people,

00:30:49.456 --> 00:30:51.096 A:middle
artists, writers, plants,

00:30:51.096 --> 00:30:52.616 A:middle
animals, and so forth, and the

00:30:52.616 --> 00:30:55.146 A:middle
task here is to determine from

00:30:55.146 --> 00:30:56.746 A:middle
the entry what the

00:30:56.876 --> 00:30:59.186 A:middle
classification is, whether it's

00:30:59.186 --> 00:31:01.396 A:middle
a person or writer or artist,

00:30:59.186 --> 00:31:01.396 A:middle
a person or writer or artist,

00:31:01.396 --> 00:31:01.886 A:middle
etc.

00:31:01.956 --> 00:31:04.186 A:middle
And there are 14 different

00:31:04.186 --> 00:31:05.546 A:middle
classes here, and I'm going to

00:31:05.546 --> 00:31:07.036 A:middle
try and train a classifier using

00:31:07.036 --> 00:31:08.406 A:middle
only 200 examples.

00:31:08.906 --> 00:31:11.016 A:middle
So, it's a fairly difficult task

00:31:11.016 --> 00:31:13.766 A:middle
here, and so let's just-- let's

00:31:13.766 --> 00:31:15.656 A:middle
try it with our existing maxEnt

00:31:15.776 --> 00:31:16.236 A:middle
model.

00:31:17.356 --> 00:31:19.006 A:middle
So, I'll fire it off.

00:31:19.436 --> 00:31:21.316 A:middle
It starts, and it's done.

00:31:22.776 --> 00:31:25.296 A:middle
Very fast and easy, and on our

00:31:25.296 --> 00:31:29.026 A:middle
training-- if we take a look at

00:31:29.026 --> 00:31:30.966 A:middle
our performance on our test set,

00:31:31.286 --> 00:31:34.116 A:middle
we see it got 77% accuracy.

00:31:35.116 --> 00:31:39.566 A:middle
That's okay, but can we do

00:31:39.676 --> 00:31:39.796 A:middle
better?

00:31:39.796 --> 00:31:41.756 A:middle
Well, let's make one little

00:31:41.756 --> 00:31:43.926 A:middle
change to our code here.

00:31:44.266 --> 00:31:46.856 A:middle
Instead of using the maxEnt

00:31:46.856 --> 00:31:47.986 A:middle
model, we're going to use the

00:31:47.986 --> 00:31:49.526 A:middle
Transfer Learning with Dynamic

00:31:49.526 --> 00:31:53.266 A:middle
Embeddings, and let's start it.

00:31:54.736 --> 00:31:56.186 A:middle
Now, as I mentioned, this is

00:31:56.186 --> 00:31:57.956 A:middle
training a Neural Network model,

00:31:58.136 --> 00:31:59.526 A:middle
so it takes a little bit longer,

00:32:00.256 --> 00:32:02.606 A:middle
so while it's training, let's

00:32:02.606 --> 00:32:04.286 A:middle
just take a little closer look

00:32:04.326 --> 00:32:05.596 A:middle
at the data that we're training

00:32:05.596 --> 00:32:05.916 A:middle
on.

00:32:06.326 --> 00:32:08.196 A:middle
As it turns out, when you're

00:32:08.196 --> 00:32:09.646 A:middle
training Neural Network models,

00:32:09.916 --> 00:32:11.556 A:middle
it's important to pay close

00:32:11.556 --> 00:32:13.616 A:middle
attention to the data that you

00:32:13.616 --> 00:32:14.216 A:middle
train it on.

00:32:14.596 --> 00:32:17.166 A:middle
So, notice that this data is a

00:32:17.276 --> 00:32:19.386 A:middle
random sample across the various

00:32:19.386 --> 00:32:22.646 A:middle
classes, and I've arranged it so

00:32:22.646 --> 00:32:23.846 A:middle
that they're roughly the same

00:32:23.846 --> 00:32:25.996 A:middle
number of instances for each

00:32:26.046 --> 00:32:26.676 A:middle
class.

00:32:27.186 --> 00:32:28.346 A:middle
It's a balanced set.

00:32:29.366 --> 00:32:30.626 A:middle
This is our training set.

00:32:30.626 --> 00:32:31.926 A:middle
In addition, we also have a

00:32:31.926 --> 00:32:34.146 A:middle
separate validation set that is

00:32:34.146 --> 00:32:36.226 A:middle
similarly a random sampling of

00:32:36.226 --> 00:32:38.546 A:middle
examples across classes, maybe

00:32:38.546 --> 00:32:39.756 A:middle
not quite as large as the

00:32:39.756 --> 00:32:41.296 A:middle
training set, but balanced.

00:32:41.986 --> 00:32:43.246 A:middle
And the validation set is

00:32:43.306 --> 00:32:44.886 A:middle
particularly important in this

00:32:44.886 --> 00:32:45.536 A:middle
kind of training.

00:32:45.996 --> 00:32:48.466 A:middle
Neural Network training has a

00:32:48.516 --> 00:32:50.846 A:middle
tendency to over fitting, where

00:32:50.846 --> 00:32:52.666 A:middle
it more or less memorizes the

00:32:52.666 --> 00:32:53.916 A:middle
training material and doesn't

00:32:54.056 --> 00:32:54.816 A:middle
generalize.

00:32:55.096 --> 00:32:56.616 A:middle
The validation set helps keep it

00:32:56.616 --> 00:32:57.976 A:middle
honest and make sure it

00:32:57.976 --> 00:32:59.316 A:middle
continues to generalize.

00:33:00.146 --> 00:33:01.376 A:middle
And then, of course, we also

00:33:01.376 --> 00:33:03.946 A:middle
have a separate test set that's

00:33:03.946 --> 00:33:05.846 A:middle
similarly randomly sampled and

00:33:05.846 --> 00:33:08.056 A:middle
balanced, and of course there

00:33:08.056 --> 00:33:10.196 A:middle
can't be any overlap between the

00:33:10.196 --> 00:33:12.006 A:middle
training validation test sets.

00:33:12.006 --> 00:33:12.796 A:middle
That would be cheating.

00:33:13.966 --> 00:33:16.606 A:middle
And the test set we need to see

00:33:16.606 --> 00:33:17.576 A:middle
how well we're doing, in

00:33:17.576 --> 00:33:19.586 A:middle
particular in this case, we need

00:33:19.586 --> 00:33:22.296 A:middle
it so that we can see whether

00:33:22.296 --> 00:33:24.646 A:middle
the Transfer Learning model is

00:33:24.646 --> 00:33:27.766 A:middle
doing better than our maxEnt

00:33:27.766 --> 00:33:28.126 A:middle
model.

00:33:28.596 --> 00:33:29.866 A:middle
And it looks like it's finished

00:33:29.866 --> 00:33:31.046 A:middle
now, so let's take a look and

00:33:31.046 --> 00:33:31.326 A:middle
see.

00:33:31.606 --> 00:33:36.486 A:middle
And we can see here that the

00:33:36.486 --> 00:33:38.576 A:middle
Transfer Learning has achieved

00:33:38.576 --> 00:33:41.106 A:middle
an accuracy of 86.5%, much

00:33:41.186 --> 00:33:45.976 A:middle
better than our maxEnt model.

00:33:46.516 --> 00:33:51.796 A:middle
[ Applause ]

00:33:52.296 --> 00:33:55.996 A:middle
So, how does this apply to our

00:33:55.996 --> 00:33:56.976 A:middle
cheese application?

00:33:57.056 --> 00:33:59.536 A:middle
Well, what I've done is I've

00:33:59.576 --> 00:34:01.746 A:middle
taken my cheese tasting notes,

00:33:59.576 --> 00:34:01.746 A:middle
taken my cheese tasting notes,

00:34:03.146 --> 00:34:05.726 A:middle
and I labeled them each by the

00:34:05.756 --> 00:34:07.116 A:middle
cheese that they referred to,

00:34:07.396 --> 00:34:09.626 A:middle
and I use that to train a cheese

00:34:09.626 --> 00:34:10.676 A:middle
classifier model.

00:34:10.676 --> 00:34:13.196 A:middle
And so my cheese classifier

00:34:13.196 --> 00:34:16.146 A:middle
model can take a sentence and

00:34:16.246 --> 00:34:18.216 A:middle
try to classify it and determine

00:34:18.216 --> 00:34:20.156 A:middle
which cheese it most closely

00:34:20.156 --> 00:34:20.866 A:middle
refers to.

00:34:21.016 --> 00:34:24.036 A:middle
And I put that into my cheese

00:34:24.036 --> 00:34:27.936 A:middle
application, and so, what I'm

00:34:27.936 --> 00:34:28.826 A:middle
going to do in the cheese

00:34:28.826 --> 00:34:32.366 A:middle
application is if the user

00:34:32.366 --> 00:34:33.545 A:middle
didn't refer to a specific

00:34:33.585 --> 00:34:34.936 A:middle
cheese, then I'm going to try to

00:34:34.936 --> 00:34:36.136 A:middle
figure out which cheese they

00:34:36.136 --> 00:34:36.746 A:middle
might want.

00:34:37.255 --> 00:34:39.456 A:middle
And all I do is ask the model

00:34:39.456 --> 00:34:41.306 A:middle
for the label for the text.

00:34:42.076 --> 00:34:43.226 A:middle
And very simple.

00:34:43.226 --> 00:34:45.000 A:middle
Let's try it out.

00:35:01.046 --> 00:35:02.336 A:middle
So, I'm going to type in

00:35:02.336 --> 00:35:03.000 A:middle
something here.

00:35:15.486 --> 00:35:18.936 A:middle
And we'll let the cheese

00:35:18.936 --> 00:35:20.966 A:middle
classifier work on it.

00:35:21.516 --> 00:35:23.536 A:middle
And so the cheese classifier

00:35:23.696 --> 00:35:24.996 A:middle
determined that this is most

00:35:25.046 --> 00:35:26.716 A:middle
closely resembling Camembert,

00:35:27.066 --> 00:35:29.066 A:middle
and then my cheese embedding has

00:35:29.066 --> 00:35:30.516 A:middle
recommended some other cheeses

00:35:30.516 --> 00:35:31.936 A:middle
that are very similar, Brie and

00:35:31.936 --> 00:35:32.756 A:middle
so on and so forth.

00:35:34.156 --> 00:35:36.000 A:middle
Or, maybe I say--

00:35:45.386 --> 00:35:46.826 A:middle
Something firm and sharp and it

00:35:46.826 --> 00:35:47.946 A:middle
recognizes that as resembling

00:35:48.286 --> 00:35:49.826 A:middle
cheddar, and it recommends some

00:35:50.036 --> 00:35:50.966 A:middle
similar cheeses to us.

00:35:51.001 --> 00:35:53.001 A:middle
[applause]

00:35:53.036 --> 00:35:54.386 A:middle
So, this again shows us the

00:35:54.426 --> 00:35:57.596 A:middle
power of Text Classification in

00:35:57.596 --> 00:35:59.746 A:middle
combination with the other

00:35:59.956 --> 00:36:01.486 A:middle
NaturalLanguage APIs.

00:35:59.956 --> 00:36:01.486 A:middle
NaturalLanguage APIs.

00:36:01.736 --> 00:36:03.276 A:middle
So, I'd like to finish off with

00:36:03.276 --> 00:36:05.366 A:middle
some considerations for the use

00:36:05.456 --> 00:36:07.656 A:middle
of the Text Classification.

00:36:07.656 --> 00:36:09.266 A:middle
First of all, we need to note

00:36:09.266 --> 00:36:10.756 A:middle
the languages that are supported

00:36:11.166 --> 00:36:12.846 A:middle
for transfer learning, either

00:36:12.846 --> 00:36:14.956 A:middle
via Static Embeddings or the

00:36:14.956 --> 00:36:17.746 A:middle
special Dynamic Embeddings that

00:36:17.886 --> 00:36:19.576 A:middle
take context into account.

00:36:20.026 --> 00:36:23.196 A:middle
And then I want to talk a bit

00:36:23.196 --> 00:36:25.056 A:middle
about, more about data.

00:36:26.326 --> 00:36:28.446 A:middle
So, the first commandment when

00:36:28.446 --> 00:36:29.626 A:middle
dealing with data is that you

00:36:29.626 --> 00:36:31.676 A:middle
need to understand the domain

00:36:31.676 --> 00:36:32.296 A:middle
you're working with.

00:36:33.506 --> 00:36:35.036 A:middle
What kind of text do you expect

00:36:35.036 --> 00:36:36.176 A:middle
to see in practice?

00:36:36.396 --> 00:36:37.626 A:middle
Is it going to be sentence

00:36:37.626 --> 00:36:39.086 A:middle
fragments, full sentences,

00:36:39.086 --> 00:36:41.556 A:middle
multiple sentences, and make

00:36:41.556 --> 00:36:43.576 A:middle
sure that your training data is

00:36:43.576 --> 00:36:45.526 A:middle
as similar as possible to the

00:36:45.526 --> 00:36:47.106 A:middle
text that you expect to see and

00:36:47.106 --> 00:36:48.576 A:middle
try to classify in practice.

00:36:49.646 --> 00:36:52.026 A:middle
And covers as much as possible

00:36:52.286 --> 00:36:53.646 A:middle
of the variations that you're

00:36:53.646 --> 00:36:55.866 A:middle
likely to see when you encounter

00:36:55.866 --> 00:36:57.776 A:middle
this text in your application.

00:36:58.906 --> 00:37:02.746 A:middle
And, as we saw in our DBpedia

00:36:58.906 --> 00:37:02.746 A:middle
And, as we saw in our DBpedia

00:37:02.746 --> 00:37:04.806 A:middle
example, you want to make sure

00:37:05.266 --> 00:37:08.806 A:middle
that you have randomly sampled

00:37:08.806 --> 00:37:11.316 A:middle
as much as possible distinct

00:37:11.316 --> 00:37:13.606 A:middle
sets for training, for

00:37:13.606 --> 00:37:15.266 A:middle
validation, and tests.

00:37:15.766 --> 00:37:17.696 A:middle
This is basic data hygiene.

00:37:18.096 --> 00:37:21.706 A:middle
And how do you know which

00:37:21.706 --> 00:37:23.306 A:middle
algorithm will be best for your

00:37:23.306 --> 00:37:23.916 A:middle
case?

00:37:24.336 --> 00:37:25.616 A:middle
Well, in general, you'll have to

00:37:25.616 --> 00:37:28.426 A:middle
try it, but some guidelines.

00:37:28.626 --> 00:37:29.886 A:middle
You can start with the maxEnt

00:37:29.886 --> 00:37:30.466 A:middle
classifier.

00:37:30.466 --> 00:37:31.456 A:middle
It's very fast.

00:37:31.456 --> 00:37:32.606 A:middle
It will give you an answer.

00:37:33.766 --> 00:37:35.206 A:middle
But what does a maxEnt

00:37:35.206 --> 00:37:36.356 A:middle
classifier do?

00:37:36.896 --> 00:37:38.926 A:middle
A maxEnt classifier works by

00:37:38.926 --> 00:37:41.556 A:middle
noticing the words that are used

00:37:42.146 --> 00:37:44.056 A:middle
most often in the training

00:37:44.056 --> 00:37:44.556 A:middle
material.

00:37:45.096 --> 00:37:46.806 A:middle
So, for example, if you're

00:37:46.806 --> 00:37:49.756 A:middle
trying to train positive and

00:37:49.756 --> 00:37:51.486 A:middle
negative, it might notice words

00:37:51.486 --> 00:37:52.676 A:middle
like love and happy are

00:37:52.736 --> 00:37:54.166 A:middle
positive, hate and unhappy

00:37:54.166 --> 00:37:54.666 A:middle
negative.

00:37:55.326 --> 00:37:57.406 A:middle
And if the examples you

00:37:57.406 --> 00:37:59.106 A:middle
encounter in practice use these

00:37:59.106 --> 00:38:00.426 A:middle
same words, then the maxEnt

00:37:59.106 --> 00:38:00.426 A:middle
same words, then the maxEnt

00:38:00.426 --> 00:38:01.876 A:middle
classifier is going to work very

00:38:01.876 --> 00:38:02.146 A:middle
well.

00:38:02.676 --> 00:38:08.146 A:middle
What the Transfer Learning does

00:38:08.456 --> 00:38:10.076 A:middle
is it notices the meaning of

00:38:10.076 --> 00:38:10.546 A:middle
words.

00:38:11.056 --> 00:38:12.906 A:middle
So if the examples you encounter

00:38:12.906 --> 00:38:14.476 A:middle
in practice are likely to

00:38:14.476 --> 00:38:16.926 A:middle
express a similar meaning with

00:38:17.016 --> 00:38:20.426 A:middle
different words, then that is

00:38:20.426 --> 00:38:21.786 A:middle
the case where Transfer Learning

00:38:21.786 --> 00:38:24.476 A:middle
shines and it's likely to do

00:38:24.476 --> 00:38:27.156 A:middle
better than the simple maxEnt

00:38:27.156 --> 00:38:27.546 A:middle
model.

00:38:28.046 --> 00:38:33.086 A:middle
So, to summarize, we have new

00:38:33.086 --> 00:38:35.676 A:middle
APIs available for Sentiment

00:38:35.676 --> 00:38:38.706 A:middle
Analysis, for Text Catalogs with

00:38:38.706 --> 00:38:41.906 A:middle
MLGazetteer, for Word Embeddings

00:38:41.996 --> 00:38:45.376 A:middle
with NL embedding, and we have a

00:38:45.376 --> 00:38:47.306 A:middle
new type of text classification,

00:38:47.466 --> 00:38:49.046 A:middle
a particularly powerful new type

00:38:49.716 --> 00:38:51.736 A:middle
that takes advantage of Transfer

00:38:51.736 --> 00:38:52.056 A:middle
Learning.

00:38:53.096 --> 00:38:55.226 A:middle
I hope you'll take advantage of

00:38:55.226 --> 00:38:58.086 A:middle
these in your applications, and

00:38:58.426 --> 00:38:59.566 A:middle
there's much more information

00:38:59.566 --> 00:39:01.496 A:middle
available online, and there are

00:38:59.566 --> 00:39:01.496 A:middle
available online, and there are

00:39:01.496 --> 00:39:04.256 A:middle
other related sessions that you

00:39:04.256 --> 00:39:05.256 A:middle
can take a look at.

00:39:06.356 --> 00:39:06.796 A:middle
Thank you.

00:39:07.516 --> 00:39:12.500 A:middle
[ Applause ]
