WEBVTT

00:00:01.516 --> 00:00:04.500 A:middle
[ Music ]

00:00:08.516 --> 00:00:13.146 A:middle
[ Applause ]

00:00:13.646 --> 00:00:15.286 A:middle
&gt;&gt; This year, our Create ML

00:00:15.286 --> 00:00:17.276 A:middle
release has new models and a

00:00:17.276 --> 00:00:18.416 A:middle
whole new workflow.

00:00:19.646 --> 00:00:21.156 A:middle
Every workflow starts with

00:00:21.156 --> 00:00:21.526 A:middle
input.

00:00:22.166 --> 00:00:23.946 A:middle
The devices that we develop for,

00:00:24.136 --> 00:00:26.106 A:middle
use, and love, are rich with

00:00:26.106 --> 00:00:27.196 A:middle
information from different

00:00:27.196 --> 00:00:29.326 A:middle
sensors such as a camera, the

00:00:29.326 --> 00:00:30.946 A:middle
microphone, the keyboard,

00:00:31.296 --> 00:00:33.236 A:middle
Accelerometer, even Gyroscope.

00:00:34.036 --> 00:00:35.436 A:middle
And all of these types of input

00:00:35.716 --> 00:00:37.406 A:middle
can be used so you can train

00:00:37.406 --> 00:00:38.906 A:middle
machine learning models and make

00:00:38.906 --> 00:00:40.656 A:middle
your apps more personalized and

00:00:40.656 --> 00:00:41.346 A:middle
more intelligent.

00:00:42.756 --> 00:00:44.876 A:middle
Last year, we supported three of

00:00:44.876 --> 00:00:47.136 A:middle
these types of input; images,

00:00:47.436 --> 00:00:48.946 A:middle
text, and tabular data.

00:00:50.086 --> 00:00:51.836 A:middle
This year, we're increasing the

00:00:51.906 --> 00:00:53.446 A:middle
set of available domains from

00:00:53.506 --> 00:00:54.736 A:middle
three to five.

00:00:54.736 --> 00:00:57.146 A:middle
And now, introducing Activity

00:00:57.326 --> 00:00:57.876 A:middle
and Sound.

00:00:58.676 --> 00:01:00.096 A:middle
We're also expanding the breadth

00:00:58.676 --> 00:01:00.096 A:middle
We're also expanding the breadth

00:01:00.156 --> 00:01:01.886 A:middle
of available models within all

00:01:02.736 --> 00:01:03.776 A:middle
of them.

00:01:03.986 --> 00:01:05.626 A:middle
And all of this is being brought

00:01:05.866 --> 00:01:07.036 A:middle
into a new medium.

00:01:07.656 --> 00:01:09.386 A:middle
We call it Create ML app.

00:01:10.426 --> 00:01:12.416 A:middle
It all starts with identifying

00:01:12.416 --> 00:01:13.006 A:middle
your domain.

00:01:14.266 --> 00:01:15.436 A:middle
And once you filter by your

00:01:15.436 --> 00:01:16.936 A:middle
input, you can see all of the

00:01:16.936 --> 00:01:18.366 A:middle
available model types you can

00:01:18.366 --> 00:01:18.836 A:middle
create.

00:01:20.946 --> 00:01:22.286 A:middle
Create ML then breaks down the

00:01:22.286 --> 00:01:23.966 A:middle
task of creating machine

00:01:23.966 --> 00:01:25.556 A:middle
learning model into three simple

00:01:25.556 --> 00:01:28.486 A:middle
phases; input, training, and

00:01:29.336 --> 00:01:29.486 A:middle
output.

00:01:30.156 --> 00:01:32.056 A:middle
This new environment changes the

00:01:32.056 --> 00:01:33.726 A:middle
way you interact with machine

00:01:33.726 --> 00:01:34.746 A:middle
learning on the system.

00:01:35.316 --> 00:01:37.696 A:middle
The app then displays an

00:01:37.696 --> 00:01:39.476 A:middle
overview of your data and a rich

00:01:39.476 --> 00:01:41.306 A:middle
set of analytics as it trains.

00:01:42.006 --> 00:01:43.156 A:middle
You can visualize your model's

00:01:43.246 --> 00:01:44.466 A:middle
progress in an easy to

00:01:44.466 --> 00:01:46.386 A:middle
understand graphical view that

00:01:46.386 --> 00:01:47.586 A:middle
displays the accuracy of your

00:01:47.586 --> 00:01:49.156 A:middle
model across iterations.

00:01:49.666 --> 00:01:52.296 A:middle
You can also see a breakdown of

00:01:52.296 --> 00:01:53.836 A:middle
the precision and recall values

00:01:53.886 --> 00:01:55.396 A:middle
for each class your model was

00:01:55.396 --> 00:01:55.906 A:middle
trained on.

00:01:56.646 --> 00:01:58.276 A:middle
And the table is interactive so

00:01:58.736 --> 00:02:00.316 A:middle
you can filter by class or by

00:01:58.736 --> 00:02:00.316 A:middle
you can filter by class or by

00:02:00.316 --> 00:02:02.336 A:middle
percentage to better understand

00:02:02.336 --> 00:02:03.436 A:middle
your model's performance.

00:02:04.096 --> 00:02:07.136 A:middle
The process of testing is as

00:02:07.196 --> 00:02:08.586 A:middle
simple as dragging and dropping

00:02:08.586 --> 00:02:09.045 A:middle
in new data.

00:02:10.175 --> 00:02:11.366 A:middle
You can have the ability to

00:02:11.366 --> 00:02:13.306 A:middle
train and retest just by

00:02:13.306 --> 00:02:14.316 A:middle
clicking the Test button.

00:02:16.006 --> 00:02:17.436 A:middle
And what's really unique about

00:02:17.436 --> 00:02:18.866 A:middle
Create ML is you can easily

00:02:18.866 --> 00:02:20.516 A:middle
preview trained models in the

00:02:20.516 --> 00:02:21.166 A:middle
Output tab.

00:02:21.936 --> 00:02:23.156 A:middle
This new feature allows you to

00:02:23.256 --> 00:02:24.776 A:middle
see exactly how your model will

00:02:24.826 --> 00:02:26.606 A:middle
predict without having to

00:02:26.606 --> 00:02:27.976 A:middle
incorporate your models into

00:02:27.976 --> 00:02:28.206 A:middle
your apps.

00:02:29.256 --> 00:02:30.676 A:middle
This means no more waiting to

00:02:30.676 --> 00:02:31.286 A:middle
deploy them.

00:02:31.896 --> 00:02:33.056 A:middle
You can do this directly in

00:02:33.056 --> 00:02:34.846 A:middle
Create ML, saving you time to

00:02:34.846 --> 00:02:36.186 A:middle
perfect your models instead.

00:02:36.796 --> 00:02:39.516 A:middle
The Preview section is also

00:02:39.516 --> 00:02:41.296 A:middle
custom built for every template,

00:02:41.686 --> 00:02:43.266 A:middle
ensuring a complete end-to-end

00:02:43.266 --> 00:02:44.776 A:middle
experience for every task.

00:02:46.246 --> 00:02:47.606 A:middle
But what better way to see this

00:02:47.996 --> 00:02:49.206 A:middle
than to show it to you live?

00:02:51.126 --> 00:02:51.726 A:middle
Let's take a look.

00:02:52.516 --> 00:02:57.606 A:middle
[ Applause ]

00:02:58.106 --> 00:02:59.746 A:middle
Now, over in Xcode, I've been

00:02:59.746 --> 00:03:01.336 A:middle
working on a flower classifier

00:02:59.746 --> 00:03:01.336 A:middle
working on a flower classifier

00:03:01.796 --> 00:03:02.896 A:middle
app to help me identify

00:03:02.896 --> 00:03:04.296 A:middle
different types of flowers.

00:03:05.046 --> 00:03:06.406 A:middle
And I've been using a model that

00:03:06.406 --> 00:03:07.496 A:middle
I downloaded from the Model

00:03:07.496 --> 00:03:09.696 A:middle
Gallery called Resnet50.

00:03:10.096 --> 00:03:11.576 A:middle
And this is a well-known image

00:03:11.576 --> 00:03:13.146 A:middle
classifier model that's been

00:03:13.146 --> 00:03:14.896 A:middle
trained to recognize 1,000

00:03:14.896 --> 00:03:15.726 A:middle
different classes.

00:03:16.956 --> 00:03:18.186 A:middle
But this model is taking up

00:03:18.226 --> 00:03:19.736 A:middle
about 100 megabytes of my app.

00:03:20.746 --> 00:03:22.076 A:middle
And we can see when I actually

00:03:22.076 --> 00:03:24.386 A:middle
try it on different images it

00:03:25.456 --> 00:03:27.496 A:middle
knows that this Hibiscus is a

00:03:27.496 --> 00:03:29.196 A:middle
flower, but it doesn't know the

00:03:29.196 --> 00:03:29.826 A:middle
exact type.

00:03:30.306 --> 00:03:32.856 A:middle
So, it doesn't quite suit my

00:03:33.386 --> 00:03:33.516 A:middle
needs.

00:03:33.756 --> 00:03:35.866 A:middle
Now, what I can do is from Xcode

00:03:37.386 --> 00:03:39.386 A:middle
I can open Developer Tools and

00:03:39.386 --> 00:03:41.216 A:middle
launch Create ML.

00:03:42.696 --> 00:03:44.876 A:middle
This then prompts me to create a

00:03:44.876 --> 00:03:45.506 A:middle
new document.

00:03:45.506 --> 00:03:48.506 A:middle
And we can see I'm launched into

00:03:48.506 --> 00:03:50.296 A:middle
the Template View where I can

00:03:50.356 --> 00:03:52.386 A:middle
see all the available models we

00:03:53.006 --> 00:03:53.926 A:middle
can create.

00:03:54.116 --> 00:03:55.276 A:middle
Since I'm working with images,

00:03:55.646 --> 00:03:57.416 A:middle
I'll filter by image and select

00:03:57.746 --> 00:03:58.746 A:middle
the Image Classifier.

00:04:00.026 --> 00:04:00.896 A:middle
We can then name this.

00:04:05.366 --> 00:04:07.276 A:middle
And then, pick the place to save

00:04:07.276 --> 00:04:08.516 A:middle
it so we can come back to it

00:04:08.516 --> 00:04:08.816 A:middle
later.

00:04:09.426 --> 00:04:12.226 A:middle
And then, launch into the New

00:04:12.626 --> 00:04:13.286 A:middle
App view.

00:04:14.036 --> 00:04:16.346 A:middle
And you can see that I'm, I'm

00:04:16.346 --> 00:04:18.435 A:middle
first prompted to drag in input

00:04:18.435 --> 00:04:19.166 A:middle
as training data.

00:04:19.166 --> 00:04:21.356 A:middle
And if I progress through some

00:04:21.356 --> 00:04:22.786 A:middle
of the other tabs, they're not

00:04:22.786 --> 00:04:24.416 A:middle
unlocked yet because I haven't

00:04:24.416 --> 00:04:25.256 A:middle
gone through the flow.

00:04:26.516 --> 00:04:27.756 A:middle
So, let's try this sequentially.

00:04:28.416 --> 00:04:31.906 A:middle
On my desktop, I set aside some

00:04:31.906 --> 00:04:33.116 A:middle
images of different types of

00:04:33.116 --> 00:04:33.566 A:middle
flowers.

00:04:34.396 --> 00:04:36.306 A:middle
And you can see, I have some

00:04:36.306 --> 00:04:40.266 A:middle
hibiscus, some passionflower,

00:04:40.266 --> 00:04:43.836 A:middle
and then even some roses,

00:04:45.316 --> 00:04:46.306 A:middle
dahlias, and daisies.

00:04:47.756 --> 00:04:48.876 A:middle
I could take this folder and

00:04:48.876 --> 00:04:51.136 A:middle
drag it in and immediately see

00:04:51.136 --> 00:04:53.136 A:middle
that I have 65 different images

00:04:53.256 --> 00:04:54.686 A:middle
contained within it and they're

00:04:54.686 --> 00:04:59.706 A:middle
across five different classes.

00:04:59.816 --> 00:05:01.376 A:middle
Now, since we have our input

00:04:59.816 --> 00:05:01.376 A:middle
Now, since we have our input

00:05:01.446 --> 00:05:03.076 A:middle
data, I can hit the Run button

00:05:03.356 --> 00:05:04.836 A:middle
and automatically this model

00:05:04.836 --> 00:05:05.666 A:middle
begins training.

00:05:06.456 --> 00:05:07.816 A:middle
It first starts by extracting

00:05:07.816 --> 00:05:09.046 A:middle
features from the images.

00:05:09.556 --> 00:05:10.616 A:middle
And then, we can see the

00:05:10.616 --> 00:05:12.416 A:middle
progress as training begins.

00:05:13.796 --> 00:05:15.216 A:middle
I can see a breakdown of how the

00:05:15.216 --> 00:05:16.446 A:middle
model's performing on this data.

00:05:17.116 --> 00:05:18.546 A:middle
But what I'd really like to do

00:05:18.546 --> 00:05:20.206 A:middle
is see how the model performs on

00:05:20.206 --> 00:05:21.776 A:middle
new data that it hasn't seen.

00:05:22.256 --> 00:05:23.496 A:middle
So, I'll navigate to the Testing

00:05:23.496 --> 00:05:25.836 A:middle
tab and I'll drag in these new

00:05:25.836 --> 00:05:27.886 A:middle
flowers that I've set aside and

00:05:28.476 --> 00:05:29.266 A:middle
hit Test.

00:05:34.296 --> 00:05:35.686 A:middle
Now, what I'd really like to do

00:05:35.686 --> 00:05:36.886 A:middle
is take a look at the trained

00:05:36.886 --> 00:05:38.136 A:middle
model in the Output tab.

00:05:38.136 --> 00:05:40.816 A:middle
And we can see here I have a

00:05:40.816 --> 00:05:42.996 A:middle
flower classifier that's 66

00:05:43.066 --> 00:05:43.586 A:middle
kilobytes.

00:05:44.326 --> 00:05:46.886 A:middle
Now, to actually preview this,

00:05:47.106 --> 00:05:49.006 A:middle
I've taken some other photos and

00:05:49.006 --> 00:05:50.416 A:middle
perhaps this hibiscus that

00:05:50.806 --> 00:05:52.046 A:middle
wasn't working before with

00:05:52.106 --> 00:05:52.516 A:middle
Resnet.

00:05:53.766 --> 00:05:55.466 A:middle
And I can see now, this model

00:05:55.466 --> 00:05:57.006 A:middle
can correctly predict exactly

00:05:57.006 --> 00:05:57.506 A:middle
what it is.

00:05:58.106 --> 00:05:59.366 A:middle
And I can see other predictions

00:05:59.366 --> 00:06:00.476 A:middle
the model has made and

00:05:59.366 --> 00:06:00.476 A:middle
the model has made and

00:06:00.476 --> 00:06:02.106 A:middle
confidence values for each one.

00:06:02.356 --> 00:06:05.376 A:middle
I can even take a full folder

00:06:05.376 --> 00:06:09.006 A:middle
and drag them in and debug any

00:06:09.006 --> 00:06:10.276 A:middle
image that this model has

00:06:10.276 --> 00:06:10.876 A:middle
predicted on.

00:06:12.356 --> 00:06:13.896 A:middle
Now, once I'm satisfied, I can

00:06:13.896 --> 00:06:15.656 A:middle
take this model and drag it out.

00:06:20.196 --> 00:06:21.546 A:middle
And then, reintegrate that into

00:06:21.616 --> 00:06:21.836 A:middle
my app.

00:06:23.246 --> 00:06:24.856 A:middle
But what's more, is you can also

00:06:24.856 --> 00:06:26.736 A:middle
leverage the power of Continuity

00:06:26.736 --> 00:06:28.186 A:middle
Camera in Create ML.

00:06:29.106 --> 00:06:31.196 A:middle
And from this, what I can do is

00:06:31.196 --> 00:06:33.936 A:middle
I can import from my phone which

00:06:33.936 --> 00:06:34.226 A:middle
is attached.

00:06:34.826 --> 00:06:37.106 A:middle
And I can try to take a photo of

00:06:37.656 --> 00:06:39.596 A:middle
this flower that I have here on

00:06:39.596 --> 00:06:41.376 A:middle
stage, and we can see how it

00:06:41.376 --> 00:06:41.626 A:middle
does.

00:06:42.146 --> 00:06:44.526 A:middle
And it actually turns out okay.

00:06:46.516 --> 00:06:52.586 A:middle
[ Applause ]

00:06:53.086 --> 00:06:54.106 A:middle
Now, if you're not happy with

00:06:54.106 --> 00:06:55.866 A:middle
your performance or if you'd

00:06:55.866 --> 00:06:56.886 A:middle
just like to run some more

00:06:56.886 --> 00:06:58.226 A:middle
experiments, there's a Plus

00:06:58.326 --> 00:06:59.206 A:middle
button here, as well.

00:06:59.706 --> 00:07:00.906 A:middle
And what you can do is you can

00:06:59.706 --> 00:07:00.906 A:middle
And what you can do is you can

00:07:00.976 --> 00:07:03.076 A:middle
select more training data.

00:07:03.256 --> 00:07:04.516 A:middle
You can toggle how our

00:07:04.516 --> 00:07:06.226 A:middle
validation data is specified and

00:07:06.846 --> 00:07:08.616 A:middle
even your testing data, as well.

00:07:10.116 --> 00:07:11.476 A:middle
This time, I might want to tweak

00:07:11.526 --> 00:07:12.496 A:middle
some augmentations.

00:07:13.236 --> 00:07:14.286 A:middle
And then, I can hit Run to

00:07:14.286 --> 00:07:14.706 A:middle
train.

00:07:16.096 --> 00:07:17.896 A:middle
And that's a look at the new

00:07:17.896 --> 00:07:19.466 A:middle
workflow in Create ML.

00:07:20.016 --> 00:07:21.066 A:middle
Let's go back to the slides.

00:07:22.516 --> 00:07:24.736 A:middle
[ Applause ]

00:07:25.236 --> 00:07:27.656 A:middle
So, you've seen Create ML gives

00:07:27.656 --> 00:07:29.376 A:middle
you a whole new way to train

00:07:29.376 --> 00:07:30.476 A:middle
your custom machine learning

00:07:30.476 --> 00:07:32.276 A:middle
models on the Mac, with a

00:07:32.276 --> 00:07:33.506 A:middle
beautiful look and feel.

00:07:34.296 --> 00:07:35.826 A:middle
And with additions like metrics

00:07:35.876 --> 00:07:37.756 A:middle
visualization, live progress,

00:07:37.966 --> 00:07:40.016 A:middle
and interactive preview, Create

00:07:40.016 --> 00:07:42.306 A:middle
ML app sets the bar for a great

00:07:42.306 --> 00:07:43.666 A:middle
model training experience.

00:07:45.006 --> 00:07:46.746 A:middle
In the demo, we walked through

00:07:46.986 --> 00:07:48.476 A:middle
just one model that you can

00:07:48.476 --> 00:07:49.556 A:middle
create with Create ML.

00:07:50.146 --> 00:07:51.396 A:middle
But this release, we're

00:07:51.396 --> 00:07:52.436 A:middle
introducing nine.

00:07:53.306 --> 00:07:54.816 A:middle
So, let's take a high-level tour

00:07:54.876 --> 00:07:56.196 A:middle
of all of the models you can

00:07:56.196 --> 00:07:58.176 A:middle
create and some examples of

00:07:58.236 --> 00:07:59.646 A:middle
sample apps.

00:08:00.766 --> 00:08:02.066 A:middle
Starting with the image domain,

00:08:02.396 --> 00:08:04.186 A:middle
we have the Image Classifier and

00:08:04.186 --> 00:08:04.996 A:middle
Object Detector.

00:08:06.436 --> 00:08:08.176 A:middle
An Image Classifier can be used

00:08:08.176 --> 00:08:10.076 A:middle
for categorizing images based on

00:08:10.076 --> 00:08:10.646 A:middle
their contents.

00:08:11.166 --> 00:08:12.706 A:middle
For example, the Art Style

00:08:12.706 --> 00:08:14.736 A:middle
identifier uses a custom Image

00:08:14.736 --> 00:08:16.496 A:middle
Classifier to determine the most

00:08:16.556 --> 00:08:18.086 A:middle
likely movement of a piece.

00:08:18.966 --> 00:08:20.226 A:middle
It then separately provides an

00:08:20.226 --> 00:08:22.436 A:middle
overview of notable artists to

00:08:22.436 --> 00:08:23.916 A:middle
complete the app experience.

00:08:26.636 --> 00:08:27.856 A:middle
In Create ML, the Image

00:08:27.936 --> 00:08:29.826 A:middle
Classifier leverages core Apple

00:08:29.906 --> 00:08:31.286 A:middle
technology by performing

00:08:31.286 --> 00:08:32.986 A:middle
transfer learning on top of the

00:08:32.986 --> 00:08:34.216 A:middle
vision feature print model

00:08:34.506 --> 00:08:35.525 A:middle
already in the OS.

00:08:36.145 --> 00:08:37.696 A:middle
This allows you to benefit from

00:08:37.746 --> 00:08:39.385 A:middle
faster training times and a

00:08:39.385 --> 00:08:43.006 A:middle
reduced model size in your app.

00:08:43.436 --> 00:08:44.766 A:middle
Also, you have the option to

00:08:44.766 --> 00:08:46.746 A:middle
train with augmentation to make

00:08:46.746 --> 00:08:48.326 A:middle
your models more robust to

00:08:48.366 --> 00:08:49.206 A:middle
unseen input.

00:08:50.336 --> 00:08:51.996 A:middle
If you instead want to identify

00:08:52.106 --> 00:08:53.796 A:middle
multiple objects within an image

00:08:53.796 --> 00:08:55.716 A:middle
instead of one single one, you

00:08:55.716 --> 00:08:57.126 A:middle
might want to create an Object

00:08:57.126 --> 00:08:57.626 A:middle
Detector.

00:08:58.976 --> 00:09:00.696 A:middle
Object Detectors can be used for

00:08:58.976 --> 00:09:00.696 A:middle
Object Detectors can be used for

00:09:00.726 --> 00:09:02.376 A:middle
localizing and recognizing

00:09:02.376 --> 00:09:03.876 A:middle
contents within an image.

00:09:04.866 --> 00:09:06.336 A:middle
For example, these can be

00:09:06.396 --> 00:09:07.886 A:middle
trained to detect one or more

00:09:07.886 --> 00:09:10.246 A:middle
classes such as specific playing

00:09:10.246 --> 00:09:12.196 A:middle
cards or the exact suits

00:09:12.316 --> 00:09:13.096 A:middle
contained on them.

00:09:14.626 --> 00:09:16.096 A:middle
The Object Detector is a deep

00:09:16.096 --> 00:09:17.476 A:middle
learning-based model and

00:09:17.476 --> 00:09:19.636 A:middle
performs data augmentation to

00:09:19.696 --> 00:09:20.786 A:middle
make it more robust.

00:09:21.286 --> 00:09:23.036 A:middle
And it does this entirely on

00:09:23.466 --> 00:09:25.806 A:middle
your Mac's GPU.

00:09:26.126 --> 00:09:27.976 A:middle
Our next domain is Sound.

00:09:29.186 --> 00:09:30.696 A:middle
Within Sound, we have a new

00:09:30.696 --> 00:09:31.746 A:middle
model called the Sound

00:09:31.746 --> 00:09:32.356 A:middle
Classifier.

00:09:33.816 --> 00:09:35.156 A:middle
This model allows you to

00:09:35.156 --> 00:09:36.886 A:middle
determine the most dominant

00:09:36.956 --> 00:09:38.506 A:middle
sound within an audio stream.

00:09:40.206 --> 00:09:41.796 A:middle
Since audio data is time series

00:09:41.866 --> 00:09:43.486 A:middle
based, you could differentiate

00:09:43.556 --> 00:09:45.246 A:middle
between the start and end points

00:09:45.246 --> 00:09:46.926 A:middle
of different sounds such as when

00:09:46.926 --> 00:09:48.496 A:middle
the guitar solo ends and the

00:09:48.496 --> 00:09:49.486 A:middle
crowd goes wild.

00:09:51.656 --> 00:09:53.016 A:middle
This model leverages transfer

00:09:53.016 --> 00:09:54.326 A:middle
learning so you can also

00:09:54.326 --> 00:09:55.646 A:middle
experience faster training

00:09:55.696 --> 00:09:55.946 A:middle
times.

00:09:56.916 --> 00:09:58.376 A:middle
And we also understand that

00:09:58.376 --> 00:10:00.066 A:middle
optimizing performance across

00:09:58.376 --> 00:10:00.066 A:middle
optimizing performance across

00:10:00.186 --> 00:10:01.546 A:middle
complex applications is

00:10:01.576 --> 00:10:02.146 A:middle
challenging.

00:10:02.676 --> 00:10:03.586 A:middle
Which is why we want to

00:10:03.586 --> 00:10:05.486 A:middle
emphasize that these models are

00:10:05.566 --> 00:10:06.986 A:middle
lightweight and run on the

00:10:06.986 --> 00:10:09.736 A:middle
Neural Engine, making them ideal

00:10:09.736 --> 00:10:11.566 A:middle
for real-time applications on

00:10:11.636 --> 00:10:12.276 A:middle
any device.

00:10:12.996 --> 00:10:16.986 A:middle
Our third domain is Activity.

00:10:17.586 --> 00:10:19.466 A:middle
And within Activity, we have the

00:10:19.576 --> 00:10:20.916 A:middle
Activity Classifier for the

00:10:20.916 --> 00:10:21.436 A:middle
first time.

00:10:22.826 --> 00:10:24.966 A:middle
This model also operates on time

00:10:25.046 --> 00:10:25.736 A:middle
series-based data.

00:10:25.846 --> 00:10:28.596 A:middle
And Activity Classifiers can be

00:10:28.596 --> 00:10:30.236 A:middle
trained to categorize contents

00:10:30.236 --> 00:10:32.396 A:middle
of motion data from a variety of

00:10:32.396 --> 00:10:33.396 A:middle
sensors such as the

00:10:33.396 --> 00:10:35.326 A:middle
Accelerometer and Gyroscope.

00:10:37.036 --> 00:10:37.936 A:middle
These models are deep

00:10:37.996 --> 00:10:39.536 A:middle
learning-based and train on the

00:10:39.536 --> 00:10:40.006 A:middle
GPU.

00:10:40.496 --> 00:10:41.976 A:middle
And they result in small model

00:10:42.036 --> 00:10:43.866 A:middle
sizes that are also ideal for

00:10:43.866 --> 00:10:45.436 A:middle
deployment on any device.

00:10:47.166 --> 00:10:49.046 A:middle
Our second to last input is

00:10:49.046 --> 00:10:49.216 A:middle
Text.

00:10:50.166 --> 00:10:52.356 A:middle
Within Text, there are two model

00:10:52.356 --> 00:10:54.426 A:middle
types available; the Text

00:10:54.486 --> 00:10:56.376 A:middle
Classifier and the Word Tagger.

00:10:58.456 --> 00:11:00.256 A:middle
Text classification can be used

00:10:58.456 --> 00:11:00.256 A:middle
Text classification can be used

00:11:00.256 --> 00:11:02.516 A:middle
to label sentences, paragraphs,

00:11:02.516 --> 00:11:04.516 A:middle
or even entire articles based on

00:11:04.516 --> 00:11:05.106 A:middle
their contents.

00:11:05.906 --> 00:11:07.246 A:middle
You can train these for custom

00:11:07.246 --> 00:11:08.746 A:middle
topic identification or

00:11:08.746 --> 00:11:09.926 A:middle
categorization tasks.

00:11:11.476 --> 00:11:12.566 A:middle
In Create ML, there are a

00:11:12.566 --> 00:11:14.026 A:middle
variety of different algorithms

00:11:14.026 --> 00:11:15.696 A:middle
for you to try and even a new

00:11:15.696 --> 00:11:17.456 A:middle
transfer learning option this

00:11:17.986 --> 00:11:18.096 A:middle
year.

00:11:18.896 --> 00:11:21.166 A:middle
The Word Tagger is slightly more

00:11:21.166 --> 00:11:21.616 A:middle
nuanced.

00:11:22.586 --> 00:11:24.266 A:middle
It's ideal for labeling tokens

00:11:24.466 --> 00:11:26.176 A:middle
or words of interest in text.

00:11:27.186 --> 00:11:28.706 A:middle
General purpose examples of this

00:11:28.976 --> 00:11:30.876 A:middle
are things like tagging

00:11:30.876 --> 00:11:32.426 A:middle
different parts of speech or

00:11:32.426 --> 00:11:33.846 A:middle
recognizing named entities,

00:11:34.246 --> 00:11:35.346 A:middle
though you could customize your

00:11:35.346 --> 00:11:36.976 A:middle
own to do things like tag

00:11:37.056 --> 00:11:37.486 A:middle
cheeses.

00:11:38.356 --> 00:11:39.876 A:middle
With a Cheese Tagger, you could

00:11:39.876 --> 00:11:41.306 A:middle
be sure to identify different

00:11:41.306 --> 00:11:43.046 A:middle
flavor notes from any cheese

00:11:43.086 --> 00:11:43.646 A:middle
description.

00:11:44.196 --> 00:11:47.816 A:middle
Our last domain is the most

00:11:47.816 --> 00:11:49.846 A:middle
general of all five; Tabular

00:11:49.846 --> 00:11:50.016 A:middle
Data.

00:11:51.076 --> 00:11:52.516 A:middle
And within this, we have three

00:11:52.516 --> 00:11:54.286 A:middle
model types; the Tabular

00:11:54.676 --> 00:11:57.386 A:middle
Classifier, Tabular Regressor,

00:11:58.046 --> 00:11:59.046 A:middle
and Recommender.

00:11:59.716 --> 00:12:01.696 A:middle
Classifiers are for categorizing

00:11:59.716 --> 00:12:01.696 A:middle
Classifiers are for categorizing

00:12:01.776 --> 00:12:03.446 A:middle
samples based on their features

00:12:03.446 --> 00:12:03.966 A:middle
of interest.

00:12:04.676 --> 00:12:06.216 A:middle
And features can be a variety of

00:12:06.216 --> 00:12:07.516 A:middle
different types such as

00:12:07.516 --> 00:12:10.286 A:middle
integers, doubles, strings, so

00:12:10.286 --> 00:12:11.466 A:middle
long as your target is a

00:12:11.466 --> 00:12:12.436 A:middle
discrete value.

00:12:14.216 --> 00:12:15.376 A:middle
These allow you to do things

00:12:15.426 --> 00:12:16.996 A:middle
like determine if a seat is

00:12:17.036 --> 00:12:18.836 A:middle
comfortable or not based on a

00:12:18.836 --> 00:12:20.236 A:middle
particular person's height and

00:12:20.236 --> 00:12:21.966 A:middle
weight and specific properties

00:12:22.006 --> 00:12:23.466 A:middle
of the seat such as the amount

00:12:23.466 --> 00:12:24.036 A:middle
of leg room.

00:12:25.476 --> 00:12:26.716 A:middle
What's unique about the Tabular

00:12:26.766 --> 00:12:28.736 A:middle
Classifier is it extracts away

00:12:28.956 --> 00:12:30.306 A:middle
the underlying algorithm for

00:12:30.306 --> 00:12:30.536 A:middle
you.

00:12:30.916 --> 00:12:32.796 A:middle
And identifies the best multiple

00:12:32.796 --> 00:12:34.136 A:middle
classifiers for your data.

00:12:35.766 --> 00:12:37.156 A:middle
If you instead want a model that

00:12:37.156 --> 00:12:38.656 A:middle
will predict a numeric value,

00:12:38.776 --> 00:12:40.936 A:middle
such as a rating or a score, you

00:12:40.936 --> 00:12:42.306 A:middle
may instead want to use the

00:12:42.306 --> 00:12:43.256 A:middle
Tabular Regressor.

00:12:44.516 --> 00:12:46.166 A:middle
This model quantifies samples

00:12:46.296 --> 00:12:47.216 A:middle
based on their defining

00:12:47.216 --> 00:12:47.696 A:middle
features.

00:12:47.786 --> 00:12:49.176 A:middle
So, you could train one to

00:12:49.206 --> 00:12:50.566 A:middle
estimate the price of a house

00:12:51.036 --> 00:12:52.956 A:middle
based on its location and number

00:12:52.956 --> 00:12:54.316 A:middle
of bedrooms, bathrooms, and

00:12:54.316 --> 00:12:55.126 A:middle
parking spaces.

00:12:56.556 --> 00:12:57.956 A:middle
Like the Classifier, the

00:12:57.956 --> 00:12:59.546 A:middle
Regressor also automatically

00:12:59.546 --> 00:13:01.386 A:middle
detects the best of multiple

00:12:59.546 --> 00:13:01.386 A:middle
detects the best of multiple

00:13:01.386 --> 00:13:02.336 A:middle
regressors for your data.

00:13:03.176 --> 00:13:03.866 A:middle
Though, you still have the

00:13:03.866 --> 00:13:06.146 A:middle
flexibility to choose a specific

00:13:06.256 --> 00:13:08.436 A:middle
boosted or decision tree, random

00:13:08.506 --> 00:13:10.356 A:middle
forest, or linear regressor, if

00:13:10.356 --> 00:13:11.426 A:middle
you like.

00:13:12.026 --> 00:13:14.056 A:middle
And our last model is the

00:13:14.056 --> 00:13:16.036 A:middle
Recommender which allows you to

00:13:16.036 --> 00:13:17.996 A:middle
recommend content based on user

00:13:17.996 --> 00:13:18.536 A:middle
behavior.

00:13:19.626 --> 00:13:20.866 A:middle
The Recommender can be trained

00:13:20.866 --> 00:13:23.306 A:middle
on user-item interactions with

00:13:23.306 --> 00:13:24.276 A:middle
or without ratings.

00:13:24.576 --> 00:13:26.206 A:middle
And it's able to be deployed on

00:13:26.206 --> 00:13:28.586 A:middle
device, saving you the hassle of

00:13:28.736 --> 00:13:30.896 A:middle
setting up the server.

00:13:31.506 --> 00:13:33.376 A:middle
As we saw, Create ML comes with

00:13:33.446 --> 00:13:35.456 A:middle
great features to help you set

00:13:35.456 --> 00:13:36.356 A:middle
up your machine learning

00:13:36.356 --> 00:13:38.616 A:middle
experiments, use native support

00:13:38.666 --> 00:13:40.726 A:middle
for data visualization, metrics,

00:13:40.856 --> 00:13:41.596 A:middle
and performance.

00:13:42.336 --> 00:13:43.796 A:middle
And the machine learning models

00:13:43.796 --> 00:13:45.606 A:middle
you train can easily be saved

00:13:45.606 --> 00:13:46.906 A:middle
and shared with members of your

00:13:47.016 --> 00:13:47.286 A:middle
team.

00:13:48.536 --> 00:13:50.366 A:middle
Of course, all of this leverages

00:13:50.406 --> 00:13:52.076 A:middle
the power and efficiency of

00:13:52.106 --> 00:13:53.216 A:middle
training on your Mac.

00:13:55.206 --> 00:13:56.866 A:middle
This new medium augments other

00:13:56.866 --> 00:13:58.266 A:middle
ways you have available to you

00:13:58.546 --> 00:13:59.566 A:middle
to create machine learning

00:13:59.566 --> 00:14:01.166 A:middle
models such as in Swift

00:13:59.566 --> 00:14:01.166 A:middle
models such as in Swift

00:14:01.236 --> 00:14:02.976 A:middle
Playgrounds, Swift Scripts, or

00:14:03.056 --> 00:14:04.556 A:middle
Swift Frepple [phonetic], Xcode

00:14:04.556 --> 00:14:04.856 A:middle
Playground.

00:14:05.716 --> 00:14:07.276 A:middle
But allows you to do so without

00:14:07.276 --> 00:14:09.486 A:middle
writing a single line of code.

00:14:10.456 --> 00:14:12.166 A:middle
We believe this brings machine

00:14:12.166 --> 00:14:13.706 A:middle
learning to everyone.

00:14:15.376 --> 00:14:17.446 A:middle
To summarize, in Create ML this

00:14:17.516 --> 00:14:19.876 A:middle
year, you have new models, nine

00:14:19.936 --> 00:14:21.536 A:middle
templates, and a whole new

00:14:21.536 --> 00:14:21.946 A:middle
workflow.

00:14:22.516 --> 00:14:28.500 A:middle
[ Applause ]
