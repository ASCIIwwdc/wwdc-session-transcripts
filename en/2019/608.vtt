WEBVTT

00:00:00.506 --> 00:00:05.500 A:middle
[ Music ]

00:00:11.516 --> 00:00:14.566 A:middle
[ Applause ]

00:00:15.066 --> 00:00:16.606 A:middle
&gt;&gt; Welcome to the Metal for Pro

00:00:16.606 --> 00:00:17.186 A:middle
Apps session.

00:00:17.506 --> 00:00:19.286 A:middle
My name is Eugene, and together

00:00:19.286 --> 00:00:20.856 A:middle
with Dileep and Brian, we'll be

00:00:20.856 --> 00:00:22.586 A:middle
talking about utilizing Metal to

00:00:22.586 --> 00:00:24.236 A:middle
enable new workflows and unleash

00:00:24.346 --> 00:00:26.416 A:middle
all the power of Macs and iPads

00:00:26.496 --> 00:00:28.076 A:middle
for your Pro applications.

00:00:28.996 --> 00:00:30.636 A:middle
But what is a Pro App?

00:00:31.156 --> 00:00:32.976 A:middle
We at Apple define it as an

00:00:32.976 --> 00:00:35.316 A:middle
application used by creative

00:00:35.396 --> 00:00:36.896 A:middle
professionals in the content

00:00:36.896 --> 00:00:37.666 A:middle
making business.

00:00:37.866 --> 00:00:39.796 A:middle
That includes animators and live

00:00:39.796 --> 00:00:42.616 A:middle
TV, photography, 3D animation,

00:00:43.286 --> 00:00:44.516 A:middle
print media, and audio

00:00:44.516 --> 00:00:45.166 A:middle
production.

00:00:46.146 --> 00:00:48.106 A:middle
Additionally, it includes both

00:00:48.106 --> 00:00:49.496 A:middle
first party as well as

00:00:49.496 --> 00:00:51.106 A:middle
third-party apps created by

00:00:51.386 --> 00:00:52.216 A:middle
developers like you.

00:00:53.026 --> 00:00:56.926 A:middle
These are apps such as Autodesk

00:00:57.736 --> 00:00:59.686 A:middle
Maya for 3D animation rigging

00:00:59.686 --> 00:01:02.456 A:middle
and visual effects or maybe

00:00:59.686 --> 00:01:02.456 A:middle
and visual effects or maybe

00:01:02.456 --> 00:01:05.586 A:middle
Logic Pro for audio and music

00:01:05.636 --> 00:01:06.076 A:middle
production.

00:01:06.076 --> 00:01:10.156 A:middle
Serif Labs Affinity Photo for

00:01:10.156 --> 00:01:12.056 A:middle
professional image editing or

00:01:13.106 --> 00:01:14.686 A:middle
Black Magic's DaVinci Resolve,

00:01:15.166 --> 00:01:16.336 A:middle
professional application for

00:01:16.336 --> 00:01:17.636 A:middle
video editing.

00:01:18.636 --> 00:01:20.226 A:middle
Pro apps have always been an

00:01:20.226 --> 00:01:22.266 A:middle
important of our ecosystem, and

00:01:22.266 --> 00:01:23.806 A:middle
with the recent release of the

00:01:23.806 --> 00:01:26.476 A:middle
new Mac Pro our new Pro Display

00:01:26.726 --> 00:01:29.356 A:middle
XDR robust support for external

00:01:29.356 --> 00:01:30.956 A:middle
GPU's and the new A12X

00:01:30.956 --> 00:01:32.856 A:middle
bionic-powered iPad pro.

00:01:33.166 --> 00:01:34.626 A:middle
We really doubled down on our

00:01:34.686 --> 00:01:36.206 A:middle
focus and commitment in this

00:01:36.206 --> 00:01:36.556 A:middle
space.

00:01:37.526 --> 00:01:39.066 A:middle
So why are pro apps different

00:01:39.066 --> 00:01:40.166 A:middle
from other workloads?

00:01:41.316 --> 00:01:43.156 A:middle
One key thing is that they

00:01:43.156 --> 00:01:44.806 A:middle
operate on really large assets.

00:01:45.486 --> 00:01:47.066 A:middle
This includes up to 8K video,

00:01:47.686 --> 00:01:49.296 A:middle
billions of polygons, thousands

00:01:49.296 --> 00:01:50.936 A:middle
of photos, hundreds of audio

00:01:50.936 --> 00:01:51.486 A:middle
tracks.

00:01:52.406 --> 00:01:56.466 A:middle
They also require a lot of CPU

00:01:56.466 --> 00:01:57.966 A:middle
and GPU horsepower.

00:01:58.536 --> 00:02:01.246 A:middle
Finally, there is always the

00:01:58.536 --> 00:02:01.246 A:middle
Finally, there is always the

00:02:01.246 --> 00:02:04.726 A:middle
challenge of achieving real-time

00:02:04.806 --> 00:02:06.096 A:middle
interaction while maintaining

00:02:06.096 --> 00:02:07.496 A:middle
the full fidelity of the

00:02:07.496 --> 00:02:08.175 A:middle
original content.

00:02:08.826 --> 00:02:10.216 A:middle
So let's go to the agenda of

00:02:10.485 --> 00:02:11.045 A:middle
today's talk.

00:02:12.376 --> 00:02:14.146 A:middle
First, we'll introduce the video

00:02:14.146 --> 00:02:15.306 A:middle
editing pipeline on our

00:02:15.306 --> 00:02:17.306 A:middle
platforms and discuss how to

00:02:17.306 --> 00:02:19.016 A:middle
optimize it for groundbreaking

00:02:19.016 --> 00:02:19.476 A:middle
8K.

00:02:20.236 --> 00:02:21.956 A:middle
Next, we'll talk about how you

00:02:21.956 --> 00:02:24.296 A:middle
can add HDR support to your app.

00:02:25.126 --> 00:02:28.126 A:middle
Then, we show you how to scale

00:02:28.126 --> 00:02:30.516 A:middle
across all CPU ports and GPU

00:02:30.516 --> 00:02:30.846 A:middle
channels.

00:02:31.456 --> 00:02:33.406 A:middle
And finally, we'll discuss how

00:02:33.406 --> 00:02:35.216 A:middle
to achieve most efficient data

00:02:35.216 --> 00:02:35.726 A:middle
transfers.

00:02:36.866 --> 00:02:38.866 A:middle
So let's start by talking about

00:02:38.866 --> 00:02:40.646 A:middle
the video editing pipeline with

00:02:40.646 --> 00:02:41.926 A:middle
8K content in mind.

00:02:43.156 --> 00:02:44.816 A:middle
We at Apple find video editing

00:02:44.816 --> 00:02:46.396 A:middle
as one of the most demanding and

00:02:46.606 --> 00:02:47.686 A:middle
creative workloads.

00:02:48.086 --> 00:02:50.186 A:middle
So we will use video apps as a

00:02:50.186 --> 00:02:52.656 A:middle
use case to show how Metal helps

00:02:52.656 --> 00:02:52.726 A:middle
you.

00:02:53.446 --> 00:02:55.356 A:middle
But before we start, I'd like to

00:02:55.356 --> 00:02:56.336 A:middle
give a huge thanks to our

00:02:56.336 --> 00:02:57.616 A:middle
friends at Black Magic Design.

00:02:58.136 --> 00:02:58.956 A:middle
We've been working with them

00:02:58.956 --> 00:03:00.976 A:middle
really closely optimizing both

00:02:58.956 --> 00:03:00.976 A:middle
really closely optimizing both

00:03:01.026 --> 00:03:02.546 A:middle
DaVinci Resolve and our platform

00:03:02.546 --> 00:03:05.006 A:middle
to unleash new 8K workflows, and

00:03:05.006 --> 00:03:06.436 A:middle
we're really proud of what we

00:03:06.436 --> 00:03:07.646 A:middle
have achieved together.

00:03:08.526 --> 00:03:10.736 A:middle
But let's see how it all worked

00:03:10.736 --> 00:03:13.416 A:middle
before when we first tried 8K

00:03:13.416 --> 00:03:14.106 A:middle
[inaudible] content.

00:03:14.866 --> 00:03:16.756 A:middle
You see the result is not real

00:03:16.786 --> 00:03:17.016 A:middle
time.

00:03:17.666 --> 00:03:19.666 A:middle
We have heavy stuttering, and

00:03:19.666 --> 00:03:20.726 A:middle
the experience is not great.

00:03:22.026 --> 00:03:23.296 A:middle
So that doesn't work.

00:03:24.176 --> 00:03:25.576 A:middle
Let's see how professionals

00:03:25.756 --> 00:03:27.496 A:middle
worked around this problem.

00:03:28.036 --> 00:03:30.296 A:middle
So they have huge raw footage in

00:03:30.296 --> 00:03:30.706 A:middle
8K.

00:03:31.216 --> 00:03:34.386 A:middle
First, they transcoded to get

00:03:34.386 --> 00:03:36.296 A:middle
all the [inaudible].

00:03:36.526 --> 00:03:38.336 A:middle
Then they sub-sampled and

00:03:38.336 --> 00:03:39.696 A:middle
downscaled it to 4K proxy.

00:03:40.046 --> 00:03:41.996 A:middle
So they can apply edits and

00:03:41.996 --> 00:03:43.686 A:middle
affects in real time, but there

00:03:43.686 --> 00:03:45.376 A:middle
is one really important catch.

00:03:46.256 --> 00:03:48.226 A:middle
You cannot color grade proxy

00:03:48.226 --> 00:03:49.596 A:middle
data simply because it's not

00:03:49.596 --> 00:03:50.046 A:middle
accurate.

00:03:50.626 --> 00:03:52.426 A:middle
So now you have to go back and

00:03:52.426 --> 00:03:54.406 A:middle
apply all of your edits to the

00:03:54.406 --> 00:03:56.386 A:middle
original content, run an offline

00:03:56.386 --> 00:03:58.106 A:middle
render job which may take hours.

00:03:58.736 --> 00:04:00.636 A:middle
Review it with your director and

00:03:58.736 --> 00:04:00.636 A:middle
Review it with your director and

00:04:00.636 --> 00:04:01.656 A:middle
then rinse and repeat.

00:04:02.616 --> 00:04:04.076 A:middle
We at Apple want to make it

00:04:04.076 --> 00:04:05.666 A:middle
faster for our users.

00:04:06.586 --> 00:04:08.076 A:middle
We really want all the

00:04:08.076 --> 00:04:09.486 A:middle
professionals to work straight

00:04:09.486 --> 00:04:11.356 A:middle
in 8K content out of the box.

00:04:11.866 --> 00:04:12.966 A:middle
So let me tell you the story of

00:04:13.006 --> 00:04:14.796 A:middle
how we enabled real time video

00:04:14.796 --> 00:04:16.226 A:middle
editing in 8K.

00:04:17.476 --> 00:04:19.206 A:middle
So it starts with building an

00:04:19.206 --> 00:04:20.245 A:middle
efficient video editing

00:04:20.245 --> 00:04:20.875 A:middle
pipeline.

00:04:21.526 --> 00:04:23.166 A:middle
We'll cover the general design

00:04:23.166 --> 00:04:24.916 A:middle
of an efficient pipeline, what

00:04:24.916 --> 00:04:26.516 A:middle
frameworks to use, and how to

00:04:26.516 --> 00:04:28.246 A:middle
maximize all the available

00:04:28.246 --> 00:04:28.646 A:middle
hardware.

00:04:29.726 --> 00:04:31.626 A:middle
Then, we'll discuss how to

00:04:31.626 --> 00:04:33.476 A:middle
manage real large assets.

00:04:33.996 --> 00:04:35.746 A:middle
And finally, we'll tell you

00:04:36.446 --> 00:04:37.796 A:middle
about some challenges you might

00:04:37.796 --> 00:04:39.166 A:middle
face trying to maintain a

00:04:39.456 --> 00:04:41.056 A:middle
predictable frame rate and how

00:04:41.056 --> 00:04:41.836 A:middle
to overcome them.

00:04:42.986 --> 00:04:45.026 A:middle
So let's dive into the video

00:04:45.026 --> 00:04:45.756 A:middle
editing pipeline.

00:04:47.476 --> 00:04:49.366 A:middle
Here are typical building blocks

00:04:49.366 --> 00:04:52.366 A:middle
most video editing apps need to

00:04:52.366 --> 00:04:52.666 A:middle
have.

00:04:53.366 --> 00:04:54.546 A:middle
So we start by reading the

00:04:54.546 --> 00:04:56.376 A:middle
content, then we need to decode

00:04:56.376 --> 00:04:57.746 A:middle
it so we can process it.

00:04:57.886 --> 00:04:59.936 A:middle
And finally, present or encode.

00:05:00.696 --> 00:05:02.846 A:middle
In today's session, I'll be

00:05:02.846 --> 00:05:05.906 A:middle
focusing on the decode process,

00:05:05.906 --> 00:05:07.226 A:middle
encode and display blocks.

00:05:07.696 --> 00:05:08.926 A:middle
We will be covering the import

00:05:08.926 --> 00:05:10.356 A:middle
and export blocks which

00:05:10.356 --> 00:05:11.726 A:middle
typically use AVFoundation

00:05:11.786 --> 00:05:12.106 A:middle
framework.

00:05:12.696 --> 00:05:14.506 A:middle
I encourage you to check out our

00:05:14.506 --> 00:05:16.446 A:middle
samples on AVAssetReader and

00:05:16.446 --> 00:05:17.206 A:middle
AVAssetWriter.

00:05:17.806 --> 00:05:21.226 A:middle
Let's dive in how to make

00:05:21.226 --> 00:05:23.256 A:middle
decoding part closer to Metal.

00:05:24.696 --> 00:05:26.316 A:middle
Apple provides a flexible

00:05:26.316 --> 00:05:27.906 A:middle
low-level framework called Video

00:05:27.906 --> 00:05:29.446 A:middle
Toolbox to achieve efficient,

00:05:29.806 --> 00:05:31.056 A:middle
high-performance video

00:05:31.296 --> 00:05:31.776 A:middle
processing.

00:05:32.346 --> 00:05:34.266 A:middle
It can be used on iOS, macOS,

00:05:34.266 --> 00:05:36.626 A:middle
and tvOS, supports a huge number

00:05:36.626 --> 00:05:38.476 A:middle
of formats and leverages any

00:05:38.476 --> 00:05:40.066 A:middle
available hardware on our

00:05:40.066 --> 00:05:40.506 A:middle
devices.

00:05:41.526 --> 00:05:42.766 A:middle
The building block for the

00:05:42.766 --> 00:05:44.016 A:middle
decode is a decompression

00:05:44.016 --> 00:05:45.696 A:middle
session, and I can quickly show

00:05:45.696 --> 00:05:47.006 A:middle
you how to set it up.

00:05:47.826 --> 00:05:50.506 A:middle
First, we specify that we want

00:05:50.506 --> 00:05:51.526 A:middle
to use [inaudible] video

00:05:51.526 --> 00:05:52.006 A:middle
decoding.

00:05:53.146 --> 00:05:55.296 A:middle
Then we create a session for

00:05:55.296 --> 00:05:56.596 A:middle
each video stream.

00:05:57.296 --> 00:05:58.736 A:middle
We set it up with a completion

00:05:58.736 --> 00:05:59.366 A:middle
handler here.

00:06:01.216 --> 00:06:04.466 A:middle
While we go through our video

00:06:04.466 --> 00:06:07.176 A:middle
stream we call decode frame with

00:06:07.176 --> 00:06:08.196 A:middle
an [inaudible] flag.

00:06:08.196 --> 00:06:09.746 A:middle
This is really important to make

00:06:09.746 --> 00:06:10.976 A:middle
the code [inaudible].

00:06:11.776 --> 00:06:13.156 A:middle
Apple frame decode completion,

00:06:13.526 --> 00:06:15.076 A:middle
our callback is going to be

00:06:15.076 --> 00:06:15.246 A:middle
called.

00:06:15.246 --> 00:06:18.016 A:middle
And finally please don't forget

00:06:18.066 --> 00:06:20.126 A:middle
to clean up after you are done.

00:06:20.606 --> 00:06:23.126 A:middle
So now we know how to decompress

00:06:23.126 --> 00:06:23.666 A:middle
our frames.

00:06:24.196 --> 00:06:25.776 A:middle
Now let's talk about how to make

00:06:25.776 --> 00:06:27.106 A:middle
sure that we are doing it in a

00:06:27.106 --> 00:06:28.216 A:middle
most optimal way.

00:06:30.066 --> 00:06:32.416 A:middle
Your Mac might have set several

00:06:32.416 --> 00:06:34.236 A:middle
hardware decoding blocks

00:06:34.236 --> 00:06:34.776 A:middle
available.

00:06:35.186 --> 00:06:36.766 A:middle
To make sure we are using the

00:06:36.766 --> 00:06:38.816 A:middle
same physical memory with zero

00:06:38.816 --> 00:06:39.846 A:middle
copies we'll leverage an

00:06:39.846 --> 00:06:41.086 A:middle
internal object called an

00:06:41.086 --> 00:06:41.826 A:middle
IOSurface.

00:06:42.846 --> 00:06:45.276 A:middle
IOSurface is a hardware

00:06:45.276 --> 00:06:47.516 A:middle
accelerated image buffer with

00:06:47.516 --> 00:06:48.916 A:middle
GPU [inaudible] tracking.

00:06:49.616 --> 00:06:51.416 A:middle
It also gives you interprocess

00:06:51.496 --> 00:06:53.376 A:middle
and interframework access to the

00:06:53.376 --> 00:06:55.206 A:middle
same GPU memory so it's perfect

00:06:55.206 --> 00:06:56.666 A:middle
for this scenario.

00:06:57.696 --> 00:06:59.546 A:middle
Core Video and Metal provides

00:07:00.046 --> 00:07:02.426 A:middle
you an easy way to leverage the

00:07:02.426 --> 00:07:04.136 A:middle
benefits of IOSurface using an

00:07:04.186 --> 00:07:05.006 A:middle
object called

00:07:05.356 --> 00:07:06.716 A:middle
CVMetalTextureCache.

00:07:07.196 --> 00:07:08.706 A:middle
Let's see how to set it up.

00:07:09.936 --> 00:07:12.976 A:middle
So here we create our

00:07:12.976 --> 00:07:15.286 A:middle
CVMetalTextureCache, and we want

00:07:15.286 --> 00:07:16.686 A:middle
to make sure we use the Metal

00:07:16.686 --> 00:07:18.196 A:middle
device we're going to be using

00:07:18.196 --> 00:07:19.346 A:middle
for pixel processing.

00:07:19.786 --> 00:07:22.446 A:middle
So next whenever we get a new CV

00:07:22.446 --> 00:07:23.936 A:middle
pixel buffer, we need to turn it

00:07:23.936 --> 00:07:24.886 A:middle
into a Metal texture.

00:07:25.306 --> 00:07:26.996 A:middle
It happens automatically at zero

00:07:26.996 --> 00:07:28.716 A:middle
cost if our pixel buffer is

00:07:28.836 --> 00:07:30.186 A:middle
backed by an IOSurface.

00:07:30.986 --> 00:07:33.206 A:middle
Finally, don't forget to clean

00:07:33.206 --> 00:07:34.446 A:middle
up your textures and pixel

00:07:34.446 --> 00:07:36.336 A:middle
buffers to ensure proper reuse

00:07:36.436 --> 00:07:39.506 A:middle
in the texture cache.

00:07:39.836 --> 00:07:41.556 A:middle
So now we have our frame as an

00:07:41.556 --> 00:07:43.986 A:middle
MTL texture, and we are ready to

00:07:43.986 --> 00:07:45.066 A:middle
do some pixel processing.

00:07:45.366 --> 00:07:47.196 A:middle
Here we have several options.

00:07:48.706 --> 00:07:50.406 A:middle
Of course, we can write our own

00:07:50.406 --> 00:07:51.896 A:middle
processing and grading kernels

00:07:52.206 --> 00:07:53.346 A:middle
and it's really easy since

00:07:53.346 --> 00:07:54.576 A:middle
Metal's [inaudible] language is

00:07:54.796 --> 00:07:55.676 A:middle
C++ based.

00:07:55.676 --> 00:07:58.196 A:middle
At the same time, we highly

00:07:58.196 --> 00:07:59.646 A:middle
encourage you to use Metal

00:07:59.816 --> 00:08:01.186 A:middle
performance shaders to do your

00:07:59.816 --> 00:08:01.186 A:middle
performance shaders to do your

00:08:01.186 --> 00:08:01.946 A:middle
pixel processing.

00:08:02.416 --> 00:08:03.446 A:middle
You can even build your own

00:08:03.446 --> 00:08:04.976 A:middle
neural network as part of your

00:08:04.976 --> 00:08:05.446 A:middle
pipeline.

00:08:06.826 --> 00:08:08.666 A:middle
Now let's see how to use MPS to

00:08:08.666 --> 00:08:10.726 A:middle
run a typical blur filter.

00:08:12.076 --> 00:08:13.766 A:middle
So we start with the Metal queue

00:08:14.276 --> 00:08:15.716 A:middle
and the common buffer.

00:08:17.516 --> 00:08:20.356 A:middle
We create a Gaussian blur

00:08:20.536 --> 00:08:23.246 A:middle
kernel, one of many built into

00:08:23.996 --> 00:08:24.346 A:middle
MPS.

00:08:24.346 --> 00:08:26.066 A:middle
And now, we can attempt to

00:08:26.066 --> 00:08:27.926 A:middle
encode the work in place and we

00:08:28.106 --> 00:08:29.666 A:middle
provide a fallback allocator in

00:08:29.666 --> 00:08:31.996 A:middle
the case it fails.

00:08:31.996 --> 00:08:33.515 A:middle
And, finally, we commit our

00:08:33.716 --> 00:08:34.246 A:middle
common buffer.

00:08:34.666 --> 00:08:36.616 A:middle
MPS is a really powerful

00:08:36.616 --> 00:08:38.916 A:middle
framework tuned for every device

00:08:38.916 --> 00:08:40.256 A:middle
on our platform.

00:08:40.326 --> 00:08:41.666 A:middle
We encourage you to read more

00:08:41.666 --> 00:08:43.206 A:middle
and start using it.

00:08:44.166 --> 00:08:45.576 A:middle
So we are done with the pixel

00:08:45.576 --> 00:08:47.016 A:middle
processing and we are ready to

00:08:47.116 --> 00:08:49.046 A:middle
encode our MTL texture to the

00:08:49.046 --> 00:08:49.766 A:middle
output format.

00:08:50.566 --> 00:08:52.986 A:middle
Of course, we will again use

00:08:52.986 --> 00:08:54.936 A:middle
Video Toolbox here and let me

00:08:54.936 --> 00:08:56.456 A:middle
show you how to do that in the

00:08:56.456 --> 00:08:58.326 A:middle
most efficient way.

00:08:58.956 --> 00:09:00.316 A:middle
Your new Mac Pro might have

00:08:58.956 --> 00:09:00.316 A:middle
Your new Mac Pro might have

00:09:00.316 --> 00:09:02.336 A:middle
several GPU's and each of them

00:09:02.456 --> 00:09:03.426 A:middle
might have more than one

00:09:03.426 --> 00:09:04.196 A:middle
encoding engine.

00:09:08.936 --> 00:09:10.446 A:middle
Of course, we can let Video

00:09:10.446 --> 00:09:12.166 A:middle
Toolbox be the best available

00:09:12.166 --> 00:09:13.996 A:middle
device, but in many cases you'll

00:09:13.996 --> 00:09:15.206 A:middle
want to specify a device

00:09:15.276 --> 00:09:17.596 A:middle
explicitly to minimize copy

00:09:17.596 --> 00:09:18.076 A:middle
overhead.

00:09:18.326 --> 00:09:20.546 A:middle
So let's see how we do this and

00:09:20.546 --> 00:09:22.246 A:middle
how to use CVPixelBufferPool to

00:09:22.246 --> 00:09:23.506 A:middle
keep memory recycled.

00:09:28.106 --> 00:09:29.826 A:middle
So here is how we get a list of

00:09:30.056 --> 00:09:31.456 A:middle
all available encoders.

00:09:32.566 --> 00:09:34.506 A:middle
First, we use the enable

00:09:34.876 --> 00:09:35.896 A:middle
[inaudible] to ensure we are

00:09:35.896 --> 00:09:37.766 A:middle
leveraging hardware encoding.

00:09:38.276 --> 00:09:39.996 A:middle
Then, we tell Video Toolbox

00:09:40.136 --> 00:09:41.366 A:middle
which device we want to use.

00:09:41.456 --> 00:09:43.386 A:middle
This is a critical step to

00:09:43.386 --> 00:09:44.566 A:middle
ensure we're encoding on the

00:09:44.566 --> 00:09:46.436 A:middle
same device we did our pixel

00:09:46.436 --> 00:09:46.946 A:middle
processing.

00:09:48.386 --> 00:09:49.896 A:middle
Another great thing here is we

00:09:49.896 --> 00:09:51.646 A:middle
can use CVPixelBufferPool to get

00:09:51.646 --> 00:09:53.426 A:middle
the surfaces in the exact format

00:09:53.726 --> 00:09:55.546 A:middle
used by the hardware encoder.

00:09:57.366 --> 00:09:58.836 A:middle
So this is how we get a buffer

00:09:59.146 --> 00:10:00.836 A:middle
from the pool and then we use

00:09:59.146 --> 00:10:00.836 A:middle
from the pool and then we use

00:10:01.166 --> 00:10:02.666 A:middle
MetalTextureCache again.

00:10:03.306 --> 00:10:05.506 A:middle
Now we can convert our

00:10:05.836 --> 00:10:07.546 A:middle
[inaudible] process data to

00:10:07.546 --> 00:10:08.896 A:middle
[inaudible] format which is what

00:10:08.896 --> 00:10:09.976 A:middle
Video Toolbox needs.

00:10:10.846 --> 00:10:12.696 A:middle
And, as usual, we clean up

00:10:12.696 --> 00:10:14.246 A:middle
everything to keep buffers

00:10:15.786 --> 00:10:17.016 A:middle
recycled.

00:10:17.016 --> 00:10:18.976 A:middle
So we can now build the most

00:10:18.976 --> 00:10:21.256 A:middle
efficient pipeline possible and

00:10:21.256 --> 00:10:22.076 A:middle
that's really great.

00:10:22.846 --> 00:10:24.106 A:middle
We'll cover display section

00:10:24.106 --> 00:10:25.546 A:middle
separately and now let's talk

00:10:25.546 --> 00:10:26.826 A:middle
about 8K for a bit.

00:10:28.256 --> 00:10:30.716 A:middle
8K means really large assets.

00:10:31.076 --> 00:10:32.676 A:middle
So let's see how to deal with

00:10:32.676 --> 00:10:32.776 A:middle
them.

00:10:33.786 --> 00:10:35.116 A:middle
First, let's do the math.

00:10:35.636 --> 00:10:37.466 A:middle
An 8K frame is just huge.

00:10:38.286 --> 00:10:40.456 A:middle
It is 16 times larger than an HD

00:10:40.456 --> 00:10:42.566 A:middle
frame totaling up to 270

00:10:42.566 --> 00:10:44.256 A:middle
megabytes uncompressed.

00:10:44.786 --> 00:10:49.256 A:middle
And we have to send almost 300

00:10:49.256 --> 00:10:50.336 A:middle
megabytes every frame.

00:10:50.666 --> 00:10:52.296 A:middle
So for 30 frames per second we

00:10:52.296 --> 00:10:54.316 A:middle
have nine gigabytes per second

00:10:54.316 --> 00:10:55.016 A:middle
of bandwidth.

00:10:55.386 --> 00:10:56.796 A:middle
It's really close to the PCI

00:10:56.796 --> 00:10:57.456 A:middle
Express limit.

00:10:58.236 --> 00:10:59.826 A:middle
Moreover, even with [inaudible]

00:10:59.826 --> 00:11:01.916 A:middle
4 by 4 compression, a 10-minute

00:10:59.826 --> 00:11:01.916 A:middle
4 by 4 compression, a 10-minute

00:11:02.246 --> 00:11:04.496 A:middle
clip can easily take massive one

00:11:04.726 --> 00:11:05.256 A:middle
terabyte.

00:11:05.796 --> 00:11:07.636 A:middle
This creates a real challenge

00:11:08.006 --> 00:11:09.216 A:middle
for real-time playback.

00:11:09.556 --> 00:11:11.596 A:middle
So let's see what it looks like

00:11:11.596 --> 00:11:12.986 A:middle
when we trace it using

00:11:12.986 --> 00:11:14.996 A:middle
instruments in [inaudible].

00:11:15.206 --> 00:11:17.456 A:middle
So here is a system trace for

00:11:17.456 --> 00:11:18.936 A:middle
the video playback session we

00:11:18.936 --> 00:11:19.546 A:middle
showed earlier.

00:11:20.666 --> 00:11:22.116 A:middle
If we zoom into the Virtual

00:11:22.116 --> 00:11:23.666 A:middle
Memory Track, we see a huge

00:11:23.666 --> 00:11:24.756 A:middle
amount of page folds.

00:11:26.056 --> 00:11:27.346 A:middle
And the associated [inaudible]

00:11:27.426 --> 00:11:28.676 A:middle
cost is really high.

00:11:29.066 --> 00:11:30.226 A:middle
We can see it below.

00:11:31.226 --> 00:11:32.746 A:middle
So that naturally explains why

00:11:32.746 --> 00:11:33.986 A:middle
all the decoding threads are

00:11:33.986 --> 00:11:35.746 A:middle
stuck and cannot proceed.

00:11:37.066 --> 00:11:38.366 A:middle
We need to manage our memory

00:11:38.576 --> 00:11:39.536 A:middle
more carefully.

00:11:40.086 --> 00:11:43.816 A:middle
[Inaudible] an operating system

00:11:43.816 --> 00:11:44.916 A:middle
don't actually physically

00:11:44.916 --> 00:11:46.346 A:middle
allocate memory pages until they

00:11:46.346 --> 00:11:46.706 A:middle
are used.

00:11:47.096 --> 00:11:48.756 A:middle
So once we start accessing all

00:11:48.756 --> 00:11:50.056 A:middle
of these new pages from many

00:11:50.056 --> 00:11:51.306 A:middle
decoding [inaudible] we have to

00:11:51.306 --> 00:11:53.136 A:middle
wait for the system to map all

00:11:53.136 --> 00:11:54.116 A:middle
those pages for us.

00:11:55.166 --> 00:11:56.006 A:middle
The way to figure that is

00:11:56.006 --> 00:11:56.516 A:middle
simple.

00:11:56.816 --> 00:11:59.506 A:middle
Pre-warm your CPU buffers before

00:11:59.506 --> 00:12:01.596 A:middle
use to make sure all the pages

00:11:59.506 --> 00:12:01.596 A:middle
use to make sure all the pages

00:12:01.596 --> 00:12:03.536 A:middle
are resident before playback

00:12:04.376 --> 00:12:05.386 A:middle
starts.

00:12:06.086 --> 00:12:07.746 A:middle
Now let me give you a few more

00:12:07.806 --> 00:12:10.946 A:middle
memory management tips.

00:12:11.076 --> 00:12:12.606 A:middle
Every allocation has a system

00:12:12.606 --> 00:12:12.956 A:middle
call.

00:12:13.306 --> 00:12:15.246 A:middle
One simple rule is to allocate

00:12:15.246 --> 00:12:16.586 A:middle
early enough and avoid

00:12:16.816 --> 00:12:18.246 A:middle
mid-workflow allocations.

00:12:18.966 --> 00:12:21.036 A:middle
Another good advice is to always

00:12:21.036 --> 00:12:22.146 A:middle
reuse your buffers.

00:12:22.556 --> 00:12:24.326 A:middle
This is why it's so important to

00:12:24.326 --> 00:12:25.666 A:middle
use objects such as

00:12:25.666 --> 00:12:27.116 A:middle
CVPixelBufferPool and

00:12:27.346 --> 00:12:28.716 A:middle
CVMetalTextureCache.

00:12:30.016 --> 00:12:31.746 A:middle
So now we have improved the way

00:12:31.746 --> 00:12:34.076 A:middle
we manage our frames but there

00:12:34.076 --> 00:12:35.796 A:middle
are always many, many smaller

00:12:35.796 --> 00:12:37.636 A:middle
allocations needed along the

00:12:37.636 --> 00:12:38.926 A:middle
lifetime of your app.

00:12:39.226 --> 00:12:40.426 A:middle
Let me give you some tips on how

00:12:40.426 --> 00:12:41.056 A:middle
to manage those.

00:12:41.706 --> 00:12:44.236 A:middle
With MTLheap's we can

00:12:44.236 --> 00:12:45.836 A:middle
efficiently manage all of our

00:12:46.086 --> 00:12:47.216 A:middle
transit allocations.

00:12:47.906 --> 00:12:49.106 A:middle
Allocating from a MTLheap

00:12:49.286 --> 00:12:51.266 A:middle
doesn't require a kernel call

00:12:51.386 --> 00:12:52.336 A:middle
since the entire heap is

00:12:52.336 --> 00:12:54.286 A:middle
allocated at creation time.

00:12:54.756 --> 00:12:56.436 A:middle
The heap is a monolithic

00:12:56.436 --> 00:12:58.266 A:middle
resource from the system's point

00:12:58.266 --> 00:12:58.526 A:middle
of view.

00:12:58.946 --> 00:13:00.306 A:middle
So it's made resident as a

00:12:58.946 --> 00:13:00.306 A:middle
So it's made resident as a

00:13:00.306 --> 00:13:00.826 A:middle
whole.

00:13:01.936 --> 00:13:03.366 A:middle
Also, allocating from heap

00:13:03.806 --> 00:13:05.496 A:middle
allows for tighter memory

00:13:05.946 --> 00:13:06.096 A:middle
packing,

00:13:06.716 --> 00:13:08.266 A:middle
and with heaps you can alias

00:13:08.266 --> 00:13:10.096 A:middle
resource memory within the

00:13:10.096 --> 00:13:10.756 A:middle
common buffer.

00:13:11.036 --> 00:13:12.346 A:middle
Something we trust impossible

00:13:12.346 --> 00:13:13.486 A:middle
with the regular buffers.

00:13:13.976 --> 00:13:15.626 A:middle
Let me show you how to do this.

00:13:16.976 --> 00:13:18.446 A:middle
In this sample, we will be

00:13:18.446 --> 00:13:20.326 A:middle
aliasing transit allocations.

00:13:20.746 --> 00:13:23.066 A:middle
First, we created the heap using

00:13:23.066 --> 00:13:23.816 A:middle
our device.

00:13:24.296 --> 00:13:26.926 A:middle
Along the filter stages, we

00:13:27.136 --> 00:13:28.736 A:middle
created the uniforms for our

00:13:28.736 --> 00:13:31.006 A:middle
blur kernel from that heap.

00:13:32.046 --> 00:13:34.006 A:middle
Next, we allocate another buffer

00:13:34.006 --> 00:13:35.886 A:middle
for color grade uniforms from

00:13:35.886 --> 00:13:37.146 A:middle
that same heap.

00:13:37.736 --> 00:13:39.216 A:middle
So after the color grading

00:13:39.216 --> 00:13:40.326 A:middle
stage, we don't need those

00:13:40.326 --> 00:13:41.916 A:middle
anymore and we mark them as

00:13:41.916 --> 00:13:43.966 A:middle
aliasable, and the heap can

00:13:43.966 --> 00:13:45.486 A:middle
actually recycle that memory for

00:13:45.696 --> 00:13:46.846 A:middle
future allocations.

00:13:47.736 --> 00:13:49.596 A:middle
So when we allocate a new

00:13:49.626 --> 00:13:51.436 A:middle
intermediate buffer, the heap is

00:13:51.556 --> 00:13:53.566 A:middle
free to reuse any memory marked

00:13:53.566 --> 00:13:55.946 A:middle
as aliasable so this is really

00:13:55.946 --> 00:13:56.346 A:middle
efficient.

00:13:57.746 --> 00:13:59.236 A:middle
So that was a quick overview of

00:13:59.236 --> 00:14:01.046 A:middle
how to manage our resource

00:13:59.236 --> 00:14:01.046 A:middle
how to manage our resource

00:14:01.046 --> 00:14:01.696 A:middle
allocations.

00:14:02.306 --> 00:14:04.276 A:middle
Now let's talk about how to

00:14:04.486 --> 00:14:06.246 A:middle
present our friends with a

00:14:06.646 --> 00:14:08.306 A:middle
predictable frame rate.

00:14:09.146 --> 00:14:11.216 A:middle
So here is a timing sample for

00:14:11.416 --> 00:14:13.026 A:middle
triple buffer Metal application.

00:14:14.016 --> 00:14:15.476 A:middle
In this example, we're playing a

00:14:15.476 --> 00:14:17.986 A:middle
30-hertz video on a 60-hertz

00:14:18.056 --> 00:14:18.396 A:middle
display.

00:14:19.106 --> 00:14:20.546 A:middle
Notice how the frames are

00:14:20.546 --> 00:14:21.776 A:middle
showing up on the display at a

00:14:21.776 --> 00:14:23.856 A:middle
non-uniform cadence.

00:14:24.566 --> 00:14:26.036 A:middle
Users feel it as stutters.

00:14:27.386 --> 00:14:29.276 A:middle
So why is this happening?

00:14:29.806 --> 00:14:32.436 A:middle
Note how the CPU is incurring

00:14:32.436 --> 00:14:34.516 A:middle
GPU work without regard for

00:14:34.566 --> 00:14:34.896 A:middle
timing.

00:14:36.516 --> 00:14:38.056 A:middle
Once the third frame is

00:14:38.426 --> 00:14:39.376 A:middle
[inaudible], the CPU is blocked

00:14:39.736 --> 00:14:41.086 A:middle
waiting for a [inaudible] to

00:14:41.176 --> 00:14:42.606 A:middle
become available which is not

00:14:42.726 --> 00:14:44.496 A:middle
going to happen until frame one

00:14:44.496 --> 00:14:45.236 A:middle
leaves the glass.

00:14:46.756 --> 00:14:48.716 A:middle
So this approach maximizes GPU

00:14:48.956 --> 00:14:51.836 A:middle
utilization but produces visible

00:14:51.836 --> 00:14:52.366 A:middle
stutters.

00:14:53.626 --> 00:14:55.696 A:middle
We generally want each frame to

00:14:55.696 --> 00:14:57.276 A:middle
remain on the glass an equal

00:14:57.306 --> 00:14:59.266 A:middle
amount of time.

00:14:59.456 --> 00:15:01.296 A:middle
As a solution, Core Video offers

00:14:59.456 --> 00:15:01.296 A:middle
As a solution, Core Video offers

00:15:01.296 --> 00:15:02.166 A:middle
an interface called

00:15:02.316 --> 00:15:03.336 A:middle
CVDisplayLink.

00:15:03.646 --> 00:15:05.326 A:middle
This is a high-precision

00:15:05.446 --> 00:15:07.406 A:middle
low-level timer which notifies

00:15:07.406 --> 00:15:09.616 A:middle
you before every VBLANK at a

00:15:09.616 --> 00:15:10.896 A:middle
displaced refresh rate.

00:15:11.646 --> 00:15:13.736 A:middle
Rather than let the CPU

00:15:13.736 --> 00:15:14.976 A:middle
[inaudible] as many frames as

00:15:14.976 --> 00:15:17.266 A:middle
possible, We use display link to

00:15:17.496 --> 00:15:18.986 A:middle
determine the right time to

00:15:18.986 --> 00:15:20.906 A:middle
submit each frame to the GPU.

00:15:21.696 --> 00:15:23.886 A:middle
This significantly reduces video

00:15:23.886 --> 00:15:24.506 A:middle
playback jitter.

00:15:25.326 --> 00:15:26.386 A:middle
So let me show you the code

00:15:26.386 --> 00:15:28.766 A:middle
snippet how to do this.

00:15:28.966 --> 00:15:30.556 A:middle
We started by making a link with

00:15:30.556 --> 00:15:31.646 A:middle
the display we will be using.

00:15:32.206 --> 00:15:35.866 A:middle
Then, we set up our callback

00:15:35.866 --> 00:15:37.896 A:middle
handler and for every call we

00:15:37.966 --> 00:15:40.086 A:middle
will get the current time and

00:15:40.086 --> 00:15:41.396 A:middle
the next VBLANK time.

00:15:41.996 --> 00:15:43.436 A:middle
And we can use these values to

00:15:43.686 --> 00:15:44.996 A:middle
determine when to issue a

00:15:45.276 --> 00:15:46.716 A:middle
present call assuming we have

00:15:46.956 --> 00:15:47.876 A:middle
processed frames ready.

00:15:48.486 --> 00:15:50.616 A:middle
And we can adjust the desired

00:15:50.866 --> 00:15:52.246 A:middle
frequency to our needs.

00:15:53.206 --> 00:15:54.566 A:middle
So this will significantly

00:15:54.606 --> 00:15:56.286 A:middle
reduce stutters but we can take

00:15:56.286 --> 00:15:57.266 A:middle
it a step further.

00:15:58.086 --> 00:16:00.336 A:middle
For example, playing 24-hertz

00:15:58.086 --> 00:16:00.336 A:middle
For example, playing 24-hertz

00:16:00.396 --> 00:16:02.296 A:middle
content on a 60-hertz display,

00:16:02.666 --> 00:16:04.206 A:middle
we need three-two pull down.

00:16:04.596 --> 00:16:06.946 A:middle
It means we will present even

00:16:06.946 --> 00:16:08.916 A:middle
frames for three VBLANKS and odd

00:16:08.916 --> 00:16:11.066 A:middle
frames over two VBLANKS.

00:16:11.786 --> 00:16:13.486 A:middle
This is the best we can do given

00:16:13.486 --> 00:16:15.076 A:middle
the mismatch, and the code

00:16:15.076 --> 00:16:16.206 A:middle
snippet I just showed you will

00:16:16.206 --> 00:16:18.286 A:middle
handle this just fine, but the

00:16:18.286 --> 00:16:19.796 A:middle
good news is we can do even

00:16:19.796 --> 00:16:20.086 A:middle
better.

00:16:20.836 --> 00:16:23.386 A:middle
Our new Pro Display XDR supports

00:16:23.386 --> 00:16:25.546 A:middle
multiple refresh rates including

00:16:25.656 --> 00:16:26.446 A:middle
48-hertz.

00:16:26.966 --> 00:16:29.286 A:middle
So your 24-hertz content will

00:16:29.286 --> 00:16:31.286 A:middle
play extremely smoothly jitter

00:16:31.286 --> 00:16:31.546 A:middle
free.

00:16:32.906 --> 00:16:34.696 A:middle
So we have made quite a few

00:16:34.696 --> 00:16:36.036 A:middle
important optimizations.

00:16:37.036 --> 00:16:38.056 A:middle
Now I'd like to show you the

00:16:38.056 --> 00:16:38.726 A:middle
final result.

00:16:39.246 --> 00:16:40.586 A:middle
This is DaVinci Resolve now

00:16:41.126 --> 00:16:42.916 A:middle
playing that same 8k stream.

00:16:43.636 --> 00:16:44.866 A:middle
As you can see, playback is

00:16:44.866 --> 00:16:46.826 A:middle
smooth with no stutters.

00:16:47.366 --> 00:16:49.876 A:middle
This has been a great

00:16:50.046 --> 00:16:51.326 A:middle
collaboration for us with Black

00:16:51.326 --> 00:16:51.596 A:middle
Magic.

00:16:52.156 --> 00:16:53.576 A:middle
We achieved outstanding results

00:16:53.816 --> 00:16:55.296 A:middle
together, and we encourage you

00:16:55.546 --> 00:16:56.716 A:middle
to start leveraging our

00:16:56.956 --> 00:16:58.786 A:middle
high-performance frameworks and

00:16:58.786 --> 00:17:00.286 A:middle
start building new and exciting

00:16:58.786 --> 00:17:00.286 A:middle
start building new and exciting

00:17:00.496 --> 00:17:02.366 A:middle
pro apps for our platform.

00:17:02.856 --> 00:17:05.406 A:middle
We have tackled that 8k

00:17:05.406 --> 00:17:05.856 A:middle
challenge.

00:17:06.606 --> 00:17:08.786 A:middle
Now I'd like to invite Dileep to

00:17:08.786 --> 00:17:10.896 A:middle
talk about our support for HDR

00:17:11.616 --> 00:17:13.056 A:middle
and how you can enable it in

00:17:13.056 --> 00:17:13.406 A:middle
your app.

00:17:13.925 --> 00:17:14.195 A:middle
Dileep?

00:17:15.516 --> 00:17:20.046 A:middle
[ Applause ]

00:17:20.546 --> 00:17:21.705 A:middle
&gt;&gt; Thanks, Eugene.

00:17:22.396 --> 00:17:24.566 A:middle
In recent years high-dynamic

00:17:24.566 --> 00:17:26.346 A:middle
range rendering and displays

00:17:26.346 --> 00:17:27.756 A:middle
have greatly enhanced the

00:17:27.826 --> 00:17:29.576 A:middle
quality of images that we see on

00:17:29.576 --> 00:17:29.966 A:middle
screen.

00:17:30.936 --> 00:17:32.876 A:middle
At Apple we have been constantly

00:17:33.156 --> 00:17:34.246 A:middle
[inaudible] support to improve

00:17:34.246 --> 00:17:36.116 A:middle
the image technology.

00:17:36.626 --> 00:17:38.466 A:middle
As you know, we have added many

00:17:38.466 --> 00:17:40.416 A:middle
technologies such as retina

00:17:40.416 --> 00:17:43.176 A:middle
display, 4K and 5K resolution,

00:17:43.466 --> 00:17:45.866 A:middle
wide gamut color space and many

00:17:46.256 --> 00:17:47.796 A:middle
and have enabled you, the

00:17:47.796 --> 00:17:50.166 A:middle
developers, to create amazing

00:17:50.166 --> 00:17:51.826 A:middle
and high-quality images.

00:17:52.556 --> 00:17:54.326 A:middle
Continuing in that part, this

00:17:54.326 --> 00:17:56.576 A:middle
year we are adding great support

00:17:56.576 --> 00:17:58.656 A:middle
for HDR on macOS.

00:17:59.336 --> 00:18:00.726 A:middle
I'm excited to give you an

00:17:59.336 --> 00:18:00.726 A:middle
I'm excited to give you an

00:18:00.726 --> 00:18:02.806 A:middle
overview of the support for HDR

00:18:02.856 --> 00:18:04.406 A:middle
rendering and display.

00:18:05.376 --> 00:18:07.826 A:middle
To do that, I'll cover four

00:18:07.826 --> 00:18:08.676 A:middle
topics with you.

00:18:09.376 --> 00:18:11.996 A:middle
One, I'll briefly talk about

00:18:11.996 --> 00:18:13.696 A:middle
some common traits of HDR

00:18:13.696 --> 00:18:14.186 A:middle
images.

00:18:15.106 --> 00:18:17.386 A:middle
Then I'll describe our approach

00:18:17.386 --> 00:18:19.666 A:middle
to HDR, our rendering model of

00:18:20.726 --> 00:18:20.816 A:middle
HDR.

00:18:21.066 --> 00:18:23.456 A:middle
Then I'll go into detail on how

00:18:23.456 --> 00:18:26.116 A:middle
to use Metal for HDR rendering.

00:18:26.656 --> 00:18:28.496 A:middle
And finally, wrap it up with

00:18:28.496 --> 00:18:30.416 A:middle
some recommendations on best

00:18:30.416 --> 00:18:31.036 A:middle
practices.

00:18:32.346 --> 00:18:34.696 A:middle
So let's begin with describing

00:18:34.696 --> 00:18:36.536 A:middle
some common traits of HDR

00:18:36.536 --> 00:18:37.216 A:middle
images.

00:18:37.636 --> 00:18:38.866 A:middle
What makes them special?

00:18:39.956 --> 00:18:41.506 A:middle
Compared to standard dynamic

00:18:41.506 --> 00:18:44.456 A:middle
range or SDR images, HDR images

00:18:44.856 --> 00:18:46.656 A:middle
have better contrast levels.

00:18:47.336 --> 00:18:48.826 A:middle
They have great details in the

00:18:48.826 --> 00:18:50.436 A:middle
dark and the bright areas of the

00:18:50.436 --> 00:18:50.826 A:middle
image.

00:18:52.126 --> 00:18:54.476 A:middle
Usually SDR images, these

00:18:54.476 --> 00:18:56.126 A:middle
details are not discernible.

00:18:56.386 --> 00:18:58.276 A:middle
They're either crushed or washed

00:18:58.276 --> 00:18:58.426 A:middle
out.

00:19:00.036 --> 00:19:03.206 A:middle
HDR images have more colors with

00:19:03.206 --> 00:19:04.976 A:middle
wide range of colors in them.

00:19:05.486 --> 00:19:07.146 A:middle
They look very realistic.

00:19:08.376 --> 00:19:10.336 A:middle
Also, they are really bright.

00:19:10.826 --> 00:19:12.266 A:middle
The brightness information is

00:19:12.356 --> 00:19:15.566 A:middle
encoded in the image itself with

00:19:15.566 --> 00:19:17.696 A:middle
such a high brightness and great

00:19:17.696 --> 00:19:19.816 A:middle
contrast ratios, they make it

00:19:19.916 --> 00:19:21.976 A:middle
possible to add lighting effects

00:19:21.976 --> 00:19:24.216 A:middle
in the scene that look closer to

00:19:24.216 --> 00:19:24.856 A:middle
real life.

00:19:25.596 --> 00:19:28.176 A:middle
And finally, they need to be

00:19:28.176 --> 00:19:29.886 A:middle
viewed on a capable display.

00:19:30.816 --> 00:19:32.636 A:middle
The display that can preserve

00:19:32.786 --> 00:19:34.496 A:middle
all the details of the image.

00:19:35.026 --> 00:19:36.356 A:middle
The display in itself should

00:19:36.356 --> 00:19:38.316 A:middle
have underlying technologies to

00:19:38.316 --> 00:19:39.666 A:middle
be able to produce high

00:19:39.666 --> 00:19:41.926 A:middle
brightness, high color fidelity,

00:19:41.926 --> 00:19:43.436 A:middle
and great contrast ratios.

00:19:44.656 --> 00:19:47.026 A:middle
Our new Pro Display XDR is a

00:19:47.176 --> 00:19:49.826 A:middle
great example of that.

00:19:50.046 --> 00:19:53.136 A:middle
Now, how do we render and

00:19:53.136 --> 00:19:54.866 A:middle
display these amazing HDR

00:19:54.866 --> 00:19:56.856 A:middle
contents on our devices?

00:19:58.036 --> 00:19:59.676 A:middle
At Apple, we have a unique

00:19:59.676 --> 00:20:00.456 A:middle
approach for this.

00:19:59.676 --> 00:20:00.456 A:middle
approach for this.

00:20:01.076 --> 00:20:03.256 A:middle
We call this EDR, extended

00:20:03.256 --> 00:20:04.146 A:middle
dynamic range.

00:20:05.636 --> 00:20:07.606 A:middle
In this approach, we use the

00:20:07.606 --> 00:20:09.226 A:middle
brightness headroom available on

00:20:09.226 --> 00:20:10.376 A:middle
the display to show the

00:20:10.376 --> 00:20:12.376 A:middle
highlights and shadows of HDR

00:20:12.376 --> 00:20:12.976 A:middle
images.

00:20:13.656 --> 00:20:15.976 A:middle
Let me explain the concept in

00:20:16.686 --> 00:20:16.856 A:middle
detail.

00:20:17.276 --> 00:20:19.096 A:middle
As you know, the brightness set

00:20:19.096 --> 00:20:20.716 A:middle
on a display is dependent on the

00:20:20.716 --> 00:20:22.006 A:middle
viewing conditions or the

00:20:22.006 --> 00:20:22.956 A:middle
ambient conditions.

00:20:23.986 --> 00:20:25.606 A:middle
For example, if you're in a

00:20:25.606 --> 00:20:27.446 A:middle
dimmed room the brightness set

00:20:27.446 --> 00:20:29.186 A:middle
on your display could be 200

00:20:29.186 --> 00:20:31.626 A:middle
nits, maybe low, and the

00:20:31.626 --> 00:20:34.366 A:middle
brightness set is ideal to view

00:20:34.406 --> 00:20:37.716 A:middle
SDR contents such as UI or

00:20:37.716 --> 00:20:39.456 A:middle
Safari or YouTube video.

00:20:40.656 --> 00:20:42.736 A:middle
But if your display is capable

00:20:42.736 --> 00:20:45.736 A:middle
of producing up to thousand nits

00:20:45.736 --> 00:20:47.396 A:middle
then you have a huge brightness

00:20:47.396 --> 00:20:48.516 A:middle
headroom available on the

00:20:48.516 --> 00:20:48.926 A:middle
display.

00:20:49.566 --> 00:20:52.126 A:middle
Similarly, if you're in well-lit

00:20:52.126 --> 00:20:54.066 A:middle
conditions such as office space,

00:20:54.626 --> 00:20:55.696 A:middle
the brightness set on the

00:20:55.696 --> 00:20:58.026 A:middle
display could be higher, say 500

00:20:58.026 --> 00:20:58.316 A:middle
nits.

00:20:58.966 --> 00:21:00.586 A:middle
And again, the brightness set is

00:20:58.966 --> 00:21:00.586 A:middle
And again, the brightness set is

00:21:00.636 --> 00:21:03.306 A:middle
ideal to view SDR contents but

00:21:03.306 --> 00:21:04.806 A:middle
still you have brightness

00:21:04.856 --> 00:21:06.756 A:middle
headroom left on the display in

00:21:06.756 --> 00:21:07.696 A:middle
this condition too.

00:21:08.216 --> 00:21:11.016 A:middle
In an approach to HDR, we take

00:21:11.016 --> 00:21:11.956 A:middle
advantage of this.

00:21:12.476 --> 00:21:14.596 A:middle
When we render the pixels, we

00:21:14.596 --> 00:21:16.726 A:middle
map the SDR pixels to the

00:21:16.726 --> 00:21:18.336 A:middle
brightness set on the display

00:21:18.766 --> 00:21:20.756 A:middle
and use the headroom to map the

00:21:20.796 --> 00:21:21.826 A:middle
HDR pixels.

00:21:22.396 --> 00:21:25.146 A:middle
The extent to which we map these

00:21:25.146 --> 00:21:27.266 A:middle
two categories really depends on

00:21:27.266 --> 00:21:28.646 A:middle
the viewing conditions as you

00:21:28.646 --> 00:21:30.086 A:middle
can clearly see in the two

00:21:30.086 --> 00:21:31.586 A:middle
examples here.

00:21:33.216 --> 00:21:35.236 A:middle
However, too, rendering this

00:21:35.286 --> 00:21:37.356 A:middle
model, the pixels needs to be

00:21:37.476 --> 00:21:40.076 A:middle
structured in a certain way and

00:21:40.256 --> 00:21:43.236 A:middle
we do that by scaling the HDR

00:21:43.236 --> 00:21:45.176 A:middle
pixels relative to the SDR

00:21:45.366 --> 00:21:46.466 A:middle
brightness of the display.

00:21:47.966 --> 00:21:49.786 A:middle
Let's use our previous example

00:21:49.786 --> 00:21:51.316 A:middle
of a dimmed room and see how the

00:21:51.316 --> 00:21:53.026 A:middle
pixel values are structured

00:21:53.026 --> 00:21:54.246 A:middle
relative to the brightness of

00:21:54.246 --> 00:21:54.756 A:middle
the display.

00:21:56.266 --> 00:21:58.106 A:middle
In here, we represent the

00:21:58.156 --> 00:22:01.026 A:middle
brightness in X axis and the

00:21:58.156 --> 00:22:01.026 A:middle
brightness in X axis and the

00:22:01.026 --> 00:22:02.976 A:middle
normalized pixel values in Y

00:22:02.976 --> 00:22:03.466 A:middle
axis.

00:22:04.126 --> 00:22:06.216 A:middle
In this example, the brightness

00:22:06.216 --> 00:22:09.746 A:middle
of the display set to 200 nits.

00:22:10.566 --> 00:22:12.956 A:middle
In our rendering model we always

00:22:12.956 --> 00:22:14.646 A:middle
reserve the pixel values, the

00:22:14.646 --> 00:22:16.396 A:middle
normalized pixel values in the

00:22:16.396 --> 00:22:19.606 A:middle
range 0 to 14 SDR contents and

00:22:19.606 --> 00:22:21.576 A:middle
we map it to the brightness set

00:22:21.576 --> 00:22:22.176 A:middle
on the display.

00:22:23.196 --> 00:22:25.406 A:middle
So a pixel value of one here

00:22:25.776 --> 00:22:28.256 A:middle
corresponds to 200 nits.

00:22:29.116 --> 00:22:30.736 A:middle
But as you can see, there is a

00:22:30.736 --> 00:22:32.276 A:middle
huge headroom available on the

00:22:32.336 --> 00:22:32.746 A:middle
display.

00:22:33.186 --> 00:22:35.316 A:middle
So you have pixel values from

00:22:35.316 --> 00:22:37.366 A:middle
one through five available to

00:22:37.366 --> 00:22:39.166 A:middle
represent HDR contents.

00:22:40.126 --> 00:22:42.886 A:middle
A scale factor of 5x relative to

00:22:42.886 --> 00:22:44.906 A:middle
the SDR range to take full

00:22:44.906 --> 00:22:46.016 A:middle
advantage of the display

00:22:46.016 --> 00:22:46.596 A:middle
brightness.

00:22:47.886 --> 00:22:49.686 A:middle
We call this scale factor as

00:22:50.136 --> 00:22:52.366 A:middle
maximum EDR.

00:22:53.036 --> 00:22:54.806 A:middle
If the viewing conditions change

00:22:54.906 --> 00:22:57.146 A:middle
or you're in a well-lit room and

00:22:57.146 --> 00:22:58.926 A:middle
the brightness is increased to

00:22:58.926 --> 00:23:01.806 A:middle
500 nits, then the maximum EDR

00:22:58.926 --> 00:23:01.806 A:middle
500 nits, then the maximum EDR

00:23:01.806 --> 00:23:05.346 A:middle
drops down but note the pixel

00:23:05.346 --> 00:23:07.036 A:middle
values in the range zero to one

00:23:07.396 --> 00:23:09.416 A:middle
are still dedicated for SDR

00:23:09.566 --> 00:23:10.196 A:middle
contents.

00:23:10.876 --> 00:23:12.396 A:middle
But they're mapped differently

00:23:12.396 --> 00:23:15.246 A:middle
now, so now a pixel value of one

00:23:15.386 --> 00:23:17.846 A:middle
corresponds to 500 nits instead

00:23:17.846 --> 00:23:19.646 A:middle
of 200 in the previous example.

00:23:20.906 --> 00:23:22.506 A:middle
And since you have a smaller

00:23:22.506 --> 00:23:24.156 A:middle
headroom available here, in this

00:23:24.156 --> 00:23:26.046 A:middle
case, you have a smaller range

00:23:26.046 --> 00:23:27.786 A:middle
of pixel calls available to

00:23:27.786 --> 00:23:29.396 A:middle
represent HDR contents.

00:23:30.236 --> 00:23:32.316 A:middle
So merely 2x here in this

00:23:32.316 --> 00:23:34.266 A:middle
example, relative to the SDR

00:23:34.386 --> 00:23:36.406 A:middle
range to represent HDR pixels.

00:23:37.626 --> 00:23:39.666 A:middle
As you can see, we structured

00:23:39.666 --> 00:23:41.766 A:middle
our pixels in such a way that

00:23:41.876 --> 00:23:43.816 A:middle
the HDR pixels are relative to

00:23:43.816 --> 00:23:46.076 A:middle
the SDR range and they scale

00:23:46.166 --> 00:23:47.686 A:middle
relative to the SDR range.

00:23:48.576 --> 00:23:50.646 A:middle
We also use negative pixels for

00:23:50.646 --> 00:23:52.176 A:middle
representing the darker side of

00:23:52.436 --> 00:23:53.656 A:middle
the HDR image.

00:23:54.646 --> 00:23:58.116 A:middle
So in summary, EDR or external

00:23:58.116 --> 00:23:59.816 A:middle
dynamic range is a display

00:23:59.816 --> 00:24:01.766 A:middle
referred rendering model in

00:23:59.816 --> 00:24:01.766 A:middle
referred rendering model in

00:24:01.766 --> 00:24:03.296 A:middle
which we use the brightness

00:24:03.296 --> 00:24:04.686 A:middle
headroom available on the

00:24:04.686 --> 00:24:07.386 A:middle
display for HDR pixels, and we

00:24:07.626 --> 00:24:10.186 A:middle
scale the HDR pixels relative to

00:24:10.186 --> 00:24:11.656 A:middle
the SDR brightness of the

00:24:11.656 --> 00:24:12.066 A:middle
display.

00:24:13.426 --> 00:24:16.066 A:middle
The advantage of this model is

00:24:16.066 --> 00:24:18.196 A:middle
that you can do HDR rendering on

00:24:18.386 --> 00:24:20.196 A:middle
pretty much any display on which

00:24:20.196 --> 00:24:23.116 A:middle
we can set brightness, but if

00:24:23.116 --> 00:24:24.946 A:middle
you have more capable display

00:24:25.126 --> 00:24:27.196 A:middle
such as of a new Pro Display XDR

00:24:27.646 --> 00:24:28.926 A:middle
with its huge headroom

00:24:28.926 --> 00:24:31.196 A:middle
availability then the contents

00:24:31.196 --> 00:24:35.246 A:middle
are going to look just better.

00:24:35.436 --> 00:24:37.036 A:middle
Now that we have looked into our

00:24:37.036 --> 00:24:38.676 A:middle
rendering model of our approach

00:24:38.676 --> 00:24:41.416 A:middle
to HDR, let's look into what

00:24:41.416 --> 00:24:43.726 A:middle
API's do we have and how you can

00:24:43.726 --> 00:24:45.266 A:middle
use those API's in your

00:24:45.266 --> 00:24:45.866 A:middle
application.

00:24:48.566 --> 00:24:51.166 A:middle
On both macOS and iOS, you have

00:24:51.166 --> 00:24:52.016 A:middle
a couple of options.

00:24:52.886 --> 00:24:55.526 A:middle
One, you can use AVFoundation

00:24:56.506 --> 00:24:56.786 A:middle
API's.

00:24:56.786 --> 00:24:58.816 A:middle
These API's are ideal for media

00:24:58.816 --> 00:24:59.886 A:middle
playback applications.

00:25:00.586 --> 00:25:02.646 A:middle
They handle all aspects of tone

00:25:02.646 --> 00:25:04.186 A:middle
mapping and color management for

00:25:04.186 --> 00:25:04.336 A:middle
you.

00:25:05.216 --> 00:25:07.376 A:middle
Two, you can directly use Metal.

00:25:08.026 --> 00:25:09.426 A:middle
Metal provides with a lot of

00:25:09.426 --> 00:25:11.356 A:middle
options and great flexibility.

00:25:12.386 --> 00:25:15.196 A:middle
Using the CAMetalLayer and EDR

00:25:15.196 --> 00:25:17.806 A:middle
API's, you can take full control

00:25:17.806 --> 00:25:19.226 A:middle
of HDR rendering in your

00:25:19.226 --> 00:25:21.146 A:middle
application including tone

00:25:21.146 --> 00:25:23.066 A:middle
mapping and color management.

00:25:24.316 --> 00:25:26.186 A:middle
These API's are ideal for

00:25:26.426 --> 00:25:27.316 A:middle
content creation.

00:25:28.626 --> 00:25:30.696 A:middle
Now using a code snippet, let's

00:25:30.696 --> 00:25:32.286 A:middle
look at how the metal layer and

00:25:32.286 --> 00:25:34.336 A:middle
the EDR API's all come together

00:25:34.336 --> 00:25:35.876 A:middle
in an application, shall we?

00:25:36.686 --> 00:25:39.086 A:middle
So the first and the foremost

00:25:39.086 --> 00:25:40.906 A:middle
that you do in your code base is

00:25:40.906 --> 00:25:43.026 A:middle
to check for the EDR support on

00:25:43.026 --> 00:25:45.076 A:middle
the display, and this screen

00:25:45.076 --> 00:25:46.276 A:middle
provides you with the property

00:25:46.276 --> 00:25:47.276 A:middle
for that.

00:25:47.856 --> 00:25:50.106 A:middle
Then as usual, you create and

00:25:50.146 --> 00:25:51.306 A:middle
set up your metal layer.

00:25:52.426 --> 00:25:53.856 A:middle
When you set up the metal layer,

00:25:54.016 --> 00:25:55.906 A:middle
you need to choose a wide gamut

00:25:55.986 --> 00:25:57.816 A:middle
color space that suits your

00:25:57.816 --> 00:25:58.436 A:middle
application.

00:25:59.466 --> 00:26:01.236 A:middle
Metal supports rendering into

00:25:59.466 --> 00:26:01.236 A:middle
Metal supports rendering into

00:26:01.236 --> 00:26:02.996 A:middle
wide gamut color spaces such as

00:26:03.106 --> 00:26:05.656 A:middle
BT2020 or B3.

00:26:06.756 --> 00:26:08.436 A:middle
Next, you need to choose the

00:26:08.436 --> 00:26:10.116 A:middle
transfer function that matches

00:26:10.116 --> 00:26:10.756 A:middle
your content.

00:26:11.516 --> 00:26:13.386 A:middle
Again, the API's have support

00:26:13.386 --> 00:26:15.206 A:middle
for all industry standard

00:26:15.246 --> 00:26:18.116 A:middle
transfer functions such as PQ,

00:26:18.116 --> 00:26:19.416 A:middle
HLG, or Gamma.

00:26:20.876 --> 00:26:23.406 A:middle
Then you need to choose pixel

00:26:23.406 --> 00:26:25.166 A:middle
format for your HDR rendering.

00:26:25.926 --> 00:26:28.606 A:middle
We recommend that you use float

00:26:28.606 --> 00:26:30.766 A:middle
16 as a preferred pixel format

00:26:30.816 --> 00:26:32.636 A:middle
for most of your HDR rendering

00:26:32.636 --> 00:26:35.486 A:middle
needs because float 16 has

00:26:35.596 --> 00:26:37.116 A:middle
enough precision to carry the

00:26:37.216 --> 00:26:38.376 A:middle
color and the brightness

00:26:38.376 --> 00:26:40.096 A:middle
information for HDR contents.

00:26:40.646 --> 00:26:43.076 A:middle
And finally, in the layers set

00:26:43.076 --> 00:26:44.646 A:middle
up you need to indicate to Metal

00:26:44.966 --> 00:26:46.866 A:middle
that you have opted in to EDR

00:26:46.866 --> 00:26:47.626 A:middle
rendering model.

00:26:48.576 --> 00:26:50.066 A:middle
So this is a typical layer set

00:26:50.066 --> 00:26:52.046 A:middle
up that you would do.

00:26:52.446 --> 00:26:54.156 A:middle
Next, moving on to main render

00:26:54.226 --> 00:26:54.446 A:middle
loop.

00:26:54.946 --> 00:26:56.566 A:middle
In the main render loop you need

00:26:56.566 --> 00:26:58.016 A:middle
to get the brightness headroom

00:26:58.016 --> 00:26:59.166 A:middle
that we talked about or the

00:26:59.166 --> 00:27:01.466 A:middle
maximum EDR information, right?

00:26:59.166 --> 00:27:01.466 A:middle
maximum EDR information, right?

00:27:01.796 --> 00:27:03.806 A:middle
So NSScreen provides you with

00:27:03.806 --> 00:27:05.346 A:middle
the property for that.

00:27:05.856 --> 00:27:07.416 A:middle
But note, this property is

00:27:07.416 --> 00:27:07.996 A:middle
dynamic.

00:27:08.506 --> 00:27:09.676 A:middle
It keeps changing with the

00:27:09.676 --> 00:27:11.486 A:middle
viewing conditions or when the

00:27:11.486 --> 00:27:12.646 A:middle
brightness of the display

00:27:12.646 --> 00:27:13.106 A:middle
changes.

00:27:13.616 --> 00:27:15.756 A:middle
So you need to register for a

00:27:15.756 --> 00:27:17.686 A:middle
notification for any changes on

00:27:17.686 --> 00:27:20.506 A:middle
this property and as maximum EDR

00:27:20.686 --> 00:27:22.976 A:middle
changes, you need to redraw your

00:27:23.066 --> 00:27:23.726 A:middle
contents.

00:27:25.516 --> 00:27:27.936 A:middle
Now, if you are handling tone

00:27:27.936 --> 00:27:29.486 A:middle
mapping and color management

00:27:29.486 --> 00:27:30.996 A:middle
yourselves in the application,

00:27:31.446 --> 00:27:32.946 A:middle
you need to do some additional

00:27:32.946 --> 00:27:34.686 A:middle
pixel processing in the shaders.

00:27:35.206 --> 00:27:36.856 A:middle
Let's review some common steps

00:27:36.916 --> 00:27:39.686 A:middle
that you would do.

00:27:39.936 --> 00:27:43.236 A:middle
Typically the video come in

00:27:43.236 --> 00:27:44.636 A:middle
[inaudible] color format.

00:27:45.056 --> 00:27:46.306 A:middle
So the first step in your

00:27:46.306 --> 00:27:48.046 A:middle
application or in your shaders

00:27:48.116 --> 00:27:49.786 A:middle
is to convert it to RGB.

00:27:50.876 --> 00:27:53.206 A:middle
Also, the video contents come

00:27:53.316 --> 00:27:54.796 A:middle
encoded with some kind of

00:27:54.796 --> 00:27:56.566 A:middle
non-linear transfer functions

00:27:56.796 --> 00:27:57.766 A:middle
such as PQ.

00:27:58.646 --> 00:28:00.296 A:middle
So the next step in the shader

00:27:58.646 --> 00:28:00.296 A:middle
So the next step in the shader

00:28:00.296 --> 00:28:02.576 A:middle
is to apply inverse transfer

00:28:02.576 --> 00:28:04.376 A:middle
function and linearize your

00:28:04.376 --> 00:28:06.726 A:middle
pixels, and then normalize it in

00:28:06.726 --> 00:28:08.626 A:middle
the range zero to one.

00:28:10.066 --> 00:28:12.806 A:middle
And then use the maximum EDR

00:28:12.886 --> 00:28:14.746 A:middle
that you got from NSScreen and

00:28:14.916 --> 00:28:16.806 A:middle
scale the pixels as we discussed

00:28:16.806 --> 00:28:17.946 A:middle
in the EDR section.

00:28:18.426 --> 00:28:21.136 A:middle
And then perform editing,

00:28:21.136 --> 00:28:23.116 A:middle
grading, or any processing that

00:28:23.256 --> 00:28:25.286 A:middle
suits your application, and

00:28:25.286 --> 00:28:27.646 A:middle
finally, perform tone mapping.

00:28:28.986 --> 00:28:30.406 A:middle
If the brightness changes then

00:28:30.406 --> 00:28:32.066 A:middle
you need to do the tone mapping

00:28:32.066 --> 00:28:32.976 A:middle
with different set of

00:28:32.976 --> 00:28:33.686 A:middle
parameters.

00:28:34.556 --> 00:28:37.996 A:middle
If your contents are in a color

00:28:37.996 --> 00:28:39.526 A:middle
space that is different from the

00:28:39.526 --> 00:28:41.866 A:middle
one on the display then you also

00:28:41.866 --> 00:28:43.406 A:middle
need to apply proper color

00:28:43.466 --> 00:28:44.006 A:middle
conversions.

00:28:45.406 --> 00:28:47.116 A:middle
However, if you don't want to

00:28:47.236 --> 00:28:48.616 A:middle
handle tone mapping or

00:28:48.616 --> 00:28:49.876 A:middle
teleprocessing, and you want

00:28:49.876 --> 00:28:51.686 A:middle
Metal to handle it for you, you

00:28:51.686 --> 00:28:52.836 A:middle
can easily do that.

00:28:53.926 --> 00:28:55.616 A:middle
When you create a Metal layer,

00:28:56.296 --> 00:28:58.596 A:middle
attach an EDR metadata object

00:28:58.596 --> 00:28:58.936 A:middle
with it.

00:28:59.986 --> 00:29:01.606 A:middle
Typically the EDR metadata

00:28:59.986 --> 00:29:01.606 A:middle
Typically the EDR metadata

00:29:01.606 --> 00:29:03.276 A:middle
object provides the information

00:29:03.566 --> 00:29:05.286 A:middle
on the mastering display and it

00:29:05.286 --> 00:29:06.916 A:middle
also tells Metal how you want to

00:29:06.916 --> 00:29:07.916 A:middle
map your pixels.

00:29:08.836 --> 00:29:10.296 A:middle
You also need to use one of the

00:29:10.296 --> 00:29:12.176 A:middle
linear color spaces available

00:29:12.176 --> 00:29:12.636 A:middle
with Metal.

00:29:13.176 --> 00:29:16.356 A:middle
So once all your pixel

00:29:16.356 --> 00:29:18.406 A:middle
processing is done, your frame

00:29:18.406 --> 00:29:19.086 A:middle
is ready.

00:29:19.306 --> 00:29:21.476 A:middle
Use the existing Metal API's to

00:29:21.606 --> 00:29:23.226 A:middle
present your frame on the

00:29:23.226 --> 00:29:23.626 A:middle
screen.

00:29:24.206 --> 00:29:27.316 A:middle
As we noted earlier, you need a

00:29:27.316 --> 00:29:29.496 A:middle
capable display such as of a Pro

00:29:29.496 --> 00:29:31.126 A:middle
Display XDR to view these

00:29:31.126 --> 00:29:31.676 A:middle
contents.

00:29:32.736 --> 00:29:35.416 A:middle
We also support HDR 10 and Dolby

00:29:35.416 --> 00:29:37.026 A:middle
Vision TV's available in the

00:29:37.026 --> 00:29:37.526 A:middle
market.

00:29:38.636 --> 00:29:40.856 A:middle
So this is a simple illustration

00:29:40.856 --> 00:29:43.626 A:middle
of how you can use Metal layer

00:29:43.836 --> 00:29:46.746 A:middle
and EDR API's for HDR rendering

00:29:46.876 --> 00:29:47.746 A:middle
in your application.

00:29:48.656 --> 00:29:50.716 A:middle
So before we end this section,

00:29:51.336 --> 00:29:53.406 A:middle
let's review some key takeaways

00:29:53.586 --> 00:29:55.196 A:middle
and some recommendations on best

00:29:55.196 --> 00:29:55.826 A:middle
practices.

00:29:58.656 --> 00:30:00.936 A:middle
Remember to redraw and update

00:29:58.656 --> 00:30:00.936 A:middle
Remember to redraw and update

00:30:00.936 --> 00:30:02.536 A:middle
your content as the brightness

00:30:02.536 --> 00:30:02.946 A:middle
changes.

00:30:04.506 --> 00:30:06.366 A:middle
Use float 16 as a preferred

00:30:06.366 --> 00:30:09.066 A:middle
pixel format for most of your

00:30:09.066 --> 00:30:09.896 A:middle
HDR rendering needs.

00:30:11.346 --> 00:30:13.196 A:middle
When you set up the Metal layer,

00:30:13.196 --> 00:30:14.566 A:middle
select the color space and

00:30:14.796 --> 00:30:16.426 A:middle
transfer function that matches

00:30:16.426 --> 00:30:18.396 A:middle
your content and then perform

00:30:18.396 --> 00:30:19.936 A:middle
any additional processing in the

00:30:19.936 --> 00:30:21.446 A:middle
shaders as necessary.

00:30:22.226 --> 00:30:24.596 A:middle
Last, but not the least, HDR

00:30:24.886 --> 00:30:27.686 A:middle
processing adds to computational

00:30:27.686 --> 00:30:29.226 A:middle
overhead and adds [inaudible].

00:30:30.006 --> 00:30:32.766 A:middle
So bypass tone mapping if your

00:30:32.836 --> 00:30:34.656 A:middle
contents are already tone mapped

00:30:35.066 --> 00:30:37.006 A:middle
or if performance is more

00:30:37.006 --> 00:30:39.136 A:middle
important for you than color

00:30:39.136 --> 00:30:39.736 A:middle
accuracy.

00:30:40.936 --> 00:30:43.686 A:middle
So, in summary, we have provided

00:30:43.686 --> 00:30:45.876 A:middle
you with powerful API's, a

00:30:45.876 --> 00:30:47.896 A:middle
display for EDR rendering model

00:30:47.896 --> 00:30:50.356 A:middle
support on both iOS and macOS,

00:30:50.356 --> 00:30:52.986 A:middle
and a great support for our Pro

00:30:52.986 --> 00:30:53.796 A:middle
Display XDR.

00:30:54.796 --> 00:30:56.816 A:middle
I'm sure you can use these tools

00:30:56.816 --> 00:30:59.330 A:middle
to create amazing HDR contents.

00:31:02.546 --> 00:31:03.936 A:middle
In the next section, we are

00:31:03.936 --> 00:31:05.856 A:middle
going to talk about how you can

00:31:05.856 --> 00:31:07.616 A:middle
leverage the computational

00:31:07.616 --> 00:31:09.026 A:middle
resources available on the

00:31:09.066 --> 00:31:10.786 A:middle
platform to get the best

00:31:10.786 --> 00:31:12.756 A:middle
possible performance and to tell

00:31:12.756 --> 00:31:15.386 A:middle
you all about it, I invite Brian

00:31:15.386 --> 00:31:16.146 A:middle
Ross on stage.

00:31:17.516 --> 00:31:20.500 A:middle
[ Applause ]

00:31:25.366 --> 00:31:26.016 A:middle
&gt;&gt; Thanks, Dileep.

00:31:27.316 --> 00:31:28.926 A:middle
Scaling your performance to

00:31:28.926 --> 00:31:30.896 A:middle
harness both CPU and GPU

00:31:30.896 --> 00:31:32.386 A:middle
parallelism is the most

00:31:32.386 --> 00:31:34.286 A:middle
important and sometimes the

00:31:34.286 --> 00:31:35.936 A:middle
easiest optimization you can do.

00:31:36.886 --> 00:31:38.206 A:middle
In this section, I'm going to

00:31:38.206 --> 00:31:40.176 A:middle
talk about several ways to scale

00:31:40.176 --> 00:31:41.276 A:middle
your performance based on the

00:31:41.276 --> 00:31:42.566 A:middle
architecture of your hardware.

00:31:43.366 --> 00:31:44.636 A:middle
So first, I'll talk about how

00:31:44.636 --> 00:31:46.316 A:middle
Metal can help you to scale

00:31:46.316 --> 00:31:48.346 A:middle
across any number of CPU cores.

00:31:49.556 --> 00:31:50.936 A:middle
Next, I'll talk about how to

00:31:50.936 --> 00:31:54.226 A:middle
leverage, utilize asynchronous

00:31:54.286 --> 00:31:55.326 A:middle
GPU channels.

00:31:56.156 --> 00:31:57.476 A:middle
And finally, I'll close this

00:31:57.476 --> 00:31:59.826 A:middle
section by going over a few ways

00:32:00.276 --> 00:32:01.776 A:middle
to use multiple GPU's.

00:32:02.366 --> 00:32:05.276 A:middle
So today's props are adding more

00:32:05.276 --> 00:32:06.146 A:middle
and more complexity.

00:32:07.276 --> 00:32:09.266 A:middle
They demand more CPU cycles to

00:32:09.616 --> 00:32:11.486 A:middle
decode frames, build render

00:32:11.486 --> 00:32:13.736 A:middle
graphs, and encode metal render

00:32:13.736 --> 00:32:14.136 A:middle
passes.

00:32:15.446 --> 00:32:17.406 A:middle
Doing all this on a single CPU

00:32:17.406 --> 00:32:18.706 A:middle
thread is not sufficient for

00:32:18.706 --> 00:32:19.466 A:middle
today's devices.

00:32:20.736 --> 00:32:22.616 A:middle
The latest iPhone has six cores

00:32:23.166 --> 00:32:25.196 A:middle
and a Mac Pro can have up to 28.

00:32:26.556 --> 00:32:28.756 A:middle
Therefore scalable multithread

00:32:28.756 --> 00:32:30.516 A:middle
architecture is key to great

00:32:30.516 --> 00:32:31.566 A:middle
performance on all of our

00:32:31.566 --> 00:32:32.006 A:middle
devices.

00:32:32.896 --> 00:32:34.106 A:middle
Metal is designed for

00:32:34.106 --> 00:32:34.696 A:middle
multithreading.

00:32:35.576 --> 00:32:37.256 A:middle
In this section, let's look at

00:32:37.256 --> 00:32:38.746 A:middle
two ways how you can parallelize

00:32:38.746 --> 00:32:40.306 A:middle
your encoding on the CPU.

00:32:40.536 --> 00:32:42.896 A:middle
So I'm going to set up an

00:32:42.896 --> 00:32:45.166 A:middle
example of a typical video

00:32:45.166 --> 00:32:45.466 A:middle
frame.

00:32:46.216 --> 00:32:48.056 A:middle
With a classic single threaded

00:32:48.056 --> 00:32:49.736 A:middle
rendering, you could serially

00:32:49.736 --> 00:32:51.956 A:middle
decode frames and build commands

00:32:51.956 --> 00:32:53.576 A:middle
into a single command buffer in

00:32:53.576 --> 00:32:55.006 A:middle
GPU execution order.

00:32:55.786 --> 00:32:56.846 A:middle
And you typically have to fit

00:32:56.936 --> 00:32:58.746 A:middle
this into some tiny fraction of

00:32:58.746 --> 00:32:59.426 A:middle
your frame time.

00:33:00.386 --> 00:33:02.276 A:middle
And of course, you're going to

00:33:02.276 --> 00:33:03.536 A:middle
have maximum latency because you

00:33:03.536 --> 00:33:04.856 A:middle
have to encode the entire

00:33:04.856 --> 00:33:06.936 A:middle
command buffer before the GPU

00:33:06.936 --> 00:33:07.636 A:middle
can consume it.

00:33:08.176 --> 00:33:09.446 A:middle
Obviously, there's a better way

00:33:09.446 --> 00:33:09.916 A:middle
to do this.

00:33:10.106 --> 00:33:11.506 A:middle
So what we're going to do is

00:33:11.506 --> 00:33:13.326 A:middle
start by building in parallelism

00:33:13.436 --> 00:33:16.656 A:middle
with the CPU.

00:33:16.846 --> 00:33:18.546 A:middle
Render blit and compute passes

00:33:18.546 --> 00:33:20.016 A:middle
are the basic granularity of

00:33:20.016 --> 00:33:21.056 A:middle
multithreading on Metal.

00:33:21.866 --> 00:33:23.266 A:middle
All you need to do is create

00:33:23.266 --> 00:33:25.286 A:middle
multiple command buffers and

00:33:25.286 --> 00:33:27.096 A:middle
start encoding passes into each

00:33:27.156 --> 00:33:27.976 A:middle
on a separate thread.

00:33:28.816 --> 00:33:30.126 A:middle
You can encode in any order you

00:33:30.126 --> 00:33:30.566 A:middle
wish.

00:33:30.986 --> 00:33:32.956 A:middle
The final order of execution is

00:33:32.956 --> 00:33:34.356 A:middle
determined by the order that you

00:33:34.356 --> 00:33:35.486 A:middle
added to the command queue.

00:33:36.106 --> 00:33:37.906 A:middle
So now let's look at how you can

00:33:37.906 --> 00:33:39.000 A:middle
do this in your code.

00:33:42.336 --> 00:33:43.726 A:middle
Encoding multiple command

00:33:43.726 --> 00:33:44.686 A:middle
buffers is actually quite

00:33:44.726 --> 00:33:45.096 A:middle
simple.

00:33:45.556 --> 00:33:47.256 A:middle
The first thing we do is we

00:33:47.256 --> 00:33:48.956 A:middle
create any number of Metal

00:33:48.956 --> 00:33:50.366 A:middle
command buffer objects from the

00:33:50.906 --> 00:33:51.000 A:middle
queue.

00:33:52.436 --> 00:33:54.686 A:middle
Next, we define the GPU

00:33:54.686 --> 00:33:56.166 A:middle
execution order up front by

00:33:56.166 --> 00:33:57.426 A:middle
using the enqueue interface.

00:33:57.496 --> 00:33:58.416 A:middle
This is great because you could

00:33:58.416 --> 00:33:59.686 A:middle
do it early and you don't have

00:33:59.726 --> 00:34:00.956 A:middle
to wait for encoding to complete

00:33:59.726 --> 00:34:00.956 A:middle
to wait for encoding to complete

00:34:01.046 --> 00:34:01.666 A:middle
first.

00:34:02.116 --> 00:34:05.576 A:middle
And finally, for each command

00:34:05.576 --> 00:34:06.826 A:middle
buffer we create a separate

00:34:06.826 --> 00:34:08.426 A:middle
thread using the asynchronous

00:34:08.426 --> 00:34:10.806 A:middle
dispatch queue and encode passes

00:34:10.806 --> 00:34:12.216 A:middle
for the frame and that's it.

00:34:12.326 --> 00:34:13.786 A:middle
It's really fast and it's really

00:34:13.786 --> 00:34:14.235 A:middle
simple.

00:34:15.716 --> 00:34:17.065 A:middle
So as you could see in our

00:34:17.065 --> 00:34:18.286 A:middle
example, we've done a good job

00:34:18.286 --> 00:34:19.866 A:middle
parallelizing with multiple

00:34:19.866 --> 00:34:21.076 A:middle
Metal command buffer objects,

00:34:21.076 --> 00:34:23.226 A:middle
but what if you have one really

00:34:23.226 --> 00:34:25.255 A:middle
large effects and blending pass?

00:34:26.036 --> 00:34:28.396 A:middle
In this case, Metal offers a

00:34:28.396 --> 00:34:30.286 A:middle
dedicated parallel encoder that

00:34:30.286 --> 00:34:32.606 A:middle
allows you to encode on multiple

00:34:32.606 --> 00:34:34.146 A:middle
threads without explicitly

00:34:34.146 --> 00:34:36.585 A:middle
dividing up the render pass or

00:34:36.585 --> 00:34:37.346 A:middle
the command buffer.

00:34:38.096 --> 00:34:39.216 A:middle
Let's take a look at how easy

00:34:39.216 --> 00:34:39.996 A:middle
this is to doing your

00:34:39.996 --> 00:34:41.000 A:middle
application.

00:34:43.346 --> 00:34:44.646 A:middle
So here, the first thing we do

00:34:44.646 --> 00:34:46.126 A:middle
is create a parallel encoder

00:34:46.126 --> 00:34:47.076 A:middle
from the command buffer.

00:34:48.196 --> 00:34:49.416 A:middle
Then we create any number of

00:34:49.416 --> 00:34:51.376 A:middle
subordinate coders and this is

00:34:51.376 --> 00:34:53.065 A:middle
actually where we define the GPU

00:34:53.065 --> 00:34:54.786 A:middle
execution order by the order

00:34:54.786 --> 00:34:56.255 A:middle
that we create the subordinates.

00:34:57.716 --> 00:34:58.846 A:middle
Next, we create a separate

00:34:58.846 --> 00:35:00.406 A:middle
thread and call our encoding

00:34:58.846 --> 00:35:00.406 A:middle
thread and call our encoding

00:35:00.406 --> 00:35:01.406 A:middle
function for each.

00:35:01.636 --> 00:35:02.666 A:middle
This is where the effects and

00:35:02.666 --> 00:35:03.866 A:middle
blending will be processed.

00:35:05.326 --> 00:35:06.236 A:middle
And finally we set up a

00:35:06.236 --> 00:35:07.456 A:middle
notification when the threads

00:35:07.456 --> 00:35:09.616 A:middle
are complete and we end

00:35:09.616 --> 00:35:10.716 A:middle
parallelizing encoding, and

00:35:10.716 --> 00:35:11.296 A:middle
that's it.

00:35:11.376 --> 00:35:12.406 A:middle
That's all you have to do.

00:35:12.406 --> 00:35:13.786 A:middle
It's very simple and very

00:35:13.786 --> 00:35:14.266 A:middle
efficient.

00:35:14.936 --> 00:35:16.206 A:middle
So I've shown you two ways on

00:35:16.206 --> 00:35:17.836 A:middle
how to parallelize on the CPU.

00:35:18.246 --> 00:35:19.776 A:middle
Now let's see how Metal can help

00:35:19.776 --> 00:35:22.226 A:middle
you to leverage asynchronous GPU

00:35:22.226 --> 00:35:22.916 A:middle
channels.

00:35:25.056 --> 00:35:26.916 A:middle
Modern GPU's today have a common

00:35:26.916 --> 00:35:27.626 A:middle
capability.

00:35:28.366 --> 00:35:29.836 A:middle
They each contain a number of

00:35:29.836 --> 00:35:30.906 A:middle
channels that allow you to

00:35:31.276 --> 00:35:33.416 A:middle
execute asynchronously so this

00:35:33.416 --> 00:35:35.316 A:middle
means that you can potentially

00:35:35.316 --> 00:35:36.476 A:middle
decode video on one channel

00:35:36.476 --> 00:35:39.296 A:middle
while also executing 3D effects

00:35:39.296 --> 00:35:39.866 A:middle
on another.

00:35:41.226 --> 00:35:42.706 A:middle
Metal could extract this type of

00:35:42.706 --> 00:35:44.196 A:middle
parallelism in two ways.

00:35:44.786 --> 00:35:46.176 A:middle
The first comes naturally just

00:35:46.176 --> 00:35:47.856 A:middle
by using the render, blit, and

00:35:47.856 --> 00:35:49.316 A:middle
compute encoders for the

00:35:49.316 --> 00:35:50.386 A:middle
appropriate workloads.

00:35:51.216 --> 00:35:52.346 A:middle
The other way Metal extracts

00:35:52.346 --> 00:35:54.196 A:middle
parallelism is by analyzing your

00:35:54.196 --> 00:35:55.106 A:middle
data dependencies.

00:35:55.836 --> 00:35:57.176 A:middle
But the most compelling detail

00:35:57.176 --> 00:35:58.356 A:middle
of all here is you get most of

00:35:58.356 --> 00:35:58.946 A:middle
this for free.

00:35:59.476 --> 00:36:00.796 A:middle
Metal does a lot of this for you

00:35:59.476 --> 00:36:00.796 A:middle
Metal does a lot of this for you

00:36:00.796 --> 00:36:01.366 A:middle
under the hood.

00:36:02.736 --> 00:36:03.336 A:middle
Let's see how.

00:36:04.006 --> 00:36:06.806 A:middle
So let's look at how the GPU

00:36:06.806 --> 00:36:08.026 A:middle
executes a series of these

00:36:08.026 --> 00:36:08.596 A:middle
frames.

00:36:09.066 --> 00:36:10.696 A:middle
Here I have another video frame

00:36:10.696 --> 00:36:11.186 A:middle
example.

00:36:11.186 --> 00:36:12.866 A:middle
In your application we're going

00:36:12.866 --> 00:36:13.926 A:middle
to be decoding with Video

00:36:13.926 --> 00:36:16.146 A:middle
Toolbox followed by using the

00:36:16.146 --> 00:36:17.776 A:middle
blit encoder to upload those

00:36:17.856 --> 00:36:19.666 A:middle
frames from system to VRAM.

00:36:20.016 --> 00:36:21.886 A:middle
Then we'll apply filtering with

00:36:21.886 --> 00:36:23.896 A:middle
compute and effects and blending

00:36:23.896 --> 00:36:24.526 A:middle
with render.

00:36:26.656 --> 00:36:27.666 A:middle
This work will happen

00:36:27.666 --> 00:36:28.906 A:middle
repetitively for each frame.

00:36:29.596 --> 00:36:30.866 A:middle
So now let's see how this gets

00:36:30.866 --> 00:36:33.326 A:middle
executed on both the CPU and the

00:36:33.326 --> 00:36:34.926 A:middle
GPU in a timeline diagram.

00:36:35.276 --> 00:36:36.506 A:middle
Let's also see if we can apply

00:36:36.506 --> 00:36:38.016 A:middle
some optimizations to improve

00:36:38.016 --> 00:36:38.766 A:middle
concurrency.

00:36:39.296 --> 00:36:41.556 A:middle
The first thing we're going to

00:36:41.556 --> 00:36:43.746 A:middle
do is encode frame one commands

00:36:43.746 --> 00:36:45.106 A:middle
using the various encoders on

00:36:45.106 --> 00:36:45.796 A:middle
separate threads.

00:36:45.796 --> 00:36:48.166 A:middle
This work is going to get

00:36:48.196 --> 00:36:49.636 A:middle
scheduled and eventually

00:36:49.636 --> 00:36:50.786 A:middle
executed across all the

00:36:50.786 --> 00:36:51.446 A:middle
channels.

00:36:52.266 --> 00:36:53.826 A:middle
And then we continue on with

00:36:53.826 --> 00:36:56.526 A:middle
frames two, three, and four.

00:36:57.056 --> 00:37:00.186 A:middle
Thanks to Metal, you can see

00:36:57.056 --> 00:37:00.186 A:middle
Thanks to Metal, you can see

00:37:00.186 --> 00:37:01.196 A:middle
that we're already achieving

00:37:01.196 --> 00:37:02.616 A:middle
some parallelism for free.

00:37:03.816 --> 00:37:04.916 A:middle
But we can also see there's a

00:37:04.916 --> 00:37:05.896 A:middle
lot of gaps.

00:37:06.586 --> 00:37:07.596 A:middle
This means that some of the

00:37:07.596 --> 00:37:08.856 A:middle
threads and channels are sitting

00:37:08.856 --> 00:37:10.256 A:middle
idle during our valuable frame

00:37:10.256 --> 00:37:10.506 A:middle
time.

00:37:11.006 --> 00:37:12.996 A:middle
To maintain efficiency, we want

00:37:12.996 --> 00:37:14.396 A:middle
to saturate our channels as much

00:37:14.396 --> 00:37:15.006 A:middle
as possible.

00:37:16.316 --> 00:37:17.616 A:middle
Metal can't always do all this

00:37:17.616 --> 00:37:17.976 A:middle
for us.

00:37:17.976 --> 00:37:19.546 A:middle
So in this case it's time to

00:37:19.546 --> 00:37:20.926 A:middle
apply some optimizations.

00:37:21.846 --> 00:37:23.116 A:middle
You'll notice on the CPU there

00:37:23.116 --> 00:37:24.916 A:middle
is extremely large gaps.

00:37:25.206 --> 00:37:27.516 A:middle
This can happen for many reasons

00:37:27.516 --> 00:37:29.166 A:middle
but for simplicity I'll focus on

00:37:29.166 --> 00:37:30.076 A:middle
a common mistake.

00:37:30.786 --> 00:37:31.856 A:middle
Sometimes applications

00:37:31.856 --> 00:37:33.436 A:middle
gratuitously call or wait until

00:37:33.436 --> 00:37:35.426 A:middle
completed after encoding and

00:37:35.426 --> 00:37:36.486 A:middle
committing a command buffer.

00:37:37.496 --> 00:37:38.986 A:middle
In this scenario it's creating

00:37:38.986 --> 00:37:41.106 A:middle
large gaps or bubbles for the

00:37:41.106 --> 00:37:42.806 A:middle
duration of our decode workload.

00:37:43.496 --> 00:37:45.076 A:middle
It's also causing small gaps in

00:37:45.076 --> 00:37:46.486 A:middle
the decode channel in the GPU.

00:37:47.306 --> 00:37:49.266 A:middle
To fix that, we can try to

00:37:49.266 --> 00:37:50.286 A:middle
replace the weight with a

00:37:50.286 --> 00:37:51.236 A:middle
completion handler.

00:37:52.086 --> 00:37:53.456 A:middle
This will avoid blocking on the

00:37:53.456 --> 00:37:55.656 A:middle
CPU and schedule any post

00:37:55.656 --> 00:37:56.966 A:middle
processing after the GPU is

00:37:56.966 --> 00:37:57.456 A:middle
completed.

00:37:58.076 --> 00:37:59.306 A:middle
Let's try that and see where it

00:37:59.306 --> 00:38:00.426 A:middle
gets us.

00:37:59.306 --> 00:38:00.426 A:middle
gets us.

00:38:03.116 --> 00:38:04.426 A:middle
So you can see that's much

00:38:04.426 --> 00:38:04.976 A:middle
better.

00:38:05.296 --> 00:38:06.436 A:middle
We're now keeping our CPU

00:38:06.436 --> 00:38:07.006 A:middle
threads busy.

00:38:07.006 --> 00:38:08.596 A:middle
You will also notice that the

00:38:08.596 --> 00:38:10.286 A:middle
decoding channel is saturated

00:38:10.286 --> 00:38:11.006 A:middle
really nicely.

00:38:11.296 --> 00:38:13.776 A:middle
We could still see quite a few

00:38:13.896 --> 00:38:16.146 A:middle
gaps in the blit, compute, and

00:38:16.146 --> 00:38:17.156 A:middle
render channels.

00:38:18.236 --> 00:38:19.406 A:middle
Looking closely, you can see

00:38:19.406 --> 00:38:20.596 A:middle
that there is a rewrite

00:38:20.596 --> 00:38:22.506 A:middle
dependency where the upload

00:38:22.506 --> 00:38:24.746 A:middle
can't begin until the decode is

00:38:24.746 --> 00:38:25.186 A:middle
finished.

00:38:26.266 --> 00:38:28.006 A:middle
One solution to fix this problem

00:38:28.006 --> 00:38:30.096 A:middle
is to decode say 10 frames

00:38:30.096 --> 00:38:30.406 A:middle
ahead.

00:38:30.916 --> 00:38:31.806 A:middle
This will remove that

00:38:31.806 --> 00:38:32.396 A:middle
dependency.

00:38:32.586 --> 00:38:33.576 A:middle
Let's try it and see what

00:38:33.576 --> 00:38:34.000 A:middle
happens.

00:38:37.356 --> 00:38:38.726 A:middle
So now our resource updates look

00:38:38.726 --> 00:38:39.046 A:middle
great.

00:38:39.386 --> 00:38:41.016 A:middle
We're saturating both the video

00:38:41.016 --> 00:38:43.056 A:middle
and the blit channels, but

00:38:43.056 --> 00:38:43.836 A:middle
you'll notice that there is

00:38:43.836 --> 00:38:45.676 A:middle
still a few gaps in the compute

00:38:45.676 --> 00:38:46.596 A:middle
and render channels.

00:38:47.566 --> 00:38:49.206 A:middle
Similar to last time if you look

00:38:49.206 --> 00:38:50.676 A:middle
closely, you could see that

00:38:50.676 --> 00:38:51.756 A:middle
there's another dependency but

00:38:51.756 --> 00:38:53.696 A:middle
the filtering cannot begin until

00:38:53.696 --> 00:38:55.916 A:middle
the blit channel has uploaded

00:38:56.126 --> 00:38:56.666 A:middle
all the data.

00:38:58.076 --> 00:38:59.686 A:middle
Similar to before, we can fix

00:38:59.766 --> 00:39:01.806 A:middle
this by preloading our bit maps

00:38:59.766 --> 00:39:01.806 A:middle
this by preloading our bit maps

00:39:01.806 --> 00:39:02.466 A:middle
ahead of time.

00:39:03.146 --> 00:39:04.156 A:middle
This will remove that

00:39:04.156 --> 00:39:05.000 A:middle
dependency.

00:39:08.206 --> 00:39:10.826 A:middle
And with this, we've now closed

00:39:10.826 --> 00:39:11.846 A:middle
most of the gaps and we have a

00:39:11.846 --> 00:39:13.176 A:middle
really efficient pipeline.

00:39:13.656 --> 00:39:14.966 A:middle
So now that I've reviewed the

00:39:14.966 --> 00:39:16.656 A:middle
GPU channels and some example

00:39:16.656 --> 00:39:19.456 A:middle
optimizations, let's see how to

00:39:19.456 --> 00:39:22.286 A:middle
continue scaling performance on

00:39:22.286 --> 00:39:23.256 A:middle
more GPU's.

00:39:25.216 --> 00:39:27.016 A:middle
GPU's are quickly becoming a

00:39:27.066 --> 00:39:28.156 A:middle
performance multiplier.

00:39:29.106 --> 00:39:30.436 A:middle
Supporting more GPU's can

00:39:30.436 --> 00:39:32.116 A:middle
accelerate image processing,

00:39:32.596 --> 00:39:34.536 A:middle
video editing, and improve your

00:39:34.536 --> 00:39:35.486 A:middle
overall frame rate.

00:39:36.016 --> 00:39:38.316 A:middle
In this section, I'm first going

00:39:38.316 --> 00:39:41.236 A:middle
to go over how Metal can be used

00:39:41.316 --> 00:39:42.606 A:middle
to leverage multi GPU

00:39:42.606 --> 00:39:43.616 A:middle
configurations.

00:39:44.576 --> 00:39:45.766 A:middle
Then I'll show you a few load

00:39:45.766 --> 00:39:47.056 A:middle
balancing strategies proven

00:39:47.056 --> 00:39:49.006 A:middle
effective by Pro App developers

00:39:49.006 --> 00:39:49.336 A:middle
today.

00:39:49.996 --> 00:39:51.286 A:middle
And finally, I'll discuss how to

00:39:51.286 --> 00:39:52.976 A:middle
synchronize operations between

00:39:52.976 --> 00:39:53.656 A:middle
your GPU's.

00:39:55.036 --> 00:39:57.046 A:middle
So what can Metal do for your

00:39:57.046 --> 00:39:57.866 A:middle
Pro App?

00:39:58.146 --> 00:39:59.626 A:middle
To start, Metal gives you all

00:39:59.626 --> 00:40:01.516 A:middle
the tools you need to detect all

00:39:59.626 --> 00:40:01.516 A:middle
the tools you need to detect all

00:40:01.516 --> 00:40:02.796 A:middle
the connected GPU's and their

00:40:02.796 --> 00:40:03.776 A:middle
capabilities.

00:40:04.666 --> 00:40:06.076 A:middle
With Metal it's easy to manage

00:40:06.076 --> 00:40:07.286 A:middle
multiple GPU's because they're

00:40:07.286 --> 00:40:08.796 A:middle
essentially just separate Metal

00:40:08.796 --> 00:40:09.776 A:middle
device objects.

00:40:10.166 --> 00:40:11.866 A:middle
So program them as the same as

00:40:11.866 --> 00:40:13.226 A:middle
you do today for a single GPU.

00:40:14.306 --> 00:40:15.906 A:middle
Metal also supports a brand-new

00:40:16.246 --> 00:40:17.516 A:middle
peer group transferring PI.

00:40:18.286 --> 00:40:19.746 A:middle
This incorporates the concept of

00:40:19.866 --> 00:40:21.796 A:middle
remote texture views which allow

00:40:21.796 --> 00:40:23.926 A:middle
you to copy data between GPU's.

00:40:24.866 --> 00:40:26.086 A:middle
And finally, Metal offers

00:40:26.136 --> 00:40:27.816 A:middle
powerful shared events that

00:40:27.816 --> 00:40:29.026 A:middle
allow you to synchronize your

00:40:29.026 --> 00:40:30.426 A:middle
workloads between GPU's.

00:40:30.666 --> 00:40:32.106 A:middle
Now let's take a quick look at

00:40:32.106 --> 00:40:33.836 A:middle
how to detect multi GPU

00:40:33.836 --> 00:40:34.786 A:middle
configurations.

00:40:36.676 --> 00:40:38.406 A:middle
Metal exposes device properties

00:40:38.406 --> 00:40:39.706 A:middle
to identify the location,

00:40:40.096 --> 00:40:41.866 A:middle
location number, and max

00:40:41.866 --> 00:40:43.336 A:middle
transfer rate for each device.

00:40:44.116 --> 00:40:45.306 A:middle
This information could be used

00:40:45.736 --> 00:40:47.466 A:middle
to say determine the fastest

00:40:47.466 --> 00:40:49.496 A:middle
possible hosted device transfer

00:40:49.496 --> 00:40:49.966 A:middle
device.

00:40:50.696 --> 00:40:52.246 A:middle
It can also be used to determine

00:40:52.286 --> 00:40:53.706 A:middle
if a device is integrated,

00:40:54.056 --> 00:40:56.296 A:middle
discreet, or external or even

00:40:56.296 --> 00:40:57.326 A:middle
low power or headless.

00:40:58.316 --> 00:40:59.716 A:middle
So once we're able to detect

00:40:59.716 --> 00:41:01.756 A:middle
multiple GPU's with this, it's

00:40:59.716 --> 00:41:01.756 A:middle
multiple GPU's with this, it's

00:41:01.756 --> 00:41:03.796 A:middle
time to think about how to

00:41:03.796 --> 00:41:05.066 A:middle
balance your workloads.

00:41:06.636 --> 00:41:08.426 A:middle
There is many, many ways to load

00:41:08.426 --> 00:41:10.416 A:middle
balance between GPU's, and

00:41:10.416 --> 00:41:11.226 A:middle
there's a lot of design

00:41:11.226 --> 00:41:12.136 A:middle
decisions that you have to

00:41:12.136 --> 00:41:13.076 A:middle
consider when you select

00:41:13.076 --> 00:41:13.756 A:middle
strategy.

00:41:14.526 --> 00:41:15.626 A:middle
At the end of the day what we

00:41:15.726 --> 00:41:17.806 A:middle
seek is a really simple load

00:41:17.806 --> 00:41:19.626 A:middle
balancing strategy with higher

00:41:19.676 --> 00:41:20.596 A:middle
scale and efficiency.

00:41:21.306 --> 00:41:22.726 A:middle
Let's go over a few proven

00:41:22.726 --> 00:41:24.036 A:middle
strategies that some Pro App

00:41:24.036 --> 00:41:25.956 A:middle
developers are using today.

00:41:26.736 --> 00:41:27.856 A:middle
The first and most

00:41:27.856 --> 00:41:29.916 A:middle
straightforward is supporting

00:41:29.916 --> 00:41:31.036 A:middle
alternating frames.

00:41:31.226 --> 00:41:32.916 A:middle
So the concept is to ping pong

00:41:32.916 --> 00:41:34.526 A:middle
odd and even frames between the

00:41:34.526 --> 00:41:35.346 A:middle
two GPU's.

00:41:35.976 --> 00:41:37.496 A:middle
This easily fits into existing

00:41:37.496 --> 00:41:39.236 A:middle
architectures and can

00:41:39.236 --> 00:41:40.506 A:middle
potentially double the rate that

00:41:40.506 --> 00:41:41.666 A:middle
you process frames.

00:41:42.316 --> 00:41:43.886 A:middle
However, sometimes apps have

00:41:44.566 --> 00:41:46.376 A:middle
variable workloads like UI

00:41:46.376 --> 00:41:48.106 A:middle
updates or graph building, and

00:41:48.106 --> 00:41:50.516 A:middle
this might result in unbalanced

00:41:50.866 --> 00:41:51.586 A:middle
load balancing.

00:41:52.136 --> 00:41:53.636 A:middle
So let's take a look at another

00:41:53.636 --> 00:41:54.156 A:middle
strategy.

00:41:54.766 --> 00:41:58.286 A:middle
This one uses small 32 by

00:41:58.336 --> 00:42:00.746 A:middle
32-pixel tiles to distribute

00:41:58.336 --> 00:42:00.746 A:middle
32-pixel tiles to distribute

00:42:00.826 --> 00:42:01.826 A:middle
[inaudible] evenly among the

00:42:01.826 --> 00:42:02.546 A:middle
GPU's.

00:42:03.266 --> 00:42:05.196 A:middle
So if you have four GPU's, you

00:42:05.196 --> 00:42:06.596 A:middle
can preselect separate tile

00:42:06.596 --> 00:42:07.436 A:middle
groups for each.

00:42:08.076 --> 00:42:09.626 A:middle
Here we use a random assignment

00:42:09.626 --> 00:42:10.946 A:middle
to avoid too much correlation

00:42:10.946 --> 00:42:11.516 A:middle
with the scene.

00:42:11.976 --> 00:42:13.986 A:middle
This means that mapping of tiles

00:42:13.986 --> 00:42:15.546 A:middle
to GPU's is constant from frame

00:42:15.546 --> 00:42:15.916 A:middle
to frame.

00:42:16.406 --> 00:42:18.376 A:middle
This is a really good solution

00:42:18.486 --> 00:42:20.386 A:middle
for compute heavy workloads but

00:42:20.386 --> 00:42:21.806 A:middle
might not be the best choice for

00:42:21.806 --> 00:42:22.926 A:middle
bandwidth intensive ones.

00:42:23.676 --> 00:42:24.916 A:middle
To see this in more detail,

00:42:24.916 --> 00:42:26.016 A:middle
check out the rate tracing

00:42:26.016 --> 00:42:26.446 A:middle
section.

00:42:26.586 --> 00:42:29.886 A:middle
So here's a similar approach

00:42:29.936 --> 00:42:31.146 A:middle
that uses a tile queue.

00:42:31.836 --> 00:42:32.796 A:middle
In this case, the host

00:42:32.796 --> 00:42:34.136 A:middle
application can populate the

00:42:34.136 --> 00:42:35.676 A:middle
queue with all the tiles.

00:42:36.426 --> 00:42:37.866 A:middle
They can then be dequeued on

00:42:37.866 --> 00:42:40.026 A:middle
demand by each GPU based on an

00:42:40.026 --> 00:42:41.606 A:middle
algorithm that keeps the GPU's

00:42:41.606 --> 00:42:41.996 A:middle
busy.

00:42:42.866 --> 00:42:44.446 A:middle
This approach may provide really

00:42:44.446 --> 00:42:45.996 A:middle
good load balancing but it is

00:42:45.996 --> 00:42:46.996 A:middle
adding more complexity.

00:42:48.306 --> 00:42:50.166 A:middle
So once we've decided on our

00:42:50.166 --> 00:42:51.916 A:middle
load balancing scheme, we need

00:42:51.916 --> 00:42:52.926 A:middle
to think about how to

00:42:53.016 --> 00:42:54.146 A:middle
synchronize our workloads

00:42:54.146 --> 00:42:55.526 A:middle
between the GPU's.

00:42:56.106 --> 00:42:58.626 A:middle
To accomplish this, Metal

00:42:58.626 --> 00:43:00.116 A:middle
provides a powerful construct

00:42:58.626 --> 00:43:00.116 A:middle
provides a powerful construct

00:43:00.116 --> 00:43:01.176 A:middle
called shared events.

00:43:01.846 --> 00:43:03.506 A:middle
They allow you to specify

00:43:03.736 --> 00:43:04.966 A:middle
synchronization points in your

00:43:04.966 --> 00:43:07.306 A:middle
app where you can wait and

00:43:07.366 --> 00:43:08.856 A:middle
signal for specific command

00:43:08.856 --> 00:43:09.286 A:middle
completion.

00:43:10.436 --> 00:43:12.116 A:middle
This can be done across GPU's,

00:43:12.556 --> 00:43:14.606 A:middle
between a CPU and the GPU, and

00:43:14.606 --> 00:43:15.526 A:middle
across processes.

00:43:16.136 --> 00:43:17.536 A:middle
Let's put this into practice.

00:43:18.566 --> 00:43:21.016 A:middle
So here's an example of a single

00:43:21.016 --> 00:43:22.416 A:middle
GPU workload that performs a

00:43:22.416 --> 00:43:23.926 A:middle
motion analysis on pairs of

00:43:23.926 --> 00:43:24.526 A:middle
frames.

00:43:25.136 --> 00:43:26.496 A:middle
Notice that these are all render

00:43:26.496 --> 00:43:27.746 A:middle
workloads so we can't take

00:43:27.746 --> 00:43:29.006 A:middle
advantage of the parallel

00:43:29.386 --> 00:43:30.566 A:middle
asynchronous channels that we

00:43:30.566 --> 00:43:33.556 A:middle
talked about earlier, but if we

00:43:33.556 --> 00:43:35.916 A:middle
have two GPU's, we can divide

00:43:35.916 --> 00:43:36.966 A:middle
this work between them to

00:43:36.966 --> 00:43:38.076 A:middle
improve performance.

00:43:38.436 --> 00:43:40.326 A:middle
So the strategy here is to move

00:43:40.326 --> 00:43:41.486 A:middle
the motion analysis to the

00:43:41.486 --> 00:43:42.336 A:middle
second GPU.

00:43:42.906 --> 00:43:45.166 A:middle
Keep in mind that each motion

00:43:45.166 --> 00:43:47.726 A:middle
pass has to analyze the previous

00:43:47.776 --> 00:43:48.676 A:middle
pair of frames.

00:43:49.316 --> 00:43:50.866 A:middle
This means that we have to wait

00:43:50.866 --> 00:43:51.956 A:middle
for the previous frames to be

00:43:51.956 --> 00:43:54.086 A:middle
written before we read them from

00:43:54.086 --> 00:43:56.076 A:middle
the motion pass and this repeats

00:43:56.146 --> 00:43:57.096 A:middle
for each frame pair.

00:43:57.746 --> 00:44:00.676 A:middle
So we can accomplish this by

00:43:57.746 --> 00:44:00.676 A:middle
So we can accomplish this by

00:44:00.676 --> 00:44:02.156 A:middle
using Metal shared events.

00:44:02.666 --> 00:44:03.886 A:middle
First, we need to signal

00:44:03.886 --> 00:44:05.246 A:middle
completion when the frames are

00:44:05.246 --> 00:44:07.276 A:middle
done rendering, and then we wait

00:44:07.276 --> 00:44:08.956 A:middle
for that signal before reading

00:44:08.956 --> 00:44:10.826 A:middle
them with motion pass.

00:44:11.566 --> 00:44:13.346 A:middle
And with this, we can safely

00:44:13.346 --> 00:44:14.886 A:middle
offload the motion analysis to a

00:44:14.886 --> 00:44:16.836 A:middle
second GPU and everything runs

00:44:16.836 --> 00:44:17.336 A:middle
in parallel.

00:44:18.056 --> 00:44:19.676 A:middle
And because the signal

00:44:19.766 --> 00:44:21.026 A:middle
[inaudible] encoded on the GPU,

00:44:21.346 --> 00:44:22.776 A:middle
you don't block any CPU

00:44:22.776 --> 00:44:23.326 A:middle
execution.

00:44:24.426 --> 00:44:25.896 A:middle
So now let's take a look at how

00:44:25.896 --> 00:44:26.876 A:middle
we can do this in our code.

00:44:27.526 --> 00:44:29.806 A:middle
So the first thing we're going

00:44:29.806 --> 00:44:31.266 A:middle
to do is create a shared event

00:44:31.736 --> 00:44:33.076 A:middle
from the device that renders our

00:44:33.076 --> 00:44:33.786 A:middle
frames.

00:44:34.576 --> 00:44:36.416 A:middle
We also create two command

00:44:36.446 --> 00:44:37.916 A:middle
queues, one for each device.

00:44:39.116 --> 00:44:40.796 A:middle
Now to render the frames, we

00:44:40.796 --> 00:44:42.006 A:middle
create a command buffer and

00:44:42.236 --> 00:44:44.676 A:middle
encode, then immediately encode

00:44:44.676 --> 00:44:46.286 A:middle
a signal event to notify the

00:44:46.286 --> 00:44:47.566 A:middle
other GPU's that we're complete.

00:44:48.606 --> 00:44:50.356 A:middle
And finally, to encode the

00:44:50.356 --> 00:44:54.426 A:middle
motion, we start by creating a

00:44:54.426 --> 00:44:55.576 A:middle
command buffer from the queue.

00:44:56.096 --> 00:44:57.496 A:middle
Then immediately encode a wait

00:44:57.496 --> 00:44:59.296 A:middle
event to avoid reading the

00:44:59.296 --> 00:45:00.416 A:middle
frames before they're done.

00:44:59.296 --> 00:45:00.416 A:middle
frames before they're done.

00:45:01.466 --> 00:45:02.666 A:middle
And then we encode the motion

00:45:02.666 --> 00:45:04.786 A:middle
analysis and commit, and as you

00:45:04.786 --> 00:45:05.876 A:middle
can see it's a fairly

00:45:05.986 --> 00:45:07.306 A:middle
straightforward process and it's

00:45:07.306 --> 00:45:08.186 A:middle
very powerful.

00:45:08.576 --> 00:45:10.576 A:middle
And before I move on, let's take

00:45:10.576 --> 00:45:12.196 A:middle
a look at how we can look at

00:45:12.516 --> 00:45:14.316 A:middle
multi GPU's and channels in our

00:45:14.316 --> 00:45:14.916 A:middle
tools.

00:45:15.486 --> 00:45:18.726 A:middle
So Metal System Trace shows the

00:45:18.726 --> 00:45:20.616 A:middle
work for each of your test

00:45:20.616 --> 00:45:21.146 A:middle
GPU's.

00:45:21.616 --> 00:45:22.896 A:middle
In this example we're using four

00:45:22.966 --> 00:45:23.446 A:middle
GPU's.

00:45:23.446 --> 00:45:25.896 A:middle
One internal, and three external

00:45:25.896 --> 00:45:26.536 A:middle
GPU's.

00:45:26.876 --> 00:45:30.156 A:middle
It exposes detailed visibility

00:45:30.436 --> 00:45:32.166 A:middle
into each GPU by showing all the

00:45:32.166 --> 00:45:34.116 A:middle
asynchronous workloads across

00:45:34.116 --> 00:45:35.936 A:middle
all the channels, and it maps

00:45:35.996 --> 00:45:38.266 A:middle
those workloads with relevant

00:45:38.316 --> 00:45:39.116 A:middle
symbol names.

00:45:39.706 --> 00:45:42.416 A:middle
In the activity summary, you

00:45:42.416 --> 00:45:43.616 A:middle
could actually see all the

00:45:43.616 --> 00:45:45.246 A:middle
execution statistics for all the

00:45:45.246 --> 00:45:46.286 A:middle
connected GPU's.

00:45:47.566 --> 00:45:48.956 A:middle
You could even dive deeper to

00:45:49.016 --> 00:45:50.246 A:middle
see more detailed channel

00:45:50.246 --> 00:45:52.776 A:middle
information for any GPU on a per

00:45:52.776 --> 00:45:53.536 A:middle
frame basis.

00:45:54.296 --> 00:45:55.676 A:middle
This includes details for page

00:45:55.676 --> 00:45:56.926 A:middle
on and page off in the blit

00:45:56.926 --> 00:45:58.996 A:middle
channel or compute and render

00:45:58.996 --> 00:45:59.716 A:middle
workloads.

00:46:00.686 --> 00:46:02.266 A:middle
You can even drill down to see

00:46:02.266 --> 00:46:03.666 A:middle
IOSurface access.

00:46:04.336 --> 00:46:05.476 A:middle
As Eugene mentioned, this is

00:46:05.476 --> 00:46:06.536 A:middle
something that's very useful

00:46:06.536 --> 00:46:07.896 A:middle
because a lot of Pro Apps need

00:46:07.896 --> 00:46:10.976 A:middle
to utilize IOSurfaces, which is

00:46:11.406 --> 00:46:12.946 A:middle
really necessary for framework

00:46:13.006 --> 00:46:13.886 A:middle
interoperability.

00:46:14.446 --> 00:46:17.546 A:middle
And finally, our tools give you

00:46:17.546 --> 00:46:19.146 A:middle
visibility into Metal events and

00:46:19.146 --> 00:46:19.896 A:middle
shared events.

00:46:19.896 --> 00:46:22.096 A:middle
So you can actually see where

00:46:22.096 --> 00:46:23.206 A:middle
the signal and wait events

00:46:23.206 --> 00:46:23.646 A:middle
occur.

00:46:24.466 --> 00:46:25.406 A:middle
It also shows how many

00:46:25.406 --> 00:46:26.896 A:middle
milliseconds are spent waiting

00:46:27.386 --> 00:46:28.756 A:middle
and draws dependency lines for

00:46:28.756 --> 00:46:29.366 A:middle
you to follow.

00:46:30.596 --> 00:46:31.606 A:middle
And finally at the bottom,

00:46:31.746 --> 00:46:32.736 A:middle
there's even detailed lists

00:46:32.736 --> 00:46:33.996 A:middle
about your events in the

00:46:33.996 --> 00:46:34.786 A:middle
activity summary.

00:46:35.446 --> 00:46:37.096 A:middle
So Metal system trace is a great

00:46:37.146 --> 00:46:38.796 A:middle
tool for all your Pro App needs.

00:46:39.626 --> 00:46:40.626 A:middle
So now that we understand how to

00:46:40.626 --> 00:46:42.846 A:middle
utilize multiple GPU's, let's

00:46:42.846 --> 00:46:44.306 A:middle
look at how to transfer data

00:46:44.306 --> 00:46:45.476 A:middle
between them.

00:46:46.976 --> 00:46:48.646 A:middle
Scaling performance across CPU's

00:46:48.646 --> 00:46:49.936 A:middle
and GPU's is extremely

00:46:49.936 --> 00:46:51.676 A:middle
important, but at the end of the

00:46:51.676 --> 00:46:53.666 A:middle
day your Pro App is only as fast

00:46:53.666 --> 00:46:55.016 A:middle
as its slowest bottleneck.

00:46:55.856 --> 00:46:57.236 A:middle
When you're transferring massive

00:46:57.236 --> 00:46:59.776 A:middle
8K frames, your data transfers

00:46:59.776 --> 00:47:00.786 A:middle
can quickly become that

00:46:59.776 --> 00:47:00.786 A:middle
can quickly become that

00:47:00.786 --> 00:47:01.286 A:middle
bottleneck.

00:47:01.896 --> 00:47:04.396 A:middle
In this section, I'm going to

00:47:04.396 --> 00:47:05.276 A:middle
talk about bandwidth

00:47:05.276 --> 00:47:07.186 A:middle
considerations and how they

00:47:07.186 --> 00:47:08.436 A:middle
relate to the new Mac Pro.

00:47:09.476 --> 00:47:11.806 A:middle
Then I'll review a few Metal

00:47:11.806 --> 00:47:13.746 A:middle
peer groups transfer strategies,

00:47:14.126 --> 00:47:15.156 A:middle
and some of these are already in

00:47:15.156 --> 00:47:16.796 A:middle
use today by Pro App developers.

00:47:17.276 --> 00:47:18.316 A:middle
And finally I'll walk you

00:47:18.356 --> 00:47:20.186 A:middle
through an example use case to

00:47:20.186 --> 00:47:21.676 A:middle
show how Infinity Fabric Link

00:47:21.676 --> 00:47:22.926 A:middle
can help unlock challenging

00:47:22.926 --> 00:47:23.656 A:middle
workflows.

00:47:24.286 --> 00:47:27.496 A:middle
So let's start by looking at the

00:47:27.496 --> 00:47:28.686 A:middle
transfer rates for our key

00:47:28.726 --> 00:47:29.636 A:middle
connection points.

00:47:29.986 --> 00:47:31.866 A:middle
Our baseline here is PCI Express

00:47:31.906 --> 00:47:33.696 A:middle
gen 3 with 16 links.

00:47:34.846 --> 00:47:36.206 A:middle
So first we have Thunderbolt 3.

00:47:36.206 --> 00:47:38.586 A:middle
In the real world this maxes out

00:47:38.586 --> 00:47:39.956 A:middle
around one-quarter of the rate

00:47:39.956 --> 00:47:41.076 A:middle
of PCI Express.

00:47:41.486 --> 00:47:42.846 A:middle
It's a really great scalable

00:47:42.846 --> 00:47:44.456 A:middle
solution for compute heavy

00:47:44.456 --> 00:47:45.996 A:middle
workloads but maybe not the best

00:47:46.076 --> 00:47:47.386 A:middle
for bandwidth intensive ones.

00:47:48.146 --> 00:47:51.096 A:middle
Next we have two GPU's each with

00:47:51.096 --> 00:47:52.256 A:middle
their one PCI lanes.

00:47:52.576 --> 00:47:53.936 A:middle
This can double your bandwidth.

00:47:55.026 --> 00:47:57.096 A:middle
And this week we introduced the

00:47:57.096 --> 00:47:58.706 A:middle
new Infinity Fabric Link with

00:47:58.826 --> 00:48:00.006 A:middle
the peer group transfer API

00:47:58.826 --> 00:48:00.006 A:middle
the peer group transfer API

00:48:00.596 --> 00:48:02.036 A:middle
which can transfer data between

00:48:02.036 --> 00:48:04.046 A:middle
GPU's at speeds up to five times

00:48:04.046 --> 00:48:07.166 A:middle
that of PCI Express.

00:48:07.606 --> 00:48:09.526 A:middle
So now let's look at some common

00:48:09.616 --> 00:48:10.786 A:middle
Mac Pro configurations.

00:48:11.596 --> 00:48:13.156 A:middle
This diagram illustrates a great

00:48:13.156 --> 00:48:14.426 A:middle
configuration for bandwidth

00:48:14.426 --> 00:48:15.196 A:middle
intensive ones.

00:48:16.146 --> 00:48:17.556 A:middle
Here we have a new Apple

00:48:17.556 --> 00:48:19.056 A:middle
Afterburner which has its own

00:48:19.056 --> 00:48:20.346 A:middle
dedicated PCI lanes.

00:48:21.226 --> 00:48:22.876 A:middle
We also have two internal GPU's

00:48:22.876 --> 00:48:24.386 A:middle
with their own dedicated PCI

00:48:24.386 --> 00:48:24.616 A:middle
lanes.

00:48:25.496 --> 00:48:26.716 A:middle
And finally, you can connect

00:48:26.816 --> 00:48:28.456 A:middle
those GPU's with Infinity Fabric

00:48:28.526 --> 00:48:30.346 A:middle
Link to quickly copy data

00:48:30.346 --> 00:48:31.566 A:middle
between them.

00:48:32.976 --> 00:48:34.476 A:middle
The Mac Pro also allows you to

00:48:34.476 --> 00:48:36.356 A:middle
have up to four internal GPU's

00:48:36.356 --> 00:48:38.096 A:middle
that share two sets of PCI

00:48:38.096 --> 00:48:38.336 A:middle
lanes.

00:48:39.226 --> 00:48:40.456 A:middle
Because the lanes are shared, it

00:48:40.456 --> 00:48:41.726 A:middle
lends itself maybe to a more

00:48:41.726 --> 00:48:43.156 A:middle
compute heavy pro application.

00:48:43.766 --> 00:48:45.516 A:middle
And in this case, it can also be

00:48:45.516 --> 00:48:46.556 A:middle
connected with the Infinity

00:48:46.596 --> 00:48:47.126 A:middle
Fabric Link.

00:48:47.706 --> 00:48:51.506 A:middle
So there is many, many ways to

00:48:51.506 --> 00:48:52.646 A:middle
manage these transfer

00:48:52.646 --> 00:48:53.466 A:middle
strategies.

00:48:53.886 --> 00:48:55.026 A:middle
I'm going to go over a few

00:48:55.026 --> 00:48:56.676 A:middle
proven strategies that some Pro

00:48:56.676 --> 00:48:57.926 A:middle
App developers are using today.

00:48:59.186 --> 00:49:00.866 A:middle
The most straightforward

00:48:59.186 --> 00:49:00.866 A:middle
The most straightforward

00:49:00.866 --> 00:49:02.446 A:middle
approach is to transfer entire

00:49:02.506 --> 00:49:03.496 A:middle
frames for display.

00:49:04.196 --> 00:49:05.396 A:middle
The premise is to process

00:49:05.396 --> 00:49:06.646 A:middle
alternating frames.

00:49:06.986 --> 00:49:08.206 A:middle
Any frame processed on the

00:49:08.206 --> 00:49:09.846 A:middle
auxiliary device can be

00:49:09.846 --> 00:49:10.876 A:middle
transferred quickly to the

00:49:10.876 --> 00:49:12.926 A:middle
display attached GPU and then

00:49:13.236 --> 00:49:16.516 A:middle
sent to the display.

00:49:16.516 --> 00:49:17.926 A:middle
Another transfer strategy is to

00:49:17.926 --> 00:49:20.566 A:middle
send tiles to each GPU that are

00:49:20.566 --> 00:49:22.156 A:middle
essentially pieces of the entire

00:49:22.156 --> 00:49:22.546 A:middle
frame.

00:49:23.376 --> 00:49:24.736 A:middle
All the tiles processed on the

00:49:24.736 --> 00:49:26.146 A:middle
auxiliary device can be sent to

00:49:26.146 --> 00:49:27.956 A:middle
the display GPU and then

00:49:27.956 --> 00:49:29.276 A:middle
reconstructed as part of the

00:49:29.276 --> 00:49:30.526 A:middle
final output image.

00:49:31.566 --> 00:49:32.826 A:middle
This result has really good load

00:49:32.826 --> 00:49:33.246 A:middle
balancing.

00:49:34.186 --> 00:49:35.826 A:middle
So we've looked at two

00:49:35.826 --> 00:49:36.956 A:middle
strategies quickly.

00:49:37.336 --> 00:49:39.066 A:middle
Now let's see a great example of

00:49:39.066 --> 00:49:40.806 A:middle
a Pro App actually leveraging

00:49:40.806 --> 00:49:42.646 A:middle
the Infinity Fabric Link.

00:49:43.556 --> 00:49:45.316 A:middle
So over the last six months,

00:49:45.316 --> 00:49:46.976 A:middle
I've had the opportunity to

00:49:46.976 --> 00:49:48.326 A:middle
collaborate with the Final Cut

00:49:48.326 --> 00:49:48.716 A:middle
Pro team.

00:49:49.426 --> 00:49:51.056 A:middle
They've done an outstanding job

00:49:51.056 --> 00:49:52.746 A:middle
optimizing for the new Mac Pro.

00:49:53.536 --> 00:49:55.496 A:middle
They're scaling across 28 CPU

00:49:55.496 --> 00:49:58.066 A:middle
cores and all internal GPU's.

00:49:58.916 --> 00:50:00.376 A:middle
They've also fully utilized the

00:49:58.916 --> 00:50:00.376 A:middle
They've also fully utilized the

00:50:00.376 --> 00:50:01.436 A:middle
Infinity Fabric Link.

00:50:02.026 --> 00:50:03.416 A:middle
This is helping them to enable

00:50:03.526 --> 00:50:06.286 A:middle
real time editing of multiple 8K

00:50:06.286 --> 00:50:06.976 A:middle
ProRes video streams.

00:50:08.406 --> 00:50:09.836 A:middle
Now let's take a closer look at

00:50:09.836 --> 00:50:10.886 A:middle
how this works.

00:50:12.306 --> 00:50:13.516 A:middle
So here we have a simple

00:50:13.516 --> 00:50:14.956 A:middle
timeline diagram that shows how

00:50:14.956 --> 00:50:16.886 A:middle
video streams move from the CPU

00:50:16.996 --> 00:50:17.716 A:middle
to the display.

00:50:17.716 --> 00:50:19.816 A:middle
In this case we're focusing on

00:50:19.876 --> 00:50:22.136 A:middle
playback of three 8k ProRes raw

00:50:22.136 --> 00:50:23.796 A:middle
video streams with some effects.

00:50:24.816 --> 00:50:25.706 A:middle
This is how it might look on a

00:50:25.766 --> 00:50:26.536 A:middle
single GPU.

00:50:28.116 --> 00:50:29.536 A:middle
So first, we encode frame one

00:50:29.536 --> 00:50:30.636 A:middle
commands on the CPU.

00:50:31.706 --> 00:50:33.536 A:middle
Then upload all three streams

00:50:33.536 --> 00:50:34.946 A:middle
over PCI to VRAM.

00:50:36.166 --> 00:50:38.206 A:middle
Finally we process those streams

00:50:38.206 --> 00:50:39.976 A:middle
with effects on the GPU and

00:50:39.976 --> 00:50:40.486 A:middle
display.

00:50:41.016 --> 00:50:43.276 A:middle
We continue this process for

00:50:43.276 --> 00:50:44.736 A:middle
each of the additional frames.

00:50:45.876 --> 00:50:47.186 A:middle
And as much as we want this to

00:50:47.186 --> 00:50:48.696 A:middle
fit within our 30 frames per

00:50:48.696 --> 00:50:50.466 A:middle
second, it won't.

00:50:50.846 --> 00:50:52.316 A:middle
It's just too much work to pack

00:50:52.316 --> 00:50:53.286 A:middle
into that space.

00:50:53.626 --> 00:50:55.926 A:middle
A Pro App will drop at least 30%

00:50:55.926 --> 00:50:56.696 A:middle
of their frames in this

00:50:56.696 --> 00:50:57.296 A:middle
scenario.

00:50:57.936 --> 00:50:58.916 A:middle
Now let's see how this might

00:50:58.916 --> 00:51:00.826 A:middle
work on a dual GPU system.

00:50:58.916 --> 00:51:00.826 A:middle
work on a dual GPU system.

00:51:02.046 --> 00:51:04.456 A:middle
So first, we encode frame one as

00:51:04.456 --> 00:51:05.466 A:middle
in the previous example.

00:51:06.546 --> 00:51:07.816 A:middle
For frame two, we follow a

00:51:07.816 --> 00:51:08.846 A:middle
similar process.

00:51:09.386 --> 00:51:10.606 A:middle
Now this is looking really good.

00:51:10.606 --> 00:51:12.286 A:middle
We've got things going in

00:51:12.286 --> 00:51:12.976 A:middle
parallel here.

00:51:13.306 --> 00:51:14.696 A:middle
But do we double our frame rate?

00:51:15.406 --> 00:51:16.796 A:middle
Unfortunately, we don't.

00:51:17.456 --> 00:51:20.356 A:middle
The problem comes when any frame

00:51:20.356 --> 00:51:21.516 A:middle
that we've processed on the

00:51:21.516 --> 00:51:23.136 A:middle
auxiliary device has to somehow

00:51:23.136 --> 00:51:24.996 A:middle
be copied back to the display

00:51:24.996 --> 00:51:26.206 A:middle
attach device, and this is where

00:51:26.266 --> 00:51:27.096 A:middle
things get tricky.

00:51:27.766 --> 00:51:30.256 A:middle
To get the display GPU, we have

00:51:30.256 --> 00:51:33.106 A:middle
to copy a 265-megabyte output

00:51:33.106 --> 00:51:35.936 A:middle
buffer over PCI to the host, and

00:51:35.936 --> 00:51:37.566 A:middle
then we copy a second time from

00:51:37.566 --> 00:51:38.866 A:middle
there to the display attached

00:51:38.866 --> 00:51:39.246 A:middle
GPU.

00:51:40.606 --> 00:51:42.026 A:middle
This can take up to 48

00:51:42.026 --> 00:51:43.206 A:middle
milliseconds on a good day.

00:51:43.626 --> 00:51:45.136 A:middle
So now, let's continue with

00:51:45.136 --> 00:51:46.516 A:middle
frames three and four to give

00:51:46.516 --> 00:51:48.000 A:middle
you a better picture.

00:51:50.436 --> 00:51:51.746 A:middle
And you can quickly see that

00:51:51.746 --> 00:51:52.866 A:middle
we're using a considerable

00:51:52.866 --> 00:51:54.936 A:middle
amount of PCI bandwidth but also

00:51:54.936 --> 00:51:56.106 A:middle
we see a lot of gaps and

00:51:56.106 --> 00:51:56.856 A:middle
dependencies.

00:51:57.296 --> 00:51:58.406 A:middle
We're still doing better than

00:51:58.406 --> 00:52:00.076 A:middle
the single GPU case, but it's

00:51:58.406 --> 00:52:00.076 A:middle
the single GPU case, but it's

00:52:00.076 --> 00:52:01.326 A:middle
not going to double our frame

00:52:01.326 --> 00:52:01.496 A:middle
rate.

00:52:02.386 --> 00:52:04.306 A:middle
All this PCI traffic will result

00:52:04.306 --> 00:52:05.586 A:middle
in dropping some frames.

00:52:06.146 --> 00:52:09.076 A:middle
But to improve on this problem,

00:52:09.376 --> 00:52:11.186 A:middle
the Mac Pro introduces the new

00:52:11.186 --> 00:52:12.456 A:middle
Infinity Fabric Link feature

00:52:12.456 --> 00:52:13.586 A:middle
with the peer group API.

00:52:14.056 --> 00:52:16.006 A:middle
This completely blows away the

00:52:16.006 --> 00:52:16.776 A:middle
GPU copy.

00:52:18.436 --> 00:52:20.046 A:middle
You could see here with Infinity

00:52:20.046 --> 00:52:21.656 A:middle
Fabric Link the transfer is much

00:52:21.656 --> 00:52:22.316 A:middle
faster.

00:52:23.046 --> 00:52:24.666 A:middle
It also frees up a considerable

00:52:24.666 --> 00:52:27.576 A:middle
amount of PCI bandwidth and with

00:52:27.576 --> 00:52:29.186 A:middle
that bandwidth we can upload our

00:52:29.246 --> 00:52:30.226 A:middle
frames earlier.

00:52:32.256 --> 00:52:33.786 A:middle
Infinity Fabric Link also

00:52:33.786 --> 00:52:35.556 A:middle
operates on its own parallel GPU

00:52:35.556 --> 00:52:35.956 A:middle
channel.

00:52:36.526 --> 00:52:37.576 A:middle
This means you could transfer

00:52:37.576 --> 00:52:39.216 A:middle
data while using the render and

00:52:39.216 --> 00:52:40.306 A:middle
compute channels at the same

00:52:40.306 --> 00:52:40.596 A:middle
time.

00:52:41.916 --> 00:52:42.846 A:middle
This helps us to improve

00:52:42.846 --> 00:52:44.486 A:middle
concurrency and hide latency.

00:52:44.856 --> 00:52:46.316 A:middle
At the end of the day, this can

00:52:46.316 --> 00:52:48.006 A:middle
enable your Pro App to unlock

00:52:48.316 --> 00:52:49.776 A:middle
challenging workloads and enable

00:52:49.776 --> 00:52:50.646 A:middle
new use cases.

00:52:51.346 --> 00:52:52.406 A:middle
So this is what it looks like on

00:52:52.406 --> 00:52:53.786 A:middle
a boring timeline diagram.

00:52:54.376 --> 00:52:55.566 A:middle
But now let's see what it looks

00:52:55.566 --> 00:52:56.076 A:middle
in action.

00:52:56.666 --> 00:52:59.336 A:middle
This is the Final Cut Pro demo

00:52:59.336 --> 00:53:00.296 A:middle
you saw in the keynote.

00:52:59.336 --> 00:53:00.296 A:middle
you saw in the keynote.

00:53:00.886 --> 00:53:01.856 A:middle
You can see it plays back

00:53:01.856 --> 00:53:03.776 A:middle
multiple streams of 8K video

00:53:03.776 --> 00:53:05.336 A:middle
with effects and transitions.

00:53:05.336 --> 00:53:08.316 A:middle
This is also done in real time

00:53:08.316 --> 00:53:09.806 A:middle
using multiple GPU's and the

00:53:09.806 --> 00:53:10.776 A:middle
Infinity Fabric Link.

00:53:11.776 --> 00:53:13.556 A:middle
Final Cut Pro is an outstanding

00:53:13.556 --> 00:53:15.356 A:middle
example of a Pro App utilizing

00:53:15.586 --> 00:53:17.066 A:middle
efficient data transfers.

00:53:17.376 --> 00:53:19.136 A:middle
So now before we close this

00:53:19.136 --> 00:53:21.156 A:middle
section, let's look at how to

00:53:21.156 --> 00:53:22.846 A:middle
use Infinity Fabric Link and the

00:53:22.966 --> 00:53:25.336 A:middle
peer grant transfer group API in

00:53:25.336 --> 00:53:25.796 A:middle
your code.

00:53:26.466 --> 00:53:29.456 A:middle
So the first thing you need to

00:53:29.976 --> 00:53:31.756 A:middle
do is detect these connections.

00:53:32.176 --> 00:53:33.666 A:middle
To facilitate this, Metal

00:53:33.666 --> 00:53:35.376 A:middle
defines a brand-new peer group

00:53:35.376 --> 00:53:37.626 A:middle
API, defines properties on the

00:53:37.626 --> 00:53:39.516 A:middle
Metal device for peer group ID,

00:53:39.596 --> 00:53:40.546 A:middle
index, and count.

00:53:41.866 --> 00:53:43.146 A:middle
With this you can detect if you

00:53:43.146 --> 00:53:44.836 A:middle
have linked GPU's and if they

00:53:44.836 --> 00:53:46.726 A:middle
have shared PCI lanes or dual

00:53:46.726 --> 00:53:47.546 A:middle
PCI lanes.

00:53:47.916 --> 00:53:49.206 A:middle
More importantly, you can use

00:53:49.206 --> 00:53:52.046 A:middle
this to determine the best

00:53:52.046 --> 00:53:53.756 A:middle
configuration for you and scale

00:53:53.756 --> 00:53:54.886 A:middle
your performance based on the

00:53:54.886 --> 00:53:56.016 A:middle
bandwidth limitations.

00:53:58.226 --> 00:53:59.296 A:middle
And this is how you transfer

00:53:59.296 --> 00:54:00.746 A:middle
data between GPU's.

00:53:59.296 --> 00:54:00.746 A:middle
data between GPU's.

00:54:01.226 --> 00:54:02.766 A:middle
The first thing you need to do

00:54:02.766 --> 00:54:04.366 A:middle
is create your shared event from

00:54:04.366 --> 00:54:05.476 A:middle
the auxiliary device.

00:54:06.396 --> 00:54:08.466 A:middle
We also create a render texture

00:54:08.466 --> 00:54:10.006 A:middle
and a remote texture view.

00:54:10.436 --> 00:54:11.616 A:middle
The remote view will give our

00:54:11.616 --> 00:54:13.926 A:middle
display attached GPU access to

00:54:14.036 --> 00:54:15.396 A:middle
the auxiliary texture.

00:54:17.016 --> 00:54:18.436 A:middle
Next we create an encoder and

00:54:18.436 --> 00:54:18.846 A:middle
render.

00:54:20.136 --> 00:54:20.976 A:middle
This should immediately be

00:54:21.056 --> 00:54:22.486 A:middle
followed by the encoded signal

00:54:23.366 --> 00:54:23.526 A:middle
event.

00:54:24.416 --> 00:54:26.066 A:middle
Now on the display device we

00:54:26.066 --> 00:54:27.446 A:middle
create a blit command buffer.

00:54:28.036 --> 00:54:29.426 A:middle
We immediately encode a wait

00:54:29.426 --> 00:54:29.756 A:middle
event.

00:54:29.826 --> 00:54:31.046 A:middle
So we wait for the rendering to

00:54:31.046 --> 00:54:32.476 A:middle
complete before transferring the

00:54:32.476 --> 00:54:32.826 A:middle
data.

00:54:33.446 --> 00:54:36.406 A:middle
And finally we do a copy using

00:54:36.406 --> 00:54:37.736 A:middle
the textured view, and that's

00:54:37.736 --> 00:54:38.006 A:middle
it.

00:54:38.406 --> 00:54:39.026 A:middle
Very simple.

00:54:41.596 --> 00:54:43.446 A:middle
Utilizing Metal peer group API

00:54:43.596 --> 00:54:45.436 A:middle
to leverage Infinity Fabric Link

00:54:45.676 --> 00:54:47.336 A:middle
can unlock challenging workloads

00:54:47.336 --> 00:54:49.196 A:middle
by reducing your PCI bandwidth.

00:54:49.726 --> 00:54:51.516 A:middle
It also can enhance concurrency

00:54:51.846 --> 00:54:53.086 A:middle
by using a parallel channel.

00:54:53.846 --> 00:54:55.026 A:middle
So before I conclude this

00:54:55.026 --> 00:54:57.306 A:middle
session, let's look at one more

00:54:57.376 --> 00:54:58.846 A:middle
really great Pro App in action.

00:55:00.366 --> 00:55:01.616 A:middle
So now I'm excited to share a

00:55:01.616 --> 00:55:03.266 A:middle
demo of Affinity Photo from

00:55:03.266 --> 00:55:04.176 A:middle
Serif Labs.

00:55:04.746 --> 00:55:05.916 A:middle
The engineers at Serif have done

00:55:05.916 --> 00:55:07.886 A:middle
an outstanding job of adopting

00:55:07.886 --> 00:55:08.266 A:middle
Metal.

00:55:08.626 --> 00:55:10.836 A:middle
They're also a really, really

00:55:10.836 --> 00:55:12.676 A:middle
good example of how to

00:55:12.676 --> 00:55:13.996 A:middle
officially leverage platform

00:55:13.996 --> 00:55:14.686 A:middle
resources.

00:55:15.266 --> 00:55:16.836 A:middle
On a typical document, their

00:55:16.836 --> 00:55:18.256 A:middle
performance can be around 10

00:55:18.256 --> 00:55:20.126 A:middle
times faster on a single GPU

00:55:20.396 --> 00:55:21.876 A:middle
when compared to an eight course

00:55:21.876 --> 00:55:22.296 A:middle
CPU.

00:55:23.186 --> 00:55:23.936 A:middle
Let's take a look.

00:55:25.566 --> 00:55:26.876 A:middle
So in this example, Affinity is

00:55:26.876 --> 00:55:29.126 A:middle
going to be live compositing a

00:55:29.126 --> 00:55:30.296 A:middle
massive document called the

00:55:30.336 --> 00:55:30.936 A:middle
rabbit trick.

00:55:31.726 --> 00:55:32.996 A:middle
As the video demonstrates, it

00:55:32.996 --> 00:55:34.796 A:middle
has hundreds of massive layers,

00:55:35.026 --> 00:55:36.616 A:middle
and they'll be compositing at 4K

00:55:36.616 --> 00:55:37.196 A:middle
resolution.

00:55:38.156 --> 00:55:39.456 A:middle
Some layers have pixel data

00:55:39.456 --> 00:55:40.656 A:middle
while others have procedural

00:55:40.656 --> 00:55:41.466 A:middle
adjustments.

00:55:42.446 --> 00:55:43.476 A:middle
This will be hierarchically

00:55:43.476 --> 00:55:46.056 A:middle
composited in real time, and

00:55:46.056 --> 00:55:47.406 A:middle
this will also put a tremendous

00:55:47.406 --> 00:55:49.456 A:middle
load on both the CPU and the

00:55:49.886 --> 00:55:50.000 A:middle
GPU.

00:55:52.006 --> 00:55:53.556 A:middle
Now let's run this massive

00:55:53.596 --> 00:55:54.606 A:middle
document on the CPU.

00:55:55.396 --> 00:55:57.256 A:middle
This is using an 18-core system.

00:55:57.736 --> 00:55:58.636 A:middle
You could see that we're able to

00:55:58.636 --> 00:56:00.516 A:middle
composite in real time; however,

00:55:58.636 --> 00:56:00.516 A:middle
composite in real time; however,

00:56:00.516 --> 00:56:02.736 A:middle
the document is so complex it

00:56:02.736 --> 00:56:03.896 A:middle
gets a little bit choppy in the

00:56:03.896 --> 00:56:04.966 A:middle
user interface.

00:56:08.946 --> 00:56:10.286 A:middle
Now let's switch and run that on

00:56:10.286 --> 00:56:11.276 A:middle
a single GPU.

00:56:12.266 --> 00:56:13.346 A:middle
Here, you can see the UI

00:56:13.346 --> 00:56:15.076 A:middle
responds really well and

00:56:15.076 --> 00:56:16.256 A:middle
everything runs smoothly.

00:56:16.476 --> 00:56:18.366 A:middle
The frame rate runs about 18 to

00:56:18.366 --> 00:56:19.500 A:middle
20 frames per second.

00:56:22.616 --> 00:56:23.776 A:middle
And now for the best part.

00:56:23.776 --> 00:56:25.456 A:middle
We're going to enable a total of

00:56:25.646 --> 00:56:27.856 A:middle
four external GPU's and as you

00:56:27.856 --> 00:56:29.076 A:middle
can see it runs incredibly

00:56:29.166 --> 00:56:30.746 A:middle
smooth and it maintains greater

00:56:30.746 --> 00:56:31.996 A:middle
than 60 frames per second the

00:56:31.996 --> 00:56:32.786 A:middle
entire time.

00:56:33.436 --> 00:56:34.566 A:middle
This is due in part to

00:56:34.566 --> 00:56:36.906 A:middle
Affinity's advanced tile-based

00:56:36.906 --> 00:56:37.896 A:middle
load balancing scheme.

00:56:38.586 --> 00:56:39.716 A:middle
They can distribute their work

00:56:39.716 --> 00:56:41.466 A:middle
efficiently among any number of

00:56:41.466 --> 00:56:43.326 A:middle
GPU's, and with this they can

00:56:43.326 --> 00:56:44.556 A:middle
achieve linear performance

00:56:44.556 --> 00:56:45.046 A:middle
scaling.

00:56:45.656 --> 00:56:48.236 A:middle
Here is one last example that I

00:56:48.236 --> 00:56:48.686 A:middle
want to share.

00:56:49.696 --> 00:56:50.826 A:middle
This is one of Affinity Photo's

00:56:50.826 --> 00:56:52.546 A:middle
most memory bandwidth intensive

00:56:52.546 --> 00:56:54.236 A:middle
filters known as depth of field.

00:56:55.426 --> 00:56:56.566 A:middle
Here we're previewing in real

00:56:56.566 --> 00:56:57.896 A:middle
time on the CPU.

00:56:58.556 --> 00:57:00.096 A:middle
You can visually see the time it

00:56:58.556 --> 00:57:00.096 A:middle
You can visually see the time it

00:57:00.096 --> 00:57:01.226 A:middle
takes between applying the

00:57:01.226 --> 00:57:02.286 A:middle
effect and it actually

00:57:02.286 --> 00:57:02.706 A:middle
rendering.

00:57:03.626 --> 00:57:04.956 A:middle
This is still impressive, and

00:57:04.956 --> 00:57:06.996 A:middle
it's fast, but the GPU can make

00:57:06.996 --> 00:57:08.000 A:middle
this even better.

00:57:09.336 --> 00:57:10.066 A:middle
So now we're going to run the

00:57:10.066 --> 00:57:11.866 A:middle
same effect with four external

00:57:11.866 --> 00:57:12.146 A:middle
GPU's.

00:57:12.146 --> 00:57:14.466 A:middle
You could see here it runs

00:57:14.466 --> 00:57:16.536 A:middle
amazingly smooth and easily

00:57:16.536 --> 00:57:18.086 A:middle
maintains a frame rate greater

00:57:18.086 --> 00:57:19.346 A:middle
than 60 frames per second.

00:57:20.196 --> 00:57:21.836 A:middle
This particular filter is memory

00:57:21.836 --> 00:57:22.896 A:middle
bandwidth intensive.

00:57:23.276 --> 00:57:25.076 A:middle
So we get great improvement here

00:57:25.396 --> 00:57:27.736 A:middle
because of the massive memory

00:57:27.736 --> 00:57:29.696 A:middle
bandwidth available on modern

00:57:29.696 --> 00:57:30.536 A:middle
GPU's today.

00:57:31.356 --> 00:57:32.766 A:middle
And this is an outstanding

00:57:32.766 --> 00:57:34.476 A:middle
example of how to officially

00:57:34.476 --> 00:57:36.186 A:middle
scale performance across

00:57:36.186 --> 00:57:37.376 A:middle
multiple GPU's.

00:57:37.946 --> 00:57:40.686 A:middle
So before we close this session,

00:57:41.026 --> 00:57:42.346 A:middle
let's review some of the key

00:57:42.346 --> 00:57:43.116 A:middle
takeaways.

00:57:44.506 --> 00:57:45.856 A:middle
Apple provides a wealth of

00:57:45.856 --> 00:57:47.716 A:middle
frameworks to solve all your Pro

00:57:47.716 --> 00:57:48.006 A:middle
App needs.

00:57:48.856 --> 00:57:50.526 A:middle
You can leverage this ecosystem

00:57:50.526 --> 00:57:52.126 A:middle
to achieve real-time editing

00:57:52.126 --> 00:57:54.576 A:middle
performance on 8k content with a

00:57:54.576 --> 00:57:55.586 A:middle
predictable frame rate.

00:57:57.086 --> 00:57:59.456 A:middle
Apple's AV Foundation and Core

00:57:59.456 --> 00:58:01.516 A:middle
Animation Metal Layer provide

00:57:59.456 --> 00:58:01.516 A:middle
Animation Metal Layer provide

00:58:01.516 --> 00:58:03.406 A:middle
API's to seamlessly support high

00:58:03.406 --> 00:58:04.426 A:middle
dynamic range.

00:58:04.826 --> 00:58:06.196 A:middle
You can couple this with HDR

00:58:06.256 --> 00:58:08.686 A:middle
TV's and Apple's new Pro Display

00:58:08.686 --> 00:58:11.256 A:middle
XDR to generate amazing videos

00:58:11.256 --> 00:58:11.916 A:middle
and images.

00:58:12.516 --> 00:58:15.436 A:middle
The Mac Pro can have up to 28

00:58:15.526 --> 00:58:17.266 A:middle
CPU cores and four internal

00:58:17.266 --> 00:58:18.116 A:middle
GPU's.

00:58:18.666 --> 00:58:20.096 A:middle
Metal provides all the API for

00:58:20.206 --> 00:58:21.426 A:middle
you to scale your performance

00:58:21.426 --> 00:58:22.796 A:middle
across all these devices.

00:58:24.366 --> 00:58:26.186 A:middle
And finally, we introduced a new

00:58:26.186 --> 00:58:27.746 A:middle
hardware feature Affinity Fabric

00:58:27.746 --> 00:58:29.296 A:middle
Link with a Metal peer group

00:58:29.296 --> 00:58:29.656 A:middle
API.

00:58:30.516 --> 00:58:32.186 A:middle
This empowers you to leverage

00:58:32.186 --> 00:58:34.926 A:middle
this connection to unlock new

00:58:34.926 --> 00:58:36.146 A:middle
and exciting use cases.

00:58:37.626 --> 00:58:39.386 A:middle
For more information, please

00:58:39.386 --> 00:58:41.146 A:middle
visit our website and please

00:58:41.146 --> 00:58:42.626 A:middle
visit us in tomorrow's lab.

00:58:42.956 --> 00:58:44.456 A:middle
Also check out additional Metal

00:58:44.456 --> 00:58:45.366 A:middle
labs on Friday.

00:58:45.596 --> 00:58:46.456 A:middle
Thank you very much.

00:58:47.516 --> 00:58:51.500 A:middle
[ Applause ]
