WEBVTT

00:00:01.176 --> 00:00:04.500 A:middle
[ Music ]

00:00:09.516 --> 00:00:15.546 A:middle
[ Applause ]

00:00:16.046 --> 00:00:16.826 A:middle
&gt;&gt; Good afternoon.

00:00:17.536 --> 00:00:18.636 A:middle
My name's Justin.

00:00:18.756 --> 00:00:20.376 A:middle
I'm an engineer in GPU Software,

00:00:20.376 --> 00:00:21.746 A:middle
and this is Metal for Machine

00:00:21.746 --> 00:00:21.976 A:middle
Learning.

00:00:24.516 --> 00:00:25.946 A:middle
Today we'll be discussing the

00:00:25.946 --> 00:00:26.896 A:middle
Metal Performance Shaders

00:00:26.896 --> 00:00:28.466 A:middle
framework, and new machine

00:00:28.466 --> 00:00:29.426 A:middle
learning features that we added

00:00:29.426 --> 00:00:29.796 A:middle
this year.

00:00:30.396 --> 00:00:33.096 A:middle
The Metal Performance Shaders or

00:00:33.096 --> 00:00:35.156 A:middle
MPS is a collection of

00:00:35.156 --> 00:00:36.626 A:middle
GPU-accelerated primitives,

00:00:37.066 --> 00:00:38.006 A:middle
which allow you to leverage the

00:00:38.006 --> 00:00:39.356 A:middle
high-performance capabilities of

00:00:39.356 --> 00:00:40.476 A:middle
metal in the GPU.

00:00:41.226 --> 00:00:43.326 A:middle
MPS provides kernels for image

00:00:43.356 --> 00:00:46.266 A:middle
processing, linear algebra, ray

00:00:46.266 --> 00:00:48.486 A:middle
tracing, and machine learning.

00:00:49.066 --> 00:00:51.016 A:middle
Now machine learning kernels

00:00:51.016 --> 00:00:52.826 A:middle
support both inference and

00:00:52.826 --> 00:00:54.516 A:middle
training, and they're optimized

00:00:54.516 --> 00:00:57.506 A:middle
for both for iOS, macOS, and

00:00:58.756 --> 00:00:58.896 A:middle
tvOS.

00:00:59.066 --> 00:01:00.446 A:middle
MPS also provides a convenient

00:00:59.066 --> 00:01:00.446 A:middle
MPS also provides a convenient

00:01:00.446 --> 00:01:01.766 A:middle
way of building neural networks

00:01:02.006 --> 00:01:07.646 A:middle
through the graph API.

00:01:07.876 --> 00:01:10.326 A:middle
So, here we can see how MPS fits

00:01:10.326 --> 00:01:11.826 A:middle
into the larger Apple ML

00:01:11.826 --> 00:01:12.436 A:middle
ecosystem.

00:01:13.646 --> 00:01:14.936 A:middle
You have higher-level frameworks

00:01:14.936 --> 00:01:17.806 A:middle
like Core ML and Create ML that

00:01:17.806 --> 00:01:18.736 A:middle
give you a convenient way to

00:01:18.736 --> 00:01:20.386 A:middle
implement many of your networks.

00:01:20.916 --> 00:01:22.076 A:middle
But if you want a little more

00:01:22.076 --> 00:01:23.646 A:middle
flexibility and control over

00:01:23.646 --> 00:01:25.086 A:middle
your program, you can use a

00:01:25.086 --> 00:01:27.186 A:middle
lower-level framework like MPS.

00:01:29.386 --> 00:01:31.146 A:middle
And this year, we have expanded

00:01:31.146 --> 00:01:32.266 A:middle
our machine learning support

00:01:32.266 --> 00:01:33.696 A:middle
with several new features.

00:01:34.816 --> 00:01:36.356 A:middle
We've added kernels to support

00:01:36.396 --> 00:01:37.676 A:middle
even more networks than before,

00:01:39.426 --> 00:01:41.256 A:middle
we've improved performance on

00:01:41.256 --> 00:01:43.726 A:middle
existing networks, and we've

00:01:43.726 --> 00:01:47.176 A:middle
made MPS even easier to use.

00:01:47.176 --> 00:01:48.276 A:middle
Now, as we go over these new

00:01:48.276 --> 00:01:49.456 A:middle
features, it's going to be

00:01:49.456 --> 00:01:50.636 A:middle
helpful to know a few things

00:01:50.636 --> 00:01:52.476 A:middle
about how inference and training

00:01:53.386 --> 00:01:54.546 A:middle
work in machine learning.

00:01:54.546 --> 00:01:56.006 A:middle
So, let's briefly review these

00:01:56.006 --> 00:01:56.706 A:middle
concepts.

00:01:59.156 --> 00:02:01.136 A:middle
So, inference is the process of

00:01:59.156 --> 00:02:01.136 A:middle
So, inference is the process of

00:02:01.136 --> 00:02:02.536 A:middle
applying a network on an input,

00:02:02.536 --> 00:02:04.196 A:middle
in this case an image, and

00:02:04.196 --> 00:02:05.676 A:middle
producing an output or a guess

00:02:05.676 --> 00:02:06.366 A:middle
of what it is.

00:02:07.386 --> 00:02:09.066 A:middle
Now, the network is made up of a

00:02:09.066 --> 00:02:10.346 A:middle
variety of functions such as

00:02:10.346 --> 00:02:12.106 A:middle
convolutions and neuron

00:02:12.106 --> 00:02:14.586 A:middle
activations, and these layers in

00:02:14.586 --> 00:02:15.746 A:middle
turn depend upon a set of

00:02:15.746 --> 00:02:16.456 A:middle
parameters.

00:02:16.696 --> 00:02:18.526 A:middle
During inference, these sets of

00:02:18.526 --> 00:02:20.246 A:middle
parameters are fixed, but their

00:02:20.246 --> 00:02:21.856 A:middle
values are determined during the

00:02:21.856 --> 00:02:22.746 A:middle
training process.

00:02:23.306 --> 00:02:25.896 A:middle
So, what happens during

00:02:25.896 --> 00:02:26.266 A:middle
training.

00:02:26.266 --> 00:02:28.146 A:middle
During training, we give the

00:02:28.146 --> 00:02:30.406 A:middle
network many images of known

00:02:30.406 --> 00:02:30.956 A:middle
objects.

00:02:31.346 --> 00:02:32.506 A:middle
The training process involves

00:02:32.506 --> 00:02:34.016 A:middle
repeatedly classifying these

00:02:34.016 --> 00:02:35.926 A:middle
images, and as we do so, we

00:02:35.926 --> 00:02:38.496 A:middle
update our parameters, and each

00:02:38.496 --> 00:02:39.416 A:middle
iteration of the network

00:02:39.786 --> 00:02:40.676 A:middle
produces a better set of

00:02:40.736 --> 00:02:42.086 A:middle
parameters until we finally

00:02:42.086 --> 00:02:42.976 A:middle
reach a set of parameters that

00:02:42.976 --> 00:02:45.336 A:middle
allows us to best classify the

00:02:45.336 --> 00:02:45.896 A:middle
images.

00:02:46.406 --> 00:02:49.526 A:middle
Now, at that point we stop the

00:02:49.526 --> 00:02:50.726 A:middle
training process, and our

00:02:50.726 --> 00:02:51.716 A:middle
parameters are ready to be used

00:02:51.716 --> 00:02:52.186 A:middle
in inference.

00:02:52.746 --> 00:02:56.036 A:middle
So, let's look at how we can MPS

00:02:56.036 --> 00:02:57.076 A:middle
to implement some of these

00:02:57.076 --> 00:02:57.546 A:middle
ideas.

00:02:58.186 --> 00:02:59.516 A:middle
But I would like to mention that

00:03:00.036 --> 00:03:00.966 A:middle
there's a lot more to inference

00:03:00.966 --> 00:03:02.066 A:middle
and training than what we just

00:03:02.066 --> 00:03:02.536 A:middle
covered here.

00:03:02.536 --> 00:03:03.956 A:middle
So if you want more details,

00:03:04.296 --> 00:03:05.406 A:middle
please see some of our talks

00:03:05.406 --> 00:03:06.936 A:middle
from the past couple years.

00:03:10.026 --> 00:03:11.256 A:middle
Now, we added several new

00:03:11.256 --> 00:03:12.256 A:middle
features this year to better

00:03:12.256 --> 00:03:13.456 A:middle
support a wide range of

00:03:13.456 --> 00:03:14.636 A:middle
inference and training networks.

00:03:15.556 --> 00:03:16.616 A:middle
So, first we made creating

00:03:16.616 --> 00:03:18.576 A:middle
graphs of your network simpler

00:03:18.576 --> 00:03:19.946 A:middle
by supporting implicit creation

00:03:19.946 --> 00:03:20.876 A:middle
of your training graphs from

00:03:20.876 --> 00:03:21.706 A:middle
your inference graphs.

00:03:22.206 --> 00:03:24.316 A:middle
We've added kernels for

00:03:24.316 --> 00:03:26.146 A:middle
separable loss layers and random

00:03:26.146 --> 00:03:28.426 A:middle
number generation to enable a

00:03:28.426 --> 00:03:31.046 A:middle
variety of new networks and

00:03:31.046 --> 00:03:31.936 A:middle
we've added support for things

00:03:31.936 --> 00:03:33.366 A:middle
like predication and better

00:03:33.366 --> 00:03:35.276 A:middle
control over how MPS commits its

00:03:35.276 --> 00:03:37.276 A:middle
work to improve performance.

00:03:37.826 --> 00:03:40.326 A:middle
So, let's start with implicit

00:03:40.326 --> 00:03:41.056 A:middle
graph creation.

00:03:41.586 --> 00:03:44.866 A:middle
With implicit graph creation, we

00:03:44.866 --> 00:03:45.816 A:middle
can implicitly create our

00:03:45.816 --> 00:03:46.526 A:middle
training graphs from our

00:03:46.526 --> 00:03:47.246 A:middle
inference graphs.

00:03:48.466 --> 00:03:49.996 A:middle
So, let's first review how we

00:03:49.996 --> 00:03:52.266 A:middle
create a graph for our network.

00:03:52.426 --> 00:03:53.996 A:middle
Here we have a simple inference

00:03:53.996 --> 00:03:54.306 A:middle
network.

00:03:54.526 --> 00:03:55.836 A:middle
It's made up of some convolution

00:03:55.836 --> 00:03:58.756 A:middle
layers, some pooling layers, and

00:03:58.756 --> 00:03:59.796 A:middle
finally some fully connected

00:03:59.796 --> 00:04:00.166 A:middle
layers.

00:03:59.796 --> 00:04:00.166 A:middle
layers.

00:04:00.726 --> 00:04:03.306 A:middle
So, we're going to create a

00:04:03.306 --> 00:04:04.596 A:middle
graph for this network by

00:04:04.596 --> 00:04:06.006 A:middle
creating nodes for each layer.

00:04:06.006 --> 00:04:07.556 A:middle
We're going to create a

00:04:07.556 --> 00:04:09.106 A:middle
convolution node for each of the

00:04:09.106 --> 00:04:11.706 A:middle
convolution layers, a pooling

00:04:11.706 --> 00:04:12.716 A:middle
node for each of the pooling

00:04:12.716 --> 00:04:14.876 A:middle
layers, and finally some fully

00:04:14.876 --> 00:04:16.375 A:middle
connecting nodes for the fully

00:04:16.375 --> 00:04:17.106 A:middle
connected layers.

00:04:17.685 --> 00:04:20.315 A:middle
So now with our inference graph

00:04:20.315 --> 00:04:21.586 A:middle
defined, we can extend it to a

00:04:21.586 --> 00:04:21.976 A:middle
training graph.

00:04:25.276 --> 00:04:26.556 A:middle
We do this by first attending a

00:04:26.556 --> 00:04:28.186 A:middle
loss node at the end of our

00:04:28.186 --> 00:04:30.616 A:middle
inference graph, and then then

00:04:30.616 --> 00:04:31.676 A:middle
we add gradient nodes for each

00:04:31.676 --> 00:04:33.066 A:middle
of our forward nodes, moving in

00:04:33.066 --> 00:04:33.926 A:middle
the reverse order of our

00:04:34.026 --> 00:04:34.946 A:middle
inference graph.

00:04:35.506 --> 00:04:37.256 A:middle
So, we can look at the code for

00:04:37.256 --> 00:04:37.806 A:middle
this section.

00:04:38.606 --> 00:04:39.886 A:middle
As before, we start by adding

00:04:39.886 --> 00:04:43.306 A:middle
the loss node, and then we add

00:04:43.306 --> 00:04:44.956 A:middle
each gradient node, just moving

00:04:44.956 --> 00:04:46.216 A:middle
in the same order we just

00:04:46.216 --> 00:04:46.546 A:middle
mentioned.

00:04:47.146 --> 00:04:49.996 A:middle
So, here we can see that each

00:04:49.996 --> 00:04:51.876 A:middle
gradient node is pretty easily

00:04:51.876 --> 00:04:53.676 A:middle
created from the forward node,

00:04:53.676 --> 00:04:55.406 A:middle
but with implicit graph

00:04:55.406 --> 00:04:56.786 A:middle
creation, this is even simpler.

00:04:58.896 --> 00:05:00.116 A:middle
Now, once you've initialized

00:04:58.896 --> 00:05:00.116 A:middle
Now, once you've initialized

00:05:00.116 --> 00:05:01.046 A:middle
your gradient image with the

00:05:01.046 --> 00:05:03.216 A:middle
loss node, we can automatically

00:05:03.216 --> 00:05:04.616 A:middle
create the entire training graph

00:05:04.656 --> 00:05:05.666 A:middle
corresponding to the inference

00:05:05.666 --> 00:05:05.946 A:middle
graph.

00:05:07.646 --> 00:05:08.716 A:middle
So, as before, we create our

00:05:08.716 --> 00:05:09.276 A:middle
loss node.

00:05:09.846 --> 00:05:12.526 A:middle
Then with a single line of code,

00:05:12.786 --> 00:05:13.946 A:middle
we can create our entire

00:05:13.946 --> 00:05:14.546 A:middle
training graph.

00:05:14.546 --> 00:05:17.126 A:middle
Now, in this case, we're

00:05:17.126 --> 00:05:18.266 A:middle
creating the training graph from

00:05:18.266 --> 00:05:18.846 A:middle
the loss node.

00:05:18.846 --> 00:05:19.896 A:middle
We're going to use a nil

00:05:19.896 --> 00:05:20.886 A:middle
argument for our source

00:05:20.886 --> 00:05:23.226 A:middle
gradient, which tells the loss

00:05:23.226 --> 00:05:24.626 A:middle
node to use its result to

00:05:24.626 --> 00:05:25.686 A:middle
initialized the gradients.

00:05:26.086 --> 00:05:27.306 A:middle
But we could use another image

00:05:27.306 --> 00:05:27.786 A:middle
if we wanted.

00:05:28.336 --> 00:05:31.036 A:middle
And we're also providing nil for

00:05:31.036 --> 00:05:31.736 A:middle
the second argument.

00:05:31.736 --> 00:05:32.886 A:middle
This is called a node handler.

00:05:33.426 --> 00:05:34.476 A:middle
The node handler allows you to

00:05:34.476 --> 00:05:36.006 A:middle
provide a block, which you can

00:05:36.006 --> 00:05:37.526 A:middle
use to execute some custom code

00:05:38.036 --> 00:05:39.596 A:middle
to configure your nodes after

00:05:39.596 --> 00:05:39.976 A:middle
they're created.

00:05:43.766 --> 00:05:44.716 A:middle
I also want to mention another

00:05:44.716 --> 00:05:46.466 A:middle
useful feature, the stop

00:05:46.466 --> 00:05:47.176 A:middle
gradient property.

00:05:48.116 --> 00:05:49.766 A:middle
So, typically, when you generate

00:05:49.766 --> 00:05:50.986 A:middle
your training sequence, all of

00:05:50.986 --> 00:05:52.536 A:middle
your trainable layers will

00:05:52.536 --> 00:05:53.346 A:middle
update their weights.

00:05:54.696 --> 00:05:55.776 A:middle
In this case, those are

00:05:55.776 --> 00:05:57.236 A:middle
convolutions and the fully

00:05:57.236 --> 00:05:58.026 A:middle
connected layers.

00:05:58.556 --> 00:06:00.106 A:middle
But in some cases, you may only

00:05:58.556 --> 00:06:00.106 A:middle
But in some cases, you may only

00:06:00.106 --> 00:06:01.276 A:middle
want to update the weights for

00:06:01.276 --> 00:06:02.086 A:middle
some of the layers of the

00:06:02.086 --> 00:06:03.736 A:middle
network, as in transfer

00:06:03.736 --> 00:06:04.746 A:middle
learning, for example.

00:06:05.116 --> 00:06:06.606 A:middle
Now, in transfer learning, we

00:06:06.606 --> 00:06:07.686 A:middle
are going to use pretrained

00:06:07.686 --> 00:06:09.036 A:middle
weights for many of the layers,

00:06:09.036 --> 00:06:09.896 A:middle
and we only want to train the

00:06:09.896 --> 00:06:10.876 A:middle
weight for some of the layers.

00:06:11.266 --> 00:06:12.396 A:middle
Let's say, for example, the

00:06:12.396 --> 00:06:13.666 A:middle
final fully connected layers.

00:06:15.576 --> 00:06:17.016 A:middle
Implicit graph creation also

00:06:17.016 --> 00:06:18.266 A:middle
supports creating graphs for

00:06:18.266 --> 00:06:19.566 A:middle
these types of networks through

00:06:19.566 --> 00:06:20.556 A:middle
the stop gradient property.

00:06:21.166 --> 00:06:24.176 A:middle
So, to do this, we're going to

00:06:24.176 --> 00:06:25.396 A:middle
set the stop gradient property

00:06:25.396 --> 00:06:26.856 A:middle
on the first, on the first

00:06:27.066 --> 00:06:28.696 A:middle
layer, whose weights we want to

00:06:28.696 --> 00:06:28.986 A:middle
update.

00:06:29.956 --> 00:06:30.956 A:middle
In this case, the fully

00:06:30.956 --> 00:06:31.526 A:middle
connected layer.

00:06:32.056 --> 00:06:35.156 A:middle
And then when the graph is

00:06:35.156 --> 00:06:37.066 A:middle
generated, none of the

00:06:37.066 --> 00:06:38.736 A:middle
subsequent gradient nodes will

00:06:38.736 --> 00:06:39.306 A:middle
be created.

00:06:39.886 --> 00:06:42.906 A:middle
So as you can see, using

00:06:42.906 --> 00:06:44.576 A:middle
implicit graph creation is a

00:06:44.576 --> 00:06:46.726 A:middle
very easy way of generating your

00:06:46.726 --> 00:06:47.666 A:middle
training graphs from your

00:06:47.666 --> 00:06:48.366 A:middle
inference graphs.

00:06:52.236 --> 00:06:53.496 A:middle
So now let's look at a feature

00:06:53.496 --> 00:06:55.256 A:middle
we added to support some new

00:06:55.256 --> 00:06:55.836 A:middle
networks.

00:06:56.576 --> 00:06:57.926 A:middle
Separable loss kernels.

00:06:59.676 --> 00:07:01.726 A:middle
So, earlier, we just saw how to

00:06:59.676 --> 00:07:01.726 A:middle
So, earlier, we just saw how to

00:07:01.726 --> 00:07:04.836 A:middle
use a loss node using MPS CNN

00:07:04.836 --> 00:07:05.276 A:middle
loss.

00:07:06.316 --> 00:07:07.966 A:middle
MPS CNN loss consumes a final

00:07:07.966 --> 00:07:09.006 A:middle
image, which is usually the

00:07:09.006 --> 00:07:10.456 A:middle
result of something like a soft

00:07:10.456 --> 00:07:12.116 A:middle
max layer along with the ground

00:07:12.116 --> 00:07:13.726 A:middle
truth data in order to compute

00:07:13.726 --> 00:07:14.726 A:middle
gradient values to begin the

00:07:14.726 --> 00:07:15.786 A:middle
back-propagation phase.

00:07:16.476 --> 00:07:18.206 A:middle
But there are some networks

00:07:18.206 --> 00:07:19.956 A:middle
which use multiple intermediate

00:07:19.956 --> 00:07:21.676 A:middle
loss values in order to produce

00:07:21.676 --> 00:07:22.456 A:middle
a final loss.

00:07:22.926 --> 00:07:24.936 A:middle
So, to support this, we added

00:07:24.986 --> 00:07:26.526 A:middle
separate forward and gradient

00:07:26.526 --> 00:07:27.186 A:middle
loss kernels.

00:07:27.656 --> 00:07:29.256 A:middle
So, here we can see two loss

00:07:29.256 --> 00:07:31.256 A:middle
values being computed using

00:07:31.336 --> 00:07:33.506 A:middle
forward loss nodes, and then we

00:07:33.506 --> 00:07:34.746 A:middle
take those results, add them

00:07:34.746 --> 00:07:36.966 A:middle
together to produce a final

00:07:36.966 --> 00:07:37.396 A:middle
loss.

00:07:38.016 --> 00:07:41.236 A:middle
Now, we need to initialize the

00:07:41.236 --> 00:07:42.216 A:middle
gradient value to begin the

00:07:42.216 --> 00:07:43.286 A:middle
back-propagation phase.

00:07:44.926 --> 00:07:46.446 A:middle
Before this happened implicitly

00:07:46.446 --> 00:07:47.566 A:middle
through the loss node now, we

00:07:47.566 --> 00:07:48.796 A:middle
need to add an initial gradient

00:07:48.796 --> 00:07:49.066 A:middle
kernel.

00:07:49.536 --> 00:07:51.126 A:middle
This is going to generate just a

00:07:51.126 --> 00:07:52.516 A:middle
gradient image of ones, and it's

00:07:52.516 --> 00:07:53.716 A:middle
going to be sized to the result

00:07:53.716 --> 00:07:54.996 A:middle
of the final loss calculation.

00:07:55.606 --> 00:07:57.896 A:middle
So with the gradient values

00:07:57.896 --> 00:07:59.266 A:middle
initialized, we can start the

00:07:59.266 --> 00:08:00.386 A:middle
back-propagation phase.

00:07:59.266 --> 00:08:00.386 A:middle
back-propagation phase.

00:08:00.686 --> 00:08:01.706 A:middle
We're going to use gradient

00:08:01.706 --> 00:08:02.736 A:middle
kernels for each of our forward

00:08:02.736 --> 00:08:03.806 A:middle
kernels with an addition

00:08:03.806 --> 00:08:05.836 A:middle
gradient and gradients for each

00:08:05.836 --> 00:08:06.586 A:middle
forward loss kernel.

00:08:06.586 --> 00:08:09.706 A:middle
Now, let's take a look at a

00:08:09.706 --> 00:08:12.256 A:middle
network that uses separable

00:08:12.256 --> 00:08:12.726 A:middle
losses.

00:08:13.266 --> 00:08:14.196 A:middle
Specifically, we're going to

00:08:14.196 --> 00:08:15.336 A:middle
look at style transfer.

00:08:15.926 --> 00:08:18.766 A:middle
Now, the style transfer network

00:08:18.766 --> 00:08:20.256 A:middle
produces images which are

00:08:20.256 --> 00:08:22.436 A:middle
combinations of a style and an

00:08:22.436 --> 00:08:23.176 A:middle
original image.

00:08:24.716 --> 00:08:26.286 A:middle
The model we'll be looking at is

00:08:26.286 --> 00:08:27.276 A:middle
one that you can find and to

00:08:27.276 --> 00:08:28.646 A:middle
re-create, and it's implemented

00:08:28.646 --> 00:08:29.986 A:middle
using MPS.

00:08:31.086 --> 00:08:32.466 A:middle
Now in inference, this network

00:08:32.466 --> 00:08:34.176 A:middle
consists of a transformer node,

00:08:34.176 --> 00:08:35.405 A:middle
which is made up of things like

00:08:35.405 --> 00:08:36.556 A:middle
convolutions and instance

00:08:36.556 --> 00:08:38.135 A:middle
normalization layers, and their

00:08:38.135 --> 00:08:39.416 A:middle
weights make up the trained

00:08:39.416 --> 00:08:40.015 A:middle
parameters.

00:08:40.775 --> 00:08:41.976 A:middle
This is where the style is

00:08:41.976 --> 00:08:42.566 A:middle
incorporated.

00:08:43.126 --> 00:08:44.766 A:middle
It's learned into the parameters

00:08:44.866 --> 00:08:45.876 A:middle
through the training process.

00:08:46.716 --> 00:08:48.246 A:middle
So let's look at how we do the

00:08:48.246 --> 00:08:48.596 A:middle
training.

00:08:49.186 --> 00:08:51.266 A:middle
So here we have an overview of

00:08:51.266 --> 00:08:51.706 A:middle
the network.

00:08:53.546 --> 00:08:55.126 A:middle
Now, as an inference, we're

00:08:55.126 --> 00:08:56.306 A:middle
going to apply the transformer

00:08:56.926 --> 00:08:58.496 A:middle
to produce a stylized image.

00:08:59.186 --> 00:09:00.216 A:middle
Now, in this case, this is going

00:08:59.186 --> 00:09:00.216 A:middle
Now, in this case, this is going

00:09:00.216 --> 00:09:02.136 A:middle
to be the network's current

00:09:02.356 --> 00:09:04.516 A:middle
guess at the best styled image,

00:09:04.516 --> 00:09:05.586 A:middle
which combines the style and the

00:09:05.586 --> 00:09:05.956 A:middle
content.

00:09:06.686 --> 00:09:08.726 A:middle
And since the goal of the

00:09:08.726 --> 00:09:10.286 A:middle
network is to match both the

00:09:10.286 --> 00:09:11.726 A:middle
desired style and the content of

00:09:11.726 --> 00:09:12.846 A:middle
the original image, we're going

00:09:12.846 --> 00:09:13.996 A:middle
to need two loss values.

00:09:14.486 --> 00:09:18.116 A:middle
So, the first loss value is

00:09:18.116 --> 00:09:19.526 A:middle
computed by this sum network

00:09:19.526 --> 00:09:20.166 A:middle
that we're going to call the

00:09:20.166 --> 00:09:21.096 A:middle
style loss network.

00:09:22.316 --> 00:09:23.326 A:middle
This loss value is going to help

00:09:23.326 --> 00:09:24.086 A:middle
ensure that the network

00:09:24.086 --> 00:09:25.756 A:middle
converges on a result, which

00:09:25.756 --> 00:09:27.336 A:middle
closely matches our desired

00:09:27.336 --> 00:09:27.706 A:middle
style.

00:09:28.316 --> 00:09:29.666 A:middle
And then we also want to make

00:09:29.666 --> 00:09:32.036 A:middle
sure that the generated image

00:09:32.776 --> 00:09:33.936 A:middle
also retains the features of the

00:09:33.936 --> 00:09:34.366 A:middle
original.

00:09:34.496 --> 00:09:35.346 A:middle
So, for this we're going to use

00:09:35.346 --> 00:09:36.236 A:middle
a second loss network.

00:09:36.626 --> 00:09:37.846 A:middle
This is the content loss.

00:09:38.336 --> 00:09:41.896 A:middle
And we can use our new forward

00:09:41.896 --> 00:09:43.166 A:middle
loss kernels for each of these

00:09:43.166 --> 00:09:44.116 A:middle
loss calculations.

00:09:46.416 --> 00:09:48.716 A:middle
But let's take a closer look at

00:09:48.716 --> 00:09:49.766 A:middle
the style loss network.

00:09:50.786 --> 00:09:51.926 A:middle
So, in order to compute the

00:09:51.926 --> 00:09:53.676 A:middle
style loss, we need a way of

00:09:53.916 --> 00:09:55.146 A:middle
sort of measuring the style of

00:09:55.146 --> 00:09:55.586 A:middle
an image.

00:09:56.236 --> 00:09:57.086 A:middle
So, to do this we're going to

00:09:57.086 --> 00:09:58.306 A:middle
calculate what's called the Gram

00:09:58.306 --> 00:09:59.936 A:middle
Matrix for several intermediate

00:09:59.936 --> 00:10:00.776 A:middle
feature representations of the

00:09:59.936 --> 00:10:00.776 A:middle
feature representations of the

00:10:00.776 --> 00:10:00.976 A:middle
images.

00:10:01.116 --> 00:10:04.766 A:middle
This year, Gram Matrix

00:10:04.766 --> 00:10:05.946 A:middle
calculations are natively

00:10:05.946 --> 00:10:07.596 A:middle
supported in MPS with both

00:10:07.596 --> 00:10:08.996 A:middle
forward and gradient kernels.

00:10:09.606 --> 00:10:11.476 A:middle
So let's take a quick look at

00:10:11.656 --> 00:10:12.686 A:middle
the Gram Matrix and how it's

00:10:12.686 --> 00:10:13.116 A:middle
computed.

00:10:13.666 --> 00:10:15.286 A:middle
So, the Gram Matrix represents

00:10:15.286 --> 00:10:16.626 A:middle
uncentered cross-correlations

00:10:16.716 --> 00:10:17.856 A:middle
between feature vectors.

00:10:18.396 --> 00:10:20.296 A:middle
Now, each feature vector results

00:10:20.296 --> 00:10:21.296 A:middle
from spatially flattening the

00:10:21.296 --> 00:10:23.186 A:middle
results from a single image in a

00:10:23.186 --> 00:10:23.926 A:middle
single feature channel.

00:10:24.536 --> 00:10:26.926 A:middle
We compute dot products between

00:10:26.926 --> 00:10:28.476 A:middle
each feature vector to produce a

00:10:28.476 --> 00:10:29.146 A:middle
Gram Matrix.

00:10:29.916 --> 00:10:30.946 A:middle
So let's take a look at how it's

00:10:30.946 --> 00:10:31.216 A:middle
used.

00:10:32.036 --> 00:10:34.586 A:middle
So, before we get to the Gram

00:10:34.586 --> 00:10:35.906 A:middle
Matrix, we're going to use the

00:10:35.906 --> 00:10:37.466 A:middle
VGG image classification network

00:10:37.466 --> 00:10:38.986 A:middle
to extract some features from

00:10:38.986 --> 00:10:40.696 A:middle
both our style and our stylized

00:10:40.796 --> 00:10:41.366 A:middle
input image.

00:10:41.366 --> 00:10:43.896 A:middle
Now, as we described before, the

00:10:43.896 --> 00:10:45.106 A:middle
Gram Matrix gives us

00:10:45.106 --> 00:10:46.076 A:middle
correlations between feature

00:10:46.076 --> 00:10:46.526 A:middle
vectors.

00:10:47.586 --> 00:10:48.906 A:middle
Now, when we take these from the

00:10:48.906 --> 00:10:49.986 A:middle
features extracted from the

00:10:49.986 --> 00:10:52.776 A:middle
style, this gives us our sort of

00:10:52.776 --> 00:10:54.376 A:middle
ground truth for the style that

00:10:54.376 --> 00:10:56.216 A:middle
we want to apply, and we're also

00:10:56.216 --> 00:10:57.946 A:middle
going to do the same thing for

00:10:57.946 --> 00:10:59.206 A:middle
our current guess at the best

00:10:59.566 --> 00:11:00.496 A:middle
stylized image.

00:10:59.566 --> 00:11:00.496 A:middle
stylized image.

00:11:01.506 --> 00:11:02.706 A:middle
Now, we take these two values

00:11:02.706 --> 00:11:06.306 A:middle
together to form our style loss.

00:11:08.916 --> 00:11:10.196 A:middle
So now let's look at how we

00:11:10.196 --> 00:11:11.216 A:middle
compute the second of our two

00:11:11.216 --> 00:11:12.746 A:middle
losses, the content loss.

00:11:13.306 --> 00:11:15.326 A:middle
So, as before, we're going to

00:11:15.326 --> 00:11:17.576 A:middle
extract features using VGG and

00:11:17.686 --> 00:11:19.026 A:middle
then compute a loss using those

00:11:19.026 --> 00:11:20.556 A:middle
features and our features from

00:11:20.556 --> 00:11:21.426 A:middle
our stylized image.

00:11:22.396 --> 00:11:23.556 A:middle
And then the network's final

00:11:23.556 --> 00:11:25.386 A:middle
loss is going to be the sum of

00:11:25.386 --> 00:11:26.696 A:middle
the content loss and the style

00:11:26.696 --> 00:11:27.066 A:middle
loss.

00:11:28.206 --> 00:11:29.256 A:middle
So, now let's look at how we can

00:11:29.256 --> 00:11:30.966 A:middle
use MPS to compute these values

00:11:30.966 --> 00:11:32.046 A:middle
and initialize gradients.

00:11:32.606 --> 00:11:36.086 A:middle
So first, let's assume we have

00:11:36.086 --> 00:11:37.426 A:middle
our feature representations, as

00:11:37.426 --> 00:11:38.326 A:middle
produced by VGG.

00:11:39.306 --> 00:11:40.326 A:middle
First, we're going to add our

00:11:40.326 --> 00:11:42.876 A:middle
Gram Matrix calculation nodes to

00:11:42.946 --> 00:11:44.266 A:middle
compute the Gram Matrix for both

00:11:44.266 --> 00:11:46.066 A:middle
the style and our stylized

00:11:46.066 --> 00:11:46.376 A:middle
image.

00:11:49.546 --> 00:11:50.526 A:middle
We're going to feed these

00:11:50.526 --> 00:11:52.206 A:middle
results into a forward loss node

00:11:52.806 --> 00:11:54.256 A:middle
to just compute the loss for our

00:11:54.256 --> 00:11:54.626 A:middle
style.

00:11:55.886 --> 00:11:57.536 A:middle
The source image here is the

00:11:57.536 --> 00:11:58.626 A:middle
result of the Gram Matrix

00:11:58.626 --> 00:11:59.926 A:middle
calculation for our network

00:11:59.926 --> 00:12:00.756 A:middle
stylized image.

00:11:59.926 --> 00:12:00.756 A:middle
stylized image.

00:12:03.416 --> 00:12:04.646 A:middle
The Gram Matrix for the

00:12:04.646 --> 00:12:06.566 A:middle
reference style image is going

00:12:06.566 --> 00:12:07.506 A:middle
to be used in the labels

00:12:07.506 --> 00:12:07.926 A:middle
argument.

00:12:09.256 --> 00:12:10.126 A:middle
Now this shows an important

00:12:10.126 --> 00:12:11.636 A:middle
feature of the new forward loss

00:12:11.636 --> 00:12:12.096 A:middle
kernels.

00:12:12.356 --> 00:12:13.656 A:middle
Previously, you had to pass

00:12:13.656 --> 00:12:15.276 A:middle
labels using MPS state objects.

00:12:15.826 --> 00:12:18.486 A:middle
But now, you can used MPS

00:12:20.686 --> 00:12:20.866 A:middle
images.

00:12:21.036 --> 00:12:22.256 A:middle
So now we can add the loss node

00:12:22.256 --> 00:12:23.996 A:middle
for the content loss using the

00:12:24.036 --> 00:12:25.206 A:middle
features of the stylized image

00:12:25.206 --> 00:12:27.326 A:middle
and the original image, and we

00:12:27.326 --> 00:12:28.816 A:middle
can combine them to get our

00:12:28.816 --> 00:12:29.686 A:middle
total loss value.

00:12:30.276 --> 00:12:32.466 A:middle
And now we need to initialize

00:12:32.466 --> 00:12:34.066 A:middle
the final loss gradient to begin

00:12:34.066 --> 00:12:35.246 A:middle
the back-propagation phase.

00:12:36.636 --> 00:12:38.256 A:middle
We do this using the initial

00:12:38.256 --> 00:12:39.146 A:middle
gradient node we discussed

00:12:39.146 --> 00:12:39.506 A:middle
before.

00:12:43.236 --> 00:12:44.316 A:middle
Now we saw before how the result

00:12:44.316 --> 00:12:46.316 A:middle
of the loss node can be used to

00:12:46.316 --> 00:12:47.586 A:middle
implicitly generate the training

00:12:47.586 --> 00:12:47.956 A:middle
graph.

00:12:48.276 --> 00:12:49.826 A:middle
This is because it generates the

00:12:49.826 --> 00:12:50.496 A:middle
initial gradient.

00:12:51.266 --> 00:12:52.856 A:middle
But now, as I mentioned before,

00:12:52.856 --> 00:12:54.976 A:middle
with the separable loss kernels,

00:12:54.976 --> 00:12:56.326 A:middle
we do this explicitly using the

00:12:56.326 --> 00:12:57.216 A:middle
initial gradient node.

00:12:57.586 --> 00:12:58.696 A:middle
So, this is the node that were

00:12:58.696 --> 00:12:59.676 A:middle
going to use to generate our

00:12:59.676 --> 00:12:59.976 A:middle
training graph.

00:13:02.536 --> 00:13:03.586 A:middle
So, with the graph generated,

00:13:03.966 --> 00:13:05.626 A:middle
let's take a look at what this

00:13:05.626 --> 00:13:07.156 A:middle
network does in action.

00:13:10.836 --> 00:13:12.236 A:middle
So, here we can see the style

00:13:12.236 --> 00:13:13.876 A:middle
transfer network running on the

00:13:13.876 --> 00:13:14.766 A:middle
GPU using MPS.

00:13:14.766 --> 00:13:17.106 A:middle
This was run on a Mac Book Pro

00:13:17.176 --> 00:13:19.386 A:middle
with an AMD Radeon pro 560

00:13:19.386 --> 00:13:20.266 A:middle
graphics card.

00:13:20.866 --> 00:13:22.986 A:middle
Now this is showing the results

00:13:22.986 --> 00:13:24.336 A:middle
of the style transfer training

00:13:24.336 --> 00:13:25.556 A:middle
at each iteration as it

00:13:25.556 --> 00:13:26.106 A:middle
progresses.

00:13:26.576 --> 00:13:28.866 A:middle
As you can see, the style is

00:13:28.866 --> 00:13:30.996 A:middle
being applied progressively, but

00:13:30.996 --> 00:13:31.916 A:middle
the content of the image is

00:13:31.916 --> 00:13:32.506 A:middle
being retained.

00:13:32.506 --> 00:13:34.156 A:middle
I also want to mention that

00:13:34.156 --> 00:13:35.746 A:middle
these iterations have been sped

00:13:35.746 --> 00:13:37.776 A:middle
up for this video from real time

00:13:37.776 --> 00:13:38.906 A:middle
to better illustrate the

00:13:38.906 --> 00:13:40.786 A:middle
progression of the training

00:13:40.786 --> 00:13:40.976 A:middle
network.

00:13:47.266 --> 00:13:49.576 A:middle
So now, I'd like to look at

00:13:49.576 --> 00:13:50.566 A:middle
another feature that we added

00:13:50.566 --> 00:13:51.686 A:middle
this year, random number

00:13:51.686 --> 00:13:52.146 A:middle
generation.

00:13:54.596 --> 00:13:56.016 A:middle
This year we added support for

00:13:56.016 --> 00:13:57.026 A:middle
two types of random number

00:13:57.026 --> 00:13:58.116 A:middle
generators in MPS.

00:13:58.816 --> 00:13:59.586 A:middle
We have a variant of the

00:13:59.586 --> 00:14:01.656 A:middle
Mersenne Twister called MTGP32

00:13:59.586 --> 00:14:01.656 A:middle
Mersenne Twister called MTGP32

00:14:01.656 --> 00:14:03.806 A:middle
and a counter-based generator

00:14:03.806 --> 00:14:04.416 A:middle
called Philox.

00:14:05.596 --> 00:14:06.676 A:middle
Now these generators were chosen

00:14:06.676 --> 00:14:07.806 A:middle
because their algorithms are

00:14:07.806 --> 00:14:08.706 A:middle
well suited to GPU

00:14:08.706 --> 00:14:10.086 A:middle
architectures, and they still

00:14:10.086 --> 00:14:12.046 A:middle
provide sequences of random

00:14:12.046 --> 00:14:12.846 A:middle
numbers with pretty good

00:14:12.846 --> 00:14:13.896 A:middle
statistical properties.

00:14:14.316 --> 00:14:16.566 A:middle
Now, you can use these kernels

00:14:16.566 --> 00:14:18.126 A:middle
to generate large sequences of

00:14:18.126 --> 00:14:20.526 A:middle
random numbers using buffers and

00:14:20.526 --> 00:14:21.056 A:middle
GPU memory.

00:14:21.626 --> 00:14:22.606 A:middle
And since you have this result

00:14:22.606 --> 00:14:24.496 A:middle
available in GPU memory, you can

00:14:24.496 --> 00:14:25.476 A:middle
avoid having to synchronize

00:14:25.476 --> 00:14:26.496 A:middle
large rays and numbers from the

00:14:26.496 --> 00:14:26.766 A:middle
CPU.

00:14:27.796 --> 00:14:29.176 A:middle
And generating random numbers

00:14:29.696 --> 00:14:30.576 A:middle
like this is important for

00:14:30.576 --> 00:14:31.416 A:middle
several machine learning

00:14:31.416 --> 00:14:32.056 A:middle
applications.

00:14:32.756 --> 00:14:33.986 A:middle
They're required, for example,

00:14:33.986 --> 00:14:35.536 A:middle
for initializing your weights of

00:14:35.536 --> 00:14:37.636 A:middle
your networks for training and

00:14:37.636 --> 00:14:39.376 A:middle
also for creating inputs when

00:14:39.376 --> 00:14:40.836 A:middle
training generated adversarial

00:14:40.836 --> 00:14:41.946 A:middle
networks, or GANs.

00:14:43.076 --> 00:14:44.016 A:middle
Now GANs are an especially

00:14:44.016 --> 00:14:45.526 A:middle
important use case for random

00:14:45.526 --> 00:14:46.366 A:middle
number generators.

00:14:46.636 --> 00:14:47.626 A:middle
You had to generate the random

00:14:47.626 --> 00:14:50.016 A:middle
input at each iteration of your

00:14:50.016 --> 00:14:50.336 A:middle
training.

00:14:50.956 --> 00:14:53.576 A:middle
If you had to synchronize an

00:14:53.576 --> 00:14:55.026 A:middle
array of numbers from the CPU,

00:14:55.456 --> 00:14:57.186 A:middle
every iteration, it could make

00:14:57.186 --> 00:14:58.196 A:middle
training your network

00:14:58.236 --> 00:14:59.216 A:middle
prohibitively expensive.

00:15:00.636 --> 00:15:01.946 A:middle
So, let's take a closer look at

00:15:01.946 --> 00:15:03.206 A:middle
those networks and how we can

00:15:03.206 --> 00:15:04.346 A:middle
use the new random number

00:15:04.346 --> 00:15:04.866 A:middle
generators.

00:15:07.016 --> 00:15:09.436 A:middle
So, generative adversarial

00:15:09.436 --> 00:15:10.666 A:middle
networks or GANs are built

00:15:10.666 --> 00:15:11.566 A:middle
around two networks.

00:15:11.566 --> 00:15:12.706 A:middle
We have a generator network and

00:15:12.706 --> 00:15:13.756 A:middle
a discriminator network.

00:15:14.726 --> 00:15:15.576 A:middle
Here we have an example of a

00:15:15.576 --> 00:15:17.416 A:middle
generator, which just generates

00:15:17.416 --> 00:15:18.526 A:middle
images of handwritten digits.

00:15:19.106 --> 00:15:21.506 A:middle
Now, similar to image

00:15:21.506 --> 00:15:22.766 A:middle
classification during training,

00:15:22.766 --> 00:15:23.526 A:middle
we're going to provide the

00:15:23.526 --> 00:15:25.116 A:middle
network with many examples of

00:15:25.116 --> 00:15:25.876 A:middle
handwritten digits.

00:15:25.876 --> 00:15:27.046 A:middle
However, instead of attempting

00:15:27.046 --> 00:15:29.236 A:middle
to classify them, the network is

00:15:29.236 --> 00:15:31.296 A:middle
going to attempt to generate new

00:15:31.296 --> 00:15:32.906 A:middle
images from a random initial set

00:15:32.906 --> 00:15:34.676 A:middle
of data to look similar to its

00:15:34.676 --> 00:15:35.216 A:middle
training set.

00:15:35.746 --> 00:15:39.326 A:middle
So, in order to perform this

00:15:39.326 --> 00:15:41.886 A:middle
training process, we needed some

00:15:41.886 --> 00:15:43.836 A:middle
way of determining how similar

00:15:44.236 --> 00:15:45.046 A:middle
these images should be.

00:15:45.626 --> 00:15:46.676 A:middle
So, for this second network,

00:15:46.806 --> 00:15:48.016 A:middle
we're going to use what we call

00:15:48.016 --> 00:15:48.726 A:middle
the discriminator.

00:15:50.576 --> 00:15:52.356 A:middle
Now as this name suggests, it's

00:15:52.356 --> 00:15:54.426 A:middle
designed to discriminate between

00:15:54.426 --> 00:15:57.056 A:middle
training images and those images

00:15:57.056 --> 00:15:58.076 A:middle
which are simulated by the

00:15:58.076 --> 00:15:58.486 A:middle
generator.

00:15:59.206 --> 00:16:00.406 A:middle
So, in this case, it acts as an

00:15:59.206 --> 00:16:00.406 A:middle
So, in this case, it acts as an

00:16:00.406 --> 00:16:01.416 A:middle
image classifier network but

00:16:01.416 --> 00:16:02.726 A:middle
with only two possibilities.

00:16:03.426 --> 00:16:05.496 A:middle
The input is either real, from

00:16:05.496 --> 00:16:06.596 A:middle
the training set, or it's a

00:16:06.596 --> 00:16:08.016 A:middle
generated, or a fake image.

00:16:08.326 --> 00:16:10.596 A:middle
So you can see, here's the

00:16:10.596 --> 00:16:11.996 A:middle
discriminator, looking at some

00:16:11.996 --> 00:16:13.966 A:middle
numbers and coming with whether

00:16:13.966 --> 00:16:15.606 A:middle
they're real or fake.

00:16:17.946 --> 00:16:19.066 A:middle
Now, typically both the

00:16:19.066 --> 00:16:20.206 A:middle
generator and the discriminator

00:16:20.206 --> 00:16:20.916 A:middle
are trained together.

00:16:21.646 --> 00:16:23.206 A:middle
We trained the generator to

00:16:23.206 --> 00:16:24.586 A:middle
produce more realistic images,

00:16:25.066 --> 00:16:25.626 A:middle
while we trained the

00:16:25.626 --> 00:16:26.556 A:middle
discriminator to better

00:16:26.556 --> 00:16:27.976 A:middle
distinguish synthetic images

00:16:28.186 --> 00:16:29.136 A:middle
from the training images.

00:16:29.876 --> 00:16:31.466 A:middle
So, here we have a high-level

00:16:31.466 --> 00:16:32.626 A:middle
overview of the nodes for your

00:16:32.626 --> 00:16:33.786 A:middle
training network.

00:16:34.416 --> 00:16:35.706 A:middle
So here's our discriminator

00:16:35.706 --> 00:16:36.766 A:middle
training, training network.

00:16:37.656 --> 00:16:38.676 A:middle
It consists of two loss

00:16:38.676 --> 00:16:39.426 A:middle
calculations.

00:16:39.536 --> 00:16:40.486 A:middle
So, this is an example of where

00:16:40.486 --> 00:16:41.626 A:middle
you could use the separable loss

00:16:41.626 --> 00:16:42.486 A:middle
nodes we just talked about.

00:16:43.636 --> 00:16:46.176 A:middle
We have one loss where we

00:16:46.176 --> 00:16:47.766 A:middle
attempt to ensure the

00:16:47.766 --> 00:16:48.756 A:middle
discriminator properly

00:16:48.756 --> 00:16:50.656 A:middle
classifies the simulated images

00:16:50.656 --> 00:16:52.816 A:middle
as fake, and we have a second

00:16:52.816 --> 00:16:55.356 A:middle
loss where we trained the

00:16:55.356 --> 00:16:56.596 A:middle
discriminator to classify the

00:16:56.596 --> 00:16:57.596 A:middle
real images from the training

00:16:57.596 --> 00:16:58.546 A:middle
set as real.

00:16:59.086 --> 00:17:02.696 A:middle
After computing the separate

00:16:59.086 --> 00:17:02.696 A:middle
After computing the separate

00:17:02.696 --> 00:17:04.346 A:middle
loss values, we can use an

00:17:04.346 --> 00:17:06.306 A:middle
initial gradient node to

00:17:06.306 --> 00:17:07.256 A:middle
initialize your training graph.

00:17:07.866 --> 00:17:10.906 A:middle
And secondly, here we have the

00:17:10.906 --> 00:17:11.856 A:middle
generator training network.

00:17:12.516 --> 00:17:13.596 A:middle
This one is a little simpler.

00:17:13.596 --> 00:17:14.856 A:middle
It just has a single loss value.

00:17:15.756 --> 00:17:18.496 A:middle
But in this case, we use a label

00:17:18.496 --> 00:17:20.026 A:middle
value of real to ensure that our

00:17:20.026 --> 00:17:21.886 A:middle
generator generates images,

00:17:21.886 --> 00:17:22.715 A:middle
which the discriminator

00:17:22.715 --> 00:17:23.965 A:middle
subsequently classifies as real.

00:17:24.856 --> 00:17:26.016 A:middle
Now, I mentioned earlier that

00:17:26.016 --> 00:17:27.076 A:middle
the generator network begins

00:17:27.076 --> 00:17:28.926 A:middle
with a random set of data that

00:17:28.926 --> 00:17:29.806 A:middle
we're going to use our random

00:17:29.806 --> 00:17:30.596 A:middle
number generator for.

00:17:31.256 --> 00:17:32.476 A:middle
So, let's take a closer look at

00:17:33.196 --> 00:17:34.246 A:middle
random number generation.

00:17:34.826 --> 00:17:37.206 A:middle
Now random number generation

00:17:37.206 --> 00:17:39.446 A:middle
kernels belong to the MPSMatrix

00:17:39.446 --> 00:17:41.196 A:middle
subframework, and they're

00:17:41.196 --> 00:17:42.506 A:middle
accessed through MPSMatrix

00:17:42.506 --> 00:17:43.866 A:middle
random classes.

00:17:44.806 --> 00:17:46.206 A:middle
So, they operate on MPSMatrix

00:17:46.206 --> 00:17:47.356 A:middle
and MPSVector objects, which

00:17:47.356 --> 00:17:48.226 A:middle
means they work with metal

00:17:48.226 --> 00:17:51.096 A:middle
buffers, and they support

00:17:51.096 --> 00:17:53.476 A:middle
generating random integers with

00:17:53.476 --> 00:17:54.576 A:middle
the underlying generator, or you

00:17:54.576 --> 00:17:55.566 A:middle
can generate floating point

00:17:55.566 --> 00:17:56.576 A:middle
values using a uniform

00:17:56.576 --> 00:17:57.126 A:middle
distribution.

00:17:57.726 --> 00:17:59.996 A:middle
So, here, we're going to create

00:17:59.996 --> 00:18:01.706 A:middle
a distribution descriptor for

00:17:59.996 --> 00:18:01.706 A:middle
a distribution descriptor for

00:18:01.706 --> 00:18:03.976 A:middle
uniform distribution of values

00:18:03.976 --> 00:18:04.676 A:middle
between 0 and 1.

00:18:05.226 --> 00:18:07.896 A:middle
Then we're going to create our

00:18:07.896 --> 00:18:11.066 A:middle
generator, testing the proper

00:18:11.066 --> 00:18:12.246 A:middle
data types, and then we give it

00:18:12.246 --> 00:18:13.006 A:middle
an initial seed.

00:18:15.976 --> 00:18:17.366 A:middle
Finally, we create a matrix to

00:18:17.366 --> 00:18:19.276 A:middle
hold the result, and we encode

00:18:19.276 --> 00:18:21.236 A:middle
the operation to the command

00:18:21.236 --> 00:18:21.496 A:middle
buffer.

00:18:21.496 --> 00:18:23.426 A:middle
So, now let's go back to the

00:18:23.426 --> 00:18:24.436 A:middle
network and see how we can use

00:18:24.986 --> 00:18:25.106 A:middle
it.

00:18:25.756 --> 00:18:27.226 A:middle
So, here's a closer view of the

00:18:27.226 --> 00:18:27.926 A:middle
generator network.

00:18:27.926 --> 00:18:30.246 A:middle
We have some convolution layers,

00:18:30.466 --> 00:18:31.786 A:middle
some ReLu layers, and the

00:18:31.786 --> 00:18:33.026 A:middle
hyperbolic tangent neuron.

00:18:33.646 --> 00:18:36.256 A:middle
Now the input image is going to

00:18:36.256 --> 00:18:37.076 A:middle
be the output of our random

00:18:37.076 --> 00:18:37.706 A:middle
number generator.

00:18:39.046 --> 00:18:40.046 A:middle
As we saw before the random

00:18:40.046 --> 00:18:41.266 A:middle
number generator works with

00:18:41.266 --> 00:18:43.406 A:middle
matrices, but the graph and all

00:18:43.406 --> 00:18:44.416 A:middle
the neural network kernels

00:18:44.416 --> 00:18:45.216 A:middle
require images.

00:18:45.576 --> 00:18:47.186 A:middle
So, we're going to use our MPS

00:18:47.186 --> 00:18:48.646 A:middle
copy kernel to copy the data

00:18:49.106 --> 00:18:50.926 A:middle
from the matrix into an image.

00:18:53.436 --> 00:18:54.676 A:middle
So, first we'll create a matrix

00:18:54.676 --> 00:18:55.836 A:middle
to hold our random values.

00:18:57.576 --> 00:18:58.996 A:middle
Then we'll also create an image,

00:18:58.996 --> 00:18:59.816 A:middle
which is going to serve as the

00:18:59.816 --> 00:19:00.606 A:middle
input for our network.

00:18:59.816 --> 00:19:00.606 A:middle
input for our network.

00:19:04.616 --> 00:19:05.766 A:middle
And we're going to initialize a

00:19:05.766 --> 00:19:07.706 A:middle
copy kernel to perform the copy.

00:19:09.246 --> 00:19:10.946 A:middle
Then were going to encode our

00:19:10.946 --> 00:19:12.436 A:middle
random number generator to

00:19:12.436 --> 00:19:13.386 A:middle
generate the values.

00:19:13.386 --> 00:19:14.446 A:middle
We're going to encode the copy

00:19:14.726 --> 00:19:16.556 A:middle
to copy them into the image, and

00:19:16.556 --> 00:19:19.556 A:middle
now we're going to encode the

00:19:20.146 --> 00:19:21.226 A:middle
network using the image.

00:19:21.826 --> 00:19:25.376 A:middle
Now, for more details on this

00:19:25.376 --> 00:19:27.246 A:middle
network and using MPSMatrix

00:19:27.246 --> 00:19:28.426 A:middle
random number generation

00:19:28.426 --> 00:19:30.086 A:middle
kernels, please see the online

00:19:30.086 --> 00:19:30.766 A:middle
documentation.

00:19:30.766 --> 00:19:31.796 A:middle
There's also some sample code.

00:19:36.046 --> 00:19:36.766 A:middle
Now we also added features to

00:19:36.766 --> 00:19:38.296 A:middle
help improve the performance and

00:19:38.296 --> 00:19:39.866 A:middle
efficiency of networks using

00:19:39.866 --> 00:19:40.336 A:middle
MPS.

00:19:41.136 --> 00:19:42.006 A:middle
So let's take a look at one of

00:19:42.006 --> 00:19:43.396 A:middle
them now, predication.

00:19:43.966 --> 00:19:46.176 A:middle
With predication, you can now

00:19:46.216 --> 00:19:47.426 A:middle
conditionally execute MPS

00:19:47.426 --> 00:19:47.966 A:middle
kernels.

00:19:48.836 --> 00:19:50.376 A:middle
The kernels' execution is

00:19:50.416 --> 00:19:52.196 A:middle
predicated on values which exist

00:19:52.196 --> 00:19:53.736 A:middle
in GPU memory, and they're

00:19:53.736 --> 00:19:54.396 A:middle
referenced at the time of

00:19:54.396 --> 00:19:54.976 A:middle
execution of the kernel.

00:19:58.226 --> 00:19:58.966 A:middle
So, let's take a look at a

00:19:58.966 --> 00:20:00.266 A:middle
network, which illustrates how

00:19:58.966 --> 00:20:00.266 A:middle
network, which illustrates how

00:20:00.266 --> 00:20:01.026 A:middle
this can be used.

00:20:01.846 --> 00:20:02.876 A:middle
This is image captioning.

00:20:03.256 --> 00:20:04.526 A:middle
This is a network we showed a

00:20:04.526 --> 00:20:06.336 A:middle
couple years ago, and it

00:20:06.336 --> 00:20:07.556 A:middle
generates captions of images

00:20:07.556 --> 00:20:08.756 A:middle
using a convolutional neural

00:20:08.756 --> 00:20:10.596 A:middle
network and a recurrent neural

00:20:10.996 --> 00:20:11.186 A:middle
network.

00:20:13.116 --> 00:20:14.496 A:middle
The convolution network is the

00:20:14.496 --> 00:20:15.596 A:middle
common classification network.

00:20:15.596 --> 00:20:16.566 A:middle
In this case, we're using

00:20:16.566 --> 00:20:16.976 A:middle
Inception V3.

00:20:16.976 --> 00:20:18.946 A:middle
It's going to be used to extract

00:20:18.946 --> 00:20:20.136 A:middle
features from the source image.

00:20:20.666 --> 00:20:23.286 A:middle
Then we take these feature maps,

00:20:23.456 --> 00:20:24.686 A:middle
and we feed them into a small

00:20:24.686 --> 00:20:26.136 A:middle
LSTM-based network where those

00:20:26.136 --> 00:20:27.226 A:middle
captions are generated from the

00:20:27.226 --> 00:20:28.196 A:middle
extracted features.

00:20:28.926 --> 00:20:30.026 A:middle
Now, then we iterate this

00:20:30.026 --> 00:20:31.226 A:middle
network to produce the image

00:20:31.226 --> 00:20:31.586 A:middle
caption.

00:20:32.216 --> 00:20:35.856 A:middle
In this case, we need to know,

00:20:36.646 --> 00:20:38.206 A:middle
in this case, we need to run the

00:20:38.206 --> 00:20:39.696 A:middle
LSTM-based network for some

00:20:39.696 --> 00:20:41.486 A:middle
number of iterations, which is

00:20:41.486 --> 00:20:42.676 A:middle
going to be fixed, and we need

00:20:42.676 --> 00:20:43.836 A:middle
to do it at least as many times

00:20:43.836 --> 00:20:44.986 A:middle
as we believe will be needed to

00:20:44.986 --> 00:20:46.246 A:middle
generate the captions for the

00:20:46.246 --> 00:20:46.676 A:middle
image.

00:20:47.926 --> 00:20:48.936 A:middle
In this case, for example, we

00:20:48.936 --> 00:20:50.566 A:middle
run the LSTM-based network 20

00:20:50.566 --> 00:20:51.046 A:middle
times.

00:20:51.586 --> 00:20:53.956 A:middle
Each iteration then computes the

00:20:53.956 --> 00:20:55.416 A:middle
best captions by appending a new

00:20:55.416 --> 00:20:56.776 A:middle
word to the captions produced in

00:20:56.776 --> 00:20:57.516 A:middle
the prior iteration.

00:20:58.046 --> 00:21:00.546 A:middle
But if the caption were to only

00:20:58.046 --> 00:21:00.546 A:middle
But if the caption were to only

00:21:00.546 --> 00:21:02.896 A:middle
require five words, then we've

00:21:02.896 --> 00:21:04.236 A:middle
had to run many more iterations

00:21:04.236 --> 00:21:05.326 A:middle
than we need.

00:21:06.356 --> 00:21:08.906 A:middle
With predication, we can end the

00:21:08.906 --> 00:21:09.656 A:middle
execution early.

00:21:09.956 --> 00:21:11.056 A:middle
In this case, after the

00:21:11.056 --> 00:21:11.986 A:middle
five-word caption has been

00:21:11.986 --> 00:21:12.466 A:middle
generated.

00:21:13.466 --> 00:21:14.716 A:middle
So let's look at how we can use

00:21:14.716 --> 00:21:15.466 A:middle
this in MPS.

00:21:16.206 --> 00:21:17.406 A:middle
But to do so, we need to first

00:21:17.406 --> 00:21:19.476 A:middle
discuss how we provide predicate

00:21:19.476 --> 00:21:22.826 A:middle
values to MPS commands, and for

00:21:22.826 --> 00:21:24.356 A:middle
this, we introduce the

00:21:24.356 --> 00:21:25.236 A:middle
MPSCommandBuffer.

00:21:25.776 --> 00:21:29.536 A:middle
Now, MPSCommandBuffer is a class

00:21:29.536 --> 00:21:30.216 A:middle
that conforms to the

00:21:30.216 --> 00:21:31.426 A:middle
MTLCommandBuffer protocol, but

00:21:31.426 --> 00:21:32.256 A:middle
it adds a little bit more

00:21:32.256 --> 00:21:32.836 A:middle
flexibility.

00:21:33.656 --> 00:21:34.546 A:middle
It can be used anywhere you're

00:21:34.546 --> 00:21:35.486 A:middle
currently using metal command

00:21:35.486 --> 00:21:36.506 A:middle
buff, and like a

00:21:36.506 --> 00:21:37.926 A:middle
MTLCommandBuffer, it's

00:21:37.926 --> 00:21:38.576 A:middle
constructed from a

00:21:38.576 --> 00:21:39.216 A:middle
MTLCommandQueue.

00:21:39.216 --> 00:21:41.236 A:middle
Now, it provides several

00:21:41.236 --> 00:21:42.036 A:middle
important benefits.

00:21:42.696 --> 00:21:43.776 A:middle
It allows you to predicate

00:21:43.776 --> 00:21:46.146 A:middle
execution of MPS kernels, and as

00:21:46.146 --> 00:21:47.296 A:middle
we'll discuss later, it allows

00:21:47.296 --> 00:21:48.446 A:middle
you to easily perform some

00:21:48.446 --> 00:21:49.686 A:middle
intermediate commits as you

00:21:49.686 --> 00:21:51.436 A:middle
encode your MPS work, using a

00:21:51.436 --> 00:21:52.706 A:middle
method called commitAndContinue,

00:21:52.706 --> 00:21:53.476 A:middle
but we'll get back to that

00:21:53.476 --> 00:21:53.766 A:middle
later.

00:21:54.256 --> 00:21:55.706 A:middle
First, let's look at how we an

00:21:55.706 --> 00:21:57.546 A:middle
use MPSCommandBuffers to supply

00:21:57.546 --> 00:21:58.766 A:middle
predicates to MPS kernels.

00:21:59.216 --> 00:22:01.836 A:middle
So an MPS predicate object

00:21:59.216 --> 00:22:01.836 A:middle
So an MPS predicate object

00:22:01.836 --> 00:22:03.146 A:middle
contains a metal buffer, which

00:22:03.146 --> 00:22:04.346 A:middle
contains 32-bit integer

00:22:04.346 --> 00:22:05.666 A:middle
predicate values, and they're at

00:22:05.666 --> 00:22:06.096 A:middle
an offset.

00:22:07.276 --> 00:22:08.166 A:middle
We take the value within the

00:22:08.166 --> 00:22:09.476 A:middle
metal buffer at the offset as

00:22:09.476 --> 00:22:10.386 A:middle
the execution predicate.

00:22:10.576 --> 00:22:12.656 A:middle
Now, a value of 0 means we don't

00:22:12.656 --> 00:22:13.916 A:middle
want the kernel to execute, and

00:22:14.116 --> 00:22:15.976 A:middle
a nonzero value means to execute

00:22:15.976 --> 00:22:16.336 A:middle
as normal.

00:22:16.846 --> 00:22:18.736 A:middle
So, in this diagram here, we've

00:22:18.736 --> 00:22:19.736 A:middle
effectively bypassed the

00:22:19.736 --> 00:22:21.276 A:middle
execution of this kernel by

00:22:21.276 --> 00:22:22.496 A:middle
setting the value at the offset

00:22:22.496 --> 00:22:22.896 A:middle
to 0.

00:22:23.436 --> 00:22:25.246 A:middle
And the offset is important.

00:22:25.246 --> 00:22:26.186 A:middle
It can allow you to share a

00:22:26.186 --> 00:22:27.556 A:middle
single metal buffer among

00:22:27.556 --> 00:22:28.986 A:middle
multiple MPS predicate objects

00:22:28.986 --> 00:22:29.966 A:middle
so you can send a predicate to

00:22:29.966 --> 00:22:30.726 A:middle
multiple kernels.

00:22:31.206 --> 00:22:33.326 A:middle
Each predicate value will be

00:22:33.416 --> 00:22:34.146 A:middle
referenced with a different

00:22:34.146 --> 00:22:34.456 A:middle
offset.

00:22:35.006 --> 00:22:38.106 A:middle
Now, in order to use a predicate

00:22:38.106 --> 00:22:39.826 A:middle
value, we have to attach it to

00:22:39.826 --> 00:22:40.686 A:middle
an MPSCommandBuffer.

00:22:41.236 --> 00:22:42.576 A:middle
This way, any MPS kernels that

00:22:42.576 --> 00:22:43.826 A:middle
we encode on that command buffer

00:22:43.826 --> 00:22:44.756 A:middle
will perceive the predicate

00:22:44.756 --> 00:22:45.326 A:middle
values.

00:22:45.976 --> 00:22:47.096 A:middle
So, let's take a look at how we

00:22:47.096 --> 00:22:49.096 A:middle
can create a predicate and set

00:22:49.096 --> 00:22:50.156 A:middle
it on an MPSCommandBuffer.

00:22:50.706 --> 00:22:53.976 A:middle
So, first, we create an

00:22:53.976 --> 00:22:56.966 A:middle
MPSPredicate object, and we

00:22:57.186 --> 00:22:58.666 A:middle
attach the predicate to our

00:22:58.666 --> 00:22:59.406 A:middle
MPSCommandBuffer.

00:22:59.966 --> 00:23:01.226 A:middle
Now, we'll encode an operation

00:22:59.966 --> 00:23:01.226 A:middle
Now, we'll encode an operation

00:23:01.936 --> 00:23:03.056 A:middle
that modifies the predicate

00:23:03.056 --> 00:23:03.526 A:middle
values.

00:23:04.206 --> 00:23:05.056 A:middle
Now because of the existing

00:23:05.056 --> 00:23:06.146 A:middle
metal buffers, we need a kernel

00:23:06.146 --> 00:23:07.756 A:middle
that produces its result in a

00:23:07.756 --> 00:23:08.286 A:middle
metal buffer.

00:23:08.546 --> 00:23:10.516 A:middle
You can use your own kernel, or

00:23:10.516 --> 00:23:11.516 A:middle
you may be able to use one of

00:23:11.516 --> 00:23:13.016 A:middle
the MPSMatrix kernels, which is

00:23:13.016 --> 00:23:13.786 A:middle
what we're going to do here.

00:23:14.496 --> 00:23:15.356 A:middle
So, we're going to start by

00:23:15.356 --> 00:23:16.686 A:middle
wrapping the predicate in an

00:23:16.686 --> 00:23:17.616 A:middle
MPSMatrix object.

00:23:18.026 --> 00:23:19.156 A:middle
Then we're going to encode a

00:23:19.156 --> 00:23:20.266 A:middle
kernel to modify the predicate

00:23:20.266 --> 00:23:20.616 A:middle
value.

00:23:22.106 --> 00:23:23.106 A:middle
So, here, we're just using a

00:23:23.106 --> 00:23:24.506 A:middle
linear neuron kernel, and we're

00:23:24.506 --> 00:23:25.636 A:middle
going to use it to do something

00:23:25.636 --> 00:23:25.926 A:middle
simple.

00:23:25.926 --> 00:23:26.716 A:middle
We're just going to decrement

00:23:26.716 --> 00:23:27.526 A:middle
the value of the predicate.

00:23:28.046 --> 00:23:29.846 A:middle
And finally, we're going to

00:23:29.846 --> 00:23:31.796 A:middle
encode a cnnKernel to read the

00:23:31.796 --> 00:23:33.016 A:middle
value of the predicate prior to

00:23:33.016 --> 00:23:33.656 A:middle
execution.

00:23:37.256 --> 00:23:38.866 A:middle
So, using predication in

00:23:38.866 --> 00:23:40.716 A:middle
MPSCommandBuffers is an easy way

00:23:40.946 --> 00:23:42.396 A:middle
of eliminating unnecessary work

00:23:42.396 --> 00:23:42.996 A:middle
in your networks.

00:23:43.666 --> 00:23:45.026 A:middle
If you have kernels, which can

00:23:45.026 --> 00:23:46.086 A:middle
be bypassed, you can use

00:23:46.086 --> 00:23:47.336 A:middle
predication to take advantage of

00:23:47.336 --> 00:23:48.066 A:middle
the reduced workload.

00:23:48.416 --> 00:23:49.926 A:middle
And if there are multiple

00:23:49.926 --> 00:23:51.336 A:middle
kernels for which this applies,

00:23:51.816 --> 00:23:53.136 A:middle
you can use multiple predicates

00:23:53.376 --> 00:23:54.416 A:middle
and use only a single metal

00:23:54.416 --> 00:23:55.706 A:middle
buffer by setting unique offset

00:23:55.706 --> 00:23:56.166 A:middle
values.

00:23:56.166 --> 00:23:58.916 A:middle
So, now let's talk about the

00:23:58.916 --> 00:23:59.886 A:middle
other feature of

00:23:59.886 --> 00:24:00.826 A:middle
MPSCommandBuffers,

00:23:59.886 --> 00:24:00.826 A:middle
MPSCommandBuffers,

00:24:01.126 --> 00:24:01.806 A:middle
commitAndContinue.

00:24:02.406 --> 00:24:05.206 A:middle
Now this is a method which

00:24:05.206 --> 00:24:07.126 A:middle
allows you to easily get better

00:24:07.126 --> 00:24:09.956 A:middle
GPU utilization when executing

00:24:09.956 --> 00:24:10.846 A:middle
your work.

00:24:11.776 --> 00:24:12.936 A:middle
So, to see how it can benefit,

00:24:12.936 --> 00:24:14.406 A:middle
let's first review how a typical

00:24:14.406 --> 00:24:15.356 A:middle
workload is executed.

00:24:16.326 --> 00:24:18.046 A:middle
Now, the usual way of executing

00:24:18.046 --> 00:24:19.336 A:middle
MPS kernels is to encode your

00:24:19.336 --> 00:24:20.386 A:middle
work onto a command buffer and

00:24:20.386 --> 00:24:21.476 A:middle
then commit it for execution.

00:24:21.966 --> 00:24:22.956 A:middle
So, here we have a case of a

00:24:22.956 --> 00:24:24.246 A:middle
single command buffer, you

00:24:24.246 --> 00:24:25.246 A:middle
encode some work, and then we

00:24:25.246 --> 00:24:26.286 A:middle
execute it afterwards.

00:24:27.216 --> 00:24:28.606 A:middle
Now, in reality, the CPU's

00:24:28.606 --> 00:24:29.506 A:middle
encoding time is going to be

00:24:29.506 --> 00:24:31.066 A:middle
less than the GPU's execution

00:24:31.066 --> 00:24:33.316 A:middle
time, but we want to avoid any

00:24:33.396 --> 00:24:35.696 A:middle
idle time due to throttling and

00:24:35.696 --> 00:24:36.846 A:middle
things like that.

00:24:37.966 --> 00:24:39.346 A:middle
So you can see we're going to

00:24:39.346 --> 00:24:42.026 A:middle
get some stalling here between

00:24:42.026 --> 00:24:42.956 A:middle
the CPU and the GPU.

00:24:43.546 --> 00:24:45.776 A:middle
Now, one way of solving this is

00:24:45.776 --> 00:24:46.816 A:middle
to use double buffering.

00:24:47.286 --> 00:24:48.976 A:middle
With double buffering, we're

00:24:48.976 --> 00:24:49.936 A:middle
going to keep around two command

00:24:49.936 --> 00:24:51.156 A:middle
buffers, and we're going to

00:24:51.156 --> 00:24:52.206 A:middle
encode work to one while

00:24:52.206 --> 00:24:53.036 A:middle
executing the other.

00:24:53.866 --> 00:24:54.746 A:middle
Now, this should pretty well

00:24:55.406 --> 00:24:56.896 A:middle
eliminate the idling that we saw

00:24:56.896 --> 00:24:58.476 A:middle
before, but it has some

00:24:58.476 --> 00:24:59.256 A:middle
limitations.

00:24:59.686 --> 00:25:00.546 A:middle
So, first off, as I mentioned,

00:24:59.686 --> 00:25:00.546 A:middle
So, first off, as I mentioned,

00:25:00.546 --> 00:25:01.416 A:middle
you're going to have to keep two

00:25:01.416 --> 00:25:02.206 A:middle
sets of work, which means you're

00:25:02.206 --> 00:25:03.216 A:middle
going to have to find a way to

00:25:03.216 --> 00:25:04.696 A:middle
partition your work into two

00:25:04.696 --> 00:25:05.836 A:middle
independent workloads.

00:25:06.286 --> 00:25:07.586 A:middle
And as a result, you can have

00:25:07.586 --> 00:25:08.826 A:middle
substantially increased memory

00:25:08.826 --> 00:25:09.486 A:middle
requirements.

00:25:11.336 --> 00:25:12.646 A:middle
However, we the

00:25:12.646 --> 00:25:13.986 A:middle
commitAndContinue method, we can

00:25:13.986 --> 00:25:15.046 A:middle
gain much of this performance

00:25:15.046 --> 00:25:16.726 A:middle
benefit by dividing each

00:25:16.726 --> 00:25:18.276 A:middle
workload into smaller portions.

00:25:19.456 --> 00:25:20.366 A:middle
So, here we're going to break

00:25:20.366 --> 00:25:21.556 A:middle
down the work by utilizing

00:25:21.556 --> 00:25:23.026 A:middle
independence of layers within

00:25:23.026 --> 00:25:23.816 A:middle
each command buffer.

00:25:24.906 --> 00:25:25.876 A:middle
Then we're going to commit the

00:25:25.876 --> 00:25:27.506 A:middle
smaller groups of work using

00:25:27.506 --> 00:25:28.046 A:middle
double buffering.

00:25:28.626 --> 00:25:30.596 A:middle
Now, commitAndContinue is

00:25:30.596 --> 00:25:31.676 A:middle
automatically going to handle

00:25:31.676 --> 00:25:32.836 A:middle
this internal division of work

00:25:32.836 --> 00:25:34.646 A:middle
while also ensuring that any

00:25:34.646 --> 00:25:35.826 A:middle
temporary objects that you

00:25:35.826 --> 00:25:37.056 A:middle
allocated on the command buffer

00:25:37.056 --> 00:25:38.356 A:middle
will remain valid for subsequent

00:25:38.356 --> 00:25:39.026 A:middle
work to be encoded.

00:25:39.536 --> 00:25:42.226 A:middle
As with double buffering, it

00:25:42.226 --> 00:25:43.576 A:middle
allows you to execute work on

00:25:43.576 --> 00:25:44.856 A:middle
the GPU while continuing to

00:25:44.856 --> 00:25:45.706 A:middle
encode it on the CPU.

00:25:46.506 --> 00:25:47.646 A:middle
And by easily allowing you to

00:25:47.646 --> 00:25:49.116 A:middle
partition your workload, you can

00:25:49.116 --> 00:25:50.306 A:middle
avoid the increased memory

00:25:50.306 --> 00:25:51.656 A:middle
requirement of double buffering

00:25:51.766 --> 00:25:52.716 A:middle
while still getting much

00:25:52.766 --> 00:25:54.016 A:middle
improved GPU utilization.

00:25:54.946 --> 00:25:55.856 A:middle
So let's see how you can take

00:25:55.856 --> 00:25:56.676 A:middle
advantage of this in your own

00:25:56.676 --> 00:25:56.896 A:middle
code.

00:25:58.356 --> 00:26:00.316 A:middle
So here we have four MPS kernels

00:25:58.356 --> 00:26:00.316 A:middle
So here we have four MPS kernels

00:26:00.316 --> 00:26:00.926 A:middle
we're encoding to a

00:26:00.926 --> 00:26:01.676 A:middle
MTLCommandBuffer.

00:26:02.246 --> 00:26:04.686 A:middle
And finally, we commit the work

00:26:04.686 --> 00:26:05.266 A:middle
for execution.

00:26:06.556 --> 00:26:08.046 A:middle
As we showed earlier, this is

00:26:08.046 --> 00:26:09.636 A:middle
going to give you the stalls

00:26:09.636 --> 00:26:11.206 A:middle
that we saw.

00:26:11.446 --> 00:26:12.236 A:middle
However, by using

00:26:12.236 --> 00:26:13.886 A:middle
MPSCommandBuffers and the new

00:26:13.886 --> 00:26:15.166 A:middle
CommitAndContinue method, we can

00:26:15.166 --> 00:26:16.106 A:middle
easily improve this.

00:26:17.226 --> 00:26:18.226 A:middle
So, here we're going to create

00:26:18.226 --> 00:26:19.156 A:middle
an MPSCommandBuffer.

00:26:20.476 --> 00:26:21.406 A:middle
We'll encode our first two

00:26:21.406 --> 00:26:21.836 A:middle
kernels.

00:26:23.306 --> 00:26:23.936 A:middle
Then we'll call

00:26:23.936 --> 00:26:24.606 A:middle
commitAndContinue.

00:26:25.146 --> 00:26:27.176 A:middle
This will commit the work that

00:26:27.176 --> 00:26:29.966 A:middle
we've already encoded, move any

00:26:29.966 --> 00:26:31.136 A:middle
allocations forward, and allow

00:26:31.136 --> 00:26:32.236 A:middle
us to immediately continue

00:26:32.236 --> 00:26:33.936 A:middle
encoding the other two kernels.

00:26:34.696 --> 00:26:35.826 A:middle
Finally, we can commit the

00:26:35.826 --> 00:26:36.956 A:middle
remaining work using a regular

00:26:36.956 --> 00:26:37.196 A:middle
commit.

00:26:37.196 --> 00:26:39.896 A:middle
So you can see, using

00:26:39.896 --> 00:26:41.426 A:middle
commitAndContinue requires very

00:26:41.426 --> 00:26:43.676 A:middle
few changes to your code, but if

00:26:43.676 --> 00:26:44.596 A:middle
you're taking advantage of the

00:26:44.596 --> 00:26:46.426 A:middle
graph, it's even easier.

00:26:47.846 --> 00:26:49.206 A:middle
When you encode and MPS in graph

00:26:49.206 --> 00:26:51.326 A:middle
using MPSCommandBuffer, it will

00:26:51.326 --> 00:26:52.106 A:middle
automatically use

00:26:52.106 --> 00:26:52.866 A:middle
commitAndContinue to

00:26:52.866 --> 00:26:53.956 A:middle
periodically submit work

00:26:54.346 --> 00:26:55.596 A:middle
throughout the encoding process.

00:26:56.346 --> 00:26:57.516 A:middle
No further changes are needed.

00:26:57.886 --> 00:26:59.416 A:middle
Simply use an MPSCommandBuffer

00:26:59.546 --> 00:27:00.806 A:middle
instead of a MTLCommandBuffer.

00:26:59.546 --> 00:27:00.806 A:middle
instead of a MTLCommandBuffer.

00:27:01.356 --> 00:27:04.076 A:middle
And finally, I want to point out

00:27:04.076 --> 00:27:05.516 A:middle
that you can still combine

00:27:05.556 --> 00:27:06.786 A:middle
commitAndContinue with double

00:27:06.786 --> 00:27:08.946 A:middle
buffering and get even better

00:27:08.946 --> 00:27:09.656 A:middle
performance.

00:27:09.656 --> 00:27:10.816 A:middle
So, as you can see here, it

00:27:10.816 --> 00:27:12.216 A:middle
allows you to eliminate even the

00:27:12.216 --> 00:27:13.376 A:middle
small stalls that we saw with

00:27:13.376 --> 00:27:14.026 A:middle
commitAndContinue.

00:27:14.606 --> 00:27:16.606 A:middle
So, we now have a variety of

00:27:16.606 --> 00:27:17.616 A:middle
options for committing our work

00:27:17.616 --> 00:27:18.226 A:middle
for execution.

00:27:18.226 --> 00:27:20.326 A:middle
You can use a single command

00:27:20.326 --> 00:27:21.776 A:middle
buffer, executing a single piece

00:27:21.776 --> 00:27:22.426 A:middle
of work at a time.

00:27:23.186 --> 00:27:24.326 A:middle
For better performance,

00:27:24.386 --> 00:27:25.786 A:middle
potentially with increased

00:27:25.786 --> 00:27:26.866 A:middle
memory consumption, you can use

00:27:26.866 --> 00:27:27.516 A:middle
double buffering.

00:27:28.966 --> 00:27:30.906 A:middle
And now, with MPSCommandBuffer,

00:27:31.386 --> 00:27:32.746 A:middle
you can achieve nearly the same

00:27:32.746 --> 00:27:33.436 A:middle
performance using

00:27:33.436 --> 00:27:34.106 A:middle
commitAndContinue.

00:27:34.696 --> 00:27:36.766 A:middle
And if you still want even

00:27:36.766 --> 00:27:37.786 A:middle
better performance, you can use

00:27:37.786 --> 00:27:39.256 A:middle
commitAndContinue and double

00:27:39.256 --> 00:27:39.586 A:middle
buffering.

00:27:39.846 --> 00:27:42.256 A:middle
So let's take a look at how

00:27:42.256 --> 00:27:43.556 A:middle
these approaches perform on a

00:27:43.556 --> 00:27:44.326 A:middle
real-world network.

00:27:44.326 --> 00:27:47.006 A:middle
So for this case, were going to

00:27:47.006 --> 00:27:48.326 A:middle
look at the ResNet 50 network

00:27:48.326 --> 00:27:50.076 A:middle
running on a CIFAR-10 dataset.

00:27:50.746 --> 00:27:52.226 A:middle
Now this data was measured using

00:27:52.226 --> 00:27:54.446 A:middle
an external AMD Radeon Pro Vega

00:27:54.446 --> 00:27:55.336 A:middle
64 GPU.

00:27:56.336 --> 00:27:56.926 A:middle
It's a common image

00:27:56.926 --> 00:27:58.416 A:middle
classification network with many

00:27:58.416 --> 00:27:59.696 A:middle
layers, so it's a good example

00:27:59.696 --> 00:28:00.336 A:middle
of what we can see with

00:27:59.696 --> 00:28:00.336 A:middle
of what we can see with

00:28:00.336 --> 00:28:00.956 A:middle
commitAndContinue.

00:28:01.146 --> 00:28:03.426 A:middle
So we're going to start with our

00:28:03.426 --> 00:28:04.626 A:middle
single buffering case as our

00:28:04.626 --> 00:28:05.106 A:middle
baseline.

00:28:05.436 --> 00:28:06.476 A:middle
We have performance and memory

00:28:06.476 --> 00:28:07.506 A:middle
consumption here on the vertical

00:28:07.506 --> 00:28:08.036 A:middle
axis.

00:28:08.426 --> 00:28:09.096 A:middle
So, let's see how double

00:28:09.096 --> 00:28:10.016 A:middle
buffering compares.

00:28:10.016 --> 00:28:11.356 A:middle
Now we've improved the

00:28:11.356 --> 00:28:12.586 A:middle
performance quite a bit, but

00:28:12.926 --> 00:28:14.116 A:middle
we've also increased our memory

00:28:14.116 --> 00:28:15.306 A:middle
consumption by a similar amount.

00:28:16.156 --> 00:28:17.146 A:middle
That's because we achieve double

00:28:17.146 --> 00:28:18.356 A:middle
buffering by maintaining twice

00:28:18.356 --> 00:28:19.406 A:middle
as much work in flight at any

00:28:19.406 --> 00:28:19.886 A:middle
given time.

00:28:20.556 --> 00:28:21.486 A:middle
So, let's look at using

00:28:21.486 --> 00:28:22.176 A:middle
CommitAndContinue.

00:28:23.296 --> 00:28:24.306 A:middle
We come very close on the

00:28:24.306 --> 00:28:25.926 A:middle
performance and with

00:28:25.926 --> 00:28:26.996 A:middle
significantly less memory

00:28:26.996 --> 00:28:31.186 A:middle
overhead, and here we also see

00:28:31.186 --> 00:28:32.236 A:middle
CommitAndContinue along with

00:28:32.236 --> 00:28:32.816 A:middle
double buffering.

00:28:33.716 --> 00:28:34.646 A:middle
We still get a little bit better

00:28:34.646 --> 00:28:37.006 A:middle
performance, but we still use a

00:28:37.006 --> 00:28:37.856 A:middle
lot more memory as well.

00:28:37.856 --> 00:28:40.526 A:middle
So, you can see, using

00:28:40.526 --> 00:28:42.316 A:middle
CommitAndContinue is a very easy

00:28:42.316 --> 00:28:43.316 A:middle
way to achieve much better

00:28:43.316 --> 00:28:45.266 A:middle
performance with minimal

00:28:45.266 --> 00:28:46.166 A:middle
increase in memory pressure.

00:28:46.786 --> 00:28:49.266 A:middle
So now, let's put all of these

00:28:49.266 --> 00:28:50.896 A:middle
approaches together by looking

00:28:50.896 --> 00:28:51.806 A:middle
at another application of

00:28:51.806 --> 00:28:53.096 A:middle
machine learning, denoising.

00:28:53.096 --> 00:28:56.136 A:middle
Now as this name suggests,

00:28:56.136 --> 00:28:58.806 A:middle
denoising seeks to remove noise

00:28:58.806 --> 00:28:59.746 A:middle
from a noisy image and produce a

00:28:59.746 --> 00:28:59.976 A:middle
clean one.

00:29:02.116 --> 00:29:03.056 A:middle
Now, we're going to be looking

00:29:03.056 --> 00:29:04.026 A:middle
at this in the context of ray

00:29:04.026 --> 00:29:04.426 A:middle
tracing.

00:29:05.036 --> 00:29:07.446 A:middle
If you saw the earlier metal for

00:29:07.446 --> 00:29:08.796 A:middle
ray tracing session, you saw

00:29:08.796 --> 00:29:09.956 A:middle
another example of denoising,

00:29:09.996 --> 00:29:11.496 A:middle
one using image processing

00:29:11.496 --> 00:29:12.016 A:middle
techniques.

00:29:12.096 --> 00:29:13.176 A:middle
Here, we're going to be looking

00:29:13.176 --> 00:29:14.756 A:middle
at a solution based on machine

00:29:14.756 --> 00:29:15.016 A:middle
learning.

00:29:15.586 --> 00:29:18.606 A:middle
So for this example, we'll look

00:29:18.606 --> 00:29:19.356 A:middle
at three phases.

00:29:19.356 --> 00:29:20.396 A:middle
We're going to create an offline

00:29:20.396 --> 00:29:21.236 A:middle
training process.

00:29:21.236 --> 00:29:22.526 A:middle
We're going to run the training

00:29:22.526 --> 00:29:24.166 A:middle
network, and finally we're going

00:29:24.166 --> 00:29:25.226 A:middle
to deploy the inference graph to

00:29:25.226 --> 00:29:26.346 A:middle
filter new images.

00:29:28.286 --> 00:29:29.516 A:middle
So, first, we need to create the

00:29:29.516 --> 00:29:29.916 A:middle
graph.

00:29:30.496 --> 00:29:31.836 A:middle
Let's take a closer look at the

00:29:31.836 --> 00:29:32.266 A:middle
structure.

00:29:32.866 --> 00:29:35.316 A:middle
So here we're going to start

00:29:35.606 --> 00:29:38.066 A:middle
with our input image, which is

00:29:38.066 --> 00:29:39.746 A:middle
our noisy image, which came out

00:29:39.746 --> 00:29:40.946 A:middle
of our ray tracer.

00:29:41.556 --> 00:29:44.006 A:middle
We're going to feed this image

00:29:44.006 --> 00:29:45.196 A:middle
into encoder stages.

00:29:45.346 --> 00:29:46.436 A:middle
Now encoders are small

00:29:46.436 --> 00:29:48.276 A:middle
subnetworks which extract

00:29:48.276 --> 00:29:49.056 A:middle
higher-level feature

00:29:49.056 --> 00:29:50.576 A:middle
representations while spatially

00:29:50.576 --> 00:29:51.446 A:middle
compressing the image.

00:29:51.996 --> 00:29:53.716 A:middle
We're going to pass these

00:29:53.716 --> 00:29:55.286 A:middle
results into our decoder stages.

00:29:55.856 --> 00:29:56.856 A:middle
Now these perform the reverse

00:29:56.886 --> 00:29:57.406 A:middle
process.

00:29:57.606 --> 00:29:58.506 A:middle
They're going to reconstruct the

00:29:58.506 --> 00:29:59.636 A:middle
image from the feature maps.

00:30:00.206 --> 00:30:02.536 A:middle
Now we're also going to use what

00:30:02.536 --> 00:30:03.646 A:middle
are called skip connections.

00:30:03.726 --> 00:30:05.246 A:middle
These boost features from the

00:30:05.246 --> 00:30:07.126 A:middle
encoded image into each decoder

00:30:07.126 --> 00:30:07.576 A:middle
stage.

00:30:08.456 --> 00:30:09.536 A:middle
This is done by forwarding the

00:30:09.536 --> 00:30:10.786 A:middle
result from each encoder to its

00:30:10.786 --> 00:30:11.176 A:middle
decoder.

00:30:11.986 --> 00:30:14.146 A:middle
Finally, the denoised image is

00:30:14.146 --> 00:30:14.966 A:middle
fully reconstructed.

00:30:16.086 --> 00:30:17.426 A:middle
So, let's take a closer look at

00:30:17.696 --> 00:30:18.796 A:middle
the encoder stages.

00:30:19.476 --> 00:30:21.386 A:middle
The encoder stage compresses the

00:30:21.386 --> 00:30:23.336 A:middle
images while trying to learn how

00:30:23.336 --> 00:30:24.506 A:middle
to preserve its features,

00:30:24.566 --> 00:30:25.786 A:middle
consists of three pairs of

00:30:25.786 --> 00:30:27.586 A:middle
convolution and ReLu layers and

00:30:27.586 --> 00:30:28.756 A:middle
finally a max pooling layer.

00:30:29.696 --> 00:30:30.676 A:middle
Let's look at the code.

00:30:31.556 --> 00:30:32.686 A:middle
Now, as we saw before, we can

00:30:32.686 --> 00:30:33.596 A:middle
construct each node in the

00:30:33.596 --> 00:30:35.096 A:middle
sequence in the same order they

00:30:35.096 --> 00:30:35.886 A:middle
appear in the network.

00:30:36.366 --> 00:30:38.816 A:middle
And we'll construct the decoders

00:30:38.816 --> 00:30:39.316 A:middle
in the same way.

00:30:39.316 --> 00:30:41.366 A:middle
You start with an upsampling

00:30:41.366 --> 00:30:41.596 A:middle
layer.

00:30:42.696 --> 00:30:43.846 A:middle
After this, we add the result of

00:30:43.846 --> 00:30:45.056 A:middle
the corresponding encoder via

00:30:45.056 --> 00:30:48.046 A:middle
the skip connection, and then

00:30:48.046 --> 00:30:49.286 A:middle
finally we have two pairs of

00:30:49.286 --> 00:30:50.976 A:middle
convolution and ReLu layers.

00:30:53.996 --> 00:30:55.106 A:middle
Again, as before, we're going to

00:30:55.106 --> 00:30:56.266 A:middle
insert nodes corresponding to

00:30:56.266 --> 00:30:57.136 A:middle
each layer in the network.

00:30:58.306 --> 00:31:00.146 A:middle
Now we can put our encoder and

00:30:58.306 --> 00:31:00.146 A:middle
Now we can put our encoder and

00:31:00.146 --> 00:31:01.566 A:middle
decoder stages together.

00:31:04.916 --> 00:31:06.096 A:middle
So, first we're going to connect

00:31:06.096 --> 00:31:06.916 A:middle
our encoder nodes.

00:31:09.536 --> 00:31:10.746 A:middle
But before we move on and

00:31:10.746 --> 00:31:11.776 A:middle
connect our decoder nodes, we

00:31:11.776 --> 00:31:12.876 A:middle
need to put in one more encoder

00:31:12.876 --> 00:31:13.736 A:middle
node, which we're going to call

00:31:13.736 --> 00:31:14.566 A:middle
the bottleneck node.

00:31:15.026 --> 00:31:16.266 A:middle
It's identical to an encoder

00:31:16.266 --> 00:31:17.696 A:middle
except it doesn't have the final

00:31:17.696 --> 00:31:18.406 A:middle
max pooling layer.

00:31:18.956 --> 00:31:21.056 A:middle
And after the bottleneck nodes,

00:31:21.296 --> 00:31:21.946 A:middle
we're going to connect our

00:31:21.946 --> 00:31:22.806 A:middle
decoder nodes.

00:31:23.486 --> 00:31:25.236 A:middle
Now, by passing the result image

00:31:25.266 --> 00:31:26.306 A:middle
from the corresponding encoder

00:31:26.306 --> 00:31:27.826 A:middle
nodes, we're going to satisfy

00:31:27.826 --> 00:31:28.656 A:middle
the skip connections.

00:31:30.636 --> 00:31:31.496 A:middle
So now we have the inference

00:31:31.496 --> 00:31:31.876 A:middle
graph.

00:31:32.226 --> 00:31:32.886 A:middle
Let's look at the training

00:31:32.886 --> 00:31:32.976 A:middle
phase.

00:31:35.496 --> 00:31:37.006 A:middle
To begin the training phase, we

00:31:37.006 --> 00:31:38.086 A:middle
need to compute the loss value.

00:31:38.146 --> 00:31:39.196 A:middle
So we're going to start we the

00:31:39.196 --> 00:31:40.546 A:middle
inference, we're going to start

00:31:40.546 --> 00:31:41.416 A:middle
with the result of the inference

00:31:41.416 --> 00:31:43.586 A:middle
graph, which for a training

00:31:43.586 --> 00:31:44.796 A:middle
iteration is now our network's

00:31:44.866 --> 00:31:46.146 A:middle
best guess at the current

00:31:46.146 --> 00:31:46.876 A:middle
denoised image.

00:31:47.446 --> 00:31:49.246 A:middle
Now, we're going to take the

00:31:49.246 --> 00:31:51.156 A:middle
clean RGB image for our ground

00:31:51.156 --> 00:31:52.006 A:middle
truth, and we're going to use

00:31:52.006 --> 00:31:53.076 A:middle
that to compute a loss value.

00:31:53.076 --> 00:31:55.066 A:middle
Now, we're also going to want to

00:31:55.066 --> 00:31:56.076 A:middle
compute a second loss.

00:31:56.566 --> 00:31:57.706 A:middle
We're going to perform some edge

00:31:57.706 --> 00:31:58.206 A:middle
detection.

00:31:58.286 --> 00:31:59.356 A:middle
We're going to do this doing a

00:31:59.356 --> 00:32:00.706 A:middle
Laplacian of Gaussian filter.

00:31:59.356 --> 00:32:00.706 A:middle
Laplacian of Gaussian filter.

00:32:01.616 --> 00:32:03.026 A:middle
Now, we want to do this because

00:32:03.546 --> 00:32:04.576 A:middle
we want our network to learn how

00:32:04.576 --> 00:32:06.096 A:middle
to denoise the image, but at the

00:32:06.096 --> 00:32:07.086 A:middle
same time we also want to make

00:32:07.086 --> 00:32:08.516 A:middle
sure that it preserves the edges

00:32:08.516 --> 00:32:09.396 A:middle
of the original image.

00:32:10.536 --> 00:32:12.436 A:middle
So, were going to implement the

00:32:12.436 --> 00:32:14.026 A:middle
Laplacian of Gaussian or the LoG

00:32:14.026 --> 00:32:15.976 A:middle
filter using convolutions here.

00:32:17.396 --> 00:32:18.446 A:middle
Finally, we're going to combine

00:32:18.446 --> 00:32:19.326 A:middle
these two losses.

00:32:19.486 --> 00:32:20.426 A:middle
The first loss we're going to

00:32:20.426 --> 00:32:22.956 A:middle
call the RGB loss and the second

00:32:22.956 --> 00:32:24.336 A:middle
the LoG loss, and we're going to

00:32:24.336 --> 00:32:25.556 A:middle
combine these into the final

00:32:25.556 --> 00:32:25.916 A:middle
loss.

00:32:28.476 --> 00:32:29.956 A:middle
So now let's take a closer look

00:32:29.956 --> 00:32:30.666 A:middle
at how we do this.

00:32:30.796 --> 00:32:32.456 A:middle
So, we're going to create our

00:32:32.456 --> 00:32:34.546 A:middle
RBG loss node using the result

00:32:34.546 --> 00:32:35.796 A:middle
of the inference graph and the

00:32:35.796 --> 00:32:37.086 A:middle
ground truth RGB images.

00:32:37.196 --> 00:32:39.476 A:middle
So, as you mentioned earlier, we

00:32:39.476 --> 00:32:40.876 A:middle
can use separable loss kernels,

00:32:41.246 --> 00:32:43.256 A:middle
and we're going to pass both of

00:32:43.256 --> 00:32:44.316 A:middle
our, we're going to pass images

00:32:44.316 --> 00:32:45.216 A:middle
for both our source and our

00:32:45.216 --> 00:32:45.656 A:middle
labels.

00:32:46.166 --> 00:32:49.256 A:middle
For our LoG loss, we need to

00:32:49.256 --> 00:32:50.656 A:middle
apply the LoG filter to the

00:32:50.656 --> 00:32:52.346 A:middle
target RBG images as well as the

00:32:52.346 --> 00:32:52.976 A:middle
result of the inference graph.

00:32:56.476 --> 00:32:57.676 A:middle
So, were going to implement the

00:32:57.676 --> 00:32:58.856 A:middle
LoG filter using convolution

00:32:58.856 --> 00:32:58.976 A:middle
nodes.

00:33:02.136 --> 00:33:03.576 A:middle
We're going to compute the LoG

00:33:03.576 --> 00:33:04.916 A:middle
loss using the results of the

00:33:04.916 --> 00:33:08.116 A:middle
convolutions, and finally with

00:33:08.116 --> 00:33:09.386 A:middle
both loss values computed, we

00:33:09.386 --> 00:33:10.866 A:middle
can add them together to produce

00:33:10.866 --> 00:33:11.606 A:middle
the final loss.

00:33:12.186 --> 00:33:15.216 A:middle
Now with the final loss value,

00:33:15.346 --> 00:33:15.876 A:middle
we can begin the

00:33:15.876 --> 00:33:17.206 A:middle
back-propagation phase and look

00:33:17.206 --> 00:33:17.946 A:middle
at the training graph.

00:33:18.976 --> 00:33:20.466 A:middle
So, we're going to do this as

00:33:20.756 --> 00:33:22.546 A:middle
before by computing the initial

00:33:22.546 --> 00:33:22.896 A:middle
gradient.

00:33:22.896 --> 00:33:25.166 A:middle
With the initial gradient value,

00:33:25.166 --> 00:33:26.246 A:middle
we can begin the training graph.

00:33:27.316 --> 00:33:28.576 A:middle
So, this involved several

00:33:28.576 --> 00:33:29.546 A:middle
gradient nodes first for the

00:33:29.546 --> 00:33:31.266 A:middle
addition followed by gradient

00:33:31.266 --> 00:33:33.386 A:middle
nodes for each forward loss and

00:33:33.456 --> 00:33:34.596 A:middle
then for the encoder and decoder

00:33:34.596 --> 00:33:35.136 A:middle
stages.

00:33:35.926 --> 00:33:36.966 A:middle
Now, implementing graph nodes

00:33:36.966 --> 00:33:38.346 A:middle
for each of these layers would

00:33:38.346 --> 00:33:39.526 A:middle
take a substantial amount of

00:33:39.526 --> 00:33:41.526 A:middle
code and introduce plenty of

00:33:41.526 --> 00:33:42.626 A:middle
opportunity for errors.

00:33:43.176 --> 00:33:44.706 A:middle
However, with implicit graph

00:33:44.706 --> 00:33:46.396 A:middle
creation, we can have the graph

00:33:46.566 --> 00:33:47.886 A:middle
do all of this work for us.

00:33:48.426 --> 00:33:51.096 A:middle
So, here's all we need to write

00:33:51.096 --> 00:33:51.976 A:middle
to generate the training graph.

00:33:55.156 --> 00:33:56.206 A:middle
First, we add the initial

00:33:56.206 --> 00:33:57.566 A:middle
gradient node using the result

00:33:57.566 --> 00:33:59.046 A:middle
of the final loss.

00:34:00.496 --> 00:34:01.686 A:middle
Then using implicit graph

00:34:01.686 --> 00:34:03.656 A:middle
creation, we generate all of the

00:34:03.656 --> 00:34:05.266 A:middle
remaining gradient nodes.

00:34:07.436 --> 00:34:08.616 A:middle
So now that we have our graph

00:34:08.616 --> 00:34:10.126 A:middle
created, we can begin training

00:34:10.676 --> 00:34:10.746 A:middle
it.

00:34:11.295 --> 00:34:12.826 A:middle
So first, let's discuss our

00:34:12.826 --> 00:34:13.536 A:middle
input training data.

00:34:14.045 --> 00:34:15.246 A:middle
Now, the inputs are images for

00:34:15.246 --> 00:34:16.025 A:middle
which we know the desired

00:34:16.025 --> 00:34:16.376 A:middle
result.

00:34:16.926 --> 00:34:17.795 A:middle
In this case we have noisy

00:34:17.795 --> 00:34:18.755 A:middle
images and we have the

00:34:18.755 --> 00:34:19.886 A:middle
corresponding clean images.

00:34:20.856 --> 00:34:22.056 A:middle
Now both images were generated

00:34:22.056 --> 00:34:23.626 A:middle
using a ray tracer built on top

00:34:23.626 --> 00:34:23.876 A:middle
of MPS.

00:34:23.876 --> 00:34:26.315 A:middle
We generated the noisy images by

00:34:26.315 --> 00:34:27.545 A:middle
only letting the ray tracer run

00:34:27.545 --> 00:34:28.716 A:middle
for a short period of time.

00:34:29.275 --> 00:34:31.226 A:middle
And the clean images we obtained

00:34:31.226 --> 00:34:32.376 A:middle
by running the ray tracer for an

00:34:32.376 --> 00:34:35.045 A:middle
extended period of time.

00:34:35.266 --> 00:34:36.045 A:middle
Now, by training with these

00:34:36.045 --> 00:34:37.786 A:middle
images, we hope our network will

00:34:37.786 --> 00:34:38.876 A:middle
learn to approximate the clean

00:34:38.876 --> 00:34:40.056 A:middle
ones from the noisy ones.

00:34:40.396 --> 00:34:42.025 A:middle
And further, we're going to

00:34:42.025 --> 00:34:43.346 A:middle
augment our input data with a

00:34:43.346 --> 00:34:45.775 A:middle
few other images, also produced

00:34:45.775 --> 00:34:46.386 A:middle
by a ray tracer.

00:34:47.255 --> 00:34:48.826 A:middle
Surface normal and albedo.

00:34:50.085 --> 00:34:51.556 A:middle
The albedo image is a

00:34:51.556 --> 00:34:52.786 A:middle
three-channel image containing

00:34:52.786 --> 00:34:55.596 A:middle
values which for the amount of

00:34:55.596 --> 00:34:58.366 A:middle
reflected light, the surface

00:34:58.366 --> 00:34:59.316 A:middle
normals are a three-channel

00:34:59.316 --> 00:35:00.556 A:middle
image where each channel is

00:34:59.316 --> 00:35:00.556 A:middle
image where each channel is

00:35:00.556 --> 00:35:02.676 A:middle
going to contain a component of

00:35:02.676 --> 00:35:03.686 A:middle
the surface normal vector.

00:35:04.286 --> 00:35:06.446 A:middle
Now, before we can begin

00:35:06.446 --> 00:35:07.976 A:middle
training, we need to do a little

00:35:08.196 --> 00:35:09.926 A:middle
bit of preprocessing.

00:35:09.926 --> 00:35:12.706 A:middle
So, as I mentioned, these all

00:35:12.706 --> 00:35:13.626 A:middle
contain their data in three

00:35:13.626 --> 00:35:14.166 A:middle
channels.

00:35:15.336 --> 00:35:17.436 A:middle
However, MPS networks and MPS

00:35:17.436 --> 00:35:20.586 A:middle
cnnKernels use their images as

00:35:20.726 --> 00:35:21.986 A:middle
four-channel textures.

00:35:22.546 --> 00:35:23.266 A:middle
So, we're going to have to

00:35:23.266 --> 00:35:24.346 A:middle
concatenate these values

00:35:24.346 --> 00:35:24.836 A:middle
together.

00:35:25.506 --> 00:35:28.186 A:middle
Now, because each image is three

00:35:28.186 --> 00:35:30.246 A:middle
channels, we need to concatenate

00:35:30.246 --> 00:35:31.136 A:middle
these into a single metal

00:35:31.136 --> 00:35:33.626 A:middle
texture array, and we can't

00:35:33.826 --> 00:35:35.436 A:middle
necessarily use the MPS cnn

00:35:35.516 --> 00:35:37.146 A:middle
concatenation because it

00:35:37.146 --> 00:35:38.166 A:middle
requires feature channels in a

00:35:38.166 --> 00:35:38.816 A:middle
multiple of four.

00:35:39.636 --> 00:35:40.756 A:middle
However, we can write a simple

00:35:40.756 --> 00:35:42.656 A:middle
kernel to do this for us.

00:35:43.646 --> 00:35:45.006 A:middle
So here's a simple metal compute

00:35:45.006 --> 00:35:46.076 A:middle
shader to concatenate these

00:35:46.076 --> 00:35:46.866 A:middle
images together.

00:35:46.866 --> 00:35:49.306 A:middle
We're going to start using a

00:35:49.306 --> 00:35:51.276 A:middle
grid of threads mapped to each

00:35:51.276 --> 00:35:52.686 A:middle
four-channel pixel the result.

00:35:52.686 --> 00:35:55.026 A:middle
Our arguments are going to be a

00:35:55.026 --> 00:35:56.276 A:middle
result to hold the concatenated

00:35:56.276 --> 00:35:58.616 A:middle
image, the RGB input, the albedo

00:35:58.616 --> 00:36:00.036 A:middle
input, and our normal image.

00:35:58.616 --> 00:36:00.036 A:middle
input, and our normal image.

00:36:00.586 --> 00:36:02.586 A:middle
So we're going to start having

00:36:02.586 --> 00:36:04.956 A:middle
each thread read a pixel from

00:36:04.956 --> 00:36:06.476 A:middle
each input at its location in

00:36:06.476 --> 00:36:07.166 A:middle
the grid.

00:36:08.056 --> 00:36:09.286 A:middle
We're going to concatenate those

00:36:09.286 --> 00:36:11.476 A:middle
values together, and we're going

00:36:11.476 --> 00:36:12.286 A:middle
to fill the remaining unused

00:36:12.286 --> 00:36:12.926 A:middle
channels with 0.

00:36:17.216 --> 00:36:18.126 A:middle
Finally, we're going to write

00:36:18.126 --> 00:36:19.896 A:middle
out the result at its same

00:36:19.896 --> 00:36:21.856 A:middle
location in the grid.

00:36:21.906 --> 00:36:23.676 A:middle
So now that we have a shader

00:36:23.676 --> 00:36:25.026 A:middle
which can concatenate these

00:36:25.026 --> 00:36:26.076 A:middle
values together into a single

00:36:26.076 --> 00:36:27.436 A:middle
MPS image, let's look at how we

00:36:27.436 --> 00:36:28.176 A:middle
hand it to the graph.

00:36:29.246 --> 00:36:30.236 A:middle
Or rather, let's look at how we

00:36:30.236 --> 00:36:31.086 A:middle
encode it first.

00:36:31.086 --> 00:36:33.536 A:middle
So here's an example of how we

00:36:33.536 --> 00:36:34.616 A:middle
encode our kernel and wrap the

00:36:34.616 --> 00:36:35.696 A:middle
result in an MPS image.

00:36:36.896 --> 00:36:37.856 A:middle
So our inputs are images

00:36:37.856 --> 00:36:40.326 A:middle
containing the data, and we're

00:36:40.496 --> 00:36:41.696 A:middle
going to want to use the result

00:36:41.696 --> 00:36:42.496 A:middle
as an input to the graph.

00:36:42.496 --> 00:36:43.656 A:middle
So, we need to construct an MPS

00:36:43.656 --> 00:36:44.006 A:middle
image.

00:36:44.346 --> 00:36:45.506 A:middle
We're going to use its texture

00:36:45.646 --> 00:36:46.696 A:middle
to hold the result of our

00:36:46.696 --> 00:36:47.446 A:middle
concatenation kernel.

00:36:47.926 --> 00:36:50.336 A:middle
Next, we're going to bind each

00:36:50.336 --> 00:36:51.496 A:middle
argument at its appropriate

00:36:51.496 --> 00:36:51.856 A:middle
location.

00:36:53.026 --> 00:36:54.976 A:middle
We'll dispatch our threads and

00:36:54.976 --> 00:36:56.416 A:middle
then finally return the image

00:36:56.626 --> 00:36:57.756 A:middle
ready to be passed into our

00:36:57.756 --> 00:36:58.086 A:middle
network.

00:36:58.706 --> 00:36:59.726 A:middle
So, now that our inputs are

00:36:59.726 --> 00:37:01.326 A:middle
prepared, let's look at

00:36:59.726 --> 00:37:01.326 A:middle
prepared, let's look at

00:37:01.326 --> 00:37:02.476 A:middle
executing the training graph.

00:37:02.526 --> 00:37:04.436 A:middle
Now during training, we'll be

00:37:04.436 --> 00:37:05.746 A:middle
executing the graph from many

00:37:05.746 --> 00:37:06.416 A:middle
iterations.

00:37:06.416 --> 00:37:07.936 A:middle
We're going to be executing

00:37:08.006 --> 00:37:09.526 A:middle
multiple batches within each

00:37:09.526 --> 00:37:11.016 A:middle
training set, and then we're

00:37:11.016 --> 00:37:12.166 A:middle
going to be executing multiple

00:37:12.166 --> 00:37:13.976 A:middle
batches over each epoch.

00:37:16.596 --> 00:37:18.886 A:middle
So, here we're going to run one

00:37:18.886 --> 00:37:19.986 A:middle
iteration of the training graph.

00:37:20.496 --> 00:37:21.376 A:middle
We're going to concatenate our

00:37:21.376 --> 00:37:22.956 A:middle
images together using the kernel

00:37:22.956 --> 00:37:24.266 A:middle
we just showed except for each

00:37:24.266 --> 00:37:24.976 A:middle
image in the batch.

00:37:27.076 --> 00:37:28.046 A:middle
We're going to put these

00:37:28.046 --> 00:37:29.746 A:middle
together into and array because

00:37:29.956 --> 00:37:31.726 A:middle
the graph requires an array of

00:37:31.726 --> 00:37:33.076 A:middle
images, one for the source

00:37:33.076 --> 00:37:34.376 A:middle
images and one for our labels.

00:37:34.926 --> 00:37:37.306 A:middle
Now we're going to use

00:37:37.306 --> 00:37:38.646 A:middle
MPSCommandBuffers here, because

00:37:38.646 --> 00:37:39.766 A:middle
as we saw earlier, it's an easy

00:37:39.766 --> 00:37:41.066 A:middle
way of getting improved GPU

00:37:41.066 --> 00:37:41.706 A:middle
utilization.

00:37:43.006 --> 00:37:43.946 A:middle
So finally, we're going to

00:37:43.946 --> 00:37:45.766 A:middle
encode the graph and then commit

00:37:45.766 --> 00:37:46.396 A:middle
it for execution.

00:37:47.006 --> 00:37:49.136 A:middle
So, now let's look closer at

00:37:49.136 --> 00:37:49.896 A:middle
each training epoch.

00:37:50.216 --> 00:37:51.526 A:middle
Now in this scheme, we're going

00:37:51.526 --> 00:37:52.626 A:middle
to process the full training

00:37:52.626 --> 00:37:54.156 A:middle
data set, each epoch, to allow

00:37:54.156 --> 00:37:55.106 A:middle
for better convergence.

00:37:55.796 --> 00:37:57.106 A:middle
We're also going to update the

00:37:57.106 --> 00:37:59.476 A:middle
training set every some number

00:37:59.476 --> 00:38:00.636 A:middle
of epochs, in this case every

00:37:59.476 --> 00:38:00.636 A:middle
of epochs, in this case every

00:38:00.636 --> 00:38:02.196 A:middle
100, and at that point, we're

00:38:02.196 --> 00:38:03.296 A:middle
also going to perform our

00:38:03.296 --> 00:38:04.156 A:middle
network validation.

00:38:04.976 --> 00:38:06.356 A:middle
Finally, at every thousandth

00:38:06.356 --> 00:38:07.126 A:middle
epoch, we're going to decrease

00:38:07.126 --> 00:38:07.796 A:middle
the learning rate of our

00:38:07.796 --> 00:38:08.386 A:middle
optimizer.

00:38:08.526 --> 00:38:10.006 A:middle
This will also help improve

00:38:10.006 --> 00:38:10.606 A:middle
convergence.

00:38:10.656 --> 00:38:12.046 A:middle
So let's look at the code for

00:38:12.046 --> 00:38:12.346 A:middle
this.

00:38:12.386 --> 00:38:13.116 A:middle
So, we're going to begin by

00:38:13.116 --> 00:38:14.496 A:middle
processing the entire training

00:38:14.496 --> 00:38:15.856 A:middle
set once each epoch.

00:38:15.856 --> 00:38:18.546 A:middle
Here we see every hundredth

00:38:18.546 --> 00:38:18.736 A:middle
epoch.

00:38:18.736 --> 00:38:19.876 A:middle
We're going to update our

00:38:19.876 --> 00:38:21.026 A:middle
training data set, and we're

00:38:21.026 --> 00:38:22.136 A:middle
going to run the validation.

00:38:23.416 --> 00:38:24.676 A:middle
And finally, every thousandth

00:38:24.676 --> 00:38:25.786 A:middle
epoch, we'll decay our learning

00:38:25.786 --> 00:38:28.936 A:middle
rate by a factor of 2.

00:38:29.166 --> 00:38:30.146 A:middle
So, now that we've trained the

00:38:30.146 --> 00:38:31.846 A:middle
graph, we can begin denoising

00:38:31.846 --> 00:38:32.466 A:middle
new images.

00:38:33.016 --> 00:38:34.596 A:middle
Now, because MPS is available

00:38:34.596 --> 00:38:36.006 A:middle
and optimized across multiple

00:38:36.006 --> 00:38:38.276 A:middle
platforms, we can easily deploy

00:38:38.276 --> 00:38:39.166 A:middle
the training network on a

00:38:39.166 --> 00:38:39.906 A:middle
different device.

00:38:40.106 --> 00:38:41.916 A:middle
For example, you may want to

00:38:41.916 --> 00:38:43.366 A:middle
execute the computationally

00:38:43.366 --> 00:38:44.816 A:middle
expensive task of training on a

00:38:44.816 --> 00:38:46.636 A:middle
Mac and then use the train

00:38:46.636 --> 00:38:48.276 A:middle
network to filter images on an

00:38:49.096 --> 00:38:49.236 A:middle
iPad.

00:38:49.776 --> 00:38:51.086 A:middle
So, first, let's take a look at

00:38:51.086 --> 00:38:52.546 A:middle
serialization support in MPS.

00:38:52.546 --> 00:38:55.356 A:middle
Now all MPS kernels as well as

00:38:55.356 --> 00:38:56.276 A:middle
the graph support a secure

00:38:56.276 --> 00:38:56.616 A:middle
coding.

00:38:57.116 --> 00:38:58.386 A:middle
This allows you to easily save

00:38:58.386 --> 00:38:59.526 A:middle
and restore your networks to and

00:38:59.526 --> 00:38:59.996 A:middle
from disk.

00:39:01.166 --> 00:39:02.306 A:middle
And for networks which load

00:39:02.306 --> 00:39:03.036 A:middle
their weights from a data

00:39:03.036 --> 00:39:04.286 A:middle
source, you're going to have to

00:39:04.286 --> 00:39:05.646 A:middle
implement secure coding support

00:39:05.976 --> 00:39:06.976 A:middle
on your data source yourself.

00:39:07.806 --> 00:39:09.946 A:middle
Now this requires the support

00:39:09.946 --> 00:39:11.016 A:middle
secure coding property and the

00:39:11.136 --> 00:39:12.586 A:middle
init and encode with coder

00:39:12.586 --> 00:39:13.016 A:middle
methods.

00:39:13.166 --> 00:39:14.506 A:middle
Now, once your data source

00:39:14.506 --> 00:39:16.246 A:middle
conforms to secure coding, it's

00:39:16.246 --> 00:39:18.326 A:middle
easy to serialize and save the

00:39:18.326 --> 00:39:18.716 A:middle
graph.

00:39:19.276 --> 00:39:20.576 A:middle
So, first we're going to create

00:39:20.576 --> 00:39:21.696 A:middle
a coder in which to encode the

00:39:21.696 --> 00:39:22.086 A:middle
graph.

00:39:22.816 --> 00:39:23.776 A:middle
Then we're going to call encode

00:39:23.776 --> 00:39:24.606 A:middle
with coder on the graph.

00:39:24.606 --> 00:39:25.886 A:middle
Now, when this happens, it's

00:39:25.886 --> 00:39:27.116 A:middle
going to serialize each of the

00:39:27.116 --> 00:39:28.376 A:middle
individual kernels, and if those

00:39:28.376 --> 00:39:30.196 A:middle
kernels have data sources, it

00:39:30.196 --> 00:39:31.406 A:middle
will serialize those as well.

00:39:31.716 --> 00:39:33.676 A:middle
That way, the resulting archive

00:39:33.676 --> 00:39:34.786 A:middle
contains all of the information

00:39:34.786 --> 00:39:36.166 A:middle
necessary to restore and

00:39:36.166 --> 00:39:36.996 A:middle
initialize the graph.

00:39:38.156 --> 00:39:40.306 A:middle
Finally, we can save the data to

00:39:40.306 --> 00:39:40.666 A:middle
a file.

00:39:41.266 --> 00:39:43.966 A:middle
Now let's look at loading it.

00:39:44.746 --> 00:39:45.896 A:middle
So, in order to ensure at the

00:39:45.896 --> 00:39:47.436 A:middle
unarchived kernels initialize on

00:39:47.436 --> 00:39:49.266 A:middle
the proper metal device, we

00:39:49.266 --> 00:39:50.146 A:middle
provide you with the

00:39:50.146 --> 00:39:51.076 A:middle
MPSKeyedUnarchiver.

00:39:51.726 --> 00:39:52.926 A:middle
It's like a regular unarchiver

00:39:52.926 --> 00:39:54.206 A:middle
except you initialize it with a

00:39:54.206 --> 00:39:55.606 A:middle
metal device, and then it will

00:39:55.606 --> 00:39:56.936 A:middle
provide this device to all the

00:39:56.936 --> 00:39:58.086 A:middle
kernels as they're initialized.

00:39:58.536 --> 00:39:59.796 A:middle
So, after we load our data,

00:39:59.796 --> 00:40:01.286 A:middle
we'll create an unarchiver with

00:39:59.796 --> 00:40:01.286 A:middle
we'll create an unarchiver with

00:40:01.286 --> 00:40:01.896 A:middle
the device.

00:40:02.386 --> 00:40:03.336 A:middle
We'll restore the graph on the

00:40:03.336 --> 00:40:05.116 A:middle
new device, and with the train

00:40:05.116 --> 00:40:06.736 A:middle
network now initialized, the

00:40:06.736 --> 00:40:08.136 A:middle
graph is ready to be used to

00:40:08.136 --> 00:40:09.296 A:middle
denoise new images.

00:40:09.626 --> 00:40:10.536 A:middle
So, let's take a look at this

00:40:10.536 --> 00:40:11.386 A:middle
network in action.

00:40:11.986 --> 00:40:15.086 A:middle
So, here we applied our denoiser

00:40:15.166 --> 00:40:15.676 A:middle
to a scene.

00:40:16.506 --> 00:40:17.626 A:middle
The top region shows how the

00:40:17.626 --> 00:40:19.236 A:middle
scene looks in our input noisy

00:40:19.236 --> 00:40:19.566 A:middle
image.

00:40:20.066 --> 00:40:21.006 A:middle
The center region shows the

00:40:21.006 --> 00:40:23.486 A:middle
result of our denoiser, and you

00:40:23.486 --> 00:40:24.536 A:middle
can see the bottom region shows

00:40:24.536 --> 00:40:25.546 A:middle
the ground truth clean image.

00:40:26.236 --> 00:40:27.686 A:middle
As you can see, the denoised

00:40:27.686 --> 00:40:29.056 A:middle
region looks nearly as good as

00:40:29.056 --> 00:40:30.956 A:middle
the clean target, except we're

00:40:30.956 --> 00:40:31.846 A:middle
achieving this with

00:40:31.976 --> 00:40:33.086 A:middle
significantly less work because

00:40:33.086 --> 00:40:34.016 A:middle
were not running the full ray

00:40:34.016 --> 00:40:34.356 A:middle
tracer.

00:40:34.946 --> 00:40:37.846 A:middle
So as you saw, using MPS, we can

00:40:37.916 --> 00:40:39.156 A:middle
easily implement complex

00:40:39.156 --> 00:40:40.386 A:middle
networks like denoising and

00:40:40.386 --> 00:40:41.066 A:middle
style transfer.

00:40:42.506 --> 00:40:44.206 A:middle
This year we've expanded support

00:40:44.716 --> 00:40:46.086 A:middle
for inference and training to a

00:40:46.086 --> 00:40:47.086 A:middle
new class of networks with

00:40:47.086 --> 00:40:49.146 A:middle
features like separable loss and

00:40:49.146 --> 00:40:50.136 A:middle
random number generation.

00:40:50.706 --> 00:40:52.856 A:middle
And with MPSCommandBuffering, we

00:40:52.856 --> 00:40:54.136 A:middle
now support improved performance

00:40:54.136 --> 00:40:55.696 A:middle
and better utilization through

00:40:55.696 --> 00:40:57.036 A:middle
things like predication and

00:40:57.036 --> 00:40:59.036 A:middle
commitAndContinue, and we made

00:40:59.036 --> 00:41:00.426 A:middle
all of these features easier to

00:40:59.036 --> 00:41:00.426 A:middle
all of these features easier to

00:41:00.426 --> 00:41:01.576 A:middle
use through implicit graph

00:41:01.576 --> 00:41:01.996 A:middle
creation.

00:41:02.566 --> 00:41:04.946 A:middle
So, for more information about

00:41:04.946 --> 00:41:06.556 A:middle
MPS and metal, please see the

00:41:06.556 --> 00:41:07.796 A:middle
online documentation and our

00:41:07.796 --> 00:41:09.326 A:middle
sample code, and for more

00:41:09.526 --> 00:41:10.706 A:middle
information about MPS and ray

00:41:10.706 --> 00:41:12.496 A:middle
tracing, please see the Metal

00:41:12.496 --> 00:41:13.626 A:middle
for Ray Tracing session earlier.

00:41:14.486 --> 00:41:14.976 A:middle
Thank you.

00:41:15.516 --> 00:41:20.500 A:middle
[ Applause ]
