WEBVTT

00:00:00.506 --> 00:00:05.500 A:middle
[ Music ]

00:00:10.976 --> 00:00:12.336 A:middle
[ Applause ]

00:00:12.336 --> 00:00:12.786 A:middle
&gt;&gt; Good morning.

00:00:14.756 --> 00:00:15.836 A:middle
Welcome to our session on

00:00:15.836 --> 00:00:17.266 A:middle
Drawing Classification and

00:00:17.266 --> 00:00:18.686 A:middle
One-Shot Object Detection in

00:00:18.686 --> 00:00:19.276 A:middle
Turi Create.

00:00:19.956 --> 00:00:21.416 A:middle
My name is Sam and I'll be

00:00:21.416 --> 00:00:22.406 A:middle
joined by my colleagues,

00:00:22.536 --> 00:00:24.306 A:middle
Shantanu and Abhishek to talk to

00:00:24.306 --> 00:00:25.166 A:middle
you about what we've been

00:00:25.166 --> 00:00:27.036 A:middle
building to enable even richer

00:00:27.036 --> 00:00:29.836 A:middle
experiences in your apps.

00:00:29.986 --> 00:00:30.746 A:middle
Let's dive right in.

00:00:32.206 --> 00:00:34.746 A:middle
First, a quick refresher on Turi

00:00:34.746 --> 00:00:35.546 A:middle
Create itself.

00:00:36.646 --> 00:00:38.656 A:middle
Turi Create is a Python library

00:00:38.986 --> 00:00:40.316 A:middle
used for creating Core ML

00:00:40.316 --> 00:00:40.846 A:middle
models.

00:00:41.406 --> 00:00:44.286 A:middle
It has a simple, easy to use

00:00:44.476 --> 00:00:45.826 A:middle
task-oriented API.

00:00:46.966 --> 00:00:49.136 A:middle
Now, tasks are our term for a

00:00:49.136 --> 00:00:50.756 A:middle
collection of complex, machine

00:00:50.756 --> 00:00:52.606 A:middle
learning algorithms abstracted

00:00:52.606 --> 00:00:55.056 A:middle
away into a simple, easy to use

00:00:55.056 --> 00:00:56.586 A:middle
solution for you to build your

00:00:56.586 --> 00:00:57.066 A:middle
models.

00:00:57.616 --> 00:01:00.326 A:middle
It's cross-platform, working on

00:00:57.616 --> 00:01:00.326 A:middle
It's cross-platform, working on

00:01:00.326 --> 00:01:02.966 A:middle
both Mac OS and Linux and we're

00:01:02.966 --> 00:01:04.296 A:middle
extremely proud to be open

00:01:04.355 --> 00:01:05.936 A:middle
source, working closely with our

00:01:05.936 --> 00:01:08.286 A:middle
community on features and fixes.

00:01:08.896 --> 00:01:12.246 A:middle
We built Turi Create to enable

00:01:12.246 --> 00:01:14.596 A:middle
you to create Core ML models for

00:01:14.596 --> 00:01:16.416 A:middle
your intelligent applications.

00:01:17.646 --> 00:01:19.946 A:middle
Now to build these models, we

00:01:19.946 --> 00:01:21.286 A:middle
integrate with a various of

00:01:21.286 --> 00:01:22.956 A:middle
system frameworks, accepting

00:01:22.956 --> 00:01:25.276 A:middle
data from frameworks like

00:01:25.366 --> 00:01:26.976 A:middle
PencilKit and Core Motion.

00:01:28.496 --> 00:01:30.476 A:middle
Once we've built our model, we

00:01:30.476 --> 00:01:31.756 A:middle
integrate with other system

00:01:31.756 --> 00:01:34.676 A:middle
frameworks like Vision and Sound

00:01:34.676 --> 00:01:36.526 A:middle
Analysis to create extremely

00:01:36.526 --> 00:01:38.196 A:middle
compelling app experiences.

00:01:39.956 --> 00:01:41.696 A:middle
So say you'd want to build an

00:01:41.696 --> 00:01:43.776 A:middle
application used to classify

00:01:43.976 --> 00:01:44.916 A:middle
musical instruments.

00:01:45.066 --> 00:01:47.066 A:middle
[ Guitar Sound ]

00:01:47.156 --> 00:01:49.156 A:middle
Using microphone data, you can

00:01:49.156 --> 00:01:50.576 A:middle
understand what instrument is

00:01:50.676 --> 00:01:53.476 A:middle
being played and attempt to tune

00:01:54.096 --> 00:01:55.176 A:middle
the instrument.

00:01:55.176 --> 00:01:57.036 A:middle
Or say you'd want to use raw

00:01:57.066 --> 00:01:58.876 A:middle
sensor data from the Apple Watch

00:01:59.276 --> 00:02:01.096 A:middle
to detect what activities a user

00:01:59.276 --> 00:02:01.096 A:middle
to detect what activities a user

00:02:01.096 --> 00:02:04.966 A:middle
may be performing in the gym.

00:02:05.166 --> 00:02:07.466 A:middle
Or say you'd want to use image

00:02:07.466 --> 00:02:09.996 A:middle
data to be able to detect what

00:02:09.996 --> 00:02:12.006 A:middle
ingredients a user may be

00:02:12.006 --> 00:02:13.996 A:middle
holding and to suggest recipes

00:02:14.326 --> 00:02:15.636 A:middle
using these ingredients.

00:02:16.096 --> 00:02:18.476 A:middle
All of these are possible

00:02:18.916 --> 00:02:20.256 A:middle
because we have built an

00:02:20.256 --> 00:02:22.126 A:middle
intelligent Core ML model.

00:02:23.196 --> 00:02:25.396 A:middle
And to build these models, we've

00:02:25.396 --> 00:02:27.476 A:middle
identified a five-step pipeline

00:02:27.616 --> 00:02:28.116 A:middle
to do so.

00:02:29.276 --> 00:02:31.246 A:middle
First up in our pipeline, we

00:02:31.246 --> 00:02:32.946 A:middle
need to identify the task or

00:02:32.946 --> 00:02:34.166 A:middle
what problem it is that we're

00:02:34.166 --> 00:02:34.926 A:middle
trying to solve.

00:02:35.476 --> 00:02:38.746 A:middle
Next, we need to collect data

00:02:38.746 --> 00:02:41.246 A:middle
and sometimes, lots of it.

00:02:42.136 --> 00:02:44.506 A:middle
After that, we train our model.

00:02:46.316 --> 00:02:48.656 A:middle
Next, we evaluate our model,

00:02:49.036 --> 00:02:50.386 A:middle
attempting to understand the

00:02:50.436 --> 00:02:51.516 A:middle
real-world performance

00:02:51.516 --> 00:02:52.776 A:middle
characteristics and to

00:02:52.776 --> 00:02:54.356 A:middle
potentially offer corrections.

00:02:56.726 --> 00:02:58.866 A:middle
After that, we deploy our model

00:02:59.116 --> 00:03:01.376 A:middle
for use within Core ML and your

00:02:59.116 --> 00:03:01.376 A:middle
for use within Core ML and your

00:03:01.376 --> 00:03:01.976 A:middle
application.

00:03:03.436 --> 00:03:04.806 A:middle
Now let's take a look at these

00:03:04.806 --> 00:03:06.966 A:middle
five steps in code.

00:03:07.816 --> 00:03:11.606 A:middle
After we import turicreate we

00:03:11.606 --> 00:03:14.006 A:middle
load our data from an SFrame on

00:03:14.966 --> 00:03:15.126 A:middle
disk.

00:03:15.126 --> 00:03:16.366 A:middle
An SFrame is something that

00:03:16.366 --> 00:03:17.986 A:middle
Shantanu will cover in a little

00:03:18.646 --> 00:03:18.746 A:middle
bit.

00:03:19.816 --> 00:03:23.036 A:middle
After this, we split our data

00:03:23.036 --> 00:03:25.036 A:middle
into two sets, one used for

00:03:25.036 --> 00:03:26.476 A:middle
testing and one used for

00:03:26.476 --> 00:03:27.426 A:middle
training our model.

00:03:28.966 --> 00:03:31.606 A:middle
Next, we create our model with

00:03:31.606 --> 00:03:33.486 A:middle
just a single line of code for

00:03:33.486 --> 00:03:34.866 A:middle
running complicated machine

00:03:34.866 --> 00:03:35.756 A:middle
learning algorithms.

00:03:38.536 --> 00:03:40.686 A:middle
Next, we gather metrics as to

00:03:40.686 --> 00:03:42.206 A:middle
the performance of this model.

00:03:42.246 --> 00:03:46.536 A:middle
And finally, we save it to disk

00:03:46.636 --> 00:03:49.336 A:middle
for use within XCode and your

00:03:49.646 --> 00:03:50.286 A:middle
app.

00:03:51.366 --> 00:03:53.366 A:middle
Now we think one of the great

00:03:53.366 --> 00:03:55.056 A:middle
things about Turi Create is its

00:03:55.056 --> 00:03:56.716 A:middle
simple and consistent API.

00:03:57.726 --> 00:03:58.536 A:middle
So no matter whether you're

00:03:58.536 --> 00:04:01.446 A:middle
using an object detector, a

00:03:58.536 --> 00:04:01.446 A:middle
using an object detector, a

00:04:01.446 --> 00:04:04.146 A:middle
sound classifier, an activity

00:04:04.146 --> 00:04:06.096 A:middle
classifier, or any of our other

00:04:06.096 --> 00:04:08.006 A:middle
tasks, the API remains

00:04:08.036 --> 00:04:11.516 A:middle
consistent and easy to use.

00:04:11.716 --> 00:04:13.246 A:middle
Now I've mentioned these tasks

00:04:13.296 --> 00:04:15.066 A:middle
multiple times and I'd like to

00:04:15.116 --> 00:04:16.375 A:middle
cover the full collection that

00:04:16.375 --> 00:04:17.456 A:middle
Turi Create offers.

00:04:17.606 --> 00:04:21.076 A:middle
We offer tasks that work with

00:04:21.185 --> 00:04:25.646 A:middle
images and sound as well as user

00:04:25.646 --> 00:04:29.636 A:middle
activities and text.

00:04:29.796 --> 00:04:31.266 A:middle
We offer tasks that work with

00:04:31.316 --> 00:04:33.746 A:middle
user preferences and numeric

00:04:33.746 --> 00:04:33.976 A:middle
data.

00:04:34.506 --> 00:04:37.276 A:middle
And today we're extremely

00:04:37.276 --> 00:04:39.106 A:middle
excited to share with you two

00:04:39.106 --> 00:04:42.306 A:middle
brand new tasks.

00:04:42.306 --> 00:04:44.446 A:middle
First, we have our One-Shot

00:04:44.566 --> 00:04:45.786 A:middle
Object Detection task.

00:04:46.356 --> 00:04:48.206 A:middle
Now you may already be familiar

00:04:48.206 --> 00:04:49.266 A:middle
with object detection.

00:04:50.626 --> 00:04:52.086 A:middle
Object detection is the ability

00:04:52.086 --> 00:04:54.076 A:middle
to detect the presence and

00:04:54.076 --> 00:04:56.156 A:middle
location of specific objects

00:04:56.206 --> 00:04:56.886 A:middle
within a frame.

00:04:58.176 --> 00:05:00.056 A:middle
One-Shot Object Detection is a

00:04:58.176 --> 00:05:00.056 A:middle
One-Shot Object Detection is a

00:05:00.056 --> 00:05:01.226 A:middle
twist on this existing

00:05:01.226 --> 00:05:03.366 A:middle
framework, which depending on

00:05:03.366 --> 00:05:04.806 A:middle
the type of data that you're

00:05:04.806 --> 00:05:06.526 A:middle
attempting to detect, can

00:05:06.526 --> 00:05:07.866 A:middle
dramatically reduce the amount

00:05:07.866 --> 00:05:09.776 A:middle
of data needed to train a model.

00:05:12.186 --> 00:05:13.516 A:middle
Next, we have our Drawing

00:05:13.516 --> 00:05:14.616 A:middle
Classification task.

00:05:15.656 --> 00:05:18.056 A:middle
Using user input in the form of

00:05:18.056 --> 00:05:20.816 A:middle
a finger on screen or the Apple

00:05:20.816 --> 00:05:23.616 A:middle
Pencil, you can now attempt to

00:05:23.616 --> 00:05:25.636 A:middle
classify and understand what

00:05:25.636 --> 00:05:27.496 A:middle
your users have drawn into your

00:05:27.706 --> 00:05:28.446 A:middle
app.

00:05:29.016 --> 00:05:31.436 A:middle
Now I'd like to take a deep dive

00:05:31.576 --> 00:05:32.816 A:middle
into the One-Shot Object

00:05:32.816 --> 00:05:34.426 A:middle
Detection task.

00:05:35.036 --> 00:05:36.296 A:middle
Say you'd want to build an

00:05:36.296 --> 00:05:38.936 A:middle
application to take an image of

00:05:38.936 --> 00:05:40.316 A:middle
a player's hand in a game of

00:05:40.356 --> 00:05:42.446 A:middle
poker and to offer probabilities

00:05:42.486 --> 00:05:43.566 A:middle
that this hand would occur.

00:05:45.246 --> 00:05:46.976 A:middle
Or say you'd want to build an

00:05:46.976 --> 00:05:49.046 A:middle
application to take a picture of

00:05:49.046 --> 00:05:50.386 A:middle
your car's dashboard and to

00:05:50.386 --> 00:05:52.156 A:middle
attempt to understand what those

00:05:52.156 --> 00:05:53.566 A:middle
obscure icons may mean.

00:05:54.176 --> 00:05:56.796 A:middle
Or say you'd want to build an

00:05:56.796 --> 00:05:58.946 A:middle
app to detect company logos to

00:05:58.946 --> 00:06:00.426 A:middle
provide your users with more

00:05:58.946 --> 00:06:00.426 A:middle
provide your users with more

00:06:00.426 --> 00:06:02.396 A:middle
information about this company.

00:06:03.516 --> 00:06:04.686 A:middle
What do all three of these

00:06:04.686 --> 00:06:06.146 A:middle
applications have in common?

00:06:07.106 --> 00:06:09.606 A:middle
They're all trying to detect 2D

00:06:09.976 --> 00:06:11.186 A:middle
regular images.

00:06:12.616 --> 00:06:14.356 A:middle
One-Shot Object Detection is

00:06:14.356 --> 00:06:15.776 A:middle
able to take advantage of these

00:06:15.776 --> 00:06:17.606 A:middle
characteristics of regularity

00:06:17.606 --> 00:06:19.666 A:middle
and consistency to dramatically

00:06:19.666 --> 00:06:21.536 A:middle
reduce the amount of data needed

00:06:21.536 --> 00:06:22.706 A:middle
to build an accurate model.

00:06:23.916 --> 00:06:25.586 A:middle
So let's use this card counting

00:06:25.586 --> 00:06:27.076 A:middle
app, which Shantanu will build

00:06:27.076 --> 00:06:28.886 A:middle
for us in just a minute, as a

00:06:28.886 --> 00:06:30.766 A:middle
case study into how this works.

00:06:32.626 --> 00:06:34.856 A:middle
Originally in order to build an

00:06:34.856 --> 00:06:36.736 A:middle
object detection model, you

00:06:36.736 --> 00:06:38.226 A:middle
would need to collect vast

00:06:38.226 --> 00:06:39.986 A:middle
amounts of data of your object

00:06:40.036 --> 00:06:40.846 A:middle
in the real world.

00:06:41.456 --> 00:06:44.566 A:middle
In addition to this, you would

00:06:44.566 --> 00:06:46.246 A:middle
also need to annotate each of

00:06:46.246 --> 00:06:48.066 A:middle
these images with the location

00:06:48.066 --> 00:06:50.586 A:middle
in the frame of your image.

00:06:51.136 --> 00:06:53.646 A:middle
As you can see, this is an

00:06:53.646 --> 00:06:55.556 A:middle
incredibly data intensive and

00:06:55.556 --> 00:06:58.636 A:middle
time-consuming task.

00:06:58.636 --> 00:07:00.916 A:middle
So we built a better way.

00:06:58.636 --> 00:07:00.916 A:middle
So we built a better way.

00:07:02.416 --> 00:07:04.096 A:middle
With One-Shot Object Detection,

00:07:04.366 --> 00:07:06.096 A:middle
you now need as little as one

00:07:06.096 --> 00:07:07.966 A:middle
image per class that you're

00:07:07.966 --> 00:07:08.896 A:middle
attempting to detect.

00:07:09.806 --> 00:07:11.606 A:middle
So instead of dozens of images

00:07:11.966 --> 00:07:14.046 A:middle
of the Ace of Clubs, you now

00:07:14.046 --> 00:07:16.036 A:middle
need a single image in order to

00:07:16.036 --> 00:07:17.686 A:middle
build a reliable and accurate

00:07:17.686 --> 00:07:17.976 A:middle
model.

00:07:18.196 --> 00:07:20.196 A:middle
[ Applause ]

00:07:20.376 --> 00:07:20.636 A:middle
Thank you.

00:07:21.466 --> 00:07:23.466 A:middle
[ Applause ]

00:07:23.916 --> 00:07:24.926 A:middle
So let's talk about how this

00:07:24.926 --> 00:07:26.066 A:middle
works behind the scenes.

00:07:26.966 --> 00:07:28.486 A:middle
This works with a process called

00:07:28.486 --> 00:07:30.356 A:middle
Synthetic Data Augmentation.

00:07:31.356 --> 00:07:32.566 A:middle
Turi Create ships with a

00:07:32.606 --> 00:07:34.606 A:middle
collection of images of the real

00:07:34.606 --> 00:07:34.976 A:middle
world.

00:07:35.906 --> 00:07:37.806 A:middle
We then take your source image

00:07:37.876 --> 00:07:39.566 A:middle
that you have supplied and

00:07:39.566 --> 00:07:41.616 A:middle
overlay onto these real-world

00:07:41.616 --> 00:07:43.676 A:middle
images along with various color

00:07:43.676 --> 00:07:45.876 A:middle
perturbations and distortions to

00:07:45.916 --> 00:07:47.736 A:middle
simulate real world effects.

00:07:49.186 --> 00:07:50.686 A:middle
In addition to this, there's

00:07:50.686 --> 00:07:52.846 A:middle
absolutely no need to annotate

00:07:53.046 --> 00:07:54.916 A:middle
these images as our algorithms

00:07:54.916 --> 00:07:56.456 A:middle
do that for you automatically.

00:07:58.936 --> 00:08:01.276 A:middle
Now One-Shot Object Detection

00:07:58.936 --> 00:08:01.276 A:middle
Now One-Shot Object Detection

00:08:01.516 --> 00:08:03.256 A:middle
works with 2D objects only.

00:08:04.076 --> 00:08:06.306 A:middle
It requires very little data and

00:08:06.306 --> 00:08:08.026 A:middle
absolutely no annotation.

00:08:08.846 --> 00:08:10.276 A:middle
However, if you're wanting to

00:08:10.276 --> 00:08:12.316 A:middle
detect an object that is

00:08:12.316 --> 00:08:14.036 A:middle
potentially 3D or more

00:08:14.036 --> 00:08:15.876 A:middle
irregular, you may be interested

00:08:15.876 --> 00:08:17.266 A:middle
in our more traditional object

00:08:17.356 --> 00:08:18.176 A:middle
detection framework.

00:08:18.686 --> 00:08:21.646 A:middle
Now let's take a look at this in

00:08:21.646 --> 00:08:21.986 A:middle
code.

00:08:22.886 --> 00:08:24.916 A:middle
As you'd expect, our API is

00:08:24.916 --> 00:08:26.776 A:middle
incredibly consistent with our

00:08:26.776 --> 00:08:29.286 A:middle
other tasks using just a single

00:08:29.286 --> 00:08:31.286 A:middle
line of code with our dot create

00:08:31.286 --> 00:08:33.346 A:middle
method to train an incredibly

00:08:33.346 --> 00:08:34.066 A:middle
accurate model.

00:08:34.066 --> 00:08:37.326 A:middle
And now with code up on the

00:08:37.366 --> 00:08:38.866 A:middle
screen, I'd like to invite my

00:08:38.866 --> 00:08:40.576 A:middle
colleague, Shantanu to talk to

00:08:40.576 --> 00:08:42.296 A:middle
you about our Three Card Poker

00:08:42.296 --> 00:08:43.166 A:middle
App and to give you a

00:08:43.166 --> 00:08:44.566 A:middle
demonstration of this in the

00:08:44.566 --> 00:08:45.086 A:middle
real world.

00:08:45.166 --> 00:08:45.976 A:middle
Shantanu.

00:08:46.516 --> 00:08:51.646 A:middle
[ Applause ]

00:08:52.146 --> 00:08:52.746 A:middle
&gt;&gt; Thanks Sam.

00:08:53.646 --> 00:08:54.606 A:middle
Good morning everyone.

00:08:54.736 --> 00:08:58.276 A:middle
Welcome to the last day of WWDC.

00:08:58.436 --> 00:09:02.336 A:middle
Now I'm super excited to give

00:08:58.436 --> 00:09:02.336 A:middle
Now I'm super excited to give

00:09:02.336 --> 00:09:03.466 A:middle
you a first look into the

00:09:03.466 --> 00:09:04.836 A:middle
One-Shot Object Detector.

00:09:05.966 --> 00:09:08.616 A:middle
The thing is, Sam and I play a

00:09:08.616 --> 00:09:10.206 A:middle
lot of three card poker at work.

00:09:11.106 --> 00:09:12.706 A:middle
And to be honest, I'm getting a

00:09:12.706 --> 00:09:14.096 A:middle
little too tired of winning all

00:09:14.096 --> 00:09:14.526 A:middle
the time.

00:09:15.126 --> 00:09:17.276 A:middle
So I thought, you know today on

00:09:17.276 --> 00:09:18.796 A:middle
stage, why don't we build an app

00:09:19.046 --> 00:09:21.486 A:middle
for Sam that helps him, that

00:09:21.486 --> 00:09:23.916 A:middle
tells him what his hand is, and

00:09:23.916 --> 00:09:24.736 A:middle
you know, helps him make a

00:09:24.736 --> 00:09:25.446 A:middle
better decision.

00:09:26.356 --> 00:09:28.326 A:middle
Now to build an app like that,

00:09:28.326 --> 00:09:30.126 A:middle
we'd need a Core ML model that

00:09:30.126 --> 00:09:32.136 A:middle
can detect all the cards in your

00:09:32.136 --> 00:09:32.696 A:middle
playing deck.

00:09:33.536 --> 00:09:35.076 A:middle
So why don't we just go ahead

00:09:35.076 --> 00:09:36.006 A:middle
and write some code to build

00:09:36.006 --> 00:09:36.786 A:middle
that?

00:09:37.406 --> 00:09:39.866 A:middle
Okay, so here I have a blank

00:09:39.866 --> 00:09:41.146 A:middle
Jupyter Notebook which is an

00:09:41.146 --> 00:09:42.756 A:middle
interactive Python environment

00:09:42.756 --> 00:09:44.286 A:middle
to write some code and

00:09:44.286 --> 00:09:45.966 A:middle
immediately see the output of

00:09:45.966 --> 00:09:47.786 A:middle
your code after that.

00:09:47.786 --> 00:09:49.166 A:middle
And we're going to use that to

00:09:49.166 --> 00:09:49.986 A:middle
write some code today.

00:09:50.866 --> 00:09:52.376 A:middle
Now the first line of code that

00:09:52.376 --> 00:09:54.096 A:middle
we write, and this is our

00:09:54.096 --> 00:09:55.926 A:middle
favorite line of code, it's

00:09:56.156 --> 00:09:59.586 A:middle
import turicreate as tc.

00:10:00.046 --> 00:10:01.206 A:middle
And I need to select the cell

00:10:01.206 --> 00:10:04.506 A:middle
before I write that.

00:10:04.506 --> 00:10:06.706 A:middle
And this will be your favorite

00:10:06.706 --> 00:10:09.236 A:middle
line too after this session.

00:10:09.236 --> 00:10:10.506 A:middle
Next, I'm going to switch to

00:10:10.616 --> 00:10:12.606 A:middle
Finder to take a look at all our

00:10:12.876 --> 00:10:15.846 A:middle
starter images and it looks like

00:10:15.846 --> 00:10:17.376 A:middle
we have a bunch of cards here

00:10:17.376 --> 00:10:19.026 A:middle
where the playing card spans the

00:10:19.026 --> 00:10:20.316 A:middle
entire frame of the image.

00:10:20.316 --> 00:10:22.226 A:middle
We have an Ace of Clubs, an Ace

00:10:22.226 --> 00:10:24.936 A:middle
of Diamonds, Ace of Hearts, Five

00:10:24.936 --> 00:10:27.386 A:middle
of Hearts, and we have a lot of

00:10:27.386 --> 00:10:27.916 A:middle
images here.

00:10:29.026 --> 00:10:30.916 A:middle
So why don't we go ahead and

00:10:30.916 --> 00:10:32.466 A:middle
load this up into an SFrame?

00:10:33.446 --> 00:10:35.506 A:middle
An SFrame is Turi Create's

00:10:35.706 --> 00:10:37.276 A:middle
scalable data structure.

00:10:37.276 --> 00:10:38.706 A:middle
It's [Inaudible] and it's to

00:10:38.806 --> 00:10:40.286 A:middle
represent all the data that you

00:10:40.286 --> 00:10:40.476 A:middle
have.

00:10:41.616 --> 00:10:42.766 A:middle
So we're going to create a

00:10:42.766 --> 00:10:44.486 A:middle
variable called starter images

00:10:44.806 --> 00:10:46.056 A:middle
and Turi Create has this

00:10:46.056 --> 00:10:47.646 A:middle
functionality to load images,

00:10:48.036 --> 00:10:49.846 A:middle
where you just pass in the --

00:10:50.096 --> 00:10:51.786 A:middle
directly that contains all your

00:10:51.786 --> 00:10:53.416 A:middle
images and it builds an SFrame

00:10:53.416 --> 00:10:54.466 A:middle
out of that on its own.

00:10:54.876 --> 00:10:57.556 A:middle
Now let's take a look at what

00:10:57.556 --> 00:10:59.066 A:middle
the starter image SFrame looks

00:10:59.066 --> 00:10:59.286 A:middle
like.

00:11:00.376 --> 00:11:01.716 A:middle
Alright, so there are two

00:11:01.716 --> 00:11:02.886 A:middle
columns in this SFrame.

00:11:02.886 --> 00:11:04.336 A:middle
There's a path column and an

00:11:04.336 --> 00:11:05.026 A:middle
image column.

00:11:05.026 --> 00:11:07.386 A:middle
The path column contains the

00:11:07.386 --> 00:11:08.876 A:middle
relative path to the image that

00:11:08.876 --> 00:11:09.986 A:middle
is in the image column.

00:11:10.986 --> 00:11:12.406 A:middle
Looks good but the path column

00:11:12.406 --> 00:11:13.906 A:middle
has this redundant .

00:11:14.616 --> 00:11:15.696 A:middle
/ and .png.

00:11:16.016 --> 00:11:18.126 A:middle
So let's write a quick code

00:11:18.126 --> 00:11:19.826 A:middle
snippet to get rid of that.

00:11:20.476 --> 00:11:22.576 A:middle
So we're going to create another

00:11:22.576 --> 00:11:24.436 A:middle
column in the starter image's

00:11:24.486 --> 00:11:26.236 A:middle
SFrame and call that label and

00:11:26.416 --> 00:11:27.736 A:middle
we're going to write some code

00:11:27.736 --> 00:11:30.706 A:middle
to extract the label out of the

00:11:31.376 --> 00:11:31.746 A:middle
path.

00:11:31.746 --> 00:11:33.296 A:middle
And we're going to use something

00:11:33.296 --> 00:11:35.206 A:middle
like a Python slice applied to

00:11:35.206 --> 00:11:36.806 A:middle
all the elements in the SFrame

00:11:37.106 --> 00:11:38.406 A:middle
-- in the column of the SFrame.

00:11:39.506 --> 00:11:41.306 A:middle
So we do an element slice from

00:11:41.306 --> 00:11:42.956 A:middle
the second index to the negative

00:11:42.956 --> 00:11:44.666 A:middle
four index similar to a Python

00:11:44.666 --> 00:11:45.016 A:middle
slice.

00:11:46.606 --> 00:11:48.606 A:middle
And next, let's explore this

00:11:48.606 --> 00:11:48.876 A:middle
SFrame.

00:11:49.826 --> 00:11:51.166 A:middle
Turi Create has an explore

00:11:51.166 --> 00:11:52.866 A:middle
functionality on the SFrame,

00:11:52.976 --> 00:11:54.126 A:middle
which we're going to take a look

00:11:54.126 --> 00:11:54.296 A:middle
at.

00:11:54.996 --> 00:11:56.216 A:middle
This pops up, a new

00:11:56.216 --> 00:11:57.866 A:middle
visualization window, which

00:11:57.866 --> 00:11:59.716 A:middle
gives us a way to interactively

00:11:59.716 --> 00:12:01.536 A:middle
explore all the data that is in

00:11:59.716 --> 00:12:01.536 A:middle
explore all the data that is in

00:12:01.536 --> 00:12:02.086 A:middle
our SFrame.

00:12:03.196 --> 00:12:05.126 A:middle
And as we can see, there's three

00:12:05.126 --> 00:12:05.726 A:middle
column here.

00:12:05.906 --> 00:12:07.326 A:middle
There's a path, image, and

00:12:07.326 --> 00:12:07.626 A:middle
label.

00:12:08.096 --> 00:12:09.046 A:middle
And it looks like we did

00:12:09.046 --> 00:12:10.736 A:middle
successfully extract the label

00:12:10.736 --> 00:12:11.746 A:middle
out of the path.

00:12:11.746 --> 00:12:13.306 A:middle
We did get rid of the .

00:12:13.306 --> 00:12:13.776 A:middle
/ and .png.

00:12:14.136 --> 00:12:15.336 A:middle
We can also take a look at all

00:12:15.336 --> 00:12:16.816 A:middle
the thumbnails of our images in

00:12:16.816 --> 00:12:18.116 A:middle
this SFrame which we one day

00:12:18.116 --> 00:12:19.136 A:middle
will do when we just printed it

00:12:19.136 --> 00:12:19.396 A:middle
out.

00:12:20.316 --> 00:12:23.496 A:middle
Great. How many rows are in this

00:12:23.536 --> 00:12:23.876 A:middle
SFrame?

00:12:24.276 --> 00:12:26.696 A:middle
Let's take a look at that.

00:12:26.696 --> 00:12:28.086 A:middle
So it looks like there are 52

00:12:28.086 --> 00:12:31.186 A:middle
rows and that's the number of

00:12:31.256 --> 00:12:32.546 A:middle
cards in our playing card deck.

00:12:32.546 --> 00:12:33.566 A:middle
So that looks good.

00:12:33.566 --> 00:12:36.486 A:middle
But the important thing to note

00:12:36.486 --> 00:12:39.646 A:middle
here is that it's one image per

00:12:39.646 --> 00:12:41.776 A:middle
class of the object that we're

00:12:41.776 --> 00:12:42.416 A:middle
trying to detect.

00:12:43.846 --> 00:12:45.476 A:middle
Now we looked at the data.

00:12:45.476 --> 00:12:46.516 A:middle
We've looked at the task.

00:12:46.516 --> 00:12:47.656 A:middle
We know the task is One-Shot

00:12:47.656 --> 00:12:48.446 A:middle
Object Detection.

00:12:49.006 --> 00:12:50.506 A:middle
The next step in our five-step

00:12:50.556 --> 00:12:52.326 A:middle
biplane is to take a look at the

00:12:52.326 --> 00:12:53.576 A:middle
model creation process.

00:12:54.696 --> 00:12:56.206 A:middle
And consistent with all our

00:12:56.206 --> 00:12:57.516 A:middle
other toolkits, the model

00:12:57.516 --> 00:12:59.166 A:middle
creation process looks something

00:12:59.166 --> 00:12:59.466 A:middle
like

00:12:59.976 --> 00:13:02.186 A:middle
tc.oneshotobjectdetector.create

00:12:59.976 --> 00:13:02.186 A:middle
tc.oneshotobjectdetector.create

00:13:03.656 --> 00:13:05.046 A:middle
and we pass in the starter

00:13:05.046 --> 00:13:07.336 A:middle
images SFrame as well as the

00:13:07.336 --> 00:13:08.576 A:middle
target column, which is in this

00:13:08.576 --> 00:13:09.436 A:middle
case, is label.

00:13:10.286 --> 00:13:11.336 A:middle
But I won't run this line of

00:13:11.336 --> 00:13:13.996 A:middle
code because this take a while

00:13:13.996 --> 00:13:15.566 A:middle
and what it does behind the

00:13:15.566 --> 00:13:17.776 A:middle
scenes is it not only generate

00:13:17.776 --> 00:13:19.596 A:middle
all the synthetic data by

00:13:19.596 --> 00:13:21.306 A:middle
applying different projections

00:13:21.306 --> 00:13:22.566 A:middle
on your starter images,

00:13:22.916 --> 00:13:24.326 A:middle
superimposing them on random

00:13:24.326 --> 00:13:25.586 A:middle
backgrounds and applying color

00:13:25.586 --> 00:13:27.296 A:middle
perturbations, but it also

00:13:27.296 --> 00:13:28.986 A:middle
trains a model after that.

00:13:29.576 --> 00:13:31.586 A:middle
So instead, we're going to

00:13:31.586 --> 00:13:33.256 A:middle
switch to a Cooking Show Mode,

00:13:33.366 --> 00:13:34.456 A:middle
where we're going to load a

00:13:34.456 --> 00:13:35.726 A:middle
model that we've already baked

00:13:35.726 --> 00:13:37.456 A:middle
in the oven sometime.

00:13:38.036 --> 00:13:39.696 A:middle
So let's use the load model

00:13:39.696 --> 00:13:42.606 A:middle
functionality and it's called

00:13:42.686 --> 00:13:43.996 A:middle
carddetector.model.

00:13:43.996 --> 00:13:46.896 A:middle
Let's see what this model looks

00:13:46.896 --> 00:13:47.186 A:middle
like.

00:13:48.276 --> 00:13:49.606 A:middle
So it looks like it's a One-Shot

00:13:49.606 --> 00:13:51.886 A:middle
Object Detector trained on 52

00:13:51.886 --> 00:13:52.406 A:middle
classes.

00:13:53.306 --> 00:13:54.246 A:middle
But hold on.

00:13:54.386 --> 00:13:55.626 A:middle
The number of synthetically

00:13:55.626 --> 00:13:58.616 A:middle
generated examples is 104,000.

00:13:58.616 --> 00:14:00.696 A:middle
That's strange.

00:13:58.616 --> 00:14:00.696 A:middle
That's strange.

00:14:00.846 --> 00:14:02.576 A:middle
We just provided 52 images.

00:14:04.056 --> 00:14:06.636 A:middle
The toolkit automatically

00:14:06.716 --> 00:14:08.876 A:middle
synthetically generated 2,000

00:14:08.876 --> 00:14:12.506 A:middle
images per class and created a

00:14:12.506 --> 00:14:14.836 A:middle
training set of 104,000.

00:14:14.836 --> 00:14:16.556 A:middle
And that's not it.

00:14:17.476 --> 00:14:19.466 A:middle
It also synthetically generated

00:14:19.466 --> 00:14:21.406 A:middle
bounding boxes for all the data

00:14:21.406 --> 00:14:22.876 A:middle
that it generated because the

00:14:22.876 --> 00:14:24.256 A:middle
toolkit generated the data

00:14:24.256 --> 00:14:24.616 A:middle
itself.

00:14:25.786 --> 00:14:26.796 A:middle
That's pretty insane.

00:14:27.516 --> 00:14:32.116 A:middle
[ Applause ]

00:14:32.616 --> 00:14:35.146 A:middle
So we've looked at our model.

00:14:35.296 --> 00:14:37.096 A:middle
The next step is let's small

00:14:37.096 --> 00:14:39.056 A:middle
test this model on an image that

00:14:39.056 --> 00:14:40.176 A:middle
the model hasn't seen before.

00:14:41.506 --> 00:14:42.856 A:middle
So I'm going to load up a test

00:14:42.856 --> 00:14:43.256 A:middle
image.

00:14:43.566 --> 00:14:47.266 A:middle
And I have a test directory

00:14:47.896 --> 00:14:49.316 A:middle
which contains a test image.

00:14:49.826 --> 00:14:51.846 A:middle
And it's definitely not Sam's

00:14:51.846 --> 00:14:53.146 A:middle
hand and you'll see why that it

00:14:53.146 --> 00:14:54.946 A:middle
is when I show you what this

00:14:54.946 --> 00:14:55.686 A:middle
test image is.

00:14:56.176 --> 00:14:59.906 A:middle
Yeah, Sam never gets this lucky.

00:14:59.906 --> 00:15:03.346 A:middle
This is probably my hand.

00:14:59.906 --> 00:15:03.346 A:middle
This is probably my hand.

00:15:03.666 --> 00:15:04.296 A:middle
It's a Flush.

00:15:04.646 --> 00:15:05.786 A:middle
So anyway, we can see that

00:15:05.786 --> 00:15:06.926 A:middle
there's an Eight of Clubs, a

00:15:06.926 --> 00:15:08.066 A:middle
Nine of Clubs, and a Ten of

00:15:08.116 --> 00:15:09.066 A:middle
Clubs in this image.

00:15:09.936 --> 00:15:12.546 A:middle
Let's see if the model agrees

00:15:12.546 --> 00:15:13.626 A:middle
with us.

00:15:14.776 --> 00:15:16.286 A:middle
So we're going to call the

00:15:16.286 --> 00:15:18.096 A:middle
predict method on the model and

00:15:18.096 --> 00:15:19.576 A:middle
pass in our test image.

00:15:19.756 --> 00:15:21.736 A:middle
And let's save this result in

00:15:21.736 --> 00:15:23.016 A:middle
variable called prediction.

00:15:25.106 --> 00:15:26.646 A:middle
And next, let's print this

00:15:26.646 --> 00:15:28.746 A:middle
prediction out.

00:15:29.016 --> 00:15:30.766 A:middle
Okay. Let's take that in.

00:15:31.456 --> 00:15:33.166 A:middle
So it looks like there are three

00:15:33.166 --> 00:15:35.326 A:middle
dictionaries in this list and

00:15:35.376 --> 00:15:37.136 A:middle
each dictionary represents a

00:15:37.136 --> 00:15:38.666 A:middle
bounding box that is part of the

00:15:38.666 --> 00:15:39.286 A:middle
prediction.

00:15:40.036 --> 00:15:41.096 A:middle
Let's go through the fields in

00:15:41.096 --> 00:15:41.716 A:middle
each prediction.

00:15:41.716 --> 00:15:42.376 A:middle
It looks like there's a

00:15:42.376 --> 00:15:43.526 A:middle
confidence, there's a

00:15:43.566 --> 00:15:45.996 A:middle
coordinates, a label, and a

00:15:45.996 --> 00:15:46.216 A:middle
type.

00:15:47.366 --> 00:15:49.116 A:middle
Confidence represents how

00:15:49.116 --> 00:15:51.766 A:middle
confident the model is in this

00:15:51.766 --> 00:15:52.416 A:middle
bounding box.

00:15:52.916 --> 00:15:54.036 A:middle
Coordinates represents the

00:15:54.036 --> 00:15:56.116 A:middle
coordinates of the bounding box.

00:15:56.766 --> 00:15:58.886 A:middle
Label is what class label

00:15:58.886 --> 00:16:00.366 A:middle
belongs to this bounding box.

00:15:58.886 --> 00:16:00.366 A:middle
belongs to this bounding box.

00:16:00.366 --> 00:16:01.366 A:middle
And type is what type of

00:16:01.366 --> 00:16:02.426 A:middle
bounding box it is, which it's

00:16:02.496 --> 00:16:02.996 A:middle
rectangle.

00:16:03.256 --> 00:16:05.126 A:middle
That looks great.

00:16:05.476 --> 00:16:07.286 A:middle
And we can see that the model

00:16:07.286 --> 00:16:08.606 A:middle
did detect the Ten of Clubs and

00:16:08.606 --> 00:16:09.606 A:middle
Eight of Clubs and the Nine of

00:16:09.656 --> 00:16:09.956 A:middle
Clubs.

00:16:10.676 --> 00:16:12.096 A:middle
But it doesn't really tell us

00:16:12.316 --> 00:16:14.486 A:middle
what location the model detected

00:16:14.486 --> 00:16:15.066 A:middle
it in.

00:16:15.786 --> 00:16:17.686 A:middle
So let's use a utility that the

00:16:17.686 --> 00:16:20.106 A:middle
One-Shot Object Detector has to

00:16:20.106 --> 00:16:22.646 A:middle
draw bounding boxes and we'll

00:16:22.646 --> 00:16:24.296 A:middle
pass in the test image along

00:16:24.296 --> 00:16:25.636 A:middle
with annotations, which in this

00:16:25.706 --> 00:16:26.716 A:middle
case, is the prediction.

00:16:28.366 --> 00:16:30.646 A:middle
And let's call this annotated

00:16:31.266 --> 00:16:31.766 A:middle
image.

00:16:34.566 --> 00:16:36.756 A:middle
And next, let's print this

00:16:36.756 --> 00:16:37.686 A:middle
annotated image out.

00:16:38.516 --> 00:16:40.956 A:middle
[ Applause ]

00:16:41.456 --> 00:16:42.546 A:middle
Yeah that looks pretty good.

00:16:43.406 --> 00:16:44.876 A:middle
On an image that the model has

00:16:44.876 --> 00:16:46.876 A:middle
never seen before, an Eight of

00:16:46.876 --> 00:16:48.036 A:middle
Clubs with 70 percent

00:16:48.036 --> 00:16:49.366 A:middle
confidence, a Ten of Clubs with

00:16:49.366 --> 00:16:50.836 A:middle
91 percent, and Nine of Clubs at

00:16:50.836 --> 00:16:51.676 A:middle
69 percent.

00:16:52.256 --> 00:16:54.036 A:middle
And notice how all the bounding

00:16:54.036 --> 00:16:57.016 A:middle
boxes perfectly capture all the

00:16:57.016 --> 00:16:57.406 A:middle
clubs.

00:17:00.146 --> 00:17:02.446 A:middle
So we've small tested this model

00:17:02.656 --> 00:17:04.146 A:middle
on a test image that the model

00:17:04.146 --> 00:17:05.066 A:middle
never saw before.

00:17:05.606 --> 00:17:07.526 A:middle
The last step is deployment on

00:17:07.526 --> 00:17:08.066 A:middle
device.

00:17:08.566 --> 00:17:10.506 A:middle
And like all our other toolkits,

00:17:10.566 --> 00:17:12.386 A:middle
the model has a method to export

00:17:12.386 --> 00:17:12.976 A:middle
Core ML.

00:17:13.516 --> 00:17:14.935 A:middle
And let's call this Core ML

00:17:14.935 --> 00:17:17.986 A:middle
model CardDetector.mlmodel.

00:17:20.316 --> 00:17:22.205 A:middle
And next, let's open this

00:17:22.286 --> 00:17:27.935 A:middle
CardDetector.mlmodel in XCode.

00:17:28.006 --> 00:17:30.496 A:middle
Alright. So we can see that we

00:17:30.496 --> 00:17:32.386 A:middle
have a CardDetector model which

00:17:32.386 --> 00:17:35.076 A:middle
is trained by Turi Create 5.6.

00:17:35.886 --> 00:17:37.436 A:middle
The inputs are image, which is a

00:17:37.436 --> 00:17:40.126 A:middle
416 x 416 color image and

00:17:40.126 --> 00:17:42.146 A:middle
confidence is representative of

00:17:42.146 --> 00:17:43.796 A:middle
how many classes the model was

00:17:43.796 --> 00:17:45.506 A:middle
trained on and coordinates

00:17:45.656 --> 00:17:46.776 A:middle
represents the coordinates of

00:17:46.776 --> 00:17:48.436 A:middle
the bounding box of the classes.

00:17:49.906 --> 00:17:50.526 A:middle
This looks good.

00:17:50.526 --> 00:17:52.606 A:middle
It looks like a very good Core

00:17:52.606 --> 00:17:53.326 A:middle
ML model.

00:17:54.006 --> 00:17:56.246 A:middle
But why don't we have some fun

00:17:56.306 --> 00:17:58.486 A:middle
and put this into action in an

00:17:58.756 --> 00:18:00.626 A:middle
app that Sam can use next time

00:17:58.756 --> 00:18:00.626 A:middle
app that Sam can use next time

00:18:00.626 --> 00:18:01.656 A:middle
he plays three card poker

00:18:01.656 --> 00:18:02.806 A:middle
against me.

00:18:03.976 --> 00:18:06.006 A:middle
Alright. And here's my Three

00:18:06.006 --> 00:18:07.106 A:middle
Card Poker app.

00:18:07.426 --> 00:18:08.946 A:middle
So it says add an image to

00:18:08.946 --> 00:18:09.746 A:middle
evaluate cards.

00:18:09.976 --> 00:18:11.246 A:middle
Here I have a deck of cards and

00:18:11.246 --> 00:18:12.396 A:middle
I'm just going to randomly draw

00:18:12.396 --> 00:18:12.836 A:middle
from this.

00:18:12.986 --> 00:18:17.706 A:middle
And this will be Sam's hand.

00:18:19.216 --> 00:18:20.876 A:middle
So let's take a photo right

00:18:20.876 --> 00:18:21.146 A:middle
here.

00:18:22.436 --> 00:18:24.776 A:middle
So it looks like there's -- this

00:18:24.776 --> 00:18:26.126 A:middle
looks like one of the best hands

00:18:26.126 --> 00:18:27.356 A:middle
Sam has gotten in a while.

00:18:31.656 --> 00:18:33.196 A:middle
Alright. So it looks like the

00:18:33.196 --> 00:18:34.426 A:middle
model thinks there's a Five of

00:18:34.486 --> 00:18:35.826 A:middle
Clubs, a Three of Hearts, and a

00:18:35.826 --> 00:18:36.426 A:middle
King of Hearts.

00:18:36.936 --> 00:18:38.206 A:middle
And it also detected it was a

00:18:38.206 --> 00:18:38.746 A:middle
hard card.

00:18:38.786 --> 00:18:39.786 A:middle
The probability of which is

00:18:39.786 --> 00:18:40.976 A:middle
74.39 percent.

00:18:41.391 --> 00:18:43.391 A:middle
[ Applause ]

00:18:43.766 --> 00:18:48.166 A:middle
Yeah. Now given that it's a high

00:18:48.166 --> 00:18:50.146 A:middle
card, Sam should probably fold

00:18:50.146 --> 00:18:51.396 A:middle
because it's pretty likely to

00:18:51.396 --> 00:18:52.036 A:middle
get a high card.

00:18:52.036 --> 00:18:53.526 A:middle
But just for fun, let's see what

00:18:53.526 --> 00:18:54.026 A:middle
I got.

00:18:59.056 --> 00:19:01.316 A:middle
Yeah, that's -- well let's take

00:18:59.056 --> 00:19:01.316 A:middle
Yeah, that's -- well let's take

00:19:01.316 --> 00:19:02.486 A:middle
a picture and then talk about my

00:19:02.516 --> 00:19:02.816 A:middle
hand.

00:19:07.316 --> 00:19:08.616 A:middle
I have a Flush.

00:19:08.686 --> 00:19:09.976 A:middle
Nine of Hearts, Six of Hearts,

00:19:09.976 --> 00:19:13.066 A:middle
and Four of Hearts.

00:19:13.066 --> 00:19:14.476 A:middle
So even though we built this app

00:19:14.586 --> 00:19:17.786 A:middle
for Sam, we do sort of -- I'm

00:19:17.786 --> 00:19:19.126 A:middle
still reaping the benefits of

00:19:19.936 --> 00:19:20.056 A:middle
it.

00:19:21.166 --> 00:19:22.746 A:middle
Alright. So that was it for the

00:19:22.746 --> 00:19:23.826 A:middle
Card Detector Demo.

00:19:23.826 --> 00:19:28.946 A:middle
And to sort of recap, we started

00:19:28.946 --> 00:19:32.766 A:middle
with one image per class.

00:19:33.976 --> 00:19:35.746 A:middle
We just called one line of code

00:19:36.466 --> 00:19:37.606 A:middle
that automatically,

00:19:37.696 --> 00:19:39.056 A:middle
synthetically generated a

00:19:39.056 --> 00:19:40.166 A:middle
training data set for us.

00:19:40.226 --> 00:19:41.006 A:middle
Trained a model.

00:19:41.916 --> 00:19:44.196 A:middle
We then small tested it on a

00:19:44.196 --> 00:19:45.456 A:middle
random image the model had never

00:19:45.526 --> 00:19:46.176 A:middle
seen before.

00:19:46.176 --> 00:19:49.346 A:middle
And we then saw it in an app.

00:19:49.346 --> 00:19:51.126 A:middle
And this is just one example of

00:19:51.126 --> 00:19:53.286 A:middle
the kind of user experience that

00:19:53.286 --> 00:19:53.846 A:middle
you can build.

00:19:54.966 --> 00:19:57.046 A:middle
We were thrilled with the sort

00:19:57.046 --> 00:19:58.316 A:middle
of stuff you built last year

00:19:58.316 --> 00:20:00.256 A:middle
with the Object Detector and

00:19:58.316 --> 00:20:00.256 A:middle
with the Object Detector and

00:20:00.496 --> 00:20:02.556 A:middle
that sort of led us to build

00:20:02.556 --> 00:20:04.716 A:middle
this toolkit because we wanted

00:20:04.716 --> 00:20:06.456 A:middle
to reduce your overhead on data

00:20:06.456 --> 00:20:07.866 A:middle
collection and annotation.

00:20:08.256 --> 00:20:09.316 A:middle
That time has gone down from

00:20:09.316 --> 00:20:10.436 A:middle
like, I don't know, a few days

00:20:10.436 --> 00:20:13.886 A:middle
to like five minutes and only

00:20:13.886 --> 00:20:14.926 A:middle
for 2D objects though.

00:20:15.916 --> 00:20:17.856 A:middle
And we can't wait to see what

00:20:17.856 --> 00:20:18.786 A:middle
you build with the One-Shot

00:20:18.786 --> 00:20:19.506 A:middle
Object Detector.

00:20:19.966 --> 00:20:21.636 A:middle
So feel free to come to our labs

00:20:21.666 --> 00:20:23.026 A:middle
and try this demo out live.

00:20:23.196 --> 00:20:24.886 A:middle
We will be really excited to

00:20:24.886 --> 00:20:25.936 A:middle
have you.

00:20:25.936 --> 00:20:29.066 A:middle
And with that, I'm going to move

00:20:29.066 --> 00:20:31.236 A:middle
onto to our next toolkit for

00:20:32.796 --> 00:20:32.936 A:middle
today.

00:20:33.106 --> 00:20:34.556 A:middle
I'm really excited to talk to

00:20:34.556 --> 00:20:35.126 A:middle
you about the Drawing

00:20:35.126 --> 00:20:35.656 A:middle
Classifier.

00:20:37.516 --> 00:20:40.836 A:middle
So far Turi Create has enabled

00:20:40.836 --> 00:20:42.726 A:middle
you to build apps with sound

00:20:42.726 --> 00:20:46.686 A:middle
input, raw sensor data input,

00:20:48.456 --> 00:20:49.456 A:middle
and images.

00:20:52.116 --> 00:20:55.046 A:middle
Today, we're adding a new form

00:20:55.046 --> 00:20:56.966 A:middle
of input, the Apple Pencil.

00:20:57.516 --> 00:21:00.566 A:middle
[ Applause ]

00:20:57.516 --> 00:21:00.566 A:middle
[ Applause ]

00:21:01.066 --> 00:21:03.076 A:middle
Imagine building an app that

00:21:03.076 --> 00:21:04.676 A:middle
let's your users create handsome

00:21:04.676 --> 00:21:06.656 A:middle
greeting cards by recognizing

00:21:06.656 --> 00:21:08.706 A:middle
their strokes and automatically

00:21:08.706 --> 00:21:10.156 A:middle
replacing them with professional

00:21:10.156 --> 00:21:10.586 A:middle
drawings.

00:21:11.876 --> 00:21:12.866 A:middle
Power to the user.

00:21:14.246 --> 00:21:15.556 A:middle
Or imagine building an app that

00:21:15.556 --> 00:21:17.826 A:middle
breaks ground in education by

00:21:18.216 --> 00:21:19.926 A:middle
helping professors grade their

00:21:19.926 --> 00:21:21.636 A:middle
student's exams much faster by

00:21:21.636 --> 00:21:22.896 A:middle
recognizing their strokes.

00:21:23.456 --> 00:21:25.436 A:middle
We're actually going to build

00:21:25.436 --> 00:21:25.836 A:middle
this app.

00:21:26.136 --> 00:21:28.396 A:middle
But before that, let's talk

00:21:28.396 --> 00:21:29.736 A:middle
about the data.

00:21:30.596 --> 00:21:32.556 A:middle
The Drawing Classification task

00:21:32.676 --> 00:21:34.116 A:middle
can accept bitmap-based

00:21:34.116 --> 00:21:36.336 A:middle
drawings, represented as Turi

00:21:36.336 --> 00:21:39.116 A:middle
Create images, but that's not

00:21:39.116 --> 00:21:39.326 A:middle
all.

00:21:39.326 --> 00:21:44.346 A:middle
The task can also accept

00:21:44.346 --> 00:21:45.996 A:middle
stroke-based drawings, where

00:21:45.996 --> 00:21:47.746 A:middle
every stroke is a time series

00:21:47.746 --> 00:21:50.336 A:middle
data of x and y coordinates.

00:21:51.546 --> 00:21:53.086 A:middle
We wanted to give you as much

00:21:53.126 --> 00:21:55.906 A:middle
flexibility in your data as

00:21:57.696 --> 00:21:58.196 A:middle
possible.

00:21:58.196 --> 00:21:59.776 A:middle
Model creation follows an API

00:21:59.776 --> 00:22:01.086 A:middle
consistent with all our other

00:21:59.776 --> 00:22:01.086 A:middle
consistent with all our other

00:22:01.086 --> 00:22:02.846 A:middle
toolkits, turicreate

00:22:02.846 --> 00:22:04.846 A:middle
drawingclassifier.create with

00:22:04.846 --> 00:22:06.376 A:middle
the training SFrame and the

00:22:06.416 --> 00:22:07.046 A:middle
target column.

00:22:07.046 --> 00:22:09.626 A:middle
The model that you get out of

00:22:09.626 --> 00:22:10.656 A:middle
here is state of the art.

00:22:11.386 --> 00:22:12.956 A:middle
The Core ML model that you get

00:22:12.956 --> 00:22:14.746 A:middle
is less than 500 kilobytes on

00:22:14.746 --> 00:22:15.156 A:middle
device.

00:22:15.556 --> 00:22:17.826 A:middle
And this is GPU accelerated.

00:22:18.516 --> 00:22:22.596 A:middle
[ Applause ]

00:22:23.096 --> 00:22:24.286 A:middle
But we didn't stop there.

00:22:25.556 --> 00:22:27.256 A:middle
We trained a model on millions

00:22:27.256 --> 00:22:29.216 A:middle
of drawings and published it to

00:22:29.216 --> 00:22:30.526 A:middle
automatically one start your

00:22:30.526 --> 00:22:30.886 A:middle
models.

00:22:31.136 --> 00:22:33.536 A:middle
And not only does this help you

00:22:33.536 --> 00:22:36.366 A:middle
create more accurate models, it

00:22:36.366 --> 00:22:38.126 A:middle
also helps you train on as few

00:22:38.126 --> 00:22:39.796 A:middle
as 30 drawings per class.

00:22:40.486 --> 00:22:42.236 A:middle
Thirty. Let that sink in.

00:22:42.236 --> 00:22:46.296 A:middle
So what does the code look like?

00:22:47.246 --> 00:22:48.826 A:middle
Five lines of code, five steps.

00:22:49.176 --> 00:22:50.166 A:middle
We start with importing

00:22:50.166 --> 00:22:50.986 A:middle
turicreate.

00:22:50.986 --> 00:22:52.816 A:middle
Looking at our data, calling

00:22:52.816 --> 00:22:54.796 A:middle
model creation, evaluating our

00:22:54.796 --> 00:22:56.216 A:middle
data, and then exploring to Core

00:22:56.216 --> 00:22:56.396 A:middle
ML.

00:22:56.626 --> 00:22:59.776 A:middle
And with that, remember that

00:22:59.776 --> 00:23:01.336 A:middle
grading app that we saw which

00:22:59.776 --> 00:23:01.336 A:middle
grading app that we saw which

00:23:01.336 --> 00:23:02.936 A:middle
was like recognizing checks and

00:23:02.936 --> 00:23:04.406 A:middle
crosses and doing some more

00:23:04.676 --> 00:23:05.736 A:middle
fancy stuff?

00:23:06.466 --> 00:23:07.456 A:middle
Why don't we go ahead and build

00:23:07.456 --> 00:23:07.926 A:middle
that?

00:23:08.056 --> 00:23:10.096 A:middle
So we're going to take a look at

00:23:10.686 --> 00:23:14.316 A:middle
this app on the iPad, which

00:23:15.016 --> 00:23:16.436 A:middle
helps us grade exams.

00:23:17.136 --> 00:23:18.806 A:middle
So let's say I'm a professor and

00:23:18.806 --> 00:23:20.806 A:middle
I have my Apple Pencil and I

00:23:20.806 --> 00:23:21.816 A:middle
want to grade my students'

00:23:21.816 --> 00:23:23.586 A:middle
exams, but I want to grade them

00:23:23.586 --> 00:23:24.246 A:middle
really quickly.

00:23:25.096 --> 00:23:26.706 A:middle
So let's add an image to begin

00:23:26.706 --> 00:23:27.086 A:middle
grading.

00:23:27.086 --> 00:23:29.276 A:middle
This is an exam of my student,

00:23:29.276 --> 00:23:31.366 A:middle
Jane Appleseed and it's Math

00:23:31.366 --> 00:23:32.806 A:middle
101, which is pretty hard.

00:23:35.886 --> 00:23:36.786 A:middle
So let's take a look at the

00:23:36.786 --> 00:23:38.386 A:middle
image and now let's start

00:23:38.386 --> 00:23:38.776 A:middle
grading.

00:23:39.646 --> 00:23:41.476 A:middle
So one plus one is two, right?

00:23:41.476 --> 00:23:42.546 A:middle
Last I checked that was still

00:23:42.546 --> 00:23:42.866 A:middle
true.

00:23:43.506 --> 00:23:44.706 A:middle
So let's mark that as correct.

00:23:44.836 --> 00:23:46.336 A:middle
And as you can see, the model

00:23:46.336 --> 00:23:48.416 A:middle
detected the check and recorded

00:23:48.416 --> 00:23:49.596 A:middle
ten points on the right-hand

00:23:49.596 --> 00:23:51.556 A:middle
side, giving the student ten out

00:23:51.556 --> 00:23:52.696 A:middle
of ten on this question.

00:23:53.766 --> 00:23:54.716 A:middle
One plus two is four.

00:23:54.716 --> 00:23:57.056 A:middle
That's correct too.

00:23:57.296 --> 00:23:58.246 A:middle
Oh I guess it's not.

00:23:58.326 --> 00:24:01.236 A:middle
So erase that.

00:23:58.326 --> 00:24:01.236 A:middle
So erase that.

00:24:01.236 --> 00:24:02.686 A:middle
I think I should go back to Math

00:24:02.686 --> 00:24:03.466 A:middle
101 maybe.

00:24:04.466 --> 00:24:05.806 A:middle
So let's mark that incorrect

00:24:06.456 --> 00:24:07.766 A:middle
because the model made a

00:24:07.766 --> 00:24:08.486 A:middle
mistake.

00:24:08.486 --> 00:24:09.666 A:middle
So let's erase that again.

00:24:10.186 --> 00:24:12.316 A:middle
And to give you a preview into

00:24:12.316 --> 00:24:13.886 A:middle
how you can improve your models,

00:24:13.886 --> 00:24:14.956 A:middle
Abhishek is going to be up on

00:24:14.956 --> 00:24:16.036 A:middle
stage in a few minutes.

00:24:16.616 --> 00:24:18.966 A:middle
And this app is also designed to

00:24:18.966 --> 00:24:20.246 A:middle
take care of models failing.

00:24:20.556 --> 00:24:21.676 A:middle
So if you want, you can check

00:24:21.676 --> 00:24:22.946 A:middle
out the 11:00 AM session on

00:24:22.946 --> 00:24:24.516 A:middle
Designing Apps for Machine

00:24:24.516 --> 00:24:24.726 A:middle
Learning.

00:24:25.266 --> 00:24:26.076 A:middle
So let's keep grading.

00:24:26.616 --> 00:24:27.646 A:middle
So one plus two is four.

00:24:27.646 --> 00:24:28.576 A:middle
That's incorrect.

00:24:28.576 --> 00:24:31.196 A:middle
And the model detected the cross

00:24:31.276 --> 00:24:31.976 A:middle
as incorrect.

00:24:31.976 --> 00:24:33.566 A:middle
And it's a pretty serious

00:24:33.566 --> 00:24:35.726 A:middle
mistake for Math 101 in college.

00:24:36.186 --> 00:24:37.346 A:middle
So let's give that a negative

00:24:37.446 --> 00:24:37.816 A:middle
seven.

00:24:37.816 --> 00:24:40.176 A:middle
And as you can see, the model

00:24:40.176 --> 00:24:41.766 A:middle
registered the negative seven

00:24:42.016 --> 00:24:43.406 A:middle
and gave the student three out

00:24:43.406 --> 00:24:44.766 A:middle
of ten points on the right-hand

00:24:44.766 --> 00:24:44.996 A:middle
side.

00:24:46.186 --> 00:24:47.126 A:middle
Three plus two is five.

00:24:47.126 --> 00:24:48.786 A:middle
That's correct.

00:24:49.646 --> 00:24:51.426 A:middle
To give you an insight into what

00:24:51.426 --> 00:24:53.216 A:middle
the model is that powers this

00:24:53.216 --> 00:24:55.386 A:middle
app, this model is trained on

00:24:55.386 --> 00:24:58.316 A:middle
check, cross, and ten negative

00:24:58.356 --> 00:24:59.796 A:middle
scored deductions from negative

00:24:59.796 --> 00:25:00.716 A:middle
one through negative ten.

00:24:59.796 --> 00:25:00.716 A:middle
one through negative ten.

00:25:01.466 --> 00:25:02.566 A:middle
So let's keep grading.

00:25:03.226 --> 00:25:04.856 A:middle
One plus 99 is.

00:25:06.686 --> 00:25:07.716 A:middle
It's a hundred, okay.

00:25:08.356 --> 00:25:09.266 A:middle
So that's incorrect.

00:25:09.266 --> 00:25:11.446 A:middle
And that's another mistake the

00:25:11.446 --> 00:25:11.966 A:middle
model made.

00:25:12.456 --> 00:25:14.496 A:middle
So let's correct that and mark

00:25:14.496 --> 00:25:15.086 A:middle
that incorrect.

00:25:16.126 --> 00:25:17.306 A:middle
So let's give that maybe a

00:25:17.306 --> 00:25:19.836 A:middle
negative five and the model

00:25:19.836 --> 00:25:21.376 A:middle
registered the negative five and

00:25:21.376 --> 00:25:22.916 A:middle
stored it on the right-hand

00:25:22.916 --> 00:25:23.146 A:middle
side.

00:25:23.146 --> 00:25:25.946 A:middle
And this last question is, it's

00:25:25.946 --> 00:25:29.926 A:middle
hard but I don't know how the

00:25:29.926 --> 00:25:31.856 A:middle
student this right, but they got

00:25:31.856 --> 00:25:32.886 A:middle
one plus two wrong.

00:25:33.626 --> 00:25:34.526 A:middle
Anyway, let's give them a

00:25:34.526 --> 00:25:35.346 A:middle
correct for this.

00:25:36.476 --> 00:25:39.286 A:middle
Okay. So this is the kind of

00:25:39.286 --> 00:25:41.146 A:middle
experience that you can build

00:25:41.786 --> 00:25:43.186 A:middle
with the Drawing Classifier.

00:25:43.186 --> 00:25:47.456 A:middle
And why don't we go ahead and

00:25:47.456 --> 00:25:48.996 A:middle
write some code to actually

00:25:48.996 --> 00:25:50.256 A:middle
build a Core ML model that

00:25:50.256 --> 00:25:51.726 A:middle
powered this app.

00:25:56.076 --> 00:25:58.096 A:middle
So here I have another blank

00:25:58.096 --> 00:26:00.516 A:middle
Jupyter Notebook and we're going

00:25:58.096 --> 00:26:00.516 A:middle
Jupyter Notebook and we're going

00:26:00.516 --> 00:26:01.516 A:middle
to go through that five-step

00:26:01.516 --> 00:26:02.416 A:middle
pipeline again.

00:26:03.136 --> 00:26:07.516 A:middle
The first step being, the task.

00:26:07.516 --> 00:26:08.446 A:middle
The task here is Drawing

00:26:08.446 --> 00:26:09.306 A:middle
Classification.

00:26:09.436 --> 00:26:11.636 A:middle
We've established that.

00:26:11.636 --> 00:26:13.196 A:middle
So the next step is the data.

00:26:14.396 --> 00:26:15.886 A:middle
But before that, let's write our

00:26:15.886 --> 00:26:19.096 A:middle
favorite line of code which is

00:26:19.096 --> 00:26:20.806 A:middle
import turicreate as tc.

00:26:22.026 --> 00:26:23.466 A:middle
Now to look at the data, we're

00:26:23.466 --> 00:26:25.136 A:middle
going to load up an SFrame of

00:26:25.346 --> 00:26:26.676 A:middle
some data that we've already

00:26:26.676 --> 00:26:27.286 A:middle
accumulated.

00:26:28.246 --> 00:26:32.006 A:middle
Let's call it train.

00:26:32.136 --> 00:26:34.256 A:middle
And it's called train.sframe.

00:26:34.726 --> 00:26:37.566 A:middle
Next, let's use the explore

00:26:37.596 --> 00:26:39.136 A:middle
functionality on the train

00:26:39.326 --> 00:26:41.636 A:middle
SFrame and see what it looks

00:26:42.876 --> 00:26:43.226 A:middle
like.

00:26:43.226 --> 00:26:44.876 A:middle
Great. So it looks like we have

00:26:44.876 --> 00:26:46.706 A:middle
a lot of data here.

00:26:46.706 --> 00:26:47.896 A:middle
We have a negative three.

00:26:48.096 --> 00:26:49.156 A:middle
That's labeled as a negative

00:26:49.156 --> 00:26:49.396 A:middle
three.

00:26:49.736 --> 00:26:51.026 A:middle
A check labeled as a check.

00:26:51.386 --> 00:26:52.816 A:middle
Again, this SFrame has two

00:26:52.816 --> 00:26:54.446 A:middle
columns, bitmap and label.

00:26:54.936 --> 00:26:56.216 A:middle
And for this demo, we're going

00:26:56.216 --> 00:26:57.536 A:middle
to be using bitmap-based

00:26:57.536 --> 00:26:58.916 A:middle
drawings, but you can also have

00:26:58.916 --> 00:27:00.326 A:middle
stroke-based drawings instead of

00:26:58.916 --> 00:27:00.326 A:middle
stroke-based drawings instead of

00:27:00.326 --> 00:27:01.026 A:middle
the bitmap column.

00:27:02.516 --> 00:27:03.746 A:middle
So we have a bunch of drawings

00:27:03.746 --> 00:27:04.086 A:middle
here.

00:27:04.286 --> 00:27:05.946 A:middle
If we scroll through it, we have

00:27:05.946 --> 00:27:07.526 A:middle
a cross, another check, some

00:27:07.526 --> 00:27:08.696 A:middle
negative score deductions.

00:27:09.096 --> 00:27:09.896 A:middle
Looks pretty good.

00:27:09.896 --> 00:27:11.206 A:middle
How many examples are there,

00:27:11.906 --> 00:27:13.466 A:middle
4,436?

00:27:13.846 --> 00:27:15.246 A:middle
Okay, that's quite a few

00:27:15.246 --> 00:27:16.666 A:middle
examples.

00:27:16.836 --> 00:27:17.826 A:middle
You might be wondering, "Well

00:27:17.826 --> 00:27:19.176 A:middle
how did you collect all that

00:27:19.216 --> 00:27:19.586 A:middle
data.

00:27:19.586 --> 00:27:20.966 A:middle
How did you get all that data?"

00:27:21.506 --> 00:27:23.386 A:middle
So three of us got into a

00:27:23.386 --> 00:27:25.226 A:middle
conference room with iPads and

00:27:25.226 --> 00:27:27.146 A:middle
Pencils and we just drew these

00:27:27.146 --> 00:27:28.676 A:middle
strokes on our iPads for about

00:27:28.676 --> 00:27:31.286 A:middle
an hour and then just converted

00:27:31.286 --> 00:27:32.146 A:middle
it to an SFrame.

00:27:32.666 --> 00:27:34.656 A:middle
So data collection overhead for

00:27:34.656 --> 00:27:36.376 A:middle
this toolkit is also pretty low.

00:27:38.936 --> 00:27:40.006 A:middle
So now that we've looked at our

00:27:40.006 --> 00:27:43.576 A:middle
data, let's go ahead and look at

00:27:43.576 --> 00:27:44.976 A:middle
what the model creation process

00:27:44.976 --> 00:27:46.026 A:middle
looks like.

00:27:47.236 --> 00:27:48.346 A:middle
So we have

00:27:48.716 --> 00:27:50.226 A:middle
drawingclassifier.create.

00:27:50.226 --> 00:27:53.066 A:middle
We pass in the training SFrame

00:27:53.066 --> 00:27:54.166 A:middle
and we pass in the target

00:27:54.166 --> 00:27:55.506 A:middle
column, which in this case, is

00:27:55.506 --> 00:27:55.826 A:middle
label.

00:27:56.216 --> 00:27:57.756 A:middle
And I'm also going to pass into

00:27:57.756 --> 00:27:59.586 A:middle
a max iterations perimeter of

00:27:59.586 --> 00:28:02.006 A:middle
one to just give you a feel of

00:27:59.586 --> 00:28:02.006 A:middle
one to just give you a feel of

00:28:02.006 --> 00:28:03.156 A:middle
what the training process looks

00:28:03.206 --> 00:28:03.396 A:middle
like.

00:28:04.876 --> 00:28:06.306 A:middle
Behind the scenes what this is

00:28:06.306 --> 00:28:08.426 A:middle
doing is it's resizing all our

00:28:08.426 --> 00:28:11.426 A:middle
images down to 28 x 28 and then

00:28:11.476 --> 00:28:12.616 A:middle
parsing them through the neural

00:28:12.616 --> 00:28:14.106 A:middle
network for one iteration.

00:28:16.036 --> 00:28:17.736 A:middle
And looks like that's done.

00:28:17.816 --> 00:28:19.066 A:middle
But this model is not going to

00:28:19.066 --> 00:28:20.966 A:middle
be good enough for our use case.

00:28:21.496 --> 00:28:24.096 A:middle
So again, let's switch to

00:28:24.096 --> 00:28:25.686 A:middle
Cooking Show Mode and open the

00:28:25.686 --> 00:28:26.926 A:middle
door of the oven and take out a

00:28:26.926 --> 00:28:28.166 A:middle
model from it.

00:28:29.276 --> 00:28:30.846 A:middle
So we have the load model

00:28:30.846 --> 00:28:33.846 A:middle
functionality and we load up the

00:28:33.906 --> 00:28:34.536 A:middle
grading model.

00:28:34.996 --> 00:28:38.066 A:middle
Alright. So if we take a look at

00:28:38.066 --> 00:28:40.106 A:middle
this model, we have a Drawing

00:28:40.106 --> 00:28:42.136 A:middle
Classifier model that's trained

00:28:42.136 --> 00:28:44.146 A:middle
on 12 classes with the feature

00:28:44.146 --> 00:28:45.516 A:middle
column being bitmap, the target

00:28:45.516 --> 00:28:47.036 A:middle
column being label, and it's

00:28:47.036 --> 00:28:48.756 A:middle
trained for 200 iterations and

00:28:48.756 --> 00:28:49.816 A:middle
only for 30 minutes.

00:28:50.936 --> 00:28:53.506 A:middle
So after training for only 30

00:28:53.506 --> 00:28:54.776 A:middle
minutes we got a model with a

00:28:54.776 --> 00:28:56.096 A:middle
pretty high training accuracy.

00:28:56.316 --> 00:28:56.976 A:middle
That's pretty good.

00:28:56.976 --> 00:29:00.516 A:middle
So now that we have the model,

00:28:56.976 --> 00:29:00.516 A:middle
So now that we have the model,

00:29:00.516 --> 00:29:03.746 A:middle
the next step is to evaluate

00:29:03.786 --> 00:29:04.276 A:middle
this model.

00:29:05.416 --> 00:29:07.316 A:middle
But I'm going to skip that

00:29:07.316 --> 00:29:08.426 A:middle
because my colleague, Abhishek

00:29:08.426 --> 00:29:09.706 A:middle
will be up here in a few minutes

00:29:10.126 --> 00:29:11.986 A:middle
and not only will he show us how

00:29:11.986 --> 00:29:13.356 A:middle
to visualize the model's

00:29:13.356 --> 00:29:15.726 A:middle
mistakes, but he'll also show us

00:29:15.836 --> 00:29:17.546 A:middle
how to establish a feedback loop

00:29:17.546 --> 00:29:19.576 A:middle
of the model and improve it.

00:29:20.066 --> 00:29:22.436 A:middle
So let's skip ahead to exporting

00:29:22.436 --> 00:29:23.716 A:middle
to Core ML.

00:29:25.576 --> 00:29:28.016 A:middle
And consistent with all our

00:29:28.016 --> 00:29:30.886 A:middle
other toolkits, we have an

00:29:30.886 --> 00:29:32.426 A:middle
export coreml method on the

00:29:32.426 --> 00:29:34.406 A:middle
model and it's not CardDetector,

00:29:34.406 --> 00:29:35.106 A:middle
it's Grading.

00:29:35.616 --> 00:29:37.506 A:middle
So let's call it Grading.mlmodel

00:29:37.966 --> 00:29:39.436 A:middle
and then let's take a look in

00:29:39.466 --> 00:29:39.796 A:middle
XCode.

00:29:44.466 --> 00:29:48.496 A:middle
Great. So this model has bitmap

00:29:48.596 --> 00:29:49.716 A:middle
as its input which is a

00:29:49.716 --> 00:29:51.816 A:middle
grayscale image of size 28 x 28

00:29:52.276 --> 00:29:53.346 A:middle
and the outputs are label

00:29:53.346 --> 00:29:55.126 A:middle
probabilities and class label.

00:29:55.486 --> 00:29:56.876 A:middle
Label probabilities being the

00:29:56.876 --> 00:29:58.736 A:middle
probabilities of all the classes

00:29:58.736 --> 00:30:00.056 A:middle
that the model was trained on

00:29:58.736 --> 00:30:00.056 A:middle
that the model was trained on

00:30:00.386 --> 00:30:01.976 A:middle
and class label being the class

00:30:01.976 --> 00:30:03.056 A:middle
label of the top prediction.

00:30:04.536 --> 00:30:05.276 A:middle
So this looks good.

00:30:06.766 --> 00:30:08.526 A:middle
We worked really hard to bring

00:30:08.526 --> 00:30:10.946 A:middle
the size of the Core ML down as

00:30:10.946 --> 00:30:12.496 A:middle
much as we could because we

00:30:12.496 --> 00:30:14.466 A:middle
wanted this model to be as

00:30:14.576 --> 00:30:15.826 A:middle
portable as possible for your

00:30:15.826 --> 00:30:16.486 A:middle
use case.

00:30:16.486 --> 00:30:20.316 A:middle
And we brought it down to 396

00:30:20.406 --> 00:30:20.876 A:middle
kilobytes.

00:30:20.876 --> 00:30:21.966 A:middle
That's kilobytes.

00:30:22.516 --> 00:30:27.596 A:middle
[ Applause ]

00:30:28.096 --> 00:30:29.716 A:middle
So now that we've taken a look

00:30:29.716 --> 00:30:31.916 A:middle
at the Core ML model and we've

00:30:31.916 --> 00:30:35.546 A:middle
taken a look at what the final

00:30:35.546 --> 00:30:37.616 A:middle
app that we had was, let's also

00:30:37.616 --> 00:30:39.306 A:middle
take a look at what the Swift

00:30:39.306 --> 00:30:40.386 A:middle
code you need to write to

00:30:40.386 --> 00:30:42.176 A:middle
integrate this model into your

00:30:42.176 --> 00:30:42.556 A:middle
apps.

00:30:43.806 --> 00:30:45.406 A:middle
PencilKit released their API

00:30:45.406 --> 00:30:47.036 A:middle
this past week and they have a

00:30:47.036 --> 00:30:49.076 A:middle
Peek at Canvas view, which has a

00:30:49.076 --> 00:30:50.136 A:middle
Peek at Drawing, which is the

00:30:50.136 --> 00:30:51.156 A:middle
drawing data model.

00:30:51.536 --> 00:30:53.436 A:middle
You can extract the drawing out

00:30:53.436 --> 00:30:55.816 A:middle
of the Canvas view as a UI image

00:30:56.056 --> 00:30:57.506 A:middle
using that line of code.

00:30:57.506 --> 00:31:02.176 A:middle
And next, you can crop it using

00:30:57.506 --> 00:31:02.176 A:middle
And next, you can crop it using

00:31:02.436 --> 00:31:04.386 A:middle
again, API from PencilKit to

00:31:04.386 --> 00:31:05.786 A:middle
crop it down to the bounds of

00:31:05.786 --> 00:31:06.946 A:middle
the drawing where the user drew

00:31:06.946 --> 00:31:07.666 A:middle
their strokes.

00:31:08.136 --> 00:31:09.526 A:middle
And now that you have this

00:31:09.656 --> 00:31:12.066 A:middle
cropped, your image that is

00:31:12.126 --> 00:31:14.156 A:middle
ready to be consumed by the Core

00:31:14.156 --> 00:31:16.406 A:middle
ML model, you can use the Vision

00:31:16.406 --> 00:31:18.946 A:middle
API and that's all you need.

00:31:19.876 --> 00:31:23.686 A:middle
To recap, we started with some

00:31:23.686 --> 00:31:25.186 A:middle
drawings and their labels.

00:31:25.876 --> 00:31:28.486 A:middle
We interactively explored our

00:31:28.486 --> 00:31:28.866 A:middle
data.

00:31:28.866 --> 00:31:30.226 A:middle
We saw what the data looked

00:31:30.226 --> 00:31:30.496 A:middle
like.

00:31:31.606 --> 00:31:33.016 A:middle
Then we trained a model or

00:31:33.016 --> 00:31:34.196 A:middle
loaded it from the oven,

00:31:35.676 --> 00:31:38.296 A:middle
exported it to Core ML, and then

00:31:38.296 --> 00:31:39.746 A:middle
deployed using PencilKit and

00:31:39.746 --> 00:31:40.016 A:middle
Vision.

00:31:41.486 --> 00:31:42.786 A:middle
But I did miss one thing.

00:31:43.096 --> 00:31:44.476 A:middle
I did skip it on purpose.

00:31:45.456 --> 00:31:47.086 A:middle
I did skip evaluation and that's

00:31:47.086 --> 00:31:49.576 A:middle
a pretty important part of your

00:31:50.196 --> 00:31:50.786 A:middle
workflow.

00:31:51.306 --> 00:31:52.576 A:middle
And if you actually evaluate

00:31:52.576 --> 00:31:53.766 A:middle
your models and make them

00:31:53.766 --> 00:31:55.146 A:middle
better, you won't see errors

00:31:55.146 --> 00:31:56.216 A:middle
like you saw in the app today.

00:31:57.006 --> 00:31:58.276 A:middle
So with that, I'm going to

00:31:58.276 --> 00:31:59.986 A:middle
invite my colleague, Abhishek to

00:31:59.986 --> 00:32:01.206 A:middle
take us through an exciting

00:31:59.986 --> 00:32:01.206 A:middle
take us through an exciting

00:32:01.206 --> 00:32:02.356 A:middle
model evaluation journey.

00:32:02.496 --> 00:32:02.976 A:middle
Abhishek.

00:32:03.516 --> 00:32:08.226 A:middle
[ Applause ]

00:32:08.726 --> 00:32:11.136 A:middle
&gt;&gt; Thank you.

00:32:11.136 --> 00:32:12.396 A:middle
So today I'd like to talk to you

00:32:12.396 --> 00:32:15.216 A:middle
about Model Evaluation and why

00:32:15.216 --> 00:32:16.636 A:middle
it's really important in

00:32:16.636 --> 00:32:18.416 A:middle
building the best possible user

00:32:18.416 --> 00:32:19.206 A:middle
experiences.

00:32:19.826 --> 00:32:23.856 A:middle
But first, let's understand how

00:32:23.856 --> 00:32:25.656 A:middle
evaluation works.

00:32:27.046 --> 00:32:28.036 A:middle
Let's take the Drawing

00:32:28.036 --> 00:32:29.446 A:middle
Classifier model we trained in

00:32:29.446 --> 00:32:30.276 A:middle
the previous demo.

00:32:31.076 --> 00:32:32.586 A:middle
And if we pass a drawing through

00:32:32.586 --> 00:32:34.006 A:middle
it, we get a prediction.

00:32:35.546 --> 00:32:38.086 A:middle
Using ground truth data, we can

00:32:38.086 --> 00:32:39.706 A:middle
identify whether this prediction

00:32:39.706 --> 00:32:41.906 A:middle
is correct or sometimes

00:32:42.466 --> 00:32:43.196 A:middle
incorrect.

00:32:43.876 --> 00:32:45.686 A:middle
But using a single data point to

00:32:45.686 --> 00:32:48.186 A:middle
evaluate a model doesn't give us

00:32:48.186 --> 00:32:49.716 A:middle
a full picture of what the model

00:32:49.716 --> 00:32:50.136 A:middle
is doing.

00:32:50.606 --> 00:32:51.606 A:middle
So what do we do?

00:32:52.506 --> 00:32:54.146 A:middle
Well, we use more data.

00:32:55.496 --> 00:32:57.046 A:middle
This is our test data set.

00:32:58.276 --> 00:33:00.206 A:middle
We can run the model across the

00:32:58.276 --> 00:33:00.206 A:middle
We can run the model across the

00:33:00.206 --> 00:33:02.766 A:middle
data and get correct and

00:33:02.766 --> 00:33:04.396 A:middle
incorrect predictions for each

00:33:04.396 --> 00:33:05.116 A:middle
of the drawings.

00:33:06.476 --> 00:33:07.776 A:middle
By grouping the drawings

00:33:07.846 --> 00:33:09.156 A:middle
together in correct and

00:33:09.156 --> 00:33:11.676 A:middle
incorrect groups we get a sense

00:33:11.676 --> 00:33:12.786 A:middle
for how well the model is

00:33:12.836 --> 00:33:13.296 A:middle
performing.

00:33:14.716 --> 00:33:16.516 A:middle
This is analogous to the metric

00:33:16.516 --> 00:33:18.436 A:middle
of accuracy, a measure of the

00:33:18.436 --> 00:33:21.096 A:middle
correct predicted drawings over

00:33:21.096 --> 00:33:22.406 A:middle
the total number of drawings in

00:33:22.406 --> 00:33:22.936 A:middle
our data set.

00:33:23.496 --> 00:33:25.906 A:middle
And there are other metrics we

00:33:25.906 --> 00:33:27.746 A:middle
can use to help us quantify our

00:33:27.746 --> 00:33:28.836 A:middle
model's performance.

00:33:30.256 --> 00:33:32.226 A:middle
To access these in Turi Create,

00:33:32.226 --> 00:33:33.996 A:middle
simply call the evaluate method

00:33:34.586 --> 00:33:35.906 A:middle
available to use on the model

00:33:35.906 --> 00:33:38.146 A:middle
object and pass in that test

00:33:38.186 --> 00:33:39.326 A:middle
data set.

00:33:39.996 --> 00:33:41.856 A:middle
A dictionary of these metrics

00:33:41.896 --> 00:33:43.866 A:middle
will then be returned to now

00:33:43.866 --> 00:33:47.976 A:middle
evaluate our model.

00:33:48.256 --> 00:33:51.196 A:middle
But this actually doesn't tell

00:33:51.196 --> 00:33:52.266 A:middle
us the whole story.

00:33:53.426 --> 00:33:55.786 A:middle
For instance, take a model with

00:33:55.786 --> 00:33:57.576 A:middle
an accuracy of 85 percent.

00:33:58.366 --> 00:33:59.586 A:middle
Initially that seems pretty good

00:33:59.586 --> 00:34:00.236 A:middle
to us, doesn't it?

00:33:59.586 --> 00:34:00.236 A:middle
to us, doesn't it?

00:34:01.486 --> 00:34:04.166 A:middle
Well, if we dig down into the

00:34:04.246 --> 00:34:06.996 A:middle
per class accuracy, we see that

00:34:06.996 --> 00:34:08.856 A:middle
the class of four has a much

00:34:08.856 --> 00:34:10.606 A:middle
lower accuracy than the rest of

00:34:10.606 --> 00:34:11.536 A:middle
the other classes.

00:34:12.116 --> 00:34:14.656 A:middle
And this is a case that you

00:34:14.656 --> 00:34:16.025 A:middle
usually might run into.

00:34:17.485 --> 00:34:19.755 A:middle
Well, what's causing this low

00:34:19.755 --> 00:34:20.335 A:middle
accuracy?

00:34:20.946 --> 00:34:22.596 A:middle
One thing might be that there

00:34:22.596 --> 00:34:24.436 A:middle
might be a low number of

00:34:24.436 --> 00:34:26.206 A:middle
examples present for that

00:34:26.206 --> 00:34:27.346 A:middle
particular class.

00:34:28.295 --> 00:34:30.146 A:middle
To correct for this we may want

00:34:30.146 --> 00:34:31.126 A:middle
to add more examples.

00:34:31.766 --> 00:34:34.226 A:middle
But there are other things that

00:34:34.226 --> 00:34:34.946 A:middle
can be going on.

00:34:36.085 --> 00:34:38.376 A:middle
For instance, we've noticed that

00:34:38.376 --> 00:34:40.186 A:middle
in some data sets the

00:34:40.186 --> 00:34:41.466 A:middle
annotations are incorrect.

00:34:42.116 --> 00:34:45.136 A:middle
In the drawing to your left, you

00:34:45.136 --> 00:34:46.556 A:middle
see that the model has predicted

00:34:46.876 --> 00:34:48.326 A:middle
this drawing to be one, but the

00:34:48.326 --> 00:34:49.446 A:middle
annotation is seven.

00:34:50.596 --> 00:34:52.016 A:middle
And when visually inspecting

00:34:52.016 --> 00:34:53.926 A:middle
this drawing, we can see that

00:34:53.926 --> 00:34:55.716 A:middle
the annotation probably should

00:34:55.716 --> 00:34:56.166 A:middle
be one.

00:34:57.276 --> 00:34:58.816 A:middle
So we can go and correct the

00:34:58.906 --> 00:34:59.596 A:middle
annotation.

00:35:00.666 --> 00:35:02.306 A:middle
But in other instances such as

00:35:02.306 --> 00:35:04.466 A:middle
the one to your right, the model

00:35:04.466 --> 00:35:05.906 A:middle
has predicted it to be four and

00:35:05.906 --> 00:35:08.106 A:middle
the annotation is one but it's

00:35:08.106 --> 00:35:10.386 A:middle
unclear whether the annotation

00:35:10.476 --> 00:35:11.996 A:middle
or the model is incorrect.

00:35:14.676 --> 00:35:16.256 A:middle
There also may be systematic

00:35:16.256 --> 00:35:17.776 A:middle
biases present in your model.

00:35:18.206 --> 00:35:19.886 A:middle
For instance, in this example,

00:35:20.506 --> 00:35:22.026 A:middle
the model has predicted sevens

00:35:22.026 --> 00:35:24.736 A:middle
with bars to be incorrect as

00:35:24.866 --> 00:35:27.586 A:middle
three but correctly predicts the

00:35:27.586 --> 00:35:28.646 A:middle
sevens without bars.

00:35:28.716 --> 00:35:33.566 A:middle
And to help you identify these

00:35:33.636 --> 00:35:35.766 A:middle
issues, we've created an

00:35:35.766 --> 00:35:37.436 A:middle
interactive visualization tool.

00:35:37.436 --> 00:35:40.546 A:middle
Let me show you how it works.

00:35:40.706 --> 00:35:42.806 A:middle
Alright. So let's go back to the

00:35:42.806 --> 00:35:44.266 A:middle
Jupyter Notebook that Shantanu

00:35:44.266 --> 00:35:46.256 A:middle
was showing us and load in a

00:35:46.366 --> 00:35:48.816 A:middle
test data set that we can use to

00:35:48.816 --> 00:35:49.736 A:middle
evaluate our model.

00:35:57.436 --> 00:35:58.846 A:middle
Now that we've loaded in our

00:35:58.846 --> 00:36:00.546 A:middle
test data set, let's call that

00:35:58.846 --> 00:36:00.546 A:middle
test data set, let's call that

00:36:00.546 --> 00:36:06.816 A:middle
evaluate method passing in that

00:36:06.936 --> 00:36:11.696 A:middle
test data set.

00:36:11.916 --> 00:36:13.886 A:middle
So now that we have our metrics

00:36:13.976 --> 00:36:16.776 A:middle
object, we can simply call the

00:36:16.776 --> 00:36:18.856 A:middle
explorer method on that metric's

00:36:18.936 --> 00:36:21.766 A:middle
object to now look at our

00:36:21.766 --> 00:36:23.006 A:middle
interactive visualization.

00:36:23.636 --> 00:36:27.356 A:middle
And as you can see, a window

00:36:27.356 --> 00:36:30.736 A:middle
popped up and it has three

00:36:30.736 --> 00:36:33.666 A:middle
distinct sections, an Overview

00:36:33.666 --> 00:36:35.436 A:middle
section, which gives us the

00:36:35.436 --> 00:36:37.346 A:middle
overall accuracy of the model as

00:36:37.346 --> 00:36:38.916 A:middle
well as the number of iterations

00:36:39.456 --> 00:36:40.756 A:middle
in the model that we've trained,

00:36:40.856 --> 00:36:42.186 A:middle
the Drawing Classifier model.

00:36:43.396 --> 00:36:45.426 A:middle
The second section is a Per

00:36:45.426 --> 00:36:47.466 A:middle
Class breakdown of the metrics

00:36:47.786 --> 00:36:49.216 A:middle
as well as a couple of example

00:36:49.216 --> 00:36:51.396 A:middle
images that have been correctly

00:36:51.396 --> 00:36:52.596 A:middle
been predicted by the model.

00:36:53.596 --> 00:36:55.956 A:middle
And lastly, there's an Error

00:36:55.956 --> 00:36:57.826 A:middle
section that shows us all of the

00:36:57.826 --> 00:37:01.086 A:middle
errors that the model has made.

00:36:57.826 --> 00:37:01.086 A:middle
errors that the model has made.

00:37:01.286 --> 00:37:02.926 A:middle
So let's take a look at the

00:37:03.016 --> 00:37:04.446 A:middle
first class, negative four.

00:37:04.776 --> 00:37:06.816 A:middle
We see that class has an

00:37:06.816 --> 00:37:08.466 A:middle
accuracy of 20 percent.

00:37:09.646 --> 00:37:11.486 A:middle
If we click on it, we see that

00:37:11.486 --> 00:37:13.286 A:middle
there are actually four errors

00:37:13.476 --> 00:37:14.636 A:middle
that have been made by the

00:37:14.636 --> 00:37:14.926 A:middle
model.

00:37:15.966 --> 00:37:17.276 A:middle
But something else that we see

00:37:17.276 --> 00:37:18.826 A:middle
is that the number of elements

00:37:18.826 --> 00:37:20.366 A:middle
that we've tested is five.

00:37:21.036 --> 00:37:22.706 A:middle
And that's a pretty low number.

00:37:23.306 --> 00:37:25.676 A:middle
So to kind of determine whether

00:37:25.676 --> 00:37:27.036 A:middle
the model is performing

00:37:27.036 --> 00:37:29.006 A:middle
improperly on this class or

00:37:29.006 --> 00:37:30.676 A:middle
simply we have a low number of

00:37:30.676 --> 00:37:33.126 A:middle
examples that we're testing, we

00:37:33.126 --> 00:37:34.466 A:middle
might want to go back and add

00:37:34.516 --> 00:37:36.136 A:middle
more examples to this class to

00:37:36.136 --> 00:37:38.026 A:middle
get a better determination of

00:37:38.026 --> 00:37:39.636 A:middle
whether the model is performing

00:37:39.636 --> 00:37:42.676 A:middle
incorrectly or simply we don't

00:37:42.706 --> 00:37:43.766 A:middle
have enough examples.

00:37:44.366 --> 00:37:48.006 A:middle
Let's go to class of negative

00:37:49.696 --> 00:37:49.786 A:middle
two.

00:37:50.006 --> 00:37:51.596 A:middle
We see something that stands out

00:37:51.596 --> 00:37:53.106 A:middle
when we filter by this class.

00:37:53.606 --> 00:37:55.506 A:middle
There are 11 incorrect

00:37:55.506 --> 00:37:57.156 A:middle
predictions of the same type,

00:37:58.176 --> 00:37:59.556 A:middle
meaning that the actual

00:37:59.556 --> 00:38:01.046 A:middle
annotation is negative two, but

00:37:59.556 --> 00:38:01.046 A:middle
annotation is negative two, but

00:38:01.046 --> 00:38:02.566 A:middle
the model has predicted all of

00:38:02.566 --> 00:38:04.026 A:middle
these examples to be negative

00:38:04.026 --> 00:38:04.316 A:middle
seven.

00:38:05.196 --> 00:38:06.396 A:middle
But when we look through these

00:38:06.396 --> 00:38:07.396 A:middle
examples that have been

00:38:07.396 --> 00:38:09.896 A:middle
misclassified, we see that some

00:38:09.896 --> 00:38:11.536 A:middle
of these examples are, in fact,

00:38:11.596 --> 00:38:12.216 A:middle
negative seven.

00:38:12.736 --> 00:38:14.116 A:middle
And this is a case where the

00:38:14.116 --> 00:38:16.006 A:middle
data set has some misannotated

00:38:16.046 --> 00:38:16.576 A:middle
data points.

00:38:17.306 --> 00:38:19.196 A:middle
So we might want to go back and

00:38:19.196 --> 00:38:21.036 A:middle
correct those annotations to get

00:38:21.036 --> 00:38:22.296 A:middle
a better indication of our

00:38:22.296 --> 00:38:23.426 A:middle
model's performance.

00:38:23.976 --> 00:38:27.956 A:middle
We've also included a number of

00:38:27.956 --> 00:38:30.546 A:middle
other metrics such as F1 Score

00:38:30.546 --> 00:38:32.266 A:middle
Precision and Recall which may

00:38:32.266 --> 00:38:33.986 A:middle
be more relevant to your use

00:38:33.986 --> 00:38:35.756 A:middle
cases when evaluating your

00:38:35.756 --> 00:38:36.126 A:middle
models.

00:38:38.536 --> 00:38:42.826 A:middle
So, a recap.

00:38:44.556 --> 00:38:45.776 A:middle
We now allow you to

00:38:45.776 --> 00:38:47.456 A:middle
interactively visualize model

00:38:47.506 --> 00:38:47.946 A:middle
predictions.

00:38:49.496 --> 00:38:51.256 A:middle
This can help us easily spot

00:38:51.556 --> 00:38:53.346 A:middle
annotation errors as well as

00:38:53.346 --> 00:38:55.336 A:middle
identify those systematic biases

00:38:55.336 --> 00:38:56.646 A:middle
we talked about.

00:38:57.936 --> 00:38:59.416 A:middle
But now that we've identified

00:38:59.416 --> 00:39:01.516 A:middle
these issues, what steps can we

00:38:59.416 --> 00:39:01.516 A:middle
these issues, what steps can we

00:39:01.586 --> 00:39:03.816 A:middle
take to improve the model?

00:39:03.816 --> 00:39:07.446 A:middle
Well, let's take a look at our

00:39:07.446 --> 00:39:07.876 A:middle
pipeline.

00:39:09.836 --> 00:39:12.336 A:middle
First, we have our test data

00:39:12.336 --> 00:39:12.586 A:middle
set.

00:39:14.006 --> 00:39:15.456 A:middle
We've passed it through the

00:39:15.456 --> 00:39:17.006 A:middle
Drawing Classifier model and

00:39:17.006 --> 00:39:18.586 A:middle
used our interactive

00:39:18.586 --> 00:39:20.316 A:middle
visualization tool to identify

00:39:20.406 --> 00:39:20.906 A:middle
some issues.

00:39:22.746 --> 00:39:25.416 A:middle
And we may want to add more

00:39:25.416 --> 00:39:27.426 A:middle
examples to correct for some of

00:39:27.426 --> 00:39:28.096 A:middle
these issues.

00:39:29.556 --> 00:39:31.136 A:middle
We also may want to remove

00:39:31.136 --> 00:39:34.236 A:middle
incorrectly trained data as well

00:39:34.236 --> 00:39:36.346 A:middle
as maybe update incorrect

00:39:36.346 --> 00:39:37.056 A:middle
annotations.

00:39:37.476 --> 00:39:39.856 A:middle
In Turi Create, we enable you to

00:39:39.856 --> 00:39:42.806 A:middle
load data as well as sort and

00:39:42.846 --> 00:39:44.576 A:middle
filter data if you want to

00:39:44.576 --> 00:39:46.716 A:middle
remove incorrect training data.

00:39:48.496 --> 00:39:50.196 A:middle
If you want to add more data,

00:39:51.046 --> 00:39:52.616 A:middle
simply use the append command.

00:39:53.266 --> 00:39:57.746 A:middle
And new in Turi Create 6.0 we've

00:39:57.746 --> 00:40:00.976 A:middle
introduced an annotation tool.

00:39:57.746 --> 00:40:00.976 A:middle
introduced an annotation tool.

00:40:01.046 --> 00:40:03.176 A:middle
To use it, pass in the data set

00:40:03.176 --> 00:40:05.646 A:middle
that you want to annotate, and a

00:40:05.646 --> 00:40:07.426 A:middle
GUI pops up with two distinct

00:40:07.426 --> 00:40:07.856 A:middle
sections.

00:40:08.846 --> 00:40:10.576 A:middle
To your left, you can see the

00:40:10.576 --> 00:40:11.756 A:middle
image that you want to annotate

00:40:11.806 --> 00:40:13.336 A:middle
and to your right you see a

00:40:13.336 --> 00:40:14.066 A:middle
labels column.

00:40:15.466 --> 00:40:17.436 A:middle
You can add labels and annotate

00:40:17.436 --> 00:40:18.286 A:middle
your data points.

00:40:19.786 --> 00:40:21.576 A:middle
But we also recognize that if

00:40:21.576 --> 00:40:22.976 A:middle
you're going through a large

00:40:23.026 --> 00:40:25.796 A:middle
data set it may be annoying to

00:40:25.866 --> 00:40:29.366 A:middle
kind of spend that time to go

00:40:29.426 --> 00:40:30.546 A:middle
through the entire data set.

00:40:30.546 --> 00:40:31.426 A:middle
So we've included image

00:40:31.426 --> 00:40:32.366 A:middle
similarity and we're going to

00:40:32.406 --> 00:40:34.066 A:middle
help you quickly go through your

00:40:34.066 --> 00:40:34.526 A:middle
data set.

00:40:35.776 --> 00:40:37.996 A:middle
We've also included a Table view

00:40:38.066 --> 00:40:39.676 A:middle
that allows you to scroll

00:40:39.676 --> 00:40:41.336 A:middle
through your data set, look at

00:40:41.336 --> 00:40:43.376 A:middle
annotations, maybe identify

00:40:43.376 --> 00:40:44.806 A:middle
those systematic biases we

00:40:44.866 --> 00:40:47.076 A:middle
talked about, and add multiple

00:40:47.076 --> 00:40:48.936 A:middle
annotations to multiple images.

00:40:49.516 --> 00:40:57.546 A:middle
[ Applause ]

00:40:58.046 --> 00:40:59.546 A:middle
So a summary of this session.

00:41:00.206 --> 00:41:03.416 A:middle
Sam and Shantanu showed us the

00:41:03.416 --> 00:41:05.616 A:middle
new One-Shot Object Detector

00:41:05.616 --> 00:41:06.046 A:middle
Toolkit.

00:41:06.946 --> 00:41:08.616 A:middle
Shantanu upped Sam's game with a

00:41:08.616 --> 00:41:10.656 A:middle
Three Card Poker app and was

00:41:10.656 --> 00:41:12.586 A:middle
able to build a robust model

00:41:12.586 --> 00:41:16.566 A:middle
with only one example per class.

00:41:16.736 --> 00:41:18.086 A:middle
Next, we looked at the new

00:41:18.086 --> 00:41:19.896 A:middle
Drawing Classifier ToolKit.

00:41:20.516 --> 00:41:22.716 A:middle
In it, we saw the new

00:41:22.716 --> 00:41:24.076 A:middle
integration with the Apple

00:41:24.206 --> 00:41:24.536 A:middle
Pencil.

00:41:26.716 --> 00:41:28.986 A:middle
The interactive visualization

00:41:29.296 --> 00:41:32.216 A:middle
tool showed us how to evaluate

00:41:32.216 --> 00:41:34.886 A:middle
models interactively and

00:41:34.946 --> 00:41:37.046 A:middle
hopefully showed us a process

00:41:37.176 --> 00:41:38.966 A:middle
for building better experiences

00:41:39.166 --> 00:41:39.816 A:middle
for our users.

00:41:40.406 --> 00:41:43.326 A:middle
And finally, we introduced a new

00:41:43.326 --> 00:41:45.136 A:middle
annotation tool that not only

00:41:45.136 --> 00:41:46.876 A:middle
allows you to label data, but

00:41:46.876 --> 00:41:48.006 A:middle
quickly go through your data

00:41:48.006 --> 00:41:49.246 A:middle
sets with the use of image

00:41:49.246 --> 00:41:49.796 A:middle
similarity.

00:41:50.816 --> 00:41:52.656 A:middle
Please install Turicreate.

00:41:52.946 --> 00:41:54.016 A:middle
We hope you've enjoyed this

00:41:54.016 --> 00:41:56.156 A:middle
session and join us in the labs

00:41:56.246 --> 00:41:57.366 A:middle
at 2:00 if you want to see any

00:41:57.366 --> 00:41:58.776 A:middle
of the demos or have any

00:41:58.836 --> 00:41:59.456 A:middle
questions.

00:42:00.726 --> 00:42:01.886 A:middle
We encourage you to check out

00:42:01.886 --> 00:42:03.066 A:middle
these related sessions.

00:42:04.536 --> 00:42:05.426 A:middle
Thank you for coming to WWDC

00:42:05.426 --> 00:42:05.976 A:middle
2019.

00:42:06.516 --> 00:42:09.500 A:middle
[ Applause ]
