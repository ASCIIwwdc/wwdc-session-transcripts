WEBVTT

00:00:07.516 --> 00:00:19.286 A:middle
[ Music ]

00:00:19.786 --> 00:00:22.776 A:middle
&gt;&gt; Hi. I'm Henry Mason,
an engineer working

00:00:22.776 --> 00:00:24.366 A:middle
on speech recognition for Siri.

00:00:25.486 --> 00:00:28.306 A:middle
Today we're incredibly excited
to announce a brand new API

00:00:29.006 --> 00:00:31.376 A:middle
which will let our speech
recognition solve problems

00:00:31.376 --> 00:00:32.386 A:middle
for your apps too.

00:00:35.246 --> 00:00:37.636 A:middle
A quick overview of what
speech recognition is.

00:00:38.286 --> 00:00:40.616 A:middle
Speech recognition is
the automatic process

00:00:40.616 --> 00:00:43.486 A:middle
of converting audio of
human speech into text.

00:00:44.226 --> 00:00:46.276 A:middle
It depends on the
language of the speech.

00:00:46.536 --> 00:00:47.976 A:middle
English will be recognized
differently

00:00:47.976 --> 00:00:49.136 A:middle
than Chinese, for example.

00:00:50.196 --> 00:00:52.346 A:middle
On iOS, most people
think of Siri

00:00:52.506 --> 00:00:55.376 A:middle
but speech recognition is also
useful for many other tasks.

00:00:56.456 --> 00:00:58.776 A:middle
Since Siri was released
with iPhone 4S,

00:00:59.166 --> 00:01:01.606 A:middle
iOS has also featured
keyboard dictation.

00:00:59.166 --> 00:01:01.606 A:middle
iOS has also featured
keyboard dictation.

00:01:02.776 --> 00:01:04.176 A:middle
That little microphone
button next

00:01:04.176 --> 00:01:07.826 A:middle
to your iOS keyboard spacebar
triggers speech recognition

00:01:07.826 --> 00:01:10.076 A:middle
for any UI kit text input.

00:01:11.116 --> 00:01:13.726 A:middle
Tens of thousands of apps
every day use this feature.

00:01:14.266 --> 00:01:16.176 A:middle
In fact, about a third
of all requests come

00:01:16.176 --> 00:01:17.286 A:middle
from third party apps.

00:01:18.356 --> 00:01:19.896 A:middle
It's extremely easy to use.

00:01:20.236 --> 00:01:23.356 A:middle
It handles audio recording
and recording interruption.

00:01:23.476 --> 00:01:25.216 A:middle
It displays a user interface.

00:01:25.686 --> 00:01:28.106 A:middle
It doesn't require you to write
anymore code than you would

00:01:28.106 --> 00:01:29.686 A:middle
to support any text input.

00:01:30.666 --> 00:01:32.446 A:middle
And it's been available
since iOS 5.

00:01:36.026 --> 00:01:38.326 A:middle
But with its simplicity
comes many limitations.

00:01:40.116 --> 00:01:42.376 A:middle
It often doesn't make sense
for your user interface

00:01:42.376 --> 00:01:43.576 A:middle
to require a keyboard.

00:01:44.526 --> 00:01:47.146 A:middle
You can't control when the
audio recording starts.

00:01:47.736 --> 00:01:49.876 A:middle
There's no control over
which language is used.

00:01:49.996 --> 00:01:52.386 A:middle
It just happens to use the
system's keyboard language.

00:01:53.166 --> 00:01:54.506 A:middle
There isn't even a way to know

00:01:54.506 --> 00:01:56.136 A:middle
if the dictation
button is available.

00:01:58.176 --> 00:02:00.596 A:middle
The default audio recording
might not make sense

00:01:58.176 --> 00:02:00.596 A:middle
The default audio recording
might not make sense

00:02:00.596 --> 00:02:03.596 A:middle
for your use case and you
may want more information

00:02:03.596 --> 00:02:06.726 A:middle
than just text.

00:02:07.166 --> 00:02:09.186 A:middle
So now in iOS 10,

00:02:09.186 --> 00:02:11.346 A:middle
we're introducing a
new speech framework.

00:02:14.286 --> 00:02:17.246 A:middle
It uses the same underlying
technology that we use

00:02:17.296 --> 00:02:18.536 A:middle
in Siri and Dictation.

00:02:19.576 --> 00:02:21.606 A:middle
It provides fast
and accurate results

00:02:21.936 --> 00:02:24.166 A:middle
which are transparently
customized to the user

00:02:24.666 --> 00:02:26.596 A:middle
without you having to
collect any user data.

00:02:29.106 --> 00:02:31.576 A:middle
The framework also
provides more information

00:02:33.356 --> 00:02:35.136 A:middle
about recognition
than just text.

00:02:36.416 --> 00:02:39.066 A:middle
For example, we also provide
alternative interpretations

00:02:39.066 --> 00:02:41.666 A:middle
of what your users might
have said, confidence levels,

00:02:41.666 --> 00:02:42.866 A:middle
and timing information.

00:02:44.166 --> 00:02:46.316 A:middle
Audio for the API
can be provided

00:02:46.316 --> 00:02:47.856 A:middle
from either pre-recorded files

00:02:47.966 --> 00:02:49.606 A:middle
or a live source
like a microphone.

00:02:52.086 --> 00:02:55.616 A:middle
iOS 10 supports over 50
languages and dialects

00:02:55.616 --> 00:02:56.976 A:middle
from Arabic to Vietnamese.

00:02:57.206 --> 00:03:01.256 A:middle
Any device which runs
iOS 10 is supported.

00:02:57.206 --> 00:03:01.256 A:middle
Any device which runs
iOS 10 is supported.

00:03:03.006 --> 00:03:06.326 A:middle
The speech recognition API
typically does its heavy lifting

00:03:06.326 --> 00:03:09.376 A:middle
on our big servers which
requires an internet connection.

00:03:10.296 --> 00:03:14.976 A:middle
However, some newer devices do
support speech recognition all

00:03:14.976 --> 00:03:15.476 A:middle
the time.

00:03:16.386 --> 00:03:18.906 A:middle
We provide an availability
API to determine

00:03:18.906 --> 00:03:21.506 A:middle
if a given language is
available at the moment.

00:03:21.506 --> 00:03:23.056 A:middle
Use this rather than looking

00:03:23.056 --> 00:03:25.226 A:middle
for internet connectivity
explicitly.

00:03:28.356 --> 00:03:30.856 A:middle
Since speech recognition
requires transmitting the user's

00:03:30.856 --> 00:03:32.096 A:middle
audio over the internet,

00:03:32.716 --> 00:03:34.796 A:middle
the user must explicitly
provide permission

00:03:34.796 --> 00:03:37.766 A:middle
to your application before
speech recognition can be used.

00:03:40.846 --> 00:03:42.196 A:middle
There are four major steps

00:03:42.196 --> 00:03:44.206 A:middle
to adopting speech
recognition in your app.

00:03:46.726 --> 00:03:48.756 A:middle
First, provide a
usage description

00:03:48.756 --> 00:03:50.116 A:middle
in your app's info.plist.

00:03:51.606 --> 00:03:54.636 A:middle
For example, your
camera app, Phromage,

00:03:55.136 --> 00:03:57.306 A:middle
might have used a
usage description

00:03:57.506 --> 00:04:01.536 A:middle
for speech recognition
of this will allow you

00:03:57.506 --> 00:04:01.536 A:middle
for speech recognition
of this will allow you

00:04:01.736 --> 00:04:03.936 A:middle
to take a photo just
by saying cheese.

00:04:05.966 --> 00:04:09.546 A:middle
Second, request authorization
using the request authorization

00:04:09.546 --> 00:04:10.236 A:middle
class method.

00:04:11.536 --> 00:04:14.146 A:middle
The explanation you provided
earlier will be presented

00:04:14.426 --> 00:04:16.596 A:middle
to the user in a
familiar dialogue.

00:04:16.596 --> 00:04:19.346 A:middle
And the user will be able
to decide if they want

00:04:19.346 --> 00:04:21.495 A:middle
to provide your app
to speech recognition.

00:04:23.196 --> 00:04:25.336 A:middle
Next create a speech
recognition request.

00:04:27.126 --> 00:04:29.156 A:middle
If you already have
recorded audio file,

00:04:29.636 --> 00:04:32.606 A:middle
use the
SFSpeechURLRecognitionRequest

00:04:32.606 --> 00:04:33.086 A:middle
class.

00:04:34.066 --> 00:04:34.946 A:middle
Otherwise, you'll want

00:04:34.946 --> 00:04:38.476 A:middle
to use the SFSpeechAudioBuffer
RecognitionRequest class.

00:04:40.836 --> 00:04:42.806 A:middle
Finally hand the
recognition request

00:04:42.806 --> 00:04:45.446 A:middle
to an SFSpeech recognizer
to begin recognition.

00:04:46.456 --> 00:04:49.066 A:middle
You can optionally hold onto
the returned recognition task

00:04:49.336 --> 00:04:50.836 A:middle
which can useful for monitoring

00:04:51.136 --> 00:04:52.856 A:middle
and controlling recognition
progress.

00:04:56.356 --> 00:04:58.256 A:middle
Let's see what this
all looks like in code.

00:04:59.286 --> 00:05:01.546 A:middle
We'll assume we've already
updated our info.plist

00:04:59.286 --> 00:05:01.546 A:middle
We'll assume we've already
updated our info.plist

00:05:01.546 --> 00:05:04.726 A:middle
with an accurate description
of how will it be used.

00:05:05.066 --> 00:05:07.496 A:middle
Our next step is to
request authorization.

00:05:08.486 --> 00:05:10.606 A:middle
It may be a good idea
to wait to do this

00:05:10.606 --> 00:05:12.886 A:middle
until the user has invoked
a feature of your app

00:05:12.886 --> 00:05:14.366 A:middle
which depends on
speech recognition.

00:05:14.866 --> 00:05:20.036 A:middle
The request authorization class
method takes the completion

00:05:20.036 --> 00:05:23.426 A:middle
handler which doesn't guarantee
a particular execution context.

00:05:24.596 --> 00:05:26.976 A:middle
Apps will typically want to
dispatch to the main queue

00:05:27.246 --> 00:05:29.046 A:middle
if they're going to do
something like enable

00:05:29.046 --> 00:05:31.006 A:middle
or disable a user
interface button.

00:05:33.636 --> 00:05:37.596 A:middle
If your authorization handler
has given authorize status,

00:05:38.116 --> 00:05:39.896 A:middle
you should be ready
to start recognition.

00:05:41.646 --> 00:05:44.296 A:middle
If not, recognition won't
be available to your app.

00:05:45.586 --> 00:05:48.566 A:middle
It's important to gracefully
disable necessary functionality

00:05:48.646 --> 00:05:50.106 A:middle
when the user makes
this decision

00:05:50.886 --> 00:05:52.946 A:middle
or when the device is
otherwise restricted

00:05:52.946 --> 00:05:54.506 A:middle
from accessing speech
recognition.

00:05:55.496 --> 00:05:57.436 A:middle
Authorization can
be changed later

00:05:57.466 --> 00:05:59.156 A:middle
in the device's privacy
settings.

00:06:01.286 --> 00:06:04.066 A:middle
Let's see what it looks like
to recognize a prerecorded

00:06:04.066 --> 00:06:04.796 A:middle
audio file.

00:06:05.956 --> 00:06:07.946 A:middle
We'll assume we already
have a file url.

00:06:09.886 --> 00:06:12.526 A:middle
Recognition requires
a speech recognizer

00:06:12.716 --> 00:06:14.716 A:middle
which only recognizes
a single language.

00:06:15.536 --> 00:06:19.826 A:middle
The default initializer for
SFSpeechRecognizer is failable.

00:06:20.336 --> 00:06:23.936 A:middle
So it'll return nil if the
locale is not supported.

00:06:24.906 --> 00:06:27.726 A:middle
The default initializer uses
device's current locale.

00:06:29.866 --> 00:06:32.236 A:middle
In this function, we'll just
return one in this case.

00:06:34.586 --> 00:06:36.836 A:middle
While this speech
recognition may be supported,

00:06:37.016 --> 00:06:39.316 A:middle
it may not be available,
perhaps due

00:06:39.316 --> 00:06:40.846 A:middle
to having no internet
connectivity.

00:06:41.966 --> 00:06:45.636 A:middle
Use the is available property on
your recognizer to monitor this.

00:06:48.916 --> 00:06:50.686 A:middle
Now we create a recognition
request

00:06:50.686 --> 00:06:52.916 A:middle
with the recorded
file's url and give

00:06:52.916 --> 00:06:56.976 A:middle
that to the recognition task
method of the recognizer.

00:07:02.046 --> 00:07:03.906 A:middle
This method takes
completion handler

00:07:03.956 --> 00:07:06.366 A:middle
with two optional
arguments, result and error.

00:07:07.696 --> 00:07:10.706 A:middle
If result is nil, that
means recognition has failed

00:07:10.706 --> 00:07:11.456 A:middle
for some reason.

00:07:12.086 --> 00:07:14.106 A:middle
Check the error parameter
for an explanation.

00:07:15.666 --> 00:07:18.896 A:middle
Otherwise, we can read the
speech we recognize so far

00:07:19.306 --> 00:07:20.356 A:middle
by looking at results.

00:07:21.706 --> 00:07:24.916 A:middle
Note that the completion handler
may be called more than once

00:07:25.326 --> 00:07:27.136 A:middle
as speech is recognized
incrementally.

00:07:28.256 --> 00:07:30.506 A:middle
You can tell the
recognition is finished

00:07:30.506 --> 00:07:33.746 A:middle
by checking the is final
property of the result.

00:07:34.656 --> 00:07:37.386 A:middle
Here we'll just print the
text of the final recognition.

00:07:43.926 --> 00:07:46.876 A:middle
Recognizing live audio from
the device's microphone is very

00:07:46.876 --> 00:07:49.396 A:middle
similar but requires
a few changes.

00:07:50.486 --> 00:07:53.176 A:middle
We'll make an audio buffer
recognition request instead.

00:07:53.926 --> 00:07:55.486 A:middle
This allows us to
provide a sequence

00:07:55.486 --> 00:07:58.386 A:middle
of in memory audio buffers
instead of a file on disc.

00:07:59.696 --> 00:08:03.316 A:middle
Here we'll use AVAudioEngine to
get a stream of audio buffers.

00:07:59.696 --> 00:08:03.316 A:middle
Here we'll use AVAudioEngine to
get a stream of audio buffers.

00:08:04.946 --> 00:08:06.306 A:middle
Then append them to the request.

00:08:07.456 --> 00:08:09.896 A:middle
Note that it's totally okay
to append audio buffers

00:08:09.896 --> 00:08:11.906 A:middle
to a recognition
request both before

00:08:11.906 --> 00:08:13.376 A:middle
and after starting recognition.

00:08:17.346 --> 00:08:20.596 A:middle
One difference here is that
we no longer ignore the return

00:08:20.596 --> 00:08:22.616 A:middle
value of the recognition
task method.

00:08:23.466 --> 00:08:25.616 A:middle
Instead we store it in
a variable property.

00:08:26.366 --> 00:08:27.406 A:middle
We'll see why in a moment.

00:08:28.626 --> 00:08:32.696 A:middle
When we're done recording,
we need to inform the request

00:08:32.696 --> 00:08:35.775 A:middle
that no more audio is coming so
that it can finish recognition.

00:08:37.025 --> 00:08:39.046 A:middle
Use the end audio
method to do this.

00:08:39.846 --> 00:08:42.076 A:middle
But what if the user
cancels our recording

00:08:42.076 --> 00:08:43.885 A:middle
or the audio recording
gets interrupted?

00:08:44.796 --> 00:08:47.236 A:middle
In this case, we really
don't care about the results

00:08:47.416 --> 00:08:49.686 A:middle
and we should free up any
resources still being used

00:08:49.686 --> 00:08:50.746 A:middle
by speech recognition.

00:08:52.786 --> 00:08:54.996 A:middle
Just cancel the recognition
task that we started --

00:08:55.196 --> 00:08:56.646 A:middle
we stored when we
started recognition.

00:08:57.446 --> 00:08:59.856 A:middle
This can also be done for
prerecorded audio recognition.

00:09:02.216 --> 00:09:04.516 A:middle
Now just a quick talk
about some best practices.

00:09:07.276 --> 00:09:10.676 A:middle
We're making speech recognition
available for free to all apps

00:09:11.256 --> 00:09:13.166 A:middle
but we do have some
reasonable limits in place

00:09:13.166 --> 00:09:15.306 A:middle
so that the service remains
available to everyone.

00:09:17.176 --> 00:09:19.426 A:middle
Individual devices may
be limited in the amount

00:09:19.426 --> 00:09:21.416 A:middle
of recognitions that can
be performed per day.

00:09:23.046 --> 00:09:25.216 A:middle
Apps may also be
throttled globally

00:09:25.216 --> 00:09:26.886 A:middle
on a request per day basis.

00:09:28.606 --> 00:09:32.986 A:middle
Like other service backed
APIs, for example CLGO Coder,

00:09:33.656 --> 00:09:36.586 A:middle
be prepared to handle network
and rate limiting failures.

00:09:38.326 --> 00:09:39.806 A:middle
If you find that you're
routinely hitting your

00:09:39.806 --> 00:09:41.566 A:middle
throttling limits,
please let us know.

00:09:42.576 --> 00:09:45.876 A:middle
It's also important to be aware

00:09:45.876 --> 00:09:48.376 A:middle
that speech recognition can
have a high cost in terms

00:09:48.376 --> 00:09:50.196 A:middle
of battery drain
and network traffic.

00:09:52.336 --> 00:09:55.536 A:middle
For iOS 10 we're starting with
a strict audio duration limit

00:09:55.536 --> 00:09:57.936 A:middle
of about one minute
which is similar to that

00:09:57.936 --> 00:09:58.976 A:middle
of keyboard dictation.

00:10:02.506 --> 00:10:04.576 A:middle
A few words about
being transparent

00:10:04.576 --> 00:10:06.316 A:middle
and respecting your
user's privacy.

00:10:07.676 --> 00:10:10.316 A:middle
If you're recording the user's
speech, it's a great idea

00:10:10.316 --> 00:10:12.696 A:middle
to make this crystal clear
in your user interface.

00:10:13.606 --> 00:10:16.706 A:middle
Playing recording sounds and/or
displaying a visual recording

00:10:16.706 --> 00:10:18.536 A:middle
indicator makes it
clear to your users

00:10:18.756 --> 00:10:19.866 A:middle
that they're being recorded.

00:10:22.186 --> 00:10:24.726 A:middle
Some speech is a bad
candidate for recognition.

00:10:25.556 --> 00:10:28.056 A:middle
Passwords, health data,
financial information,

00:10:28.056 --> 00:10:30.086 A:middle
and other sensitive
speech should not be given

00:10:30.086 --> 00:10:31.106 A:middle
to speech recognition.

00:10:33.796 --> 00:10:36.396 A:middle
Displaying speech as it
is recognized like Siri

00:10:36.396 --> 00:10:39.516 A:middle
and Dictation do can also help
users understand what your app

00:10:39.516 --> 00:10:40.036 A:middle
is doing.

00:10:40.966 --> 00:10:43.666 A:middle
It can also be helpful for
users so that they can see

00:10:43.666 --> 00:10:45.146 A:middle
when recognition errors occur.

00:10:47.896 --> 00:10:49.026 A:middle
So developers.

00:10:49.456 --> 00:10:51.026 A:middle
Your apps now have free access

00:10:51.026 --> 00:10:54.086 A:middle
to high performance speech
recognition dozens of languages.

00:10:54.996 --> 00:10:56.826 A:middle
But it's important to
gracefully handle cases

00:10:56.826 --> 00:10:57.756 A:middle
where it's not available

00:10:57.756 --> 00:10:59.656 A:middle
or the user doesn't
want your app to use it.

00:11:01.136 --> 00:11:02.966 A:middle
Transparency is the best policy.

00:11:03.456 --> 00:11:04.396 A:middle
Make it clear to the user

00:11:04.396 --> 00:11:06.246 A:middle
when speech recognition
is being used.

00:11:07.916 --> 00:11:09.976 A:middle
We're incredibly excited
to see what new uses

00:11:09.976 --> 00:11:11.946 A:middle
for speech recognition
you come up with.

00:11:14.186 --> 00:11:16.416 A:middle
For more information
and some sample code,

00:11:16.526 --> 00:11:18.096 A:middle
check out this session's
webpage.

00:11:18.996 --> 00:11:21.396 A:middle
You might also be interested
in some sessions on SiriKit.

00:11:21.956 --> 00:11:24.786 A:middle
There's one on Wednesday and
the more advanced one later

00:11:24.786 --> 00:11:25.436 A:middle
on Thursday.

00:11:26.706 --> 00:11:28.976 A:middle
Thank you for your time
and have a great WWDC.
