WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:07.516 --> 00:00:18.500 A:middle
[ Music ]

00:00:25.516 --> 00:00:31.546 A:middle
[ Applause ]

00:00:32.046 --> 00:00:32.716 A:middle
&gt;&gt; So, hello everyone.

00:00:33.026 --> 00:00:35.416 A:middle
My name is Fiona and this
is my colleague Alex.

00:00:36.146 --> 00:00:40.776 A:middle
And I work on the iOS GPU
complier team and our job is

00:00:40.776 --> 00:00:43.356 A:middle
to make your shaders run
on the latest iOS devices,

00:00:43.436 --> 00:00:46.176 A:middle
and to make them run as
efficiently as possible.

00:00:46.636 --> 00:00:49.056 A:middle
And I'm here to talk
about our presentations,

00:00:49.166 --> 00:00:52.136 A:middle
Advanced Metal Shader
Optimization, that is Forging

00:00:52.136 --> 00:00:53.666 A:middle
and Polishing your
Metal shaders.

00:00:54.006 --> 00:00:56.286 A:middle
Our compiler is based on LVM.

00:00:56.906 --> 00:00:58.546 A:middle
And we work with the
Open Source committee

00:00:58.546 --> 00:01:01.636 A:middle
to make LVM more suitable
for use on GPUs by everyone.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:58.546 --> 00:01:01.636 A:middle
to make LVM more suitable
for use on GPUs by everyone.

00:01:03.806 --> 00:01:06.006 A:middle
Here's a quick overview of
the other Metal session,

00:01:06.006 --> 00:01:06.856 A:middle
in case you missed them,

00:01:06.856 --> 00:01:08.966 A:middle
and don't worry you can
watch the recordings online.

00:01:09.416 --> 00:01:11.736 A:middle
Yesterday we had part one
and two of adopting Metal

00:01:12.326 --> 00:01:14.556 A:middle
and earlier today we had part
one and two of what's new

00:01:14.616 --> 00:01:16.516 A:middle
in Metal, because there's quite
a lot that's new in Metal.

00:01:17.326 --> 00:01:18.946 A:middle
And of course here's
the last one,

00:01:19.586 --> 00:01:20.786 A:middle
the one you're watching
right now.

00:01:22.206 --> 00:01:24.646 A:middle
So in this presentation we're
going to be going over a number

00:01:24.646 --> 00:01:26.956 A:middle
of things you can do to
work with the compiler

00:01:27.266 --> 00:01:28.696 A:middle
to make your code faster.

00:01:29.566 --> 00:01:32.606 A:middle
And some of this stuff is
going to be specific to A8

00:01:32.606 --> 00:01:35.046 A:middle
and later GPUs including
some information

00:01:35.046 --> 00:01:36.636 A:middle
that has never been
made public before.

00:01:36.816 --> 00:01:39.176 A:middle
And some of it will
also be more general.

00:01:39.466 --> 00:01:42.306 A:middle
And we'll be noting that with
the A8 icon you can see there

00:01:42.506 --> 00:01:44.996 A:middle
for slides that are
more A8 specific.

00:01:46.056 --> 00:01:50.006 A:middle
And additionally, we'll be
noting some potential pitfalls.

00:01:50.496 --> 00:01:53.036 A:middle
That is things that may not
come up as often as the kind

00:01:53.036 --> 00:01:55.466 A:middle
of micro optimizations
you're used to looking for,

00:01:55.826 --> 00:01:58.026 A:middle
but if you run into these,
you're likely to lose

00:01:58.026 --> 00:02:01.486 A:middle
so much performance, nothing is
going to matter by comparison.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:01:58.026 --> 00:02:01.486 A:middle
so much performance, nothing is
going to matter by comparison.

00:02:01.776 --> 00:02:04.226 A:middle
So it's always worth making
sure you don't run into those.

00:02:04.566 --> 00:02:05.386 A:middle
And those will be marked

00:02:05.386 --> 00:02:07.036 A:middle
with the triangle icon,
as you can see there.

00:02:08.205 --> 00:02:10.586 A:middle
Before we go on, this
is not the first step.

00:02:10.996 --> 00:02:12.136 A:middle
This is the last step.

00:02:12.886 --> 00:02:15.446 A:middle
There's no point to doing
low-level shader optimization

00:02:15.446 --> 00:02:17.756 A:middle
until you've done the
high-level optimizations before,

00:02:17.896 --> 00:02:19.466 A:middle
like watching the
other Metal talks

00:02:19.466 --> 00:02:21.766 A:middle
from optimizing your
draw calls, the structure

00:02:21.836 --> 00:02:22.976 A:middle
of your engine and so forth.

00:02:23.656 --> 00:02:26.226 A:middle
Optimizing your later shader
should be roughly the last thing

00:02:26.226 --> 00:02:28.036 A:middle
you do.

00:02:28.036 --> 00:02:30.356 A:middle
And, this presentation
is primarily

00:02:30.436 --> 00:02:31.936 A:middle
for experienced shader authors.

00:02:32.506 --> 00:02:34.766 A:middle
Perhaps you've worked on Metal
a whole lot and you're looking

00:02:34.766 --> 00:02:37.686 A:middle
to get more into optimizing your
shaders, or perhaps your new

00:02:37.686 --> 00:02:40.286 A:middle
to Metal, but you've done a
lot of shader optimization

00:02:40.286 --> 00:02:42.346 A:middle
on other platforms and
you'd like to know how

00:02:42.346 --> 00:02:44.276 A:middle
to optimize better
for A8 and later GPUs,

00:02:44.276 --> 00:02:46.606 A:middle
this is the presentation
for you.

00:02:48.396 --> 00:02:50.886 A:middle
So you may have seen this
pipeline if you watched any

00:02:50.886 --> 00:02:51.916 A:middle
of the previous Metal talks.

00:02:52.426 --> 00:02:54.436 A:middle
And we will be focusing
of course

00:02:54.496 --> 00:02:56.456 A:middle
on the programmable
stages of this pipeline,

00:02:56.456 --> 00:02:58.316 A:middle
as you can see there,
the shader course.

00:02:59.336 --> 00:03:00.596 A:middle
So first, Alex is going to go


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:02:59.336 --> 00:03:00.596 A:middle
So first, Alex is going to go

00:03:00.596 --> 00:03:02.506 A:middle
over some shader
performance fundamentals

00:03:02.506 --> 00:03:03.536 A:middle
and higher level issues.

00:03:03.916 --> 00:03:06.846 A:middle
After which, I'll return
for some low-level,

00:03:06.846 --> 00:03:09.096 A:middle
down and dirty shader
optimizations.

00:03:12.516 --> 00:03:17.546 A:middle
[ Applause ]

00:03:18.046 --> 00:03:18.456 A:middle
&gt;&gt; Thanks, Fiona.

00:03:18.456 --> 00:03:19.956 A:middle
Let me start by explaining
the idea

00:03:19.956 --> 00:03:21.256 A:middle
of shader performance
fundamentals.

00:03:21.776 --> 00:03:22.986 A:middle
These are the things that
you want to make sure

00:03:22.986 --> 00:03:24.616 A:middle
that you have right
before you start digging

00:03:24.616 --> 00:03:26.116 A:middle
into source level optimizations.

00:03:26.546 --> 00:03:27.776 A:middle
Usually the impact of the kind

00:03:27.776 --> 00:03:29.716 A:middle
of changes you'll
make here can dwarf

00:03:29.716 --> 00:03:32.176 A:middle
or potentially hide other
more targeted changes

00:03:32.176 --> 00:03:32.966 A:middle
that you make elsewhere.

00:03:33.336 --> 00:03:34.936 A:middle
So I'm going to talk
about four of these today.

00:03:34.936 --> 00:03:36.716 A:middle
Address space selection
for buffer arguments,

00:03:37.226 --> 00:03:39.056 A:middle
buffer preloading, dealing

00:03:39.056 --> 00:03:40.436 A:middle
with fragment function
resource writes,

00:03:40.436 --> 00:03:42.276 A:middle
and how to optimize
your computer kernels.

00:03:42.276 --> 00:03:45.676 A:middle
So, let's start with
addresses spaces.

00:03:46.246 --> 00:03:48.886 A:middle
So since this functionality
doesn't exist

00:03:48.886 --> 00:03:50.596 A:middle
in all shading languages,
I'll give a quick primer.

00:03:50.866 --> 00:03:53.816 A:middle
So, GPUs have multiple paths
for getting date from memory.

00:03:53.816 --> 00:03:56.936 A:middle
And these paths are optimized
for different use cases,

00:03:57.086 --> 00:03:59.846 A:middle
and they have different
performance characteristics.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:00.706 --> 00:04:03.806 A:middle
In Metal, we expose control
over which path is used

00:04:03.956 --> 00:04:06.926 A:middle
to the developer by requiring
that they qualify all buffers,

00:04:07.356 --> 00:04:09.386 A:middle
arguments and pointers
in the shading language

00:04:09.386 --> 00:04:11.096 A:middle
with which address
space they want to use.

00:04:11.766 --> 00:04:14.726 A:middle
So a couple of the address
spaces specifically apply

00:04:14.726 --> 00:04:16.786 A:middle
to getting information
from memory.

00:04:17.055 --> 00:04:20.416 A:middle
The first of which is
the device address space.

00:04:21.086 --> 00:04:23.296 A:middle
This is an address space with
relatively few restrictions.

00:04:23.296 --> 00:04:25.016 A:middle
You can read and write data
through this address space,

00:04:25.016 --> 00:04:28.076 A:middle
you can pass as much data as
you want, and the buffer offsets

00:04:28.076 --> 00:04:30.756 A:middle
that you specify at the API
level have relatively flexible

00:04:30.756 --> 00:04:31.486 A:middle
alignment requirements.

00:04:32.156 --> 00:04:35.866 A:middle
On the other end of things, you
have the constant address space.

00:04:36.086 --> 00:04:38.246 A:middle
As the name implies, this is
a read only address space,

00:04:38.246 --> 00:04:39.856 A:middle
but there are a couple of
additional restrictions.

00:04:40.316 --> 00:04:42.136 A:middle
There are limits on how
much data you can pass

00:04:42.256 --> 00:04:44.426 A:middle
through this address space, and
additionally the buffer offsets

00:04:44.426 --> 00:04:46.966 A:middle
that you specify at the API
level have more stringent

00:04:46.966 --> 00:04:47.716 A:middle
alignment requirements.

00:04:48.296 --> 00:04:51.016 A:middle
However, this is the address
space that's optimized for cases

00:04:51.016 --> 00:04:52.036 A:middle
with a lot of data reuse.

00:04:52.036 --> 00:04:53.016 A:middle
So you want to take advantage

00:04:53.016 --> 00:04:54.766 A:middle
of this address space
whenever it makes sense.

00:04:55.786 --> 00:04:58.336 A:middle
Figuring out whether or not the
constant address space makes

00:04:58.336 --> 00:05:00.116 A:middle
sense for your buffer
argument is typically a matter


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:58.336 --> 00:05:00.116 A:middle
sense for your buffer
argument is typically a matter

00:05:00.116 --> 00:05:01.846 A:middle
of asking yourself
two questions.

00:05:02.636 --> 00:05:05.176 A:middle
The first question is, do I
know how much data I have.

00:05:05.176 --> 00:05:07.786 A:middle
And if you have a potentially
variable amount of data,

00:05:07.786 --> 00:05:08.946 A:middle
this is usually a
sign that you need

00:05:08.946 --> 00:05:10.716 A:middle
to be using the device
address space.

00:05:11.466 --> 00:05:14.656 A:middle
Additionally, you want to
look at how much each item

00:05:15.056 --> 00:05:16.526 A:middle
in your buffer is being read.

00:05:16.576 --> 00:05:20.606 A:middle
And if these items can
potentially be read many times,

00:05:21.046 --> 00:05:22.756 A:middle
this is usually a sign
that you want to put them

00:05:22.756 --> 00:05:23.866 A:middle
into the constant address space.

00:05:24.536 --> 00:05:27.016 A:middle
So let's put this into practice
with a couple of examples

00:05:27.016 --> 00:05:28.726 A:middle
from some vertex shaders.

00:05:29.496 --> 00:05:31.886 A:middle
First, you have regular,
old vertex data.

00:05:32.396 --> 00:05:36.376 A:middle
So as you can see, each vertex
has its own piece of data.

00:05:36.706 --> 00:05:39.046 A:middle
And each vertex is the only one
that reads that piece of data.

00:05:39.046 --> 00:05:40.536 A:middle
So there's essentially
no reuse here.

00:05:40.536 --> 00:05:42.646 A:middle
This is the kind of thing
that really needs to be

00:05:42.646 --> 00:05:45.396 A:middle
in the device address space.

00:05:46.816 --> 00:05:51.626 A:middle
Next, you have projection
matrices, another matrices.

00:05:51.926 --> 00:05:55.426 A:middle
Now, typically what you have
here is that you have one

00:05:55.426 --> 00:05:59.926 A:middle
of these objects, and they're
read by every single vertex.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:00.686 --> 00:06:03.206 A:middle
So with this kind of complete
data reuse, you really want this

00:06:03.206 --> 00:06:04.636 A:middle
to be in the constant
address space.

00:06:04.826 --> 00:06:09.036 A:middle
Let's mix things up a little bit

00:06:09.036 --> 00:06:11.276 A:middle
and take a look at
standing matrices.

00:06:11.276 --> 00:06:14.816 A:middle
So hopefully in this case
you have some maximum number

00:06:14.816 --> 00:06:15.836 A:middle
of bones that you're handling.

00:06:16.706 --> 00:06:20.186 A:middle
But if you look at each
bone that matrix may be read

00:06:20.186 --> 00:06:21.956 A:middle
by every vertex that
references that bone,

00:06:21.956 --> 00:06:25.046 A:middle
and that also is a potential
for a large amount of reuse.

00:06:25.046 --> 00:06:26.086 A:middle
And so this really ought to be

00:06:26.086 --> 00:06:29.116 A:middle
on the constant address
space as well.

00:06:29.316 --> 00:06:31.176 A:middle
Finally, let's look
at per instance data.

00:06:31.756 --> 00:06:35.266 A:middle
As you can see all vertices

00:06:35.266 --> 00:06:37.756 A:middle
in the instance will read
this particular piece of data,

00:06:38.396 --> 00:06:40.916 A:middle
but on the other hand you have
a potentially variable number

00:06:40.916 --> 00:06:42.396 A:middle
of instances, so this
actually needs to be

00:06:42.396 --> 00:06:44.226 A:middle
in the device address
space as well.

00:06:45.616 --> 00:06:48.356 A:middle
For an example of why address
space selection matters

00:06:48.356 --> 00:06:49.406 A:middle
for performance, let's move

00:06:49.406 --> 00:06:51.206 A:middle
on to our next topic,
buffer preloading.

00:06:52.746 --> 00:06:55.226 A:middle
So Fiona will spend some
time talking about how

00:06:55.226 --> 00:06:57.396 A:middle
to actually optimize loads and
stores within your shaders,

00:06:57.396 --> 00:06:59.856 A:middle
but for many cases the best
thing that you can do is

00:06:59.856 --> 00:07:02.186 A:middle
to actually off load this
work to dedicated hardware.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:59.856 --> 00:07:02.186 A:middle
to actually off load this
work to dedicated hardware.

00:07:02.676 --> 00:07:04.906 A:middle
So we can do this
for you in two cases,

00:07:05.456 --> 00:07:06.856 A:middle
context buffers and
vertex buffers.

00:07:07.616 --> 00:07:11.086 A:middle
But this relies on knowing
things about the access patterns

00:07:11.086 --> 00:07:13.936 A:middle
in your shaders and what address
space you've placed them into.

00:07:14.866 --> 00:07:17.056 A:middle
So let's start with
constant buffer preloading.

00:07:17.426 --> 00:07:20.136 A:middle
So the idea here is
that rather than loading

00:07:20.136 --> 00:07:21.156 A:middle
through the constant
address space,

00:07:21.156 --> 00:07:23.016 A:middle
what we can actually do is
take your data and put it

00:07:23.016 --> 00:07:25.456 A:middle
into special constant
registers that are even faster

00:07:25.456 --> 00:07:26.536 A:middle
for the ALU to access.

00:07:27.286 --> 00:07:28.116 A:middle
So we can do this as long

00:07:28.116 --> 00:07:29.826 A:middle
as we know exactly
what data will be read.

00:07:30.726 --> 00:07:32.776 A:middle
If your offsets are
known a compile time,

00:07:32.776 --> 00:07:33.786 A:middle
this is straightforward.

00:07:34.036 --> 00:07:34.936 A:middle
But if your offsets aren't known

00:07:34.936 --> 00:07:37.976 A:middle
until run time then we need a
little bit of extra information

00:07:37.976 --> 00:07:39.416 A:middle
about how much data
that you're reading.

00:07:39.986 --> 00:07:42.346 A:middle
So indicating this

00:07:42.346 --> 00:07:44.876 A:middle
to the compiler is usually
a matter of two steps.

00:07:45.016 --> 00:07:46.476 A:middle
First, you need to make
sure that this data is

00:07:46.476 --> 00:07:47.676 A:middle
in the constant address space.

00:07:48.696 --> 00:07:50.256 A:middle
And additionally
you need to indicate

00:07:50.256 --> 00:07:51.696 A:middle
that your accesses are
statically bounded.

00:07:53.296 --> 00:07:55.436 A:middle
The best way to do this
is to pass your arguments

00:07:55.696 --> 00:07:57.726 A:middle
by reference rather than
pointer where possible.

00:07:58.056 --> 00:08:00.676 A:middle
If you're passing only a
single item or a single struct,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:07:58.056 --> 00:08:00.676 A:middle
If you're passing only a
single item or a single struct,

00:08:00.676 --> 00:08:02.396 A:middle
this is straightforward, you
can just change your pointers

00:08:02.396 --> 00:08:05.106 A:middle
to references and change
your accesses accordingly.

00:08:05.296 --> 00:08:07.976 A:middle
This is a little different
if you're passing an array

00:08:07.976 --> 00:08:09.006 A:middle
that you know is bounded.

00:08:09.666 --> 00:08:12.656 A:middle
So what you do in this case is
you can embed that size array

00:08:12.656 --> 00:08:14.946 A:middle
and pass that struct
by reference rather

00:08:14.946 --> 00:08:16.176 A:middle
than passing the
original pointer.

00:08:16.936 --> 00:08:18.966 A:middle
So we can put this into
practice with an example

00:08:19.536 --> 00:08:21.426 A:middle
at a forward lighting
fragment shader.

00:08:21.776 --> 00:08:23.176 A:middle
So as you can see in sort

00:08:23.176 --> 00:08:26.246 A:middle
of the original version what we
have are a bunch of arguments

00:08:26.246 --> 00:08:27.756 A:middle
that are passed as
regular device pointers.

00:08:27.756 --> 00:08:29.806 A:middle
And this doesn't expose the
information that we want.

00:08:30.616 --> 00:08:31.586 A:middle
So we can do better than this.

00:08:32.306 --> 00:08:33.676 A:middle
Instead if we note the number

00:08:33.676 --> 00:08:36.946 A:middle
of lights is bonded what we can
do is we can put the light data

00:08:36.946 --> 00:08:39.056 A:middle
and the count together into
a single struct like this.

00:08:40.356 --> 00:08:43.116 A:middle
And we can pass that struct
in the constant address space

00:08:43.116 --> 00:08:43.986 A:middle
as a reference like this.

00:08:44.616 --> 00:08:46.526 A:middle
And so that gets us
constant buffer preloading.

00:08:48.366 --> 00:08:49.346 A:middle
Let's look at another example

00:08:49.346 --> 00:08:51.086 A:middle
of how this can affect
you in practice.

00:08:52.156 --> 00:08:55.206 A:middle
So, there are many ways to
implement a deferred render,

00:08:55.206 --> 00:08:57.786 A:middle
but what we find is that the
actually implementation choices

00:08:57.786 --> 00:09:00.036 A:middle
that you make can have a big
impact on the performance


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:08:57.786 --> 00:09:00.036 A:middle
that you make can have a big
impact on the performance

00:09:00.036 --> 00:09:01.236 A:middle
that you achieve in practice.

00:09:01.696 --> 00:09:05.496 A:middle
One pattern that's common
now is to use a single shader

00:09:05.496 --> 00:09:07.456 A:middle
to accumulate the
results of all lights.

00:09:08.456 --> 00:09:10.776 A:middle
And what you can see form the
declaration of this function,

00:09:10.776 --> 00:09:13.436 A:middle
is that it can potentially read
any or all lights in the scene

00:09:13.436 --> 00:09:15.306 A:middle
and that means that your
input size is unbounded.

00:09:15.306 --> 00:09:20.026 A:middle
Now, on the other hand if you're
able to structure your rendering

00:09:20.026 --> 00:09:21.246 A:middle
such that each light is handled

00:09:21.246 --> 00:09:24.006 A:middle
in its own draw call
then what happens is

00:09:24.006 --> 00:09:27.206 A:middle
that each light only needs
to read that light's data

00:09:27.206 --> 00:09:29.506 A:middle
and it's shader and that
means that you can pass it

00:09:29.536 --> 00:09:31.666 A:middle
in the constant address space

00:09:32.026 --> 00:09:33.476 A:middle
and take advantage
of buffer preloading.

00:09:34.336 --> 00:09:36.546 A:middle
In practice we see
that on A8 later GPUs

00:09:36.546 --> 00:09:38.176 A:middle
that this is a significant
performance win.

00:09:38.176 --> 00:09:42.416 A:middle
Now let's talk about
vertex buffer preloading.

00:09:42.776 --> 00:09:44.386 A:middle
The idea of vertex
buffer preloading is

00:09:44.386 --> 00:09:46.656 A:middle
to reuse the same dedicated
hardware that we would use

00:09:46.656 --> 00:09:47.936 A:middle
for a fix function
vertex fetching.

00:09:48.226 --> 00:09:51.666 A:middle
And we can do this for regular
buffer loads as long as the way

00:09:51.666 --> 00:09:53.216 A:middle
that you access your
buffer looks just

00:09:53.216 --> 00:09:54.456 A:middle
like fix function
vertex fetching.

00:09:54.876 --> 00:09:55.896 A:middle
So what that means
is that you need

00:09:55.896 --> 00:09:58.976 A:middle
to be indexing using the
vertex or instance ID.

00:09:59.046 --> 00:10:01.316 A:middle
Now we can handle a couple
additional modifications


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:09:59.046 --> 00:10:01.316 A:middle
Now we can handle a couple
additional modifications

00:10:01.316 --> 00:10:04.216 A:middle
to the vertex or instance IDs
such as applying a deviser

00:10:04.216 --> 00:10:06.916 A:middle
and that's with or
without any base vertex

00:10:06.916 --> 00:10:09.216 A:middle
or instance offsets you might
have applied at the API level.

00:10:09.876 --> 00:10:12.206 A:middle
Of course the easiest way to
take advantage of this is just

00:10:12.206 --> 00:10:15.116 A:middle
to use the Metal vertex
descriptor functionality

00:10:15.116 --> 00:10:15.926 A:middle
wherever possible.

00:10:15.926 --> 00:10:18.156 A:middle
But if you are writing
your own indexing code,

00:10:18.826 --> 00:10:20.496 A:middle
we strongly suggest that
you layout your data

00:10:20.496 --> 00:10:23.126 A:middle
so that vertexes fetch linearly
to simplify buffer indexing.

00:10:23.366 --> 00:10:26.196 A:middle
Note that this doesn't preclude
you from doing fancier things,

00:10:26.196 --> 00:10:28.996 A:middle
like if you were rendering quads
and you want to pass one value

00:10:29.446 --> 00:10:33.256 A:middle
to all vertices in the quad,
you can still do things

00:10:33.256 --> 00:10:35.526 A:middle
like indexing by vertex
ID divided by four

00:10:35.526 --> 00:10:36.926 A:middle
because this just
looks like a divider.

00:10:38.106 --> 00:10:42.086 A:middle
So now let's move on to a couple
shader stage specific concerns.

00:10:42.686 --> 00:10:47.016 A:middle
In iOS 10 we introduced the
ability to do resource writes

00:10:47.016 --> 00:10:48.436 A:middle
from within your
fragment functions.

00:10:48.626 --> 00:10:50.186 A:middle
And this has interesting
implications

00:10:50.186 --> 00:10:51.156 A:middle
for hidden surface removal.

00:10:52.246 --> 00:10:54.446 A:middle
So prior to this you might have
been accustomed to the behavior

00:10:54.446 --> 00:10:57.386 A:middle
that a fragment wouldn't
need to be shaded as long

00:10:57.386 --> 00:10:59.286 A:middle
as an opaque fragment
came in and occluded it.

00:10:59.956 --> 00:11:02.176 A:middle
So this is no longer
true specifically


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:59.956 --> 00:11:02.176 A:middle
So this is no longer
true specifically

00:11:02.176 --> 00:11:03.926 A:middle
if your fragment function
is doing resource writes,

00:11:03.926 --> 00:11:05.656 A:middle
because those resource
writes still need to happen.

00:11:06.836 --> 00:11:09.046 A:middle
So instead your behavior
really only depends

00:11:09.346 --> 00:11:10.346 A:middle
on what's come before.

00:11:10.346 --> 00:11:12.956 A:middle
And specifically what
happens depends on whether

00:11:12.956 --> 00:11:14.776 A:middle
or not you've enabled
early fragment tests

00:11:14.776 --> 00:11:15.686 A:middle
on your fragment function.

00:11:16.116 --> 00:11:19.236 A:middle
If you have enabled
early fragment tests,

00:11:19.916 --> 00:11:21.296 A:middle
once it's rasterized as long

00:11:21.296 --> 00:11:23.666 A:middle
as it also passes the early
depth and stencil tests.

00:11:24.066 --> 00:11:26.366 A:middle
If you haven't specified
early fragment tests,

00:11:26.496 --> 00:11:28.146 A:middle
then your fragment
will be shaded

00:11:28.146 --> 00:11:29.306 A:middle
as long as it's rasterized.

00:11:30.136 --> 00:11:32.276 A:middle
So from a perspective of
minimizing your shading,

00:11:32.276 --> 00:11:34.376 A:middle
what you want to do is
use early fragment tests

00:11:34.376 --> 00:11:35.116 A:middle
wherever possible.

00:11:35.116 --> 00:11:36.466 A:middle
But there are a couple
additional things

00:11:36.466 --> 00:11:38.536 A:middle
that you can do to improve
the rejection that you get.

00:11:39.676 --> 00:11:41.796 A:middle
And most of these boil
down to draw order.

00:11:41.836 --> 00:11:44.406 A:middle
You want to draw these objects,

00:11:44.466 --> 00:11:47.046 A:middle
the objects where the fragment
functions do resource writes

00:11:47.376 --> 00:11:48.516 A:middle
after opaque objects.

00:11:48.716 --> 00:11:50.586 A:middle
And if you're using these
objects to update your depth

00:11:50.586 --> 00:11:52.536 A:middle
and stencil buffers,
we strongly suggest

00:11:52.536 --> 00:11:54.766 A:middle
that you sort these
buffer from front to back.

00:11:55.646 --> 00:11:57.816 A:middle
Note that this guidance
should sound fairly familiar

00:11:57.816 --> 00:11:59.506 A:middle
if you've been dealing
with fragment functions

00:11:59.506 --> 00:12:01.676 A:middle
that do discard or modify
your depth per pixel.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:11:59.506 --> 00:12:01.676 A:middle
that do discard or modify
your depth per pixel.

00:12:01.676 --> 00:12:05.536 A:middle
Now let's talk about
compute kernels.

00:12:05.736 --> 00:12:08.546 A:middle
Since the defining
characters of a compute kernels

00:12:08.546 --> 00:12:10.366 A:middle
that you can structure your
computation however you want.

00:12:11.036 --> 00:12:14.736 A:middle
Let's talk about what factors
influence how you do this

00:12:14.796 --> 00:12:16.386 A:middle
on iOS.

00:12:17.076 --> 00:12:19.226 A:middle
First we have computer
thread launch overhead.

00:12:20.576 --> 00:12:24.856 A:middle
So on A8 and later GPUs
there's a certain amount of time

00:12:24.856 --> 00:12:27.486 A:middle
that it takes to launch a
group of compute threads.

00:12:27.586 --> 00:12:28.836 A:middle
So if you don't do enough work

00:12:28.836 --> 00:12:31.376 A:middle
from within a single compute
thread you can potentially,

00:12:31.376 --> 00:12:33.036 A:middle
it leaves the hardware
underutilized

00:12:33.036 --> 00:12:34.266 A:middle
and leave performance
on the table.

00:12:36.046 --> 00:12:38.716 A:middle
And a good way to deal with
this and actually a good pattern

00:12:38.716 --> 00:12:41.116 A:middle
for writing computer
kernels on iOS in general is

00:12:41.116 --> 00:12:43.466 A:middle
to actually process multiple
conceptual work items

00:12:43.466 --> 00:12:44.666 A:middle
in a single compute threat.

00:12:45.166 --> 00:12:48.276 A:middle
And in particular a pattern
that we find works well is

00:12:48.276 --> 00:12:50.416 A:middle
to reuse values not
by passing them

00:12:50.416 --> 00:12:53.586 A:middle
through thread group memory, but
rather by reusing values loaded

00:12:53.586 --> 00:12:57.106 A:middle
for one work item when you're
processing the next work item

00:12:57.296 --> 00:12:58.426 A:middle
in the same compute thread.

00:12:58.426 --> 00:13:00.916 A:middle
And it's best to illustrate
this with an example.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:58.426 --> 00:13:00.916 A:middle
And it's best to illustrate
this with an example.

00:13:01.696 --> 00:13:04.226 A:middle
So this is a syllable
filter kernel, this is sort

00:13:04.226 --> 00:13:06.226 A:middle
of the most straightforward
version of it, as you see,

00:13:06.226 --> 00:13:07.966 A:middle
it reads as a three-
[inaudible] region of its source

00:13:08.366 --> 00:13:10.576 A:middle
and produces one output pixel.

00:13:11.146 --> 00:13:15.696 A:middle
So if instead we
apply the pattern

00:13:15.696 --> 00:13:17.416 A:middle
of processing multiple
work items

00:13:17.876 --> 00:13:18.876 A:middle
in a single compute thread,

00:13:18.876 --> 00:13:20.476 A:middle
we get something
that looks like this.

00:13:21.086 --> 00:13:24.536 A:middle
Notice now that we're striding
by two pixels at a time.

00:13:24.916 --> 00:13:27.126 A:middle
So processing the first pixel
looks much as it did before.

00:13:27.126 --> 00:13:28.556 A:middle
We read the 3 by 3 region.

00:13:29.046 --> 00:13:31.246 A:middle
We apply the filter and
we write up the value.

00:13:31.786 --> 00:13:34.716 A:middle
But now let's look at
how pixel 2 is handled.

00:13:35.006 --> 00:13:38.516 A:middle
So stents are striding by
two pixels at a time we need

00:13:38.516 --> 00:13:40.426 A:middle
to make sure that there is
a second pixel to process.

00:13:41.486 --> 00:13:42.546 A:middle
And now we read its data.

00:13:43.386 --> 00:13:45.536 A:middle
Note here that a 2 by 3 region

00:13:45.536 --> 00:13:47.576 A:middle
of what this pixel
wants was already loaded

00:13:47.576 --> 00:13:48.416 A:middle
by the previous pixel.

00:13:48.416 --> 00:13:49.376 A:middle
So we don't need
to load it again,

00:13:49.376 --> 00:13:50.776 A:middle
we can reuse those old values.

00:13:51.016 --> 00:13:52.396 A:middle
All we need to load now is the 1

00:13:52.396 --> 00:13:54.646 A:middle
by 3 region that's
new to this pixel.

00:13:55.786 --> 00:13:58.166 A:middle
After which, we can apply
the filter and we're done.

00:13:58.916 --> 00:14:02.496 A:middle
Note that as a result we're
not doing 12 texture reads,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:13:58.916 --> 00:14:02.496 A:middle
Note that as a result we're
not doing 12 texture reads,

00:14:02.496 --> 00:14:05.276 A:middle
instead of the old 9, but
we're producing 2 pixels.

00:14:05.276 --> 00:14:07.816 A:middle
So this is a significant
reduction in the amount

00:14:07.816 --> 00:14:09.126 A:middle
of texture reads per pixel.

00:14:09.866 --> 00:14:13.466 A:middle
Of course this pattern doesn't
work for all compute use cases.

00:14:14.026 --> 00:14:16.086 A:middle
Sometimes you do still
need to pass data

00:14:16.086 --> 00:14:16.856 A:middle
through thread group memory.

00:14:17.456 --> 00:14:20.396 A:middle
And in that case, when you're
synchronizing between threads

00:14:20.396 --> 00:14:24.286 A:middle
in a thread group, an important
thing to keep in mind is

00:14:24.286 --> 00:14:26.906 A:middle
that you want to use the barrier
with the smallest possible scope

00:14:26.906 --> 00:14:28.476 A:middle
for the threads that
you need to synchronize.

00:14:29.326 --> 00:14:33.436 A:middle
In particular, if your thread
group fits within a single SIMD,

00:14:34.116 --> 00:14:35.966 A:middle
the regular thread
group barrier function

00:14:35.966 --> 00:14:37.156 A:middle
in Metal is unnecessary.

00:14:37.626 --> 00:14:41.346 A:middle
What you can use instead is the
new SIMD group barrier function

00:14:41.346 --> 00:14:42.536 A:middle
introduced in iOS 10.

00:14:43.476 --> 00:14:47.076 A:middle
And what we find is actually
the targeting your thread group

00:14:47.076 --> 00:14:48.336 A:middle
to fit within a single SIMD

00:14:48.336 --> 00:14:52.426 A:middle
and using SIMD group barrier
is often faster than trying

00:14:52.426 --> 00:14:54.406 A:middle
to use a larger thread
group in order to squeeze

00:14:54.406 --> 00:14:55.266 A:middle
that additional reuse,

00:14:55.266 --> 00:14:57.146 A:middle
but having to use thread
group barrier as a result.

00:14:57.706 --> 00:15:01.136 A:middle
So that wraps things up
for me, in conclusion,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:14:57.706 --> 00:15:01.136 A:middle
So that wraps things up
for me, in conclusion,

00:15:01.946 --> 00:15:04.596 A:middle
make sure you're using the
appropriate address space

00:15:04.596 --> 00:15:06.106 A:middle
for each of your buffer
arguments according

00:15:06.106 --> 00:15:07.386 A:middle
to the guidelines
that we described.

00:15:08.546 --> 00:15:09.916 A:middle
Structure your data
and rendering

00:15:09.916 --> 00:15:11.696 A:middle
to take maximal advantage
of constant

00:15:11.696 --> 00:15:12.996 A:middle
and vertex buffer preloading.

00:15:14.526 --> 00:15:16.426 A:middle
Make sure you're using early
fragment tests to reject

00:15:16.426 --> 00:15:18.576 A:middle
as many fragments as possible

00:15:18.646 --> 00:15:19.796 A:middle
when you're doing
resource writes.

00:15:20.336 --> 00:15:23.096 A:middle
Put enough work in
each compute thread

00:15:23.096 --> 00:15:24.386 A:middle
so you're not being limited

00:15:24.386 --> 00:15:26.506 A:middle
by your compute thread
launch overhead.

00:15:27.056 --> 00:15:29.336 A:middle
And use the smallest barrier
for the job when you need

00:15:29.336 --> 00:15:31.126 A:middle
to synchronize between
threads in a thread group.

00:15:31.446 --> 00:15:33.926 A:middle
And with that I'd like to pass
it back to Fiona to dive deeper

00:15:33.926 --> 00:15:34.796 A:middle
into tuning shader code.

00:15:35.516 --> 00:15:40.956 A:middle
[ Applause ]

00:15:41.456 --> 00:15:42.006 A:middle
&gt;&gt; Thank you, Alex.

00:15:43.306 --> 00:15:46.476 A:middle
So, before jumping into the
specifics here, I want to go

00:15:46.476 --> 00:15:48.686 A:middle
over some general
characteristics of GPUs

00:15:48.686 --> 00:15:50.846 A:middle
and the bottlenecks
you can encounter.

00:15:50.846 --> 00:15:52.336 A:middle
And all of you may be
familiar with this,

00:15:52.536 --> 00:15:54.146 A:middle
but I figure I should
just do a quick review.

00:15:54.836 --> 00:15:58.596 A:middle
So with GPUs typically you
have a set of resources.

00:15:58.696 --> 00:16:01.116 A:middle
And it's fairly common for
a shader to be bottlenecked


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:15:58.696 --> 00:16:01.116 A:middle
And it's fairly common for
a shader to be bottlenecked

00:16:01.116 --> 00:16:02.336 A:middle
by one of those resources.

00:16:02.596 --> 00:16:04.186 A:middle
And so for example if
you're bottlenecked

00:16:04.186 --> 00:16:06.406 A:middle
by memory bandwidth,
improving other things

00:16:06.406 --> 00:16:08.836 A:middle
in your shader will often
not give any apparent

00:16:08.886 --> 00:16:09.966 A:middle
performance improvement.

00:16:10.616 --> 00:16:13.036 A:middle
And while it is important to
identify these bottlenecks

00:16:13.036 --> 00:16:15.846 A:middle
and focus on them to
improve performance,

00:16:16.356 --> 00:16:18.796 A:middle
there is actually still
benefit to improving things

00:16:18.796 --> 00:16:19.826 A:middle
that aren't bottlenecks.

00:16:19.826 --> 00:16:22.336 A:middle
For example, in that example
if you are bottlenecked

00:16:22.336 --> 00:16:25.356 A:middle
at memory usage, but then
you improve your arithmetic

00:16:25.356 --> 00:16:28.866 A:middle
to be more efficient, you
will still save power even

00:16:28.866 --> 00:16:30.566 A:middle
if you are not improving
your frame rate.

00:16:30.726 --> 00:16:32.046 A:middle
And of course being on mobile,

00:16:32.346 --> 00:16:34.016 A:middle
saving power is always
important.

00:16:34.286 --> 00:16:35.996 A:middle
So it's not something to ignore,

00:16:36.106 --> 00:16:38.536 A:middle
just because your frame rate
doesn't go up in that case.

00:16:38.696 --> 00:16:41.256 A:middle
So there's four typical
bottlenecks to keep

00:16:41.256 --> 00:16:43.506 A:middle
in mind in shaders here.

00:16:43.656 --> 00:16:45.596 A:middle
The first is fairly
straightforward, ALU bandwidth.

00:16:45.846 --> 00:16:47.696 A:middle
The amount of math
that the GPU can do.

00:16:48.626 --> 00:16:50.936 A:middle
The second is memory bandwidth,
again, fairly straightforward,

00:16:50.966 --> 00:16:53.746 A:middle
the amount of data that the GPU
can load from system memory.

00:16:54.116 --> 00:16:55.846 A:middle
The other two are
little more subtle.

00:16:55.846 --> 00:16:57.716 A:middle
The first one is
memory issue rate.

00:16:58.076 --> 00:17:00.466 A:middle
Which represents the
number of memory operations


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:58.076 --> 00:17:00.466 A:middle
Which represents the
number of memory operations

00:17:00.466 --> 00:17:01.486 A:middle
that can be performed.

00:17:01.946 --> 00:17:04.026 A:middle
And this can come up in the case

00:17:04.066 --> 00:17:06.086 A:middle
where you have smaller
memory operations,

00:17:06.086 --> 00:17:08.346 A:middle
or you're using a lot of thread
group memory and so forth.

00:17:09.096 --> 00:17:11.236 A:middle
And the last one, which I'll
go into detail a bit more

00:17:11.236 --> 00:17:13.816 A:middle
about later is latency
occupancy register usage.

00:17:13.816 --> 00:17:15.146 A:middle
You may have heard about that,

00:17:15.226 --> 00:17:17.236 A:middle
but I will save that
until the end.

00:17:18.616 --> 00:17:20.656 A:middle
So to try to alleviate
some of these bottlenecks,

00:17:20.656 --> 00:17:23.116 A:middle
and improve overall shader
performance and efficiency,

00:17:23.455 --> 00:17:25.136 A:middle
we're going to look
at four categories

00:17:25.165 --> 00:17:26.766 A:middle
of optimization opportunity
here.

00:17:27.665 --> 00:17:28.996 A:middle
And the first one is data types.

00:17:29.076 --> 00:17:31.376 A:middle
And the first thing to consider

00:17:31.376 --> 00:17:34.366 A:middle
when optimizing your shader
is choosing your data types.

00:17:34.846 --> 00:17:36.726 A:middle
And the most important
thing to remember

00:17:36.726 --> 00:17:38.726 A:middle
when you're choosing
data types is that A8

00:17:38.726 --> 00:17:42.206 A:middle
and later GPUs have
16-bit register units,

00:17:42.856 --> 00:17:45.846 A:middle
which means that for example if
you're using a 32-bit data type,

00:17:45.916 --> 00:17:49.226 A:middle
that's twice the register
space, twice the bandwidth,

00:17:49.756 --> 00:17:51.916 A:middle
potentially twice the
power and so-forth,

00:17:52.316 --> 00:17:53.826 A:middle
it's just twice as much stuff.

00:17:54.626 --> 00:17:57.116 A:middle
So, accordingly you
will save registers,

00:17:57.116 --> 00:18:00.026 A:middle
you will get faster performance,
you'll get lower power


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:17:57.116 --> 00:18:00.026 A:middle
you will get faster performance,
you'll get lower power

00:18:00.266 --> 00:18:01.706 A:middle
by using smaller data types.

00:18:02.006 --> 00:18:04.496 A:middle
Use half and short for
arithmetic wherever you can.

00:18:05.276 --> 00:18:07.226 A:middle
Energy wise, half is
cheaper than float.

00:18:07.766 --> 00:18:09.526 A:middle
And float is cheaper
than integer,

00:18:09.886 --> 00:18:12.676 A:middle
but even among integers,
smaller integers are cheaper

00:18:12.676 --> 00:18:13.296 A:middle
than bigger ones.

00:18:13.866 --> 00:18:17.136 A:middle
And the most effective thing
you can do to save registers is

00:18:17.136 --> 00:18:20.816 A:middle
to use half for texture reads
and interpolates because most

00:18:20.816 --> 00:18:23.036 A:middle
of the time you really do
not need float for these.

00:18:23.446 --> 00:18:26.166 A:middle
And note I do not mean
your texture formats.

00:18:26.226 --> 00:18:29.006 A:middle
I mean the data types you're
using to store the results

00:18:29.006 --> 00:18:30.806 A:middle
of a texture sample
or an interpolate.

00:18:32.116 --> 00:18:36.656 A:middle
And one aspect of A8 in later
GPUs that is fairly convenient

00:18:37.146 --> 00:18:39.346 A:middle
and makes using smaller
data types easier

00:18:39.346 --> 00:18:40.656 A:middle
than on some other GPUs is

00:18:40.986 --> 00:18:43.986 A:middle
that data type conversions
are typically free,

00:18:44.166 --> 00:18:48.226 A:middle
even between float and half,
which means that you don't have

00:18:48.256 --> 00:18:51.336 A:middle
to worry, oh am I introducing
too many conversions in this

00:18:51.336 --> 00:18:53.006 A:middle
by trying to use half here?

00:18:53.266 --> 00:18:54.496 A:middle
Is this going to cost too much?

00:18:54.496 --> 00:18:55.286 A:middle
Is it worth it or not?

00:18:55.746 --> 00:18:58.266 A:middle
No it's probably fast because
the conversions are free,

00:18:58.626 --> 00:19:00.576 A:middle
so you can use half wherever
you want and not worry


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:18:58.626 --> 00:19:00.576 A:middle
so you can use half wherever
you want and not worry

00:19:00.576 --> 00:19:01.626 A:middle
about that part of it.

00:19:01.766 --> 00:19:03.526 A:middle
The one thing to keep
in mind here though is

00:19:03.586 --> 00:19:05.356 A:middle
that half-precision numerics

00:19:05.356 --> 00:19:08.106 A:middle
and limitations are
different from float.

00:19:08.996 --> 00:19:11.496 A:middle
And a common bug
that can come up here

00:19:11.496 --> 00:19:16.386 A:middle
for example is people will
write 65,535 as a half,

00:19:17.506 --> 00:19:19.766 A:middle
but that is actually infinity.

00:19:20.236 --> 00:19:22.666 A:middle
Because that's bigger
than the maximum half.

00:19:22.666 --> 00:19:25.116 A:middle
And so by being aware of
what these limitations are,

00:19:25.116 --> 00:19:27.146 A:middle
you'll better be able to
know where you perhaps should

00:19:27.146 --> 00:19:28.486 A:middle
and shouldn't use half.

00:19:28.486 --> 00:19:31.116 A:middle
And less likely to encounter
unexpected bugs in your shaders.

00:19:32.076 --> 00:19:34.216 A:middle
So one example application

00:19:34.216 --> 00:19:38.766 A:middle
for using smaller integer
data types is thread IDs.

00:19:39.356 --> 00:19:41.976 A:middle
And as those of you who worked
on computer kernels will know,

00:19:41.976 --> 00:19:44.506 A:middle
thread IDs are used
all over your programs.

00:19:45.076 --> 00:19:47.916 A:middle
And so making them smaller
can significantly increase the

00:19:47.966 --> 00:19:51.796 A:middle
performance of arithmetic, and
can save registers and so forth.

00:19:52.696 --> 00:19:57.076 A:middle
And so local thread IDs, there's
no reason to ever use uint

00:19:57.176 --> 00:19:58.616 A:middle
for them as in this case,

00:19:58.936 --> 00:20:01.436 A:middle
because local thread IDs can't
have that many thread IDs.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:58.936 --> 00:20:01.436 A:middle
because local thread IDs can't
have that many thread IDs.

00:20:02.076 --> 00:20:04.836 A:middle
For global thread IDs, usually
you can get away with a ushort

00:20:05.316 --> 00:20:06.946 A:middle
because most of the
time you don't have

00:20:06.946 --> 00:20:08.316 A:middle
that many global tread IDs.

00:20:08.316 --> 00:20:09.646 A:middle
Of course it depends
on your program.

00:20:10.056 --> 00:20:13.786 A:middle
But in most cases, you won't
go over 2 to the 16 minus 1,

00:20:14.276 --> 00:20:15.526 A:middle
so it is said you can do this.

00:20:16.186 --> 00:20:19.426 A:middle
And this is going to be lower
power, it's going to be faster

00:20:19.426 --> 00:20:22.326 A:middle
because all of the arithmetic
involving your thread ID is now

00:20:22.326 --> 00:20:23.296 A:middle
going to be faster.

00:20:23.576 --> 00:20:28.076 A:middle
So I highly recommend
this wherever possible.

00:20:28.636 --> 00:20:31.696 A:middle
Additionally, keep in mind
that in C like languages,

00:20:31.696 --> 00:20:33.856 A:middle
which of course includes
Metal, the precision

00:20:33.856 --> 00:20:37.126 A:middle
of an operation is defined by
the larger of the input types.

00:20:37.886 --> 00:20:39.946 A:middle
For example, if you're
multiplying a float by a half,

00:20:40.276 --> 00:20:43.566 A:middle
that's a float operation not a
half operation, it's promoted.

00:20:44.156 --> 00:20:47.456 A:middle
So accordingly, make sure
not to use float literals

00:20:47.456 --> 00:20:51.386 A:middle
when not necessary, because
that will turn here what appears

00:20:51.436 --> 00:20:53.786 A:middle
to be a half operation, it
takes a half and returns a half,

00:20:54.256 --> 00:20:55.546 A:middle
into a float operation.

00:20:55.586 --> 00:20:57.126 A:middle
Because by the language
semantics,

00:20:57.126 --> 00:20:59.886 A:middle
that's actually a float
operation since at least one

00:20:59.886 --> 00:21:01.056 A:middle
of the inputs is float.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:20:59.886 --> 00:21:01.056 A:middle
of the inputs is float.

00:21:01.856 --> 00:21:03.776 A:middle
And so you probably
want to do this.

00:21:04.636 --> 00:21:06.516 A:middle
This will actually
be a half operation.

00:21:06.516 --> 00:21:08.116 A:middle
This will actually be faster.

00:21:08.696 --> 00:21:10.206 A:middle
This is probably what you mean.

00:21:10.556 --> 00:21:11.586 A:middle
So be careful not

00:21:11.586 --> 00:21:14.066 A:middle
to inadvertently introduce
float precision arithmetic

00:21:14.066 --> 00:21:19.216 A:middle
into your code when
that's not what you meant.

00:21:19.216 --> 00:21:21.836 A:middle
And while I did mention that
smaller data types are better,

00:21:21.836 --> 00:21:24.556 A:middle
there's one exception to
this rule and that is char.

00:21:25.156 --> 00:21:27.606 A:middle
Remember as I said that
native data type size on A8

00:21:27.606 --> 00:21:30.686 A:middle
and later GPUs is
16-bit, not 8-bit.

00:21:31.466 --> 00:21:34.806 A:middle
And so char is not going to
save you any space or power

00:21:34.806 --> 00:21:35.606 A:middle
or anything like that

00:21:35.606 --> 00:21:38.126 A:middle
and furthermore there's no
native 8-bit arithmetic.

00:21:38.506 --> 00:21:40.006 A:middle
So it sort of has
to be emulated.

00:21:40.246 --> 00:21:43.296 A:middle
It's not overly expensive if you
need it, feel free to use it.

00:21:43.616 --> 00:21:45.616 A:middle
But it may result in
extra instructions.

00:21:45.836 --> 00:21:48.746 A:middle
So don't unnecessarily
shrink things to char

00:21:48.746 --> 00:21:53.706 A:middle
that don't actually need it.

00:21:53.966 --> 00:21:57.216 A:middle
So next we have arithmetic
optimizations,

00:21:57.436 --> 00:21:58.826 A:middle
and pretty much everything

00:21:58.826 --> 00:22:00.946 A:middle
in this category
affects ALU bandwidth.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:21:58.826 --> 00:22:00.946 A:middle
in this category
affects ALU bandwidth.

00:22:01.416 --> 00:22:05.106 A:middle
The first thing you can do
is always use Metal built-ins

00:22:05.106 --> 00:22:05.856 A:middle
whenever possible.

00:22:06.336 --> 00:22:07.846 A:middle
They're optimized
implementations

00:22:07.846 --> 00:22:09.016 A:middle
for a variety of functions.

00:22:09.206 --> 00:22:11.006 A:middle
They're already optimized
for the hardware.

00:22:11.316 --> 00:22:13.426 A:middle
It's generally better than
implementing them yourself.

00:22:14.426 --> 00:22:18.076 A:middle
And in particular,
there are some of these

00:22:18.156 --> 00:22:20.256 A:middle
that are usually
free in practice.

00:22:21.446 --> 00:22:24.416 A:middle
And this is because GPUs
typically have modifiers.

00:22:24.526 --> 00:22:27.176 A:middle
Operations that can be
performed for free on the input

00:22:27.176 --> 00:22:28.406 A:middle
and output of instructions.

00:22:28.956 --> 00:22:31.876 A:middle
And for A8 and later GPUs
these typically include negate,

00:22:32.246 --> 00:22:35.176 A:middle
absolute value, and
saturate as you can see here,

00:22:35.176 --> 00:22:36.686 A:middle
these three operations in green.

00:22:37.076 --> 00:22:41.666 A:middle
So, there's no point to trying
to "be clever" and speed

00:22:41.666 --> 00:22:44.046 A:middle
up your code by avoiding
those, because again,

00:22:44.046 --> 00:22:45.386 A:middle
they're almost always free.

00:22:45.716 --> 00:22:48.426 A:middle
And because they're free,
you can't do better than fee.

00:22:48.426 --> 00:22:50.306 A:middle
There's no way to
optimize better than free.

00:22:50.956 --> 00:22:54.486 A:middle
A8 and later GPUs, like a lot

00:22:54.486 --> 00:22:56.556 A:middle
of others nowadays,
are scalar machines.

00:22:57.226 --> 00:22:59.586 A:middle
And while shaders are
typically written with vectors,

00:22:59.636 --> 00:23:02.386 A:middle
the compiler is going to split
them all apart internally.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:59.636 --> 00:23:02.386 A:middle
the compiler is going to split
them all apart internally.

00:23:02.866 --> 00:23:05.256 A:middle
Of course, there's no downside
to writing vector code,

00:23:05.906 --> 00:23:08.996 A:middle
I mean often it's clearer,
often it's more maintainable,

00:23:09.026 --> 00:23:12.496 A:middle
often it fits what you're trying
to do, but it's also no better

00:23:12.496 --> 00:23:15.076 A:middle
than writing scaler code
from a compiler perspective

00:23:15.076 --> 00:23:15.936 A:middle
and the code you're
going to get.

00:23:16.546 --> 00:23:19.456 A:middle
So there's no point in
trying to vectorize code

00:23:19.456 --> 00:23:23.126 A:middle
that doesn't really fit a vector
format, because it's just going

00:23:23.126 --> 00:23:24.776 A:middle
to end up the same
thing in the end,

00:23:24.866 --> 00:23:27.066 A:middle
and you're kind of
wasting your time.

00:23:27.326 --> 00:23:29.216 A:middle
However, as a side
note, which I'll go

00:23:29.216 --> 00:23:32.146 A:middle
into more detail a lot later,
in later A8 and later GPUs,

00:23:32.146 --> 00:23:35.186 A:middle
do have vector load in store
even though they do not have

00:23:35.186 --> 00:23:36.156 A:middle
vector arithmetic.

00:23:36.596 --> 00:23:38.926 A:middle
So this only applies
to arithmetic here.

00:23:41.006 --> 00:23:43.626 A:middle
Instruction Level Parallelism
is something that some

00:23:43.626 --> 00:23:45.326 A:middle
of you may have used
optimizing for,

00:23:45.326 --> 00:23:47.336 A:middle
especially if you've
done work on CPUs.

00:23:47.866 --> 00:23:51.896 A:middle
But on A8 and later GPUs this
is generally not a good thing

00:23:51.896 --> 00:23:54.176 A:middle
to try to optimize for
because it typically works

00:23:54.176 --> 00:23:55.266 A:middle
against registry usage,

00:23:55.266 --> 00:23:57.376 A:middle
and registry usage
typically matters more.

00:23:57.966 --> 00:24:01.096 A:middle
So a common pattern you may
have seen is a kind of loop


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:23:57.966 --> 00:24:01.096 A:middle
So a common pattern you may
have seen is a kind of loop

00:24:01.096 --> 00:24:03.406 A:middle
where you have multiple
accumulators in order

00:24:03.406 --> 00:24:07.016 A:middle
to better deal with
latency on a CPU.

00:24:07.816 --> 00:24:11.376 A:middle
But on A8 and later GPUs this
is probably counterproductive.

00:24:11.776 --> 00:24:13.906 A:middle
You'd be better off just
using one accumulator.

00:24:14.156 --> 00:24:16.606 A:middle
Of course this applies to
much more complex examples

00:24:16.656 --> 00:24:18.686 A:middle
than the artificial
simple ones here.

00:24:19.256 --> 00:24:21.986 A:middle
Just write what you mean, don't
try to restructure your code

00:24:21.986 --> 00:24:23.346 A:middle
to get more ILP out of it.

00:24:23.346 --> 00:24:26.166 A:middle
It's probably not going to
help you at best, and at worst,

00:24:26.166 --> 00:24:28.906 A:middle
you just might get worse code.

00:24:29.686 --> 00:24:33.306 A:middle
So one fairly nice feature
of A8 and later GPUs is

00:24:33.386 --> 00:24:35.916 A:middle
that they have very
fast select instructions

00:24:35.916 --> 00:24:37.746 A:middle
that is the ternary operator.

00:24:38.476 --> 00:24:40.966 A:middle
And historically it's
been fairly common

00:24:40.966 --> 00:24:43.536 A:middle
to use clever tricks,
like this to try

00:24:43.536 --> 00:24:46.536 A:middle
to perform select
operations in ternaries

00:24:46.916 --> 00:24:49.066 A:middle
to avoid those branches
or whatever.

00:24:49.596 --> 00:24:52.986 A:middle
But on modern GPUs this is
usually counterproductive,

00:24:52.986 --> 00:24:56.846 A:middle
and especially on A8 later GPUs
because the compiler can't see

00:24:56.846 --> 00:24:57.786 A:middle
through this cleverness.

00:24:57.786 --> 00:25:00.116 A:middle
It's not going to figure
out what you actually mean.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:24:57.786 --> 00:25:00.116 A:middle
It's not going to figure
out what you actually mean.

00:25:00.646 --> 00:25:02.776 A:middle
And really, this is really ugly.

00:25:03.586 --> 00:25:04.756 A:middle
You could just have
written this.

00:25:04.756 --> 00:25:07.596 A:middle
And this is going to be faster,
shorter, and it's actually going

00:25:07.596 --> 00:25:08.246 A:middle
to show what you mean.

00:25:08.966 --> 00:25:12.776 A:middle
Like before, being overly clever
will often obfuscate what you're

00:25:12.776 --> 00:25:14.656 A:middle
trying to do and
confuse the compiler.

00:25:16.846 --> 00:25:18.676 A:middle
Now, this is a potential
major pitfall,

00:25:18.676 --> 00:25:20.116 A:middle
hopefully this won't
come up too much.

00:25:21.066 --> 00:25:26.106 A:middle
On modern GPUs most of them
do not have integer division

00:25:26.106 --> 00:25:28.796 A:middle
or modulus instructions,
integer not float.

00:25:29.616 --> 00:25:33.876 A:middle
So avoid divisional
modulus by denominators

00:25:33.906 --> 00:25:36.666 A:middle
that are not literal
or function consonants,

00:25:36.746 --> 00:25:38.876 A:middle
the new feature mentioned in
some of the earlier talks.

00:25:39.556 --> 00:25:43.036 A:middle
So in this example, what we
have over here, this first one

00:25:43.036 --> 00:25:45.426 A:middle
where the denominator
is a variable,

00:25:45.736 --> 00:25:47.756 A:middle
that will be very, very slow.

00:25:47.756 --> 00:25:49.356 A:middle
Think hundreds of clock seconds.

00:25:50.346 --> 00:25:52.506 A:middle
But these other two examples,
those will be very fast.

00:25:52.736 --> 00:25:53.256 A:middle
Those are fine.

00:25:53.626 --> 00:25:56.926 A:middle
So don't feel like you
have to avoid that.

00:25:57.616 --> 00:25:59.976 A:middle
So, finally the topic
of fast-math.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:26:00.996 --> 00:26:04.166 A:middle
So in Metal, fast-math
is on by default.

00:26:04.416 --> 00:26:07.286 A:middle
And this is because compiler
fast-math optimizations are

00:26:07.576 --> 00:26:09.616 A:middle
critical to performance
Metal shaders.

00:26:10.046 --> 00:26:13.156 A:middle
They can give off in 50%
performance gain or more

00:26:13.396 --> 00:26:14.946 A:middle
over having fast-math off.

00:26:14.946 --> 00:26:16.466 A:middle
So it's no wonder
it's on be default.

00:26:17.236 --> 00:26:20.226 A:middle
And so what exactly do
we do in fast-math mode?

00:26:20.846 --> 00:26:22.396 A:middle
Well, the first is that some

00:26:22.546 --> 00:26:25.206 A:middle
of the Metal built-in functions
have different precision

00:26:25.206 --> 00:26:27.646 A:middle
guarantees between
fast-math and non fast-math.

00:26:27.646 --> 00:26:30.146 A:middle
And so in some of them they will
have slightly lower precision

00:26:30.436 --> 00:26:33.236 A:middle
in fast-math mode to
get better performance.

00:26:34.576 --> 00:26:37.626 A:middle
The compiler may increase
the intermediate precision

00:26:37.626 --> 00:26:39.886 A:middle
of your operations like
by forming a fuse multiple

00:26:39.886 --> 00:26:40.686 A:middle
add instructions.

00:26:41.306 --> 00:26:44.206 A:middle
It will not decrease the
intermediate precision.

00:26:44.696 --> 00:26:48.086 A:middle
So for example if you write a
float operation you will get an

00:26:48.086 --> 00:26:50.296 A:middle
operation that is at
least a float operation.

00:26:50.376 --> 00:26:51.566 A:middle
Not a math operation.

00:26:52.096 --> 00:26:54.386 A:middle
So if you want to write half
operations you better write

00:26:54.466 --> 00:26:56.576 A:middle
that, the compiler will
not do that for you,

00:26:56.576 --> 00:26:57.556 A:middle
because it's not allowed to.

00:26:57.626 --> 00:27:00.456 A:middle
It can't your precision
like that.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:26:57.626 --> 00:27:00.456 A:middle
It can't your precision
like that.

00:27:00.976 --> 00:27:03.896 A:middle
We do ignore strict if not
a number, infinity steal,

00:27:03.896 --> 00:27:06.686 A:middle
and sign zero semantics,
which is fairly important,

00:27:06.686 --> 00:27:08.986 A:middle
because without that
you can't actually prove

00:27:08.986 --> 00:27:10.926 A:middle
that x times zero
is equal to zero.

00:27:11.906 --> 00:27:16.246 A:middle
But we will not introduce a new
not at new NaNs, not a number

00:27:16.666 --> 00:27:20.466 A:middle
because in practice
that's a really nice way

00:27:20.466 --> 00:27:22.496 A:middle
to annoy developers,
and break their code

00:27:22.496 --> 00:27:25.256 A:middle
and we don't want to do that.

00:27:25.256 --> 00:27:28.576 A:middle
And the compiler will perform
arithmetic re-association,

00:27:28.846 --> 00:27:30.676 A:middle
but it will not do
arithmetic distribution.

00:27:30.676 --> 00:27:34.046 A:middle
And really this just comes
down to what doesn't break code

00:27:34.046 --> 00:27:36.356 A:middle
and makes it faster versus
what does break code.

00:27:36.526 --> 00:27:38.406 A:middle
And we don't want to break code.

00:27:39.476 --> 00:27:44.006 A:middle
So if you absolutely cannot use
fast-math for whatever reason,

00:27:44.446 --> 00:27:47.116 A:middle
there are some ways to recover
some of that performance.

00:27:48.156 --> 00:27:51.866 A:middle
Metal has a fused multiply-add
built in which you can see here.

00:27:52.286 --> 00:27:54.266 A:middle
Which allows you to
directly request a fused

00:27:54.266 --> 00:27:55.496 A:middle
multiply-add instructions.

00:27:55.806 --> 00:27:57.146 A:middle
And of course if
fast-math is off,

00:27:57.146 --> 00:27:59.336 A:middle
the compiler is not even
allowed to make those,

00:27:59.386 --> 00:28:02.866 A:middle
it cannot change one bit of
your rounding, it is prohibited.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:27:59.386 --> 00:28:02.866 A:middle
it cannot change one bit of
your rounding, it is prohibited.

00:28:03.366 --> 00:28:05.886 A:middle
So if you want to use
fused multiply-add

00:28:05.886 --> 00:28:07.296 A:middle
and fast-math is
off, you're going

00:28:07.296 --> 00:28:08.406 A:middle
to have to use the built-in.

00:28:08.526 --> 00:28:11.086 A:middle
And that will regain
some of the performance,

00:28:11.476 --> 00:28:14.896 A:middle
not all of it, but
at least some.

00:28:15.136 --> 00:28:17.386 A:middle
So, on our third
topic, control flow.

00:28:18.456 --> 00:28:21.116 A:middle
Predicated GP control flow
is not a new topic and some

00:28:21.116 --> 00:28:22.856 A:middle
of you may already
be familiar with it.

00:28:22.896 --> 00:28:24.826 A:middle
But here's a quick review
of what it means for you.

00:28:25.606 --> 00:28:28.046 A:middle
Control flow that is
uniform across the SIMD,

00:28:28.046 --> 00:28:30.016 A:middle
that is every thread is
doing the same thing,

00:28:30.496 --> 00:28:31.326 A:middle
is generally fast.

00:28:31.856 --> 00:28:35.056 A:middle
And this is true even if
the compiler can't see that.

00:28:35.566 --> 00:28:39.776 A:middle
So if your program doesn't
appear uniform, but just happens

00:28:39.826 --> 00:28:44.786 A:middle
to be uniform when it runs,
that's still just as fast.

00:28:44.786 --> 00:28:46.936 A:middle
And similarly, the
opposite of this divergence,

00:28:46.936 --> 00:28:50.476 A:middle
different lanes doing different
things, well in that case,

00:28:50.476 --> 00:28:52.346 A:middle
it potentially may
have to run all

00:28:52.346 --> 00:28:55.476 A:middle
of the different paths
simultaneously unlike a CPU

00:28:55.476 --> 00:28:57.746 A:middle
which only takes
one path at a time.

00:28:58.386 --> 00:29:01.876 A:middle
And as a result it does more
work, which of course means


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:28:58.386 --> 00:29:01.876 A:middle
And as a result it does more
work, which of course means

00:29:01.906 --> 00:29:04.126 A:middle
that inefficient control
flow can affect any

00:29:04.126 --> 00:29:06.696 A:middle
of the bottlenecks, because it
just outright means the GPU is

00:29:06.756 --> 00:29:09.396 A:middle
doing more stuff, whatever
that stuff happens to be.

00:29:11.246 --> 00:29:16.176 A:middle
So, the one suggestion I'll make
on the topic of control flow is

00:29:16.176 --> 00:29:18.376 A:middle
to avoid switch fall-throughs.

00:29:18.666 --> 00:29:20.786 A:middle
And these are fairly
common in CPU code.

00:29:21.096 --> 00:29:24.006 A:middle
But on GPUs they can potentially
be somewhat inefficient,

00:29:24.266 --> 00:29:28.446 A:middle
because the compiler has to do
fairly nasty transformations

00:29:28.446 --> 00:29:30.806 A:middle
to make them fit within the
control flow model of GPUs.

00:29:30.806 --> 00:29:34.006 A:middle
And often this will involve
duplicating code and all sort

00:29:34.006 --> 00:29:36.636 A:middle
of nasty things you probably
would rather not be happening.

00:29:37.216 --> 00:29:39.966 A:middle
So if you can find a nice way to
avoid these switch fall-throughs

00:29:39.966 --> 00:29:41.636 A:middle
in your code, you'll
probably be better off.

00:29:42.526 --> 00:29:45.076 A:middle
So now we're on to
our final topic.

00:29:45.366 --> 00:29:46.166 A:middle
Memory access.

00:29:46.446 --> 00:29:48.296 A:middle
And we'll start with
the biggest pitfall

00:29:48.526 --> 00:29:50.156 A:middle
that people most
commonly run into

00:29:50.156 --> 00:29:54.946 A:middle
and that is dynamically indexed
non-constant stack arrays.

00:29:55.116 --> 00:29:56.516 A:middle
Now that's quite a mouthful,

00:29:56.516 --> 00:29:59.506 A:middle
but a lot of you probably
are familiar with code

00:29:59.506 --> 00:30:00.466 A:middle
that looks vaguely like this.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:59.506 --> 00:30:00.466 A:middle
that looks vaguely like this.

00:30:01.046 --> 00:30:04.626 A:middle
You have an array that consist
of values that are defined

00:30:04.626 --> 00:30:08.226 A:middle
in runtime and vary between each
thread or each function call.

00:30:08.226 --> 00:30:10.986 A:middle
And you index it to the
array with another value

00:30:10.986 --> 00:30:12.076 A:middle
that is also a variable.

00:30:12.416 --> 00:30:15.026 A:middle
That is a dynamically indexed
non-constant stack array.

00:30:15.846 --> 00:30:18.436 A:middle
Now before we go on, I'm
not going to ask you to take

00:30:18.436 --> 00:30:20.966 A:middle
for grabs at the idea that
stacks are slow on GPUs.

00:30:20.966 --> 00:30:22.456 A:middle
I'm going to explain why.

00:30:23.306 --> 00:30:26.446 A:middle
So, on CPUs typically you
have like a couple threads,

00:30:26.546 --> 00:30:29.506 A:middle
maybe a dozen threads, and you
have megabytes of cache split

00:30:29.546 --> 00:30:30.276 A:middle
between those threads.

00:30:30.396 --> 00:30:33.126 A:middle
So every thread can have
hundreds of kilobytes

00:30:33.126 --> 00:30:35.366 A:middle
of stack space before they
get really slow and have

00:30:35.406 --> 00:30:36.506 A:middle
to head off to main memory.

00:30:37.336 --> 00:30:40.956 A:middle
On a GPU you often have tens of
thousands of threads running.

00:30:41.016 --> 00:30:43.976 A:middle
And they're all sharing
a much smaller cache too.

00:30:44.256 --> 00:30:46.356 A:middle
So when it comes down to
it each thread has very,

00:30:46.356 --> 00:30:48.436 A:middle
very little space
for data for a stack.

00:30:49.206 --> 00:30:52.176 A:middle
It's just not meant for that,
it's not efficient and so

00:30:52.176 --> 00:30:54.966 A:middle
as a general rule,
for most GPU programs,

00:30:54.966 --> 00:30:57.276 A:middle
if you're using the
stack, you've already lost.

00:30:57.326 --> 00:31:00.786 A:middle
It's so slow that almost
anything else would have


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:57.326 --> 00:31:00.786 A:middle
It's so slow that almost
anything else would have

00:31:00.786 --> 00:31:01.156 A:middle
been better.

00:31:02.696 --> 00:31:06.856 A:middle
And an example for a real
world app is at the start

00:31:06.856 --> 00:31:09.586 A:middle
of the program it needed
to select one of two float

00:31:09.586 --> 00:31:12.376 A:middle
for vectors, so it
used a 32-byte array,

00:31:12.376 --> 00:31:14.836 A:middle
an array of two float
fours and tried to select

00:31:14.916 --> 00:31:16.336 A:middle
between them using
this stack array.

00:31:16.336 --> 00:31:18.996 A:middle
And that caused a
30% performance loss

00:31:18.996 --> 00:31:21.076 A:middle
in this program even though it's
only done once at the start.

00:31:21.546 --> 00:31:24.036 A:middle
It can be pretty significant.

00:31:24.716 --> 00:31:27.516 A:middle
And of course every time we
improve the compiler we are

00:31:27.516 --> 00:31:30.936 A:middle
going to try harder and harder
to avoid, do anything we can

00:31:31.546 --> 00:31:34.706 A:middle
to avoid generating these stack
access because it is that bad.

00:31:35.806 --> 00:31:38.186 A:middle
Now I'll show you two
examples here that are okay.

00:31:39.636 --> 00:31:42.876 A:middle
This other one, you can
see those are constants,

00:31:42.976 --> 00:31:43.666 A:middle
not variables.

00:31:44.026 --> 00:31:46.706 A:middle
It's not a non-constant
stack array and that's fine

00:31:47.266 --> 00:31:50.706 A:middle
because the values don't vary
per threads, they don't need

00:31:50.706 --> 00:31:51.856 A:middle
to be duplicated per thread.

00:31:52.426 --> 00:31:54.506 A:middle
So that's okay.

00:31:54.856 --> 00:31:56.406 A:middle
And this one is also okay.

00:31:56.616 --> 00:31:57.136 A:middle
Wait, why?

00:31:57.136 --> 00:31:59.486 A:middle
It's still a dynamically indexed
non-constant stack array.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:00.116 --> 00:32:02.646 A:middle
But it's only done dynamically
indexed because of this loop.

00:32:03.266 --> 00:32:06.116 A:middle
And the compiler is going
to unroll that loop.

00:32:06.476 --> 00:32:09.526 A:middle
In fact, your compiler
aggressively unrolls any loop

00:32:09.526 --> 00:32:12.426 A:middle
that is accessing the stack to
try to make it stop doing that.

00:32:13.256 --> 00:32:15.836 A:middle
So in this case after it's
unrolled it will no longer be

00:32:15.836 --> 00:32:17.326 A:middle
dynamically indexed,
so it will be fast.

00:32:17.326 --> 00:32:18.796 A:middle
And this is worth mentioning,

00:32:18.796 --> 00:32:20.706 A:middle
because this is a fairly
common pattern in a lot

00:32:20.706 --> 00:32:23.336 A:middle
of graphics code and I don't
want to scare you into not doing

00:32:23.336 --> 00:32:24.676 A:middle
that when it's probably fine.

00:32:25.516 --> 00:32:27.986 A:middle
So now that we've gone
over the topic of how

00:32:27.986 --> 00:32:30.236 A:middle
to not do certain types
of loads and stores,

00:32:30.536 --> 00:32:32.426 A:middle
let's go on to making
the loads and stores

00:32:32.426 --> 00:32:34.556 A:middle
that we do actually fast.

00:32:35.416 --> 00:32:38.066 A:middle
Now while A8 and later
GPUs use scalar arithmetic,

00:32:38.066 --> 00:32:41.236 A:middle
as I went over earlier, they
do have vector memory units.

00:32:42.006 --> 00:32:45.546 A:middle
And one big vector loading
source of course faster

00:32:45.546 --> 00:32:48.746 A:middle
than multiple smaller ones
that sum up to the same size.

00:32:49.616 --> 00:32:52.266 A:middle
And this typically effects the
memory issue rate bottleneck

00:32:52.326 --> 00:32:53.266 A:middle
because if you're running

00:32:53.266 --> 00:32:55.186 A:middle
through a loads,
that's fewer loads.

00:32:56.266 --> 00:33:00.136 A:middle
And, so as of iOS 10, one of
our new compiler optimizations,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:56.266 --> 00:33:00.136 A:middle
And, so as of iOS 10, one of
our new compiler optimizations,

00:33:00.136 --> 00:33:03.186 A:middle
is we will try to vectorize
some loads and stores that go

00:33:03.186 --> 00:33:05.396 A:middle
to neighboring memory
locations wherever we can,

00:33:05.626 --> 00:33:07.766 A:middle
because again it can give
good performance improvements.

00:33:08.956 --> 00:33:12.656 A:middle
But nevertheless, this is one
of the cases where working

00:33:12.656 --> 00:33:14.286 A:middle
with the compiler
can be very helpful,

00:33:14.536 --> 00:33:15.436 A:middle
and I'll give an example.

00:33:16.436 --> 00:33:18.336 A:middle
So as you can see here,
here's a simple loop

00:33:18.436 --> 00:33:21.016 A:middle
that does some arithmetic and
reads in an array of structures,

00:33:21.876 --> 00:33:25.066 A:middle
but on each iteration,
it reads just two loads.

00:33:25.506 --> 00:33:27.696 A:middle
Now we would want that
to be one if we could,

00:33:27.696 --> 00:33:29.856 A:middle
because one is better than two.

00:33:29.856 --> 00:33:32.096 A:middle
And the compiler wants that too.

00:33:32.096 --> 00:33:34.976 A:middle
It wants to try to vectorize
this but it can't, because A

00:33:34.976 --> 00:33:36.886 A:middle
and C aren't next to
each other in memory

00:33:36.886 --> 00:33:37.896 A:middle
so there's nothing it can do.

00:33:37.896 --> 00:33:39.976 A:middle
The compiler's not allowed
to rearrange your structs,

00:33:40.256 --> 00:33:41.156 A:middle
so we've got two loads.

00:33:42.186 --> 00:33:43.436 A:middle
There's two solutions to this.

00:33:44.036 --> 00:33:46.536 A:middle
Number one, of course,
just make it a float to,

00:33:46.536 --> 00:33:47.966 A:middle
now it's a vector
load, you're done.

00:33:48.696 --> 00:33:49.996 A:middle
One load, a set of
two, we're all good.

00:33:51.176 --> 00:33:54.946 A:middle
Also, as of iOS 10, this
should also be equally fast,

00:33:55.276 --> 00:33:56.986 A:middle
because here, we've
reordered our struct

00:33:56.986 --> 00:33:58.486 A:middle
to put the values
next to each other,

00:33:58.836 --> 00:34:00.936 A:middle
so the compiler can
now vectorize the loads


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:33:58.836 --> 00:34:00.936 A:middle
so the compiler can
now vectorize the loads

00:34:00.936 --> 00:34:01.936 A:middle
when it's doing it.

00:34:02.256 --> 00:34:05.286 A:middle
And this is an example again
of working with the compiler,

00:34:05.636 --> 00:34:08.616 A:middle
you've allowed the compiler to
do something it couldn't before,

00:34:08.726 --> 00:34:11.295 A:middle
because you understand
what's going on.

00:34:11.295 --> 00:34:13.766 A:middle
You understand how the
patterns need to be

00:34:13.766 --> 00:34:15.246 A:middle
to make the compiler happy

00:34:15.516 --> 00:34:18.916 A:middle
and make it able to
do a [inaudible].

00:34:19.835 --> 00:34:23.216 A:middle
So, another thing to keep in
mind with loads and stores is

00:34:23.216 --> 00:34:26.235 A:middle
that A8 and later GPUs
have dedicated hardware

00:34:26.235 --> 00:34:31.735 A:middle
for device memory addressing,
but this hardware has limits.

00:34:32.406 --> 00:34:35.065 A:middle
The offset for accessing
device memory must fit

00:34:35.065 --> 00:34:36.406 A:middle
within a signed integer.

00:34:36.876 --> 00:34:39.335 A:middle
Smaller types like short
and ushort are also okay,

00:34:39.335 --> 00:34:40.916 A:middle
in fact they're highly
encouraged,

00:34:41.416 --> 00:34:43.545 A:middle
because those do also fit
within a signed integer.

00:34:44.366 --> 00:34:47.786 A:middle
However, of course uint does
not because it can have values

00:34:47.786 --> 00:34:49.076 A:middle
out of range of signed integer.

00:34:49.696 --> 00:34:54.076 A:middle
And so if the compiler
runs into a situation

00:34:54.076 --> 00:34:56.716 A:middle
where the offset is a
uint and it cannot prove

00:34:56.775 --> 00:34:58.896 A:middle
that it will safely fit
within a signed integer,

00:34:59.266 --> 00:35:01.596 A:middle
it has to manually
calculate the address,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:59.266 --> 00:35:01.596 A:middle
it has to manually
calculate the address,

00:35:02.156 --> 00:35:04.086 A:middle
rather than letting the
dedicated hardware do it.

00:35:04.366 --> 00:35:05.656 A:middle
And that can waste power,

00:35:05.786 --> 00:35:08.886 A:middle
it can waste ALU
performance and so forth.

00:35:09.006 --> 00:35:10.066 A:middle
It's not good.

00:35:10.626 --> 00:35:15.396 A:middle
So, change your offset to
int, now the problem's solved.

00:35:15.396 --> 00:35:16.426 A:middle
And of course taking advantage

00:35:16.426 --> 00:35:18.606 A:middle
to this will typically
save you ALU bandwidth.

00:35:21.496 --> 00:35:23.626 A:middle
So now on to our final
topic that I sort of glossed

00:35:23.626 --> 00:35:25.476 A:middle
over earlier, latency
and occupancy.

00:35:26.266 --> 00:35:28.496 A:middle
So one of the core
design tenants

00:35:28.496 --> 00:35:30.316 A:middle
of modern GPUs is
they hide latency

00:35:30.316 --> 00:35:32.146 A:middle
by using large scale
multithreading.

00:35:32.646 --> 00:35:34.866 A:middle
So when they're waiting for
something slow to finish,

00:35:34.866 --> 00:35:36.856 A:middle
like a texture read,
they just go

00:35:36.856 --> 00:35:37.896 A:middle
and run another thread instead

00:35:37.896 --> 00:35:39.336 A:middle
of sitting there doing
nothing while waiting.

00:35:39.336 --> 00:35:40.536 A:middle
And this is fairly important

00:35:40.536 --> 00:35:43.426 A:middle
because texture reads typically
take a couple hundred cycles

00:35:43.426 --> 00:35:44.656 A:middle
to complete on average.

00:35:47.306 --> 00:35:49.536 A:middle
And so the more latency
you have in a shader,

00:35:49.536 --> 00:35:52.066 A:middle
the more threads you need
to hide that latency,

00:35:52.606 --> 00:35:53.776 A:middle
and how many threads
can you have?

00:35:54.236 --> 00:35:56.526 A:middle
Well it's limited by the fact
that you have a fixed set

00:35:56.526 --> 00:35:58.116 A:middle
of resources that are shared

00:35:58.116 --> 00:35:59.696 A:middle
between threads in
a thread group.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:36:00.016 --> 00:36:02.706 A:middle
So clearly depending on
how much each thread uses,

00:36:02.706 --> 00:36:04.596 A:middle
you have a limitation on
the number of threads.

00:36:04.846 --> 00:36:07.006 A:middle
And the two things that
are split are the number

00:36:07.006 --> 00:36:08.766 A:middle
of registers and
thread group memory.

00:36:09.316 --> 00:36:11.136 A:middle
So if you use more
registers per thread,

00:36:11.306 --> 00:36:12.606 A:middle
now you can't have
as many threads.

00:36:12.716 --> 00:36:13.126 A:middle
Simple enough.

00:36:13.606 --> 00:36:17.626 A:middle
And if you use more thread group
memory per thread, again you run

00:36:17.626 --> 00:36:18.646 A:middle
into the same problem,

00:36:18.806 --> 00:36:20.936 A:middle
more thread your memory per
thread means to your threads.

00:36:21.726 --> 00:36:25.316 A:middle
And you can actually check out
the occupancy of your shader

00:36:25.636 --> 00:36:29.416 A:middle
by using MTLComputePipeLineState
incurring

00:36:29.416 --> 00:36:31.306 A:middle
maxTotalThreadsPerThreadgroup,

00:36:31.646 --> 00:36:33.826 A:middle
which will tell you what
the actual occupancy

00:36:33.826 --> 00:36:36.776 A:middle
of your shader is based
on the register usage

00:36:36.846 --> 00:36:39.486 A:middle
and the thread group
memory usage.

00:36:40.006 --> 00:36:42.346 A:middle
And so when we say a
shader is latency limited,

00:36:42.626 --> 00:36:44.426 A:middle
it means you have
too few threads

00:36:44.496 --> 00:36:45.806 A:middle
to hide the latency of a shader.

00:36:45.806 --> 00:36:47.436 A:middle
And there's two things
you can do there,

00:36:47.696 --> 00:36:49.616 A:middle
you can either reduce the
latency of your shader,

00:36:50.016 --> 00:36:52.296 A:middle
your save registers
or whatever else it is

00:36:52.476 --> 00:36:54.546 A:middle
that is preventing you
from having more threads.

00:36:57.066 --> 00:37:02.236 A:middle
So, since it's kind of
hard to go over latency


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:36:57.066 --> 00:37:02.236 A:middle
So, since it's kind of
hard to go over latency

00:37:02.236 --> 00:37:03.856 A:middle
in a very large complex shader.

00:37:04.246 --> 00:37:06.356 A:middle
I'll go over a little bit
of a pseudocode example

00:37:06.356 --> 00:37:08.516 A:middle
that will hopefully give you
a big of an intuition of how

00:37:08.516 --> 00:37:10.496 A:middle
to think about latency
and how to sort

00:37:10.496 --> 00:37:12.926 A:middle
of mentally model
in your shaders.

00:37:14.166 --> 00:37:16.666 A:middle
So, here's an example
of a REAL dependency.

00:37:17.066 --> 00:37:19.686 A:middle
We have a texture sample,
and then we use the operative

00:37:19.686 --> 00:37:21.786 A:middle
of that texture sample
to run an if statement

00:37:21.786 --> 00:37:24.306 A:middle
and then we do another texture
sample inside that x statement.

00:37:24.986 --> 00:37:26.056 A:middle
We have to wait twice.

00:37:26.056 --> 00:37:28.706 A:middle
Because we have to wait once
before doing the if statement.

00:37:29.016 --> 00:37:31.566 A:middle
And we have to wait again
before using the value

00:37:31.566 --> 00:37:32.836 A:middle
from the second texture sample.

00:37:32.836 --> 00:37:36.566 A:middle
So that's two serial
texture accesses

00:37:37.026 --> 00:37:38.716 A:middle
for a total of twice
the latency.

00:37:40.326 --> 00:37:42.416 A:middle
Now here's an example
of a false dependency.

00:37:42.416 --> 00:37:43.456 A:middle
It looks a lot like the other,

00:37:43.456 --> 00:37:45.716 A:middle
except we're not using
a in the if statement.

00:37:46.906 --> 00:37:51.086 A:middle
But typically, we can't
wait across control flow.

00:37:51.346 --> 00:37:54.366 A:middle
The if statement acts an
effective barrier in this case.

00:37:54.706 --> 00:37:56.746 A:middle
So, we automatically have

00:37:56.886 --> 00:37:59.796 A:middle
to wait here anyways even though
there's no data dependency.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:38:00.116 --> 00:38:01.636 A:middle
So we still get twice
the latency.

00:38:02.006 --> 00:38:04.386 A:middle
As you noticed the GPU
does not actually care

00:38:04.456 --> 00:38:05.656 A:middle
about your data dependencies.

00:38:06.046 --> 00:38:09.406 A:middle
It only cares about what the
dependencies appear to be

00:38:09.966 --> 00:38:13.106 A:middle
and so the second one will
be just as long latency

00:38:13.106 --> 00:38:15.196 A:middle
as the first one, even
though there isn't a data

00:38:15.196 --> 00:38:16.016 A:middle
dependency there.

00:38:16.846 --> 00:38:19.426 A:middle
And then finally
here's a simple one

00:38:19.426 --> 00:38:21.326 A:middle
where you just have two
texture reads at the top,

00:38:21.946 --> 00:38:23.826 A:middle
and they can both
be done in parallel

00:38:24.456 --> 00:38:26.626 A:middle
and then we can have
a single wait.

00:38:26.746 --> 00:38:29.186 A:middle
So it's 1 x instead
of 2 x for latency.

00:38:30.226 --> 00:38:32.386 A:middle
So, what are you going to
do with this knowledge?

00:38:32.696 --> 00:38:36.146 A:middle
So in many real world
shaders you have opportunities

00:38:36.146 --> 00:38:38.466 A:middle
to tradeoff between
latency and throughput.

00:38:39.046 --> 00:38:41.946 A:middle
And a common example of this
might be that you have some code

00:38:41.946 --> 00:38:45.956 A:middle
where based on one texture read
you can decide, oh we don't need

00:38:45.956 --> 00:38:48.776 A:middle
to do anything in this shader,
we're going to quit early.

00:38:48.776 --> 00:38:50.436 A:middle
And that can be very useful.

00:38:50.436 --> 00:38:53.366 A:middle
Because now all that work
that's being done in the cases

00:38:53.366 --> 00:38:54.546 A:middle
where you don't need
it to be done,

00:38:55.026 --> 00:38:56.056 A:middle
you're saving all that work.

00:38:56.346 --> 00:38:57.036 A:middle
That's great.

00:38:57.386 --> 00:39:01.816 A:middle
But now you're increasing
your throughput


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:38:57.386 --> 00:39:01.816 A:middle
But now you're increasing
your throughput

00:39:02.596 --> 00:39:04.156 A:middle
by reducing the amount
of work you need to do.

00:39:05.026 --> 00:39:09.256 A:middle
But you're also increasing
your latency because now it has

00:39:09.316 --> 00:39:12.866 A:middle
to do the first texture read,
then wait for that texture read,

00:39:13.306 --> 00:39:14.956 A:middle
then do your early
termination check,

00:39:15.336 --> 00:39:18.616 A:middle
and then do whatever other
texture reads you have.

00:39:18.996 --> 00:39:20.626 A:middle
And well is it faster?

00:39:20.626 --> 00:39:21.106 A:middle
Is it not?

00:39:21.476 --> 00:39:23.976 A:middle
Often you just have to test.

00:39:24.386 --> 00:39:26.756 A:middle
Because which is faster
is really going to depend

00:39:26.756 --> 00:39:28.966 A:middle
on your shader, but it's
a thing worth being aware

00:39:28.966 --> 00:39:32.026 A:middle
of that often is a real
tradeoff and you often have

00:39:32.096 --> 00:39:33.436 A:middle
to experiment to
see what's right.

00:39:34.246 --> 00:39:35.976 A:middle
Now, while there isn't
a universal rule,

00:39:35.976 --> 00:39:39.056 A:middle
there is one particular
guideline I can give for A8

00:39:39.056 --> 00:39:43.016 A:middle
and later GPUs and that is
typically the hardware needs

00:39:43.016 --> 00:39:45.556 A:middle
at least two texture
reads at a time

00:39:45.556 --> 00:39:47.706 A:middle
to get full ability
to hide latency.

00:39:48.206 --> 00:39:49.086 A:middle
One is not enough.

00:39:49.896 --> 00:39:51.656 A:middle
If you have to do
one, no problem.

00:39:51.706 --> 00:39:53.816 A:middle
But if you have some choice

00:39:53.816 --> 00:39:55.726 A:middle
in how you arrange your
texture reads in your shader,

00:39:55.946 --> 00:39:58.066 A:middle
if you allow it to do
at least two at a time,

00:39:58.266 --> 00:39:59.416 A:middle
you may get better performance.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:40:01.326 --> 00:40:02.236 A:middle
So, in summary.

00:40:03.576 --> 00:40:06.436 A:middle
Make sure you pick the correct
address spaces, data structures,

00:40:06.436 --> 00:40:09.556 A:middle
layouts and so forth, because
getting this wrong is going

00:40:09.556 --> 00:40:11.676 A:middle
to hurt so much that often
none of the other stuff

00:40:11.676 --> 00:40:12.816 A:middle
in the presentation will matter.

00:40:14.326 --> 00:40:15.646 A:middle
Work with the compiler.

00:40:15.646 --> 00:40:16.506 A:middle
Write what you mean.

00:40:17.086 --> 00:40:18.476 A:middle
Don't try to be too clever,

00:40:18.476 --> 00:40:20.966 A:middle
or the compiler won't know what
you mean and will get lost,

00:40:21.406 --> 00:40:22.786 A:middle
and won't be able to do its job.

00:40:23.656 --> 00:40:25.456 A:middle
Plus, it's easier to
write what you mean.

00:40:26.976 --> 00:40:28.566 A:middle
Keep an eye out for
the big pitfalls,

00:40:28.566 --> 00:40:30.156 A:middle
not just the
micro-optimizations.

00:40:30.386 --> 00:40:32.796 A:middle
They're often not as obvious,
and they often don't come

00:40:32.796 --> 00:40:35.326 A:middle
up as often, but when
they do, they hurt.

00:40:35.456 --> 00:40:37.716 A:middle
And they will hurt so
much that no number

00:40:37.716 --> 00:40:39.346 A:middle
of micro-optimizations
will save you.

00:40:40.986 --> 00:40:42.466 A:middle
And feel free to experiment.

00:40:42.696 --> 00:40:44.926 A:middle
There's a number of rule
tradeoffs that happen,

00:40:44.926 --> 00:40:47.646 A:middle
where there's simply
no single rule.

00:40:48.076 --> 00:40:49.946 A:middle
And try them both,
see what's faster.

00:40:51.936 --> 00:40:54.486 A:middle
So, if you want more
information, go online.

00:40:54.486 --> 00:40:55.886 A:middle
The video of the talk
will be up there.

00:40:55.886 --> 00:40:59.946 A:middle
Here are the other session if
you missed them earlier, again,

00:40:59.946 --> 00:41:01.406 A:middle
the videos will be online.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:40:59.946 --> 00:41:01.406 A:middle
the videos will be online.

00:41:02.936 --> 00:41:03.246 A:middle
Thank you.

