WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:08.516 --> 00:00:17.500 A:middle
[ Music ]

00:00:23.216 --> 00:00:24.276 A:middle
&gt;&gt; Good morning.

00:00:25.666 --> 00:00:27.896 A:middle
Morning everyone and
welcome to session 501.

00:00:28.526 --> 00:00:29.466 A:middle
I'm Brad Ford.

00:00:29.686 --> 00:00:30.816 A:middle
I work on the Core Media

00:00:30.816 --> 00:00:32.986 A:middle
and AV Foundation
Capture Teams at Apple.

00:00:34.726 --> 00:00:37.206 A:middle
And this session is all
about the iOS camera.

00:00:37.416 --> 00:00:38.836 A:middle
Hopefully you've
figured that out by now.

00:00:38.986 --> 00:00:41.366 A:middle
This is the most popular
camera in the world.

00:00:41.536 --> 00:00:43.616 A:middle
And it's also about photography.

00:00:43.866 --> 00:00:47.316 A:middle
If you develop a photography
app, or even just thinking

00:00:47.316 --> 00:00:48.856 A:middle
about developing
a photography app,

00:00:49.276 --> 00:00:51.366 A:middle
then this is a very
good OS for you.

00:00:51.506 --> 00:00:54.666 A:middle
I think you and iOS 10 are
about to become fast friends.

00:00:55.666 --> 00:00:58.196 A:middle
Today we'll be focusing on
the AV Foundation framework,

00:00:58.306 --> 00:01:01.336 A:middle
which is our lowest level
and most powerful framework


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:58.306 --> 00:01:01.336 A:middle
which is our lowest level
and most powerful framework

00:01:01.336 --> 00:01:02.446 A:middle
for accessing the camera.

00:01:02.446 --> 00:01:05.025 A:middle
AV Foundation is broad and deep.

00:01:05.316 --> 00:01:08.016 A:middle
If you're new to camera
capture on iOS, I invite you

00:01:08.016 --> 00:01:12.376 A:middle
to review our past WWC camera
presentation videos listed here.

00:01:13.076 --> 00:01:16.046 A:middle
They give you a good base for
today's presentation and plus,

00:01:16.046 --> 00:01:17.636 A:middle
you get to watch
me age gracefully.

00:01:18.116 --> 00:01:22.086 A:middle
Here's what we're going to
do for the next 58 minutes.

00:01:22.876 --> 00:01:26.006 A:middle
I'll present a brand
new AVCaptureOutput

00:01:26.206 --> 00:01:29.166 A:middle
for capturing photographic
content, and then we're going

00:01:29.166 --> 00:01:30.986 A:middle
to focus on four feature areas.

00:01:30.986 --> 00:01:34.096 A:middle
We're going to focus
on Live Photos.

00:01:34.266 --> 00:01:36.166 A:middle
You'll learn how to capture
Live Photos in your app,

00:01:36.426 --> 00:01:38.106 A:middle
just like Apple's camera app.

00:01:38.916 --> 00:01:41.976 A:middle
You'll learn how to capture
bare RAW images and store them

00:01:41.976 --> 00:01:45.236 A:middle
to DNG files, which is a
first on our platform in iOS.

00:01:46.146 --> 00:01:47.636 A:middle
You'll learn about
how to get preview

00:01:47.636 --> 00:01:51.006 A:middle
or thumbnail images along with
your regular photo captures

00:01:51.006 --> 00:01:52.286 A:middle
for a more responsive UI.

00:01:53.766 --> 00:01:56.196 A:middle
And lastly, you'll learn
how to capture gorgeous,

00:01:56.256 --> 00:01:58.416 A:middle
vivid images in wide color.

00:01:58.976 --> 00:01:59.676 A:middle
Let's get started.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:02:00.476 --> 00:02:01.436 A:middle
Here's a quick refresher

00:02:01.436 --> 00:02:03.716 A:middle
on how AV Foundation's
capture classes work.

00:02:04.216 --> 00:02:06.216 A:middle
At the center of our
capture universe is

00:02:06.216 --> 00:02:07.636 A:middle
the AVCaptureSession.

00:02:08.106 --> 00:02:10.795 A:middle
This is the object you tell
it to start or stop running.

00:02:11.466 --> 00:02:14.776 A:middle
In order to do anything useful,
though, it needs some inputs.

00:02:14.776 --> 00:02:17.066 A:middle
Inputs like a camera
or a microphone.

00:02:17.476 --> 00:02:19.476 A:middle
And they provide
data to the session.

00:02:19.746 --> 00:02:22.086 A:middle
And it also needs outputs
to receive the data,

00:02:22.476 --> 00:02:25.686 A:middle
such as a StillImageOutput
which can capture still images

00:02:26.036 --> 00:02:27.796 A:middle
or a QuickTime movie
file output,

00:02:27.866 --> 00:02:29.316 A:middle
which records QuickTime movies.

00:02:30.156 --> 00:02:34.736 A:middle
There are also connections, and
these are represented in the API

00:02:34.876 --> 00:02:36.506 A:middle
as AVCaptureConnections.

00:02:36.866 --> 00:02:38.496 A:middle
That's our overall object graph.

00:02:38.496 --> 00:02:40.866 A:middle
You've kind of seen how we
all put things together.

00:02:42.006 --> 00:02:43.596 A:middle
All of these features,
I just mentioned,

00:02:43.596 --> 00:02:45.076 A:middle
relate to taking still images.

00:02:45.076 --> 00:02:47.516 A:middle
So we might expect that we'd
be spending a lot of time

00:02:47.516 --> 00:02:51.586 A:middle
in the AVCaptureStillImageOutput
today but you'd be wrong.

00:02:53.196 --> 00:02:56.696 A:middle
Today we're introducing a brand
new CaptureOutput in iOS 10.

00:02:56.696 --> 00:02:58.966 A:middle
And it's called the
AVCapturePhotoOutput,

00:02:59.406 --> 00:03:01.936 A:middle
emphasizing the fact that
our photos are much more


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:02:59.406 --> 00:03:01.936 A:middle
emphasizing the fact that
our photos are much more

00:03:01.936 --> 00:03:03.416 A:middle
than static still images now.

00:03:04.496 --> 00:03:09.236 A:middle
AVCapturePhotoOutput addresses
AVStillImageOutput's design

00:03:09.236 --> 00:03:11.736 A:middle
challenges in four main areas.

00:03:12.446 --> 00:03:14.906 A:middle
It features a functional
programming model.

00:03:15.196 --> 00:03:16.476 A:middle
There are clear delineations

00:03:16.476 --> 00:03:18.546 A:middle
between mutable and
immutable data.

00:03:19.456 --> 00:03:21.236 A:middle
We've encapsulated
photo settings

00:03:21.236 --> 00:03:23.636 A:middle
into a distinct object
unto itself.

00:03:24.556 --> 00:03:27.846 A:middle
And the PhotoOutput can
track your photo's progress

00:03:27.846 --> 00:03:29.186 A:middle
from request to completion

00:03:29.506 --> 00:03:32.196 A:middle
through a delegate-style
interface of callbacks.

00:03:32.726 --> 00:03:36.456 A:middle
And lastly, it resolves your
indeterminate photo settings

00:03:36.456 --> 00:03:37.896 A:middle
early in the capture process,

00:03:38.166 --> 00:03:39.716 A:middle
so you know what you're
going to be getting.

00:03:39.776 --> 00:03:42.916 A:middle
Let's talk a little bit more
about that last feature there.

00:03:44.276 --> 00:03:46.356 A:middle
Here's what an
AVCapturePhotoOutput looks like.

00:03:46.666 --> 00:03:49.736 A:middle
Even with all its new features,
it's a very thin interface,

00:03:49.826 --> 00:03:52.536 A:middle
smaller even than
AVCaptureStillImageOutput.

00:03:52.976 --> 00:03:55.236 A:middle
It has a small set of
read-only properties

00:03:55.556 --> 00:03:57.896 A:middle
that tell you whether particular
features are supported,

00:03:58.196 --> 00:04:00.626 A:middle
such as is
LivePhotoCaptureSupported?


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:58.196 --> 00:04:00.626 A:middle
such as is
LivePhotoCaptureSupported?

00:04:01.346 --> 00:04:04.536 A:middle
It has a smaller set of writable
properties that let you opt

00:04:04.536 --> 00:04:07.586 A:middle
in for particular
features when supported.

00:04:07.766 --> 00:04:10.876 A:middle
Some capture features affect how
the capture render pipeline is

00:04:10.876 --> 00:04:13.716 A:middle
built, so you have to
specify them upfront.

00:04:14.126 --> 00:04:16.216 A:middle
One such is
HighResolutionCapture.

00:04:16.286 --> 00:04:18.995 A:middle
If you ever intend to capture
high-resolution photos,

00:04:18.995 --> 00:04:23.486 A:middle
such as five-megapixel
selfies on the iPhone 6s,

00:04:24.066 --> 00:04:26.806 A:middle
you have to opt-in for the
feature first before calling

00:04:26.806 --> 00:04:28.666 A:middle
startRunning on the
AVCapture Session.

00:04:29.486 --> 00:04:32.806 A:middle
Lastly, there's a single
method that you can call

00:04:32.936 --> 00:04:34.286 A:middle
to kick off a photo capture.

00:04:35.056 --> 00:04:35.796 A:middle
Just one verb.

00:04:35.876 --> 00:04:36.246 A:middle
That's it.

00:04:36.896 --> 00:04:39.306 A:middle
Now you're probably asking
yourself, well what happened

00:04:39.306 --> 00:04:40.746 A:middle
to all the per photo state?

00:04:40.886 --> 00:04:43.356 A:middle
How do I request
the flash capture?

00:04:43.356 --> 00:04:44.786 A:middle
How do I get BGRA?

00:04:44.786 --> 00:04:46.496 A:middle
How do I get still
image stabilization?

00:04:47.386 --> 00:04:49.276 A:middle
These features and
others have moved

00:04:49.276 --> 00:04:52.456 A:middle
to a new object called
AVCapturePhotoSettings.

00:04:53.026 --> 00:04:55.356 A:middle
This object contains all
the settings that pertain

00:04:55.356 --> 00:04:57.946 A:middle
to one single photo
capture request.

00:04:58.136 --> 00:05:01.666 A:middle
Think of it like the
list of options to choose


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:58.136 --> 00:05:01.666 A:middle
Think of it like the
list of options to choose

00:05:01.666 --> 00:05:04.966 A:middle
from when you're buying a MAC
on the Apple online store.

00:05:05.416 --> 00:05:07.436 A:middle
You fill out the online
form with all the features

00:05:07.436 --> 00:05:10.096 A:middle
that you want and then you
hit the place order button.

00:05:10.646 --> 00:05:13.496 A:middle
And placing the order is
like calling capturePhoto,

00:05:13.766 --> 00:05:15.656 A:middle
passing the
AVCapturePhotoSettings

00:05:15.656 --> 00:05:16.766 A:middle
as your first parameter.

00:05:17.796 --> 00:05:19.436 A:middle
Now when you place
an order online,

00:05:19.566 --> 00:05:21.996 A:middle
the store needs your email
address to communicate

00:05:21.996 --> 00:05:23.316 A:middle
with you about your order.

00:05:24.376 --> 00:05:26.396 A:middle
Within AVCapturePhotoOutput's
world,

00:05:26.446 --> 00:05:30.236 A:middle
the email address you provide
is an object conforming

00:05:30.236 --> 00:05:33.476 A:middle
to AVCapturePhotoCaptureDelegate
protocol.

00:05:34.056 --> 00:05:36.716 A:middle
This delegate gets called
back as events related

00:05:36.716 --> 00:05:38.336 A:middle
to your photo capture occur.

00:05:39.016 --> 00:05:41.406 A:middle
This object gets passed
as your second parameter

00:05:41.406 --> 00:05:42.276 A:middle
to CapturePhoto.

00:05:43.686 --> 00:05:46.146 A:middle
Okay, so what's good about
AVCapturePhotoSettings?

00:05:46.526 --> 00:05:48.326 A:middle
First of all, they are atomic.

00:05:48.856 --> 00:05:51.736 A:middle
All settings are
encapsulated in a single object.

00:05:52.026 --> 00:05:54.996 A:middle
There's no potential for
settings getting out of sync

00:05:55.496 --> 00:05:58.456 A:middle
because they are not properties
of the AVCapturePhotoOutput,

00:05:58.656 --> 00:06:00.816 A:middle
but rather, a per-settings
object.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:05:58.656 --> 00:06:00.816 A:middle
but rather, a per-settings
object.

00:06:01.396 --> 00:06:02.036 A:middle
They're unique.

00:06:02.636 --> 00:06:05.966 A:middle
Each photo settings instance
has a unique ID property.

00:06:06.356 --> 00:06:09.136 A:middle
You're only allowed to use
one photo settings once

00:06:09.376 --> 00:06:10.166 A:middle
and never again.

00:06:10.406 --> 00:06:13.186 A:middle
So you'll receive
exactly one set of results

00:06:13.186 --> 00:06:14.996 A:middle
for each photo capture request.

00:06:16.836 --> 00:06:19.716 A:middle
After requesting a photo
capture with a set of settings,

00:06:19.716 --> 00:06:22.666 A:middle
you can hold onto it and
validate results against it

00:06:22.666 --> 00:06:23.686 A:middle
as they're returned to you.

00:06:23.746 --> 00:06:26.206 A:middle
Sort of like making a
copy of your order form,

00:06:26.206 --> 00:06:27.346 A:middle
your online order form.

00:06:28.666 --> 00:06:30.836 A:middle
So then, what's good
about the photo delegates?

00:06:31.776 --> 00:06:33.526 A:middle
Well, it's a single
set of callbacks.

00:06:33.556 --> 00:06:35.896 A:middle
Again, per photo settings.

00:06:36.696 --> 00:06:38.076 A:middle
The ordering is documented.

00:06:38.146 --> 00:06:39.966 A:middle
You know exactly which
callbacks you're going to get

00:06:39.966 --> 00:06:41.766 A:middle
and at what time
and in what order.

00:06:42.436 --> 00:06:45.386 A:middle
And it's a vehicle for resolving
indeterminate settings.

00:06:45.846 --> 00:06:48.246 A:middle
That one I think I need to
explain a little bit more.

00:06:48.876 --> 00:06:51.756 A:middle
Let's say your app requests
the photo right here

00:06:51.886 --> 00:06:54.016 A:middle
on this timeline.

00:06:54.366 --> 00:06:56.936 A:middle
You've specified photo
settings with auto flash

00:06:57.186 --> 00:06:59.446 A:middle
and auto still image
stabilization.

00:06:59.566 --> 00:07:01.996 A:middle
I shortened still image
stabilization to SIS


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:59.566 --> 00:07:01.996 A:middle
I shortened still image
stabilization to SIS

00:07:01.996 --> 00:07:03.876 A:middle
so it would fit on
the slide better.

00:07:04.096 --> 00:07:08.006 A:middle
You're telling the PhotoOutput
I want you to use flash or SIS

00:07:08.006 --> 00:07:09.566 A:middle
but only if you need to, only

00:07:09.566 --> 00:07:10.776 A:middle
if they're appropriate
for the scene.

00:07:11.926 --> 00:07:14.286 A:middle
So very soon after
you make the request,

00:07:14.386 --> 00:07:16.886 A:middle
the PhotoOutput calls your
delegates first callback,

00:07:17.156 --> 00:07:19.916 A:middle
which is willBegin
CaptureFor ResolvedSettings.

00:07:20.506 --> 00:07:23.316 A:middle
This callback is always,
always, always called first.

00:07:23.646 --> 00:07:25.486 A:middle
It's sort of like the
courtesy email you get

00:07:25.486 --> 00:07:28.076 A:middle
from Apple saying we've
received your order.

00:07:28.516 --> 00:07:29.716 A:middle
Here's what we'll
be sending you.

00:07:30.376 --> 00:07:32.366 A:middle
The callback passes
you an instance

00:07:32.366 --> 00:07:36.886 A:middle
of a new object called
AVCapturePhotoResolvedSettings.

00:07:37.546 --> 00:07:39.946 A:middle
It's just like the photo
settings you filled out,

00:07:39.946 --> 00:07:41.576 A:middle
except now everything
is resolved.

00:07:42.586 --> 00:07:43.996 A:middle
They have the same unique ID.

00:07:43.996 --> 00:07:45.746 A:middle
Your unresolved version

00:07:45.746 --> 00:07:47.796 A:middle
and resolved version
share a unique ID,

00:07:47.796 --> 00:07:49.026 A:middle
so you compare them together.

00:07:49.496 --> 00:07:52.396 A:middle
It also tells you what features
the photo output picked for you.

00:07:52.866 --> 00:07:55.806 A:middle
So notice, in this case,
flash has been resolved to on

00:07:56.246 --> 00:07:57.926 A:middle
and SIS has been
resolved to off.

00:07:58.106 --> 00:08:00.136 A:middle
So clearly we're in a
very low light situation


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:07:58.106 --> 00:08:00.136 A:middle
So clearly we're in a
very low light situation

00:08:00.136 --> 00:08:01.116 A:middle
such as this conference room.

00:08:01.506 --> 00:08:04.576 A:middle
Next comes willCapture
PhotoFor ResolvedSettings.

00:08:04.996 --> 00:08:07.466 A:middle
It's delivered right when
the photo is being taken,

00:08:07.726 --> 00:08:10.376 A:middle
or like when the virtual
camera shudder is closing

00:08:10.716 --> 00:08:12.276 A:middle
and the shudder sound
is being played.

00:08:12.276 --> 00:08:15.286 A:middle
If you want to perform some
sort of a shudder animation,

00:08:15.286 --> 00:08:16.916 A:middle
this is the appropriate
time to do it.

00:08:17.906 --> 00:08:20.946 A:middle
And then shortly thereafter
comes didCapture PhotoFor

00:08:20.946 --> 00:08:23.896 A:middle
ResolvedSettings, just after
the image has been fully exposed

00:08:23.896 --> 00:08:26.146 A:middle
and read out, and the
virtual shudder opens.

00:08:27.486 --> 00:08:29.276 A:middle
Then some time has to pass

00:08:29.276 --> 00:08:31.046 A:middle
because the image
is being processed,

00:08:31.046 --> 00:08:32.765 A:middle
applying all the features
that you asked for.

00:08:33.416 --> 00:08:34.976 A:middle
And when the photo
is finally ready,

00:08:35.186 --> 00:08:37.515 A:middle
you get the
didProcessingPhotoSampleBuffer

00:08:37.515 --> 00:08:40.726 A:middle
callback, along with an
ImageSampleBuffer you've been

00:08:40.726 --> 00:08:41.246 A:middle
waiting for.

00:08:41.246 --> 00:08:43.876 A:middle
So, yay. It's like getting the
shiny new MAC on your doorstep.

00:08:44.716 --> 00:08:48.336 A:middle
And finally, you get
the didFinish CaptureFor

00:08:48.336 --> 00:08:49.576 A:middle
ResolvedSettings callback,

00:08:49.576 --> 00:08:51.516 A:middle
which is guaranteed
to be delivered last.

00:08:52.426 --> 00:08:54.016 A:middle
It's like the follow-up
email that you get

00:08:54.016 --> 00:08:57.236 A:middle
from Apple saying all your
packages have been delivered.

00:08:57.236 --> 00:08:59.076 A:middle
A pleasure doing business
with you over and out.

00:08:59.796 --> 00:09:02.886 A:middle
This is a good time to clean up
any of your per-photo storage.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:08:59.796 --> 00:09:02.886 A:middle
This is a good time to clean up
any of your per-photo storage.

00:09:04.196 --> 00:09:06.976 A:middle
So let's talk about those
delegates in specifics.

00:09:07.526 --> 00:09:10.556 A:middle
The callbacks track a single
photo capture request.

00:09:11.466 --> 00:09:14.926 A:middle
The photo output holds a weak
reference to your delegate,

00:09:14.966 --> 00:09:17.176 A:middle
so it will not keep that
object alive for you.

00:09:17.676 --> 00:09:19.966 A:middle
Remember to keep a strong
reference to it in your code.

00:09:20.806 --> 00:09:24.026 A:middle
All the callbacks in this
protocol are marked optional,

00:09:24.406 --> 00:09:26.466 A:middle
but some of them become
required at runtime,

00:09:26.466 --> 00:09:27.786 A:middle
depending on your
photo settings.

00:09:27.786 --> 00:09:30.526 A:middle
For instance, when you're
capturing a compressed run

00:09:30.526 --> 00:09:32.396 A:middle
compressed photo,
your delegate has

00:09:32.396 --> 00:09:34.976 A:middle
to implement the one callback
where you get the photo.

00:09:35.256 --> 00:09:37.356 A:middle
Otherwise, we would have
nowhere to deliver it.

00:09:38.016 --> 00:09:39.266 A:middle
The rules are clearly spelled

00:09:39.266 --> 00:09:41.516 A:middle
out in the
AVCapturePhotoOutput.h

00:09:41.516 --> 00:09:42.076 A:middle
headerDoc.

00:09:43.236 --> 00:09:45.016 A:middle
All callbacks pass an instance

00:09:45.016 --> 00:09:47.286 A:middle
of that nice
ResolvedPhotoSettingsObject I

00:09:47.286 --> 00:09:47.946 A:middle
talked to you about.

00:09:47.946 --> 00:09:48.876 A:middle
So you always know what you're

00:09:48.876 --> 00:09:49.976 A:middle
about to get or what
you just got.

00:09:53.936 --> 00:09:56.566 A:middle
So speaking of settings, let's
look at some code showing how

00:09:56.566 --> 00:09:57.846 A:middle
to initiate photo captures

00:09:57.846 --> 00:10:00.446 A:middle
with various
AVCapturePhotoSettings features.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:09:57.846 --> 00:10:00.446 A:middle
with various
AVCapturePhotoSettings features.

00:10:01.236 --> 00:10:03.676 A:middle
Okay, the first one,
takeHighResolutionPhoto,

00:10:04.266 --> 00:10:06.036 A:middle
as I said before, the
front facing camera

00:10:06.036 --> 00:10:10.316 A:middle
on iPhone 6s supports
five-megapixel high resolution

00:10:10.316 --> 00:10:13.526 A:middle
selfies, but it can't
stream at five megapixels.

00:10:13.586 --> 00:10:15.826 A:middle
It can only do individual
high res stills.

00:10:16.486 --> 00:10:19.196 A:middle
So you have to create
a PhotoSettingsObject,

00:10:19.456 --> 00:10:23.246 A:middle
opting in for the HighResolution
Photo CaptureEnabled.

00:10:23.596 --> 00:10:26.626 A:middle
This gives you the
default constructor,

00:10:26.626 --> 00:10:29.056 A:middle
AVCapturePhotoSettings,
with friends.

00:10:29.636 --> 00:10:33.016 A:middle
And then, by default, it sets
the output format to JPEG

00:10:33.016 --> 00:10:35.526 A:middle
and opts you in for still
image stabilization.

00:10:36.436 --> 00:10:38.436 A:middle
I then set
isHighResolutionPhotoEnabled

00:10:38.436 --> 00:10:40.666 A:middle
to true and then
call CapturePhoto.

00:10:41.556 --> 00:10:45.866 A:middle
In the second example,
takeFlashPhoto.

00:10:45.866 --> 00:10:47.786 A:middle
Notice that the flashMode
is now a property

00:10:47.786 --> 00:10:48.946 A:middle
of the settings object.

00:10:48.946 --> 00:10:50.836 A:middle
If you've worked with
StillImageOutput in the past,

00:10:50.836 --> 00:10:54.346 A:middle
you'll know that Flash was
part of the AVCapture device,

00:10:54.666 --> 00:10:55.986 A:middle
so we had a problem
there that you had

00:10:55.986 --> 00:10:58.866 A:middle
to access two different objects
in order to set settings.

00:10:58.996 --> 00:11:01.686 A:middle
Here, it's all part of
one single atomic object.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:58.996 --> 00:11:01.686 A:middle
Here, it's all part of
one single atomic object.

00:11:02.076 --> 00:11:06.776 A:middle
Nice. The final sample here
uses a more complex constructor

00:11:06.776 --> 00:11:08.206 A:middle
of AVCapturePhotoSettings.

00:11:08.206 --> 00:11:11.986 A:middle
This time we're going to pass
the output format that we want.

00:11:11.986 --> 00:11:14.536 A:middle
In this case, we want an
uncompressed BGRA format.

00:11:14.906 --> 00:11:17.826 A:middle
So we make a dictionary of
CV pixel buffer attributes

00:11:18.356 --> 00:11:19.686 A:middle
and then pass it

00:11:19.686 --> 00:11:22.666 A:middle
as the parameter
AVCapturePhotoSettings,

00:11:23.096 --> 00:11:23.806 A:middle
and we're good to go.

00:11:24.496 --> 00:11:26.146 A:middle
Now when you call capturePhoto,

00:11:26.496 --> 00:11:28.796 A:middle
AVCapturePhotoOutput will
validate your settings

00:11:28.796 --> 00:11:31.006 A:middle
and make sure you haven't
asked for crazy stuff.

00:11:31.006 --> 00:11:34.706 A:middle
It'll ensure self-consistency,
and it'll ensure that the stuff

00:11:34.706 --> 00:11:36.406 A:middle
that you've asked for
is actually supported.

00:11:36.696 --> 00:11:38.586 A:middle
And if it's not, it
will throw an exception.

00:11:40.416 --> 00:11:44.096 A:middle
Result settings, as you might
expect, are entirely immutable.

00:11:44.366 --> 00:11:45.916 A:middle
All the properties
are read-only.

00:11:46.076 --> 00:11:47.656 A:middle
They're purely for
your information.

00:11:47.926 --> 00:11:50.466 A:middle
Again, this is the functional
programming immutable part.

00:11:51.066 --> 00:11:53.076 A:middle
It has a unique ID
that you compare

00:11:53.076 --> 00:11:55.186 A:middle
with the unresolved settings
object that you have.

00:11:55.706 --> 00:11:56.666 A:middle
This is kind of a nice feature.

00:11:56.666 --> 00:11:58.696 A:middle
It tells you the dimensions
of the photo you're going

00:11:58.696 --> 00:12:00.106 A:middle
to get before you get it.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:11:58.696 --> 00:12:00.106 A:middle
to get before you get it.

00:12:00.636 --> 00:12:03.476 A:middle
So you can plan, do
some allocations,

00:12:03.476 --> 00:12:04.526 A:middle
whatever you need to do.

00:12:05.656 --> 00:12:08.466 A:middle
It tells you whether it was
resolved to flash on or off.

00:12:08.826 --> 00:12:10.896 A:middle
And still image stabilization
on or off.

00:12:12.166 --> 00:12:14.516 A:middle
It also supports
bracketed capture.

00:12:14.856 --> 00:12:16.386 A:middle
It's a specialized
type of capture

00:12:16.386 --> 00:12:18.256 A:middle
where you request
a number of images,

00:12:18.476 --> 00:12:20.476 A:middle
sometimes with differing
exposure values.

00:12:20.846 --> 00:12:22.396 A:middle
This might be done, for
instance, if you wanted

00:12:22.396 --> 00:12:25.026 A:middle
to fuse differently
exposed images together

00:12:25.336 --> 00:12:28.736 A:middle
to produce an effect
such as an HDR effect.

00:12:28.736 --> 00:12:30.166 A:middle
I spoke at length
about these kinds

00:12:30.166 --> 00:12:32.846 A:middle
of captures in 2014 Session 508.

00:12:33.566 --> 00:12:35.526 A:middle
Go check that video
out for a refresher.

00:12:36.286 --> 00:12:38.486 A:middle
As with
AVCaptureStillImageOutput,

00:12:38.686 --> 00:12:40.876 A:middle
we support auto exposure
brackets

00:12:41.036 --> 00:12:43.016 A:middle
and custom exposure brackets.

00:12:43.856 --> 00:12:47.016 A:middle
But the new way to request
a bracketed capture is

00:12:47.016 --> 00:12:50.876 A:middle
to instantiate an
AVCapturePhotoBracketSettings.

00:12:51.006 --> 00:12:53.146 A:middle
So it's like the photo
settings but it's a subclass,

00:12:53.146 --> 00:12:54.806 A:middle
and it has the extra
stuff that you would need

00:12:54.806 --> 00:12:56.416 A:middle
for doing a bracketed capture.

00:12:57.286 --> 00:13:01.046 A:middle
When you create one of
these you specify an array


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:57.286 --> 00:13:01.046 A:middle
When you create one of
these you specify an array

00:13:01.286 --> 00:13:03.496 A:middle
of AVCapture BracketedStill
ImageSettings.

00:13:03.496 --> 00:13:05.206 A:middle
This is an existing object

00:13:05.206 --> 00:13:07.546 A:middle
from the
AVCaptureStillImageOutput days.

00:13:08.266 --> 00:13:10.306 A:middle
You specify one of
these per exposure.

00:13:10.306 --> 00:13:14.886 A:middle
For instance, -2EV, +2EV, 0EV.

00:13:15.586 --> 00:13:18.976 A:middle
Also, if you're on
an iPhone 6+ or 6s+,

00:13:18.976 --> 00:13:22.416 A:middle
you can optionally enable
lens stabilization using the

00:13:22.416 --> 00:13:24.176 A:middle
isLensStabilizationEnabled
property.

00:13:24.696 --> 00:13:26.866 A:middle
So you recall the
timeline I just showed you

00:13:26.866 --> 00:13:28.836 A:middle
on the previous slide, where
the photo was delivered

00:13:28.836 --> 00:13:31.946 A:middle
to didFinish ProcessingPhoto
SampleBuffer callback.

00:13:32.476 --> 00:13:35.076 A:middle
When you request a bracket
of say three images,

00:13:35.316 --> 00:13:37.286 A:middle
that callback is going
to be called three times.

00:13:37.286 --> 00:13:38.386 A:middle
Once per image.

00:13:38.726 --> 00:13:41.136 A:middle
And the fifth parameter
tells you

00:13:41.136 --> 00:13:42.886 A:middle
which particular
bracket settings

00:13:42.926 --> 00:13:45.886 A:middle
in this image request
this corresponds to.

00:13:46.916 --> 00:13:50.486 A:middle
Okay. So we like the new
AVCapturePhotoOutput so much

00:13:50.646 --> 00:13:52.626 A:middle
that we want you to move
over to it right away.

00:13:52.936 --> 00:13:56.766 A:middle
And so we're deprecating in iOS
10 the AVCaptureStillImageOutput

00:13:57.126 --> 00:14:00.436 A:middle
and all of the flash-related
properties of AVCaptureDevice,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:13:57.126 --> 00:14:00.436 A:middle
and all of the flash-related
properties of AVCaptureDevice,

00:14:00.746 --> 00:14:03.236 A:middle
and instead, this is
what you should use.

00:14:03.706 --> 00:14:07.286 A:middle
Like I said, there are parts
of flash capture that are part

00:14:07.286 --> 00:14:09.886 A:middle
and parcel to the
photo settings and so,

00:14:09.886 --> 00:14:11.506 A:middle
it's a much better
programming interface.

00:14:11.876 --> 00:14:13.146 A:middle
Move over as soon as you can.

00:14:14.416 --> 00:14:16.666 A:middle
The last item is -- let's talk

00:14:16.666 --> 00:14:19.546 A:middle
about the photo benefits
before we move on.

00:14:20.566 --> 00:14:22.026 A:middle
They're good for
easier bookkeeping.

00:14:22.856 --> 00:14:24.496 A:middle
Immediate settings resolution.

00:14:25.266 --> 00:14:26.786 A:middle
Confident request tracking.

00:14:27.336 --> 00:14:28.896 A:middle
And it's good for Apple.

00:14:28.896 --> 00:14:31.306 A:middle
It's good for us because
it's an expandable palette

00:14:31.306 --> 00:14:32.596 A:middle
of callbacks for us.

00:14:32.596 --> 00:14:35.196 A:middle
We can add new ways to
call you back in the future

00:14:35.716 --> 00:14:38.976 A:middle
and that last little bit is
important to the next feature

00:14:38.976 --> 00:14:40.946 A:middle
that I'm going to talk
about, which is Live Photos.

00:14:41.356 --> 00:14:44.906 A:middle
So Apple.com has a
great little blurb

00:14:45.026 --> 00:14:46.926 A:middle
on Live Photos and
what they are.

00:14:46.926 --> 00:14:50.466 A:middle
It says, "A still photo captures
an instant frozen in time.

00:14:51.106 --> 00:14:53.096 A:middle
With Live Photos, you
can turn those instants

00:14:53.146 --> 00:14:55.516 A:middle
into unforgettable
living memories."

00:14:56.896 --> 00:14:59.656 A:middle
The beautiful thing about Live
Photos is that they appreciate

00:14:59.656 --> 00:15:02.016 A:middle
in value the further
you get from the memory.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:14:59.656 --> 00:15:02.016 A:middle
in value the further
you get from the memory.

00:15:02.806 --> 00:15:05.306 A:middle
So, in this picture, this
is a great still image

00:15:05.306 --> 00:15:06.236 A:middle
in and of itself.

00:15:06.966 --> 00:15:10.436 A:middle
Huge disgusting sand crabs my
nephew dug up on the beach.

00:15:10.436 --> 00:15:11.246 A:middle
A great photo.

00:15:11.586 --> 00:15:12.926 A:middle
But if I 3D touch it --

00:15:13.516 --> 00:15:16.656 A:middle
[ Inaudible ]

00:15:17.156 --> 00:15:18.356 A:middle
Okay. So now I remember.

00:15:18.416 --> 00:15:19.656 A:middle
It was a freezing day.

00:15:19.656 --> 00:15:22.116 A:middle
He'd never been in the ocean
before and his lips were blue.

00:15:22.116 --> 00:15:24.106 A:middle
He'd been in for too long
and his hands were shaking.

00:15:24.326 --> 00:15:26.796 A:middle
And I also hear my brother's
voice speaking at the beginning.

00:15:27.086 --> 00:15:29.386 A:middle
So all of these things
aid in memory recall

00:15:29.686 --> 00:15:32.986 A:middle
because I have more
senses being activated.

00:15:33.976 --> 00:15:35.976 A:middle
Then there are people
finding inventive ways

00:15:35.976 --> 00:15:38.656 A:middle
to use Live Photos as an
artistic medium unto itself.

00:15:38.656 --> 00:15:40.946 A:middle
This shot is a twist
on the selfie.

00:15:41.446 --> 00:15:44.296 A:middle
Our camera products team calls
this The Doughnut Selfie.

00:15:44.856 --> 00:15:48.426 A:middle
A high degree of
difficulty to do it well.

00:15:48.996 --> 00:15:51.966 A:middle
Also popular is the
spinning swivel chair selfie

00:15:52.386 --> 00:15:53.146 A:middle
with Live Photo.

00:15:53.256 --> 00:15:53.906 A:middle
Try that one out.

00:15:54.976 --> 00:15:57.806 A:middle
I'm a big fan of the
surprise reveal live photo,

00:15:58.146 --> 00:15:59.976 A:middle
but unfortunately,
my kids are too.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:06.426 --> 00:16:08.406 A:middle
A three-second window
is just way too tempting

00:16:08.406 --> 00:16:10.226 A:middle
for my natural-borne
photobombers.

00:16:10.226 --> 00:16:14.096 A:middle
So Live Photos began life
as a thought experiment

00:16:14.096 --> 00:16:15.336 A:middle
from Apple's design studio.

00:16:15.406 --> 00:16:18.056 A:middle
The premise was, even though
we've got these remarkable

00:16:18.056 --> 00:16:20.626 A:middle
screens now for sharing
and viewing content,

00:16:21.056 --> 00:16:25.106 A:middle
the photo experience itself has
remained static for 150 years.

00:16:25.706 --> 00:16:28.436 A:middle
JPEGs that we swipe through
on the screen are just digital

00:16:28.436 --> 00:16:30.636 A:middle
versions of the chemicals
on paper that we leaf

00:16:30.666 --> 00:16:32.876 A:middle
through in our shoeboxes.

00:16:32.876 --> 00:16:34.056 A:middle
And yet, it's the primary way

00:16:34.056 --> 00:16:35.306 A:middle
that people store
their memories.

00:16:35.306 --> 00:16:37.586 A:middle
So isn't there something
better that we can do?

00:16:37.586 --> 00:16:40.566 A:middle
And after a lot of
experimentation and prototyping,

00:16:40.566 --> 00:16:43.146 A:middle
we converged on what this
new media experience is.

00:16:43.756 --> 00:16:44.716 A:middle
A moment or a memory.

00:16:45.016 --> 00:16:48.076 A:middle
Well, first of all and
foremost it is a still photo.

00:16:48.456 --> 00:16:50.786 A:middle
It's still as good
quality as before.

00:16:50.786 --> 00:16:54.286 A:middle
It's a 12-megapixel JPEG
full resolution still image,

00:16:54.566 --> 00:16:57.886 A:middle
and it has the same
quality as non-Live Photos.

00:16:57.886 --> 00:16:59.396 A:middle
Let me emphasize that again.

00:16:59.916 --> 00:17:02.316 A:middle
Live Photos get all
the great secret sauce


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:59.916 --> 00:17:02.316 A:middle
Live Photos get all
the great secret sauce

00:17:02.316 --> 00:17:04.086 A:middle
that Apple's non-Live Photos do,

00:17:04.226 --> 00:17:08.846 A:middle
so you are not sacrificing
anything by turning it on.

00:17:08.965 --> 00:17:11.935 A:middle
Also a big deal was the idea
of frictionless capture.

00:17:12.396 --> 00:17:14.306 A:middle
That means there's
nothing new to learn.

00:17:14.435 --> 00:17:16.566 A:middle
You take photos the same
way you always have.

00:17:17.106 --> 00:17:20.286 A:middle
Still the same spontaneous
frame the shot, push a button,

00:17:20.626 --> 00:17:21.976 A:middle
nothing additional
to think about.

00:17:23.516 --> 00:17:25.685 A:middle
A Live Photo is also
a memory, though.

00:17:26.066 --> 00:17:28.666 A:middle
It has to engage more senses
than the static image.

00:17:28.666 --> 00:17:30.416 A:middle
It has to aid in memory recall.

00:17:31.536 --> 00:17:34.656 A:middle
So it's nominally a short
movie, a three-second movie

00:17:34.656 --> 00:17:37.886 A:middle
with 1.5 seconds coming before
the still and 1.5 coming

00:17:37.886 --> 00:17:39.966 A:middle
after the still, and we take it

00:17:39.966 --> 00:17:43.786 A:middle
at about screen resolution
or targeting 1080p.

00:17:45.286 --> 00:17:47.136 A:middle
And it includes audio.

00:17:48.576 --> 00:17:50.866 A:middle
And we're constantly
improving on the design.

00:17:50.926 --> 00:17:54.046 A:middle
In iOS 9.1, we added
this great feature

00:17:54.046 --> 00:17:55.936 A:middle
of automatically
trimming Live Photos

00:17:55.936 --> 00:17:58.556 A:middle
in case you did a sweeping
movement towards your shoes

00:17:58.556 --> 00:17:59.276 A:middle
or your pockets.

00:17:59.546 --> 00:18:01.726 A:middle
So now we'll auto trim them
and get rid of the parts


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:17:59.546 --> 00:18:01.726 A:middle
So now we'll auto trim them
and get rid of the parts

00:18:01.726 --> 00:18:03.076 A:middle
that you don't want
see in the movie.

00:18:03.836 --> 00:18:05.836 A:middle
New in iOS 10, we've
made it even better.

00:18:05.956 --> 00:18:08.976 A:middle
Now all of the Live Photo
movies are stabilized.

00:18:10.276 --> 00:18:11.596 A:middle
Also new in iOS 10,

00:18:11.626 --> 00:18:13.286 A:middle
interruption-free
music during captures.

00:18:13.286 --> 00:18:13.976 A:middle
So if you happen
to be playing --

00:18:14.516 --> 00:18:18.006 A:middle
[ Applause ]

00:18:18.506 --> 00:18:19.346 A:middle
Yeah. That's a good one.

00:18:19.406 --> 00:18:20.056 A:middle
I like that one, too.

00:18:21.886 --> 00:18:24.576 A:middle
So in order to be both
a moment and a memory,

00:18:24.706 --> 00:18:27.186 A:middle
a Live Photo consists of two
assets, as you would expect.

00:18:27.186 --> 00:18:29.156 A:middle
JPEG file, QuickTime Movie file.

00:18:29.566 --> 00:18:31.566 A:middle
These two assets
share a common UUID

00:18:31.566 --> 00:18:33.396 A:middle
that uniquely pairs
them together.

00:18:33.776 --> 00:18:35.566 A:middle
The JPEG file's UUID is stored

00:18:35.566 --> 00:18:37.016 A:middle
within the Apple Maker
Note of the [inaudible].

00:18:37.016 --> 00:18:40.436 A:middle
And the movie asset
is, like I said,

00:18:40.436 --> 00:18:43.306 A:middle
nominally three seconds
long, has a video track,

00:18:43.306 --> 00:18:46.556 A:middle
roughly 1080p, with a
forward by 3 aspect ratio.

00:18:47.206 --> 00:18:50.676 A:middle
It contains a timed metadata
track with one single sample

00:18:50.676 --> 00:18:53.666 A:middle
in it that corresponds to the
exact time of the still photo

00:18:53.906 --> 00:18:55.046 A:middle
within the movie's timeline.

00:18:55.626 --> 00:18:58.136 A:middle
It also contains a piece
of top level movie metadata

00:18:58.136 --> 00:19:00.496 A:middle
that pairs it with
the JPEG's metadata


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:18:58.136 --> 00:19:00.496 A:middle
that pairs it with
the JPEG's metadata

00:19:00.756 --> 00:19:03.686 A:middle
and that's called the
QuickTime content identifier.

00:19:04.086 --> 00:19:06.326 A:middle
And its value is a
UUID-style stream.

00:19:08.006 --> 00:19:10.666 A:middle
Okay. So what do you have to
do to capture Live Photos?

00:19:11.456 --> 00:19:12.976 A:middle
In AVCapturePhotoOutput,

00:19:12.976 --> 00:19:17.306 A:middle
there is a property called
isLivePhotoCaptureSupported?

00:19:17.306 --> 00:19:18.376 A:middle
You have to make
sure it's supported.

00:19:18.376 --> 00:19:19.986 A:middle
It's not supported
on all devices.

00:19:20.566 --> 00:19:22.046 A:middle
And currently it's
only supported

00:19:22.046 --> 00:19:24.596 A:middle
when you're using
the preset photo.

00:19:25.716 --> 00:19:29.206 A:middle
You opt in for it using
AVCapture PhotoOutput.isLive

00:19:29.206 --> 00:19:32.446 A:middle
PhotoCaptureEnabled,
setting it to true.

00:19:32.446 --> 00:19:35.496 A:middle
You have to opt in for it before
you start the session running.

00:19:35.566 --> 00:19:37.966 A:middle
Otherwise, it will cause a
disruptive reconfiguration

00:19:37.966 --> 00:19:40.976 A:middle
of the session, and
you don't want that.

00:19:40.976 --> 00:19:44.686 A:middle
Also if you want audio in
your Live Photo movies,

00:19:44.686 --> 00:19:46.806 A:middle
you have to add an
AVCaptureDeviceInput

00:19:46.806 --> 00:19:47.716 A:middle
for the microphone.

00:19:48.176 --> 00:19:48.786 A:middle
Very important.

00:19:48.836 --> 00:19:49.556 A:middle
Don't forget to do that.

00:19:50.466 --> 00:19:53.626 A:middle
Also not supported is
simultaneous recording

00:19:53.626 --> 00:19:57.136 A:middle
of regular movies using
AVCaptureMovieOutput

00:19:57.136 --> 00:19:58.876 A:middle
and Live Photos at
the same time.

00:19:59.156 --> 00:20:00.546 A:middle
So if you have a
movie file output


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:59.156 --> 00:20:00.546 A:middle
So if you have a
movie file output

00:20:00.546 --> 00:20:04.856 A:middle
in your session's topology, it
will disable LivePhotoCapture.

00:20:04.896 --> 00:20:08.446 A:middle
You configure a LivePhotoCapture
the usual way.

00:20:09.106 --> 00:20:11.716 A:middle
It's got the default
constructors you would expect,

00:20:12.166 --> 00:20:17.086 A:middle
but additionally you specify a
URL, a LivePhotoMovieFileURL.

00:20:17.386 --> 00:20:20.206 A:middle
This is where you want
us to write the movie to.

00:20:20.346 --> 00:20:21.816 A:middle
And it has to be
in your sandbox,

00:20:21.816 --> 00:20:23.456 A:middle
and it has to be
accessible to you.

00:20:23.576 --> 00:20:28.366 A:middle
You're not required to specify
any livePhotoMovieMetadata

00:20:28.366 --> 00:20:29.616 A:middle
but you can if you'd like to.

00:20:30.086 --> 00:20:33.936 A:middle
Here I gave an example of
using the author metadata.

00:20:33.936 --> 00:20:35.716 A:middle
And I set myself as the author,

00:20:35.716 --> 00:20:37.616 A:middle
so that the world will
know that it's my movie.

00:20:37.966 --> 00:20:39.636 A:middle
But you could also
do interesting stuff

00:20:39.636 --> 00:20:42.296 A:middle
like add GPS tagging
to your movie.

00:20:42.636 --> 00:20:45.526 A:middle
So now let's talk about Live
Photo-related delegate methods.

00:20:45.946 --> 00:20:48.186 A:middle
Like I said, we have
this expandable palette

00:20:48.186 --> 00:20:50.126 A:middle
of delegate callbacks,
and we're going to use it.

00:20:50.846 --> 00:20:52.176 A:middle
When capturing a Live Photo,

00:20:52.176 --> 00:20:53.866 A:middle
your first callback
lets you know

00:20:53.866 --> 00:20:55.726 A:middle
that a Live Photo
will be recorded,

00:20:56.126 --> 00:20:58.796 A:middle
by telling you the movie's
resolved dimensions.

00:20:58.796 --> 00:21:01.316 A:middle
See that? Now, in addition
to just the photo dimensions,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:20:58.796 --> 00:21:01.316 A:middle
See that? Now, in addition
to just the photo dimensions,

00:21:01.316 --> 00:21:03.916 A:middle
you also know what dimensions
the Live Photo is going to be.

00:21:04.336 --> 00:21:06.016 A:middle
You receive the expected
callbacks,

00:21:06.066 --> 00:21:10.036 A:middle
including a JPEG being delivered
to you in memory as before.

00:21:10.036 --> 00:21:11.916 A:middle
But now we're going to
give you some new ones.

00:21:12.826 --> 00:21:15.796 A:middle
A Live Photo movie is
nominally three seconds

00:21:15.856 --> 00:21:17.616 A:middle
with a still image
right in the middle.

00:21:17.966 --> 00:21:22.206 A:middle
So that means up to 1.5 seconds
after your capture request,

00:21:22.476 --> 00:21:24.226 A:middle
you're going to receive
a new callback.

00:21:24.226 --> 00:21:25.436 A:middle
And this one has a strange name,

00:21:25.946 --> 00:21:28.906 A:middle
didFinishRecording
LivePhotoMovieFor

00:21:28.906 --> 00:21:31.146 A:middle
EventualFileAtURL.

00:21:31.836 --> 00:21:33.516 A:middle
Try to parse that.

00:21:33.516 --> 00:21:37.026 A:middle
It means the file hasn't been
written yet but all the samples

00:21:37.026 --> 00:21:38.096 A:middle
that need to be collected

00:21:38.096 --> 00:21:40.086 A:middle
for the movie are
done being collected.

00:21:40.236 --> 00:21:44.586 A:middle
In other words, if you have a
Live Photo badge up in your UI,

00:21:44.906 --> 00:21:46.946 A:middle
this is an appropriate
time to take it down.

00:21:46.986 --> 00:21:48.926 A:middle
Let people know that they don't
need to hold still anymore.

00:21:49.496 --> 00:21:52.346 A:middle
A good time to dismiss
the Live Photo badge.

00:21:53.116 --> 00:21:57.336 A:middle
And soon after, the movie file
will be finished being written.

00:21:57.636 --> 00:21:59.386 A:middle
And you'll get the
didFinishProcessing

00:21:59.386 --> 00:22:01.336 A:middle
LivePhotoTo MovieFileAtURL.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:21:59.386 --> 00:22:01.336 A:middle
LivePhotoTo MovieFileAtURL.

00:22:01.896 --> 00:22:04.416 A:middle
That is a required callback,
if you're doing Live Photos.

00:22:04.846 --> 00:22:06.516 A:middle
And now the movie's
ready to be consumed.

00:22:07.906 --> 00:22:10.696 A:middle
Lastly you get the
thumbs up, all done.

00:22:10.696 --> 00:22:13.976 A:middle
We've delivered everything
that we're going to.

00:22:14.606 --> 00:22:15.956 A:middle
So note that the JPEG portion

00:22:15.956 --> 00:22:18.416 A:middle
of the LivePhotoCapture is
delivered in the same way

00:22:18.416 --> 00:22:20.016 A:middle
as static still photos.

00:22:20.016 --> 00:22:22.716 A:middle
It comes as a sample
buffer in memory,

00:22:23.136 --> 00:22:25.326 A:middle
using didFinishing
ProcessingPhoto SampleBuffer

00:22:25.326 --> 00:22:26.776 A:middle
callback, as we've already seen.

00:22:26.776 --> 00:22:30.836 A:middle
If you want to write this
to disk, it's a trivial job.

00:22:31.726 --> 00:22:34.146 A:middle
We have a class method
in AVCapturePhotoOutput

00:22:34.146 --> 00:22:38.316 A:middle
for rewriting JPEGs as a
Data, that's with a capital D,

00:22:38.716 --> 00:22:41.936 A:middle
that's suitable for writing
to a JPEG file on disk.

00:22:42.296 --> 00:22:43.556 A:middle
And you can see it
in action here.

00:22:43.556 --> 00:22:46.966 A:middle
I'm going to gloss over
the second parameter

00:22:46.966 --> 00:22:49.046 A:middle
to that function, the
previewPhotoSampleBuffer.

00:22:49.046 --> 00:22:50.366 A:middle
We'll discuss it
in a little while.

00:22:51.856 --> 00:22:55.686 A:middle
So here's a suggestion for you
when you're doing Live Photos.

00:22:56.136 --> 00:22:58.706 A:middle
LivePhotoCapture is an
example of the kind of capture

00:22:58.706 --> 00:23:00.436 A:middle
that delivers multiple assets.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:58.706 --> 00:23:00.436 A:middle
that delivers multiple assets.

00:23:00.436 --> 00:23:03.506 A:middle
Sort of like a multi-order,
where you're going

00:23:03.506 --> 00:23:05.056 A:middle
to get the computer in one
order, and you're going

00:23:05.056 --> 00:23:07.336 A:middle
to get the dongle
in another order.

00:23:07.556 --> 00:23:10.916 A:middle
So when it delivers multiple
assets, we have found it handy,

00:23:10.916 --> 00:23:12.786 A:middle
in our own test apps
that we've written,

00:23:13.216 --> 00:23:18.266 A:middle
to instantiate a new
AVCapturePhotoDelegate object

00:23:18.266 --> 00:23:21.296 A:middle
for each photo request
in this situation.

00:23:21.686 --> 00:23:24.516 A:middle
So then, within that
object, you can aggregate all

00:23:24.516 --> 00:23:25.556 A:middle
of the things that
you're getting.

00:23:25.556 --> 00:23:29.056 A:middle
The sample buffer, the movie,
et cetera, for this request.

00:23:29.056 --> 00:23:31.626 A:middle
And then, there's a convenient
place to dispose of that object

00:23:31.626 --> 00:23:33.146 A:middle
when you get the
thumbs up callback,

00:23:33.146 --> 00:23:33.906 A:middle
saying that we're done.

00:23:34.466 --> 00:23:35.806 A:middle
That's just a helpful tip there.

00:23:37.286 --> 00:23:39.016 A:middle
Once your assets have
been written to disk,

00:23:39.016 --> 00:23:41.456 A:middle
there are still several more
steps that you need to take

00:23:41.796 --> 00:23:43.866 A:middle
to get the full live
photo experience.

00:23:43.926 --> 00:23:46.566 A:middle
Though the video complement
is a standard QuickTime movie,

00:23:46.906 --> 00:23:48.756 A:middle
it's not meant to be
played start to finish

00:23:48.756 --> 00:23:51.136 A:middle
with an AV Player like
you would a regular movie.

00:23:51.496 --> 00:23:53.406 A:middle
There's a special recipe
for playing it back.

00:23:53.786 --> 00:23:58.396 A:middle
It's supposed to ease in and out
of the photo still image time.

00:23:58.436 --> 00:24:01.316 A:middle
When you swipe between
them, these particular kinds


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:23:58.436 --> 00:24:01.316 A:middle
When you swipe between
them, these particular kinds

00:24:01.316 --> 00:24:03.546 A:middle
of assets have a little bit
of movement in the photos app.

00:24:04.236 --> 00:24:06.526 A:middle
So to get the full Live
Photo playback experience,

00:24:06.526 --> 00:24:09.506 A:middle
you need to use the photos
and photos UI frameworks.

00:24:09.886 --> 00:24:12.086 A:middle
And there are classes
relating to Live Photo,

00:24:12.426 --> 00:24:15.656 A:middle
to ingest your RAW assets
into the photo library

00:24:15.956 --> 00:24:17.656 A:middle
and properly play them
back, for instance,

00:24:17.656 --> 00:24:18.866 A:middle
with the LivePhotoView.

00:24:20.186 --> 00:24:21.516 A:middle
And new in iOS 10,

00:24:21.516 --> 00:24:24.816 A:middle
photos framework lets you
edit Live Photo content just

00:24:24.816 --> 00:24:27.756 A:middle
as you would a still
photo, and that's great news

00:24:28.076 --> 00:24:28.966 A:middle
and I'd like to demo it.

00:24:36.346 --> 00:24:40.186 A:middle
Okay. So we have a bit of sample
code here, the venerable AVCam,

00:24:40.186 --> 00:24:41.816 A:middle
which has been out
for five years,

00:24:42.506 --> 00:24:44.616 A:middle
but now we have spruced it up,

00:24:44.616 --> 00:24:47.526 A:middle
so that it has a specific
photo mode and a movie mode.

00:24:47.926 --> 00:24:50.596 A:middle
That's because you can only
do Live Photos in photo mode.

00:24:51.006 --> 00:24:53.156 A:middle
And notice it's got some badging
at the top that tells you

00:24:53.156 --> 00:24:55.076 A:middle
that Live Photo mode
is on or off.

00:24:56.036 --> 00:24:57.546 A:middle
And you can switch cameras.

00:24:57.806 --> 00:25:00.006 A:middle
I'm going to try to do the
difficult doughnut selfie.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:24:57.806 --> 00:25:00.006 A:middle
I'm going to try to do the
difficult doughnut selfie.

00:25:00.006 --> 00:25:01.516 A:middle
Let's see how successful I am.

00:25:01.806 --> 00:25:05.236 A:middle
So you have to start and
then take it somewhere

00:25:05.236 --> 00:25:07.566 A:middle
in the middle and then finish.

00:25:07.896 --> 00:25:09.996 A:middle
So notice, while I was doing
that, there was a live badge

00:25:09.996 --> 00:25:12.126 A:middle
that came up, and that's
using the callbacks

00:25:12.126 --> 00:25:13.866 A:middle
that I talked to
you about earlier.

00:25:15.406 --> 00:25:16.126 A:middle
So here it is.

00:25:16.126 --> 00:25:18.926 A:middle
It was written to the
Photos Library and --

00:25:18.926 --> 00:25:21.946 A:middle
then take it somewhere in
the middle -- nice, right?

00:25:22.396 --> 00:25:24.266 A:middle
But that's not all we
can do with it now.

00:25:24.386 --> 00:25:26.826 A:middle
In iOS 9, when you tried
to edit a Live Photo,

00:25:26.826 --> 00:25:28.426 A:middle
you would lose the
movie portion of it.

00:25:28.816 --> 00:25:34.026 A:middle
But now we can either, in the
photos app natively or with code

00:25:34.026 --> 00:25:35.256 A:middle
that you provide in your app,

00:25:35.596 --> 00:25:38.346 A:middle
such as this little sample
called LivePhotoEditor

00:25:38.346 --> 00:25:42.106 A:middle
that I've included as a
photo editing extension,

00:25:42.916 --> 00:25:45.876 A:middle
I can apply a simple
filter or trim the movie.

00:25:46.376 --> 00:25:48.016 A:middle
This just does a
really simple thing

00:25:48.016 --> 00:25:49.626 A:middle
of applying a tonal filter,

00:25:49.896 --> 00:25:51.596 A:middle
but notice it didn't
get rid of the movie.

00:25:51.596 --> 00:25:53.956 A:middle
I can still play it --
and then take it somewhere

00:25:53.956 --> 00:25:55.176 A:middle
in the middle -- so, nice.

00:25:55.176 --> 00:25:55.976 A:middle
You can now edit
your Live Photos.

00:25:56.516 --> 00:26:03.306 A:middle
[ Applause ]


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:25:56.516 --> 00:26:03.306 A:middle
[ Applause ]

00:26:03.806 --> 00:26:04.166 A:middle
All right.

00:26:04.266 --> 00:26:07.616 A:middle
AVCam. Now, like I
said, has separate video

00:26:07.616 --> 00:26:08.946 A:middle
and photo recording modes,

00:26:08.946 --> 00:26:10.876 A:middle
so you get the best
photo experience.

00:26:10.876 --> 00:26:12.876 A:middle
You get the best
movie-making experience.

00:26:13.266 --> 00:26:15.446 A:middle
And it shows the proper
live badging technique

00:26:15.446 --> 00:26:16.336 A:middle
that I was talking about.

00:26:16.706 --> 00:26:19.316 A:middle
It also shows you how to
write it to the Assets Library

00:26:19.696 --> 00:26:21.596 A:middle
and that sample code
is available right now.

00:26:21.636 --> 00:26:24.276 A:middle
If you go to our sessions'
page, you'll find it.

00:26:25.306 --> 00:26:26.466 A:middle
It was even Swiftified.

00:26:26.696 --> 00:26:28.896 A:middle
If you want to know more
about Live Photo editing,

00:26:29.166 --> 00:26:32.086 A:middle
please come to session
505 on Thursday at 11.

00:26:32.336 --> 00:26:34.926 A:middle
You'll hear all about it.

00:26:35.186 --> 00:26:37.306 A:middle
Okay. We also support
a feature called

00:26:37.306 --> 00:26:39.146 A:middle
LivePhotoCaptureSuspension.

00:26:39.326 --> 00:26:42.616 A:middle
Here's a quick example of
when this might be useful.

00:26:43.106 --> 00:26:45.196 A:middle
Let's say you have an
app that takes pictures

00:26:45.196 --> 00:26:47.646 A:middle
and makes obnoxious
foghorn sounds.

00:26:48.896 --> 00:26:50.226 A:middle
Okay, just go with
me on this one.

00:26:50.726 --> 00:26:52.156 A:middle
It takes pictures.

00:26:52.406 --> 00:26:53.946 A:middle
Makes obnoxious foghorn sounds.

00:26:54.236 --> 00:26:55.706 A:middle
Now let's say that
on a timeline,

00:26:55.746 --> 00:26:57.706 A:middle
your user takes a
Live Photo here

00:26:58.416 --> 00:27:01.906 A:middle
and then they play an
obnoxious foghorn sound here.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:26:58.416 --> 00:27:01.906 A:middle
and then they play an
obnoxious foghorn sound here.

00:27:02.006 --> 00:27:05.696 A:middle
And then after it's done
playing they take another Live

00:27:05.696 --> 00:27:06.286 A:middle
Photo there.

00:27:07.736 --> 00:27:11.686 A:middle
So this is a problem because
since the movie portions

00:27:11.726 --> 00:27:14.166 A:middle
of photos one and two overlap

00:27:14.336 --> 00:27:16.066 A:middle
with the obnoxious
foghorn sound,

00:27:16.566 --> 00:27:19.116 A:middle
you have now ruined
two Live Photo movies.

00:27:19.486 --> 00:27:22.056 A:middle
You're going to hear the end
of the foghorn in one of them

00:27:22.056 --> 00:27:24.876 A:middle
and the beginning of the
foghorn in the other.

00:27:25.016 --> 00:27:25.706 A:middle
That's no good.

00:27:25.806 --> 00:27:27.296 A:middle
So to cope with this problem,

00:27:27.726 --> 00:27:30.596 A:middle
you can set
isLivePhotoCaptureSuspended

00:27:30.756 --> 00:27:33.516 A:middle
to true, just before you
do your obnoxious thing.

00:27:34.166 --> 00:27:37.096 A:middle
And that will cause any
Live Photos in progress

00:27:37.346 --> 00:27:39.896 A:middle
to abruptly be trimmed
right to that point.

00:27:40.356 --> 00:27:41.516 A:middle
And you can do the same thing

00:27:41.516 --> 00:27:43.336 A:middle
by setting
isLivePhotoCaptureSuspended

00:27:43.336 --> 00:27:46.876 A:middle
to false, and that will
cause a nice clean break

00:27:46.876 --> 00:27:50.116 A:middle
on the endpoint, so
that no content earlier

00:27:50.116 --> 00:27:53.746 A:middle
than that point will appear in
your movies when you unsuspend.

00:27:53.856 --> 00:27:54.776 A:middle
A nice little feature.

00:27:56.316 --> 00:27:57.806 A:middle
So let's talk about support.

00:27:57.806 --> 00:27:59.686 A:middle
Where do we support
LivePhotoCapture?


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:28:00.466 --> 00:28:04.346 A:middle
We support it on all the recent
iOS devices, and the easy way

00:28:04.346 --> 00:28:07.486 A:middle
to remember it is every device
that has a 12-megapixel camera,

00:28:07.716 --> 00:28:09.376 A:middle
that's where we support
Live Photos.

00:28:11.596 --> 00:28:14.556 A:middle
All right, onto our next
major feature of the day

00:28:14.556 --> 00:28:16.036 A:middle
and that's RAW Photo Capture.

00:28:16.576 --> 00:28:21.656 A:middle
So to explain what RAW
images are, I need to start

00:28:21.656 --> 00:28:25.166 A:middle
with a very high level overview
of how CMOS sensors work.

00:28:26.086 --> 00:28:28.586 A:middle
CMOS sensors collect
photons of light

00:28:28.586 --> 00:28:31.136 A:middle
through two-dimensional
arrays of detectors.

00:28:32.096 --> 00:28:35.356 A:middle
The top layer of the array is
called a color filter array

00:28:36.056 --> 00:28:38.256 A:middle
and as light passes
through from the top,

00:28:38.496 --> 00:28:41.336 A:middle
it only allows one color
component through, either red,

00:28:41.506 --> 00:28:43.696 A:middle
green or blue, in
a Bayer pattern.

00:28:44.416 --> 00:28:46.936 A:middle
Green is twice as prevalent in
this little checkerboard here

00:28:46.936 --> 00:28:50.046 A:middle
because our eyes are twice
as sensitive to green light

00:28:50.046 --> 00:28:51.396 A:middle
as they are to the other colors.

00:28:52.256 --> 00:28:54.766 A:middle
The bottom layer here is
known as the sensor array.

00:28:55.966 --> 00:29:00.686 A:middle
Now what actually gets stored
in a RAW file is the intensity


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:28:55.966 --> 00:29:00.686 A:middle
Now what actually gets stored
in a RAW file is the intensity

00:29:00.686 --> 00:29:03.096 A:middle
of the amount of either
red, green or blue light

00:29:03.136 --> 00:29:07.776 A:middle
that hit the sensor through each
of those detectors also needs

00:29:07.776 --> 00:29:09.676 A:middle
to be stored that Bayer pattern.

00:29:09.676 --> 00:29:13.096 A:middle
In other words, the arrangement
of reds, greens and blues,

00:29:13.466 --> 00:29:15.446 A:middle
so that later on it
can be demosaiced.

00:29:15.446 --> 00:29:18.736 A:middle
You have to store a lot
of other metadata too

00:29:18.736 --> 00:29:20.986 A:middle
about color information,
exposure information.

00:29:22.416 --> 00:29:25.006 A:middle
And so RAW converters
have a really hard job.

00:29:25.256 --> 00:29:27.896 A:middle
A RAW converter that basically
takes all of this stuff

00:29:27.896 --> 00:29:29.646 A:middle
and turns it into an RGB image.

00:29:30.316 --> 00:29:33.166 A:middle
Demosaicing is just
the tip of the iceberg.

00:29:33.296 --> 00:29:35.526 A:middle
A lot of stuff needs to
happen before it can be

00:29:35.746 --> 00:29:37.226 A:middle
presented onscreen.

00:29:38.416 --> 00:29:41.806 A:middle
So to draw an analogy,
storing a RAW file is a lot

00:29:41.806 --> 00:29:44.216 A:middle
like storing the ingredients
to bake a cake, okay?

00:29:44.736 --> 00:29:47.046 A:middle
And then you have to
carry the ingredients

00:29:47.046 --> 00:29:48.296 A:middle
around with you wherever you go.

00:29:48.296 --> 00:29:50.256 A:middle
It's kind of heavy.

00:29:50.356 --> 00:29:51.426 A:middle
It's kind of awkward.

00:29:51.946 --> 00:29:55.556 A:middle
It takes some time to
bake it every time.

00:29:55.556 --> 00:29:56.986 A:middle
If you ask two different bakers

00:29:57.146 --> 00:29:59.006 A:middle
to bake the cake using
the same ingredients,

00:29:59.006 --> 00:30:01.976 A:middle
you might get a slightly
different tasting cake.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:59.006 --> 00:30:01.976 A:middle
you might get a slightly
different tasting cake.

00:30:02.396 --> 00:30:04.786 A:middle
But there are also some
huge advantages to RAW.

00:30:05.136 --> 00:30:09.086 A:middle
First and foremost, you have
bake-time flexibility, right?

00:30:09.086 --> 00:30:11.186 A:middle
So you're carrying
the ingredients around

00:30:11.186 --> 00:30:14.246 A:middle
but you can make a
better cake next year.

00:30:15.186 --> 00:30:17.436 A:middle
There's no compression involved

00:30:17.586 --> 00:30:21.396 A:middle
like there would
be in BGRA or 420.

00:30:21.396 --> 00:30:22.736 A:middle
You have more bits to work with.

00:30:22.986 --> 00:30:25.806 A:middle
It's a 10-bit sensor
RAW packaged

00:30:25.806 --> 00:30:28.636 A:middle
in 14 bits per pixel
instead of eight.

00:30:30.176 --> 00:30:32.036 A:middle
Also, you have lots of
headroom for editing.

00:30:33.216 --> 00:30:35.136 A:middle
And some greater
artistic freedom

00:30:35.136 --> 00:30:37.916 A:middle
to make different
decisions in post.

00:30:37.916 --> 00:30:39.686 A:middle
So basically you're just
deferring the baking

00:30:39.686 --> 00:30:40.316 A:middle
until later.

00:30:41.206 --> 00:30:42.716 A:middle
Okay? Now what's JPEG?

00:30:43.306 --> 00:30:45.486 A:middle
RAW images offer many benefits

00:30:45.486 --> 00:30:47.796 A:middle
but they're not the
be-all-end-all of existence.

00:30:47.796 --> 00:30:49.036 A:middle
It's important to understand

00:30:49.036 --> 00:30:51.576 A:middle
that there are tradeoffs
involved when you choose RAW

00:30:51.856 --> 00:30:56.086 A:middle
and that JPEGs are still
a very attractive option.

00:30:56.086 --> 00:31:00.846 A:middle
JPEGs are the cake, the lovingly
baked Apple cake, just for you,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:56.086 --> 00:31:00.846 A:middle
JPEGs are the cake, the lovingly
baked Apple cake, just for you,

00:31:00.996 --> 00:31:03.086 A:middle
and it's a pretty good cake.

00:31:03.206 --> 00:31:06.206 A:middle
It's got all of the
Apple goodness in it.

00:31:07.146 --> 00:31:08.206 A:middle
Much faster rendering.

00:31:08.206 --> 00:31:11.346 A:middle
You don't have to carry as
many ingredients around.

00:31:11.486 --> 00:31:15.486 A:middle
You also get some secret
sauce, like stabilization.

00:31:15.686 --> 00:31:19.366 A:middle
As I mentioned, we use multiple
image fusion for stabilization.

00:31:19.756 --> 00:31:21.486 A:middle
You can't get that with
a single RAW image,

00:31:21.486 --> 00:31:24.136 A:middle
no matter how good it is,
because we're taking --

00:31:24.136 --> 00:31:25.986 A:middle
I guess it's kind of
like a multilayer cake.

00:31:26.626 --> 00:31:29.256 A:middle
Okay? So yeah, you can't do
that with a single image.

00:31:30.176 --> 00:31:32.136 A:middle
Also you get smaller file size.

00:31:33.476 --> 00:31:36.746 A:middle
So all of these things make JPEG
a really attractive alternative

00:31:36.826 --> 00:31:39.276 A:middle
and you should decide
which one you want to use,

00:31:39.276 --> 00:31:40.216 A:middle
which is better for your app.

00:31:41.256 --> 00:31:44.146 A:middle
We identify RAW formats
using four-character codes,

00:31:44.146 --> 00:31:46.396 A:middle
just like we do for
regular pixel formats

00:31:46.436 --> 00:31:47.936 A:middle
in the Core Video framework.

00:31:48.346 --> 00:31:51.596 A:middle
We've added four new
constants to CVPixelBuffer.h

00:31:51.596 --> 00:31:53.896 A:middle
to describe the four
different Bayer patterns

00:31:54.226 --> 00:31:56.146 A:middle
that you'll encounter
on our cameras,

00:31:56.426 --> 00:31:57.306 A:middle
and they're listed there.

00:31:57.366 --> 00:31:59.216 A:middle
Basically they describe
the order of the reds,

00:31:59.216 --> 00:32:00.846 A:middle
greens and blues in
the checkerboard.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:31:59.216 --> 00:32:00.846 A:middle
greens and blues in
the checkerboard.

00:32:02.266 --> 00:32:05.196 A:middle
How do you capture RAW
with AVCapturePhotoOutput?

00:32:05.556 --> 00:32:06.306 A:middle
It's pretty simple.

00:32:07.086 --> 00:32:10.526 A:middle
RAW is only supported when
using the photo format,

00:32:10.526 --> 00:32:13.096 A:middle
the preset photo,
same as Live Photo.

00:32:14.036 --> 00:32:16.016 A:middle
It's only supported
on the rear camera.

00:32:17.276 --> 00:32:21.526 A:middle
And we do support RAW brackets,
so you can take a bracket

00:32:21.526 --> 00:32:23.706 A:middle
of three RAW images,
for instance.

00:32:24.806 --> 00:32:26.146 A:middle
To request a RAW capture,

00:32:26.296 --> 00:32:28.686 A:middle
you create an
AVCapturePhotoSettings object

00:32:28.686 --> 00:32:30.976 A:middle
but surprise, surprise,
there's a different instructor.

00:32:31.546 --> 00:32:33.586 A:middle
This one takes a
RAW pixel format.

00:32:34.486 --> 00:32:37.716 A:middle
So how do you decide which
RAW format you should ask it

00:32:37.716 --> 00:32:38.716 A:middle
to deliver to you?

00:32:38.996 --> 00:32:41.716 A:middle
Well you can ask the
PhotoOutput itself.

00:32:41.716 --> 00:32:44.366 A:middle
It'll tell you here are my
available RAW photo pixel

00:32:44.566 --> 00:32:48.086 A:middle
formats, and you can
select one of those.

00:32:49.416 --> 00:32:52.666 A:middle
The RAW format you specify has
to be supported by the hardware.

00:32:52.666 --> 00:32:57.046 A:middle
Now also important is that
in these RAW settings,

00:32:57.686 --> 00:33:02.306 A:middle
SIS has no meaning because
it's not a multiple image


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:57.686 --> 00:33:02.306 A:middle
SIS has no meaning because
it's not a multiple image

00:33:02.496 --> 00:33:03.836 A:middle
fusion scenario.

00:33:04.276 --> 00:33:07.086 A:middle
So autoStillImage
StabilizationEnabled has

00:33:07.086 --> 00:33:09.146 A:middle
to be set to no or it
will throw an exception.

00:33:09.646 --> 00:33:12.096 A:middle
And also
highResolutionPhotoEnabled is

00:33:12.096 --> 00:33:14.776 A:middle
meaningless because you're
just getting the sense of RAW,

00:33:15.426 --> 00:33:16.956 A:middle
so it also must be set to false.

00:33:18.276 --> 00:33:19.926 A:middle
There's a separate
delegate callback

00:33:19.926 --> 00:33:25.476 A:middle
for RAW photos called didFinish
ProcessingRAW PhotoSampleBuffer.

00:33:25.866 --> 00:33:29.276 A:middle
And if you are really sharp-eyed
and really fast, you'll notice

00:33:29.276 --> 00:33:31.426 A:middle
that it has exactly
the same parameters

00:33:31.566 --> 00:33:35.396 A:middle
as the previous callback,
where you get the regular kind

00:33:35.396 --> 00:33:37.076 A:middle
of image, the didFinish
ProcessingRAW

00:33:37.076 --> 00:33:38.296 A:middle
PhotoSampleBuffer callback.

00:33:38.746 --> 00:33:42.136 A:middle
So now you might ask yourself
why did we bother making a whole

00:33:42.136 --> 00:33:45.346 A:middle
new delegate callback
for RAW sample buffers

00:33:45.346 --> 00:33:48.336 A:middle
if it has the same exact
parameters as the other one?

00:33:48.856 --> 00:33:55.386 A:middle
There's a good reason, and that
reason is RAW plus processed

00:33:55.386 --> 00:33:56.066 A:middle
image support.

00:33:56.226 --> 00:33:59.626 A:middle
So we do support, just
like on DSLR cameras,

00:33:59.626 --> 00:34:03.036 A:middle
mirrorless cameras, a workflow
where you can get both RAW


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:33:59.626 --> 00:34:03.036 A:middle
mirrorless cameras, a workflow
where you can get both RAW

00:34:03.036 --> 00:34:04.956 A:middle
and JPEG simultaneously.

00:34:05.046 --> 00:34:06.516 A:middle
That's what I mean
by processed image.

00:34:07.226 --> 00:34:09.186 A:middle
The ability to shoot
RAW and JPEG is kind

00:34:09.186 --> 00:34:10.916 A:middle
of a professional feature,
kind of a big deal.

00:34:11.255 --> 00:34:14.916 A:middle
So you can get RAW
plus a processed image.

00:34:14.916 --> 00:34:17.866 A:middle
It doesn't have to be a
JPEG, it could be BGRA, 420.

00:34:18.775 --> 00:34:22.005 A:middle
The processed image is
delivered to the other callback,

00:34:22.076 --> 00:34:24.516 A:middle
the didFinish ProcessingPhoto
SampleBuffer callback,

00:34:24.956 --> 00:34:30.246 A:middle
and the RAW is delivered to
the one with RAW in the name.

00:34:30.246 --> 00:34:33.255 A:middle
RAW plus processed
brackets are supported,

00:34:33.255 --> 00:34:34.606 A:middle
so see if you can wrap
your head around that.

00:34:34.766 --> 00:34:36.106 A:middle
That would be --
I'm doing a bracket

00:34:36.106 --> 00:34:38.176 A:middle
and I'm asking for
RAW plus JPEG.

00:34:38.396 --> 00:34:40.246 A:middle
So if I'm doing a
bracket of three,

00:34:40.246 --> 00:34:42.565 A:middle
I'm going to get three
RAWs and three JPEGs.

00:34:43.096 --> 00:34:46.676 A:middle
RAW plus still image
stabilization,

00:34:46.676 --> 00:34:47.916 A:middle
though, is not supported.

00:34:49.525 --> 00:34:53.076 A:middle
Okay, so to capture RAW plus
JPEG, as you might expect,

00:34:53.076 --> 00:34:56.446 A:middle
there's yet another constructor
of AVCapturePhotoSettings.

00:34:56.835 --> 00:34:59.806 A:middle
In this one, you specify
both the RAW pixel format

00:34:59.806 --> 00:35:02.126 A:middle
and the processed
format that you want.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:59.806 --> 00:35:02.126 A:middle
and the processed
format that you want.

00:35:02.786 --> 00:35:07.776 A:middle
Here I'm choosing JPEG as the
output format and a RAW format.

00:35:09.656 --> 00:35:12.296 A:middle
Now when you select JPEGPlusRAW,

00:35:12.296 --> 00:35:14.936 A:middle
HighResolutionPhotoEnabled
does mean something.

00:35:14.936 --> 00:35:17.146 A:middle
Because now it's
applying to the JPEG.

00:35:19.136 --> 00:35:19.796 A:middle
All right.

00:35:20.016 --> 00:35:21.736 A:middle
Let's talk about
storing RAW buffers.

00:35:21.996 --> 00:35:23.396 A:middle
They're not that useful

00:35:23.396 --> 00:35:25.506 A:middle
if all you can do is
work with them in memory.

00:35:26.356 --> 00:35:29.456 A:middle
So rather than introduce an
Apple proprietary RAW file

00:35:29.456 --> 00:35:32.776 A:middle
format, like so many other
camera vendors do, we've elected

00:35:32.776 --> 00:35:36.236 A:middle
to use Adobe's digital
negative format for storage.

00:35:36.836 --> 00:35:40.906 A:middle
DNG is a standard way of just
storing bits and metadata.

00:35:41.036 --> 00:35:43.576 A:middle
It doesn't imply a file
format in any other way.

00:35:43.706 --> 00:35:48.646 A:middle
So going back to our cake-baking
analogy, a DNG is just

00:35:48.646 --> 00:35:51.346 A:middle
like a standard box for
holding ingredients.

00:35:52.056 --> 00:35:55.176 A:middle
It's still up to individual
RAW converters to decide how

00:35:55.176 --> 00:35:56.546 A:middle
to interpret those ingredients.

00:35:56.916 --> 00:36:00.866 A:middle
So DNGs opened by one third
party app might look different


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:35:56.916 --> 00:36:00.866 A:middle
So DNGs opened by one third
party app might look different

00:36:00.866 --> 00:36:03.686 A:middle
than DNGs opened
in a different app.

00:36:03.896 --> 00:36:05.726 A:middle
So storing in DNG
is pretty trivial.

00:36:06.416 --> 00:36:10.326 A:middle
You just call the class function
dngPhotoDataRepresentation,

00:36:11.116 --> 00:36:12.866 A:middle
passing the RAW buffer
you received

00:36:13.006 --> 00:36:14.076 A:middle
in the delegate callback.

00:36:14.656 --> 00:36:17.916 A:middle
This creates a capital
D Data in memory

00:36:18.376 --> 00:36:19.556 A:middle
that can be written to file.

00:36:20.536 --> 00:36:23.866 A:middle
And this API always writes
[inaudible] compressed DNG files

00:36:23.866 --> 00:36:24.976 A:middle
to save space.

00:36:28.756 --> 00:36:29.126 A:middle
All right.

00:36:29.126 --> 00:36:29.976 A:middle
I feel a demo coming on.

00:36:36.986 --> 00:36:40.746 A:middle
Okay. So for RAW capture, we've
updated another venerable piece

00:36:40.746 --> 00:36:42.786 A:middle
of sample code and
that's AVCamManual.

00:36:43.356 --> 00:36:45.516 A:middle
We released this one in 2014,

00:36:45.516 --> 00:36:48.576 A:middle
when we showed off our
manual control APIs.

00:36:48.646 --> 00:36:53.986 A:middle
So it lets you choose focus,
exposure, white balance,

00:36:54.306 --> 00:36:57.536 A:middle
and you can manually
or auto control those.

00:36:58.046 --> 00:37:02.046 A:middle
And then there's a new thing
in the HUD on the left side


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:36:58.046 --> 00:37:02.046 A:middle
And then there's a new thing
in the HUD on the left side

00:37:02.326 --> 00:37:04.616 A:middle
that lets you select
either RAW off or on.

00:37:05.326 --> 00:37:08.806 A:middle
So you can choose to shoot
RAW photos in this app.

00:37:09.496 --> 00:37:10.916 A:middle
Let's go to exposure.

00:37:10.916 --> 00:37:14.166 A:middle
Let me see if I can purposely
overexpose a little bit,

00:37:14.166 --> 00:37:16.596 A:middle
and then I'll take a photo.

00:37:16.666 --> 00:37:19.346 A:middle
And now I'm going
to leave the app.

00:37:20.426 --> 00:37:24.236 A:middle
I'm going to go to an
app called RAWExpose.

00:37:24.236 --> 00:37:26.096 A:middle
Now this was not written
by the AV Foundation Team.

00:37:26.096 --> 00:37:27.716 A:middle
This was written by
the Core Image Team,

00:37:27.716 --> 00:37:30.666 A:middle
but they graciously let
me borrow it for my demo.

00:37:30.776 --> 00:37:34.036 A:middle
And we'll go down and we can see
the picture that we just took.

00:37:34.876 --> 00:37:37.536 A:middle
Now this one is a RAW.

00:37:37.666 --> 00:37:39.666 A:middle
It's reading the DNG file.

00:37:40.216 --> 00:37:42.796 A:middle
And we can do things with
it that we could never do

00:37:42.796 --> 00:37:48.966 A:middle
with the JPEGs, like we restore
the EV to a more same value.

00:37:49.286 --> 00:37:53.866 A:middle
We can adjust the
temperature and tint.

00:37:53.866 --> 00:37:55.856 A:middle
All of these things
are being done in post

00:37:55.856 --> 00:37:57.106 A:middle
and are completely reversible.

00:37:57.586 --> 00:38:00.596 A:middle
You can also look and see
what it looks like with


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:37:57.586 --> 00:38:00.596 A:middle
You can also look and see
what it looks like with

00:38:00.596 --> 00:38:01.796 A:middle
or without noise reduction.

00:38:02.066 --> 00:38:03.586 A:middle
So all of these are part

00:38:03.586 --> 00:38:06.176 A:middle
of a new Core image
API for editing RAW.

00:38:06.176 --> 00:38:06.976 A:middle
Okay, let's go back to slides.

00:38:13.706 --> 00:38:18.156 A:middle
The AVCamManual sample code
is available right now.

00:38:18.156 --> 00:38:18.816 A:middle
You can go get it.

00:38:18.816 --> 00:38:21.746 A:middle
It's associated with
this session's slides.

00:38:22.406 --> 00:38:25.716 A:middle
And also, if you want to
learn more about RAW editing,

00:38:25.786 --> 00:38:28.276 A:middle
you need to come to that
same session as I talked

00:38:28.276 --> 00:38:31.336 A:middle
about before, session 505, where
they talk about both of these.

00:38:31.416 --> 00:38:34.026 A:middle
The second part is RAW
Processing with Core Image.

00:38:34.326 --> 00:38:37.196 A:middle
It's a great session.

00:38:37.346 --> 00:38:39.406 A:middle
Where is RAW photo
capture supported?

00:38:40.566 --> 00:38:43.326 A:middle
By happy coincidence, it's
exactly the same products

00:38:43.326 --> 00:38:46.346 A:middle
as where we support Live Photos.

00:38:46.836 --> 00:38:48.946 A:middle
So anything with a
12-megapixel camera is

00:38:48.946 --> 00:38:50.326 A:middle
where you can do RAW photos.

00:38:51.556 --> 00:38:55.366 A:middle
Onto our next topic, which
is capturing preview images,

00:38:55.656 --> 00:38:57.536 A:middle
also known as thumbnails.

00:38:57.746 --> 00:39:01.296 A:middle
Photography apps commonly
take pictures and want


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:38:57.746 --> 00:39:01.296 A:middle
Photography apps commonly
take pictures and want

00:39:01.296 --> 00:39:03.396 A:middle
to quickly show a
preview of the results,

00:39:03.836 --> 00:39:05.586 A:middle
such as Apple Zone camera app.

00:39:06.266 --> 00:39:07.976 A:middle
So take a look in the bottom
left while this is playing.

00:39:14.026 --> 00:39:17.256 A:middle
And you see, as soon as it
hits the shutter button,

00:39:17.256 --> 00:39:19.816 A:middle
almost instantaneously
you have a preview

00:39:19.816 --> 00:39:21.936 A:middle
in the image well
on the bottom left.

00:39:22.046 --> 00:39:22.636 A:middle
That's good.

00:39:22.636 --> 00:39:24.276 A:middle
That's comforting to
your users to know

00:39:24.276 --> 00:39:26.076 A:middle
that what they did just worked.

00:39:26.656 --> 00:39:28.646 A:middle
It gives them instant feedback.

00:39:29.346 --> 00:39:31.906 A:middle
Also a number of image
processing algorithms

00:39:31.906 --> 00:39:34.696 A:middle
such as Core Images,
CI Rectangle Detector

00:39:34.996 --> 00:39:38.976 A:middle
or CI QR Code Detector work
better with smaller images,

00:39:39.076 --> 00:39:40.546 A:middle
smaller uncompressed images.

00:39:40.546 --> 00:39:43.996 A:middle
They don't need the full
12-megapixel JPEG to find faces.

00:39:45.386 --> 00:39:50.176 A:middle
Unfortunately there is an
inherit impedance mismatch here.

00:39:51.066 --> 00:39:53.106 A:middle
You request a high-quality JPEG

00:39:53.446 --> 00:39:55.896 A:middle
because that's what you
want to store on disk.

00:39:55.896 --> 00:39:59.466 A:middle
That's what you want to
survive, but you also want

00:39:59.466 --> 00:40:00.976 A:middle
to get a preview on
screen really fast.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:39:59.466 --> 00:40:00.976 A:middle
to get a preview on
screen really fast.

00:40:02.166 --> 00:40:03.746 A:middle
So if you have to do
that work yourself,

00:40:03.746 --> 00:40:05.116 A:middle
you're decompressing the JPEG.

00:40:05.116 --> 00:40:06.096 A:middle
You're downscaling it.

00:40:06.306 --> 00:40:07.386 A:middle
And finally displaying it.

00:40:08.216 --> 00:40:09.346 A:middle
All of this takes time

00:40:09.346 --> 00:40:11.296 A:middle
and buffer copies
and added complexity.

00:40:12.036 --> 00:40:15.806 A:middle
Nicer would be to get both the
high-quality JPEG for storage

00:40:15.876 --> 00:40:18.786 A:middle
and if the camera could give
you a smaller version of it,

00:40:19.186 --> 00:40:22.376 A:middle
directly from the camera, not
decompressed from the JPEG.

00:40:23.626 --> 00:40:26.266 A:middle
Then you could skip all those
steps and go straight to display

00:40:26.266 --> 00:40:27.166 A:middle
with the preview image.

00:40:28.136 --> 00:40:30.346 A:middle
And this is exactly the
workflow that we support

00:40:30.346 --> 00:40:31.566 A:middle
in AVCapturePhotoOutput.

00:40:32.436 --> 00:40:32.966 A:middle
The delegate --

00:40:33.516 --> 00:40:36.856 A:middle
[ Applause ]

00:40:37.356 --> 00:40:37.976 A:middle
I'll pander.

00:40:38.256 --> 00:40:38.756 A:middle
I'll pander.

00:40:39.106 --> 00:40:42.716 A:middle
The delegate callback can
deliver a preview image along

00:40:42.716 --> 00:40:44.656 A:middle
with the processed or RAW image.

00:40:45.306 --> 00:40:49.046 A:middle
The preview is uncompressed,
so it's 420fv

00:40:49.046 --> 00:40:50.596 A:middle
or BGRA, you're choice.

00:40:50.776 --> 00:40:52.966 A:middle
If you know the size you want,

00:40:53.266 --> 00:40:56.356 A:middle
you can specify the
dimensions that you want.

00:40:56.756 --> 00:40:58.866 A:middle
Or if you're not sure what
a good preview size would be

00:40:58.866 --> 00:41:00.206 A:middle
for this current platform,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:40:58.866 --> 00:41:00.206 A:middle
for this current platform,

00:41:00.456 --> 00:41:02.866 A:middle
the PhotoOutput can pick a
good default size for you.

00:41:04.656 --> 00:41:07.986 A:middle
Here's some sample code showing
how to request a preview image.

00:41:08.496 --> 00:41:11.406 A:middle
After creating a photo
settings instance in one

00:41:11.406 --> 00:41:15.276 A:middle
of the usual ways, you can
select a previewPixelType.

00:41:15.666 --> 00:41:19.476 A:middle
Again, the photo settings
themselves can tell you

00:41:19.916 --> 00:41:23.246 A:middle
which formats are
available, and they are sorted

00:41:23.546 --> 00:41:25.626 A:middle
so that the most
optimal one is first.

00:41:25.786 --> 00:41:28.186 A:middle
So here, I'm getting the very
first one from the array.

00:41:28.816 --> 00:41:31.246 A:middle
And when I say optimal,
I mean the one

00:41:31.246 --> 00:41:33.176 A:middle
that requires the
fewest conversions

00:41:33.356 --> 00:41:34.756 A:middle
from the native camera.

00:41:36.346 --> 00:41:39.246 A:middle
You create a CVPixelBuffer
attributes dictionary

00:41:39.246 --> 00:41:43.666 A:middle
with that format type key, and
that first part is required.

00:41:43.666 --> 00:41:46.056 A:middle
So if you want preview images,

00:41:46.056 --> 00:41:48.936 A:middle
you have to at least specify
the format that you want.

00:41:49.606 --> 00:41:53.546 A:middle
Optionally, you can also
specify a width and a height,

00:41:54.646 --> 00:41:56.196 A:middle
if you want to custom size.

00:41:56.676 --> 00:41:59.826 A:middle
And you don't need to know
exactly the aspect ratio

00:41:59.826 --> 00:42:00.936 A:middle
of the image that
you're getting.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:41:59.826 --> 00:42:00.936 A:middle
of the image that
you're getting.

00:42:01.406 --> 00:42:03.826 A:middle
Here I just specified
160 by 160.

00:42:03.856 --> 00:42:07.396 A:middle
I don't really expect to get
a box out, but I'm using those

00:42:07.396 --> 00:42:09.546 A:middle
as the max for both
width and height.

00:42:09.906 --> 00:42:12.136 A:middle
And AVCapturePhotoOutput
will do the job

00:42:12.136 --> 00:42:15.626 A:middle
of resizing the preview image
so that it fits in the box,

00:42:15.936 --> 00:42:17.046 A:middle
preserving aspect ratio.

00:42:18.976 --> 00:42:21.626 A:middle
Retrieving preview images is
also very straightforward.

00:42:22.146 --> 00:42:27.886 A:middle
Here we've requested a JPEG plus
a preview image at 160 by 160.

00:42:28.926 --> 00:42:31.736 A:middle
So when we get our first
callback saying we've received

00:42:31.736 --> 00:42:37.586 A:middle
your order, you get a willBegin
CaptureFor ResolvedSettings

00:42:38.676 --> 00:42:41.686 A:middle
and a ResolvedPhotoSettings
object which, if you notice,

00:42:41.686 --> 00:42:46.126 A:middle
the previewPhotoDimensions
are not 160 by 160.

00:42:46.126 --> 00:42:49.566 A:middle
They're 160 by 120
because it's been resolved

00:42:49.746 --> 00:42:52.156 A:middle
to something that's
aspect ratio appropriate

00:42:52.156 --> 00:42:58.886 A:middle
for the 12-megapixel
photo that you want.

00:42:58.886 --> 00:43:02.956 A:middle
When the didFinish
ProcessingPhoto SampleBuffer


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:42:58.886 --> 00:43:02.956 A:middle
When the didFinish
ProcessingPhoto SampleBuffer

00:43:02.956 --> 00:43:05.346 A:middle
callback finally comes, you
get not one but two images.

00:43:05.346 --> 00:43:07.886 A:middle
The full-sized JPEG is
the first parameter,

00:43:08.096 --> 00:43:14.506 A:middle
and the previewPhotoSampleBuffer
is the second.

00:43:14.506 --> 00:43:15.686 A:middle
So if you're following
along here

00:43:15.686 --> 00:43:17.206 A:middle
and adding things
up in your mind.

00:43:17.206 --> 00:43:19.446 A:middle
If you do a RAW plus bracket
plus JPEG plus preview image,

00:43:19.476 --> 00:43:20.976 A:middle
then you're going to get mRAWs,
mJPEGs and mpreview images.

00:43:25.656 --> 00:43:28.156 A:middle
Another great use of
the preview image is

00:43:28.216 --> 00:43:32.636 A:middle
as an embedded thumbnail in your
high-quality JPEG or DNG files.

00:43:33.446 --> 00:43:36.366 A:middle
In this code sample, I'm using
the previewPhotoSampleBuffer

00:43:36.366 --> 00:43:40.036 A:middle
parameter of my didFinish
ProcessingRAW PhotoSampleBuffer

00:43:40.036 --> 00:43:44.076 A:middle
callback as an embedded
thumbnail to the DNG file.

00:43:44.666 --> 00:43:48.546 A:middle
So when I call PhotoOutput's
dngPhotoDataRepresentation,

00:43:48.856 --> 00:43:51.006 A:middle
I'm passing that as
the second parameter.

00:43:51.606 --> 00:43:53.496 A:middle
You should always do this, okay?

00:43:53.996 --> 00:43:56.716 A:middle
Embedding a thumbnail
image is always a good idea

00:43:56.926 --> 00:43:59.106 A:middle
because you don't know where
it's going to be viewed.

00:43:59.646 --> 00:44:05.786 A:middle
Some apps can handle
looking at the DNG bits,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:43:59.646 --> 00:44:05.786 A:middle
Some apps can handle
looking at the DNG bits,

00:44:05.816 --> 00:44:07.196 A:middle
the RAW bits, and some can't.

00:44:07.566 --> 00:44:09.286 A:middle
But if you have an
embedded thumbnail in there,

00:44:09.356 --> 00:44:10.906 A:middle
everyone's going to be
able to look at something.

00:44:10.906 --> 00:44:13.656 A:middle
You definitely want to do
it if you're adding a DNG

00:44:13.656 --> 00:44:16.146 A:middle
to the Photo Library so
that it can give you a nice

00:44:16.146 --> 00:44:16.846 A:middle
quick preview.

00:44:18.786 --> 00:44:21.976 A:middle
Preview image delivery
is supported everywhere.

00:44:25.376 --> 00:44:29.736 A:middle
All right, onto the last topic
of the day, which is wide color.

00:44:30.046 --> 00:44:32.976 A:middle
And as you might suspect,
it's a wide topic.

00:44:37.566 --> 00:44:40.806 A:middle
You've no doubt heard about the
beautiful new true toned display

00:44:40.906 --> 00:44:43.176 A:middle
on our iPad Pro 9.7 inch.

00:44:43.766 --> 00:44:46.986 A:middle
It's a wide-gamut
display and it's on par

00:44:46.986 --> 00:44:50.346 A:middle
with the 4K and 5K iMax.

00:44:50.346 --> 00:44:53.476 A:middle
It's capable of displaying
strikingly vivid reds

00:44:53.476 --> 00:44:57.406 A:middle
and yellows and deeply
saturated cyans and greens.

00:44:58.446 --> 00:45:01.476 A:middle
To take advantage of the
display's extended color range,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:44:58.446 --> 00:45:01.476 A:middle
To take advantage of the
display's extended color range,

00:45:01.646 --> 00:45:05.406 A:middle
we introduced color management
for the first time in iOS 9.3.

00:45:05.406 --> 00:45:06.866 A:middle
I'm not sure if you
were aware of that,

00:45:06.906 --> 00:45:10.766 A:middle
but we're now color managed
for the iPad Pro 9.7.

00:45:11.736 --> 00:45:15.126 A:middle
And with displays this
pretty, it only makes sense

00:45:15.126 --> 00:45:17.936 A:middle
to also capture photos
with equally wide color

00:45:18.426 --> 00:45:20.246 A:middle
so that we enhance the
viewing experience.

00:45:20.246 --> 00:45:22.836 A:middle
And so that when you look at
those several years from now,

00:45:22.836 --> 00:45:24.496 A:middle
you've got more color
information.

00:45:25.116 --> 00:45:27.886 A:middle
Beginning in iOS
10, photo captures

00:45:27.886 --> 00:45:30.916 A:middle
on the iPad Pro 9.7 will
magically become wide

00:45:30.916 --> 00:45:31.686 A:middle
color captures.

00:45:32.916 --> 00:45:35.816 A:middle
Let me give you a brief overview
of what wide color means,

00:45:35.816 --> 00:45:37.766 A:middle
wide color terminology, starting

00:45:37.766 --> 00:45:39.816 A:middle
with the concept
of a color space.

00:45:40.456 --> 00:45:44.416 A:middle
A color space describes
an environment

00:45:44.416 --> 00:45:49.766 A:middle
in which colors are represented,
ordered, compared, or computed.

00:45:49.766 --> 00:45:51.896 A:middle
And the most common
color space used

00:45:51.896 --> 00:45:54.186 A:middle
in computer displays is sRGB.

00:45:54.456 --> 00:45:56.916 A:middle
The s stands for
standards, so standard RGB.

00:45:57.716 --> 00:46:01.616 A:middle
It's based on an
international spec ITU 709.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:45:57.716 --> 00:46:01.616 A:middle
It's based on an
international spec ITU 709.

00:46:02.346 --> 00:46:06.956 A:middle
It has a gamma of roughly
2.2 and a white point

00:46:06.956 --> 00:46:09.216 A:middle
of 6500 degrees Kelvin.

00:46:09.706 --> 00:46:14.216 A:middle
sRGB does a really good job of
representing many common colors,

00:46:14.276 --> 00:46:19.326 A:middle
like faces, sky, grass,
but there are many colors

00:46:19.326 --> 00:46:21.916 A:middle
that sRGB does not
reproduce very well.

00:46:21.916 --> 00:46:24.956 A:middle
For instance, more than 40%

00:46:24.956 --> 00:46:28.746 A:middle
of pro football jerseys are
outside of the sRBG gamut.

00:46:29.466 --> 00:46:36.376 A:middle
Who knew? The iPad Pro 9.7
supports wide color using a new

00:46:36.376 --> 00:46:38.606 A:middle
color space that
we call Display P3.

00:46:38.606 --> 00:46:42.736 A:middle
It's similar to the
SMPTE standard DCI P3.

00:46:42.736 --> 00:46:47.356 A:middle
That's a color space that's used
in digital cinema projectors.

00:46:47.526 --> 00:46:52.626 A:middle
The color primaries are the same
as DCI P3, but then it differs

00:46:52.626 --> 00:46:54.136 A:middle
in gamma and white point.

00:46:55.686 --> 00:46:59.776 A:middle
The gamma and white point
are identical to sRGBs.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:47:00.866 --> 00:47:02.046 A:middle
Why would we do that?

00:47:02.656 --> 00:47:07.026 A:middle
The reason for that is that the
DCI P3 white point is slanted

00:47:07.026 --> 00:47:08.086 A:middle
toward the green side.

00:47:08.086 --> 00:47:10.966 A:middle
It was chosen to
maximize brightness

00:47:11.046 --> 00:47:15.026 A:middle
in dark home theater
situations and we found

00:47:15.026 --> 00:47:16.866 A:middle
that with the white
point at 6500,

00:47:16.866 --> 00:47:20.576 A:middle
we get a more compatible
superset of the sRGB standard.

00:47:20.806 --> 00:47:25.086 A:middle
So here on this slide you
can see, in gray, the sRGB

00:47:25.086 --> 00:47:27.206 A:middle
and then you can
see, super-imposed

00:47:27.206 --> 00:47:28.406 A:middle
around it, the Display P3.

00:47:28.406 --> 00:47:30.776 A:middle
And it does a nice job of kind

00:47:30.776 --> 00:47:33.496 A:middle
of broadly covering
the superset of sRGB.

00:47:33.496 --> 00:47:36.426 A:middle
And that's why we chose it.

00:47:36.696 --> 00:47:39.556 A:middle
Using Apple's color
sync utility on OS 10,

00:47:39.646 --> 00:47:42.266 A:middle
you can see a visual
representation of Display P3.

00:47:42.266 --> 00:47:46.076 A:middle
So I took a little screen
capture here to show you.

00:47:46.126 --> 00:47:49.166 A:middle
You can compare it with
sRGB in three dimensions.

00:47:49.516 --> 00:47:51.476 A:middle
So here I'm selecting
Display P3,

00:47:51.476 --> 00:47:53.966 A:middle
and then I do the hold
for comparison thing.

00:47:53.966 --> 00:47:54.636 A:middle
That's a neat trick.

00:47:54.636 --> 00:47:56.676 A:middle
And then I select sRGB.

00:47:56.676 --> 00:47:59.726 A:middle
And then I see the one
super-imposed on top

00:47:59.726 --> 00:48:03.136 A:middle
of the other, so you can see
sRGB inside and Display P3


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:47:59.726 --> 00:48:03.136 A:middle
of the other, so you can see
sRGB inside and Display P3

00:48:03.136 --> 00:48:05.006 A:middle
on the outside, and
you get a feel

00:48:05.006 --> 00:48:10.126 A:middle
for just how wide the Display
P3 is compared to sRGB.

00:48:10.126 --> 00:48:12.976 A:middle
And the range of representable
colors is visibly bigger.

00:48:16.766 --> 00:48:18.616 A:middle
So now let's get down
to the nuts and bolts

00:48:18.616 --> 00:48:20.446 A:middle
of capturing Display P3 content.

00:48:20.446 --> 00:48:24.326 A:middle
For highest fidelity, the color
space of capture content has

00:48:24.326 --> 00:48:26.246 A:middle
to be determined at the source.

00:48:26.616 --> 00:48:29.696 A:middle
That's not something that
can flow down in sRGB

00:48:29.696 --> 00:48:31.886 A:middle
and then be up-converted
to the wide.

00:48:31.886 --> 00:48:32.926 A:middle
It has to start wide.

00:48:33.616 --> 00:48:35.086 A:middle
So, as you might expect,

00:48:35.086 --> 00:48:37.516 A:middle
the color space is
fundamentally a property

00:48:37.516 --> 00:48:40.126 A:middle
of the AVCaptureDevice,
the source.

00:48:40.916 --> 00:48:42.346 A:middle
So we're going to
spend some time talking

00:48:42.346 --> 00:48:44.656 A:middle
about the AVCaptureDevice
and we're also going to talk

00:48:44.656 --> 00:48:46.086 A:middle
about the AVCaptureSession.

00:48:46.626 --> 00:48:50.106 A:middle
The session is where automatic
wide color selection can be

00:48:50.106 --> 00:48:54.216 A:middle
determined for the whole session
configuration as a whole.

00:48:54.386 --> 00:48:58.786 A:middle
Okay. AVCaptureDevice is how AV
Foundation represents a camera

00:48:59.336 --> 00:48:59.806 A:middle
or a mic.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:49:00.786 --> 00:49:03.706 A:middle
Each AVCaptureDevice
has a format property.

00:49:04.176 --> 00:49:08.006 A:middle
Formats is an array of
AVCaptureDevice formats.

00:49:08.006 --> 00:49:11.286 A:middle
They are objects themselves,
and they represent the formats

00:49:11.286 --> 00:49:12.906 A:middle
that the device can capture in.

00:49:13.726 --> 00:49:16.116 A:middle
They come in pairs,
as you see here.

00:49:16.116 --> 00:49:18.856 A:middle
For each resolution
and frame rate,

00:49:19.036 --> 00:49:23.216 A:middle
there's a 402v version
and a 420f.

00:49:23.426 --> 00:49:27.666 A:middle
That stands for v for
video range, 16 to 235

00:49:28.146 --> 00:49:31.276 A:middle
or f for full range,
the 0 to 255.

00:49:32.436 --> 00:49:33.936 A:middle
So new in iOS 10,

00:49:34.506 --> 00:49:37.456 A:middle
AVCaptureDevice formats
have a new supported color

00:49:37.456 --> 00:49:38.656 A:middle
spaces property.

00:49:39.336 --> 00:49:43.006 A:middle
It's an array of numbers
with the possible values of 0

00:49:43.006 --> 00:49:46.996 A:middle
for sRGB or 1 for P3 D65.

00:49:47.676 --> 00:49:51.496 A:middle
We refer to it as Display P3
but in the API, it's referred

00:49:51.496 --> 00:49:57.346 A:middle
to as P3 D65, the d
standing for display and 65

00:49:57.346 --> 00:50:01.346 A:middle
for the 6500 Kelvin white point.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:49:57.346 --> 00:50:01.346 A:middle
for the 6500 Kelvin white point.

00:50:01.486 --> 00:50:06.916 A:middle
On an iPad Pro 9.7, the 420v
formats only support sRGB.

00:50:07.966 --> 00:50:12.156 A:middle
But the full-range 420f
formats support either sRGB

00:50:12.476 --> 00:50:13.546 A:middle
or Display P3.

00:50:13.546 --> 00:50:17.756 A:middle
The device has a settable
active format property.

00:50:17.756 --> 00:50:18.456 A:middle
That's not new.

00:50:19.156 --> 00:50:20.716 A:middle
So that one of the formats

00:50:20.716 --> 00:50:22.726 A:middle
in the list is always
the activeFormat.

00:50:23.016 --> 00:50:24.876 A:middle
As you can see here,
I've put a yellow box

00:50:24.876 --> 00:50:26.016 A:middle
around the one that is active.

00:50:26.366 --> 00:50:29.456 A:middle
It happens to be the
12-megapixel 30 FPS version.

00:50:29.456 --> 00:50:34.066 A:middle
And if that activeFormat,
the f format,

00:50:34.376 --> 00:50:38.376 A:middle
happens to support Display P3,
then there's a new property

00:50:38.376 --> 00:50:40.976 A:middle
that you can set
called activeColorSpace.

00:50:40.976 --> 00:50:45.176 A:middle
And if the activeFormat supports
it, you get wide color flowing

00:50:45.176 --> 00:50:47.946 A:middle
from your source to all
outputs in the session.

00:50:49.286 --> 00:50:52.156 A:middle
That was longwinded, but what
I wanted you to take home

00:50:52.156 --> 00:50:54.776 A:middle
from this is hopefully you
don't have to do any of this.

00:50:55.106 --> 00:50:56.336 A:middle
Most clients will never need

00:50:56.336 --> 00:50:58.986 A:middle
to set the activeColorSpace
directly and that's

00:50:58.986 --> 00:51:01.346 A:middle
because AVCaptureSession
will try to do it


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:50:58.986 --> 00:51:01.346 A:middle
because AVCaptureSession
will try to do it

00:51:01.346 --> 00:51:02.246 A:middle
for you automatically.

00:51:02.846 --> 00:51:07.686 A:middle
So in iOS 10, AVCaptureSession
has a new property that's long,

00:51:08.026 --> 00:51:12.066 A:middle
automaticallyConfigures
CaptureDeviceForWideColor.

00:51:13.016 --> 00:51:15.356 A:middle
When does it want to
choose wide color for you?

00:51:16.516 --> 00:51:20.046 A:middle
Wide color, in iOS 10,
is only for photography.

00:51:20.416 --> 00:51:21.446 A:middle
Let me say that again.

00:51:22.396 --> 00:51:26.716 A:middle
Wide color, in iOS 10, is only
for photography, not for video.

00:51:26.716 --> 00:51:29.436 A:middle
I'll explain why in a minute.

00:51:30.696 --> 00:51:31.876 A:middle
It can automatically,

00:51:31.876 --> 00:51:33.906 A:middle
the session can automatically
choose whether

00:51:33.906 --> 00:51:37.526 A:middle
to configure the whole session
configuration for wide color.

00:51:37.806 --> 00:51:41.516 A:middle
It will set the activeColorSpace
of your device on your behalf

00:51:41.516 --> 00:51:43.696 A:middle
to P3, depending on your config.

00:51:44.356 --> 00:51:46.276 A:middle
You have to have a PhotoOutput

00:51:46.276 --> 00:51:47.836 A:middle
in your session for
this to happen.

00:51:48.296 --> 00:51:49.586 A:middle
If you don't have a PhotoOutput,

00:51:49.806 --> 00:51:51.406 A:middle
you're obviously not
doing photography,

00:51:51.616 --> 00:51:52.726 A:middle
so you don't need wide color.

00:51:52.876 --> 00:51:56.126 A:middle
There are some caveats here.

00:51:56.216 --> 00:51:58.786 A:middle
Like, if you start adding
other outputs to your session,

00:51:59.096 --> 00:52:01.336 A:middle
maybe it's not as clear
what you're trying to do.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:51:59.096 --> 00:52:01.336 A:middle
maybe it's not as clear
what you're trying to do.

00:52:02.256 --> 00:52:05.016 A:middle
If you add an
AVCaptureVideoPreviewLayer,

00:52:05.456 --> 00:52:10.756 A:middle
the session will automatically
still pick Display P3 for you

00:52:11.166 --> 00:52:13.746 A:middle
because you're just previewing
and also doing photography.

00:52:13.746 --> 00:52:15.926 A:middle
If you have a MovieFileOutput

00:52:16.016 --> 00:52:18.546 A:middle
and a PhotoOutput,
now it's ambiguous.

00:52:18.546 --> 00:52:20.336 A:middle
You might really care
more about movies,

00:52:20.566 --> 00:52:24.096 A:middle
so it will not automatically
pick Display P3 for you.

00:52:24.596 --> 00:52:28.656 A:middle
VideoDataOutput is a special
case where we deliver buffers

00:52:28.656 --> 00:52:31.226 A:middle
to you via a callback and there,

00:52:31.356 --> 00:52:33.146 A:middle
the session will
only pick Display P3

00:52:33.146 --> 00:52:35.356 A:middle
if you're using the
photo preset.

00:52:35.856 --> 00:52:38.196 A:middle
It's pretty sure if you're
doing that that you mean

00:52:38.196 --> 00:52:40.656 A:middle
to do photography stuff
with those display buffers.

00:52:41.926 --> 00:52:45.566 A:middle
If you really, really want to,
you can force the capture device

00:52:45.566 --> 00:52:47.636 A:middle
to do wide color and here's how.

00:52:47.886 --> 00:52:51.346 A:middle
First you would tell the
session stop automatically doing

00:52:51.346 --> 00:52:52.096 A:middle
that thing for me.

00:52:52.096 --> 00:52:52.956 A:middle
Get out of my way.

00:52:54.036 --> 00:52:56.386 A:middle
And then you would
go to the device

00:52:56.386 --> 00:52:57.936 A:middle
and set the active
format yourself

00:52:57.936 --> 00:52:59.626 A:middle
to a format that's
supports wide color.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:53:00.156 --> 00:53:03.656 A:middle
And then you would set the
activeColorSpace to P3.

00:53:04.466 --> 00:53:09.216 A:middle
Once you do this, wide color
buffers will flow to all outputs

00:53:09.246 --> 00:53:10.416 A:middle
that accept video data.

00:53:10.606 --> 00:53:13.326 A:middle
That includes VideoDataOutput,
MovieFileOutput,

00:53:13.706 --> 00:53:16.546 A:middle
even the deprecated
AVCaptureStillImageOutput.

00:53:18.196 --> 00:53:22.256 A:middle
So while you can forcibly set
the device's activeColorSpace

00:53:22.256 --> 00:53:25.676 A:middle
to display P3, I want
to strongly caution you

00:53:25.676 --> 00:53:27.506 A:middle
against doing it
unless you really,

00:53:27.506 --> 00:53:28.476 A:middle
really know what you're doing.

00:53:29.546 --> 00:53:32.546 A:middle
The reason is wide
color is for photos

00:53:32.726 --> 00:53:36.486 A:middle
because we have a good photo
ecosystem story for wide color,

00:53:36.836 --> 00:53:38.536 A:middle
not so much for video.

00:53:39.186 --> 00:53:41.616 A:middle
So the main worry with
Display P3 content is

00:53:41.616 --> 00:53:44.226 A:middle
that the consumer has
to be wide color-aware

00:53:44.526 --> 00:53:46.746 A:middle
or your content will
be rendered as sRGB,

00:53:46.746 --> 00:53:48.356 A:middle
and the colors will
all look wrong.

00:53:48.776 --> 00:53:49.766 A:middle
They'll be rendered badly.

00:53:50.456 --> 00:53:53.286 A:middle
Most video playback
services are not color-aware.

00:53:53.586 --> 00:53:59.046 A:middle
So if you store a wide Display
P3 movie and then you try

00:53:59.046 --> 00:54:01.456 A:middle
to play it back with
some service,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:53:59.046 --> 00:54:01.456 A:middle
to play it back with
some service,

00:54:01.826 --> 00:54:03.986 A:middle
it will likely render
the colors wrong.

00:54:05.126 --> 00:54:06.776 A:middle
So if you do choose to do this,

00:54:06.776 --> 00:54:09.636 A:middle
make sure that your
VideoDataOutput is color-aware.

00:54:10.136 --> 00:54:11.736 A:middle
That it's propagating
the color tags.

00:54:11.736 --> 00:54:13.336 A:middle
That it's doing something
sensible.

00:54:13.336 --> 00:54:14.126 A:middle
That it's color-aware.

00:54:14.746 --> 00:54:19.336 A:middle
And if you do choose to capture
Display P3 movies using the

00:54:19.336 --> 00:54:21.426 A:middle
MovieFileOutput, just be aware

00:54:21.426 --> 00:54:25.376 A:middle
that they may render
incorrectly on other platforms.

00:54:25.376 --> 00:54:28.496 A:middle
This is -- we do allow this,
though, because we recognize

00:54:28.496 --> 00:54:33.436 A:middle
that it's important for some
pro workflows to be able

00:54:33.436 --> 00:54:35.326 A:middle
to do wide color movies as well.

00:54:36.266 --> 00:54:39.576 A:middle
So now dire warnings out
of the way, I can tell you

00:54:39.576 --> 00:54:42.176 A:middle
that we do have a very
good solution for photos

00:54:42.316 --> 00:54:43.896 A:middle
in sharing wide colors.

00:54:44.556 --> 00:54:47.756 A:middle
We should be aware that wide
color JPEGs use a Display P3

00:54:47.756 --> 00:54:50.996 A:middle
profile and consumers of
these images also need

00:54:50.996 --> 00:54:51.876 A:middle
to be color-aware.

00:54:52.366 --> 00:54:56.426 A:middle
The good news is photo services,
in general, are photo color --

00:54:56.576 --> 00:54:58.086 A:middle
they are color-aware these days.

00:54:58.636 --> 00:55:00.516 A:middle
iCloud Photo Library
is one of them.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:54:58.636 --> 00:55:00.516 A:middle
iCloud Photo Library
is one of them.

00:55:00.696 --> 00:55:05.086 A:middle
It can intelligently convert
your images to sRGB on devices

00:55:05.086 --> 00:55:06.296 A:middle
that don't support wide color,

00:55:06.996 --> 00:55:10.416 A:middle
but store the nice wide
color in the cloud.

00:55:10.416 --> 00:55:14.026 A:middle
We're also an industry
in transition right now,

00:55:14.026 --> 00:55:17.836 A:middle
so some photo services
don't understand wide color,

00:55:17.836 --> 00:55:19.806 A:middle
but most of them at
least are smart enough

00:55:19.806 --> 00:55:22.296 A:middle
to render it as sRGB.

00:55:23.476 --> 00:55:25.416 A:middle
For mixed sharing scenarios,

00:55:25.416 --> 00:55:28.666 A:middle
like say sending a photo
via Messages or Mail.

00:55:28.976 --> 00:55:30.066 A:middle
You don't know where it's going.

00:55:30.196 --> 00:55:31.996 A:middle
It might be going
to multiple devices.

00:55:32.416 --> 00:55:34.066 A:middle
Some of them might
support wide color.

00:55:34.066 --> 00:55:34.786 A:middle
Some might not.

00:55:35.226 --> 00:55:40.266 A:middle
So for this situation, we have
added a new service called Apple

00:55:40.266 --> 00:55:42.206 A:middle
Wide Color Sharing Profile.

00:55:42.986 --> 00:55:47.966 A:middle
Your content can be
manipulated in a way

00:55:47.966 --> 00:55:52.926 A:middle
that we generate a content
specific table-based ICC profile

00:55:53.236 --> 00:55:56.556 A:middle
that's specific to
that particular JPEG.

00:55:57.306 --> 00:56:00.496 A:middle
And what's nice about it is
if it's rendered by someone


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:55:57.306 --> 00:56:00.496 A:middle
And what's nice about it is
if it's rendered by someone

00:56:00.496 --> 00:56:02.646 A:middle
who doesn't know about
wide color, the part that's

00:56:02.646 --> 00:56:05.526 A:middle
in the sRGB gamut renders
absolutely correctly.

00:56:06.016 --> 00:56:08.046 A:middle
The extra information is carried

00:56:08.296 --> 00:56:11.056 A:middle
in the extra ICC profile
information in a way

00:56:11.056 --> 00:56:14.176 A:middle
that they can recover the
wide color information

00:56:14.176 --> 00:56:15.976 A:middle
with minimal quality loss.

00:56:16.316 --> 00:56:20.096 A:middle
You can learn more about how
to share wide color content

00:56:20.096 --> 00:56:24.246 A:middle
in sessions 505 and 712.

00:56:24.326 --> 00:56:25.586 A:middle
Both of those are on Thursday.

00:56:25.906 --> 00:56:27.896 A:middle
I've talked about the
first one three times now.

00:56:28.316 --> 00:56:31.226 A:middle
The working with wide color one
is also an excellent session.

00:56:32.936 --> 00:56:34.936 A:middle
On iPad Pro 9.7,

00:56:35.036 --> 00:56:38.216 A:middle
the AVCapturePhotoOutput
supports wide color broadly.

00:56:38.436 --> 00:56:44.476 A:middle
It supports it in 420f, BGRA
and JPEG, just not for 420v.

00:56:44.506 --> 00:56:49.386 A:middle
So if you have your session
configured to give Display P3

00:56:49.386 --> 00:56:51.986 A:middle
but then you say you
want a 420v image,

00:56:52.306 --> 00:56:56.306 A:middle
it will be converted to sRGB.

00:56:56.306 --> 00:56:59.146 A:middle
Live Photos support wide color.

00:56:59.386 --> 00:57:01.066 A:middle
Both the still and the movie.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:56:59.386 --> 00:57:01.066 A:middle
Both the still and the movie.

00:57:01.266 --> 00:57:02.446 A:middle
These are special movies.

00:57:02.446 --> 00:57:03.816 A:middle
This is part of the
Apple ecosystem.

00:57:03.816 --> 00:57:05.476 A:middle
So those are just
going to be wide color.

00:57:06.976 --> 00:57:09.836 A:middle
And bracketed captures also
support wide color, too.

00:57:12.236 --> 00:57:14.256 A:middle
Here's an interesting twist.

00:57:14.256 --> 00:57:17.076 A:middle
While I've been talking
about iPad Pro, iPad Pro,

00:57:17.076 --> 00:57:20.136 A:middle
iPad Pro, we support RAW.

00:57:20.496 --> 00:57:25.946 A:middle
And RAW capture is inherently
wide color because it has all

00:57:25.946 --> 00:57:27.486 A:middle
of those extra bits
of information.

00:57:27.976 --> 00:57:29.916 A:middle
We store it in the
sensor primaries

00:57:30.426 --> 00:57:32.576 A:middle
and there is enough
color information there

00:57:32.576 --> 00:57:36.986 A:middle
to be either rendered
as wide or sRGB.

00:57:37.066 --> 00:57:40.066 A:middle
Again, you're carrying the
ingredients around with you.

00:57:40.066 --> 00:57:43.756 A:middle
You can decide later if you want
to render it as wide or sRGB.

00:57:44.266 --> 00:57:46.676 A:middle
So shooting RAW and
rendering in post,

00:57:47.106 --> 00:57:50.216 A:middle
you can produce wide
color content on lots

00:57:50.216 --> 00:57:51.976 A:middle
of iOS devices, not
just iPad Pro.

00:57:55.066 --> 00:57:59.456 A:middle
As I just said, you can learn
more on wide color, in general,

00:57:59.456 --> 00:58:01.906 A:middle
not just sharing but
all about wide color.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:57:59.456 --> 00:58:01.906 A:middle
not just sharing but
all about wide color.

00:58:02.066 --> 00:58:04.806 A:middle
The best session to view is
the working with wide color one

00:58:04.906 --> 00:58:05.916 A:middle
on Thursday afternoon.

00:58:08.026 --> 00:58:11.606 A:middle
Use AVCapturePhotoOutput
for improved usability.

00:58:12.676 --> 00:58:14.916 A:middle
And we talked about four
main feature areas today.

00:58:14.916 --> 00:58:16.466 A:middle
We talked about capturing
Live Photos

00:58:16.466 --> 00:58:21.266 A:middle
in your app, RAW,
RAW + JPEG, DNG.

00:58:22.216 --> 00:58:24.966 A:middle
Nice little preview images
for faster rendering.

00:58:25.676 --> 00:58:27.346 A:middle
And wide color photos.

00:58:28.646 --> 00:58:32.056 A:middle
And believe it or not,
one hour was not enough

00:58:32.056 --> 00:58:33.626 A:middle
to cover everything
that we wanted to cover.

00:58:33.626 --> 00:58:36.326 A:middle
So we've done an
addendum to this session.

00:58:36.326 --> 00:58:37.736 A:middle
It's already recorded.

00:58:37.816 --> 00:58:39.146 A:middle
It should already be online.

00:58:39.766 --> 00:58:41.766 A:middle
It's a slide plus
voiceover thing

00:58:41.766 --> 00:58:44.126 A:middle
that we're calling a Chalk Talk.

00:58:44.126 --> 00:58:46.896 A:middle
And it tells you
about in-depth topics

00:58:46.896 --> 00:58:48.006 A:middle
that we didn't have time for.

00:58:48.456 --> 00:58:51.016 A:middle
Scene monitoring in
AVCapturePhotoOutput.

00:58:51.696 --> 00:58:54.086 A:middle
Resource preparation
and reclamation.

00:58:54.406 --> 00:58:56.886 A:middle
And then an unrelated topic,

00:58:56.886 --> 00:59:00.046 A:middle
changes to camera
privacy policy in iOS 10.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:58:56.886 --> 00:59:00.046 A:middle
changes to camera
privacy policy in iOS 10.

00:59:00.046 --> 00:59:01.436 A:middle
So please take a
look at that video.

00:59:01.436 --> 00:59:02.556 A:middle
It's about 20 minutes long.

00:59:04.426 --> 00:59:05.346 A:middle
More information.

00:59:05.526 --> 00:59:07.686 A:middle
All you need to remember
is the 501 at the end.

00:59:07.876 --> 00:59:10.596 A:middle
Go to that and you'll find,
I believe, seven pieces

00:59:10.596 --> 00:59:13.446 A:middle
of sample code as well
as new documentation

00:59:13.446 --> 00:59:14.786 A:middle
for AVCapturePhotoOutput.

00:59:14.836 --> 00:59:17.186 A:middle
The documentation folks
have been working very hard

00:59:17.186 --> 00:59:20.186 A:middle
and they've documented
the heck out of it.

00:59:20.436 --> 00:59:22.806 A:middle
And here are the related
sessions one more time.

00:59:23.466 --> 00:59:25.466 A:middle
The one that is the Chalk Talk,

00:59:25.466 --> 00:59:27.936 A:middle
we're calling
AVCapturePhotoOutput beyond

00:59:27.936 --> 00:59:28.606 A:middle
the basics.

00:59:29.046 --> 00:59:30.536 A:middle
And you can look at
that any time you want.

00:59:30.536 --> 00:59:30.716 A:middle
All right.

00:59:30.716 --> 00:59:32.976 A:middle
Have a great rest of the show,
and thank you for coming.

00:59:33.508 --> 00:59:35.508 A:middle
[ Applause ]

