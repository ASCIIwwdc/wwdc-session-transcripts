WEBVTT

00:00:08.516 --> 00:00:17.500 A:middle
[ Music ]

00:00:21.516 --> 00:00:29.546 A:middle
[ Applause ]

00:00:30.046 --> 00:00:30.456 A:middle
&gt;&gt; Good morning.

00:00:30.456 --> 00:00:33.176 A:middle
This is session 411,
System Trace in Depth.

00:00:33.356 --> 00:00:34.206 A:middle
My name is Chad Woolf.

00:00:34.206 --> 00:00:35.396 A:middle
&gt;&gt; And I'm Joe Grzywacz.

00:00:36.116 --> 00:00:38.226 A:middle
&gt;&gt; And we are performance
tools engineers for Apple.

00:00:39.366 --> 00:00:41.496 A:middle
Now in last year's In Depth
session we covered the

00:00:41.496 --> 00:00:42.256 A:middle
Time Profiler.

00:00:42.726 --> 00:00:44.876 A:middle
And we showed you how to analyze
your applications all the way

00:00:44.876 --> 00:00:46.206 A:middle
down to the disassembly level.

00:00:46.286 --> 00:00:47.576 A:middle
And our goal, then,
was to show you how

00:00:47.576 --> 00:00:49.246 A:middle
to make your code
as fast as possible.

00:00:49.426 --> 00:00:52.976 A:middle
Now at some point you may want
to run that optimized code

00:00:52.976 --> 00:00:56.206 A:middle
on multiple CPUs in order
to get even more work done.

00:00:56.286 --> 00:00:59.636 A:middle
But as you do this, you also
increase the system load.

00:01:00.216 --> 00:01:01.916 A:middle
Now as the system
load increases,

00:01:01.916 --> 00:01:05.146 A:middle
a couple of second-order effects
creep in, such as increases

00:01:05.146 --> 00:01:07.886 A:middle
in preemption, lock contention,
and virtual memory activity.

00:01:08.126 --> 00:01:10.376 A:middle
Now any one of these
three things is enough

00:01:10.376 --> 00:01:12.546 A:middle
to potentially offset the
gains that you had made

00:01:12.696 --> 00:01:13.916 A:middle
when you were doing
your time profiling.

00:01:14.866 --> 00:01:16.546 A:middle
So in today's session,
we're going to show you how

00:01:16.546 --> 00:01:19.966 A:middle
to use system trace to analyze
the second-order effects.

00:01:20.416 --> 00:01:21.316 A:middle
And we're going to show you how

00:01:21.316 --> 00:01:23.636 A:middle
to efficiently load the
system while still maintaining

00:01:23.636 --> 00:01:24.796 A:middle
optimum performance.

00:01:24.796 --> 00:01:27.516 A:middle
So our session's going
to look like this today.

00:01:27.516 --> 00:01:29.136 A:middle
We're going to talk a little
bit about system trace

00:01:29.136 --> 00:01:30.956 A:middle
and why it applies to
application developers.

00:01:31.316 --> 00:01:33.546 A:middle
And then Joe and I are going to
walk you through system trace.

00:01:33.686 --> 00:01:35.236 A:middle
We're also going to talk a
little bit about threading,

00:01:35.536 --> 00:01:37.896 A:middle
signposts, some a little
bit on virtual memory,

00:01:38.476 --> 00:01:39.966 A:middle
and show you some
best practices on how

00:01:39.966 --> 00:01:41.336 A:middle
to get the most out
of the tools.

00:01:42.736 --> 00:01:44.986 A:middle
So why system trace for
application developers?

00:01:45.456 --> 00:01:47.996 A:middle
Well, when your application
becomes front and center

00:01:47.996 --> 00:01:51.326 A:middle
on the device, from the users'
perspective that is the system.

00:01:52.186 --> 00:01:54.126 A:middle
They don't see your
application as a peer

00:01:54.126 --> 00:01:56.176 A:middle
with all these system
services and daemons contending

00:01:56.176 --> 00:01:58.956 A:middle
for shared resources
like CPU time and memory.

00:01:59.526 --> 00:02:00.366 A:middle
They just see your app.

00:01:59.526 --> 00:02:00.366 A:middle
They just see your app.

00:02:00.366 --> 00:02:02.776 A:middle
And so if your app
stutters do to a flurry

00:02:02.776 --> 00:02:05.216 A:middle
of virtual memory
activity or due

00:02:05.216 --> 00:02:07.356 A:middle
to maybe a misprioritized
thread, they're going to come

00:02:07.356 --> 00:02:09.056 A:middle
to you looking for a fix.

00:02:09.056 --> 00:02:10.586 A:middle
So that's the bad news.

00:02:11.796 --> 00:02:14.356 A:middle
The good news is that when
your app is front and center

00:02:14.356 --> 00:02:17.356 A:middle
on the device, it is the most
important thing on the device.

00:02:17.916 --> 00:02:19.816 A:middle
So the operating system knows
this, and it's going to give you

00:02:19.816 --> 00:02:22.196 A:middle
as much CPU time and memory
as it can possibly spare.

00:02:22.946 --> 00:02:24.976 A:middle
So when we talk about
tuning with system trace,

00:02:25.106 --> 00:02:27.226 A:middle
we're not really talking about
tuning the system, we're talking

00:02:27.226 --> 00:02:28.466 A:middle
about tuning your application

00:02:28.856 --> 00:02:30.296 A:middle
to use the resources
that it's been given.

00:02:31.256 --> 00:02:33.716 A:middle
Now system trace is a
template in Instruments.

00:02:33.716 --> 00:02:35.676 A:middle
It works great in all
four of our platforms.

00:02:36.546 --> 00:02:38.676 A:middle
And when you take a recording
with it, it puts the kernel

00:02:38.676 --> 00:02:40.006 A:middle
into a special tracing mode

00:02:40.626 --> 00:02:43.956 A:middle
that records all the scheduling
activity, system calls,

00:02:44.466 --> 00:02:46.236 A:middle
and virtual memory
operations that are occurring.

00:02:46.976 --> 00:02:49.076 A:middle
Now this can accumulate
over time.

00:02:49.076 --> 00:02:50.006 A:middle
It could be a lot of data.

00:02:50.286 --> 00:02:52.686 A:middle
So one of the changes we
made in Instruments 8 is

00:02:52.686 --> 00:02:55.096 A:middle
that we put the template into
Windowed Mode by default.

00:02:55.096 --> 00:02:56.926 A:middle
And what that means
is that we keep

00:02:56.926 --> 00:02:58.966 A:middle
about the last five seconds
worth of data around.

00:02:59.506 --> 00:03:02.216 A:middle
And the advantage here
is that you can take --

00:02:59.506 --> 00:03:02.216 A:middle
And the advantage here
is that you can take --

00:03:02.366 --> 00:03:04.646 A:middle
you can start your recording,
setup your application,

00:03:04.946 --> 00:03:06.166 A:middle
take as long as you
need to get it

00:03:06.166 --> 00:03:07.556 A:middle
to reproduce the
performance problem,

00:03:07.796 --> 00:03:10.296 A:middle
and when that performance
problem reproduces, you hit stop

00:03:10.296 --> 00:03:12.366 A:middle
and you get that last
five seconds worth

00:03:12.366 --> 00:03:13.306 A:middle
of actionable data.

00:03:14.016 --> 00:03:16.316 A:middle
Now this is what five seconds
worth of data can look like.

00:03:16.486 --> 00:03:18.096 A:middle
These traces can
get pretty dense.

00:03:18.596 --> 00:03:20.876 A:middle
We found it's very
useful if you're able

00:03:20.876 --> 00:03:22.956 A:middle
to correlate this data with some

00:03:22.956 --> 00:03:25.016 A:middle
of the high-level activities
inside your application,

00:03:25.526 --> 00:03:27.466 A:middle
such as am I updating
a table view,

00:03:27.596 --> 00:03:29.526 A:middle
did I have a download
going on in the background,

00:03:29.596 --> 00:03:30.646 A:middle
maybe am I updating a graph.

00:03:30.646 --> 00:03:31.976 A:middle
Those kind of high level things.

00:03:32.806 --> 00:03:35.686 A:middle
So this year in Instruments
8 we included the Points

00:03:35.686 --> 00:03:36.486 A:middle
of Interest instrument.

00:03:37.666 --> 00:03:40.166 A:middle
Now the Points of Interest
instrument is essentially a

00:03:40.166 --> 00:03:42.976 A:middle
blank canvas where you tell
Instruments what you consider

00:03:42.976 --> 00:03:45.366 A:middle
interesting and we'll put it
up there on the graph for you.

00:03:46.316 --> 00:03:48.836 A:middle
Now you do this using
Signposts from within your code.

00:03:50.216 --> 00:03:52.056 A:middle
And Signposts have been
released for a while,

00:03:52.216 --> 00:03:54.956 A:middle
but we used to have -- the
way you used to get to it was

00:03:55.026 --> 00:03:57.696 A:middle
to call this direct system call
and you had to dig these macros

00:03:57.696 --> 00:03:59.286 A:middle
out of these header files
and put it altogether.

00:03:59.286 --> 00:04:01.096 A:middle
And it was kind of clunky.

00:03:59.286 --> 00:04:01.096 A:middle
And it was kind of clunky.

00:04:01.776 --> 00:04:05.466 A:middle
Now on top of it being clucky
in today's SWIFT world,

00:04:05.466 --> 00:04:06.676 A:middle
it just simply doesn't work.

00:04:06.836 --> 00:04:08.976 A:middle
So what we're going to do
is deprecate that approach.

00:04:09.936 --> 00:04:12.006 A:middle
But we have added in the new
operating system these nice

00:04:12.006 --> 00:04:14.026 A:middle
functions to do the
exact same thing.

00:04:14.156 --> 00:04:16.065 A:middle
And they're kdebug signpost.

00:04:16.065 --> 00:04:18.696 A:middle
So they work great from
C, Objective C, C++,

00:04:18.696 --> 00:04:19.836 A:middle
and now SWIFT as well.

00:04:21.356 --> 00:04:22.836 A:middle
So to get started,
the easiest way is

00:04:22.836 --> 00:04:24.446 A:middle
to drop a point event
on a timeline.

00:04:24.446 --> 00:04:26.236 A:middle
That's one of those
little red lollipops.

00:04:26.596 --> 00:04:29.926 A:middle
And the way you do that
is invoke kdebug signpost

00:04:30.096 --> 00:04:31.236 A:middle
and that's it.

00:04:31.236 --> 00:04:32.256 A:middle
So inside of our Mouse Down,

00:04:32.256 --> 00:04:33.706 A:middle
every time we hit our
Mouse Down, you'll see one

00:04:33.706 --> 00:04:35.426 A:middle
of these appear on the timeline.

00:04:36.126 --> 00:04:37.406 A:middle
Now it does take
a few arguments.

00:04:37.466 --> 00:04:40.606 A:middle
The first one is a code that's
just some arbitrary integer

00:04:40.606 --> 00:04:42.686 A:middle
between 0 and 16383.

00:04:42.916 --> 00:04:44.596 A:middle
And it helps you
identify your Signpost.

00:04:45.506 --> 00:04:47.376 A:middle
The next four arguments
are integers as well

00:04:47.376 --> 00:04:48.426 A:middle
and can be anything you want.

00:04:48.596 --> 00:04:50.656 A:middle
By default Instruments will just
pass that right up to the UI.

00:04:50.656 --> 00:04:53.606 A:middle
Now you can name these things.

00:04:53.606 --> 00:04:55.446 A:middle
Just got to toggle over to
the configuration section

00:04:55.446 --> 00:04:58.536 A:middle
of the Instrument and
add to the Table View.

00:04:58.536 --> 00:05:01.636 A:middle
And so we have our code
5 now being Mouse Down.

00:04:58.536 --> 00:05:01.636 A:middle
And so we have our code
5 now being Mouse Down.

00:05:01.726 --> 00:05:04.836 A:middle
So next time I take a recording,
I can see that those Points

00:05:04.836 --> 00:05:06.276 A:middle
of Interest are now Mouse Downs.

00:05:07.486 --> 00:05:08.536 A:middle
Now if you like Points
of Interest,

00:05:08.536 --> 00:05:10.056 A:middle
you'll also like
Regions of Interest.

00:05:10.056 --> 00:05:12.826 A:middle
They're basically the same
thing, but they work for states

00:05:12.826 --> 00:05:15.106 A:middle
and actions or things that
occur over a period of time.

00:05:15.106 --> 00:05:17.666 A:middle
Now it's a little bit more
complicated because instead

00:05:17.666 --> 00:05:18.876 A:middle
of one call you do have two.

00:05:18.876 --> 00:05:20.336 A:middle
You got a start and an end.

00:05:20.826 --> 00:05:23.576 A:middle
And you also have a pairing
rule that's in Instruments.

00:05:24.076 --> 00:05:25.896 A:middle
Now by default it's a
very simple pairing rule.

00:05:25.896 --> 00:05:27.556 A:middle
It just uses the
code, so all you have

00:05:27.556 --> 00:05:31.996 A:middle
to do is supply the same code
in both the start and the end.

00:05:31.996 --> 00:05:33.506 A:middle
Now we know that
that's not going to work

00:05:33.506 --> 00:05:35.526 A:middle
for all applications because
some applications have

00:05:35.526 --> 00:05:38.526 A:middle
to issue a flurry of starts
followed by a flurry of ends.

00:05:38.916 --> 00:05:40.096 A:middle
And what that can be --

00:05:40.096 --> 00:05:43.466 A:middle
inside Instruments there
can be some ambiguity in how

00:05:43.466 --> 00:05:44.416 A:middle
to pair those things up.

00:05:45.016 --> 00:05:46.626 A:middle
So we do allow you to
change the pairing rule.

00:05:46.936 --> 00:05:48.136 A:middle
Come down here to
the Configuration.

00:05:48.996 --> 00:05:52.426 A:middle
You can select Code and First
Argument or Code and Thread.

00:05:53.766 --> 00:05:56.826 A:middle
So Code and First Argument
means that both your start

00:05:56.826 --> 00:05:59.736 A:middle
and end have to have the same
code and same first argument.

00:06:00.396 --> 00:06:02.356 A:middle
So in this example what
we've done is started a bunch

00:06:02.356 --> 00:06:03.956 A:middle
of URL downloads in parallel,

00:06:04.386 --> 00:06:07.276 A:middle
and we've used the URL
download task pointer

00:06:07.366 --> 00:06:08.566 A:middle
as a first argument.

00:06:08.566 --> 00:06:11.176 A:middle
So now you can see
these parallel downloads

00:06:11.296 --> 00:06:12.246 A:middle
on the Instruments timeline.

00:06:12.716 --> 00:06:15.046 A:middle
If you use Code and Thread,

00:06:15.876 --> 00:06:19.426 A:middle
you have to issue
the same code start

00:06:19.426 --> 00:06:20.566 A:middle
and end on the same thread.

00:06:20.566 --> 00:06:22.346 A:middle
And here's an example
of that happening.

00:06:22.526 --> 00:06:24.456 A:middle
But you can see it's
happening with inside

00:06:24.456 --> 00:06:25.606 A:middle
of a dispatch apply block.

00:06:25.926 --> 00:06:30.076 A:middle
So now we have four Regions
of Interest on the graph

00:06:30.076 --> 00:06:32.566 A:middle
that are -- we've got one for
each thread or a worker thread.

00:06:34.476 --> 00:06:36.226 A:middle
Now so far, the Regions

00:06:36.226 --> 00:06:37.576 A:middle
of Interest you've seen
have all been read.

00:06:37.576 --> 00:06:38.476 A:middle
It's all monochromatic.

00:06:38.716 --> 00:06:40.626 A:middle
But if you're willing to
sacrifice your last argument,

00:06:40.626 --> 00:06:42.926 A:middle
you can come over here
and check this box

00:06:42.926 --> 00:06:45.026 A:middle
that says use the last
argument for color.

00:06:46.556 --> 00:06:48.786 A:middle
And in your fourth argument,
you just need to supply one

00:06:48.786 --> 00:06:51.346 A:middle
of these enumerations
between 0 and 4,

00:06:51.346 --> 00:06:53.096 A:middle
and those are the five
basic colors in Instruments.

00:06:53.166 --> 00:06:56.346 A:middle
And in this example when
my download task completes

00:06:56.346 --> 00:06:57.996 A:middle
successfully, I've
colored it green.

00:06:58.416 --> 00:07:01.386 A:middle
And if it completes with
an error, I color it red.

00:06:58.416 --> 00:07:01.386 A:middle
And if it completes with
an error, I color it red.

00:07:01.456 --> 00:07:02.716 A:middle
So you can see very
clearly a difference

00:07:02.716 --> 00:07:04.196 A:middle
between pass and fail.

00:07:05.916 --> 00:07:07.136 A:middle
So now when we put
this altogether,

00:07:07.136 --> 00:07:10.126 A:middle
you can see how it's much
easier to correlate that big,

00:07:10.126 --> 00:07:11.356 A:middle
complicated trace I showed you

00:07:11.356 --> 00:07:14.356 A:middle
with the high level
activity in your application.

00:07:15.176 --> 00:07:16.256 A:middle
So for example, you can see

00:07:16.256 --> 00:07:18.346 A:middle
that this flurry activity
was actually created

00:07:18.806 --> 00:07:20.576 A:middle
by our download tasks.

00:07:21.626 --> 00:07:23.756 A:middle
So let's talk about our
demo application today.

00:07:23.756 --> 00:07:26.386 A:middle
We're going to be
looking at an app we wrote

00:07:26.386 --> 00:07:28.966 A:middle
for you guys called Graphasaurus
2, it's the spiritual successor

00:07:28.966 --> 00:07:31.426 A:middle
to Graphasaurus from
last year's session.

00:07:31.926 --> 00:07:33.006 A:middle
But just like last
year's session,

00:07:33.006 --> 00:07:34.906 A:middle
we're going to be looking
at real-world problems.

00:07:35.116 --> 00:07:36.546 A:middle
So these are problems
that we encountered

00:07:36.606 --> 00:07:38.156 A:middle
when we were tuning
Instruments 8.

00:07:38.696 --> 00:07:40.206 A:middle
And we decided to
just include them

00:07:40.206 --> 00:07:41.836 A:middle
in an iOS application for demo.

00:07:42.686 --> 00:07:43.896 A:middle
There is a new graphing style.

00:07:43.946 --> 00:07:46.066 A:middle
This looks more like the state
graphing style that you see

00:07:46.066 --> 00:07:47.406 A:middle
in Instruments because
that's something

00:07:47.406 --> 00:07:48.956 A:middle
that we're tuning this year.

00:07:49.966 --> 00:07:51.926 A:middle
And another difference from
last year is that we're going

00:07:51.926 --> 00:07:55.046 A:middle
to assume that our code is --
has already been time profiled,

00:07:55.046 --> 00:07:57.336 A:middle
and it's already optimal
given the constraints we have.

00:07:57.746 --> 00:07:58.626 A:middle
And just like last year,

00:07:58.626 --> 00:08:00.146 A:middle
we're going to be
generating our graphs

00:07:58.626 --> 00:08:00.146 A:middle
we're going to be
generating our graphs

00:08:00.146 --> 00:08:01.916 A:middle
on the CPU using core graphics.

00:08:03.306 --> 00:08:06.696 A:middle
Now, what we did is we
did some initial timing.

00:08:07.286 --> 00:08:09.426 A:middle
And we found that to generate
all four of these graphs.

00:08:09.426 --> 00:08:11.406 A:middle
It was going to take about
20 milliseconds in total.

00:08:11.406 --> 00:08:13.836 A:middle
And that's in the worst case
when everything's zoomed out.

00:08:14.756 --> 00:08:17.466 A:middle
Now that is larger than
our 16 millisecond deadline

00:08:17.466 --> 00:08:19.346 A:middle
if we wanted to hit
60 frames per second.

00:08:19.346 --> 00:08:21.346 A:middle
So we decided that
we needed to try

00:08:21.346 --> 00:08:22.776 A:middle
to introduce some parallelism.

00:08:23.366 --> 00:08:25.626 A:middle
Because what we know
is that all four

00:08:25.626 --> 00:08:27.116 A:middle
of these graphs can be
generated independently.

00:08:27.116 --> 00:08:29.816 A:middle
And they take about five
milliseconds in the worst case.

00:08:30.006 --> 00:08:32.846 A:middle
So we're thinking if throw
all this work at dispatch

00:08:32.846 --> 00:08:36.166 A:middle
and we have perfect scalability,
then our two-core iPad

00:08:36.166 --> 00:08:38.645 A:middle
over here should be able to
cut that work down in half.

00:08:39.756 --> 00:08:41.986 A:middle
To see how we did, show you
how to use system trace.

00:08:41.986 --> 00:08:43.405 A:middle
I'm going to turn
it over to Joe.

00:08:43.405 --> 00:08:44.035 A:middle
&gt;&gt; Thank you, Chad.

00:08:45.516 --> 00:08:49.566 A:middle
[ Applause ]

00:08:50.066 --> 00:08:50.806 A:middle
All right, so what
you're looking

00:08:50.806 --> 00:08:52.776 A:middle
at here is a Quick Time mirror

00:08:52.776 --> 00:08:54.646 A:middle
of the iPad Pro I'm
playing with here.

00:08:54.646 --> 00:08:56.526 A:middle
So you can see just
like in Instruments,

00:08:56.526 --> 00:08:58.606 A:middle
you can pan around
nice and smooth.

00:08:59.026 --> 00:09:01.036 A:middle
But when I eventually
pinch out a punch,

00:08:59.026 --> 00:09:01.036 A:middle
But when I eventually
pinch out a punch,

00:09:01.276 --> 00:09:04.246 A:middle
the animation gets just a little
bit stuttery way out here.

00:09:04.246 --> 00:09:06.856 A:middle
It's not awful, but
it could be better.

00:09:07.416 --> 00:09:09.966 A:middle
So what I want to do now
is figure out why that is.

00:09:10.076 --> 00:09:12.806 A:middle
So let's go to it here to Xcode.

00:09:12.806 --> 00:09:15.896 A:middle
And let's click and hold on the
Run button and choose Profile.

00:09:16.966 --> 00:09:18.716 A:middle
So that'll build your
application release mode.

00:09:19.196 --> 00:09:20.406 A:middle
Install it on the device.

00:09:20.906 --> 00:09:23.416 A:middle
And then Instruments will come
up with its template chooser

00:09:23.416 --> 00:09:24.996 A:middle
where you decide how
you want to profile.

00:09:25.766 --> 00:09:26.856 A:middle
I'm going to go ahead
and double click

00:09:26.856 --> 00:09:28.136 A:middle
on the System Trace template.

00:09:29.336 --> 00:09:33.376 A:middle
And now from here before I
start recording, I went ahead

00:09:33.376 --> 00:09:35.956 A:middle
and added some of the kdebug
signpost start and end points

00:09:35.956 --> 00:09:37.016 A:middle
to my code ahead of time.

00:09:37.366 --> 00:09:39.326 A:middle
And so I want to configure
how those will appear inside

00:09:39.326 --> 00:09:39.956 A:middle
of Instruments.

00:09:40.366 --> 00:09:42.246 A:middle
And so you do that down
here in the lower right

00:09:43.156 --> 00:09:44.186 A:middle
in the Record settings.

00:09:44.356 --> 00:09:47.356 A:middle
And first off, I did want to
use my first argument for color,

00:09:47.696 --> 00:09:50.526 A:middle
so I put some unique numbers
inside of my kdebug signpost.

00:09:51.116 --> 00:09:54.276 A:middle
And I added three
different codes.

00:09:54.386 --> 00:09:58.276 A:middle
Code 0 is CADisplayLink.

00:09:58.716 --> 00:10:01.616 A:middle
So that's that 60 hertz timer
that's driving the animation.

00:09:58.716 --> 00:10:01.616 A:middle
So that's that 60 hertz timer
that's driving the animation.

00:10:01.806 --> 00:10:03.786 A:middle
So basically this region
will correspond approximately

00:10:03.786 --> 00:10:06.086 A:middle
to my frame time because this is
where I do all of my rendering.

00:10:07.356 --> 00:10:11.446 A:middle
Next is Code 1, and that
is, I'll call it CreatePath.

00:10:11.516 --> 00:10:13.306 A:middle
So this one I'm actually
creating the CG paths,

00:10:13.396 --> 00:10:15.356 A:middle
the rectangles and the
labels that are going

00:10:15.356 --> 00:10:16.686 A:middle
to be appearing on the screen.

00:10:17.656 --> 00:10:21.326 A:middle
Finally Code 2 is
called RenderGraph.

00:10:21.326 --> 00:10:23.856 A:middle
So that's when I take those CG
paths and actually render them

00:10:23.856 --> 00:10:26.876 A:middle
into a CG bitmap context and
then display them on the screen.

00:10:28.156 --> 00:10:30.366 A:middle
Finally, since my code's going
to be running in parallel

00:10:30.416 --> 00:10:33.006 A:middle
and they're going to be emitting
the same two codes here,

00:10:33.236 --> 00:10:35.176 A:middle
I need to tell Instruments
how to differentiate them.

00:10:35.216 --> 00:10:37.296 A:middle
And in this case, the
thread is good enough

00:10:37.296 --> 00:10:38.686 A:middle
since it'll be running
on different threads.

00:10:39.466 --> 00:10:41.346 A:middle
All right, so I did
all that configuration.

00:10:41.346 --> 00:10:42.696 A:middle
I don't want to be
doing this again

00:10:42.696 --> 00:10:44.336 A:middle
and again every time
I come to Instruments.

00:10:44.806 --> 00:10:47.296 A:middle
So we go to file and
choose Save As Template.

00:10:47.896 --> 00:10:49.586 A:middle
I'll give it a descriptive name.

00:10:51.516 --> 00:10:53.976 A:middle
Graphasaurus System
Trace and hit Save.

00:10:54.576 --> 00:10:57.046 A:middle
And now let's say you close this
document, you close Instruments,

00:10:57.046 --> 00:10:59.086 A:middle
you come back a week
later, whenever you get

00:10:59.086 --> 00:11:02.506 A:middle
to the template chooser,
move over to the Custom tab,

00:10:59.086 --> 00:11:02.506 A:middle
to the template chooser,
move over to the Custom tab,

00:11:03.386 --> 00:11:04.816 A:middle
there's your template
ready to go.

00:11:05.566 --> 00:11:06.956 A:middle
You don't have to redo
your configuration.

00:11:07.556 --> 00:11:08.266 A:middle
Just hit record.

00:11:09.446 --> 00:11:11.126 A:middle
Now Instruments is going
to wait for me to kind

00:11:11.126 --> 00:11:12.226 A:middle
of reproduce the problem here.

00:11:12.226 --> 00:11:14.566 A:middle
So I'm just going to pinch out,
just like you saw me do before.

00:11:15.556 --> 00:11:17.016 A:middle
Pinch out where it
gets to the problem.

00:11:17.266 --> 00:11:19.216 A:middle
And then I'm going to just
reproduce that problem

00:11:19.216 --> 00:11:22.136 A:middle
for a couple of seconds so that
it fills that window buffer

00:11:22.136 --> 00:11:23.346 A:middle
with the data I'm interested in.

00:11:23.746 --> 00:11:25.396 A:middle
And once I do that,
I stop the recording.

00:11:26.036 --> 00:11:28.296 A:middle
So now Instruments
will go download all

00:11:28.296 --> 00:11:30.956 A:middle
of that data off the device
and then begin to analyze it.

00:11:31.286 --> 00:11:32.856 A:middle
And since this was a
Windowed Mode recording,

00:11:32.856 --> 00:11:34.156 A:middle
you only get those
last few seconds.

00:11:34.586 --> 00:11:36.816 A:middle
Make sure that when you
reproduce the problem,

00:11:36.936 --> 00:11:38.336 A:middle
you stop the recording
right afterwards.

00:11:38.646 --> 00:11:40.526 A:middle
Otherwise, newer events are
going to come in and kind

00:11:40.526 --> 00:11:42.426 A:middle
of push out the stuff you
were actually interested in.

00:11:43.826 --> 00:11:46.706 A:middle
So we'll wait here for
Instruments to finish analyzing.

00:11:50.656 --> 00:11:54.356 A:middle
And there we go.

00:11:54.716 --> 00:11:56.306 A:middle
So we're looking at a
whole bunch of stuff here.

00:11:56.986 --> 00:11:58.936 A:middle
So let's make this
a little bit larger

00:11:58.936 --> 00:12:00.006 A:middle
so we can see what's going on.

00:11:58.936 --> 00:12:00.006 A:middle
so we can see what's going on.

00:12:00.946 --> 00:12:03.096 A:middle
All right, so this first
selected instrument that's the

00:12:03.096 --> 00:12:04.606 A:middle
new Points of Interest
Instrument.

00:12:05.006 --> 00:12:07.496 A:middle
So let's zoom in on a
section here randomly and kind

00:12:07.496 --> 00:12:10.086 A:middle
of see what we're looking at.

00:12:10.086 --> 00:12:13.246 A:middle
So now we can see there's
all those codes I created.

00:12:13.246 --> 00:12:15.716 A:middle
I see DisplayLink, the
CreatePath, the RenderGraph.

00:12:15.916 --> 00:12:17.126 A:middle
And it looks like I'd expect.

00:12:17.126 --> 00:12:19.726 A:middle
I have my big blue
CADisplayLink time here.

00:12:20.096 --> 00:12:23.276 A:middle
And inside there's four pairs
of the green and purple create

00:12:23.276 --> 00:12:24.516 A:middle
and rendering those graphs.

00:12:24.836 --> 00:12:25.726 A:middle
And so that looks good.

00:12:26.326 --> 00:12:28.976 A:middle
But when I mouse
over to this region,

00:12:29.146 --> 00:12:31.756 A:middle
you get a little tool tip
showing you those arguments you

00:12:31.756 --> 00:12:33.496 A:middle
provided along with
the duration.

00:12:33.836 --> 00:12:36.526 A:middle
And I'm actually running here
close to 30 milliseconds.

00:12:36.526 --> 00:12:39.136 A:middle
So it's about half of the
speed I want to be running at.

00:12:39.136 --> 00:12:39.806 A:middle
So that's not good.

00:12:40.706 --> 00:12:41.926 A:middle
But this was just one frame.

00:12:41.926 --> 00:12:42.806 A:middle
I rendered a ton.

00:12:43.056 --> 00:12:44.676 A:middle
So what does it look
like in aggregate?

00:12:44.916 --> 00:12:47.886 A:middle
Well, we come down here and
look at this detail table.

00:12:48.206 --> 00:12:50.206 A:middle
This is currently showing
us a time sorted list

00:12:50.206 --> 00:12:51.206 A:middle
of all those regions.

00:12:51.506 --> 00:12:53.536 A:middle
So you could look through
this huge list here and look

00:12:53.536 --> 00:12:54.986 A:middle
at the arguments and et cetera.

00:12:55.646 --> 00:12:58.946 A:middle
But we did a table here that
aggregates that for you.

00:12:59.166 --> 00:13:01.986 A:middle
It's called the KDebug Interval
Signposts by Code table.

00:12:59.166 --> 00:13:01.986 A:middle
It's called the KDebug Interval
Signposts by Code table.

00:13:02.846 --> 00:13:05.136 A:middle
And when I select that
here's all the codes

00:13:05.136 --> 00:13:06.376 A:middle
that Graphasaurus 2 emitted.

00:13:07.026 --> 00:13:09.026 A:middle
And we can see here's
my CADisplayLink.

00:13:09.166 --> 00:13:12.976 A:middle
I rendered 152 frames, and
on average, they were taking

00:13:12.976 --> 00:13:14.426 A:middle
about 28 milliseconds.

00:13:14.426 --> 00:13:16.116 A:middle
So yeah, in average,
I'm not running so well.

00:13:16.176 --> 00:13:17.636 A:middle
You can see the min, the max,

00:13:17.636 --> 00:13:19.186 A:middle
the standard deviation
that sort of thing.

00:13:19.876 --> 00:13:22.276 A:middle
You can dive in with this
focus button next to the code.

00:13:22.276 --> 00:13:25.556 A:middle
And now that'll give you a
table of all of that data.

00:13:25.556 --> 00:13:26.886 A:middle
Those are all the
events that happened

00:13:26.886 --> 00:13:28.486 A:middle
that were my CADisplayLink
events.

00:13:29.366 --> 00:13:31.456 A:middle
So I'm going to -- from
here you could sort them

00:13:31.456 --> 00:13:33.116 A:middle
by anything you want,
different arguments,

00:13:33.116 --> 00:13:35.086 A:middle
whatever is important
in your application.

00:13:35.416 --> 00:13:36.876 A:middle
Here I just want to
sort them by duration.

00:13:37.926 --> 00:13:40.476 A:middle
And then what I'm going
to do is, I don't know,

00:13:40.476 --> 00:13:43.116 A:middle
I'm going to pick one of
these ones here somewhere

00:13:43.116 --> 00:13:45.556 A:middle
in the middle, and now
what I want to point out is

00:13:45.556 --> 00:13:47.086 A:middle
when I click on one
of these rows,

00:13:47.396 --> 00:13:49.036 A:middle
the graph view up above shifted.

00:13:49.656 --> 00:13:51.596 A:middle
And what happened was it went

00:13:51.696 --> 00:13:55.636 A:middle
and it made the region
I'm interested in visible.

00:13:55.966 --> 00:13:56.546 A:middle
Here it is.

00:13:56.986 --> 00:13:59.106 A:middle
And it put this blue
inspection head

00:13:59.106 --> 00:14:00.106 A:middle
at the beginning of that region.

00:13:59.106 --> 00:14:00.106 A:middle
at the beginning of that region.

00:14:00.106 --> 00:14:01.726 A:middle
So you kind of correlate
the thing you clicked

00:14:01.726 --> 00:14:04.036 A:middle
on in the bottom with where it
is up above in the track view.

00:14:04.826 --> 00:14:05.966 A:middle
So now I'm looking
at this frame.

00:14:06.476 --> 00:14:09.976 A:middle
You can also control-click
on that row

00:14:10.076 --> 00:14:11.356 A:middle
and choose set time filter.

00:14:11.956 --> 00:14:13.406 A:middle
And what that'll do
is gray out everything

00:14:13.406 --> 00:14:15.426 A:middle
in the detail view that's
outside of that time range,

00:14:15.526 --> 00:14:17.816 A:middle
and it does the same up in
the track view up above.

00:14:17.816 --> 00:14:19.656 A:middle
So you can use that to kind
of filter out your data

00:14:19.656 --> 00:14:22.236 A:middle
that you're interested in
or here just use it as kind

00:14:22.236 --> 00:14:24.726 A:middle
of a visual cue at the
frame you're looking at.

00:14:24.786 --> 00:14:25.826 A:middle
So now that I've done that.

00:14:26.416 --> 00:14:27.646 A:middle
I'm looking at this frame.

00:14:27.776 --> 00:14:30.096 A:middle
I can see that my
CADisplayLink started here.

00:14:30.096 --> 00:14:30.796 A:middle
It ended here.

00:14:30.796 --> 00:14:32.896 A:middle
But I don't really know
why it looks like this.

00:14:32.956 --> 00:14:35.196 A:middle
All this is telling you is
when it started, when it ended.

00:14:35.546 --> 00:14:37.156 A:middle
You don't know if your
application was doing work,

00:14:37.256 --> 00:14:38.126 A:middle
if it went to sleep.

00:14:38.326 --> 00:14:39.956 A:middle
You can't tell from this graph.

00:14:40.016 --> 00:14:41.246 A:middle
So we need to dive in deeper.

00:14:42.436 --> 00:14:44.736 A:middle
Here in the top right of
Instruments in the toolbar,

00:14:45.186 --> 00:14:47.386 A:middle
we're currently on the
Instruments strategy,

00:14:47.386 --> 00:14:50.076 A:middle
which is those list of all the
instruments in this template.

00:14:50.076 --> 00:14:52.926 A:middle
You could click here
on this thread data

00:14:52.996 --> 00:14:54.546 A:middle
to see all the threads
in your application.

00:14:55.266 --> 00:14:58.086 A:middle
Alternatively, let's say we
were already down here looking

00:14:58.086 --> 00:14:59.366 A:middle
at a thread in our detail view.

00:14:59.816 --> 00:15:03.066 A:middle
If you option-click, you'll see
you get these hyperlink kind

00:14:59.816 --> 00:15:03.066 A:middle
If you option-click, you'll see
you get these hyperlink kind

00:15:03.066 --> 00:15:04.456 A:middle
of style that you
can click on that

00:15:04.796 --> 00:15:06.606 A:middle
and choose Reveal
in Thread Strategy.

00:15:07.196 --> 00:15:08.956 A:middle
So that'll jump you
to the Thread Strategy

00:15:08.996 --> 00:15:11.486 A:middle
and preselect that
thread for you.

00:15:12.036 --> 00:15:14.466 A:middle
So we can see here, make
this a little bit larger.

00:15:16.146 --> 00:15:17.706 A:middle
It selected the main
thread for us.

00:15:18.196 --> 00:15:19.776 A:middle
And if I look at
this, there's a couple

00:15:19.776 --> 00:15:22.086 A:middle
of other dispatch worker
threads that are running.

00:15:22.286 --> 00:15:25.296 A:middle
And these two in particular,
this one right here

00:15:25.296 --> 00:15:27.226 A:middle
and the one below it,
are doing a lot of work.

00:15:27.876 --> 00:15:31.196 A:middle
These are all those red
dots that are showing up.

00:15:32.196 --> 00:15:36.006 A:middle
So if I option drag to zoom
in on one of those regions,

00:15:36.586 --> 00:15:38.446 A:middle
we can actually start
to see what those are

00:15:38.666 --> 00:15:39.526 A:middle
by hovering over them.

00:15:40.456 --> 00:15:43.206 A:middle
Here, this is a ulock wake
system call, so it's waking

00:15:43.206 --> 00:15:44.076 A:middle
up from some sort of lock.

00:15:44.476 --> 00:15:47.906 A:middle
Here's a ulock wait system call,
so it's waiting on some lock.

00:15:48.176 --> 00:15:49.976 A:middle
And if you keep hovering over
them, you're actually going

00:15:49.976 --> 00:15:51.166 A:middle
to see that pattern repeating.

00:15:51.166 --> 00:15:53.606 A:middle
There's a lot of this ulock
wait and waking going on.

00:15:54.336 --> 00:15:57.346 A:middle
So if you click, you'll set that
inspection head at that point.

00:15:57.826 --> 00:16:00.156 A:middle
And if you come down here
to what we call the threads

00:15:57.826 --> 00:16:00.156 A:middle
And if you come down here
to what we call the threads

00:16:00.156 --> 00:16:03.106 A:middle
and narrative view,
down here in this table,

00:16:03.496 --> 00:16:06.706 A:middle
it'll actually show you in that
table kind of where I clicked

00:16:06.706 --> 00:16:08.736 A:middle
up above, what was going on
in the thread at this time.

00:16:08.736 --> 00:16:09.926 A:middle
All right, this is a list

00:16:09.926 --> 00:16:11.956 A:middle
of everything this thread
was doing, kind of a story

00:16:11.956 --> 00:16:12.836 A:middle
of this thread's life.

00:16:13.236 --> 00:16:15.136 A:middle
So here we can see one
of those wait calls.

00:16:15.226 --> 00:16:16.956 A:middle
Okay, well where
did that happen?

00:16:17.556 --> 00:16:20.826 A:middle
Whenever possible Instruments is
going to take a backtrace along

00:16:20.826 --> 00:16:22.006 A:middle
with those system events.

00:16:22.556 --> 00:16:24.886 A:middle
And you can find those
over here on the right

00:16:25.336 --> 00:16:26.956 A:middle
in the Extended Detail View.

00:16:28.056 --> 00:16:32.816 A:middle
So we can see I have some SWIFT
code building paths and inside

00:16:32.816 --> 00:16:35.476 A:middle
of it it's actually creating
an NSAttributedString.

00:16:36.076 --> 00:16:39.196 A:middle
Okay, and down below
that a couple frames is

00:16:39.196 --> 00:16:40.236 A:middle
where it's taking that lock.

00:16:40.986 --> 00:16:43.436 A:middle
Kind of unexpected, wasn't
expecting a lock inside

00:16:43.436 --> 00:16:45.306 A:middle
of NSAttributedString,
but there it is.

00:16:45.696 --> 00:16:47.616 A:middle
So what are the ramifications
of that?

00:16:48.176 --> 00:16:50.396 A:middle
Let's go back over to the
threads narrative view

00:16:50.396 --> 00:16:51.126 A:middle
and see what happens.

00:16:51.586 --> 00:16:55.626 A:middle
So it took us 109 microseconds
just to take that lock.

00:16:55.626 --> 00:16:57.956 A:middle
And then we blocked for
another 6 microseconds.

00:16:58.476 --> 00:17:00.896 A:middle
What's really cool this
year is now it'll show you

00:16:58.476 --> 00:17:00.896 A:middle
What's really cool this
year is now it'll show you

00:17:01.116 --> 00:17:03.276 A:middle
which thread made
your thread runnable.

00:17:03.276 --> 00:17:05.516 A:middle
So basically who released that
lock so that you could take it.

00:17:05.516 --> 00:17:07.326 A:middle
And we can see that
it was made runnable

00:17:07.326 --> 00:17:12.576 A:middle
by a Graphasaurus
thread 0x8468b.

00:17:12.576 --> 00:17:16.236 A:middle
Okay. And we can see that even
after that lock was released,

00:17:16.665 --> 00:17:19.376 A:middle
we still waiting another 98
microseconds before we actually

00:17:19.376 --> 00:17:20.136 A:middle
give a CPU back.

00:17:20.606 --> 00:17:23.516 A:middle
All right, let's look at what
that other thread was doing.

00:17:23.516 --> 00:17:25.726 A:middle
Why did he release that lock?

00:17:25.726 --> 00:17:28.056 A:middle
Option click on that, choose
reveal and thread strategy.

00:17:28.836 --> 00:17:32.436 A:middle
That'll select that other thread
up above, and then down below

00:17:32.436 --> 00:17:34.826 A:middle
in the narrative view, we'll
see what thread was doing

00:17:34.826 --> 00:17:35.366 A:middle
at that time.

00:17:35.716 --> 00:17:37.776 A:middle
And we can see he was
calling ulock wake.

00:17:37.986 --> 00:17:39.396 A:middle
So he was releasing that lock.

00:17:39.806 --> 00:17:40.396 A:middle
That makes sense.

00:17:40.396 --> 00:17:43.066 A:middle
So we can kind of see that we
have these two threads running

00:17:43.066 --> 00:17:45.776 A:middle
in parallel, except they're kind
of contending over this lock.

00:17:45.956 --> 00:17:47.036 A:middle
And so they're doing a bunch

00:17:47.036 --> 00:17:49.236 A:middle
of things besides
actually just running.

00:17:49.916 --> 00:17:53.966 A:middle
Another way to see that
is up in this track view.

00:17:54.876 --> 00:17:57.466 A:middle
We have those thread
states visible here.

00:17:57.516 --> 00:17:58.556 A:middle
Let me make this a
little bit larger.

00:17:58.926 --> 00:18:00.676 A:middle
So if you hover over
the thread states,

00:17:58.926 --> 00:18:00.676 A:middle
So if you hover over
the thread states,

00:18:00.826 --> 00:18:02.436 A:middle
you'll see it was
running for this period

00:18:02.436 --> 00:18:03.566 A:middle
of time, 64 microseconds.

00:18:03.566 --> 00:18:06.046 A:middle
Then it was blocked
for a little while.

00:18:06.376 --> 00:18:08.336 A:middle
Then it was runnable
for kind of a long time,

00:18:08.336 --> 00:18:09.696 A:middle
so that means it's
not actually running.

00:18:09.696 --> 00:18:11.486 A:middle
And then finally it runs.

00:18:11.686 --> 00:18:13.276 A:middle
And if we kept digging
around, looking around,

00:18:13.276 --> 00:18:15.246 A:middle
we would see this pattern
repeating over and over again.

00:18:15.866 --> 00:18:18.616 A:middle
And so what becomes clear is
these two threads are fighting

00:18:18.616 --> 00:18:19.166 A:middle
over this lock.

00:18:19.576 --> 00:18:21.696 A:middle
And I'm creating a whole bunch
of strings during this time.

00:18:22.566 --> 00:18:24.926 A:middle
So if this is taking so much
time and is so important,

00:18:25.126 --> 00:18:27.046 A:middle
why don't I see that
in the time profiler?

00:18:27.566 --> 00:18:29.246 A:middle
Well, truth be told if
you go back and look

00:18:29.246 --> 00:18:30.666 A:middle
at the time profiler,
it does show up.

00:18:31.006 --> 00:18:32.926 A:middle
But it's only like four
or five percent or so.

00:18:32.926 --> 00:18:34.746 A:middle
It didn't really stick
out as a giant red flag.

00:18:35.146 --> 00:18:36.756 A:middle
And a big reason for that is

00:18:36.756 --> 00:18:38.646 A:middle
because these threads are
spending a lot of time

00:18:38.646 --> 00:18:40.156 A:middle
in the blocked and
runnable states.

00:18:40.156 --> 00:18:42.496 A:middle
And time profiler only
samples what's actually running

00:18:42.496 --> 00:18:45.046 A:middle
on a CPU, so it's not
going to show up there.

00:18:45.636 --> 00:18:49.116 A:middle
And so what I need to do to fix
this problem is realize, well,

00:18:49.116 --> 00:18:52.136 A:middle
I'm just putting some attributed
strings onto a state graph.

00:18:52.136 --> 00:18:54.546 A:middle
There's not that many states
that need to be displayed.

00:18:54.906 --> 00:18:56.966 A:middle
I should just cash them ahead
of time, and then look them

00:18:56.966 --> 00:18:58.116 A:middle
up in a dictionary lock free.

00:18:58.476 --> 00:19:00.566 A:middle
And everything should
run a lot more smoothly.

00:18:58.476 --> 00:19:00.566 A:middle
And everything should
run a lot more smoothly.

00:19:00.906 --> 00:19:03.106 A:middle
And to show you what that
looks like, back over to Chad.

00:19:04.516 --> 00:19:10.546 A:middle
[ Applause ]

00:19:11.046 --> 00:19:13.406 A:middle
&gt;&gt; Okay, so what Joe is
seeing is a textbook Lock

00:19:13.406 --> 00:19:14.206 A:middle
Contention pattern.

00:19:14.276 --> 00:19:16.766 A:middle
And this is where we have
two threads now working away.

00:19:16.766 --> 00:19:19.536 A:middle
And they're contending for
a shared resource somewhere

00:19:19.536 --> 00:19:21.596 A:middle
in the attributed string
lock creation code.

00:19:21.596 --> 00:19:23.876 A:middle
Now even though we're
only holding that lock

00:19:23.876 --> 00:19:25.136 A:middle
for a few microseconds,

00:19:25.166 --> 00:19:28.726 A:middle
the performance impact is much
more significant than that.

00:19:28.726 --> 00:19:29.896 A:middle
And Joe showed you
that a little bit.

00:19:29.896 --> 00:19:31.846 A:middle
But I want to talk about
it just a little bit more.

00:19:33.356 --> 00:19:35.886 A:middle
So when your thread is in
the running state that means

00:19:35.926 --> 00:19:37.506 A:middle
that the thread is on the CPU.

00:19:37.836 --> 00:19:39.136 A:middle
It's running its full stride,

00:19:39.136 --> 00:19:40.676 A:middle
and all of those
performance optimizations

00:19:40.676 --> 00:19:42.966 A:middle
that you were making with a time
profiler are now paying off.

00:19:43.306 --> 00:19:45.666 A:middle
Now at some point, you
do call into ulock wake,

00:19:45.936 --> 00:19:46.966 A:middle
and then some short period

00:19:46.966 --> 00:19:49.476 A:middle
after that it puts the
thread into the block state.

00:19:49.756 --> 00:19:53.206 A:middle
And so what's happening here is
ulock wait system call realizes

00:19:53.286 --> 00:19:56.176 A:middle
that that lock is being
held by another thread,

00:19:56.176 --> 00:19:59.196 A:middle
and so it asks the kernel
to take you off the CPU

00:19:59.496 --> 00:20:01.596 A:middle
and put you back when
that thread or --

00:19:59.496 --> 00:20:01.596 A:middle
and put you back when
that thread or --

00:20:01.596 --> 00:20:03.086 A:middle
sorry, when that lock
is actually acquired.

00:20:03.766 --> 00:20:06.446 A:middle
Now 3.42 microseconds
later that does happen.

00:20:06.496 --> 00:20:07.826 A:middle
We do go into the
runnable state.

00:20:08.666 --> 00:20:10.026 A:middle
But now when we're in
the runnable state,

00:20:10.096 --> 00:20:11.366 A:middle
this is the amount
of time it takes us

00:20:11.366 --> 00:20:13.006 A:middle
to get back onto the CPU.

00:20:13.786 --> 00:20:15.306 A:middle
Now if you'll notice we're
in the runnable state

00:20:15.306 --> 00:20:16.566 A:middle
for about 7 microseconds.

00:20:16.566 --> 00:20:18.776 A:middle
That's nearly twice
the amount of time

00:20:18.776 --> 00:20:20.506 A:middle
that that lock was
actually contended.

00:20:20.736 --> 00:20:22.406 A:middle
So we're getting a
significant amount of overhead.

00:20:23.196 --> 00:20:25.806 A:middle
Now another way to look at this
quantitatively is you can go

00:20:25.806 --> 00:20:28.116 A:middle
into the thread strategy,
select the thread,

00:20:28.546 --> 00:20:30.926 A:middle
create a time filter selection
the way that Joe showed you,

00:20:31.466 --> 00:20:33.966 A:middle
and then change the detail
section from the narrative

00:20:33.966 --> 00:20:35.136 A:middle
over here to the thread summary.

00:20:35.136 --> 00:20:38.636 A:middle
And what that will show you
is the total time spent per

00:20:38.636 --> 00:20:39.306 A:middle
thread state.

00:20:39.446 --> 00:20:41.016 A:middle
In this particular example,

00:20:41.016 --> 00:20:42.686 A:middle
we can see that our
thread was only running

00:20:42.686 --> 00:20:44.236 A:middle
about 82 percent of the time.

00:20:45.136 --> 00:20:46.106 A:middle
Now what that means is

00:20:46.106 --> 00:20:48.196 A:middle
that we're still getting some
benefit from the multicore.

00:20:48.196 --> 00:20:50.646 A:middle
We are getting some work
done, but our scaling is not

00:20:50.646 --> 00:20:53.846 A:middle
that linear scaling, perfect
scaling that we were hoping for.

00:20:54.176 --> 00:20:56.226 A:middle
We are still wasting
a little bit of time.

00:20:56.946 --> 00:21:00.736 A:middle
Now when Joe makes the fix
that he was talking about,

00:20:56.946 --> 00:21:00.736 A:middle
Now when Joe makes the fix
that he was talking about,

00:21:00.736 --> 00:21:02.316 A:middle
what's going to happen -- well,
two things are going to happen.

00:21:02.316 --> 00:21:05.216 A:middle
The first one is that the update
graph regions, they're going

00:21:05.216 --> 00:21:07.366 A:middle
to get a little shorter
because we are doing less work

00:21:07.366 --> 00:21:08.816 A:middle
when we're caching
these strings.

00:21:09.286 --> 00:21:10.106 A:middle
But more importantly,

00:21:10.426 --> 00:21:12.716 A:middle
that thread is no running a
hundred percent of the time.

00:21:12.996 --> 00:21:14.746 A:middle
So you're going to get
that perfect scalability.

00:21:14.866 --> 00:21:16.946 A:middle
So if you add a -- so if you
double the number of CPUs,

00:21:16.946 --> 00:21:18.976 A:middle
you're going to half the amount
of time that that code takes.

00:21:18.976 --> 00:21:19.766 A:middle
And that's great.

00:21:20.106 --> 00:21:21.806 A:middle
So if you have a fix like that,

00:21:21.806 --> 00:21:23.006 A:middle
you should definitely
try to take it.

00:21:24.516 --> 00:21:25.656 A:middle
Now let's talk about preemption.

00:21:25.656 --> 00:21:28.386 A:middle
We didn't get to see any
preemption in our examples here,

00:21:28.386 --> 00:21:30.216 A:middle
it is something that shows

00:21:30.216 --> 00:21:31.786 A:middle
up quite frequently
in a system trace.

00:21:32.436 --> 00:21:35.306 A:middle
And what preemption is is
an involuntary removable

00:21:35.306 --> 00:21:37.586 A:middle
of your thread from the CPU.

00:21:38.926 --> 00:21:42.076 A:middle
So some other higher
priority work was needed --

00:21:42.076 --> 00:21:42.996 A:middle
needed the CPUs.

00:21:42.996 --> 00:21:43.916 A:middle
There were none available,

00:21:44.256 --> 00:21:45.716 A:middle
and so your thread
had to be removed.

00:21:46.476 --> 00:21:48.146 A:middle
Now there's an exception
to that.

00:21:48.146 --> 00:21:49.906 A:middle
There is a voluntary
form of preemption

00:21:49.906 --> 00:21:51.276 A:middle
that you might see
from time to time.

00:21:51.716 --> 00:21:53.336 A:middle
And that occurs inside
of a spin lock.

00:21:53.506 --> 00:21:55.776 A:middle
When a spin lock realizes it's
not making any more forward

00:21:55.776 --> 00:21:58.566 A:middle
progress, it can call into
the thread switch system call

00:21:59.186 --> 00:22:01.156 A:middle
and essentially yield
its quantum of time

00:21:59.186 --> 00:22:01.156 A:middle
and essentially yield
its quantum of time

00:22:01.156 --> 00:22:02.436 A:middle
over the holder of the lock.

00:22:03.496 --> 00:22:05.686 A:middle
And so what that looks
like in system trace

00:22:05.686 --> 00:22:07.516 A:middle
in the thread narrative
is you'll see it called a

00:22:07.516 --> 00:22:08.346 A:middle
thread switch.

00:22:08.756 --> 00:22:11.666 A:middle
And then the preemption
narrative after it will say

00:22:11.666 --> 00:22:13.706 A:middle
that it was yielding
the CPU rather

00:22:13.706 --> 00:22:15.996 A:middle
than being I think
removed from the CPU.

00:22:16.206 --> 00:22:19.286 A:middle
So another lighter weight form

00:22:19.286 --> 00:22:21.556 A:middle
of preemption is called
the interrupted state.

00:22:21.556 --> 00:22:23.946 A:middle
And the interrupted state is
when your thread is running

00:22:23.946 --> 00:22:28.526 A:middle
on a CPU and that CPU has to
handle a hardware interrupt.

00:22:28.986 --> 00:22:30.346 A:middle
So your thread is suspended.

00:22:30.506 --> 00:22:32.906 A:middle
The interrupt handler runs, and
then your thread is resumed.

00:22:33.186 --> 00:22:35.536 A:middle
Now at this point, the priority
of your thread doesn't matter.

00:22:35.536 --> 00:22:36.686 A:middle
You can have the
highest priority.

00:22:36.686 --> 00:22:37.846 A:middle
It really won't matter.

00:22:38.186 --> 00:22:40.446 A:middle
The interrupt will
always take precedence.

00:22:40.446 --> 00:22:43.116 A:middle
Now the good news is that
these are typically brief,

00:22:43.116 --> 00:22:44.246 A:middle
a couple of microseconds.

00:22:44.246 --> 00:22:46.976 A:middle
And typically they won't add
up to contribute to any sort

00:22:46.976 --> 00:22:48.706 A:middle
of performance problem
inside your application.

00:22:48.946 --> 00:22:51.636 A:middle
But they do show up, so that's
why I wanted to present them.

00:22:51.946 --> 00:22:52.876 A:middle
Now another nice feature

00:22:52.876 --> 00:22:55.836 A:middle
of Instruments 8 is called a
new System Load instrument.

00:22:55.836 --> 00:23:00.086 A:middle
And what that instrument does
is helps you identify hotspots

00:22:55.836 --> 00:23:00.086 A:middle
And what that instrument does
is helps you identify hotspots

00:23:00.466 --> 00:23:02.226 A:middle
in your system trace that
could be contributing

00:23:02.226 --> 00:23:04.276 A:middle
to dropped frames, for example.

00:23:04.526 --> 00:23:06.026 A:middle
Now it does that in two ways.

00:23:06.026 --> 00:23:07.856 A:middle
The first way is this
bottom table view.

00:23:07.856 --> 00:23:10.136 A:middle
And this shows you a picture

00:23:10.266 --> 00:23:12.466 A:middle
of what the scheduling
state look like.

00:23:12.466 --> 00:23:13.536 A:middle
All of the threads
that were ready

00:23:13.536 --> 00:23:16.376 A:middle
to run underneath the
blue inspection line.

00:23:17.516 --> 00:23:19.076 A:middle
So you can tell that
at that moment

00:23:19.076 --> 00:23:20.646 A:middle
in time, we had three threads.

00:23:20.736 --> 00:23:23.106 A:middle
One was a kernel thread and
two are a Graphasaurus threads.

00:23:23.106 --> 00:23:23.976 A:middle
And these are the threads

00:23:23.976 --> 00:23:25.856 A:middle
that were not blocked
and trying to run.

00:23:26.156 --> 00:23:28.426 A:middle
You can see the core
assignments for those as well.

00:23:28.736 --> 00:23:32.086 A:middle
Now the other feature of this
instrument is called the User

00:23:32.086 --> 00:23:33.676 A:middle
Interactive Load Average graph.

00:23:34.396 --> 00:23:35.376 A:middle
And what this is is a --

00:23:35.376 --> 00:23:38.116 A:middle
each one of these bars
represents a 10 millisecond

00:23:38.116 --> 00:23:38.796 A:middle
window of time.

00:23:38.796 --> 00:23:42.686 A:middle
And the height of the bar is the
average number of active threads

00:23:42.846 --> 00:23:44.146 A:middle
in that 10 millisecond period.

00:23:44.546 --> 00:23:47.376 A:middle
So that's threads that are
either running, runnable,

00:23:47.666 --> 00:23:48.956 A:middle
preempted, or interrupted.

00:23:49.206 --> 00:23:50.456 A:middle
Essentially threads
that are not blocked.

00:23:51.346 --> 00:23:53.786 A:middle
Now since it's the User
Interactive Load Average,

00:23:53.786 --> 00:23:56.366 A:middle
we only include threads that
have a priority greater to

00:23:56.366 --> 00:23:58.996 A:middle
or equal to 33 because
those are the --

00:23:58.996 --> 00:24:01.466 A:middle
those are the threads with a
priority that could interfere

00:23:58.996 --> 00:24:01.466 A:middle
those are the threads with a
priority that could interfere

00:24:01.826 --> 00:24:03.956 A:middle
with the user interactive
quality of service class.

00:24:04.826 --> 00:24:06.586 A:middle
Now to make it stand out
a little bit more clearly,

00:24:06.876 --> 00:24:08.806 A:middle
when the thread bars
turn orange that means

00:24:08.806 --> 00:24:11.486 A:middle
that your load average has
exceeded the number of cores

00:24:11.486 --> 00:24:12.736 A:middle
on that particular device.

00:24:12.946 --> 00:24:15.176 A:middle
So wherever you see
a burst of orange,

00:24:15.436 --> 00:24:17.886 A:middle
you can see that that's a
frame drop waiting to happen.

00:24:17.886 --> 00:24:21.406 A:middle
So you might want to zoom in
to those particular regions

00:24:21.406 --> 00:24:23.226 A:middle
that are orange, make
sure that the threads

00:24:23.226 --> 00:24:24.726 A:middle
that you have running
are balanced

00:24:24.726 --> 00:24:26.086 A:middle
at the right quality
of service level.

00:24:28.046 --> 00:24:29.886 A:middle
Now when Joe makes this
fix we're going to end

00:24:29.886 --> 00:24:30.736 A:middle
up with a little
bit more head room.

00:24:30.736 --> 00:24:32.226 A:middle
We're going to be able
to add a new feature.

00:24:32.306 --> 00:24:35.136 A:middle
And that new feature are these
hover labels, very similar

00:24:35.136 --> 00:24:36.766 A:middle
to the hover labels that
you see in Instruments,

00:24:37.066 --> 00:24:39.176 A:middle
except on Graphasaurus
you do a long press.

00:24:39.176 --> 00:24:41.156 A:middle
And then the hover labels
follow your fingertip.

00:24:41.696 --> 00:24:42.776 A:middle
So to show how that
feature is going,

00:24:42.776 --> 00:24:44.476 A:middle
I'm going to turn
it back over to Joe.

00:24:45.516 --> 00:24:49.646 A:middle
[ Applause ]

00:24:50.146 --> 00:24:50.736 A:middle
&gt;&gt; Thanks, Chad.

00:24:51.216 --> 00:24:53.626 A:middle
So yeah, so I added the
NSAttributedString fix,

00:24:53.626 --> 00:24:55.406 A:middle
went back to 60 frames
per second looked good,

00:24:55.936 --> 00:24:58.086 A:middle
added the new generation
of tool tips work,

00:24:58.086 --> 00:24:59.626 A:middle
and things got slow again.

00:24:59.626 --> 00:25:02.166 A:middle
You can kind of tell there's a
couple frames here dropping here

00:24:59.626 --> 00:25:02.166 A:middle
You can kind of tell there's a
couple frames here dropping here

00:25:02.166 --> 00:25:02.456 A:middle
and there.

00:25:02.676 --> 00:25:03.916 A:middle
So looked in at time profiler,

00:25:04.346 --> 00:25:06.106 A:middle
wasn't anything obvious
that I could remove.

00:25:06.106 --> 00:25:07.676 A:middle
There wasn't any extra
work I was doing.

00:25:08.026 --> 00:25:09.516 A:middle
So I went back and
took the system trace

00:25:09.516 --> 00:25:10.386 A:middle
that you're looking at here.

00:25:11.156 --> 00:25:12.816 A:middle
Before I took that
trace, I went ahead

00:25:12.816 --> 00:25:15.276 A:middle
and added a new Signpost code,
number 3, and that's going

00:25:15.306 --> 00:25:16.826 A:middle
to represent my GenToolTips
work.

00:25:16.826 --> 00:25:19.036 A:middle
And you'll see that
show up in red up above.

00:25:19.846 --> 00:25:23.376 A:middle
So let's zoom in on one
of these sections here.

00:25:26.436 --> 00:25:30.836 A:middle
All right, so we can see
here's my new red bars,

00:25:30.836 --> 00:25:31.956 A:middle
these GenToolTips.

00:25:32.346 --> 00:25:33.366 A:middle
And so it's important
for me to kind

00:25:33.366 --> 00:25:35.126 A:middle
of describe how my
algorithm works here.

00:25:35.526 --> 00:25:38.106 A:middle
Basically whenever this
CADisplayLink region starts,

00:25:38.376 --> 00:25:39.906 A:middle
for every single
graph on the scene,

00:25:39.956 --> 00:25:42.506 A:middle
I go and do a dispatch
async of all the render work

00:25:42.806 --> 00:25:44.526 A:middle
for that graph and
I dispatch async

00:25:44.526 --> 00:25:47.056 A:middle
to go generate the tool tip
dictionary, look up stuff.

00:25:47.916 --> 00:25:50.396 A:middle
And I do that for every
single graph on the scene.

00:25:50.846 --> 00:25:54.306 A:middle
But then I had kind of a clever
realization that in order

00:25:54.306 --> 00:25:56.896 A:middle
to kind of call my rendering
complete, I don't actually need

00:25:56.896 --> 00:25:59.066 A:middle
to wait for the tool
tip stuff to finish.

00:25:59.376 --> 00:26:02.416 A:middle
And so I do a dispatch group
wait on just the render work.

00:25:59.376 --> 00:26:02.416 A:middle
And so I do a dispatch group
wait on just the render work.

00:26:02.756 --> 00:26:05.086 A:middle
And we can see that actually
kind of worked here pretty well.

00:26:05.206 --> 00:26:06.426 A:middle
Here's my start of my frame.

00:26:06.426 --> 00:26:07.596 A:middle
The CADisplayLink time.

00:26:07.596 --> 00:26:10.196 A:middle
We can see some of those
tooltips working here.

00:26:10.486 --> 00:26:11.736 A:middle
Let me scroll over to the right.

00:26:11.736 --> 00:26:13.006 A:middle
You can see actually
one of them here.

00:26:13.006 --> 00:26:14.466 A:middle
Actually, barely
doesn't even start

00:26:14.466 --> 00:26:15.816 A:middle
until my render frame is done.

00:26:15.816 --> 00:26:17.006 A:middle
So it looks like
I did a good job.

00:26:17.006 --> 00:26:18.276 A:middle
I can give myself
a pat on the back.

00:26:18.276 --> 00:26:19.146 A:middle
That looks nice.

00:26:19.676 --> 00:26:24.226 A:middle
However, when I look at my
CADisplayLink time here,

00:26:25.366 --> 00:26:28.526 A:middle
it's taking 17.4 milliseconds.

00:26:28.606 --> 00:26:31.716 A:middle
Pretty close, but it's
not my 16.6 that I want.

00:26:32.386 --> 00:26:34.506 A:middle
So again, that was just
one of the regions.

00:26:34.506 --> 00:26:36.896 A:middle
Let's look at what we
were doing in aggregate.

00:26:37.196 --> 00:26:39.826 A:middle
Let's go back to that KDebug
Interval Signpost by Code table.

00:26:40.596 --> 00:26:42.646 A:middle
Here we can see our
CADisplayLinks.

00:26:42.646 --> 00:26:44.276 A:middle
I did about 260.

00:26:44.276 --> 00:26:47.276 A:middle
That's more than we did the
last time, so that sounds good.

00:26:47.746 --> 00:26:49.856 A:middle
Sixteen milliseconds on average.

00:26:49.856 --> 00:26:51.696 A:middle
That's actually less
than my 16.6.

00:26:51.696 --> 00:26:53.466 A:middle
So that actually
sounds pretty decent.

00:26:53.866 --> 00:26:57.106 A:middle
However, this max is still
sitting here at about 19.27.

00:26:57.676 --> 00:26:59.936 A:middle
And if we look at all
the individual events,

00:27:01.406 --> 00:27:03.946 A:middle
let's sort this by duration
from longest to shortest,

00:27:04.396 --> 00:27:06.046 A:middle
we can see here's
that one at 19.

00:27:06.166 --> 00:27:07.876 A:middle
There's a bunch in the 18s.

00:27:07.876 --> 00:27:09.766 A:middle
There's some here in the 17s.

00:27:09.766 --> 00:27:10.996 A:middle
A lot in the 17s.

00:27:10.996 --> 00:27:12.076 A:middle
More in these upper 16s.

00:27:12.326 --> 00:27:13.586 A:middle
So we still have
a number of frames

00:27:13.586 --> 00:27:15.076 A:middle
that are actually
rendering too slowly.

00:27:15.486 --> 00:27:17.686 A:middle
Not by much, but
they're still too slow.

00:27:17.686 --> 00:27:19.246 A:middle
That means we're going
to be dropping frames.

00:27:20.086 --> 00:27:22.106 A:middle
So this time, where
do we go from here?

00:27:22.106 --> 00:27:25.556 A:middle
We could go back to diving down
into the thread strategy looking

00:27:25.556 --> 00:27:27.926 A:middle
at all our threads and the
system calls and VM events

00:27:27.926 --> 00:27:29.416 A:middle
and thread events and
all sorts of things.

00:27:29.916 --> 00:27:34.256 A:middle
But whenever possible, well
this system trace template has a

00:27:34.256 --> 00:27:36.926 A:middle
bunch of instruments up here,
and they kind of give you sort

00:27:36.926 --> 00:27:39.296 A:middle
of like higher level aggregate
information that's kind

00:27:39.296 --> 00:27:41.056 A:middle
of useful to look at that first.

00:27:41.056 --> 00:27:44.066 A:middle
So before you go diving down
into the 100,000 plus events,

00:27:44.066 --> 00:27:46.396 A:middle
take a look at these
higher level aggregates.

00:27:46.776 --> 00:27:49.106 A:middle
And so what I'm going to
do is let's take a look

00:27:49.106 --> 00:27:50.666 A:middle
at this User Interactive
Load graph.

00:27:50.666 --> 00:27:52.376 A:middle
That's part of that
System Load instrument.

00:27:53.796 --> 00:27:57.826 A:middle
And let's go ahead and zoom
out here to snap track to fit,

00:27:57.826 --> 00:28:00.026 A:middle
so we can see all the data
again back on the screen.

00:27:57.826 --> 00:28:00.026 A:middle
so we can see all the data
again back on the screen.

00:28:01.016 --> 00:28:04.206 A:middle
And when we've done that, I'm
going to zoom in over here.

00:28:05.136 --> 00:28:07.836 A:middle
You can see there's a fair
bit of orange in this graph.

00:28:08.016 --> 00:28:08.946 A:middle
Make this a little bit larger.

00:28:08.946 --> 00:28:11.826 A:middle
So you can see there's a
fair bit of orange up there,

00:28:11.826 --> 00:28:14.586 A:middle
which means we have more user
interactive threads running

00:28:14.586 --> 00:28:15.406 A:middle
than we have cores, right.

00:28:15.406 --> 00:28:17.046 A:middle
These are threads that are
saying, I have a lot of work

00:28:17.046 --> 00:28:20.226 A:middle
to do, and I need to do it now.

00:28:20.336 --> 00:28:21.476 A:middle
Give me a CPU.

00:28:21.476 --> 00:28:22.866 A:middle
Well, we're running out of CPUs

00:28:22.866 --> 00:28:25.356 A:middle
and that's why our
graph here is orange.

00:28:25.356 --> 00:28:27.976 A:middle
So let's zoom on one
of these large regions

00:28:28.016 --> 00:28:29.036 A:middle
of orange over here.

00:28:29.946 --> 00:28:32.536 A:middle
You can tell what the value is
just by hovering over a region.

00:28:33.406 --> 00:28:34.236 A:middle
Zoom in a little bit.

00:28:34.716 --> 00:28:37.486 A:middle
So we can see this particular
10 millisecond bucket,

00:28:37.486 --> 00:28:40.146 A:middle
on average there's about
2.84 user interactive threads

00:28:40.146 --> 00:28:42.766 A:middle
that we're trying to run,
again, on a dual-core machine,

00:28:42.766 --> 00:28:46.186 A:middle
so about .8 threads
are lacking CPU time.

00:28:46.516 --> 00:28:47.606 A:middle
And that's why that's orange.

00:28:47.986 --> 00:28:50.016 A:middle
And we can see on
average, there's a lot

00:28:50.016 --> 00:28:52.146 A:middle
of regions here that
are too big.

00:28:52.146 --> 00:28:53.046 A:middle
Here actually it's four.

00:28:53.046 --> 00:28:55.886 A:middle
We were trying to run twice as
many threads as we have cores.

00:28:56.276 --> 00:28:58.436 A:middle
So let's look at that
region in more detail.

00:28:58.436 --> 00:29:01.546 A:middle
So let me scooch this
over so you can see this.

00:28:58.436 --> 00:29:01.546 A:middle
So let me scooch this
over so you can see this.

00:29:02.216 --> 00:29:05.346 A:middle
As Chad mentioned, you can see
what threads you're actually

00:29:05.346 --> 00:29:08.216 A:middle
trying to run in that
period by click and holding

00:29:08.216 --> 00:29:10.256 A:middle
in the ruler view up
here, and you can move

00:29:10.256 --> 00:29:11.676 A:middle
that blue inspection
head back and forth

00:29:11.676 --> 00:29:14.326 A:middle
and Instruments will tell you
which threads we're trying

00:29:14.326 --> 00:29:16.976 A:middle
to run during that
instant of time.

00:29:17.606 --> 00:29:19.756 A:middle
And if we come down
and look at this table,

00:29:19.756 --> 00:29:20.996 A:middle
I'll sort it by the priority.

00:29:21.546 --> 00:29:23.276 A:middle
We can see, I looked right here

00:29:23.276 --> 00:29:27.786 A:middle
and there are two Graphasaurus
threads that are running, cool.

00:29:28.016 --> 00:29:30.646 A:middle
There's actually two location D
threads that are trying to run

00:29:30.646 --> 00:29:31.906 A:middle
at a slightly lower priority.

00:29:32.206 --> 00:29:33.866 A:middle
And that's part of
being on a real system.

00:29:33.866 --> 00:29:35.386 A:middle
You're going to see
system daemons coming in

00:29:35.386 --> 00:29:36.436 A:middle
and trying to do their work.

00:29:36.706 --> 00:29:37.566 A:middle
But it's okay.

00:29:37.566 --> 00:29:39.386 A:middle
They're running on a slightly
lower priority than my stuff,

00:29:39.386 --> 00:29:40.886 A:middle
so I still have the
CPU, looks good.

00:29:41.396 --> 00:29:44.156 A:middle
I do, however, have this
third thread that's running

00:29:44.156 --> 00:29:47.066 A:middle
at the same time, well, trying
to run at the same time.

00:29:47.066 --> 00:29:48.886 A:middle
And he's not getting
any CPU resources.

00:29:49.846 --> 00:29:51.816 A:middle
And I know what these
threads are.

00:29:51.936 --> 00:29:53.506 A:middle
The two of them are
my render work.

00:29:53.506 --> 00:29:54.836 A:middle
And then I have the third
thread that's trying

00:29:54.836 --> 00:29:56.346 A:middle
to do my generation
of tool tips.

00:29:56.816 --> 00:29:58.566 A:middle
And so what's happening is one

00:29:58.566 --> 00:30:00.136 A:middle
of them is not able
to get a CPU.

00:29:58.566 --> 00:30:00.136 A:middle
of them is not able
to get a CPU.

00:30:01.156 --> 00:30:02.906 A:middle
And we can kind of
see this again.

00:30:02.906 --> 00:30:04.606 A:middle
If we look at, say,
one of our frames.

00:30:04.796 --> 00:30:06.846 A:middle
Let's go back up to that
Points of Interest Region.

00:30:06.846 --> 00:30:08.686 A:middle
You know, we could see

00:30:08.686 --> 00:30:11.196 A:middle
that we're doing our rendering
here inside of our frame,

00:30:11.396 --> 00:30:12.826 A:middle
and the generation
of tool tips happen,

00:30:12.826 --> 00:30:15.026 A:middle
so it gets a little
bit of CPU time here.

00:30:15.426 --> 00:30:18.276 A:middle
But what it's doing is when
it does get that CPU time,

00:30:18.276 --> 00:30:19.646 A:middle
it's taking away
from my rendering.

00:30:20.236 --> 00:30:23.116 A:middle
And so basically I've kind
of misprioritized my work

00:30:23.116 --> 00:30:25.746 A:middle
because when I stop and
think about it, well,

00:30:25.746 --> 00:30:27.496 A:middle
I need that rendering
to happen right now.

00:30:27.706 --> 00:30:29.886 A:middle
Being at that user interactive
level makes perfect sense

00:30:29.886 --> 00:30:32.476 A:middle
because I want it to be nice and
smooth and 60 frames per second.

00:30:33.106 --> 00:30:35.886 A:middle
But these tool tips, they're
not quite as high priority.

00:30:35.886 --> 00:30:37.716 A:middle
I do want them done
quickly because as soon

00:30:37.716 --> 00:30:39.166 A:middle
as that user long
presses on that screen,

00:30:39.166 --> 00:30:39.986 A:middle
I want them to show up.

00:30:40.686 --> 00:30:42.896 A:middle
But they're not really as
important as that render work.

00:30:43.076 --> 00:30:44.536 A:middle
And you can see it
pretty clearly here.

00:30:44.536 --> 00:30:46.726 A:middle
They are definitely taking
away some of that time

00:30:46.726 --> 00:30:49.746 A:middle
that CPU resources from
this render work that's now

00:30:49.746 --> 00:30:50.386 A:middle
being delayed.

00:30:50.386 --> 00:30:51.806 A:middle
And that's what's
helping kind of drag

00:30:51.806 --> 00:30:53.276 A:middle
out that CADisplayLink time.

00:30:54.126 --> 00:30:57.546 A:middle
So the fix for that is
actually simple in this case.

00:30:57.606 --> 00:30:58.706 A:middle
Let's go over to Xcode.

00:30:59.036 --> 00:31:00.646 A:middle
So I have this view
controller class.

00:30:59.036 --> 00:31:00.646 A:middle
So I have this view
controller class.

00:31:00.696 --> 00:31:03.006 A:middle
And one of the things it does
is it creates a tool tip queue.

00:31:03.526 --> 00:31:05.766 A:middle
We can see that created
right down here.

00:31:05.766 --> 00:31:08.046 A:middle
This is where I do
all my tool tip work.

00:31:08.426 --> 00:31:10.046 A:middle
And it's created with
a couple attributes.

00:31:10.046 --> 00:31:11.796 A:middle
One is, you know, it's
concurrent, so good,

00:31:11.796 --> 00:31:13.786 A:middle
they can run on multiple
CPUs if they're available.

00:31:14.256 --> 00:31:16.726 A:middle
And it's set for the user
interactive QOS class.

00:31:16.726 --> 00:31:19.096 A:middle
And that's that same QOS class

00:31:19.096 --> 00:31:20.286 A:middle
that my render work
is happening,

00:31:20.286 --> 00:31:21.926 A:middle
so they're all contending
for resources.

00:31:22.476 --> 00:31:25.176 A:middle
So like we said, it's not
actually as important,

00:31:25.176 --> 00:31:26.556 A:middle
so I'm going to change
that class.

00:31:27.016 --> 00:31:28.466 A:middle
You can read about the
different classes right

00:31:28.466 --> 00:31:29.056 A:middle
in the header file.

00:31:29.056 --> 00:31:31.826 A:middle
I'm going to take it a
couple of notches down and go

00:31:31.826 --> 00:31:33.606 A:middle
with the utility level class.

00:31:33.866 --> 00:31:36.296 A:middle
And what that'll do is give
that CPU prioritization

00:31:36.296 --> 00:31:38.856 A:middle
to do my rendering work, and
then when there is a little bit

00:31:38.856 --> 00:31:40.936 A:middle
of CPU time at the end
of the frame or whenever,

00:31:41.226 --> 00:31:42.466 A:middle
then the tool tips will run.

00:31:42.516 --> 00:31:44.086 A:middle
And they're still at a high
enough priority that when

00:31:44.086 --> 00:31:46.486 A:middle
that user taps on the screen,
they should be ready to go.

00:31:47.056 --> 00:31:49.196 A:middle
And so to show you what that
looks like, back over to Chad.

00:31:50.516 --> 00:31:55.866 A:middle
[ Applause ]

00:31:56.366 --> 00:31:58.256 A:middle
&gt;&gt; Okay, so when
Joe makes that fix,

00:31:58.256 --> 00:31:59.646 A:middle
the graph's going
to look like this.

00:31:59.646 --> 00:32:02.696 A:middle
We're going to notice that our
CADisplayLink times have come

00:31:59.646 --> 00:32:02.696 A:middle
We're going to notice that our
CADisplayLink times have come

00:32:02.696 --> 00:32:05.526 A:middle
down to about 12.7
milliseconds on average,

00:32:05.626 --> 00:32:06.726 A:middle
which is much better
than before.

00:32:07.246 --> 00:32:10.206 A:middle
But even better still is
that our max duration is only

00:32:10.206 --> 00:32:12.956 A:middle
about 14.6 milliseconds.

00:32:13.296 --> 00:32:15.406 A:middle
So we're not dropping any
frames, and we're well

00:32:15.406 --> 00:32:17.806 A:middle
within our 16 millisecond
deadline.

00:32:18.806 --> 00:32:22.386 A:middle
Now we're doing that in
spite of also continuing

00:32:22.386 --> 00:32:23.326 A:middle
to overload the system.

00:32:23.326 --> 00:32:24.166 A:middle
If you think about it,

00:32:24.406 --> 00:32:26.646 A:middle
we are still running
three different threads.

00:32:27.246 --> 00:32:29.656 A:middle
But because we've correctly
prioritized the work,

00:32:29.656 --> 00:32:31.966 A:middle
our Gen Tool Tips
code is running

00:32:31.966 --> 00:32:33.226 A:middle
down here at priority four.

00:32:33.226 --> 00:32:34.986 A:middle
So that's going to
stay out of the way

00:32:34.986 --> 00:32:36.696 A:middle
of the User Interactive code.

00:32:37.106 --> 00:32:39.936 A:middle
So we're still getting a
lot of work done on the CPU.

00:32:39.936 --> 00:32:41.946 A:middle
We still have a very
high system load.

00:32:42.366 --> 00:32:43.966 A:middle
But at the same time,

00:32:43.966 --> 00:32:46.886 A:middle
we're still getting a perfectly
smooth user experience.

00:32:48.296 --> 00:32:49.956 A:middle
So what is Quality
of Service, really?

00:32:50.006 --> 00:32:52.286 A:middle
Quality of Service, in case
you hadn't seen it yet,

00:32:52.286 --> 00:32:56.106 A:middle
is an attribute that you attach
to blocks, queues, and threads.

00:32:56.486 --> 00:32:59.826 A:middle
And it's basically an expression
to the kernel about how much

00:32:59.826 --> 00:33:02.336 A:middle
of the system resources you're
willing to devote to getting

00:32:59.826 --> 00:33:02.336 A:middle
of the system resources you're
willing to devote to getting

00:33:02.336 --> 00:33:04.476 A:middle
that particular piece
of work done quickly.

00:33:04.976 --> 00:33:06.256 A:middle
Now the different Quality

00:33:06.256 --> 00:33:09.606 A:middle
of Service classes can
constrain the priority range.

00:33:09.606 --> 00:33:12.016 A:middle
So you can see that our
utility classes put it

00:33:12.016 --> 00:33:13.236 A:middle
down into a priority of four,

00:33:13.236 --> 00:33:15.306 A:middle
so in our User Interactive
code is running

00:33:15.306 --> 00:33:16.756 A:middle
in the high 30s, high 40s.

00:33:17.546 --> 00:33:20.796 A:middle
But the Quality of Service
classes can also throttle things

00:33:20.796 --> 00:33:23.136 A:middle
like IO and also
the CPU frequency

00:33:23.136 --> 00:33:24.266 A:middle
that the code is running at.

00:33:24.956 --> 00:33:27.196 A:middle
So when you pick a Quality
of Service for your code,

00:33:27.456 --> 00:33:29.586 A:middle
make sure that you look through
the documentation very carefully

00:33:29.586 --> 00:33:31.416 A:middle
and make sure that
it matches the kind

00:33:31.416 --> 00:33:32.336 A:middle
of work that you're doing.

00:33:33.326 --> 00:33:35.446 A:middle
Now another thing that
can affect the performance

00:33:35.446 --> 00:33:37.516 A:middle
of your application is
virtual memory faults.

00:33:37.756 --> 00:33:40.816 A:middle
They do get a little
worse under load

00:33:40.816 --> 00:33:42.286 A:middle
as memory pressure increases.

00:33:42.766 --> 00:33:44.776 A:middle
But the good news is
they are manageable.

00:33:46.006 --> 00:33:48.686 A:middle
Now System Trace has all the
tools that you need in order

00:33:48.686 --> 00:33:50.126 A:middle
to analyze virtual
memory faults.

00:33:50.426 --> 00:33:53.016 A:middle
Inside the thread strategy,
virtual memory faults appear

00:33:53.016 --> 00:33:54.276 A:middle
as these little blue capsules.

00:33:54.836 --> 00:33:58.126 A:middle
Inside the thread narrative it
reports virtual memory faults

00:33:58.126 --> 00:34:00.106 A:middle
and even attaches a
backtrace on where

00:33:58.126 --> 00:34:00.106 A:middle
and even attaches a
backtrace on where

00:34:00.106 --> 00:34:02.116 A:middle
that fault was resolved
inside your code.

00:34:02.676 --> 00:34:05.716 A:middle
Now we also have an
instrument that's dedicated

00:34:05.716 --> 00:34:07.486 A:middle
to analyzing virtual
memory faults.

00:34:07.486 --> 00:34:09.356 A:middle
So for example, you can see

00:34:09.686 --> 00:34:11.676 A:middle
where your code is
more susceptible

00:34:11.676 --> 00:34:13.795 A:middle
to one type of fault or another.

00:34:13.795 --> 00:34:15.376 A:middle
So for example, maybe
you have code

00:34:15.755 --> 00:34:19.315 A:middle
that is experiencing more zero
fills or more copy on writes.

00:34:19.746 --> 00:34:21.956 A:middle
Now the next thing
you need to know

00:34:21.956 --> 00:34:24.525 A:middle
about virtual memory faults
is that the fault occurs

00:34:24.525 --> 00:34:26.876 A:middle
on access rather
than allocation.

00:34:27.226 --> 00:34:29.856 A:middle
So you can ask for a large
allocation from the kernel,

00:34:29.856 --> 00:34:33.266 A:middle
let's say 500 meg, but
you don't actually back

00:34:33.466 --> 00:34:35.335 A:middle
that with physical memory
until you start touching

00:34:35.335 --> 00:34:38.326 A:middle
or accessing the pages of that
allocation in your process.

00:34:38.326 --> 00:34:41.436 A:middle
So it's something to think about
when you're allocating memory.

00:34:41.545 --> 00:34:44.806 A:middle
The other thing that's
important to know

00:34:44.806 --> 00:34:47.255 A:middle
about virtual memory faults is
that they are resolved inline.

00:34:47.596 --> 00:34:49.505 A:middle
So there's no explicit
call that you need to make

00:34:49.505 --> 00:34:51.815 A:middle
to resolve a virtual
memory fault.

00:34:52.295 --> 00:34:55.966 A:middle
All you need to do is touch any
byte inside a page that's marked

00:34:56.266 --> 00:34:59.396 A:middle
as requiring a fault, and
the kernel will take control

00:34:59.396 --> 00:35:01.766 A:middle
of your thread, resolve
the fault,

00:34:59.396 --> 00:35:01.766 A:middle
of your thread, resolve
the fault,

00:35:01.806 --> 00:35:03.426 A:middle
and then give you control back.

00:35:03.706 --> 00:35:06.546 A:middle
And so when you see those blue
capsules in your System Trace

00:35:06.586 --> 00:35:08.816 A:middle
on the thread strategy that's
exactly what's happening.

00:35:09.206 --> 00:35:12.776 A:middle
So what do you do about
virtual memory faults inside

00:35:12.776 --> 00:35:13.386 A:middle
your application?

00:35:14.566 --> 00:35:16.336 A:middle
Well the easiest thing
to do -- excuse me.

00:35:16.896 --> 00:35:19.426 A:middle
The easiest thing to do is
just simply absorb them.

00:35:20.106 --> 00:35:22.586 A:middle
What I mean by that is leave
enough room inside your

00:35:22.586 --> 00:35:26.686 A:middle
performance budget where you
can handle a certain amount

00:35:26.686 --> 00:35:29.336 A:middle
of virtual memory faults
before you run your deadlines.

00:35:29.816 --> 00:35:31.856 A:middle
This will make you more
resilient under a load.

00:35:31.856 --> 00:35:34.446 A:middle
So as memory pressure increases,
if your budgets are big enough

00:35:34.446 --> 00:35:35.296 A:middle
and you have enough slack,

00:35:35.906 --> 00:35:37.866 A:middle
you won't notice the
difference in your performance.

00:35:38.306 --> 00:35:41.266 A:middle
Now we realize that some
people do not have these kinds

00:35:41.266 --> 00:35:43.786 A:middle
of lax deadlines in terms
of their UI generation.

00:35:44.626 --> 00:35:47.476 A:middle
So another alternative is
to try to do the faulting

00:35:47.476 --> 00:35:48.666 A:middle
on a background thread.

00:35:49.026 --> 00:35:51.156 A:middle
So let's say you have
a game, for example,

00:35:51.516 --> 00:35:53.886 A:middle
and your player is coming
to the end of level one

00:35:53.886 --> 00:35:55.426 A:middle
and they're going to
transition to level two.

00:35:55.656 --> 00:35:58.736 A:middle
Well, what you might
do is dispatch async

00:35:58.736 --> 00:36:02.926 A:middle
to a background queue and then
touch the pages for the content

00:35:58.736 --> 00:36:02.926 A:middle
to a background queue and then
touch the pages for the content

00:36:02.926 --> 00:36:04.496 A:middle
of level two on that
background queue.

00:36:04.856 --> 00:36:07.646 A:middle
And then by the time your
rendering thread comes

00:36:07.646 --> 00:36:10.026 A:middle
around to pick up that
new content there will be

00:36:10.026 --> 00:36:10.596 A:middle
no stutter.

00:36:11.376 --> 00:36:14.716 A:middle
Now, we'll have to give you a
warning here on this approach.

00:36:14.816 --> 00:36:16.366 A:middle
Make sure you only
touch the pages

00:36:16.366 --> 00:36:17.776 A:middle
that you're absolutely
going to use.

00:36:17.776 --> 00:36:20.446 A:middle
Because if you start touching
more of the pages than you need,

00:36:20.446 --> 00:36:22.446 A:middle
then you're actually going
to make the problem worse.

00:36:22.966 --> 00:36:27.206 A:middle
And that about does it
for today's session.

00:36:27.206 --> 00:36:29.106 A:middle
We think that the System
Trace makes a great companion

00:36:29.106 --> 00:36:30.176 A:middle
to the Time Profiler.

00:36:30.256 --> 00:36:32.586 A:middle
The Time Profiler helps
you make your code fast,

00:36:32.766 --> 00:36:34.736 A:middle
but System Trace
allows your application

00:36:34.736 --> 00:36:36.656 A:middle
to scale better under
a higher load.

00:36:36.656 --> 00:36:40.186 A:middle
We encourage you to try a System
Trace out on your own apps.

00:36:40.186 --> 00:36:42.406 A:middle
We know that when we try
it against Instruments,

00:36:42.406 --> 00:36:44.366 A:middle
we always find something
that's worth fixing.

00:36:44.366 --> 00:36:47.636 A:middle
And if you've used System Trace
in the past, we invite you

00:36:47.636 --> 00:36:50.376 A:middle
to come back to Instruments
8 and give it another look

00:36:50.376 --> 00:36:52.256 A:middle
because we've done
some major improvements

00:36:52.256 --> 00:36:54.256 A:middle
to both the approachability
and the power of the tool.

00:36:54.256 --> 00:36:57.066 A:middle
We think it'll make a great
addition to your toolbox.

00:36:57.796 --> 00:37:01.336 A:middle
For more information,
here's our link Session 411.

00:36:57.796 --> 00:37:01.336 A:middle
For more information,
here's our link Session 411.

00:37:02.326 --> 00:37:03.676 A:middle
We have some related
sessions today

00:37:03.676 --> 00:37:06.406 A:middle
that happened also happened
during the week and on Friday.

00:37:07.186 --> 00:37:07.946 A:middle
Enjoy the rest of your morning.
