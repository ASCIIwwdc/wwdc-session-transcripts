WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:07.516 --> 00:00:18.500 A:middle
[ Music ]

00:00:24.516 --> 00:00:29.006 A:middle
[ Applause ]

00:00:29.506 --> 00:00:30.866 A:middle
&gt;&gt; Thank you so much,
and good morning.

00:00:30.866 --> 00:00:33.976 A:middle
And my name is David Hayward and
I'm here to talk to you today

00:00:34.266 --> 00:00:35.726 A:middle
about editing Live Photos

00:00:35.726 --> 00:00:37.786 A:middle
and processing RAW
images with Core Image.

00:00:37.786 --> 00:00:39.886 A:middle
We got a bunch of great
stuff to talk about today.

00:00:40.786 --> 00:00:42.956 A:middle
First I'll give a brief
introduction to Core Image

00:00:42.956 --> 00:00:44.536 A:middle
for those of you who
are new to the subject.

00:00:45.086 --> 00:00:47.056 A:middle
Then we'll be talking about
our three main subjects

00:00:47.056 --> 00:00:47.746 A:middle
for this morning.

00:00:48.166 --> 00:00:50.746 A:middle
First we'll be adjusting
RAW images on iOS.

00:00:51.476 --> 00:00:53.796 A:middle
Second, we'll be
editing Live Photos.

00:00:53.796 --> 00:00:56.706 A:middle
And third, we'll be talking
about how to extend Core Image

00:00:56.706 --> 00:00:59.276 A:middle
in a new way using
CIImageProcessor nodes.

00:00:59.846 --> 00:01:03.396 A:middle
So first, so a very brief
introduction to Core Image.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:59.846 --> 00:01:03.396 A:middle
So first, so a very brief
introduction to Core Image.

00:01:04.275 --> 00:01:07.696 A:middle
The reason for Core Image is
that it provides a very simple,

00:01:07.696 --> 00:01:10.716 A:middle
high-performance API to
apply filters to images.

00:01:11.396 --> 00:01:14.126 A:middle
The basic idea is you start with
an input image that may come

00:01:14.126 --> 00:01:16.936 A:middle
from a JPEG or a file or
memory, and you can choose

00:01:16.936 --> 00:01:19.556 A:middle
to apply a filter to it and
the result is an output image,

00:01:20.006 --> 00:01:22.356 A:middle
and it's very, very easy
to do this in your code.

00:01:22.766 --> 00:01:26.396 A:middle
All you do is you take your
image, call applyingFilter,

00:01:26.516 --> 00:01:29.466 A:middle
and specify the name of the
filter and any parameters

00:01:29.466 --> 00:01:30.946 A:middle
that are appropriate
for that filter.

00:01:31.496 --> 00:01:32.206 A:middle
It's super easy.

00:01:32.626 --> 00:01:34.586 A:middle
And, of course, you can do
much more complex things.

00:01:34.836 --> 00:01:38.496 A:middle
You can chain together multiple
filters in either sequences

00:01:38.496 --> 00:01:41.056 A:middle
or graphs and get
very complex effects.

00:01:42.356 --> 00:01:43.616 A:middle
One of the great features

00:01:43.616 --> 00:01:45.936 A:middle
of Core Image is it provides
automatic color management,

00:01:46.396 --> 00:01:48.236 A:middle
and this is very
important these days.

00:01:48.606 --> 00:01:52.136 A:middle
We now have a variety of devices
that support wide gamut input

00:01:52.286 --> 00:01:53.566 A:middle
and wide gamut output.

00:01:54.156 --> 00:01:56.856 A:middle
And what Core Image will do is
it will automatically insert the

00:01:56.856 --> 00:01:58.616 A:middle
appropriate nodes
into the render graph

00:01:59.016 --> 00:02:01.326 A:middle
so that it will match
your input image


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:01:59.016 --> 00:02:01.326 A:middle
so that it will match
your input image

00:02:01.476 --> 00:02:04.026 A:middle
to the Core Image working
space, and when it comes time

00:02:04.026 --> 00:02:05.396 A:middle
to display, it will match

00:02:05.396 --> 00:02:07.446 A:middle
from the working space
to the display space.

00:02:08.626 --> 00:02:10.696 A:middle
And this is something you
should be very much aware

00:02:10.696 --> 00:02:12.246 A:middle
of because wide color images

00:02:12.246 --> 00:02:14.606 A:middle
and wide color displays
are common now

00:02:15.706 --> 00:02:17.416 A:middle
and many open source libraries

00:02:17.416 --> 00:02:20.406 A:middle
for doing image processing
don't handle this automatically.

00:02:20.506 --> 00:02:22.766 A:middle
So this is a great feature of
Core Image because it takes care

00:02:22.766 --> 00:02:24.616 A:middle
of all that for you in
a very easy to use way.

00:02:27.146 --> 00:02:28.336 A:middle
Another thing to be aware of is

00:02:28.336 --> 00:02:32.016 A:middle
that each filter actually has
a little bit of code associated

00:02:32.016 --> 00:02:33.916 A:middle
with it, a small
subroutine called a kernel.

00:02:34.656 --> 00:02:38.576 A:middle
And all of our built-in filters
have these kernels and one

00:02:38.576 --> 00:02:40.916 A:middle
of the great features is if
you chain together a sequence

00:02:40.916 --> 00:02:44.336 A:middle
of filters, Core Image will
automatically concatenate these

00:02:44.416 --> 00:02:46.186 A:middle
subroutines into
a single program.

00:02:46.776 --> 00:02:49.186 A:middle
The idea behind this is
to improve performance

00:02:49.286 --> 00:02:52.436 A:middle
by reducing the -- and
quality, by reducing the number

00:02:52.436 --> 00:02:55.496 A:middle
of intermediate buffers.

00:02:56.656 --> 00:02:59.086 A:middle
Core Image has over
180 built-in filters.

00:02:59.126 --> 00:03:00.666 A:middle
They are the exact
same filters on all


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:02:59.126 --> 00:03:00.666 A:middle
They are the exact
same filters on all

00:03:00.666 --> 00:03:05.086 A:middle
of our platforms;
macOS, tvOS and iOS.

00:03:05.586 --> 00:03:07.676 A:middle
We have a few new ones this year
which I'd like to talk about.

00:03:08.616 --> 00:03:09.466 A:middle
One is a new filter

00:03:09.466 --> 00:03:12.236 A:middle
for generating hue
saturation and value gradient.

00:03:12.876 --> 00:03:15.336 A:middle
It creates a gradient
in hue and saturation,

00:03:15.546 --> 00:03:18.606 A:middle
and then you can specify, as
a parameter, the brightness

00:03:18.606 --> 00:03:20.906 A:middle
of the image and also
specify the color space

00:03:20.906 --> 00:03:21.696 A:middle
that the wheel is in.

00:03:21.766 --> 00:03:26.136 A:middle
And as you might guess, this
filter is now used on macOS

00:03:26.386 --> 00:03:30.486 A:middle
as the basis of the color
picker, which is now aware

00:03:30.486 --> 00:03:36.206 A:middle
of the different types
of display color spaces.

00:03:36.206 --> 00:03:39.526 A:middle
Another new filter we have
is CINinePartStretched

00:03:39.526 --> 00:03:40.556 A:middle
and NinePartTiled.

00:03:40.916 --> 00:03:43.546 A:middle
The idea behind this is you
might have a small asset,

00:03:43.546 --> 00:03:45.956 A:middle
like this picture frame here,
and you want to stretch it

00:03:45.956 --> 00:03:48.216 A:middle
up to fit an arbitrary size.

00:03:48.476 --> 00:03:49.976 A:middle
This filter is very easy to use.

00:03:49.976 --> 00:03:54.736 A:middle
You provide an input image and
you provide four breakpoints,

00:03:54.826 --> 00:03:56.536 A:middle
two horizontal and two vertical.

00:03:56.736 --> 00:03:58.206 A:middle
Once you've specified
those points,

00:03:58.206 --> 00:04:00.606 A:middle
you can specify the size
you want it to stretch to.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:58.206 --> 00:04:00.606 A:middle
you can specify the size
you want it to stretch to.

00:04:01.416 --> 00:04:02.336 A:middle
It's very easy to use.

00:04:02.896 --> 00:04:07.206 A:middle
The third new filter is
something that's also

00:04:07.206 --> 00:04:08.076 A:middle
quite interesting.

00:04:08.076 --> 00:04:11.516 A:middle
The idea is to start
with a small input image.

00:04:11.806 --> 00:04:13.856 A:middle
In this case it's an image
containing color data,

00:04:13.856 --> 00:04:16.036 A:middle
but it can also contain
parametric data.

00:04:16.356 --> 00:04:19.356 A:middle
So imagine you have a small
set of colors or parameters

00:04:19.875 --> 00:04:23.366 A:middle
and maybe it's only 6 by 7
pixels and you want to upsample

00:04:23.366 --> 00:04:25.076 A:middle
that to the full
size of an image.

00:04:26.446 --> 00:04:28.836 A:middle
The idea is to upsample
the color image,

00:04:29.166 --> 00:04:30.106 A:middle
the small color image,

00:04:31.006 --> 00:04:33.966 A:middle
but respect the edges
in the guide image.

00:04:34.476 --> 00:04:36.166 A:middle
Now, if you weren't to
respect the guide images,

00:04:36.166 --> 00:04:39.356 A:middle
if you were just to stretch the
small image up to the same size

00:04:39.356 --> 00:04:43.006 A:middle
as the full image, you'd
just get a blend of colors,

00:04:43.476 --> 00:04:45.046 A:middle
but with this filter
you can get more.

00:04:45.296 --> 00:04:46.506 A:middle
You can actually get something

00:04:46.506 --> 00:04:49.376 A:middle
that preserves the edges while
also respecting the colors.

00:04:49.376 --> 00:04:51.616 A:middle
And this is actually a
useful feature for a lot

00:04:51.616 --> 00:04:52.866 A:middle
of other types of algorithms.

00:04:53.126 --> 00:04:56.396 A:middle
In fact, in the new version
of Photos app we use this

00:04:56.396 --> 00:05:00.116 A:middle
to improve the behavior of
the light adjustment sliders.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:56.396 --> 00:05:00.116 A:middle
to improve the behavior of
the light adjustment sliders.

00:05:00.116 --> 00:05:03.016 A:middle
I look forward to
seeing how you can use

00:05:03.016 --> 00:05:03.926 A:middle
that in your application.

00:05:04.646 --> 00:05:06.696 A:middle
We also have some new
performance controls this year

00:05:07.256 --> 00:05:09.106 A:middle
and do things that
improve performance

00:05:09.136 --> 00:05:10.036 A:middle
in Core Image this year.

00:05:10.776 --> 00:05:13.176 A:middle
One is we have Metal
turned on by default.

00:05:13.556 --> 00:05:16.926 A:middle
So if you use any of
our built-in 180 filters

00:05:16.926 --> 00:05:18.276 A:middle
or your own custom kernels,

00:05:18.686 --> 00:05:21.736 A:middle
all of those kernels
will be converted

00:05:21.736 --> 00:05:23.016 A:middle
to Metal on the fly for you.

00:05:23.336 --> 00:05:25.386 A:middle
It's a great way of
leveraging the power of Metal

00:05:25.886 --> 00:05:29.186 A:middle
with very little
effort on your part.

00:05:29.506 --> 00:05:32.356 A:middle
We've also made some great
improvements to a critical API,

00:05:32.356 --> 00:05:35.076 A:middle
which is creating a
UIImage from a CIImage,

00:05:35.536 --> 00:05:37.686 A:middle
and this now produces
much better performance

00:05:37.686 --> 00:05:38.516 A:middle
than it has in the past.

00:05:38.516 --> 00:05:40.636 A:middle
So you can actually use
this very efficiently

00:05:40.926 --> 00:05:45.216 A:middle
to animate an image
in a UIImage view.

00:05:45.866 --> 00:05:47.386 A:middle
Also another new feature is

00:05:47.386 --> 00:05:49.666 A:middle
that Core Image now
supports a feature that's new

00:05:49.666 --> 00:05:50.866 A:middle
to Core Graphics, which is

00:05:50.966 --> 00:05:53.366 A:middle
that Core Graphics
supports half-floats.

00:05:53.526 --> 00:05:55.446 A:middle
Let me just talk for a
second about pixel formats

00:05:55.446 --> 00:05:56.846 A:middle
because this brings up
an interesting point.

00:05:58.256 --> 00:06:01.196 A:middle
We're all familiar with the
conventional pixel format


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:05:58.256 --> 00:06:01.196 A:middle
We're all familiar with the
conventional pixel format

00:06:01.756 --> 00:06:06.516 A:middle
of RGBA8 and it takes just
4 bytes per pixel to store

00:06:06.516 --> 00:06:10.246 A:middle
and has 8 bits of depth,
and can encode values

00:06:10.246 --> 00:06:11.426 A:middle
in the range of 0 to 1.

00:06:12.376 --> 00:06:14.006 A:middle
However, this format
is not great

00:06:14.006 --> 00:06:18.686 A:middle
for representing wide-colored
data because it only has 8 bits

00:06:18.716 --> 00:06:20.796 A:middle
and it's limited to the
values in the range 0 to 1.

00:06:21.236 --> 00:06:25.156 A:middle
So in the past the alternative
has been to use RGBAfloat,

00:06:25.666 --> 00:06:28.636 A:middle
which takes 16 bytes per pixel,
so four times as much memory,

00:06:28.986 --> 00:06:31.866 A:middle
but gives you all the depth and
range you could ever hope for.

00:06:32.916 --> 00:06:35.456 A:middle
Another feature of the fact
that it's using floats is

00:06:35.456 --> 00:06:37.056 A:middle
that what quantization there is,

00:06:37.056 --> 00:06:38.436 A:middle
it's distributed
logarithmically,

00:06:38.466 --> 00:06:41.326 A:middle
which is a good fit for the way
the human eye perceives color.

00:06:41.326 --> 00:06:45.486 A:middle
Well, there's a new format
which Core Image has supported

00:06:45.486 --> 00:06:48.286 A:middle
and now Core Graphics does
as well, which I refer

00:06:48.286 --> 00:06:51.536 A:middle
to as the Goldilocks pixel
format, which is RGBAh,

00:06:51.536 --> 00:06:55.256 A:middle
and this allows you to,
in just 8 bytes per pixel,

00:06:55.726 --> 00:06:59.816 A:middle
store data that is 10 bits
of depth and allows values

00:06:59.816 --> 00:07:03.216 A:middle
in the range of minus
65,000 to positive 65,000.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:59.816 --> 00:07:03.216 A:middle
in the range of minus
65,000 to positive 65,000.

00:07:03.556 --> 00:07:05.806 A:middle
And again, those values are
quantized logarithmically,

00:07:05.806 --> 00:07:08.066 A:middle
so it's great to store
linear data in a way

00:07:08.066 --> 00:07:09.646 A:middle
that won't be perceived
as quantized.

00:07:10.296 --> 00:07:12.826 A:middle
So I highly recommend
this pixel format.

00:07:13.466 --> 00:07:15.306 A:middle
There's another new format
which I should mention,

00:07:15.306 --> 00:07:18.176 A:middle
which is that Core Video
supports a pixel format

00:07:18.446 --> 00:07:19.346 A:middle
with the long name

00:07:19.346 --> 00:07:23.626 A:middle
of 30RGBLittle [inaudible]
PackedWideGamut,

00:07:23.726 --> 00:07:27.646 A:middle
and this also supports 10
bits of depth, but stores it

00:07:27.646 --> 00:07:31.676 A:middle
in an only 4 bytes per pixel by
sacrificing the alpha channel.

00:07:32.026 --> 00:07:34.266 A:middle
So there's many cases where
this is useful as well

00:07:34.636 --> 00:07:37.816 A:middle
and Core Image supports
either rendering from

00:07:37.816 --> 00:07:39.966 A:middle
or to CV pixel buffers
in this format.

00:07:40.316 --> 00:07:45.756 A:middle
So now I'd like to actually talk
about the next major subject

00:07:45.756 --> 00:07:49.006 A:middle
of our discussion today,
which is adjusting RAW images

00:07:49.006 --> 00:07:50.686 A:middle
with Core Image, and
I'm really excited

00:07:50.686 --> 00:07:51.666 A:middle
to talk about this today.

00:07:51.666 --> 00:07:53.196 A:middle
We've been working on
this for a long time.

00:07:53.196 --> 00:07:55.676 A:middle
It's been a lot of hard
work and I'm really excited

00:07:55.676 --> 00:07:58.456 A:middle
about the fact that we've
brought this to iOS.

00:07:58.986 --> 00:08:01.536 A:middle
In talking about this, I'd like
to discuss what is a RAW file,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:07:58.986 --> 00:08:01.536 A:middle
In talking about this, I'd like
to discuss what is a RAW file,

00:08:02.106 --> 00:08:03.796 A:middle
how to use the CIRAWFilter API,

00:08:03.796 --> 00:08:06.716 A:middle
some notes on supporting
wide-gamut output,

00:08:07.126 --> 00:08:09.166 A:middle
and also tips for
managing memory.

00:08:10.516 --> 00:08:12.776 A:middle
So first, what is a RAW file?

00:08:13.376 --> 00:08:17.546 A:middle
Well, the way most cameras work
is that they have two key parts;

00:08:18.106 --> 00:08:20.286 A:middle
a color filter array
and a sensor array.

00:08:20.836 --> 00:08:24.016 A:middle
And the idea is light from the
scene enters from the scene

00:08:24.126 --> 00:08:25.406 A:middle
through the color filter array

00:08:25.646 --> 00:08:27.546 A:middle
and it's counted by
the sensor array.

00:08:28.596 --> 00:08:31.016 A:middle
And this data is actually
part of a much larger image,

00:08:31.016 --> 00:08:34.716 A:middle
of course, but in order to turn
this data into a usable image,

00:08:34.716 --> 00:08:38.015 A:middle
a lot of image processing
is needed in order

00:08:38.015 --> 00:08:40.385 A:middle
to produce a pleasing
image for the user.

00:08:41.726 --> 00:08:43.066 A:middle
So I want to talk a
little bit about that.

00:08:43.405 --> 00:08:46.996 A:middle
But the main idea here is
that if you take the data

00:08:46.996 --> 00:08:49.416 A:middle
that was captured by the
sensor, that is a RAW file.

00:08:49.626 --> 00:08:51.056 A:middle
If you take the data
that was captured

00:08:51.436 --> 00:08:54.346 A:middle
after the image processing,
that's a TIFF or a JPEG.

00:08:55.766 --> 00:08:58.476 A:middle
RAW files store the
unprocessed scene data,

00:08:58.726 --> 00:09:02.266 A:middle
and JPEG files store the
processed output image.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:08:58.726 --> 00:09:02.266 A:middle
and JPEG files store the
processed output image.

00:09:03.546 --> 00:09:04.846 A:middle
Another way to think of it is

00:09:04.846 --> 00:09:06.646 A:middle
that the RAW file
stores the ingredients

00:09:06.646 --> 00:09:08.976 A:middle
from which you can
make an image; whereas,

00:09:08.976 --> 00:09:12.316 A:middle
a JPEG stores the
results of the ingredients

00:09:12.316 --> 00:09:14.466 A:middle
after they've been baked
into a beautiful cake.

00:09:15.456 --> 00:09:19.176 A:middle
In order to go from
the ingredients

00:09:19.176 --> 00:09:21.146 A:middle
to a final baked product,
however, there is a lot

00:09:21.146 --> 00:09:23.696 A:middle
of stages, so let me just
outline a few of those here.

00:09:24.766 --> 00:09:26.846 A:middle
First of all, we have to
extract metadata from the file

00:09:26.976 --> 00:09:28.966 A:middle
that tells us how
long to cook the cake,

00:09:28.966 --> 00:09:30.006 A:middle
to extend the metaphor.

00:09:31.116 --> 00:09:33.416 A:middle
Also, we need to decode the
RAW data from the sensor.

00:09:34.546 --> 00:09:39.406 A:middle
We need to demosaic the image to
reconstruct the full color image

00:09:39.406 --> 00:09:41.256 A:middle
from the data that was captured

00:09:41.256 --> 00:09:43.936 A:middle
with only one RGB value
per pixel location.

00:09:44.356 --> 00:09:48.506 A:middle
We need to apply geometric
distortions for lens correction.

00:09:49.866 --> 00:09:53.426 A:middle
Noise reduction, which is a
huge piece of the processing.

00:09:54.476 --> 00:09:57.226 A:middle
We need to do color matching
from the scene-referred datas

00:09:57.226 --> 00:09:58.256 A:middle
that the sensor captured

00:09:58.506 --> 00:09:59.936 A:middle
into the output-referred
data for display.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:00.046 --> 00:10:04.296 A:middle
And then we need to do
things like adjust exposure

00:10:04.296 --> 00:10:05.206 A:middle
and temperature and tint.

00:10:05.746 --> 00:10:08.616 A:middle
And lastly, but very
importantly, add sharpening,

00:10:08.616 --> 00:10:11.576 A:middle
contrast and saturation to
make an image look pleasing.

00:10:12.006 --> 00:10:13.086 A:middle
That's a lot of stages.

00:10:13.786 --> 00:10:16.766 A:middle
What are some of the
advantages of RAW?

00:10:16.936 --> 00:10:18.476 A:middle
Well, one of the great things is

00:10:18.476 --> 00:10:21.306 A:middle
that the RAW file contains
linear and deep pixel data,

00:10:21.726 --> 00:10:23.986 A:middle
which is what enables
great editability.

00:10:25.906 --> 00:10:28.336 A:middle
Another feature is that RAW
image processing gets better

00:10:28.846 --> 00:10:29.316 A:middle
every year.

00:10:29.706 --> 00:10:32.056 A:middle
So with the RAW you
have the promise

00:10:32.056 --> 00:10:34.916 A:middle
that an image you took yesterday
might have better quality

00:10:34.916 --> 00:10:38.746 A:middle
when you process it next year.

00:10:39.456 --> 00:10:41.986 A:middle
Also, RAW files are
color space agnostic.

00:10:42.046 --> 00:10:44.316 A:middle
They can actually be rendered
to any target output space,

00:10:44.746 --> 00:10:46.846 A:middle
which is also a good
feature, given the variety

00:10:46.846 --> 00:10:47.896 A:middle
of displays we have today.

00:10:49.656 --> 00:10:52.176 A:middle
Also, a user can choose
to use different software

00:10:52.176 --> 00:10:53.316 A:middle
to interpret the RAW file.

00:10:53.676 --> 00:10:55.046 A:middle
Just like giving
the same ingredient

00:10:55.096 --> 00:10:57.266 A:middle
to two different chefs, you
can get two different results,

00:10:57.686 --> 00:11:00.116 A:middle
and some users might prefer
one chef over another.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:57.686 --> 00:11:00.116 A:middle
and some users might prefer
one chef over another.

00:11:00.726 --> 00:11:05.216 A:middle
That said, there are some great
advantages to JPEG as well.

00:11:06.226 --> 00:11:08.366 A:middle
First of all, because the
processing has been applied,

00:11:08.366 --> 00:11:09.936 A:middle
they are fast to
load and display.

00:11:11.096 --> 00:11:13.706 A:middle
They contain colors
and adjustments

00:11:13.706 --> 00:11:16.026 A:middle
that target a specific
output, which can be useful.

00:11:16.896 --> 00:11:19.146 A:middle
And that also gives
predictable results.

00:11:20.436 --> 00:11:23.986 A:middle
Also, it's worth mentioning that
cameras do a great job today

00:11:23.986 --> 00:11:25.556 A:middle
of producing JPEG images,

00:11:25.866 --> 00:11:30.806 A:middle
and our iOS cameras are an
especially good example of that.

00:11:31.946 --> 00:11:34.456 A:middle
So on the subject of RAW,
let me talk a little bit

00:11:34.456 --> 00:11:36.346 A:middle
about how our platforms
support RAW.

00:11:37.286 --> 00:11:41.526 A:middle
So the great news is that now
we fully support RAW on iOS

00:11:41.756 --> 00:11:44.286 A:middle
and upcoming seed
on tvOS as well.

00:11:45.836 --> 00:11:48.426 A:middle
This means we support over
400 unique camera models

00:11:48.426 --> 00:11:49.966 A:middle
from 16 different vendors.

00:11:50.486 --> 00:11:53.496 A:middle
And also, we support DNG
files such as those captured

00:11:53.496 --> 00:11:54.996 A:middle
by our own iOS devices.

00:11:55.886 --> 00:12:01.736 A:middle
The iOS devices include
the iPhone 6S, 6S Plus, SE,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:11:55.886 --> 00:12:01.736 A:middle
The iOS devices include
the iPhone 6S, 6S Plus, SE,

00:12:01.846 --> 00:12:03.816 A:middle
and also the iPad Pro 9.7.

00:12:05.376 --> 00:12:06.426 A:middle
That is really exciting.

00:12:06.956 --> 00:12:09.096 A:middle
I recommend you all go back,
if you haven't already,

00:12:09.096 --> 00:12:11.306 A:middle
and watch the Advances
in iOS Photography,

00:12:11.306 --> 00:12:13.636 A:middle
which talks about the new
APIs that are available

00:12:13.636 --> 00:12:15.526 A:middle
to capture RAW on these devices.

00:12:15.526 --> 00:12:20.076 A:middle
Another great thing is that
we now have the same high

00:12:20.076 --> 00:12:24.396 A:middle
performance RAW pipeline
on iOS as we do on macOS,

00:12:24.846 --> 00:12:27.016 A:middle
and this is actually
quite an achievement.

00:12:27.176 --> 00:12:29.726 A:middle
I counted the other day
and looked at our pipeline

00:12:29.726 --> 00:12:34.026 A:middle
and it involves over 4,500
lines of CIKernel code

00:12:34.676 --> 00:12:36.406 A:middle
and this all works
very efficiently

00:12:36.406 --> 00:12:39.516 A:middle
and it's a great testament to
our ability and the abilities

00:12:39.516 --> 00:12:40.646 A:middle
of Core Image to be able

00:12:40.646 --> 00:12:42.956 A:middle
to handle complex
rendering situations.

00:12:43.496 --> 00:12:49.346 A:middle
Our pipeline on iOS
requires A8 devices or later,

00:12:49.656 --> 00:12:52.516 A:middle
and you can test for this in
your application by looking

00:12:52.516 --> 00:12:56.366 A:middle
for the iOS GPU Family 2.

00:12:57.746 --> 00:12:59.486 A:middle
Another note on platform
support.

00:12:59.486 --> 00:13:01.636 A:middle
We continuously add
support for new cameras


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:59.486 --> 00:13:01.636 A:middle
We continuously add
support for new cameras

00:13:01.636 --> 00:13:04.576 A:middle
as new ones become available,
and also to improve the quality

00:13:04.576 --> 00:13:06.316 A:middle
of existing cameras
that we already support.

00:13:07.236 --> 00:13:09.866 A:middle
New cameras are added in
future software updates.

00:13:10.476 --> 00:13:13.186 A:middle
And also, we improve our
pipeline periodically as well.

00:13:13.566 --> 00:13:15.166 A:middle
And our pipelines are versions,

00:13:15.166 --> 00:13:17.466 A:middle
so you can either use our
latest version or go back

00:13:17.466 --> 00:13:19.056 A:middle
and use previous
versions if you desire.

00:13:20.286 --> 00:13:23.966 A:middle
So without further ado, I
want to give a demonstration

00:13:23.966 --> 00:13:24.976 A:middle
of how this looks in action.

00:13:32.106 --> 00:13:34.296 A:middle
So what I have here
is some sample code.

00:13:34.296 --> 00:13:36.556 A:middle
There's an early version of that
that's available for download,

00:13:36.556 --> 00:13:39.806 A:middle
and it's called RAWExposed,
and this is both an application

00:13:39.806 --> 00:13:42.946 A:middle
and this latest version is
also a photo editing extension.

00:13:43.496 --> 00:13:45.416 A:middle
So what we can do is
we can go into Photos

00:13:45.416 --> 00:13:46.816 A:middle
and actually use
this sample code.

00:13:47.436 --> 00:13:50.346 A:middle
We have three RAW images here
that are 24 megapixels each

00:13:50.346 --> 00:13:52.716 A:middle
that were taken with
a Canon 5D Mark III.

00:13:53.166 --> 00:13:55.556 A:middle
And you can see here that
this image is pretty poorly

00:13:55.556 --> 00:13:58.046 A:middle
overexposed, but one of the
great features of RAW is

00:13:58.046 --> 00:13:59.926 A:middle
that you can actually
salvage images like this.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:14:00.356 --> 00:14:01.896 A:middle
So we can go here and edit it

00:14:02.226 --> 00:14:04.816 A:middle
and use our photo
editing extension

00:14:05.376 --> 00:14:07.136 A:middle
to edit this as a RAW file.

00:14:07.956 --> 00:14:10.706 A:middle
So now, since we're
editing this as a RAW file,

00:14:10.706 --> 00:14:12.016 A:middle
we can actually make
adjustments [inaudible].

00:14:12.996 --> 00:14:17.226 A:middle
We can adjust the
exposure up and down.

00:14:18.596 --> 00:14:21.486 A:middle
You can see we can pan
across all the 24 megapixels

00:14:22.146 --> 00:14:23.466 A:middle
and we get great results.

00:14:24.576 --> 00:14:27.246 A:middle
Once I'm happy with the
image, this looks much better

00:14:27.246 --> 00:14:29.046 A:middle
than it did before,
I can hit Done

00:14:29.046 --> 00:14:32.516 A:middle
and it will generate a new
full resolution image of that,

00:14:32.516 --> 00:14:34.316 A:middle
and now it is actually
available to see

00:14:34.316 --> 00:14:34.976 A:middle
in the Photos application.

00:14:35.516 --> 00:14:42.876 A:middle
[ Applause ]

00:14:43.376 --> 00:14:45.586 A:middle
One of the other things
that's great in RAW files is

00:14:45.586 --> 00:14:46.816 A:middle
that you can make
great adjustments

00:14:46.816 --> 00:14:48.046 A:middle
on white balance in an image.

00:14:48.046 --> 00:14:49.986 A:middle
Again, on this image
the image is fine,

00:14:49.986 --> 00:14:51.316 A:middle
but it may be a little crooked,

00:14:51.316 --> 00:14:52.706 A:middle
but also the white
balance is off.

00:14:53.346 --> 00:14:54.466 A:middle
So I'm going to go in here

00:14:54.846 --> 00:14:58.396 A:middle
and adjust the white
balance just a little bit

00:14:58.396 --> 00:14:59.916 A:middle
and I can make a much
more pleasant image.

00:14:59.916 --> 00:15:01.666 A:middle
And again, we can zoom
in and see the results.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:14:59.916 --> 00:15:01.666 A:middle
And again, we can zoom
in and see the results.

00:15:02.246 --> 00:15:04.556 A:middle
And we can adjust
these results live.

00:15:05.406 --> 00:15:08.226 A:middle
So we hit Done and save that.

00:15:10.266 --> 00:15:12.096 A:middle
Another image I want to
show is this image here,

00:15:12.096 --> 00:15:13.656 A:middle
which is actually
a very noisy image.

00:15:13.656 --> 00:15:15.366 A:middle
I want to show you a little bit

00:15:15.366 --> 00:15:16.676 A:middle
about our noise reduction
algorithms.

00:15:17.146 --> 00:15:19.566 A:middle
Over half of our 4,500 lines

00:15:19.566 --> 00:15:21.486 A:middle
of kernel code relate
to noise reduction.

00:15:22.046 --> 00:15:23.906 A:middle
So if I go in here
and edit this one,

00:15:24.906 --> 00:15:26.176 A:middle
you can see that there's some --

00:15:26.236 --> 00:15:27.526 A:middle
hopefully at least
in the front rows,

00:15:27.526 --> 00:15:29.046 A:middle
you can see the grain
that's in this image.

00:15:30.056 --> 00:15:32.326 A:middle
One of the features we expose
in our API is the ability

00:15:32.326 --> 00:15:34.306 A:middle
to turn off our noise
reduction algorithm,

00:15:34.796 --> 00:15:36.746 A:middle
and then you can actually
see the colorful nature

00:15:36.746 --> 00:15:39.036 A:middle
of the noise that's actually
present in the RAW file.

00:15:39.106 --> 00:15:41.736 A:middle
And it's this very
challenging task

00:15:41.736 --> 00:15:44.596 A:middle
of doing the noise
reduction to make an image

00:15:44.596 --> 00:15:46.576 A:middle
that doesn't have
those colorful speckles

00:15:46.576 --> 00:15:49.276 A:middle
but still preserves
nice color edges

00:15:49.526 --> 00:15:50.766 A:middle
that are intended in the image.

00:15:52.376 --> 00:15:55.256 A:middle
So I'll save that as well.

00:15:55.466 --> 00:15:59.546 A:middle
Lastly, I want to demonstrate an
image we took earlier this week


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:00.136 --> 00:16:02.446 A:middle
out in the lobby, which
was taken with this iPad.

00:16:02.446 --> 00:16:03.966 A:middle
Yes, I was one of those people
taking a picture with an iPad.

00:16:04.316 --> 00:16:06.316 A:middle
[ Laughter ]

00:16:06.616 --> 00:16:09.586 A:middle
And here I want to
show you, you know,

00:16:09.586 --> 00:16:11.256 A:middle
this is an image that's
challenging in its own way

00:16:11.256 --> 00:16:12.706 A:middle
because it's got some
areas that are dark

00:16:12.706 --> 00:16:14.386 A:middle
and some areas that
are overexposed.

00:16:15.586 --> 00:16:18.986 A:middle
One thing I could do here is I
could bring down the exposure --

00:16:18.986 --> 00:16:20.796 A:middle
well, I have a highlight
slider which can allow me

00:16:20.796 --> 00:16:25.446 A:middle
to bring the highlights
in a bit.

00:16:25.666 --> 00:16:27.326 A:middle
I can also bring
down the exposure.

00:16:27.786 --> 00:16:30.166 A:middle
And now I can really see what's
going on outside the windows.

00:16:30.786 --> 00:16:32.236 A:middle
But now the shadows
are too dark,

00:16:32.236 --> 00:16:33.316 A:middle
so I can then increase those.

00:16:33.316 --> 00:16:36.786 A:middle
So this gives you an idea of the
kind of adjustments you can do

00:16:36.786 --> 00:16:38.656 A:middle
on RAW files, and
this is the benefit

00:16:38.656 --> 00:16:41.696 A:middle
of having deeper
precision on your pixel data

00:16:41.786 --> 00:16:42.826 A:middle
that you get in a RAW file.

00:16:43.936 --> 00:16:47.706 A:middle
So I'll hit Done on that.

00:16:48.046 --> 00:16:49.976 A:middle
So that's our demo
of RAW in iOS.

00:16:50.516 --> 00:16:55.546 A:middle
[ Applause ]

00:16:56.046 --> 00:16:57.956 A:middle
And a huge thanks to the team
for making this possible.

00:16:58.356 --> 00:17:01.836 A:middle
So let me talk about the API,
because it's not just enough


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:58.356 --> 00:17:01.836 A:middle
So let me talk about the API,
because it's not just enough

00:17:01.836 --> 00:17:03.706 A:middle
to provide a demo application.

00:17:03.706 --> 00:17:05.675 A:middle
We want to enable your
applications to be able

00:17:05.675 --> 00:17:07.006 A:middle
to do this in your apps as well.

00:17:07.586 --> 00:17:09.435 A:middle
So we have an API
that's referred

00:17:09.435 --> 00:17:11.096 A:middle
to as the CIRAWFilter API,

00:17:11.096 --> 00:17:14.046 A:middle
and it gives your application
some critical things.

00:17:14.526 --> 00:17:17.736 A:middle
It gives your application
a CIImage with wide-gamut,

00:17:17.736 --> 00:17:20.675 A:middle
extended range, half-float
precision math behind it.

00:17:21.766 --> 00:17:24.596 A:middle
It also gives you control
over many of the stages

00:17:24.596 --> 00:17:26.185 A:middle
in the RAW processing pipeline,

00:17:26.185 --> 00:17:27.465 A:middle
such as those that
I demonstrated.

00:17:28.806 --> 00:17:31.276 A:middle
It also provides fast
interactive performance using

00:17:31.276 --> 00:17:32.966 A:middle
the GPU on all our devices.

00:17:34.486 --> 00:17:35.786 A:middle
So how does this
work in practice?

00:17:35.786 --> 00:17:37.086 A:middle
The API is actually very simple.

00:17:37.376 --> 00:17:41.116 A:middle
You start with an input, which
is either a file URL or data,

00:17:41.416 --> 00:17:43.376 A:middle
or even in our next
seed we'll have an API

00:17:43.376 --> 00:17:45.356 A:middle
that works using CVPixelBuffer.

00:17:46.316 --> 00:17:47.456 A:middle
That is our input.

00:17:47.456 --> 00:17:48.876 A:middle
We're then going to
create an instance

00:17:48.916 --> 00:17:50.886 A:middle
of a CIRAWFilter
from that input.

00:17:51.426 --> 00:17:55.316 A:middle
At the time that filter is
instantiated it will have

00:17:55.316 --> 00:17:58.596 A:middle
default values for all the
user adjustable parameters

00:17:58.856 --> 00:18:01.086 A:middle
that you might want to
present to your user.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:17:58.856 --> 00:18:01.086 A:middle
that you might want to
present to your user.

00:18:02.836 --> 00:18:05.716 A:middle
Once you have the
CIRAWFilter, you can then ask it

00:18:05.716 --> 00:18:07.966 A:middle
for a CIImage, and you can
do lots of things from there.

00:18:07.966 --> 00:18:09.156 A:middle
Let me just show you the code

00:18:09.156 --> 00:18:10.776 A:middle
and how simple it
is just to do this.

00:18:12.146 --> 00:18:14.026 A:middle
All we need to do
is give it a URL.

00:18:14.026 --> 00:18:16.076 A:middle
We're going to create
an instance

00:18:16.076 --> 00:18:17.696 A:middle
of the CIFilter given that URL.

00:18:18.666 --> 00:18:21.186 A:middle
Then, for example, if
we want to get the value

00:18:21.186 --> 00:18:22.616 A:middle
of the current noise
reduction amount,

00:18:22.736 --> 00:18:24.546 A:middle
we can just access the value

00:18:24.546 --> 00:18:27.546 A:middle
for key kCIInput
ImageNoiseReductionAmount.

00:18:28.736 --> 00:18:30.596 A:middle
If we want to alter
that, it's equally easy.

00:18:30.596 --> 00:18:32.156 A:middle
We just set a new
value for that key.

00:18:32.906 --> 00:18:34.246 A:middle
When we're done making changes,

00:18:34.536 --> 00:18:36.606 A:middle
we ask for the outputImage
and we're done.

00:18:36.606 --> 00:18:37.656 A:middle
That's all we need to do.

00:18:38.136 --> 00:18:40.276 A:middle
Of course, you might want
to display this image,

00:18:40.656 --> 00:18:43.516 A:middle
so typically you'll take that
image and display it either

00:18:43.516 --> 00:18:47.066 A:middle
in a UIImage view or
in a MetalKit view

00:18:47.066 --> 00:18:48.876 A:middle
or other type of view system.

00:18:49.516 --> 00:18:51.616 A:middle
In this case the user might
suggest though that, well,

00:18:51.616 --> 00:18:53.486 A:middle
maybe this image is a
little underexposed,

00:18:53.736 --> 00:18:57.466 A:middle
so in your UI you can have
adjustable sliders for exposure

00:18:57.966 --> 00:18:59.936 A:middle
and then the user can
make that adjustment.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:00.256 --> 00:19:03.216 A:middle
You can then pass that in as a
new value to the CIRAWFilter.

00:19:03.726 --> 00:19:06.066 A:middle
Then you can ask for
a CIImage from that,

00:19:06.856 --> 00:19:09.676 A:middle
and then you can then
display that new image

00:19:09.676 --> 00:19:11.016 A:middle
with the exposure
slightly brighter.

00:19:12.316 --> 00:19:13.686 A:middle
And this is very easy as well.

00:19:15.956 --> 00:19:19.606 A:middle
You also might want to take your
CIImage -- at times, let's say,

00:19:19.606 --> 00:19:21.406 A:middle
you want to export your
image in the background

00:19:21.406 --> 00:19:22.716 A:middle
to produce a full-size image,

00:19:23.096 --> 00:19:25.356 A:middle
or you may be exporting several
images in the background.

00:19:25.926 --> 00:19:29.246 A:middle
So you might want to, in those
cases, either create a CGImage

00:19:29.246 --> 00:19:34.286 A:middle
for passing to other APIs, or
go directly to a JPEG or a TIFF,

00:19:34.286 --> 00:19:36.926 A:middle
and we have some easy to
use APIs for that now.

00:19:38.286 --> 00:19:40.376 A:middle
If you're going to be
doing background processing

00:19:40.376 --> 00:19:41.776 A:middle
of large files like RAWs,

00:19:42.106 --> 00:19:45.556 A:middle
we recommend you create
a CIContext explicitly

00:19:45.556 --> 00:19:46.396 A:middle
for that purpose.

00:19:46.566 --> 00:19:50.946 A:middle
Specifically, you want to
specify a context that is saved

00:19:50.946 --> 00:19:52.686 A:middle
in a singleton variable,
so there's no need

00:19:52.686 --> 00:19:54.586 A:middle
to create a new context
for every image.

00:19:55.126 --> 00:19:57.516 A:middle
This allows CI to
cache the compilation

00:19:57.656 --> 00:19:59.606 A:middle
of all the kernels
that are involved.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:20:01.166 --> 00:20:03.566 A:middle
However, because we're going to
be rendering an image only once,

00:20:03.566 --> 00:20:06.336 A:middle
we don't need Core Image to be
able to cache intermediates,

00:20:06.336 --> 00:20:07.816 A:middle
so you can specify false there,

00:20:07.816 --> 00:20:10.066 A:middle
and that will help reduce
the memory requirements

00:20:10.226 --> 00:20:11.086 A:middle
in this situation.

00:20:12.306 --> 00:20:14.126 A:middle
Also, there's a setting
to say that you want

00:20:14.126 --> 00:20:16.296 A:middle
to use a low priority
GPU render.

00:20:16.926 --> 00:20:19.106 A:middle
The idea behind this, if
you're doing a background save,

00:20:19.106 --> 00:20:21.236 A:middle
you don't want the
GPU usages required

00:20:21.236 --> 00:20:24.216 A:middle
for that background operation
to slow down the performance

00:20:24.216 --> 00:20:26.636 A:middle
of your foreground UI,
either if that's done

00:20:26.636 --> 00:20:28.036 A:middle
in Core Image or Core Animation.

00:20:29.306 --> 00:20:30.966 A:middle
So this is great for
background processing.

00:20:30.966 --> 00:20:32.916 A:middle
And a great new thing we're
announcing this year is

00:20:32.916 --> 00:20:38.736 A:middle
that this option is also
available on macOS, too.

00:20:39.456 --> 00:20:42.026 A:middle
Once you have your context,
then it's very simple.

00:20:42.346 --> 00:20:44.666 A:middle
You get to decide what color
space you want to render to.

00:20:44.816 --> 00:20:46.936 A:middle
For example, the
DisplayP3 colorSpace.

00:20:47.626 --> 00:20:49.216 A:middle
And then we have a
new convenience API

00:20:49.216 --> 00:20:52.016 A:middle
for taking a CIImage and
writing it to a JPEG.

00:20:52.166 --> 00:20:52.826 A:middle
Super easy.

00:20:52.826 --> 00:20:54.786 A:middle
You specify the CIImage,

00:20:55.226 --> 00:20:57.586 A:middle
the destination URL,
and the colorSpace.

00:20:58.786 --> 00:20:59.826 A:middle
This is also a good time

00:20:59.826 --> 00:21:03.556 A:middle
to specify what compression
quality you want for the JPEG.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:20:59.826 --> 00:21:03.556 A:middle
to specify what compression
quality you want for the JPEG.

00:21:04.876 --> 00:21:07.296 A:middle
Now, in this case this will
produce an image that is a JPEG

00:21:07.296 --> 00:21:10.406 A:middle
that has been tagged with a
P3 space, which is a great way

00:21:10.406 --> 00:21:14.046 A:middle
of producing a wide-gamut image
that will display correctly

00:21:14.046 --> 00:21:18.766 A:middle
on any platform that supports
ICC-based color management.

00:21:19.566 --> 00:21:22.036 A:middle
However, if you think your
image will go to a platform

00:21:22.036 --> 00:21:23.606 A:middle
that doesn't support
color management,

00:21:23.606 --> 00:21:25.266 A:middle
we have a new option
that's available for you.

00:21:25.986 --> 00:21:27.756 A:middle
This is an option
that's available as part

00:21:27.756 --> 00:21:29.416 A:middle
of the CGImageDestination API,

00:21:30.356 --> 00:21:33.776 A:middle
and it's CGImageDestination
OptimizeForSharing.

00:21:34.686 --> 00:21:37.556 A:middle
The idea behind this is it
stores all the colors that are

00:21:37.556 --> 00:21:40.906 A:middle
in the P3 colorSpace, but
stores them in such a way

00:21:40.906 --> 00:21:42.036 A:middle
and with a custom profile,

00:21:42.036 --> 00:21:44.196 A:middle
such that that image will
still display correctly

00:21:44.196 --> 00:21:47.746 A:middle
if your recipient of that
image doesn't support

00:21:47.746 --> 00:21:48.446 A:middle
color management.

00:21:48.826 --> 00:21:50.016 A:middle
So this is a great
feature as well.

00:21:51.566 --> 00:21:55.616 A:middle
Another thing is if you want
to actually create a CGImage

00:21:55.616 --> 00:21:58.296 A:middle
from a CIImage, we have a
new API for that as well

00:21:58.296 --> 00:21:59.296 A:middle
with some new options.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:00.176 --> 00:22:02.116 A:middle
We have this convenience
API which allows you

00:22:02.116 --> 00:22:04.836 A:middle
to specify what the
colorSpace and the pixel format

00:22:04.836 --> 00:22:06.106 A:middle
that you want to render to is.

00:22:07.546 --> 00:22:10.236 A:middle
You may choose, however,
now you to create a CGImage

00:22:10.526 --> 00:22:12.486 A:middle
that has the format of RGBAh,

00:22:12.486 --> 00:22:14.926 A:middle
the Goldilocks pixel format
I was talking about earlier.

00:22:14.926 --> 00:22:17.366 A:middle
And in that case you
might also choose

00:22:17.366 --> 00:22:18.606 A:middle
to use a special color space,

00:22:18.606 --> 00:22:21.126 A:middle
which is the extendedLinearSRGB
space.

00:22:21.326 --> 00:22:23.566 A:middle
Because the pixel format
supports values outside

00:22:23.566 --> 00:22:27.776 A:middle
of the range 0 to 1, you want
your color space to as well.

00:22:28.636 --> 00:22:30.536 A:middle
Another option that we have
that's new is being able

00:22:30.536 --> 00:22:31.816 A:middle
to specify whether the act

00:22:31.816 --> 00:22:34.136 A:middle
of creating the CGImage
does the work

00:22:34.136 --> 00:22:35.746 A:middle
in a deferred or
immediate fashion.

00:22:36.376 --> 00:22:39.746 A:middle
If you specify deferred,
then the work that's involved

00:22:39.746 --> 00:22:43.506 A:middle
in rendering the CIImage
into a CGImage takes place

00:22:43.506 --> 00:22:44.776 A:middle
when the CGImage is drawn.

00:22:45.266 --> 00:22:46.996 A:middle
This is a great way
of minimizing memory,

00:22:47.196 --> 00:22:49.116 A:middle
especially if you're only
going to be drawing part

00:22:49.116 --> 00:22:51.366 A:middle
of that CGImage later,
or if you're only going

00:22:51.366 --> 00:22:52.856 A:middle
to be drawing that CGImage once.

00:22:53.586 --> 00:22:54.946 A:middle
However, if you're
going to be rendering

00:22:54.946 --> 00:22:58.886 A:middle
that image multiple times, you
can specify deferred false,

00:22:59.186 --> 00:23:02.346 A:middle
and in that case Core Image
will do the work of rendering


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:59.186 --> 00:23:02.346 A:middle
and in that case Core Image
will do the work of rendering

00:23:02.346 --> 00:23:04.576 A:middle
into the CGImage at the time
this function is called.

00:23:04.576 --> 00:23:07.796 A:middle
So this is a great new,
flexible API that we have

00:23:07.796 --> 00:23:08.806 A:middle
for your applications.

00:23:10.776 --> 00:23:14.926 A:middle
Another advanced feature of this
Core Image filter API that I'd

00:23:14.926 --> 00:23:17.256 A:middle
like to talk about
today is this.

00:23:17.386 --> 00:23:20.706 A:middle
As I mentioned before, there's
a long stage of pipeline

00:23:20.746 --> 00:23:24.126 A:middle
in processing RAW files, and
a lot of people ask me, well,

00:23:24.126 --> 00:23:27.416 A:middle
how can I add my own
processing to that pipeline.

00:23:27.816 --> 00:23:31.076 A:middle
Well, one common place
where developers will want

00:23:31.076 --> 00:23:33.946 A:middle
to add processing to the
RAW pipeline is somewhere

00:23:33.946 --> 00:23:36.156 A:middle
in the middle; after the
demosaic has occurred,

00:23:36.256 --> 00:23:39.366 A:middle
but before all the nonlinear
operations like sharpening

00:23:39.776 --> 00:23:42.426 A:middle
and contrast and color
boosting has occurred.

00:23:42.726 --> 00:23:44.656 A:middle
So we have an API just for this.

00:23:44.656 --> 00:23:47.456 A:middle
It's a property on the
CIRAWFilter which allows you

00:23:47.456 --> 00:23:49.746 A:middle
to specify a filter
that gets inserted

00:23:49.746 --> 00:23:51.386 A:middle
into the middle of our graph.

00:23:51.476 --> 00:23:54.586 A:middle
So I look forward to seeing what
you guys can imagine and think

00:23:54.586 --> 00:23:56.496 A:middle
of and what can go
into this location.

00:23:58.926 --> 00:24:01.996 A:middle
Some notes on wide-gamut
output that I mentioned before.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:23:58.926 --> 00:24:01.996 A:middle
Some notes on wide-gamut
output that I mentioned before.

00:24:02.496 --> 00:24:06.156 A:middle
The CIKernel language supports
float precision as a language.

00:24:06.696 --> 00:24:09.936 A:middle
However, whenever a
CIFilter needs to render

00:24:09.936 --> 00:24:13.796 A:middle
to an intermediate buffer, we
will use the working format

00:24:13.796 --> 00:24:15.336 A:middle
of the current CIContext.

00:24:16.646 --> 00:24:20.196 A:middle
On macOS the default
working format is RGBA,

00:24:20.196 --> 00:24:21.356 A:middle
our Goldilocks format.

00:24:22.366 --> 00:24:26.386 A:middle
On iOS and tvOS our default
format is still BGRA8,

00:24:26.386 --> 00:24:28.636 A:middle
which is good for performance,

00:24:28.796 --> 00:24:30.656 A:middle
but if you're rendering
extended range data,

00:24:30.996 --> 00:24:33.276 A:middle
that may not be what you want.

00:24:34.266 --> 00:24:38.186 A:middle
Our RAW pipeline, with this
in mind, all of the kernels

00:24:38.186 --> 00:24:43.066 A:middle
in our pipeline force the usage
of RGBA half-float precision,

00:24:43.586 --> 00:24:44.946 A:middle
which is critical for RAW files.

00:24:46.126 --> 00:24:48.566 A:middle
But as you might guess,
if you are concerned

00:24:48.566 --> 00:24:51.216 A:middle
about wide-gamut input
and output and preserving

00:24:51.216 --> 00:24:53.126 A:middle
that data throughout
a rendered graph,

00:24:53.766 --> 00:24:57.586 A:middle
you should modify your CIContext
when you create it to specify

00:24:57.586 --> 00:25:00.496 A:middle
that you want a working
format that is RGBAh.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:24:57.586 --> 00:25:00.496 A:middle
that you want a working
format that is RGBAh.

00:25:01.216 --> 00:25:04.626 A:middle
I should also mention again

00:25:04.626 --> 00:25:06.666 A:middle
that Core Image supports
a wide variety

00:25:06.666 --> 00:25:08.216 A:middle
of wide-gamut output spaces.

00:25:08.216 --> 00:25:12.556 A:middle
For example, you can render to
extendedLinearSRGB or Adobe RGB

00:25:12.556 --> 00:25:16.066 A:middle
or DisplayP3, whatever
format you wish.

00:25:17.546 --> 00:25:18.646 A:middle
Now, as I mentioned before,

00:25:18.646 --> 00:25:20.886 A:middle
I was demonstrating
a 24-megapixel image.

00:25:20.936 --> 00:25:23.026 A:middle
RAW files can be a lot
larger than you might think.

00:25:23.796 --> 00:25:26.286 A:middle
RAW files can be large and
they also require several

00:25:26.286 --> 00:25:28.676 A:middle
intermediate buffers to render
all the stages of the pipeline.

00:25:29.896 --> 00:25:31.756 A:middle
And so it's important
that in order

00:25:31.756 --> 00:25:34.436 A:middle
to reduce the high water
memory mark of your application

00:25:34.436 --> 00:25:37.066 A:middle
that you use some of these APIs
that I've talked about today,

00:25:37.356 --> 00:25:39.866 A:middle
such as turning off caching
intermediates in cases

00:25:39.866 --> 00:25:41.206 A:middle
where you don't need it,

00:25:41.206 --> 00:25:44.106 A:middle
or using the new write JPEG
representation of image,

00:25:44.106 --> 00:25:44.976 A:middle
which is very efficient,

00:25:45.636 --> 00:25:47.436 A:middle
or specifying the
deferred rendering

00:25:47.436 --> 00:25:48.546 A:middle
when creating a CGImage.

00:25:50.006 --> 00:25:53.576 A:middle
Some notes on limits
of RAW files.

00:25:54.786 --> 00:25:58.226 A:middle
On iOS devices with 2
gigabytes of memory or more,

00:25:58.416 --> 00:26:00.896 A:middle
we support RAW files
up to 120 megapixels.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:25:58.416 --> 00:26:00.896 A:middle
we support RAW files
up to 120 megapixels.

00:26:00.896 --> 00:26:01.976 A:middle
So we're really proud to
be able to pull that off.

00:26:02.516 --> 00:26:07.946 A:middle
[ Applause ]

00:26:08.446 --> 00:26:12.976 A:middle
On apps running on devices with
1 gigabyte of memory we support

00:26:13.346 --> 00:26:16.856 A:middle
up to 60 megapixels, which is
also really quite impressive.

00:26:16.856 --> 00:26:19.496 A:middle
And this also holds true for
photo editing extensions,

00:26:19.496 --> 00:26:24.216 A:middle
which run in a lesser
amount of memory.

00:26:24.816 --> 00:26:26.546 A:middle
So that's our discussion of RAW.

00:26:26.546 --> 00:26:28.566 A:middle
Again, I'm super proud to be
able to demonstrate this today.

00:26:28.856 --> 00:26:30.646 A:middle
I would like to hand the
stage over to Etienne

00:26:30.646 --> 00:26:33.056 A:middle
who will be talking about
another great new image format

00:26:33.266 --> 00:26:35.796 A:middle
and how you can edit those in
your application, Live Photos.

00:26:35.796 --> 00:26:35.976 A:middle
Thank you.

00:26:36.516 --> 00:26:42.826 A:middle
[ Applause ]

00:26:43.326 --> 00:26:43.956 A:middle
&gt;&gt; Thank you, David.

00:26:44.326 --> 00:26:44.886 A:middle
Hello everyone.

00:26:45.576 --> 00:26:48.066 A:middle
I'm really excited to be
here today to talk to you

00:26:48.066 --> 00:26:50.226 A:middle
about how you can edit Live
Photos in your application.

00:26:50.536 --> 00:26:54.856 A:middle
So first, we're going to go
over a quick introduction

00:26:55.126 --> 00:26:57.736 A:middle
of what are Live Photos, then
we see what you can edit,

00:26:58.646 --> 00:27:02.996 A:middle
and then we'll go
step-by-step into the code


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:26:58.646 --> 00:27:02.996 A:middle
and then we'll go
step-by-step into the code

00:27:02.996 --> 00:27:06.236 A:middle
and see how you can get
a Live Photo for editing,

00:27:06.896 --> 00:27:10.476 A:middle
how you can then set up a
Live Photo Editing context,

00:27:11.556 --> 00:27:14.066 A:middle
how you can apply Core Image
filters to your Live Photo,

00:27:15.216 --> 00:27:19.196 A:middle
and how you can preview your
Live Photo in your application,

00:27:19.686 --> 00:27:22.926 A:middle
and finally, how you can save
an edited Live Photo back

00:27:22.926 --> 00:27:25.696 A:middle
into the Photo Library, and
we'll finish with a quick demo.

00:27:25.696 --> 00:27:27.036 A:middle
All right.

00:27:27.036 --> 00:27:27.786 A:middle
So let's get started.

00:27:28.546 --> 00:27:32.046 A:middle
So Live Photos, as you may know,

00:27:32.046 --> 00:27:35.396 A:middle
are photos that also include
motion and sound from before

00:27:35.556 --> 00:27:37.406 A:middle
and after the time
of the capture.

00:27:39.066 --> 00:27:42.426 A:middle
And Live Photos can be
captured on the new devices

00:27:42.916 --> 00:27:47.726 A:middle
such as iPhone 6S, 6S Plus,
iPhone SE and iPod Pro.

00:27:47.816 --> 00:27:52.206 A:middle
In fact, Live Photo is
actually a default capture mode

00:27:52.276 --> 00:27:55.036 A:middle
on those devices, so you
can expect your users

00:27:55.266 --> 00:27:57.606 A:middle
to already have plenty of Live
Photos in their Photo Library.

00:27:58.976 --> 00:28:01.466 A:middle
So what's new this
year about Live Photos?


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:27:58.976 --> 00:28:01.466 A:middle
So what's new this
year about Live Photos?

00:28:02.336 --> 00:28:06.366 A:middle
So first, users can now
fully edit their Live Photos

00:28:06.366 --> 00:28:07.206 A:middle
in Photos.

00:28:07.206 --> 00:28:09.676 A:middle
They can apply -- all the
adjustment that they would

00:28:09.676 --> 00:28:11.966 A:middle
to a regular photo they
can apply to a Live Photo.

00:28:13.346 --> 00:28:16.716 A:middle
Next we have a new API
to capture Live Photos

00:28:16.716 --> 00:28:20.136 A:middle
in your application and for
that, for more information

00:28:20.136 --> 00:28:23.496 A:middle
about that, I strongly recommend
that you watch this Advances

00:28:23.496 --> 00:28:26.526 A:middle
in iOS Photography session that
took place earlier this week.

00:28:26.926 --> 00:28:30.026 A:middle
It also includes a lot of
information about Live Photos

00:28:30.026 --> 00:28:31.126 A:middle
from the capturer point of view.

00:28:32.196 --> 00:28:34.596 A:middle
And finally, we have a new
API to edit Live Photos,

00:28:34.596 --> 00:28:36.266 A:middle
and that's why I'm here
to talk about today.

00:28:37.466 --> 00:28:38.036 A:middle
All right.

00:28:38.726 --> 00:28:40.516 A:middle
So what can be edited exactly?

00:28:40.766 --> 00:28:44.186 A:middle
Right. So first, of course,
you can edit the content

00:28:44.186 --> 00:28:47.096 A:middle
of the photo, but
you can also edit all

00:28:47.096 --> 00:28:48.516 A:middle
of the video frames as well.

00:28:49.886 --> 00:28:51.636 A:middle
You can also address
the audio volume,

00:28:53.376 --> 00:28:56.326 A:middle
and you can change the
dimensions of the Live Photo.

00:28:57.226 --> 00:28:58.736 A:middle
Things you can't do though is

00:28:58.736 --> 00:29:00.476 A:middle
that you can't change
the duration


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:28:58.736 --> 00:29:00.476 A:middle
that you can't change
the duration

00:29:00.536 --> 00:29:05.196 A:middle
or the timing of the Live Photo.

00:29:05.196 --> 00:29:09.386 A:middle
So in order to get a Live Photo
for editing, the first thing

00:29:09.386 --> 00:29:12.076 A:middle
to do is to actually get a Live
Photo out of the Photo Library.

00:29:12.076 --> 00:29:13.196 A:middle
So there's two ways to do that,

00:29:13.196 --> 00:29:15.696 A:middle
depending on whether you're
building a photo editing

00:29:15.696 --> 00:29:18.266 A:middle
extension or a PhotoKit
application.

00:29:18.736 --> 00:29:22.156 A:middle
In the case of a photo
editing extension you need

00:29:22.156 --> 00:29:25.026 A:middle
to start first by opting
in to Live Photo editing

00:29:25.026 --> 00:29:28.216 A:middle
by adding the LivePhoto
string in your array

00:29:28.216 --> 00:29:30.786 A:middle
of supported media types
for your extension.

00:29:31.836 --> 00:29:36.146 A:middle
And next, in your implementation
of startContentEditing,

00:29:36.146 --> 00:29:39.596 A:middle
that's called automatically,

00:29:39.986 --> 00:29:43.646 A:middle
you can expect the content
editing input that you receive

00:29:44.136 --> 00:29:47.046 A:middle
and you can check the media
type and the media subtypes

00:29:47.106 --> 00:29:48.776 A:middle
to make sure that
this is a Live Photo.

00:29:50.006 --> 00:29:52.096 A:middle
Okay. On the other hand,

00:29:52.286 --> 00:29:54.096 A:middle
if you're building a
PhotoKit application,

00:29:54.696 --> 00:29:58.336 A:middle
you have to request the
contentEditingInput yourself

00:29:58.336 --> 00:30:01.836 A:middle
from a PHAsset, and then
you can check the media type


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:58.336 --> 00:30:01.836 A:middle
from a PHAsset, and then
you can check the media type

00:30:01.836 --> 00:30:04.586 A:middle
and media subtypes
in the same way.

00:30:04.756 --> 00:30:05.126 A:middle
All right.

00:30:05.176 --> 00:30:08.446 A:middle
So the next step would be to set
up a LivePhotoEditingContext.

00:30:09.076 --> 00:30:12.116 A:middle
A LivePhotoEditingContext
includes all the resources

00:30:12.116 --> 00:30:13.806 A:middle
that are needed to
edit Live Photos.

00:30:14.296 --> 00:30:16.066 A:middle
It includes information
about the Live Photo,

00:30:16.066 --> 00:30:19.096 A:middle
such as its duration,
the time of the photo,

00:30:19.376 --> 00:30:23.686 A:middle
the size of the Live Photo,
also the orientation, all that.

00:30:24.616 --> 00:30:28.026 A:middle
It also has a frame processor
property that you can set

00:30:28.026 --> 00:30:29.936 A:middle
to actually edit the
contents of Live Photo,

00:30:30.096 --> 00:30:33.506 A:middle
and I'll tell you more
about that in a minute.

00:30:33.606 --> 00:30:35.966 A:middle
You can adjust the
audio volume as well.

00:30:36.776 --> 00:30:38.686 A:middle
You can ask the
LivePhotoEditingContext

00:30:38.736 --> 00:30:41.066 A:middle
to prepare a Live
Photo for playback,

00:30:42.516 --> 00:30:46.166 A:middle
and you can ask the
LivePhotoEditingContext to save

00:30:46.416 --> 00:30:47.546 A:middle
and process a Live Photo

00:30:47.546 --> 00:30:48.946 A:middle
for saving back to
the Photo Library.

00:30:50.596 --> 00:30:52.906 A:middle
Creating a
LivePhotoEditingContext is

00:30:52.906 --> 00:30:53.416 A:middle
really easy.

00:30:53.536 --> 00:30:55.456 A:middle
All you need to do is
institute a new one

00:30:55.686 --> 00:30:58.236 A:middle
from a LivePhotoEditingInput
for a Live Photo.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:31:00.586 --> 00:31:00.876 A:middle
All right.

00:31:01.326 --> 00:31:02.916 A:middle
So now let's take a look at how

00:31:02.916 --> 00:31:05.016 A:middle
to use the frame processor
I mentioned earlier.

00:31:06.076 --> 00:31:07.886 A:middle
So the frame of a Live
Photo I'll describe

00:31:07.886 --> 00:31:11.836 A:middle
by a PHLivePhotoFrame object
that contains an input image,

00:31:12.096 --> 00:31:13.856 A:middle
which is a CIImage
for that frame.

00:31:14.966 --> 00:31:18.446 A:middle
Type, which is whether it's a
video frame or a photo frame.

00:31:19.486 --> 00:31:22.186 A:middle
And the time of the
frame in the Live Photo,

00:31:22.186 --> 00:31:24.756 A:middle
as well as the resolution
at which

00:31:24.756 --> 00:31:25.906 A:middle
that frame is being rendered.

00:31:25.996 --> 00:31:32.376 A:middle
In order to implement a frame
processor you would set the

00:31:32.376 --> 00:31:35.436 A:middle
frame processor property on
the LivePhotoEditingContext

00:31:35.816 --> 00:31:40.606 A:middle
to be a block that takes
a frame as parameter

00:31:40.836 --> 00:31:43.956 A:middle
and returns an image
or an error.

00:31:43.956 --> 00:31:47.436 A:middle
And here we just simply return
the input image of the frame,

00:31:47.436 --> 00:31:50.626 A:middle
so that's just necessarily
a node frame processor.

00:31:51.236 --> 00:31:53.416 A:middle
So now let's take a
look at the real case.

00:31:53.986 --> 00:31:57.766 A:middle
This is a Live Photo, as
you can see in Photos,

00:31:58.336 --> 00:32:01.026 A:middle
and I can play it right there.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:31:58.336 --> 00:32:01.026 A:middle
and I can play it right there.

00:32:02.406 --> 00:32:04.156 A:middle
And so let's say we want

00:32:04.156 --> 00:32:07.026 A:middle
to apply a simple basic
adjustment to the Live Photo.

00:32:07.216 --> 00:32:09.466 A:middle
That's start with a
simple square crop.

00:32:10.466 --> 00:32:11.246 A:middle
Here's how to do that.

00:32:12.346 --> 00:32:15.376 A:middle
In the implementation of
your frame processor you want

00:32:15.376 --> 00:32:17.616 A:middle
to start with the input
image for the frame.

00:32:17.956 --> 00:32:19.396 A:middle
Then you compute your crop rect.

00:32:20.966 --> 00:32:24.316 A:middle
Then you crop the image
using [inaudible] here,

00:32:24.316 --> 00:32:27.046 A:middle
which is called the
cropping through rect,

00:32:27.496 --> 00:32:28.996 A:middle
and just return that
cropped image.

00:32:28.996 --> 00:32:32.326 A:middle
That's all it takes to actually
edit and crop the Live Photo.

00:32:32.966 --> 00:32:33.686 A:middle
Here's the result.

00:32:34.896 --> 00:32:37.096 A:middle
I can place side photo, you
can see the photo is cropped,

00:32:37.096 --> 00:32:40.126 A:middle
but the video is also
cropped as I play it.

00:32:41.116 --> 00:32:41.466 A:middle
All right.

00:32:42.006 --> 00:32:45.556 A:middle
So that's an example of a
very basic static adjustment.

00:32:45.926 --> 00:32:49.706 A:middle
Now, what if we want to apply
a more dynamic adjustment,

00:32:49.906 --> 00:32:52.636 A:middle
and that is one that will
actually depend on the time

00:32:53.146 --> 00:32:55.276 A:middle
and will change while the
Live Photo is being played.

00:32:55.436 --> 00:32:56.826 A:middle
So you can do that, too.

00:32:57.166 --> 00:32:59.646 A:middle
So here let's build up
on that crop example

00:32:59.646 --> 00:33:01.106 A:middle
and implement the dynamic crop.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:59.646 --> 00:33:01.106 A:middle
and implement the dynamic crop.

00:33:02.446 --> 00:33:04.386 A:middle
So here's how to do it.

00:33:04.676 --> 00:33:08.666 A:middle
So first we need to capture
a couple of information

00:33:08.666 --> 00:33:12.236 A:middle
about the timing of the Live
Photo, such as the exact time

00:33:12.236 --> 00:33:14.716 A:middle
of the photo because we want
the effect to stay the same

00:33:15.086 --> 00:33:18.266 A:middle
and have your crop rect really
centered on the Live Photo.

00:33:19.026 --> 00:33:23.196 A:middle
Next we take it so we capture
the duration of the Live Photo.

00:33:24.466 --> 00:33:27.046 A:middle
And you can notice
that we do that outside

00:33:27.046 --> 00:33:28.706 A:middle
of the frame processor
block and that's

00:33:28.706 --> 00:33:32.306 A:middle
to avoid cycling dependency.

00:33:33.146 --> 00:33:37.636 A:middle
Here in the block we can ask for
the exact time of that frame,

00:33:37.966 --> 00:33:40.676 A:middle
and then we can build a
function of time using all

00:33:40.676 --> 00:33:42.946 A:middle
that information to
drive a crop rect.

00:33:44.526 --> 00:33:46.456 A:middle
And here's what the result.

00:33:46.456 --> 00:33:48.746 A:middle
So you can see the Live Photo
is cropped the same way,

00:33:48.746 --> 00:33:50.806 A:middle
the photo is the same,
but when I play it,

00:33:51.316 --> 00:33:56.446 A:middle
you can see that the crop rect
now moves from bottom to top.

00:33:56.636 --> 00:33:56.926 A:middle
All right.

00:33:56.926 --> 00:33:59.506 A:middle
So that's an example of
a time-based adjustment.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:00.606 --> 00:34:02.186 A:middle
Now let's take a look
at something else.

00:34:03.046 --> 00:34:05.036 A:middle
This effect is interesting

00:34:05.236 --> 00:34:07.936 A:middle
because it's a
resolution-dependent effect.

00:34:08.335 --> 00:34:13.835 A:middle
What I mean by that is that the
way the filter parameters are

00:34:13.835 --> 00:34:17.005 A:middle
specified, they're
specified in pixels, right,

00:34:17.005 --> 00:34:19.545 A:middle
which mean that you
need to be extra careful

00:34:19.545 --> 00:34:21.536 A:middle
when you apply these kind
of effects to make sure

00:34:21.536 --> 00:34:24.726 A:middle
that the effect is visually
consistent regardless

00:34:24.726 --> 00:34:27.356 A:middle
of the resolution at which the
Live Photo is being rendered.

00:34:27.766 --> 00:34:30.616 A:middle
So here if I play it, you
can see that the video --

00:34:30.616 --> 00:34:32.106 A:middle
the effect is applied

00:34:32.106 --> 00:34:33.795 A:middle
to the video the same way
it's applied to the photos.

00:34:33.795 --> 00:34:34.286 A:middle
So that's great.

00:34:34.585 --> 00:34:36.996 A:middle
So let's see how to
do that correctly.

00:34:38.096 --> 00:34:41.126 A:middle
So in your frame processor
you want to pay attention

00:34:41.126 --> 00:34:43.565 A:middle
to this renderScale
property on the frame.

00:34:43.916 --> 00:34:46.326 A:middle
This will give you
the resolution

00:34:46.326 --> 00:34:48.436 A:middle
of the current frame compared

00:34:48.436 --> 00:34:52.755 A:middle
to the one-to-one full-size
still image in the Live Photo.

00:34:53.545 --> 00:34:57.406 A:middle
So keep in mind that
the video frames

00:34:57.406 --> 00:34:59.606 A:middle
and the photo are
different size as well.

00:34:59.606 --> 00:35:02.176 A:middle
Right. Usually the video is
way smaller than the photo is.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:59.606 --> 00:35:02.176 A:middle
Right. Usually the video is
way smaller than the photo is.

00:35:02.176 --> 00:35:04.806 A:middle
So you want to make sure
to apply that correctly.

00:35:05.106 --> 00:35:09.606 A:middle
In order to do that, you can
use the scale here to scale

00:35:09.606 --> 00:35:12.866 A:middle
down that width parameter
so that at one-to-one

00:35:12.866 --> 00:35:15.166 A:middle
on the full-size photo
the parameter will be 50,

00:35:15.166 --> 00:35:17.706 A:middle
but it will be smaller on
the smaller resolution.

00:35:18.696 --> 00:35:24.046 A:middle
Another way to apply your
resolution-dependent adjustment

00:35:24.046 --> 00:35:30.246 A:middle
is to use the extent of
the image like I do here

00:35:30.846 --> 00:35:32.286 A:middle
for the inputCenter parameter.

00:35:32.506 --> 00:35:35.986 A:middle
I actually use the midpoint of
the image and that's granted

00:35:35.986 --> 00:35:37.346 A:middle
to also scale [inaudible].

00:35:38.216 --> 00:35:39.686 A:middle
All right.

00:35:40.266 --> 00:35:42.716 A:middle
One more edit on that image.

00:35:43.776 --> 00:35:48.696 A:middle
You can notice that I did a logo
here that might be familiar,

00:35:49.036 --> 00:35:52.006 A:middle
and when I play it, you see

00:35:52.006 --> 00:35:54.126 A:middle
that the logo actually
disappears from the video.

00:35:54.126 --> 00:35:59.056 A:middle
So this is how you would apply
an adjustment just to the photo

00:35:59.056 --> 00:36:01.676 A:middle
and not to the video,
and here's how to do it.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:35:59.056 --> 00:36:01.676 A:middle
and not to the video,
and here's how to do it.

00:36:02.156 --> 00:36:06.736 A:middle
In your implementation of your
frame processor you want to look

00:36:06.736 --> 00:36:10.516 A:middle
at the frame type, and here
we just check if it's a photo,

00:36:10.786 --> 00:36:12.006 A:middle
then we composite the still logo

00:36:12.006 --> 00:36:15.506 A:middle
into the image, but
not on the video.

00:36:15.736 --> 00:36:16.926 A:middle
So that's as easy as that.

00:36:17.386 --> 00:36:19.986 A:middle
And you may have, you
know, some adjustments

00:36:19.986 --> 00:36:22.716 A:middle
that are local advertisement or
single ad that you don't want

00:36:22.716 --> 00:36:24.556 A:middle
to apply or you can't
apply to the video,

00:36:24.806 --> 00:36:28.206 A:middle
and so that's a good
way to do it.

00:36:28.466 --> 00:36:28.756 A:middle
All right.

00:36:29.246 --> 00:36:31.086 A:middle
Now that we have an
edited Live Photo,

00:36:32.166 --> 00:36:35.946 A:middle
let's see how we can
preview it in our app.

00:36:36.186 --> 00:36:39.766 A:middle
So in order to preview a
Live Photo you want to work

00:36:39.766 --> 00:36:40.946 A:middle
with the PHLivePhotoView.

00:36:41.426 --> 00:36:44.316 A:middle
So this view is readily
available on iOS

00:36:44.316 --> 00:36:46.696 A:middle
and is new this year on macOS.

00:36:48.446 --> 00:36:50.826 A:middle
So in order to preview
Live Photo you need

00:36:50.826 --> 00:36:53.406 A:middle
to ask the
LivePhotoEditingContext

00:36:53.406 --> 00:36:56.666 A:middle
to prepare a Live Photo
for playback and you pass

00:36:56.666 --> 00:37:01.966 A:middle
in the target size, which is
typically the size of your view


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:36:56.666 --> 00:37:01.966 A:middle
in the target size, which is
typically the size of your view

00:37:01.966 --> 00:37:06.076 A:middle
in pixels, and then you get
called back asynchronously

00:37:06.076 --> 00:37:09.056 A:middle
on the main thread with
a rendered Live Photo.

00:37:10.456 --> 00:37:13.066 A:middle
And then all you need to do
is set the Live Photo property

00:37:13.066 --> 00:37:17.136 A:middle
of the LivePhotoView so that
your users can now interact

00:37:17.136 --> 00:37:19.816 A:middle
with their Live Photo
and get an idea

00:37:19.816 --> 00:37:24.436 A:middle
of what the edited Live
Photo will look like.

00:37:24.436 --> 00:37:27.576 A:middle
Now, the final set will be to
save back to the Photo Library.

00:37:27.766 --> 00:37:32.476 A:middle
And that, again, depends whether
you're building a photo editing

00:37:32.476 --> 00:37:34.786 A:middle
extension or a PhotoKit
application.

00:37:36.066 --> 00:37:39.026 A:middle
In the case of a photo
editing extension you will

00:37:39.026 --> 00:37:40.456 A:middle
implement finishContentEditing.

00:37:41.086 --> 00:37:45.346 A:middle
And the first step is to create
a new contentEditingOutput

00:37:45.806 --> 00:37:48.526 A:middle
from that contentEditingInput
that you received earlier.

00:37:49.876 --> 00:37:53.266 A:middle
And next you will ask your
LivePhotoEditingContext

00:37:53.266 --> 00:37:55.206 A:middle
to save the Live
Photo to that output.

00:37:55.726 --> 00:37:59.156 A:middle
And again, that will process
the full resolution Live Photo

00:37:59.556 --> 00:38:02.226 A:middle
asynchronously and call
you back on the main thread


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:37:59.556 --> 00:38:02.226 A:middle
asynchronously and call
you back on the main thread

00:38:02.346 --> 00:38:05.176 A:middle
with success or error.

00:38:05.456 --> 00:38:07.626 A:middle
And in the case everything
goes fine,

00:38:08.206 --> 00:38:11.186 A:middle
make sure you save also
your adjustment data along

00:38:11.276 --> 00:38:15.116 A:middle
with your edits and that will
allow your users to go back

00:38:15.286 --> 00:38:20.536 A:middle
to your app or extension later
and continue editing there.

00:38:20.736 --> 00:38:22.756 A:middle
And then last step is

00:38:22.756 --> 00:38:24.266 A:middle
to actually call the
completionHandler

00:38:24.266 --> 00:38:25.886 A:middle
for that extension
and you're done.

00:38:27.306 --> 00:38:29.086 A:middle
If you're building a
PhotoKit application,

00:38:29.566 --> 00:38:31.756 A:middle
the steps are really similar.

00:38:32.356 --> 00:38:35.926 A:middle
The only difference really
that you have to make your --

00:38:35.926 --> 00:38:38.966 A:middle
they are from the changes
[inaudible] yourself using

00:38:38.966 --> 00:38:40.306 A:middle
a PHAssetChangeRequest.

00:38:40.306 --> 00:38:40.806 A:middle
All right.

00:38:41.516 --> 00:38:42.976 A:middle
So now I'd like to
show you a quick demo.

00:38:52.456 --> 00:38:53.036 A:middle
All right.

00:38:54.156 --> 00:38:58.326 A:middle
So I've built a simple demo
Live Photo extension that I'd

00:38:58.326 --> 00:38:59.146 A:middle
like to show you today.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:39:00.046 --> 00:39:03.656 A:middle
So here I am in Photos and I can
see a couple Live Photos here,

00:39:04.136 --> 00:39:06.286 A:middle
can pick to see the contents.

00:39:07.216 --> 00:39:09.506 A:middle
I can swipe and see
them animate.

00:39:10.296 --> 00:39:10.586 A:middle
All right.

00:39:10.586 --> 00:39:11.936 A:middle
That's the one I
want to edit today.

00:39:12.746 --> 00:39:13.806 A:middle
So I can go to edit.

00:39:13.806 --> 00:39:14.966 A:middle
And as I mentioned earlier,

00:39:15.296 --> 00:39:18.216 A:middle
I can actually edit the Live
Photo right there in Photos.

00:39:18.586 --> 00:39:19.296 A:middle
Let me do that.

00:39:19.596 --> 00:39:22.096 A:middle
I'd like to apply
this new light slider

00:39:22.206 --> 00:39:23.766 A:middle
that David mentioned earlier.

00:39:24.946 --> 00:39:25.366 A:middle
All right.

00:39:26.456 --> 00:39:29.786 A:middle
So here in Photos I
can just play that.

00:39:31.696 --> 00:39:35.766 A:middle
Right. Of course, I could
stop here, but I actually want

00:39:35.766 --> 00:39:38.116 A:middle
to apply my sample
edits as well.

00:39:38.116 --> 00:39:40.966 A:middle
So I'm going to pick
my extension here.

00:39:46.056 --> 00:39:50.806 A:middle
And, yes, we actually apply the
same adjustment that we went

00:39:50.806 --> 00:39:51.646 A:middle
through for the slides.

00:39:52.406 --> 00:39:55.956 A:middle
And you can see this is
really a simple extension,

00:39:56.176 --> 00:39:59.156 A:middle
but it shows a LivePhotoView,
so I can interact with this

00:39:59.156 --> 00:40:01.736 A:middle
and I can actually press
to play it, like this,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:39:59.156 --> 00:40:01.736 A:middle
and I can actually press
to play it, like this,

00:40:02.106 --> 00:40:03.136 A:middle
right in my extension.

00:40:03.956 --> 00:40:05.146 A:middle
So that's real easy.

00:40:05.146 --> 00:40:08.556 A:middle
And the next step is to actually
save by hitting Done here.

00:40:09.556 --> 00:40:13.146 A:middle
And this is going to process
a full resolution Live Photo

00:40:13.986 --> 00:40:15.296 A:middle
and send it back to
the Photo Library.

00:40:16.416 --> 00:40:18.176 A:middle
And there it is,
right there in Photos.

00:40:19.756 --> 00:40:20.366 A:middle
All right.

00:40:21.556 --> 00:40:22.996 A:middle
So that was for the quick demo.

00:40:22.996 --> 00:40:23.966 A:middle
Now back to slides.

00:40:24.516 --> 00:40:29.886 A:middle
[ Applause ]

00:40:30.386 --> 00:40:30.756 A:middle
Thank you.

00:40:31.386 --> 00:40:32.326 A:middle
All right.

00:40:32.326 --> 00:40:35.646 A:middle
So here's a quick summary of
what we've learned so far today.

00:40:36.546 --> 00:40:39.326 A:middle
So we've learned how
to get a Live Photo

00:40:39.466 --> 00:40:44.326 A:middle
out of the Photo Library
and how to use and set

00:40:44.326 --> 00:40:47.686 A:middle
up a LivePhotoEditingContext,
how to use a frame processor

00:40:47.916 --> 00:40:50.256 A:middle
to edit the contents
of the Live Photo.

00:40:51.036 --> 00:40:53.226 A:middle
We've seen how to
preview a Live Photo

00:40:53.226 --> 00:40:56.146 A:middle
in your app using
the LivePhotoView.

00:40:57.236 --> 00:41:00.396 A:middle
And we've seen how to
save a Live Photo back


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:40:57.236 --> 00:41:00.396 A:middle
And we've seen how to
save a Live Photo back

00:41:00.396 --> 00:41:03.156 A:middle
into the Photo Library.

00:41:03.296 --> 00:41:05.966 A:middle
Now I can't wait to see what
you will do with this new API.

00:41:07.116 --> 00:41:08.226 A:middle
A few things to remember.

00:41:08.226 --> 00:41:12.406 A:middle
First, if you're building
a photo editing extension,

00:41:12.406 --> 00:41:15.486 A:middle
do not forget to opt
in to LivePhotoEditing

00:41:15.486 --> 00:41:17.306 A:middle
in your info.plist
for your extension.

00:41:17.446 --> 00:41:19.856 A:middle
Otherwise, you'll get a still
image instead of a Live Photo.

00:41:20.966 --> 00:41:24.516 A:middle
And as I said, make sure you
always save adjustment data

00:41:24.956 --> 00:41:28.526 A:middle
as well so that your users
can go back to your app

00:41:28.526 --> 00:41:30.396 A:middle
and continue the edit
nondestructively.

00:41:31.686 --> 00:41:36.376 A:middle
Finally, I think if you
already have an image editing

00:41:36.376 --> 00:41:40.956 A:middle
application, adopting Live
Photo and adding support

00:41:40.956 --> 00:41:44.496 A:middle
for LivePhotoEditing should be
really easy with this new API,

00:41:45.096 --> 00:41:47.986 A:middle
especially if your app is
using Core Image already.

00:41:48.486 --> 00:41:52.066 A:middle
And if not, there's actually
a new API in Core Image

00:41:52.066 --> 00:41:54.926 A:middle
to let you integrate your
own custom processing

00:41:54.926 --> 00:41:55.766 A:middle
into Core Image.

00:41:56.156 --> 00:41:57.886 A:middle
And to tell you all about it,

00:41:57.886 --> 00:41:59.796 A:middle
I'd like to invite
Alex on stage.

00:41:59.796 --> 00:41:59.976 A:middle
Thank you.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:42:00.516 --> 00:42:06.546 A:middle
[ Applause ]

00:42:07.046 --> 00:42:07.566 A:middle
&gt;&gt; Thank you, Etienne.

00:42:08.146 --> 00:42:10.156 A:middle
So my name is Alexandre Naaman,
and today I'm going to talk

00:42:10.156 --> 00:42:11.926 A:middle
to you about some new
functionality we have inside

00:42:11.926 --> 00:42:14.026 A:middle
of Core Image to do
additional effects

00:42:14.026 --> 00:42:15.646 A:middle
that weren't possible
previously, and that's going

00:42:15.646 --> 00:42:18.486 A:middle
to be using a new API
called CIImageProcessor.

00:42:19.826 --> 00:42:22.596 A:middle
As David mentioned earlier,
there's a lot you can do inside

00:42:22.596 --> 00:42:26.486 A:middle
of Core Image using our
existing built-in 180 filters,

00:42:26.706 --> 00:42:28.656 A:middle
and you can extend
that even further

00:42:28.656 --> 00:42:30.136 A:middle
by writing your own
custom kernels.

00:42:30.896 --> 00:42:33.826 A:middle
Now with CIImageProcessor
we can do even more,

00:42:34.486 --> 00:42:38.316 A:middle
and we can insert a new node
inside of our render graph

00:42:39.026 --> 00:42:42.186 A:middle
that can do basically
anything we want and will fit

00:42:42.186 --> 00:42:43.556 A:middle
in perfectly with
the existing graph.

00:42:43.556 --> 00:42:47.436 A:middle
So we can write our own custom
CPU code or custom Metal code.

00:42:48.696 --> 00:42:52.386 A:middle
So there are some analogies
when using CIImageProcessor

00:42:53.136 --> 00:42:54.786 A:middle
with writing general kernels.

00:42:54.936 --> 00:42:57.466 A:middle
So in the past you would
write a general kernel,

00:42:57.466 --> 00:43:02.026 A:middle
specify some string, and then
override the output image method


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:42:57.466 --> 00:43:02.026 A:middle
specify some string, and then
override the output image method

00:43:02.406 --> 00:43:07.136 A:middle
on your CIFilter and
provide the extent,

00:43:07.136 --> 00:43:09.046 A:middle
which is the output image
size that you're going

00:43:09.046 --> 00:43:12.076 A:middle
to be creating, and
an roiCallback,

00:43:13.676 --> 00:43:16.686 A:middle
and then finally whatever
arguments you need

00:43:16.686 --> 00:43:18.406 A:middle
to pass to your kernel.

00:43:19.566 --> 00:43:22.136 A:middle
Now, there are a
lot of similarities

00:43:22.356 --> 00:43:24.836 A:middle
with creating CIImageProcessors,
and we're not going to go

00:43:24.836 --> 00:43:27.166 A:middle
into detail with them
about that today.

00:43:27.486 --> 00:43:30.656 A:middle
Instead we refer
you to Session 515

00:43:30.656 --> 00:43:32.886 A:middle
from our WWDC talk from 2014.

00:43:33.206 --> 00:43:35.426 A:middle
So if you want to
create CIImageProcessors,

00:43:35.426 --> 00:43:38.036 A:middle
we strongly suggest you go
and look back at that talk

00:43:38.036 --> 00:43:40.346 A:middle
because we talked about
how to deal with the extent

00:43:40.396 --> 00:43:43.286 A:middle
and ROI parameters
in great length.

00:43:45.536 --> 00:43:46.876 A:middle
So now let's look
at what the API

00:43:47.066 --> 00:43:49.036 A:middle
for creating a CIImage
Processor looks like,

00:43:50.266 --> 00:43:52.026 A:middle
and this may change a
little bit in future seeds,

00:43:52.026 --> 00:43:53.956 A:middle
but this is what it
looks like right now.

00:43:55.066 --> 00:43:56.666 A:middle
So the similarities are there.

00:43:56.666 --> 00:43:57.846 A:middle
We need to provide the extent,

00:43:57.846 --> 00:43:59.666 A:middle
which is the output image size
we're going to be producing,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:44:00.016 --> 00:44:02.946 A:middle
give it an input
image, and the ROI.

00:44:04.036 --> 00:44:06.386 A:middle
There are a bunch of additional
parameters we need to provide,

00:44:06.386 --> 00:44:09.586 A:middle
however, such as, for example,
the description of the node

00:44:09.586 --> 00:44:10.206 A:middle
that we'll be creating.

00:44:11.476 --> 00:44:14.606 A:middle
We then need to provide a
digest with some sort of hash

00:44:14.606 --> 00:44:15.906 A:middle
of all our input parameters.

00:44:16.206 --> 00:44:18.066 A:middle
And this is really
important for Core Image

00:44:18.066 --> 00:44:20.226 A:middle
because this is how Core
Image determines whether

00:44:20.226 --> 00:44:22.636 A:middle
or not we can cache the
values or not, and whether

00:44:22.636 --> 00:44:23.746 A:middle
or not we need to rerender.

00:44:24.316 --> 00:44:25.316 A:middle
So you need to make sure

00:44:25.316 --> 00:44:27.146 A:middle
that every time your
parameter changes,

00:44:27.726 --> 00:44:28.956 A:middle
that you update the hash.

00:44:30.306 --> 00:44:34.656 A:middle
The next thing we can
specify is an input format.

00:44:34.966 --> 00:44:37.196 A:middle
In this case here
we've used BGRA8,

00:44:38.826 --> 00:44:40.356 A:middle
but you can also specify zero,

00:44:40.356 --> 00:44:43.256 A:middle
which means you'll get the
working format for the context

00:44:43.256 --> 00:44:46.286 A:middle
as an input image format.

00:44:46.696 --> 00:44:48.716 A:middle
You can specify the
output format as well.

00:44:49.146 --> 00:44:51.356 A:middle
In this case we're using
RGBAf because the example

00:44:51.356 --> 00:44:53.696 A:middle
that we're going to be going
over in more detail needs a lot

00:44:53.696 --> 00:44:55.276 A:middle
of precision, so we'll
need full flow here.

00:44:56.306 --> 00:44:58.466 A:middle
And then finally we get
to our processor block,

00:44:58.466 --> 00:45:00.426 A:middle
which is where we have
exactly two parameters;


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:44:58.466 --> 00:45:00.426 A:middle
which is where we have
exactly two parameters;

00:45:00.966 --> 00:45:05.596 A:middle
our CIImageProcessorInput
and CIImageProcessorOutput,

00:45:06.786 --> 00:45:08.956 A:middle
and it's inside of here that
we can do all the work we need

00:45:08.956 --> 00:45:09.246 A:middle
to do.

00:45:10.416 --> 00:45:12.396 A:middle
So let's take a look
at how we can do this,

00:45:13.056 --> 00:45:14.106 A:middle
and why you would
want to do this.

00:45:16.236 --> 00:45:19.616 A:middle
So CIImageProcessor
is particularly useful

00:45:19.616 --> 00:45:22.876 A:middle
for when you have some algorithm
or you want to use a library

00:45:23.216 --> 00:45:26.216 A:middle
that implements something
outside of Core Image

00:45:26.416 --> 00:45:27.556 A:middle
and something that
isn't suitable

00:45:27.556 --> 00:45:28.636 A:middle
for the CIKernel language.

00:45:28.886 --> 00:45:31.936 A:middle
A really good example of this is
what we call an integral image.

00:45:32.746 --> 00:45:35.296 A:middle
An integral image is an image
whereby the output pixel

00:45:35.606 --> 00:45:37.896 A:middle
contains the sum of
all the pixels above it

00:45:37.896 --> 00:45:39.446 A:middle
and to the left,
including itself.

00:45:39.806 --> 00:45:42.716 A:middle
And this is a very good
example of the kind of thing

00:45:42.716 --> 00:45:45.716 A:middle
that can't be done in a
data parallel-type shader,

00:45:46.056 --> 00:45:47.296 A:middle
which is the kind of
shader that you write

00:45:47.296 --> 00:45:48.626 A:middle
when you're writing CIKernels.

00:45:50.976 --> 00:45:54.286 A:middle
So let's take a look at
what an integral image is

00:45:54.286 --> 00:45:55.136 A:middle
in a little bit more detail.

00:45:55.136 --> 00:45:57.946 A:middle
If we start off with the input
image on the left, which,

00:45:57.946 --> 00:46:01.386 A:middle
let's say, corresponds to some
single channel, 8-bit data,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:45:57.946 --> 00:46:01.386 A:middle
let's say, corresponds to some
single channel, 8-bit data,

00:46:02.716 --> 00:46:04.596 A:middle
our integral image would
be the image on the right.

00:46:04.826 --> 00:46:07.366 A:middle
So if we take a look
at this pixel here, 7,

00:46:07.896 --> 00:46:11.146 A:middle
it actually corresponds to
the sum of all of those pixels

00:46:11.146 --> 00:46:14.216 A:middle
on the left, which would
be 1 plus 4 plus 0 plus 2.

00:46:15.016 --> 00:46:19.026 A:middle
The same goes for this other
pixel; 45 corresponds to the sum

00:46:19.026 --> 00:46:22.196 A:middle
of all those other pixels above
it and to the left, plus itself.

00:46:25.266 --> 00:46:29.146 A:middle
So now let's take a look
at what you would do inside

00:46:29.146 --> 00:46:33.346 A:middle
of the image processor block
if you were writing a CPU code,

00:46:33.966 --> 00:46:36.716 A:middle
and you could also use V Image
or any number of other libraries

00:46:36.716 --> 00:46:37.516 A:middle
that we have on the system.

00:46:38.996 --> 00:46:39.866 A:middle
So first things first.

00:46:40.506 --> 00:46:42.516 A:middle
We're going to get some
pointers back to our input data.

00:46:42.996 --> 00:46:45.596 A:middle
So from the
CIImageProcessorInput we'll get

00:46:45.596 --> 00:46:47.956 A:middle
the base address,
and we'll make sure

00:46:47.956 --> 00:46:50.586 A:middle
that we use 8-bit
data, so UInt8.

00:46:50.586 --> 00:46:52.816 A:middle
And then we'll get
our outputPointer,

00:46:52.816 --> 00:46:54.426 A:middle
which is where we're going
to write all of our results

00:46:54.826 --> 00:46:56.246 A:middle
as float, because we specified

00:46:56.246 --> 00:46:58.036 A:middle
that we wanted to
write to RGBAf.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:47:00.366 --> 00:47:04.526 A:middle
The next thing we do
is we make sure to deal

00:47:04.526 --> 00:47:06.996 A:middle
with the relative offsets of
our input and output image.

00:47:07.796 --> 00:47:10.426 A:middle
It's highly likely that
Core Image will provide you

00:47:10.426 --> 00:47:13.386 A:middle
with an input image that
is going to be larger,

00:47:13.386 --> 00:47:16.026 A:middle
or at least not equivalent
to your output image,

00:47:16.026 --> 00:47:19.016 A:middle
so you have to take care of
whatever offset might be in play

00:47:19.626 --> 00:47:22.126 A:middle
when you're creating your output
image and doing your four loops.

00:47:22.716 --> 00:47:25.046 A:middle
And in this case,
once we have figured

00:47:25.046 --> 00:47:27.276 A:middle
out whatever offsets
we need, we can then go

00:47:27.276 --> 00:47:30.226 A:middle
and execute our four-loop to
calculate the output values

00:47:30.226 --> 00:47:33.996 A:middle
at location i, j by using
the input at location i, j,

00:47:34.086 --> 00:47:35.266 A:middle
plus whatever offset we had.

00:47:38.706 --> 00:47:41.426 A:middle
Now that we've seen how to do
this with a custom CPU loop,

00:47:41.426 --> 00:47:44.246 A:middle
let's take a look at how
this can be done using Metal.

00:47:44.396 --> 00:47:47.836 A:middle
In this case we're going to be
using Metal Performance Shaders.

00:47:49.176 --> 00:47:50.266 A:middle
And there's a great
primitive inside

00:47:50.266 --> 00:47:51.096 A:middle
of Metal Performance Shaders

00:47:51.126 --> 00:47:53.926 A:middle
to compute integral images
called MPSImageIntegral.

00:47:55.266 --> 00:47:59.176 A:middle
From our CIImageProcessorOutput
we can get the commandBuffer,

00:47:59.686 --> 00:48:02.266 A:middle
the Metal command buffer, so we
just create an MPSImageIntegral


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:47:59.686 --> 00:48:02.266 A:middle
the Metal command buffer, so we
just create an MPSImageIntegral

00:48:02.686 --> 00:48:03.786 A:middle
with that commandBuffer.

00:48:05.286 --> 00:48:07.856 A:middle
Once again we take care of
whatever offsets we may need

00:48:07.856 --> 00:48:11.766 A:middle
to deal with, and then we
simply encode that kernel

00:48:11.976 --> 00:48:14.226 A:middle
to the commandBuffer,
and providing

00:48:14.226 --> 00:48:16.186 A:middle
as input the input
texture that we get

00:48:16.186 --> 00:48:17.466 A:middle
from the CIImageProcessorInput,

00:48:17.956 --> 00:48:20.756 A:middle
and as a destination
the output.MetalTexture.

00:48:21.356 --> 00:48:24.486 A:middle
And this is how we can use
Metal very simply inside

00:48:24.486 --> 00:48:26.096 A:middle
of an existing CIFilter graph.

00:48:27.376 --> 00:48:29.336 A:middle
So now let's take a look
at what we can actually do

00:48:29.336 --> 00:48:30.616 A:middle
with this integral image
now that we have it.

00:48:31.796 --> 00:48:33.526 A:middle
So let's say we start
with an image like this.

00:48:33.686 --> 00:48:36.396 A:middle
Our goal is going to be
to produce a new image

00:48:37.636 --> 00:48:40.706 A:middle
where we have a per
pixel variable box blur.

00:48:41.256 --> 00:48:44.106 A:middle
So each pixel in that image
can have a different amount

00:48:44.106 --> 00:48:44.966 A:middle
of blur applied to it,

00:48:45.176 --> 00:48:48.576 A:middle
and we can do this really
quickly using an integral image.

00:48:51.006 --> 00:48:53.626 A:middle
So, as I was saying, box
blurs are very useful

00:48:54.666 --> 00:48:56.656 A:middle
for doing very fast box sums.

00:48:57.036 --> 00:48:58.896 A:middle
So if we start right off with
this input image and we wanted

00:48:58.896 --> 00:49:02.336 A:middle
to get the sum of those nine
pixels, traditionally speaking,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:48:58.896 --> 00:49:02.336 A:middle
to get the sum of those nine
pixels, traditionally speaking,

00:49:02.896 --> 00:49:04.116 A:middle
this would require nine reads,

00:49:04.606 --> 00:49:06.146 A:middle
which means it's an
n squared problem.

00:49:06.906 --> 00:49:10.056 A:middle
That's obviously not
going to be very fast.

00:49:11.856 --> 00:49:12.706 A:middle
That's not completely true.

00:49:12.706 --> 00:49:14.046 A:middle
If you were a little
more smart about it,

00:49:14.106 --> 00:49:16.516 A:middle
you could probably do this as
a multipass approach and do it

00:49:16.516 --> 00:49:18.706 A:middle
in two n reads, but that
still means you're looking

00:49:18.706 --> 00:49:21.946 A:middle
at six reads, and obviously
that doesn't scale very well.

00:49:23.646 --> 00:49:25.776 A:middle
With an integral image,
however, we can just --

00:49:26.136 --> 00:49:29.596 A:middle
if we want to get the sum of
those nine pixels, we just have

00:49:29.596 --> 00:49:30.776 A:middle
to read at a few locations.

00:49:30.776 --> 00:49:35.316 A:middle
We will read at the lower right
corner and then we can read

00:49:35.716 --> 00:49:39.216 A:middle
from just one pixel off to the
left, the sum of all the values,

00:49:39.936 --> 00:49:42.816 A:middle
and subtract that from the
first value we just read.

00:49:43.856 --> 00:49:47.006 A:middle
And then we read at a pixel
right above where we need to be

00:49:47.006 --> 00:49:49.036 A:middle
and subtract the row which
corresponds to the sum

00:49:49.036 --> 00:49:50.276 A:middle
of all the pixels
up to that stage.

00:49:50.606 --> 00:49:52.556 A:middle
But now you can see we've
highlighted the upper left

00:49:52.556 --> 00:49:54.996 A:middle
corner with a 1 because we've
subtracted that value twice,

00:49:54.996 --> 00:49:56.106 A:middle
so we need to add it back in.

00:49:57.556 --> 00:50:03.226 A:middle
So what this means is we can
create an arbitrarily-sized box


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:49:57.556 --> 00:50:03.226 A:middle
So what this means is we can
create an arbitrarily-sized box

00:50:03.276 --> 00:50:05.476 A:middle
blur with just four reads.

00:50:05.566 --> 00:50:08.126 A:middle
And if we were to --

00:50:09.016 --> 00:50:10.476 A:middle
[ Applause ]

00:50:10.476 --> 00:50:10.766 A:middle
Thank you.

00:50:11.146 --> 00:50:13.146 A:middle
[ Applause ]

00:50:13.276 --> 00:50:15.216 A:middle
If we were to actually do the
math manually, you could see

00:50:15.216 --> 00:50:16.396 A:middle
that these numbers do add up.

00:50:16.396 --> 00:50:19.796 A:middle
So 2 plus 4 plus 6, et cetera,
is equal to the exact same thing

00:50:19.796 --> 00:50:22.926 A:middle
as 66 minus 10 minus 13 plus 1.

00:50:26.896 --> 00:50:30.216 A:middle
Now let's jump back into
Core Image kernel language

00:50:30.416 --> 00:50:31.996 A:middle
and see how we can
use our integral image

00:50:31.996 --> 00:50:34.316 A:middle
that we've computed
either with a CPU code

00:50:34.866 --> 00:50:37.076 A:middle
or using the Metal
Performance Shader primitives

00:50:38.406 --> 00:50:39.336 A:middle
and continue doing the work

00:50:39.336 --> 00:50:40.836 A:middle
of actually creating
the box blur effect.

00:50:41.376 --> 00:50:42.956 A:middle
So the first thing we're
going to do is we're going

00:50:42.956 --> 00:50:44.486 A:middle
to compute our lower left corner

00:50:44.486 --> 00:50:47.036 A:middle
and upper right corner
from our image.

00:50:47.036 --> 00:50:50.546 A:middle
Those will tell us where we
need to subtract and add from.

00:50:51.696 --> 00:50:54.596 A:middle
We're then going to compute
a few additional values

00:50:54.596 --> 00:50:57.816 A:middle
and they're going to help us
determine what the alpha value

00:50:57.966 --> 00:50:59.446 A:middle
should be, so how
transparent the pixel

00:50:59.446 --> 00:51:00.856 A:middle
that we're currently
trying to produce is.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:50:59.446 --> 00:51:00.856 A:middle
that we're currently
trying to produce is.

00:51:01.956 --> 00:51:05.596 A:middle
We take our four
samples, the four corners,

00:51:07.306 --> 00:51:10.786 A:middle
and then finally we do our
additions and subtractions

00:51:10.786 --> 00:51:13.226 A:middle
and multiply by what we've
decided is the appropriate

00:51:13.226 --> 00:51:15.576 A:middle
amount of transparency
for this output pixel.

00:51:16.846 --> 00:51:22.056 A:middle
Now, this particular kernel
takes a single parameter

00:51:22.056 --> 00:51:24.906 A:middle
as an input radius, which
would mean that if you were

00:51:24.906 --> 00:51:25.906 A:middle
to call this on an
image, you would get

00:51:25.906 --> 00:51:28.386 A:middle
that same radius applied
to the entire image,

00:51:29.036 --> 00:51:33.836 A:middle
but we can very simply go and
create a variable box blur

00:51:34.036 --> 00:51:37.396 A:middle
by passing in a mask image,
and we can use this mask image

00:51:37.446 --> 00:51:41.716 A:middle
to determine how large
the radius should be

00:51:41.716 --> 00:51:42.906 A:middle
on a per pixel basis.

00:51:44.636 --> 00:51:46.836 A:middle
So we just pass in an additional
parameter, mask image.

00:51:46.896 --> 00:51:49.186 A:middle
We read from it.

00:51:49.416 --> 00:51:51.806 A:middle
We take a look at what's in the
red channel, say, or it could be

00:51:51.806 --> 00:51:55.386 A:middle
from any channel, and we then
multiply our radius by that.

00:51:55.446 --> 00:51:57.236 A:middle
So if we had a radius
of 15 and at

00:51:57.266 --> 00:51:59.406 A:middle
that current pixel
location we had .5,

00:51:59.406 --> 00:52:01.506 A:middle
it would give us
a radius of 7.5.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:51:59.406 --> 00:52:01.506 A:middle
it would give us
a radius of 7.5.

00:52:02.556 --> 00:52:04.856 A:middle
We can then take those
values and pass it

00:52:04.856 --> 00:52:06.566 A:middle
into the box blur kernel
that we just wrote.

00:52:07.006 --> 00:52:09.666 A:middle
And this is how we can very
simply create a variable box

00:52:09.666 --> 00:52:13.236 A:middle
blur using Metal
Performance Shaders

00:52:13.536 --> 00:52:14.796 A:middle
and the CIImageProcessor nodes.

00:52:18.316 --> 00:52:21.056 A:middle
One additional thing we haven't
mentioned so far today is

00:52:21.056 --> 00:52:23.736 A:middle
that we now have some
attributes you can specify

00:52:24.646 --> 00:52:28.426 A:middle
on your CIKernels when you
write them and, in fact,

00:52:28.426 --> 00:52:31.316 A:middle
we have this just one right
now, which is the output format.

00:52:31.836 --> 00:52:34.706 A:middle
In this case we're
asking for RGBAf,

00:52:34.916 --> 00:52:37.306 A:middle
which is not really
necessarily useful,

00:52:37.746 --> 00:52:40.946 A:middle
but the key thing here is
that you can say that you'd

00:52:41.046 --> 00:52:43.326 A:middle
like to write only
single-channel

00:52:43.636 --> 00:52:44.416 A:middle
or two-channel data.

00:52:44.416 --> 00:52:44.966 A:middle
So if you wanted to do --

00:52:45.516 --> 00:52:48.546 A:middle
[ Applause ]

00:52:49.046 --> 00:52:50.596 A:middle
As some people have
noticed, this is a great way

00:52:50.596 --> 00:52:56.456 A:middle
to reduce your memory usage,
and it's also a way to specify

00:52:56.596 --> 00:53:00.156 A:middle
that you want a certain
precision for a specific kernel


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:52:56.596 --> 00:53:00.156 A:middle
that you want a certain
precision for a specific kernel

00:53:00.156 --> 00:53:02.256 A:middle
in your graph that may
not correspond to the rest

00:53:02.736 --> 00:53:04.196 A:middle
of the graph, which
is also what we do

00:53:04.196 --> 00:53:05.856 A:middle
when we're processing
RAW images on iOS.

00:53:06.336 --> 00:53:10.646 A:middle
All of our kernels
are tagged with RGBAh.

00:53:10.926 --> 00:53:16.206 A:middle
So one or more thing we need
to do to create this effect is

00:53:16.206 --> 00:53:17.546 A:middle
to provide some sort
of mask image.

00:53:17.546 --> 00:53:20.956 A:middle
We can do this very simply
by calling CIFilter(name,

00:53:21.386 --> 00:53:23.106 A:middle
and then ask for
a CIRadialGradient

00:53:23.136 --> 00:53:24.796 A:middle
with a few parameters,
which are going

00:53:24.796 --> 00:53:28.126 A:middle
to determine how
large the mask will be

00:53:28.776 --> 00:53:30.226 A:middle
and where it will be located.

00:53:30.226 --> 00:53:33.066 A:middle
And then we're going to be
interpolating between 0 and 1,

00:53:33.066 --> 00:53:34.106 A:middle
which is going to
be black and white.

00:53:34.106 --> 00:53:37.446 A:middle
And then we ask for the
output image from the CIFilter

00:53:38.046 --> 00:53:39.916 A:middle
and we have a perfectly
usable mask.

00:53:42.496 --> 00:53:44.916 A:middle
So now let's take a look
at what this actually looks

00:53:44.916 --> 00:53:46.296 A:middle
like when running on device,

00:53:46.886 --> 00:53:50.076 A:middle
and this is recorded
from an iPhone 6S.

00:53:50.216 --> 00:53:52.716 A:middle
If we start with our input
image and then look at our mask,

00:53:53.016 --> 00:53:54.076 A:middle
we can move it around.

00:53:54.466 --> 00:53:55.416 A:middle
It's all very interactive.

00:53:56.506 --> 00:53:59.516 A:middle
Change the radius, even
make it go negative.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:54:01.456 --> 00:54:05.136 A:middle
And then if we apply this
mask image and use it inside

00:54:05.136 --> 00:54:08.516 A:middle
of our variable box
blur kernel code,

00:54:08.706 --> 00:54:10.696 A:middle
we then get this type of result.

00:54:11.026 --> 00:54:12.366 A:middle
And it's very interactive

00:54:13.066 --> 00:54:15.516 A:middle
because the integral image
only needs to be computed once,

00:54:15.576 --> 00:54:17.536 A:middle
and Core Image caches
those results for you.

00:54:17.666 --> 00:54:20.096 A:middle
So it literally, everything
you're seeing right now,

00:54:20.096 --> 00:54:21.536 A:middle
is just involving four reads.

00:54:21.536 --> 00:54:21.926 A:middle
So it's superfast.

00:54:22.516 --> 00:54:32.086 A:middle
[ Applause ]

00:54:32.586 --> 00:54:33.646 A:middle
Some things to keep in mind.

00:54:34.206 --> 00:54:35.606 A:middle
When you're using
the CIImageProcessor,

00:54:37.136 --> 00:54:39.706 A:middle
if the data that you
would like to use inside

00:54:39.706 --> 00:54:41.376 A:middle
of your image processor
is not inside

00:54:41.376 --> 00:54:45.456 A:middle
of the context current
workingColorSpace, you're going

00:54:45.456 --> 00:54:47.546 A:middle
to want to call
CIImage.byColorMatching

00:54:47.636 --> 00:54:49.916 A:middle
WorkingSpace(to, and then
provide a color space.

00:54:52.116 --> 00:54:55.646 A:middle
Similarly, on the way out,
if you would like the data

00:54:55.646 --> 00:54:56.726 A:middle
in a different color space,

00:54:56.726 --> 00:54:59.306 A:middle
you can call
CIImage.byColorMatching

00:54:59.306 --> 00:55:02.126 A:middle
ColorSpace(toWorking, and
then give it a color space.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:54:59.306 --> 00:55:02.126 A:middle
ColorSpace(toWorking, and
then give it a color space.

00:55:05.756 --> 00:55:09.676 A:middle
Now that we've seen how to
create the CIImageProcessor

00:55:09.976 --> 00:55:13.416 A:middle
and how to use it, let's
take a look at what happens

00:55:13.416 --> 00:55:15.206 A:middle
when we use the environment
variable CI PRINT TREE,

00:55:15.536 --> 00:55:18.996 A:middle
which we use to get an idea
of what the actual graph

00:55:18.996 --> 00:55:20.416 A:middle
that we're trying to
render looks like.

00:55:23.206 --> 00:55:24.026 A:middle
So this is what it looks

00:55:24.026 --> 00:55:26.686 A:middle
like when you use the
environment variable CI PRINT

00:55:26.686 --> 00:55:27.816 A:middle
TREE with the value
equal to the 1.

00:55:27.936 --> 00:55:30.376 A:middle
And this is read
from bottom to top.

00:55:30.476 --> 00:55:31.716 A:middle
And it can be quite verbose.

00:55:32.476 --> 00:55:36.136 A:middle
It starts off with our input
radialGradient that we created.

00:55:37.036 --> 00:55:38.106 A:middle
We then have our input image

00:55:38.396 --> 00:55:41.326 A:middle
which gets matched
to the workingspace.

00:55:42.866 --> 00:55:45.846 A:middle
And then here's our processor
node that gets called,

00:55:46.036 --> 00:55:49.466 A:middle
and that hex value is the
digest that we've computed.

00:55:50.016 --> 00:55:53.526 A:middle
And then both the processor
and the color kernel result

00:55:53.526 --> 00:55:56.586 A:middle
from the radialGradient get
fed into the variableBoxBlur.

00:55:57.786 --> 00:56:02.266 A:middle
And finally we do the color
matching to our output display.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:55:57.786 --> 00:56:02.266 A:middle
And finally we do the color
matching to our output display.

00:56:03.766 --> 00:56:06.696 A:middle
So this is the original
recipe that we use

00:56:06.726 --> 00:56:11.286 A:middle
to specify this effect, but it's
not what actually gets rendered.

00:56:12.546 --> 00:56:14.876 A:middle
If we were to set the
environmental variable CI PRINT

00:56:14.876 --> 00:56:18.566 A:middle
TREE to 8, we can now see that
many things have been collapsed

00:56:19.266 --> 00:56:22.446 A:middle
and the processing looks
to be less involved.

00:56:23.766 --> 00:56:26.096 A:middle
We still, once again,
have our processor node,

00:56:26.476 --> 00:56:28.066 A:middle
which lives on a
line on its own,

00:56:28.066 --> 00:56:30.846 A:middle
which means that it
does require the need

00:56:30.846 --> 00:56:32.386 A:middle
of an intermediate buffer,

00:56:32.386 --> 00:56:35.546 A:middle
which is why the
CIImageProcessors are great,

00:56:35.656 --> 00:56:38.056 A:middle
but you should only use them
when the kind of things --

00:56:38.056 --> 00:56:39.826 A:middle
the effect that you're trying
to produce, the algorithms

00:56:39.826 --> 00:56:42.226 A:middle
that you have cannot
be expressed inside

00:56:42.226 --> 00:56:43.316 A:middle
of the CIKernel language.

00:56:44.566 --> 00:56:45.776 A:middle
As you can see, the rest

00:56:45.776 --> 00:56:48.036 A:middle
of the processing all
gets concatenated.

00:56:48.036 --> 00:56:50.276 A:middle
So we have our variableBoxBlur
with the rest

00:56:50.276 --> 00:56:53.076 A:middle
of the color matching, and
the clamptoalpha all happening

00:56:53.076 --> 00:56:53.946 A:middle
in a single pass.

00:56:54.616 --> 00:56:57.576 A:middle
So this is why there are always
tradeoffs in between these APIs.

00:56:57.856 --> 00:57:00.066 A:middle
And if you can write something
inside the CIKernel language,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:56:57.856 --> 00:57:00.066 A:middle
And if you can write something
inside the CIKernel language,

00:57:00.066 --> 00:57:00.436 A:middle
you should.

00:57:03.106 --> 00:57:06.476 A:middle
That may be a little
difficult to read.

00:57:07.406 --> 00:57:09.966 A:middle
So we have an additional
option now that you can specify

00:57:09.966 --> 00:57:11.896 A:middle
when you're using CI PRINT
TREE, which is graphviz.

00:57:12.946 --> 00:57:16.306 A:middle
In this case we're
using CI PRINT TREE=8,

00:57:17.196 --> 00:57:18.406 A:middle
along with the graphviz option,

00:57:19.446 --> 00:57:21.606 A:middle
and we can see our
processor node and how it fits

00:57:21.606 --> 00:57:22.956 A:middle
in perfectly with the
rest of the graph.

00:57:23.996 --> 00:57:26.966 A:middle
And we can also see that
we've asked for RGBAf output.

00:57:30.816 --> 00:57:33.686 A:middle
So let's do a little recap
of what we learned today.

00:57:34.356 --> 00:57:37.276 A:middle
We saw, David showed us how
to edit RAW images on iOS.

00:57:38.196 --> 00:57:39.166 A:middle
Then Etienne spoke to us

00:57:39.166 --> 00:57:42.196 A:middle
about how you can edit Live
Photos using Core Image.

00:57:42.486 --> 00:57:45.336 A:middle
And then finally, we got to
see how to use this new API

00:57:45.336 --> 00:57:49.256 A:middle
on CIImage called
CIImageProcessor, as well as how

00:57:49.256 --> 00:57:51.066 A:middle
to specify an output
format on your kernels

00:57:51.066 --> 00:57:53.006 A:middle
to help reduce the memory usage.

00:57:53.706 --> 00:57:56.746 A:middle
For additional information
please

00:57:56.746 --> 00:57:58.546 A:middle
visit developer.apple.com.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:58:01.016 --> 00:58:03.046 A:middle
There are a few related sessions
that may be of interest to you,

00:58:03.266 --> 00:58:06.416 A:middle
especially if you're planning
on doing RAW processing on iOS.

00:58:06.496 --> 00:58:07.916 A:middle
There's Advances
in iOS Photography

00:58:07.916 --> 00:58:09.186 A:middle
that Etienne mentioned as well.

00:58:09.936 --> 00:58:13.496 A:middle
There's also a talk later on
today, Working with Wide Color,

00:58:14.216 --> 00:58:15.116 A:middle
that's taking place right here.

00:58:16.916 --> 00:58:18.746 A:middle
And on that note, I would like
to thank you all for coming.

00:58:18.746 --> 00:58:19.936 A:middle
I hope you enjoy
the rest of WWDC.

00:58:20.516 --> 00:58:30.760 A:middle
[ Applause ]

