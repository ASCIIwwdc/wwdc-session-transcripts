WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:06.516 --> 00:00:17.500 A:middle
[ Music ]

00:00:21.516 --> 00:00:29.226 A:middle
[ Applause ]

00:00:29.726 --> 00:00:31.046 A:middle
&gt;&gt; Hi, I'm Alex Rosenberg.

00:00:31.356 --> 00:00:32.426 A:middle
I'm incredibly excited to share

00:00:32.426 --> 00:00:34.666 A:middle
with you some amazing new
features we have in store

00:00:34.666 --> 00:00:36.056 A:middle
for the Apple LLVM Compiler.

00:00:36.876 --> 00:00:39.266 A:middle
But first, I want to talk
a little bit about LLVM,

00:00:40.216 --> 00:00:42.786 A:middle
the project upon which we
build the Apple LLVM Compiler.

00:00:44.186 --> 00:00:45.686 A:middle
LLVM is a modular framework

00:00:46.076 --> 00:00:48.486 A:middle
for building compilers
and related tools.

00:00:49.236 --> 00:00:51.946 A:middle
However, it need not be used
solely in this traditional way.

00:00:53.266 --> 00:00:56.656 A:middle
We all know and love
Xcode, which uses many

00:00:56.656 --> 00:00:57.996 A:middle
of the LLVM frameworks
internally.

00:00:58.746 --> 00:01:03.566 A:middle
And now the amazing, new Swift
Playgrounds app, has joined it


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:58.746 --> 00:01:03.566 A:middle
And now the amazing, new Swift
Playgrounds app, has joined it

00:01:04.135 --> 00:01:07.786 A:middle
with similar internal
uses of LLVM.

00:01:08.026 --> 00:01:10.726 A:middle
LLVM is also an integral part
of the inner workings of Metal

00:01:10.726 --> 00:01:14.626 A:middle
and our other graphics APIs.

00:01:14.826 --> 00:01:16.256 A:middle
LVVM is open source.

00:01:16.846 --> 00:01:18.136 A:middle
Apple has a long history

00:01:18.166 --> 00:01:20.116 A:middle
with open source
compilers and languages.

00:01:20.926 --> 00:01:24.036 A:middle
The Swift language was born
out of the LLVM project.

00:01:24.936 --> 00:01:27.916 A:middle
We're very happy with how you,
the community of contributors,

00:01:28.436 --> 00:01:30.936 A:middle
have move Swift forward via
the open evolution process

00:01:30.936 --> 00:01:31.766 A:middle
on Swift.org.

00:01:32.816 --> 00:01:36.066 A:middle
That process, and the Swift
development processes were

00:01:36.066 --> 00:01:39.286 A:middle
informed by the existing
LLVM project processes.

00:01:40.436 --> 00:01:42.736 A:middle
LLVM has a thriving
open source community,

00:01:43.036 --> 00:01:45.226 A:middle
backed by the nonprofit
LLVM Foundation.

00:01:45.876 --> 00:01:50.226 A:middle
LLVM is highly customizable
and composable.

00:01:51.176 --> 00:01:53.816 A:middle
By leveraging the same robust
and mature infrastructure,

00:01:53.916 --> 00:01:55.226 A:middle
underpinning the
Clang front end,

00:01:55.866 --> 00:01:57.346 A:middle
we power the Swift
compiler as well.

00:01:58.896 --> 00:02:01.966 A:middle
For more info about Swift,
review the talk from earlier.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:01:58.896 --> 00:02:01.966 A:middle
For more info about Swift,
review the talk from earlier.

00:02:03.286 --> 00:02:04.726 A:middle
Let's take a brief
look into some

00:02:04.726 --> 00:02:06.736 A:middle
of these frameworks
available from open source

00:02:06.796 --> 00:02:07.986 A:middle
and how they might be used.

00:02:09.776 --> 00:02:13.226 A:middle
Clang is the front end for
C, Objective-C, and C++.

00:02:14.376 --> 00:02:16.546 A:middle
Its libraries provide
for advanced features,

00:02:16.676 --> 00:02:19.626 A:middle
like static analysis, and
in place for your writing,

00:02:19.866 --> 00:02:22.136 A:middle
for code mitigation,
and modification.

00:02:23.426 --> 00:02:25.356 A:middle
It also powers development
environment integration

00:02:25.356 --> 00:02:27.616 A:middle
features, like source
code indexing

00:02:27.616 --> 00:02:31.146 A:middle
and intelligent code completion
that we all love in Xcode.

00:02:32.896 --> 00:02:36.586 A:middle
The open source tooling library
helps harness the power of Clang

00:02:36.586 --> 00:02:40.186 A:middle
for your own custom command-line
tools to process source code.

00:02:40.986 --> 00:02:44.256 A:middle
Imagine the amazing things
you could do with the power

00:02:44.256 --> 00:02:47.686 A:middle
of a full parser at your
command, running on your code.

00:02:51.176 --> 00:02:54.836 A:middle
The LLVM optimizer,
which we'll speak more

00:02:54.836 --> 00:02:57.096 A:middle
about in a little
bit, has a full suite

00:02:57.096 --> 00:02:59.036 A:middle
of modern compiler
optimizations.

00:02:59.786 --> 00:03:02.316 A:middle
And this is where features like
Link-Time Optimization happen.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:02:59.786 --> 00:03:02.316 A:middle
And this is where features like
Link-Time Optimization happen.

00:03:02.896 --> 00:03:05.596 A:middle
Stay tuned for some
exciting developments in LTO.

00:03:06.096 --> 00:03:10.856 A:middle
And then we have the back end,

00:03:10.976 --> 00:03:12.736 A:middle
where final code
generation happens.

00:03:13.646 --> 00:03:15.776 A:middle
There are libraries for
object file manipulation,

00:03:16.086 --> 00:03:18.016 A:middle
features like assembly
and disassembly,

00:03:18.016 --> 00:03:19.636 A:middle
and even advanced features

00:03:19.636 --> 00:03:25.006 A:middle
like just-in-time compilation
can be simply plugged together.

00:03:25.006 --> 00:03:28.046 A:middle
LLVM has many other tools
composed from its frameworks.

00:03:28.536 --> 00:03:29.186 A:middle
Let's take a look.

00:03:30.376 --> 00:03:33.236 A:middle
As part of a complete
LLVM based toolchain,

00:03:33.896 --> 00:03:36.296 A:middle
there are the usual suite
of binary file utilities,

00:03:36.576 --> 00:03:39.246 A:middle
including a burgeoning open
source effort on a framework

00:03:39.546 --> 00:03:41.386 A:middle
for making linkers
and related tools.

00:03:42.396 --> 00:03:45.376 A:middle
But perhaps the most prominent
of these projects is LLDB.

00:03:46.176 --> 00:03:49.666 A:middle
LLDB combines many of the
libraries from Clang, Swift,

00:03:50.036 --> 00:03:52.996 A:middle
the Code Generator, and its own
suite of debugger frameworks.

00:03:53.606 --> 00:03:56.426 A:middle
There will be a great session of
LLDB tips and tricks on Friday.

00:03:57.696 --> 00:04:03.016 A:middle
All of the amazing features
in Xcode, Swift Playgrounds,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:57.696 --> 00:04:03.016 A:middle
All of the amazing features
in Xcode, Swift Playgrounds,

00:04:03.246 --> 00:04:05.786 A:middle
and the Apple LLVM Compiler
wouldn't be possible

00:04:06.096 --> 00:04:09.436 A:middle
without the contributions from
the LLVM open source community.

00:04:10.186 --> 00:04:13.136 A:middle
The community is made up of
many developers like you,

00:04:13.636 --> 00:04:16.526 A:middle
inspired to bring their own
ideas into the LLVM frameworks.

00:04:18.435 --> 00:04:22.176 A:middle
The LLVM open source project
is growing at a stunning pace

00:04:22.436 --> 00:04:25.236 A:middle
that would be extremely
challenging for any one team,

00:04:25.346 --> 00:04:29.046 A:middle
at any one company, to match.

00:04:29.236 --> 00:04:32.446 A:middle
We'd like to invite you to check
out the project, at LLVM.org,

00:04:32.936 --> 00:04:34.666 A:middle
and see how you can
fit into the community

00:04:34.666 --> 00:04:36.466 A:middle
and contribute your
unique ideas.

00:04:36.466 --> 00:04:41.156 A:middle
And now I'd like to introduce
Duncan, who will go over some

00:04:41.156 --> 00:04:43.016 A:middle
of the exciting new
language features we have

00:04:43.266 --> 00:04:44.486 A:middle
in the Apple LLVM Compiler.

00:04:45.516 --> 00:04:52.766 A:middle
[ Applause ]

00:04:53.266 --> 00:04:54.686 A:middle
&gt;&gt; Let's talk about
language support.

00:04:55.966 --> 00:04:59.176 A:middle
First, we'll talk about new
language features, then updates

00:04:59.176 --> 00:05:02.746 A:middle
to the C++ library, and
finally new errors and warnings


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:59.176 --> 00:05:02.746 A:middle
to the C++ library, and
finally new errors and warnings

00:05:02.746 --> 00:05:04.506 A:middle
to help improve your code.

00:05:05.046 --> 00:05:07.656 A:middle
Let's start with new
language features.

00:05:09.256 --> 00:05:11.676 A:middle
Objective-C now supports
class properties.

00:05:12.406 --> 00:05:15.076 A:middle
This feature started in
Swift as type properties,

00:05:15.206 --> 00:05:16.686 A:middle
and we've brought
it to Objective-C.

00:05:17.476 --> 00:05:18.956 A:middle
Interoperation works great.

00:05:20.886 --> 00:05:24.436 A:middle
In this example, the class
property someString is declared

00:05:24.746 --> 00:05:27.806 A:middle
using property syntax,
by adding a class flag.

00:05:28.896 --> 00:05:32.296 A:middle
Later, this someString property
is accessed using dot syntax.

00:05:34.046 --> 00:05:35.976 A:middle
Class properties are
never synthesized.

00:05:36.346 --> 00:05:39.546 A:middle
You can provide storage,
a getter, and a setter,

00:05:39.676 --> 00:05:40.626 A:middle
in the implementation.

00:05:42.006 --> 00:05:44.936 A:middle
Or you can use @dynamic to
defer resolution to runtime.

00:05:44.936 --> 00:05:48.716 A:middle
Over to C++.

00:05:50.276 --> 00:05:54.056 A:middle
LLVM has had great support
for C++11 for years.

00:05:54.596 --> 00:05:56.216 A:middle
The only holdout
has been support

00:05:56.216 --> 00:05:57.426 A:middle
for the thread-local keyword.

00:05:58.436 --> 00:05:59.856 A:middle
This year, we added support.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:00.606 --> 00:06:02.666 A:middle
Let me tell you a
little about it.

00:06:03.806 --> 00:06:06.576 A:middle
If a variable is declared
with a thread-local keyword,

00:06:07.026 --> 00:06:09.646 A:middle
LLVM creates a separate
variable per thread.

00:06:11.056 --> 00:06:13.586 A:middle
Initializers are called
before the first use

00:06:13.586 --> 00:06:14.456 A:middle
after thread entry,

00:06:14.866 --> 00:06:16.846 A:middle
and destructors are
called on thread exit.

00:06:18.466 --> 00:06:24.026 A:middle
C++ style thread-local
storage, supports any C++ type.

00:06:26.386 --> 00:06:29.956 A:middle
And its syntax is portable
with other C++ compilers.

00:06:31.456 --> 00:06:35.016 A:middle
The Apple LLVM Compiler,
already has support

00:06:35.016 --> 00:06:36.716 A:middle
for C-style thread-local
storage,

00:06:37.096 --> 00:06:39.316 A:middle
even when compiling C++ code.

00:06:39.866 --> 00:06:41.326 A:middle
There are two syntaxes
available:

00:06:41.886 --> 00:06:43.646 A:middle
One with a GCC style keyword,

00:06:43.946 --> 00:06:45.576 A:middle
and another from
the C11 standard.

00:06:46.976 --> 00:06:49.756 A:middle
C-style thread-local
storage has lower overhead

00:06:49.806 --> 00:06:52.856 A:middle
than C++ thread local,
but it has restrictions.

00:06:53.026 --> 00:06:55.266 A:middle
It requires constant
initializers

00:06:55.266 --> 00:06:56.556 A:middle
and plain old data types.

00:06:58.076 --> 00:06:59.976 A:middle
If your code meets
these restrictions,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:07:00.126 --> 00:07:03.226 A:middle
you should continue to use
C-style thread-local storage

00:07:03.226 --> 00:07:04.526 A:middle
for maximum performance.

00:07:05.276 --> 00:07:07.866 A:middle
Otherwise, use the C++
thread-local keyword.

00:07:08.366 --> 00:07:09.146 A:middle
Both work great.

00:07:10.616 --> 00:07:13.196 A:middle
Thread-local variables
can help fix bugs

00:07:13.196 --> 00:07:14.666 A:middle
in code that uses threads.

00:07:15.376 --> 00:07:19.336 A:middle
For more on thread related
bugs, watch the Thread Sanitizer

00:07:19.336 --> 00:07:21.346 A:middle
and Static Analysis talk.

00:07:22.436 --> 00:07:24.236 A:middle
That's it for new
language features.

00:07:24.486 --> 00:07:28.786 A:middle
Let's move on to the
C++ standard library.

00:07:29.396 --> 00:07:34.726 A:middle
Libc++ has been the default
C++ standard library for years.

00:07:35.276 --> 00:07:38.426 A:middle
We've been encouraging you
to move off of Libstandardc++

00:07:38.426 --> 00:07:41.996 A:middle
and in Xcode 8, we've deprecated
it on all our platforms.

00:07:42.596 --> 00:07:44.536 A:middle
Please move on as
soon as you can.

00:07:45.856 --> 00:07:49.186 A:middle
If your Xcode project
still uses Libstandardc++,

00:07:49.586 --> 00:07:51.486 A:middle
you should upgrade to Libc++

00:07:51.586 --> 00:07:54.646 A:middle
by changing the C++ standard
library build setting.

00:07:55.296 --> 00:07:57.506 A:middle
Xcode's project modernization
will offer

00:07:57.506 --> 00:07:58.706 A:middle
to do this automatically.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:08:00.296 --> 00:08:03.526 A:middle
The Libc++.dylib has a
great update this year

00:08:03.526 --> 00:08:04.876 A:middle
for all our platforms.

00:08:05.016 --> 00:08:08.096 A:middle
It has complete library
support for C++14,

00:08:08.466 --> 00:08:10.246 A:middle
as well as many other
improvements.

00:08:11.416 --> 00:08:13.746 A:middle
Standard library features
that require the dylib,

00:08:14.166 --> 00:08:16.086 A:middle
now have availability
attributes.

00:08:16.856 --> 00:08:20.206 A:middle
While Apple frameworks encourage
deploying to old targets

00:08:20.206 --> 00:08:21.646 A:middle
through the use of
runtime checks,

00:08:22.186 --> 00:08:25.286 A:middle
the C++ standard library
availability checks are done

00:08:25.286 --> 00:08:26.096 A:middle
at compile time.

00:08:27.306 --> 00:08:30.556 A:middle
To use C++ features that
require the newest dylib,

00:08:30.966 --> 00:08:33.496 A:middle
you need to target a
platform that supports them.

00:08:34.395 --> 00:08:37.616 A:middle
That's the C++ library.

00:08:38.616 --> 00:08:42.196 A:middle
Between Xcode 7 and
Xcode 8, we've added more

00:08:42.196 --> 00:08:43.966 A:middle
than 100 new errors and warnings

00:08:43.966 --> 00:08:45.406 A:middle
to help you find
bugs in your code.

00:08:46.256 --> 00:08:49.716 A:middle
Let's talk about
just a few of them.

00:08:49.866 --> 00:08:53.086 A:middle
In Xcode 7, we added
a great feature

00:08:53.086 --> 00:08:55.426 A:middle
to Objective-C called
Lightweight Generics.

00:08:56.196 --> 00:08:58.966 A:middle
The kind of type modifier
plays an important role,

00:08:59.306 --> 00:09:01.906 A:middle
allowing implicit downcast
from the kind of type


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:08:59.306 --> 00:09:01.906 A:middle
allowing implicit downcast
from the kind of type

00:09:02.066 --> 00:09:03.396 A:middle
to any of its subclasses.

00:09:04.416 --> 00:09:07.136 A:middle
In Xcode 8, we've
improved the diagnostics

00:09:07.136 --> 00:09:09.196 A:middle
for method lookup
on kind of types.

00:09:10.176 --> 00:09:11.326 A:middle
In this example,

00:09:11.586 --> 00:09:14.676 A:middle
getAwesomeNumber is declared
inside My Custom Type,

00:09:15.126 --> 00:09:16.616 A:middle
which inherits from NSObject.

00:09:17.546 --> 00:09:21.086 A:middle
Later, getAwesomeNumber is
called on a kindof UIView.

00:09:21.916 --> 00:09:25.196 A:middle
This code is broken since
My Custom Type is unrelated

00:09:25.196 --> 00:09:25.856 A:middle
to UIView.

00:09:27.246 --> 00:09:28.866 A:middle
Xcode 8 gives an error here.

00:09:29.536 --> 00:09:32.736 A:middle
Type checking of methods called
on kind of types, is restricted

00:09:32.736 --> 00:09:33.986 A:middle
to the same class hierarchy.

00:09:34.696 --> 00:09:37.896 A:middle
This improved type checking
also avoids misleading warnings

00:09:37.966 --> 00:09:41.196 A:middle
when an unrelated type declares
a method with the same name.

00:09:41.916 --> 00:09:48.666 A:middle
In Xcode 8, kind of types
are way easier to use.

00:09:48.846 --> 00:09:51.966 A:middle
Next, containers in
Objective-C, such NSArray

00:09:51.966 --> 00:09:54.646 A:middle
or NSMutableSet can
hold arbitrary objects.

00:09:55.096 --> 00:09:57.786 A:middle
However, the NSMutableSet
called s

00:09:57.846 --> 00:09:59.866 A:middle
in this example is
added to itself.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:01.476 --> 00:10:03.556 A:middle
This creates a circular
dependency,

00:10:03.756 --> 00:10:05.526 A:middle
which triggers a
warning in Xcode 8.

00:10:06.586 --> 00:10:08.536 A:middle
Besides creating a
strong reference cycle,

00:10:08.826 --> 00:10:11.166 A:middle
a circular dependency
can prevent some methods

00:10:11.246 --> 00:10:14.966 A:middle
from being well-defined.

00:10:15.636 --> 00:10:16.816 A:middle
Infinite recursion.

00:10:18.256 --> 00:10:20.726 A:middle
This example implements
the factorial function.

00:10:21.696 --> 00:10:25.156 A:middle
If n is positive, it returns n
times factorial of n minus 1,

00:10:25.206 --> 00:10:26.856 A:middle
recursing to calculate
the answer.

00:10:27.916 --> 00:10:31.616 A:middle
If n is zero, it returns
factorial of 1, also recursing.

00:10:33.006 --> 00:10:34.546 A:middle
The compiler now has a warning.

00:10:34.946 --> 00:10:37.196 A:middle
When all pass through a
function, call itself.

00:10:38.066 --> 00:10:40.656 A:middle
This catches common cases
of infinite recursion.

00:10:42.356 --> 00:10:50.266 A:middle
Here, one possible fix is
to return 1 when n is zero.

00:10:50.426 --> 00:10:53.526 A:middle
Standard Move is a great
C++ language feature.

00:10:53.526 --> 00:10:56.936 A:middle
It allows you to specify that
ownership should be transferred

00:10:56.936 --> 00:10:58.486 A:middle
from one container to another.

00:10:59.366 --> 00:11:02.176 A:middle
Moving a resource is
faster than a deep copy.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:59.366 --> 00:11:02.176 A:middle
Moving a resource is
faster than a deep copy.

00:11:04.116 --> 00:11:07.386 A:middle
However, using standard
move on a return value,

00:11:07.576 --> 00:11:09.986 A:middle
blocks named return
value optimizations.

00:11:10.866 --> 00:11:13.596 A:middle
Typically, when a local
variable is returned by value,

00:11:14.056 --> 00:11:16.706 A:middle
the compiler can avoid
making a copy at all.

00:11:17.296 --> 00:11:20.586 A:middle
In generateBars, calling
standard move forces the

00:11:20.586 --> 00:11:22.446 A:middle
compiler to move bars.

00:11:24.206 --> 00:11:27.516 A:middle
Although moving is fast,
doing nothing is even faster.

00:11:28.156 --> 00:11:32.386 A:middle
LLVM now warns about
this pessimizing move.

00:11:32.666 --> 00:11:35.576 A:middle
The fix is to avoid standard
move on return values,

00:11:35.576 --> 00:11:37.266 A:middle
getting back the
lost performance.

00:11:38.756 --> 00:11:42.026 A:middle
Similarly, when a function
takes an argument by value,

00:11:42.176 --> 00:11:43.706 A:middle
and returns it by value,

00:11:44.126 --> 00:11:47.186 A:middle
the compiler automatically uses
standard move on the return.

00:11:47.636 --> 00:11:49.216 A:middle
There's no need to
call it explicitly.

00:11:50.536 --> 00:11:52.936 A:middle
For example, the standard
move on the return value

00:11:52.936 --> 00:11:54.696 A:middle
in rewriteText is redundant.

00:11:55.546 --> 00:11:57.726 A:middle
Although this doesn't
actively hurt performance,

00:11:57.966 --> 00:11:59.206 A:middle
it makes the code less readable.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:00.306 --> 00:12:02.076 A:middle
It's better to return
text directly.

00:12:02.526 --> 00:12:04.956 A:middle
This is easier to
maintain and consistent

00:12:04.956 --> 00:12:06.406 A:middle
with returning local variables.

00:12:06.776 --> 00:12:14.036 A:middle
Finally, there are new warnings
for references to temporaries

00:12:14.036 --> 00:12:15.956 A:middle
in C++ range-based for loops.

00:12:17.316 --> 00:12:20.496 A:middle
Here, the loop is iterating
through a vector of shorts,

00:12:20.736 --> 00:12:24.096 A:middle
but the iteration variable i,
is a const reference to an int.

00:12:25.226 --> 00:12:28.266 A:middle
Because of the implicit
conversion between short

00:12:28.266 --> 00:12:30.836 A:middle
and int, i is a temporary.

00:12:32.706 --> 00:12:35.226 A:middle
This can lead to subtle
bugs, since it looks

00:12:35.226 --> 00:12:38.326 A:middle
as if i is pointing inside
the range, but it isn't.

00:12:39.146 --> 00:12:42.076 A:middle
The compiler now warns about
this unexpected conversion.

00:12:42.856 --> 00:12:45.586 A:middle
One fix is to change i to
a const reference of short.

00:12:46.776 --> 00:12:49.766 A:middle
Another is to make it
clear that i is a temporary

00:12:50.046 --> 00:12:51.306 A:middle
by removing the reference.

00:12:52.456 --> 00:12:53.946 A:middle
There is a similar warning

00:12:54.426 --> 00:12:56.426 A:middle
when a range doesn't
return a reference at all.

00:12:56.426 --> 00:12:59.826 A:middle
An iterator to standard
vector of bool,

00:12:59.826 --> 00:13:01.586 A:middle
does not return a reference.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:59.826 --> 00:13:01.586 A:middle
does not return a reference.

00:13:01.686 --> 00:13:05.286 A:middle
So the iteration variable b in
this example is a temporary.

00:13:06.606 --> 00:13:10.026 A:middle
It's surprising that b does
not point inside the vector.

00:13:10.346 --> 00:13:12.806 A:middle
The compiler now warns
about this unexpected copy.

00:13:13.476 --> 00:13:18.116 A:middle
The fix is to remove the
reference making it clear

00:13:18.456 --> 00:13:19.516 A:middle
that b is a temporary.

00:13:19.976 --> 00:13:24.086 A:middle
The new warnings for infinite
recursion, standard move,

00:13:24.226 --> 00:13:27.516 A:middle
and C++ range-based for
loops are enabled by default.

00:13:28.086 --> 00:13:30.226 A:middle
To try them out in
your expo project,

00:13:30.676 --> 00:13:32.866 A:middle
add them to the Other
Warning Flags Build setting.

00:13:34.046 --> 00:13:35.576 A:middle
That's it for new diagnostics.

00:13:36.046 --> 00:13:40.216 A:middle
Let's move on to advancements
in compiler optimization.

00:13:40.716 --> 00:13:46.816 A:middle
We've made improvements
throughout the LLVM compiler

00:13:46.996 --> 00:13:49.536 A:middle
to optimize the runtime
performance of your code.

00:13:50.606 --> 00:13:52.256 A:middle
We've picked just a
few to highlight today.

00:13:53.456 --> 00:13:56.236 A:middle
We'll talk about improvements
to Link-Time Optimization,

00:13:56.646 --> 00:13:58.976 A:middle
highlight new code
generation optimizations,

00:13:59.266 --> 00:14:02.376 A:middle
and describe techniques
for arm64 cache tuning.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:13:59.266 --> 00:14:02.376 A:middle
and describe techniques
for arm64 cache tuning.

00:14:06.996 --> 00:14:09.406 A:middle
It has been a couple of
years since we've talked

00:14:09.406 --> 00:14:10.736 A:middle
about Link-Time Optimization

00:14:11.156 --> 00:14:12.756 A:middle
and we have major
improvements to share.

00:14:13.896 --> 00:14:17.756 A:middle
Link-Time Optimization or
LTO, optimizes the executable

00:14:17.786 --> 00:14:19.396 A:middle
as a single monolithic unit.

00:14:20.106 --> 00:14:23.686 A:middle
It inlines functions across
source files, removes dead code,

00:14:23.796 --> 00:14:27.026 A:middle
and performs other powerful,
whole program optimizations.

00:14:28.016 --> 00:14:31.566 A:middle
LTO blurs the line between
the compiler and the linker.

00:14:32.946 --> 00:14:35.936 A:middle
To understand how LTO
works, let's first look

00:14:35.936 --> 00:14:37.686 A:middle
at the traditional
compilation model.

00:14:38.746 --> 00:14:40.446 A:middle
Let's say we have
four source files.

00:14:41.336 --> 00:14:44.886 A:middle
The first step is to compile,
producing four object files.

00:14:46.446 --> 00:14:52.126 A:middle
The object files are linked with
frameworks, to produce an app.

00:14:52.386 --> 00:14:54.406 A:middle
An LTO build starts
the same way,

00:14:55.396 --> 00:14:57.806 A:middle
by compiling the sources
into object files.

00:14:58.876 --> 00:15:02.586 A:middle
In LTO, these object files
contain extra optimization


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:14:58.876 --> 00:15:02.586 A:middle
In LTO, these object files
contain extra optimization

00:15:02.586 --> 00:15:04.896 A:middle
information which
enables the linker

00:15:04.896 --> 00:15:06.936 A:middle
to perform Link-Time
Optimizations,

00:15:07.196 --> 00:15:10.276 A:middle
and produce a single,
monolithic object file.

00:15:11.236 --> 00:15:13.726 A:middle
The output of LTO is
linked with frameworks

00:15:13.726 --> 00:15:18.726 A:middle
such as Foundation,
to produce the app.

00:15:19.506 --> 00:15:21.756 A:middle
LTO maximizes performance.

00:15:23.656 --> 00:15:26.796 A:middle
Apple uses LTO extensively
on our own software,

00:15:27.356 --> 00:15:29.066 A:middle
typically speeding
up executables

00:15:29.116 --> 00:15:31.866 A:middle
by 10 percent compared to
regular release builds.

00:15:33.096 --> 00:15:34.836 A:middle
Its effects multiply
when combined

00:15:34.836 --> 00:15:36.606 A:middle
with profile guided
optimization.

00:15:37.296 --> 00:15:40.536 A:middle
It can also reduce
code size dramatically,

00:15:40.976 --> 00:15:42.986 A:middle
when optimizing for size.

00:15:44.336 --> 00:15:47.526 A:middle
However, it has cost
at compile time.

00:15:48.276 --> 00:15:50.966 A:middle
The monolithic optimization
step can have large memory

00:15:50.966 --> 00:15:54.016 A:middle
requirements, doesn't take
advantage of all your cores,

00:15:54.536 --> 00:15:56.536 A:middle
and has to be repeated
in incremental builds.

00:15:57.896 --> 00:16:00.546 A:middle
Large C++ programs
with debug info,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:15:57.896 --> 00:16:00.546 A:middle
Large C++ programs
with debug info,

00:16:00.626 --> 00:16:02.326 A:middle
have been the most
expensive to compile.

00:16:03.966 --> 00:16:06.096 A:middle
Over the last two
years, we've worked hard

00:16:06.096 --> 00:16:07.036 A:middle
to reduce the overhead.

00:16:08.416 --> 00:16:10.326 A:middle
For example, let's look
at the memory usage

00:16:10.326 --> 00:16:13.226 A:middle
for linking the Apple
LLVM compiler itself

00:16:13.486 --> 00:16:14.986 A:middle
with LTO and debug info.

00:16:15.446 --> 00:16:16.466 A:middle
Smaller bars are better.

00:16:17.166 --> 00:16:20.236 A:middle
In Xcode 6, this took
over 40 gigabytes.

00:16:21.206 --> 00:16:24.006 A:middle
Since then, we've reduced
the memory usage by 4x.

00:16:24.576 --> 00:16:27.116 A:middle
We've also reduced
compile time by 33 percent.

00:16:29.166 --> 00:16:32.796 A:middle
The Line Tables Only debug
information level uses even less

00:16:32.796 --> 00:16:33.616 A:middle
memory in LTO.

00:16:34.426 --> 00:16:39.786 A:middle
Linking LLVM itself,
now takes only 7 gigs.

00:16:39.786 --> 00:16:42.076 A:middle
LTO has never been better.

00:16:43.546 --> 00:16:46.436 A:middle
But there is still a compile
time trade-off, particularly

00:16:46.436 --> 00:16:47.446 A:middle
for incremental builds.

00:16:48.096 --> 00:16:52.086 A:middle
We have an exciting
new technology

00:16:52.086 --> 00:16:53.496 A:middle
that designs away these costs.

00:16:54.656 --> 00:16:57.696 A:middle
Incremental LTO scales
with your system.

00:16:58.876 --> 00:17:01.146 A:middle
It performs global
analysis and inlining


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:58.876 --> 00:17:01.146 A:middle
It performs global
analysis and inlining

00:17:01.286 --> 00:17:02.836 A:middle
without combining object files.

00:17:04.185 --> 00:17:07.886 A:middle
This speeds up the build because
it can optimize each object file

00:17:07.886 --> 00:17:08.465 A:middle
in parallel.

00:17:09.256 --> 00:17:12.836 A:middle
Moreover, since the
object files stay separate,

00:17:13.296 --> 00:17:14.306 A:middle
and you build cache

00:17:14.306 --> 00:17:17.146 A:middle
in the linker keeps
incremental builds superfast.

00:17:17.146 --> 00:17:22.366 A:middle
Let's look at how an
incremental LTO build works.

00:17:23.806 --> 00:17:26.266 A:middle
The compile step is the
same as monolithic LTO,

00:17:26.945 --> 00:17:29.296 A:middle
producing one object file
for each source file.

00:17:31.136 --> 00:17:35.246 A:middle
Without combining object files,
the linker runs an LTO analysis

00:17:35.246 --> 00:17:36.426 A:middle
of the entire program.

00:17:37.756 --> 00:17:39.656 A:middle
This analysis feeds
optimizations

00:17:39.656 --> 00:17:43.296 A:middle
for each object file, enabling
the objects to inline functions

00:17:43.296 --> 00:17:44.406 A:middle
from each other, as well

00:17:44.406 --> 00:17:46.876 A:middle
as other powerful whole
program optimizations.

00:17:48.576 --> 00:17:53.026 A:middle
The LTO optimized object files
are stored in a linker cache,

00:17:54.456 --> 00:17:57.566 A:middle
before being linked with
frameworks to produce the app.

00:17:59.256 --> 00:18:02.526 A:middle
The resulting runtime
performance of programs built


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:17:59.256 --> 00:18:02.526 A:middle
The resulting runtime
performance of programs built

00:18:02.526 --> 00:18:05.906 A:middle
with incremental LTO, is
similar to monolithic LTO,

00:18:06.696 --> 00:18:08.236 A:middle
with a few benchmarks
running slower,

00:18:08.236 --> 00:18:09.616 A:middle
and a few running faster.

00:18:10.206 --> 00:18:12.676 A:middle
But it's fast at
compile time too.

00:18:13.886 --> 00:18:16.856 A:middle
Let's look at build times
with my favorite C++ project:

00:18:17.396 --> 00:18:19.036 A:middle
The Apple LLVM compiler itself.

00:18:20.366 --> 00:18:22.006 A:middle
In this graph, smaller
bars are better.

00:18:22.636 --> 00:18:24.796 A:middle
The time at the top is
for building without LTO.

00:18:26.106 --> 00:18:29.066 A:middle
Monolithic LTO adds
significant build time overhead,

00:18:29.286 --> 00:18:31.516 A:middle
taking almost 20
minutes, instead of 6.

00:18:32.676 --> 00:18:35.586 A:middle
Incremental LTO is much
faster at under 8 minutes,

00:18:35.646 --> 00:18:37.476 A:middle
adding only 25 percent overhead.

00:18:38.146 --> 00:18:41.646 A:middle
Let's zoom in on the link step
where LTO is doing its work.

00:18:43.066 --> 00:18:45.846 A:middle
Without LTO, linking the
Apple LLVM compiler itself,

00:18:45.846 --> 00:18:47.366 A:middle
takes less than two seconds.

00:18:47.956 --> 00:18:49.586 A:middle
You can't see the
bar in the graph,

00:18:49.666 --> 00:18:51.366 A:middle
because the linker
isn't performing any

00:18:51.366 --> 00:18:52.766 A:middle
compiler optimizations.

00:18:54.036 --> 00:18:56.456 A:middle
Monolithic LTO takes
almost 14 minutes,

00:18:57.846 --> 00:18:59.576 A:middle
when it can use all your cores.

00:18:59.936 --> 00:19:02.116 A:middle
Incremental LTO takes two
minutes and a quarter,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:18:59.936 --> 00:19:02.116 A:middle
Incremental LTO takes two
minutes and a quarter,

00:19:02.416 --> 00:19:05.016 A:middle
more than 6x faster
than monolithic LTO.

00:19:06.506 --> 00:19:08.016 A:middle
Memory usage is great too.

00:19:08.786 --> 00:19:12.266 A:middle
Without LTO, linking the Apple
LLVM compiler uses a little more

00:19:12.266 --> 00:19:13.546 A:middle
than 200 megabytes.

00:19:14.336 --> 00:19:17.746 A:middle
As we saw earlier, monolithic
LTO takes 7 gigabytes.

00:19:19.156 --> 00:19:21.886 A:middle
Incremental LTO uses
less than 800 megabytes.

00:19:22.226 --> 00:19:23.616 A:middle
The scaling is incredible.

00:19:26.516 --> 00:19:32.436 A:middle
[ Applause ]

00:19:32.936 --> 00:19:34.496 A:middle
All these results are
for a fresh build.

00:19:35.026 --> 00:19:35.786 A:middle
It gets even better.

00:19:36.846 --> 00:19:38.616 A:middle
With incremental LTO,

00:19:38.666 --> 00:19:41.296 A:middle
incremental builds don't
repeat unnecessary work.

00:19:42.376 --> 00:19:44.886 A:middle
Let's look at an example
where the controller changes,

00:19:45.176 --> 00:19:48.666 A:middle
and you start an
incremental build of the app.

00:19:48.926 --> 00:19:51.616 A:middle
Changing the controller
invalidates the link itself,

00:19:52.096 --> 00:19:55.346 A:middle
but the other LTO object files
are still in the linker cache.

00:19:56.146 --> 00:19:59.706 A:middle
However, if a function from the
controller is inline into main,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:20:00.206 --> 00:20:03.336 A:middle
then main needs to be
reoptimized at LTO time as well.

00:20:03.946 --> 00:20:08.326 A:middle
So we start the build, and
only the controller needs

00:20:08.326 --> 00:20:10.856 A:middle
to be recompiled.

00:20:10.856 --> 00:20:13.846 A:middle
After rerunning LTO
analysis, both controller.O

00:20:13.846 --> 00:20:17.486 A:middle
and main.O are optimized and
new LTO object files are stored

00:20:17.486 --> 00:20:18.376 A:middle
in the linker cache.

00:20:19.516 --> 00:20:25.186 A:middle
Then the LTO objects are linked
as before to produce the app.

00:20:25.456 --> 00:20:28.456 A:middle
Incremental LTO gives you
the performance you expect

00:20:28.676 --> 00:20:29.766 A:middle
from an incremental build.

00:20:30.896 --> 00:20:33.806 A:middle
When a source file with small
helper functions is changed,

00:20:34.306 --> 00:20:36.616 A:middle
object files that use
them get reoptimized.

00:20:37.426 --> 00:20:39.476 A:middle
But for a typical
incremental build,

00:20:39.826 --> 00:20:43.476 A:middle
most LTO object files are linked
directly from the linker cache.

00:20:45.146 --> 00:20:46.866 A:middle
Let's take a final
look at the time

00:20:46.866 --> 00:20:49.236 A:middle
to link the Apple
LLVM compiler itself.

00:20:49.946 --> 00:20:51.536 A:middle
The top three bars
show the times

00:20:51.536 --> 00:20:52.926 A:middle
for a fresh build from before.

00:20:54.496 --> 00:20:57.206 A:middle
If we change the implementation
of an optimization pass,

00:20:57.926 --> 00:21:00.596 A:middle
monolithic LTO takes
the same amount of time.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:20:57.926 --> 00:21:00.596 A:middle
monolithic LTO takes
the same amount of time.

00:21:00.596 --> 00:21:01.696 A:middle
It's the same as a fresh build.

00:21:02.376 --> 00:21:06.026 A:middle
But incremental LTO
takes only 8 seconds.

00:21:06.916 --> 00:21:09.196 A:middle
This is 16x faster
than the initial build,

00:21:09.196 --> 00:21:11.886 A:middle
and 100x faster than
monolithic LTO.

00:21:13.516 --> 00:21:16.446 A:middle
[ Applause ]

00:21:16.946 --> 00:21:17.556 A:middle
This is stunning.

00:21:19.466 --> 00:21:21.486 A:middle
State of the art, link
time optimization,

00:21:21.836 --> 00:21:25.896 A:middle
with low memory requirements
and fast incremental builds.

00:21:26.556 --> 00:21:28.736 A:middle
Try incremental LTO today.

00:21:30.056 --> 00:21:32.836 A:middle
The improvements to
LTO are fantastic,

00:21:33.616 --> 00:21:36.426 A:middle
but if you're using LTO
with a large C++ project,

00:21:36.606 --> 00:21:39.426 A:middle
you can minimize compile time
with the line tables only,

00:21:39.656 --> 00:21:41.046 A:middle
debug information level.

00:21:41.666 --> 00:21:43.106 A:middle
This gives you rich back traces

00:21:43.106 --> 00:21:45.076 A:middle
in the debugger,
at the lowest cost.

00:21:45.686 --> 00:21:48.796 A:middle
That's it for Link-Link
optimization.

00:21:49.726 --> 00:21:51.366 A:middle
I invite Gerolf on stage to talk

00:21:51.366 --> 00:21:53.496 A:middle
about new code generation
optimizations.

00:21:54.516 --> 00:21:59.256 A:middle
[ Applause ]

00:21:59.756 --> 00:22:02.326 A:middle
&gt;&gt; So, let's move on
with optimizations


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:21:59.756 --> 00:22:02.326 A:middle
&gt;&gt; So, let's move on
with optimizations

00:22:02.326 --> 00:22:03.276 A:middle
in the code generator.

00:22:03.686 --> 00:22:08.176 A:middle
We put a lot of effort into
the Xcode 8 Apple LLVM compiler

00:22:08.176 --> 00:22:11.166 A:middle
to improve the performance
of all apps.

00:22:12.276 --> 00:22:14.746 A:middle
In this section, I will
talk about three of them:

00:22:15.216 --> 00:22:17.116 A:middle
Stack packing, shrink wrapping,

00:22:18.336 --> 00:22:20.426 A:middle
and selective fused
multiply-add.

00:22:21.056 --> 00:22:22.476 A:middle
Let's start with stack packing.

00:22:23.156 --> 00:22:27.626 A:middle
This is about local variables
and runtime stack memory.

00:22:27.836 --> 00:22:30.766 A:middle
The Apple LLVM compiler
always had optimizations,

00:22:31.116 --> 00:22:34.826 A:middle
that try to reduce the
stack memory space.

00:22:35.246 --> 00:22:38.326 A:middle
In Xcode 8, the compiler
got better at doing

00:22:38.326 --> 00:22:39.406 A:middle
that than ever before.

00:22:40.376 --> 00:22:41.056 A:middle
And here is why.

00:22:41.236 --> 00:22:42.466 A:middle
Let's look at that example.

00:22:42.936 --> 00:22:44.416 A:middle
Pay attention to the definition

00:22:44.416 --> 00:22:48.386 A:middle
of x inside the scope
of the if statement.

00:22:48.836 --> 00:22:52.066 A:middle
Then look at the definition
of y after the if statement.

00:22:52.656 --> 00:22:55.246 A:middle
If the compiler does not
optimize this code snippet,

00:22:55.246 --> 00:22:57.976 A:middle
you would expect that the
two variables x and y,

00:22:58.316 --> 00:23:00.296 A:middle
live at two different
stack locations


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:58.316 --> 00:23:00.296 A:middle
live at two different
stack locations

00:23:00.296 --> 00:23:01.726 A:middle
on the runtime memory stack.

00:23:03.306 --> 00:23:07.886 A:middle
However, according to C-style
language rules, the lifetime

00:23:07.886 --> 00:23:10.916 A:middle
of a variable ends at the
scope where it is defined.

00:23:11.576 --> 00:23:14.156 A:middle
And this is what the
compiler exploits.

00:23:14.726 --> 00:23:17.836 A:middle
Let's take a look what this
does to our two variables.

00:23:19.196 --> 00:23:22.936 A:middle
x is defined inside
the if statement.

00:23:23.476 --> 00:23:26.896 A:middle
The scope of that if statement
ends just before y is defined.

00:23:28.426 --> 00:23:32.436 A:middle
When y is defined, it starts a
lifetime of y and what you see

00:23:32.436 --> 00:23:35.936 A:middle
in this picture is that x
and y, the lifetimes for x

00:23:35.936 --> 00:23:37.216 A:middle
and y, do not overlap.

00:23:37.826 --> 00:23:40.856 A:middle
So the compiler can assign
them the same stack location.

00:23:43.896 --> 00:23:48.646 A:middle
This reduces the total memory
stack required for your program,

00:23:48.986 --> 00:23:52.826 A:middle
and that may provide better
performance for your app.

00:23:54.106 --> 00:23:58.586 A:middle
Now this is all great, but
there is a little caveat

00:23:58.706 --> 00:24:00.366 A:middle
that comes with it.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:23:58.706 --> 00:24:00.366 A:middle
that comes with it.

00:24:01.516 --> 00:24:05.466 A:middle
Programming language rules are
sometimes really hard to check.

00:24:06.776 --> 00:24:08.076 A:middle
And when they are violated,

00:24:09.226 --> 00:24:12.876 A:middle
your program may give
unpredictable results,

00:24:12.936 --> 00:24:16.076 A:middle
or in a technical term, it
may have undefined behavior.

00:24:16.736 --> 00:24:18.166 A:middle
Let's take a look
at the example.

00:24:19.626 --> 00:24:21.796 A:middle
Pay attention to the
pointer variable.

00:24:22.066 --> 00:24:25.746 A:middle
Inside the if block, it gets
assigned the address of x.

00:24:25.986 --> 00:24:27.386 A:middle
Now look at the print statement.

00:24:27.886 --> 00:24:29.126 A:middle
At that point, the address

00:24:29.126 --> 00:24:31.376 A:middle
of x is used via the
pointer variable.

00:24:31.836 --> 00:24:34.486 A:middle
So what is happening
here is that the address

00:24:34.486 --> 00:24:37.636 A:middle
of x escapes the scope
of the if statement,

00:24:37.826 --> 00:24:39.696 A:middle
and that [inaudible]
our language rules

00:24:39.956 --> 00:24:41.296 A:middle
as undefined behavior.

00:24:43.016 --> 00:24:45.226 A:middle
Luckily, it is easy to fix.

00:24:45.226 --> 00:24:46.856 A:middle
It's just something
to be aware of.

00:24:47.266 --> 00:24:50.586 A:middle
The way you fix this is by
simply extending the scope

00:24:50.586 --> 00:24:54.946 A:middle
of the lifetime for x by moving
the definition of x outside the

00:24:54.946 --> 00:24:59.566 A:middle
if statement, just before
the condition is checked.

00:24:59.936 --> 00:25:04.996 A:middle
And now the definition of x is
in the same scope as the address


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:24:59.936 --> 00:25:04.996 A:middle
And now the definition of x is
in the same scope as the address

00:25:05.316 --> 00:25:07.256 A:middle
that is used in the
print statement.

00:25:08.746 --> 00:25:13.296 A:middle
The takeaway from this is simply
please make any effort you can

00:25:13.296 --> 00:25:15.996 A:middle
think of to make
your program adhere

00:25:15.996 --> 00:25:17.566 A:middle
to programming language rules,

00:25:17.696 --> 00:25:20.306 A:middle
that will give a much
better experience for you,

00:25:20.466 --> 00:25:23.626 A:middle
for the optimizing
compiler, and for our users.

00:25:24.536 --> 00:25:26.016 A:middle
That is stack packing.

00:25:28.036 --> 00:25:29.306 A:middle
Let's move on to
shrink wrapping.

00:25:30.706 --> 00:25:34.936 A:middle
Shrink wrapping is about the
code the compiler generates

00:25:35.256 --> 00:25:37.366 A:middle
in the entry and exit
of your function.

00:25:37.846 --> 00:25:39.306 A:middle
It's resource management code

00:25:39.646 --> 00:25:42.286 A:middle
that manages the runtime
stack and the registers.

00:25:43.156 --> 00:25:46.656 A:middle
The observation here is
that this code is not needed

00:25:46.656 --> 00:25:48.786 A:middle
for all the paths
through your function,

00:25:49.096 --> 00:25:53.216 A:middle
and shrink wrapping will
place this resource managing

00:25:53.216 --> 00:25:56.016 A:middle
instruction only to places
where they are actually needed.

00:25:57.036 --> 00:25:59.526 A:middle
So let's take a look
at a simple example.

00:25:59.626 --> 00:26:05.396 A:middle
So here's a simple function that
takes two parameters, a and b,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:25:59.626 --> 00:26:05.396 A:middle
So here's a simple function that
takes two parameters, a and b,

00:26:05.596 --> 00:26:06.866 A:middle
simple compares the two.

00:26:07.726 --> 00:26:10.496 A:middle
And if a is smaller than b,
then it calls a function foo

00:26:10.926 --> 00:26:14.756 A:middle
which has the address of a
local variable as a parameter,

00:26:14.876 --> 00:26:16.296 A:middle
and eventually it returns.

00:26:16.776 --> 00:26:18.106 A:middle
To understand shrink wrapping,

00:26:18.446 --> 00:26:21.196 A:middle
let's look at the
pseudo assembly code akin

00:26:21.196 --> 00:26:23.556 A:middle
to the code the compiler
actually generates.

00:26:23.946 --> 00:26:27.976 A:middle
So here you'll see an entry code
that allocates stack memory,

00:26:27.976 --> 00:26:30.626 A:middle
saves registers, does
the comparison, branches.

00:26:31.006 --> 00:26:33.396 A:middle
And the exit block that
restores the registers,

00:26:33.426 --> 00:26:35.766 A:middle
deallocates the stack,
and returns.

00:26:36.116 --> 00:26:37.526 A:middle
And then if the condition
is right,

00:26:37.846 --> 00:26:39.076 A:middle
the function foo is called.

00:26:39.136 --> 00:26:42.716 A:middle
So what we see here is we have
two paths in that program.

00:26:42.916 --> 00:26:46.626 A:middle
One from the entry to the
exit block, and another path

00:26:46.626 --> 00:26:49.946 A:middle
from the entry block to the
call -- to the exit block.

00:26:50.286 --> 00:26:52.226 A:middle
The key observation here is

00:26:52.316 --> 00:26:54.446 A:middle
that the resource
managing instructions

00:26:54.856 --> 00:26:58.656 A:middle
for the runtime stack memory

00:26:58.656 --> 00:27:00.956 A:middle
and for the registers
are only needed


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:26:58.656 --> 00:27:00.956 A:middle
and for the registers
are only needed

00:27:01.406 --> 00:27:04.906 A:middle
because we have a call
instruction in our function.

00:27:05.846 --> 00:27:08.806 A:middle
So what shrink wrapping does,
it recognizes this condition

00:27:09.206 --> 00:27:14.196 A:middle
and moves these instructions
out of the entry block and out

00:27:14.196 --> 00:27:17.166 A:middle
of the exit block to the place
where they actually need it.

00:27:17.166 --> 00:27:18.946 A:middle
So it shrinks the lifetimes

00:27:19.396 --> 00:27:22.046 A:middle
of the resource managing
instructions and wraps them

00:27:22.046 --> 00:27:23.956 A:middle
around the region, where
they are actually needed.

00:27:23.956 --> 00:27:26.216 A:middle
In this case, the
region is just the call.

00:27:26.796 --> 00:27:29.516 A:middle
But now imagine,
that the hot code

00:27:29.706 --> 00:27:34.076 A:middle
in your function is the path
from the entry to the exit.

00:27:34.266 --> 00:27:37.216 A:middle
No longer do we have
to execute the resource

00:27:37.216 --> 00:27:38.596 A:middle
allocating instructions.

00:27:39.256 --> 00:27:40.706 A:middle
And if this is hot functions,

00:27:40.706 --> 00:27:42.646 A:middle
you have many functions
like this.

00:27:42.846 --> 00:27:45.206 A:middle
You can imagine that this
way we can save millions

00:27:45.206 --> 00:27:47.876 A:middle
of instructions, providing
nice performance gains,

00:27:48.066 --> 00:27:50.036 A:middle
and also power savings
for your app.

00:27:51.056 --> 00:27:52.586 A:middle
And that is shrink wrapping.

00:27:54.516 --> 00:27:59.516 A:middle
[ Applause ]


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:28:00.016 --> 00:28:02.256 A:middle
Let's move on with
fused multiply-adds.

00:28:03.116 --> 00:28:06.386 A:middle
It takes us back to very
simple arithmetical operations,

00:28:06.386 --> 00:28:07.976 A:middle
additions and multiplications.

00:28:08.456 --> 00:28:12.936 A:middle
The arm64 processor
has one instructions --

00:28:12.936 --> 00:28:14.986 A:middle
a fused multiply-add
instructions --

00:28:15.496 --> 00:28:17.696 A:middle
instruction, that
computes an expression

00:28:17.896 --> 00:28:21.426 A:middle
like a plus b times c, in
one single instruction.

00:28:21.966 --> 00:28:26.346 A:middle
You would naively assume that
whenever you see an expression

00:28:26.346 --> 00:28:30.386 A:middle
like this, it's always the best
to generate this instruction.

00:28:30.816 --> 00:28:33.366 A:middle
And that's exactly what the
compiler has done so far.

00:28:33.946 --> 00:28:36.186 A:middle
But it may surprise you.

00:28:36.476 --> 00:28:38.746 A:middle
In some cases, it's
actually faster

00:28:39.056 --> 00:28:42.006 A:middle
to generate two instructions,
an add instruction,

00:28:42.326 --> 00:28:43.826 A:middle
and a multiply instruction,

00:28:43.996 --> 00:28:45.776 A:middle
to get faster performance
for your app.

00:28:46.896 --> 00:28:50.746 A:middle
Why? I've prepared a simple
example to demonstrate this.

00:28:52.486 --> 00:28:55.486 A:middle
This function takes
four integer parameters

00:28:55.486 --> 00:28:57.496 A:middle
and it computes a
simple expression,

00:28:57.806 --> 00:28:59.716 A:middle
a times b plus c times d.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:01.456 --> 00:29:02.516 A:middle
What does the code look

00:29:02.516 --> 00:29:05.576 A:middle
like when the compiler
generates a single fused

00:29:05.576 --> 00:29:06.976 A:middle
multipy-add instruction?

00:29:08.186 --> 00:29:12.446 A:middle
Well, it will compute a times
b, then the multiply-add had

00:29:12.516 --> 00:29:13.876 A:middle
to wait for that result.

00:29:14.346 --> 00:29:18.536 A:middle
And the multiply-add
will compute the value

00:29:18.686 --> 00:29:19.676 A:middle
of our expression.

00:29:20.176 --> 00:29:21.166 A:middle
How long does this take?

00:29:21.166 --> 00:29:24.156 A:middle
It takes four cycle
for the multiply,

00:29:24.156 --> 00:29:25.756 A:middle
four cycle for the add.

00:29:26.216 --> 00:29:31.806 A:middle
So in total, that simple
sequence takes eight cycles.

00:29:32.846 --> 00:29:35.896 A:middle
When we generate 2
multiplies and 1 add,

00:29:36.886 --> 00:29:38.136 A:middle
how can that be faster?

00:29:38.606 --> 00:29:40.096 A:middle
Let's take a look
at that sequence.

00:29:41.056 --> 00:29:43.746 A:middle
First we issue the
compiler issues a multiply,

00:29:43.746 --> 00:29:47.156 A:middle
computes a times b,
then computes c times d.

00:29:47.316 --> 00:29:49.956 A:middle
Eventually adds the result.

00:29:50.906 --> 00:29:54.806 A:middle
The secret here is that modern
processors have instruction

00:29:54.806 --> 00:29:55.776 A:middle
level parallelism.

00:29:56.056 --> 00:29:59.506 A:middle
They can execute two
or more multiplies


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:01.076 --> 00:30:03.426 A:middle
at the same time, in parallel.

00:30:03.826 --> 00:30:05.576 A:middle
So what is happening here is

00:30:05.576 --> 00:30:08.216 A:middle
that the two multiplies
get executed in parallel.

00:30:08.446 --> 00:30:12.276 A:middle
So within four cycles, we don't
get the result of one multiply,

00:30:12.276 --> 00:30:14.326 A:middle
but the results of
two multiplies.

00:30:14.606 --> 00:30:18.716 A:middle
Then we just add the results
in one cycle, and now we see

00:30:18.716 --> 00:30:22.756 A:middle
that for this to compute the
value of this expression,

00:30:22.846 --> 00:30:24.786 A:middle
we only need five cycles.

00:30:24.916 --> 00:30:28.076 A:middle
Let's compare this with
the sequence for --

00:30:28.526 --> 00:30:32.106 A:middle
with the sequence with a fewest
multiply-add and now we see

00:30:32.106 --> 00:30:35.846 A:middle
that for this simple sequence,
we get a speed up of about 2x.

00:30:37.226 --> 00:30:40.726 A:middle
So with selective fused
multiply-add, you can now speed

00:30:40.726 --> 00:30:43.536 A:middle
up many simple expressions
in your app.

00:30:44.146 --> 00:30:46.116 A:middle
And that is fused multiply-add.

00:30:47.516 --> 00:30:52.976 A:middle
[ Applause ]

00:30:53.476 --> 00:30:56.976 A:middle
So let's move on to
arm64 cache tuning.

00:30:58.326 --> 00:31:02.346 A:middle
Here I will talk about two
techniques: The compiler has


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:58.326 --> 00:31:02.346 A:middle
Here I will talk about two
techniques: The compiler has

00:31:02.386 --> 00:31:07.006 A:middle
to impact which data gets stored
into the cache and the data

00:31:07.006 --> 00:31:08.636 A:middle
that gets stored into the cache,

00:31:08.706 --> 00:31:10.686 A:middle
impact the performance
of your app.

00:31:11.896 --> 00:31:14.996 A:middle
Before we go into the details,
what the compiler is doing,

00:31:15.266 --> 00:31:17.846 A:middle
I want to quickly review
the memory hierarchy.

00:31:18.506 --> 00:31:20.176 A:middle
At the top, you see
the main memory

00:31:20.176 --> 00:31:22.546 A:middle
that hosts the program
variables.

00:31:24.186 --> 00:31:26.176 A:middle
And it's at the top.

00:31:26.176 --> 00:31:27.806 A:middle
At the bottom, you
see the registers.

00:31:27.806 --> 00:31:31.656 A:middle
It's very slow to load data from
main memory to the registers.

00:31:31.836 --> 00:31:35.246 A:middle
To bridge that gap, there's
a cache, a temporary storage.

00:31:35.606 --> 00:31:37.546 A:middle
It's about 10,000
to 100 times --

00:31:37.616 --> 00:31:41.516 A:middle
to 100,000 times smaller than
main memory, but it's much,

00:31:41.516 --> 00:31:43.866 A:middle
much faster to load
data out of the cache.

00:31:43.866 --> 00:31:46.276 A:middle
About 10 times to
100 times faster.

00:31:47.066 --> 00:31:49.146 A:middle
Then data is loaded
out of main memory.

00:31:50.336 --> 00:31:53.216 A:middle
We not only load a
single register value,

00:31:53.216 --> 00:31:56.056 A:middle
but an entire cache
line out of main memory.

00:31:56.296 --> 00:31:59.166 A:middle
So cache line contains more
than one register value.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:00.126 --> 00:32:02.696 A:middle
The reason why this design
is usually so successful,

00:32:02.696 --> 00:32:06.966 A:middle
is because your program data
have two locality properties:

00:32:07.206 --> 00:32:10.066 A:middle
Temporal locality
and spatial locality.

00:32:10.676 --> 00:32:14.176 A:middle
Temporal locality simply means
the data your program accesses

00:32:14.176 --> 00:32:16.446 A:middle
now, it will access
this very soon again.

00:32:16.916 --> 00:32:22.316 A:middle
Spatial locality simply means
data your program accesses now,

00:32:22.386 --> 00:32:24.226 A:middle
it will also access
neighboring data.

00:32:24.776 --> 00:32:27.036 A:middle
So when you access
an array field,

00:32:27.036 --> 00:32:29.396 A:middle
it will also access
the field next to it.

00:32:29.596 --> 00:32:33.216 A:middle
When it accesses a field
in your data structure,

00:32:33.216 --> 00:32:35.436 A:middle
it will also access
a field next to that.

00:32:35.816 --> 00:32:37.056 A:middle
And so on and so forth.

00:32:37.056 --> 00:32:42.496 A:middle
Now, you look at this
design, and you wonder --

00:32:42.636 --> 00:32:46.106 A:middle
so it's so fast to load
data out of the cache.

00:32:46.666 --> 00:32:50.376 A:middle
Can we somehow magically
preload the data into the cache,

00:32:50.376 --> 00:32:53.506 A:middle
out of main memory while the
processor is doing some other

00:32:53.506 --> 00:32:56.366 A:middle
operations, so that all
data get loaded quickly

00:32:56.456 --> 00:32:58.726 A:middle
when we need them, when
our programs need them?

00:32:58.956 --> 00:33:05.206 A:middle
It might surprise you, on your
processor, in your iPhone,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:58.956 --> 00:33:05.206 A:middle
It might surprise you, on your
processor, in your iPhone,

00:33:05.366 --> 00:33:07.076 A:middle
that magic is already happening.

00:33:07.846 --> 00:33:08.946 A:middle
It's hardware prefetching.

00:33:09.456 --> 00:33:13.306 A:middle
The processor looks at each
address that is loaded,

00:33:13.786 --> 00:33:16.046 A:middle
tries to find pattern
in those addresses.

00:33:16.276 --> 00:33:17.466 A:middle
When it finds a pattern,

00:33:17.726 --> 00:33:21.356 A:middle
it predicts which data your
program will need in the future,

00:33:21.676 --> 00:33:24.636 A:middle
prefetches this data out
of main memory, again,

00:33:24.636 --> 00:33:27.496 A:middle
while other complications
are happening, puts the data

00:33:27.496 --> 00:33:30.536 A:middle
into the cache and eventually
when your program needs them,

00:33:30.726 --> 00:33:33.006 A:middle
the program can load them
quickly, out of the cache.

00:33:34.236 --> 00:33:36.996 A:middle
Now this year, we worked
with the hardware architects

00:33:37.536 --> 00:33:41.436 A:middle
to see how the compiler
can even make

00:33:41.436 --> 00:33:44.346 A:middle
that prefetching magic
work better for your apps.

00:33:45.836 --> 00:33:47.076 A:middle
And we found a few patterns.

00:33:47.076 --> 00:33:51.186 A:middle
So what the compiler does now,
it analyzes your source code,

00:33:51.626 --> 00:33:54.496 A:middle
predicts which data your
app will need in the future,

00:33:55.336 --> 00:33:59.916 A:middle
issues prefetch instructions
for this app, for this data.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:00.326 --> 00:34:01.656 A:middle
Now while your app is running,

00:34:02.026 --> 00:34:05.076 A:middle
the prefetch instruction
executes, fetches the data

00:34:05.306 --> 00:34:07.476 A:middle
from main memory, puts
it into the cache,

00:34:09.106 --> 00:34:13.085 A:middle
and when your program is ready
to need those data, it simply

00:34:13.085 --> 00:34:14.916 A:middle
and quickly loads
it out of the cache.

00:34:14.916 --> 00:34:17.136 A:middle
Your program no longer
has to wait for the data

00:34:17.136 --> 00:34:18.815 A:middle
to be loaded out of main memory.

00:34:19.496 --> 00:34:21.726 A:middle
And that is the magic
of software prefetching.

00:34:25.126 --> 00:34:25.616 A:middle
So far--

00:34:26.516 --> 00:34:31.775 A:middle
[ Applause ]

00:34:32.275 --> 00:34:33.746 A:middle
-- so far, I have talked

00:34:33.746 --> 00:34:36.916 A:middle
about optimizations the compiler
does automatically for you.

00:34:37.996 --> 00:34:39.585 A:middle
For the next optimization,

00:34:39.726 --> 00:34:42.016 A:middle
non-temporal stores it
will need your help.

00:34:42.525 --> 00:34:47.866 A:middle
To understand what is going on
there, we need to take a look

00:34:48.025 --> 00:34:53.206 A:middle
at what is happening when data
is stored into main memory.

00:34:54.036 --> 00:34:58.096 A:middle
So again, let's take a look
at our memory hierarchy,

00:34:58.286 --> 00:35:02.516 A:middle
and assume we have a simple
assignment in our program


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:34:58.286 --> 00:35:02.516 A:middle
and assume we have a simple
assignment in our program

00:35:02.516 --> 00:35:06.306 A:middle
where we want to assign a
value of say 100, to a variable

00:35:06.306 --> 00:35:09.596 A:middle
in main memory, which has
the current value of 55.

00:35:10.746 --> 00:35:14.016 A:middle
The first thing that is
happening, the old data

00:35:14.016 --> 00:35:16.386 A:middle
from the address you want
to store the new value

00:35:16.386 --> 00:35:20.026 A:middle
in is loaded into the cache.

00:35:20.026 --> 00:35:23.646 A:middle
And since we load data from main
memory, not only the old data

00:35:23.646 --> 00:35:26.776 A:middle
for that variable is loaded,
but also the neighboring data --

00:35:27.436 --> 00:35:28.606 A:middle
also the neighboring data

00:35:28.726 --> 00:35:30.416 A:middle
because we fill the
entire cache line.

00:35:31.866 --> 00:35:36.586 A:middle
In the second step, we store
the value in our register,

00:35:37.116 --> 00:35:41.786 A:middle
into the cache line,
in the cache.

00:35:43.286 --> 00:35:46.086 A:middle
And then finally, the
data in the cache line

00:35:46.176 --> 00:35:48.236 A:middle
or the cache line is
needed for different data

00:35:48.346 --> 00:35:50.596 A:middle
and our values get written back

00:35:50.596 --> 00:35:52.426 A:middle
in the third step
to main memory.

00:35:52.756 --> 00:35:54.996 A:middle
So it's a three step process.

00:35:56.166 --> 00:35:58.476 A:middle
Loading data from main
memory into the cache,

00:35:58.606 --> 00:36:00.776 A:middle
store the register
value into the cache,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:35:58.606 --> 00:36:00.776 A:middle
store the register
value into the cache,

00:36:00.886 --> 00:36:04.056 A:middle
and then eventually store the
data back into main memory.

00:36:04.946 --> 00:36:09.466 A:middle
And this all because data
usually have the locality

00:36:09.466 --> 00:36:12.456 A:middle
property, and specifically
temporal locality.

00:36:12.926 --> 00:36:16.226 A:middle
But what if your data do
not have temporal locality?

00:36:16.226 --> 00:36:22.566 A:middle
Wouldn't it be much faster to
simply store the value directly

00:36:22.686 --> 00:36:29.146 A:middle
from the register into the main
memory in just one, single step?

00:36:30.626 --> 00:36:34.096 A:middle
This is exactly what
non-temporal stores do.

00:36:34.326 --> 00:36:36.756 A:middle
They avoid the extra
load of a cache line,

00:36:37.596 --> 00:36:41.606 A:middle
and also the other benefit of
that you have is since you know

00:36:41.606 --> 00:36:45.686 A:middle
that the data are no
longer needed, that don't go

00:36:45.686 --> 00:36:48.956 A:middle
into the cache, so the cache
can now have other data

00:36:48.956 --> 00:36:50.616 A:middle
for your app that
are more useful.

00:36:51.626 --> 00:36:53.436 A:middle
The way you instruct
the compiler

00:36:53.566 --> 00:36:57.126 A:middle
to generate non-temporal stores
is with a compiler builtin.

00:36:57.806 --> 00:37:02.096 A:middle
So you use the builtin
to instruct the compiler


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:36:57.806 --> 00:37:02.096 A:middle
So you use the builtin
to instruct the compiler

00:37:02.096 --> 00:37:03.956 A:middle
to generate the non-temporal
stores.

00:37:04.186 --> 00:37:05.516 A:middle
It takes two parameters.

00:37:05.646 --> 00:37:08.096 A:middle
The value you want to
store, and the address

00:37:08.196 --> 00:37:09.646 A:middle
where you want to store it to.

00:37:11.606 --> 00:37:14.246 A:middle
When do you want to use
non-temporal stores?

00:37:14.506 --> 00:37:17.236 A:middle
When there is no [inaudible]
use, no temporal locality

00:37:17.786 --> 00:37:22.786 A:middle
in your code, you copy a large
chunk of data, preferably larger

00:37:22.786 --> 00:37:26.706 A:middle
than the size of the cache,
and to make it really count

00:37:26.706 --> 00:37:29.146 A:middle
for your app, it should be
where the performance is hiding.

00:37:29.416 --> 00:37:30.706 A:middle
So it should be in hot loops.

00:37:31.576 --> 00:37:34.006 A:middle
And you don't want to use a
non-temporal storage basically

00:37:34.006 --> 00:37:36.506 A:middle
when any of these
condition does not hold.

00:37:37.026 --> 00:37:40.366 A:middle
What can you gain from this?

00:37:41.116 --> 00:37:41.956 A:middle
So in this slide?

00:37:42.986 --> 00:37:47.066 A:middle
We look at the performance gains
from the non-temporal stores

00:37:47.506 --> 00:37:51.396 A:middle
on three benchmarks that contain
hot loops that look similar

00:37:51.396 --> 00:37:53.526 A:middle
to the example that
I showed you before.

00:37:54.106 --> 00:37:55.786 A:middle
So what this data show you is

00:37:55.856 --> 00:37:58.506 A:middle
that for very common
loop bodies,

00:37:59.056 --> 00:38:02.486 A:middle
you get very significant
speed ups in the range


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:37:59.056 --> 00:38:02.486 A:middle
you get very significant
speed ups in the range

00:38:02.486 --> 00:38:05.026 A:middle
from 30 to 40 percent.

00:38:05.926 --> 00:38:09.106 A:middle
And that is what non-temporal
stores can hopefully do

00:38:09.106 --> 00:38:10.966 A:middle
for many hot loops in your app.

00:38:12.516 --> 00:38:19.076 A:middle
[ Applause ]

00:38:19.576 --> 00:38:20.536 A:middle
It has been a long journey.

00:38:21.796 --> 00:38:25.136 A:middle
We have looked at many,
many new features and a lot

00:38:25.136 --> 00:38:26.786 A:middle
of great new optimizations

00:38:27.056 --> 00:38:29.856 A:middle
that the new compiler
brings to your app.

00:38:30.536 --> 00:38:35.166 A:middle
So we've talked about the
Apple LLVM compiler is based

00:38:35.166 --> 00:38:36.506 A:middle
on an open source project.

00:38:36.506 --> 00:38:39.286 A:middle
You can interact with us in
the open source community,

00:38:39.646 --> 00:38:42.196 A:middle
even provide patches for
your favorite compiler.

00:38:42.746 --> 00:38:44.806 A:middle
We have seen many
great new features

00:38:44.806 --> 00:38:46.706 A:middle
like the objective
class properties

00:38:47.126 --> 00:38:50.216 A:middle
and C++11 thread
local storage support.

00:38:50.626 --> 00:38:57.656 A:middle
Now the new Libc ++ has
full support for C++14

00:38:57.996 --> 00:39:01.816 A:middle
and has many new improved
features, but keep in mind,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:38:57.996 --> 00:39:01.816 A:middle
and has many new improved
features, but keep in mind,

00:39:01.936 --> 00:39:04.516 A:middle
that Libstandardc++
is deprecated.

00:39:05.086 --> 00:39:07.026 A:middle
You get many more
warning and diagnostics

00:39:07.066 --> 00:39:09.026 A:middle
to make your code
cleaner than ever before.

00:39:09.746 --> 00:39:12.266 A:middle
And you heard about this
fantastic new feature,

00:39:12.496 --> 00:39:15.926 A:middle
incremental LTO that gives you
basically the same performance

00:39:16.146 --> 00:39:19.936 A:middle
as monolithic LTO, and really,
truly, awesome compile time.

00:39:20.576 --> 00:39:22.776 A:middle
And we talked about a
number of optimizations

00:39:22.776 --> 00:39:25.976 A:middle
in the code generator that
automatically should speed

00:39:25.976 --> 00:39:29.896 A:middle
up all your apps,
and we finally talked

00:39:29.896 --> 00:39:34.196 A:middle
about long term pro stores where
the compiler provides the means,

00:39:34.906 --> 00:39:37.266 A:middle
but you provide the smarts,
and then to use them.

00:39:38.226 --> 00:39:41.206 A:middle
So I hope all this convinces you

00:39:41.206 --> 00:39:44.036 A:middle
that we put together a really
great compiler release.

00:39:44.036 --> 00:39:46.296 A:middle
We couldn't be happier about it.

00:39:46.516 --> 00:39:47.766 A:middle
Please get your hands on it.

00:39:47.976 --> 00:39:50.806 A:middle
Check it out, what it
can do for your app.

00:39:51.596 --> 00:39:55.286 A:middle
You'll find more
information on our website.

00:39:56.006 --> 00:40:00.276 A:middle
There are a number of
really cool talks out there


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:39:56.006 --> 00:40:00.276 A:middle
There are a number of
really cool talks out there

00:40:01.546 --> 00:40:03.016 A:middle
that you should be
interested in.

00:40:03.216 --> 00:40:03.846 A:middle
Check them out.

00:40:04.266 --> 00:40:05.516 A:middle
Thank you all for watching.

00:40:05.686 --> 00:40:06.476 A:middle
Thank you for coming.

00:40:06.476 --> 00:40:08.716 A:middle
Have a great time
at the conference.

00:40:09.016 --> 00:40:11.000 A:middle
[ Applause ]

