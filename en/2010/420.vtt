WEBVTT

00:00:07.870 --> 00:00:10.020
>> Matt Collins: Good morning.

00:00:10.020 --> 00:00:11.230
Thanks for all coming this morning.

00:00:11.230 --> 00:00:14.820
A little early, I see a few bleary eyes out there.

00:00:14.820 --> 00:00:16.890
Today we're going to talk about OpenGL on Mac OS.

00:00:16.890 --> 00:00:18.950
We're going to give the desktops some love.

00:00:18.950 --> 00:00:20.260
So let's begin.

00:00:20.260 --> 00:00:23.670
My name's Matt Collins, I'm a member
of Apple's GPU Software Team,

00:00:23.670 --> 00:00:27.200
we work on the OpenGL software stack and the driver stack.

00:00:27.200 --> 00:00:34.450
So today I'm going to go over a little bit about things
we added in 10.6.3 and some of the other software updates.

00:00:34.450 --> 00:00:37.570
First you might be wondering where we're at.

00:00:37.570 --> 00:00:43.100
So you wonder, I want to make a Mac game
or some 3D app on the Macintosh and I want

00:00:43.100 --> 00:00:45.730
to know what I can target, what kind of features exist.

00:00:45.730 --> 00:00:48.350
Want to know what's new in 10.6.3 and 10.6.4.

00:00:48.350 --> 00:00:51.240
You may have heard of new extensions or
new features we've added for you guys.

00:00:51.240 --> 00:00:53.140
So we'll go over those.

00:00:53.140 --> 00:00:55.730
And you might want to know what does that mean for your app.

00:00:55.730 --> 00:00:59.830
What's new, what's cool, how can you leverage it.

00:00:59.830 --> 00:01:01.770
We'll also talk a little bit about performance.

00:01:01.770 --> 00:01:03.720
So say you got your rendering looking great,

00:01:03.720 --> 00:01:07.440
and now you want to get a little bit
of performance, you want some speed.

00:01:07.440 --> 00:01:11.480
So I'll go over tips and tricks, and
we'll make your app really shine.

00:01:11.480 --> 00:01:18.070
And lastly, we'll do some pretty pictures, because
I'd be remiss if I said I'm going come up here

00:01:18.070 --> 00:01:20.420
and talk about graphics, but it's
going to be nothing cool to look at,

00:01:20.420 --> 00:01:25.600
so we'll have some cool techniques,
rendering techniques, and cool demos.

00:01:25.600 --> 00:01:28.850
First let's talk about OpenGL.

00:01:28.850 --> 00:01:30.310
Give you a little background.

00:01:30.310 --> 00:01:34.520
You may have gone to some of the
early talks, talking about OpenGL ES.

00:01:34.520 --> 00:01:37.090
This is the lowest level access to the graphics hardware.

00:01:37.090 --> 00:01:43.760
So on the desktop if you want to get the GPU's
power and really use it, you've got to use OpenGL.

00:01:43.760 --> 00:01:45.880
Most of our other frameworks are built on top of it.

00:01:45.880 --> 00:01:52.850
So everything else, like Core Image, Core Animation,
Quartz Composer, they're all built on top of OpenGL

00:01:52.850 --> 00:01:54.700
and they all use it to leverage the GPU's power.

00:01:54.700 --> 00:02:00.030
So let's talk about last time at WWDC.

00:02:00.030 --> 00:02:02.520
So some of this should be a quick recap for some of you.

00:02:02.520 --> 00:02:10.750
You might have heard of buffer objects, vertex
buffers, index buffers, frame buffer objects,

00:02:10.750 --> 00:02:17.670
fixed function pipeline, multitexturing, shader
pipeline, and you've heard of the vertex shader,

00:02:17.670 --> 00:02:19.650
the geometry shader, the fragment shader.

00:02:19.650 --> 00:02:20.800
This should all be a quick overview.

00:02:20.800 --> 00:02:27.910
We'll go over some of these topics in more detail and if
you have any questions you can always come and talk to us.

00:02:27.910 --> 00:02:29.170
So that's where we were.

00:02:29.170 --> 00:02:31.130
But where are we now?

00:02:31.130 --> 00:02:33.860
Well, now we have new extensions, new features.

00:02:33.860 --> 00:02:35.820
Give you better access to hardware functionality.

00:02:35.820 --> 00:02:40.670
These are things your GPU could already
do but you didn't have good access to.

00:02:40.670 --> 00:02:43.250
Most of this is 10.6.3 and above only.

00:02:43.250 --> 00:02:48.890
So if you want to target these cool new
things you've got to use 10.6.3 and above.

00:02:48.890 --> 00:02:51.770
But first some advice.

00:02:51.770 --> 00:02:56.850
The first piece of advice, and you may have heard this at
some of our other talks is use generic vertex attributes.

00:02:56.850 --> 00:03:00.100
So when you send a vertex down to the
GPU to render they have attributes.

00:03:00.100 --> 00:03:03.280
This could be the position, the
color, the normal, et cetera.

00:03:03.280 --> 00:03:04.480
And those are all built in to OpenGL.

00:03:04.480 --> 00:03:07.390
But we're going to tell you to use the generic ones.

00:03:07.390 --> 00:03:12.000
This is because this is the best way to
use a shader, and shaders are native.

00:03:12.000 --> 00:03:16.790
So if you have a fixed function which is the
old style rendering, glBegin, glEnd, et cetera,

00:03:16.790 --> 00:03:18.800
those are all actually emulated in the drivers.

00:03:18.800 --> 00:03:21.760
If you went to Dan Omachi's talk you
may have heard that whenever you set

00:03:21.760 --> 00:03:28.770
up fixed function state your driver will actually
generate a shader behind the scenes to emulate that state.

00:03:28.770 --> 00:03:33.340
And even better, you can port to OpenGL
ES 2.0 if you use generic attributes,

00:03:33.340 --> 00:03:36.960
because OpenGL ES doesn't have any of
the old fixed function stuff at all.

00:03:36.960 --> 00:03:41.010
Now let's talk about some new things.

00:03:41.010 --> 00:03:45.080
This is all stuff that's now available in 10.6.3.

00:03:45.080 --> 00:03:49.150
First we have a set of extensions that are here
really to make your life easier, compatibility.

00:03:49.150 --> 00:03:53.940
So provoking vertex, vertex array, BGRA, depth buffer flow.

00:03:53.940 --> 00:03:56.570
This is all to help you with compatibility and porting.

00:03:56.570 --> 00:04:00.670
Next we have a set that's really about empowering your app.

00:04:00.670 --> 00:04:04.150
So some new features that allow you to do
techniques you just couldn't do before.

00:04:04.150 --> 00:04:06.890
Frame buffer objects, texture arrays, and instancing.

00:04:06.890 --> 00:04:16.370
And last we have a set for performance and memory,
conditional rendering, different texture formats,

00:04:16.370 --> 00:04:22.280
texture RG, two-channel textures, packed float which
is mainly for HGR and shared exponent textures.

00:04:22.280 --> 00:04:25.630
So we'll go over these in detail individually.

00:04:25.630 --> 00:04:28.750
And we'll do some learning.

00:04:28.750 --> 00:04:32.390
So first I'll talk about an extension,
I'm going to tell you what it does.

00:04:32.390 --> 00:04:34.850
Then I'll tell you why you should care.

00:04:34.850 --> 00:04:37.900
Lastly, I'll show you a demo of
something cool that you can do with it.

00:04:37.900 --> 00:04:40.440
So let's get started.

00:04:40.440 --> 00:04:43.960
First we'll talk about the flexibility
of the compatibility extensions.

00:04:43.960 --> 00:04:47.980
The first one is provoking vertex
selection, this is EXT_provokes_vertex.

00:04:47.980 --> 00:04:50.440
Now who here is familiar with the term provoking vertex?

00:04:50.440 --> 00:04:52.560
Anyone? That's good.

00:04:52.560 --> 00:04:55.860
Okay, well I'll give you a little explanation.

00:04:55.860 --> 00:04:59.360
When you draw something you can either
have it smooth shaded or flat shaded.

00:04:59.360 --> 00:05:01.330
A flat shaded thing is the same color.

00:05:01.330 --> 00:05:06.870
So if you have a square, a quad
that's flat shaded, excuse me --

00:05:06.870 --> 00:05:09.900
the color has to be chosen from one of
the vertices that make up that quad.

00:05:09.900 --> 00:05:11.860
And that is the provoking vertex.

00:05:11.860 --> 00:05:17.160
Now in OpenGL, normally the provoking
vertex would be the last one.

00:05:17.160 --> 00:05:22.220
This let's you select which one is the provoking vertex,
so you can tell which vertex supplies that attribute.

00:05:22.220 --> 00:05:26.840
You have a new entry point, very simple glProvokingVertex.

00:05:26.840 --> 00:05:28.910
You can tell it pick the first or pick the last.

00:05:28.910 --> 00:05:31.330
Couldn't be easier.

00:05:31.330 --> 00:05:32.670
Now I brought up quads.

00:05:32.670 --> 00:05:33.490
What about quads?

00:05:33.490 --> 00:05:38.390
Well quads are hardware dependent, because all of
our GPUs, they're really good at rendering triangles.

00:05:38.390 --> 00:05:43.820
You can make a quad with two triangles, but that's not
how the hardware works, you know, on the very basic level.

00:05:43.820 --> 00:05:45.720
So the behavior for a quad is hardware dependent.

00:05:45.720 --> 00:05:49.720
And you can query this with this enum
GL_QUADS_FOLLOW_PROVOKING_VERTEX,

00:05:49.720 --> 00:05:53.420
and it will tell you whether your
setting is either ignored or obeyed.

00:05:53.420 --> 00:05:58.820
Now that's interesting, but why do you care.

00:05:58.820 --> 00:06:02.980
Well, for better flexibility, sure.

00:06:02.980 --> 00:06:08.000
But mainly it allows you to pick which
vertex you're pulling your color,

00:06:08.000 --> 00:06:11.000
your attributes from, without modifying your art assets.

00:06:11.000 --> 00:06:13.510
So let's say you had a game and
it had some cool particle system.

00:06:13.510 --> 00:06:16.850
And when a Jeep went across the
ground it kicked up a bunch of dust.

00:06:16.850 --> 00:06:23.490
So you have a particle spray, and it's a gray dust cloud,
but maybe you want a red dust cloud or a green dust cloud.

00:06:23.490 --> 00:06:32.000
You could set a color on one of the vertices for that
particle, and you could get a colored dust cloud.

00:06:32.000 --> 00:06:35.580
So here's an example of a flat-shaded gear.

00:06:35.580 --> 00:06:40.500
Now when you think about it, you don't just have to use
color, you could use anything to be flat shaded, right?

00:06:40.500 --> 00:06:43.450
So here you have an example of
normals that you're being visualized.

00:06:43.450 --> 00:06:45.800
So even the normal can be flat shaded.

00:06:45.800 --> 00:06:46.600
It's anything you want.

00:06:46.600 --> 00:06:47.610
It doesn't just have to be color.

00:06:47.610 --> 00:06:52.300
This is just an example of how you
could use anything to be flat shaded.

00:06:52.300 --> 00:06:56.670
Next let's talk about BGRA ordering.

00:06:56.670 --> 00:07:01.370
Now in OpenGL normally when you
provide a color it's going to be RGBA.

00:07:01.370 --> 00:07:03.460
Other APIs may not work this way.

00:07:03.460 --> 00:07:07.930
So this allows you to specify colors in BGRA order.

00:07:07.930 --> 00:07:12.370
Again, you can use something without
modifying your art assets.

00:07:12.370 --> 00:07:18.250
Something a little strange about this extension,
though, is that you actually supply GL_BGRA

00:07:18.250 --> 00:07:21.850
as a size parameter, not as -- there's no order parameter.

00:07:21.850 --> 00:07:26.890
So normally you would specify ColorPointer,
SecondaryColorPointer, or VertexAttribPointer,

00:07:26.890 --> 00:07:34.210
and I put VertexAttribPointer in gold because that's
how you supply a general vertex attribute which is good.

00:07:34.210 --> 00:07:39.870
But if you use this, the sizes implied to be four, even
though you're actually setting the size as GL_BGRA.

00:07:39.870 --> 00:07:46.240
And this has to be unsigned bytes only, because it
has to do with how you're packing your stuff in.

00:07:46.240 --> 00:07:48.240
So here's some code, it's very simple.

00:07:48.240 --> 00:07:50.550
You bind a buffer and your color VBO name.

00:07:50.550 --> 00:07:55.130
If you've gone to some of the other talks
they talk about the importance of using VBOs.

00:07:55.130 --> 00:07:57.720
So I put all my colors in this VBO, now I bind it.

00:07:57.720 --> 00:07:59.590
And now I say VertexAttribPointer.

00:07:59.590 --> 00:08:03.130
I give it the index, which is the
index of my attribute in my shader.

00:08:03.130 --> 00:08:11.630
And then instead of size I have GL_BGRA and UNSIGNED_BYTE,
FALSE means I don't want it to be normalized, 0, NULL.

00:08:11.630 --> 00:08:12.600
Pretty simple.

00:08:12.600 --> 00:08:17.480
Next we'll talk about some floating point depth buffers.

00:08:17.480 --> 00:08:22.240
This is just a couple new formats for your floating point
depth buffer -- or for your depth buffer in general.

00:08:22.240 --> 00:08:29.100
It allows you to be floating point, 32-bits of float,
and there's also a 32-bit with an 8-bit stencil.

00:08:29.100 --> 00:08:35.550
New type. And one thing to keep in mind is you notice
32-bits plus 8 bits, that's more than a single double word.

00:08:35.550 --> 00:08:38.730
So you're going to be using a lot more
space if you use a 32-bit depth buffer

00:08:38.730 --> 00:08:43.670
and an 8-bit stencil buffer, something to keep in mind.

00:08:43.670 --> 00:08:45.410
Now why would you want to do this?

00:08:45.410 --> 00:08:49.210
Well, it's mainly for very deep scenes or very small scenes.

00:08:49.210 --> 00:08:54.300
So keep in mind if you're rendering, like, the
universe, that's really, really deep, right?

00:08:54.300 --> 00:08:57.350
So a floating point number is going to
be better at doing something like that.

00:08:57.350 --> 00:09:01.690
Or if you're rendering something really, really small, like
the insides of an atom and you want something that's .0001,

00:09:01.690 --> 00:09:08.550
you know some extremely small number, a floating point
number is also going to excel at doing something like that.

00:09:08.550 --> 00:09:13.440
This is worth keeping in mind, because the standard
depth buffer is actually has better precision closer

00:09:13.440 --> 00:09:14.400
to the near plane.

00:09:14.400 --> 00:09:18.020
So you think of your depth, your
depth is actually projected.

00:09:18.020 --> 00:09:19.950
So it's the Z value over the W value.

00:09:19.950 --> 00:09:25.330
And that results in a curve with greater precision,
better precision closer to the near plane.

00:09:25.330 --> 00:09:28.920
Floating point numbers also have
better precision closer to 0.0,

00:09:28.920 --> 00:09:31.540
so when you use this, you have
to keep both of those in mind.

00:09:31.540 --> 00:09:33.510
That's something to watch out for.

00:09:33.510 --> 00:09:38.640
All right, now let's talk about empowerment.

00:09:38.640 --> 00:09:43.220
These are some techniques, some extensions to allow
you to use techniques you couldn't use before.

00:09:43.220 --> 00:09:47.340
So the first one I'd like to talk about is array textures.

00:09:47.340 --> 00:09:54.930
An array texture is an array of 1D or 2D
images with each layer being a distinct image.

00:09:54.930 --> 00:09:58.480
There's no filtering between layers and
you have distinct bitmaps per level.

00:09:58.480 --> 00:10:01.540
This allows you to do some cool things.

00:10:01.540 --> 00:10:04.140
It also means you have to use the programable pipeline.

00:10:04.140 --> 00:10:09.130
So the only way to use an array texture is to use a shader.

00:10:09.130 --> 00:10:15.680
So you also have new texture targets, array,
2D, 1D array, 2D array, and new samplers.

00:10:15.680 --> 00:10:19.980
So you sample these just like you'd
sample a normal texture except that --

00:10:19.980 --> 00:10:24.150
so say the 2D case, the third texture
coordinate will actually pick the layer.

00:10:24.150 --> 00:10:27.140
So you have layer 0, layer 1, layer 2, et cetera.

00:10:27.140 --> 00:10:32.020
And in the 1D case you actually have a 2D texture
coordinate and the second coordinate picks the layer.

00:10:32.020 --> 00:10:36.860
Now why is this interesting?

00:10:36.860 --> 00:10:40.620
Well, it allows you to store unique
data slice per layer of this texture.

00:10:40.620 --> 00:10:43.960
This is completely unique and it doesn't
-- isn't touched by any of the other ones.

00:10:43.960 --> 00:10:48.180
It's like a distinct image you
literally have an array of 2D images.

00:10:48.180 --> 00:10:50.150
So you think well 3D texture is kind of like that.

00:10:50.150 --> 00:10:51.490
It's a volume texture.

00:10:51.490 --> 00:10:54.440
I could just think of it as unique things.

00:10:54.440 --> 00:10:57.300
But that doesn't quite work because
you can't bitmap each level.

00:10:57.300 --> 00:11:01.110
If you've ever tried bitmapping a 3D texture
everything becomes this blob that's, you know,

00:11:01.110 --> 00:11:03.540
an average of all the layers smashed together.

00:11:03.540 --> 00:11:07.520
So let me show you a demo of this technique.

00:11:10.530 --> 00:11:17.730
So this is a little terrain demo I wrote.

00:11:17.730 --> 00:11:21.410
And you can see here there's a
couple little guys on the mountains.

00:11:21.410 --> 00:11:28.850
And there's the water and below that there's a little
gray and some green grass going up to the snow.

00:11:28.850 --> 00:11:30.990
Now you've probably seen terrain demos like this,

00:11:30.990 --> 00:11:38.230
but the cool thing is this is actually one texture that's an
array texture with four layers depending on the elevation.

00:11:38.230 --> 00:11:45.670
So there's a rock level, a grass level,
a more mountainy one, and then the snow.

00:11:45.670 --> 00:11:51.860
And I can dynamically change the terrain and it will
actually update which texture is being sampled from.

00:11:51.860 --> 00:11:57.520
So you can see that part that went up, and the
top part has snow and the bottom part has grass,

00:11:57.520 --> 00:12:01.600
and it sort of blends in between the
layers, and that can go down, changes again.

00:12:01.600 --> 00:12:05.540
So this is really cool for, like, a dynamic
terrain engine, because you have one texture,

00:12:05.540 --> 00:12:10.820
and it will automatically texture correctly
based on the elevation of the point.

00:12:12.570 --> 00:12:15.120
So there's actually sample code that
you can download and check this out.

00:12:15.120 --> 00:12:16.920
I highly encourage you to do so.

00:12:16.920 --> 00:12:19.090
It's a pretty cool technique.

00:12:19.090 --> 00:12:21.340
We'll come back to that a little bit later.

00:12:21.340 --> 00:12:26.190
Next I want to talk about instancing.

00:12:26.190 --> 00:12:28.730
How many people have heard of instancing.

00:12:28.730 --> 00:12:30.700
A few people, that's good.

00:12:30.700 --> 00:12:35.250
So we expose instancing in with our instance arrays.

00:12:35.250 --> 00:12:38.050
And this allows you to reuse premieres
with a single draw call.

00:12:38.050 --> 00:12:41.510
Some of the other talks talked about the
importance of batching your draw calls.

00:12:41.510 --> 00:12:43.780
Fewer draw calls is always going be better.

00:12:43.780 --> 00:12:47.190
So if you can draw 100 things with
a single draw call that's awesome.

00:12:47.190 --> 00:12:55.220
Again, programmable pipeline only, and you must use
generic vertex attributes to use this technique.

00:12:56.550 --> 00:12:59.980
This is because you're essentially
sourcing attributes at different rates.

00:12:59.980 --> 00:13:04.100
If you have a position for a point you're always
going to have a separate position for vertex,

00:13:04.100 --> 00:13:06.550
otherwise they're going to be on top of each other, right?

00:13:06.550 --> 00:13:08.700
But you may think what other things could I pass?

00:13:08.700 --> 00:13:13.370
Well, you could pass an orientation matrix,
you could pass color, you could pass normals.

00:13:13.370 --> 00:13:17.540
So you could reuse the same model, draw it
100 times with different orientation matrices

00:13:17.540 --> 00:13:20.300
and put the same guy in 100 different places.

00:13:20.300 --> 00:13:25.530
So to do this you use GL vertex attrib deviser R.

00:13:25.530 --> 00:13:31.020
Now you specify deviser, which tells OpenGL
how to source these attributes differently.

00:13:31.020 --> 00:13:36.180
So let's give a little example.

00:13:36.180 --> 00:13:41.710
First you can see we have the positions
and they're moving, and the attributes.

00:13:41.710 --> 00:13:46.090
So different positions get the same attribute.

00:13:46.090 --> 00:13:51.220
Gets the purple one, now it gets the red attribute, yellow
position, completely different, gets the same red attribute.

00:13:51.220 --> 00:13:55.220
Green one gets the yellow attribute and so on.

00:13:55.220 --> 00:13:57.820
They're different positions, and
they're reusing the same attributes.

00:13:57.820 --> 00:14:01.220
So consider each position as its own instance.

00:14:01.220 --> 00:14:09.320
And then the attributes are being -- so here in this case
the deviser is 2, because every 2 you repeat the attribute.

00:14:09.320 --> 00:14:11.540
So you might want to do this because it saves overhead.

00:14:11.540 --> 00:14:13.690
That's the main reason.

00:14:13.690 --> 00:14:18.140
And performance is always going to be
better the fewer draw calls you too.

00:14:18.140 --> 00:14:18.930
There's different techniques.

00:14:18.930 --> 00:14:22.490
This is commonly referred to as stream
instancing, if you ever heard of that.

00:14:22.490 --> 00:14:27.290
You're sourcing vertex attributes at different
rates and the best way to do this and the example

00:14:27.290 --> 00:14:34.160
that you can download is sourcing different
position and orientation matrices per instance.

00:14:34.160 --> 00:14:43.240
So let's give a demo of that.

00:14:43.240 --> 00:14:46.570
So this is a bunch of spinning gears,
use the gear model I showed you earlier.

00:14:46.570 --> 00:14:51.340
And it's a 9 by 9 grid times 6 phases.

00:14:51.340 --> 00:14:53.850
And this is a single draw call.

00:14:53.850 --> 00:14:56.760
There's one draw, glDrawElements instance.

00:14:56.760 --> 00:15:02.180
And you can see that they're all animating
separately, some of them turn one direction,

00:15:02.180 --> 00:15:05.890
the others turn the other direction, they're all lit.

00:15:05.890 --> 00:15:07.670
See any per pixel lighting.

00:15:07.670 --> 00:15:10.100
They're kind of shiny.

00:15:10.100 --> 00:15:13.190
And it's actually a pretty simple technique.

00:15:13.190 --> 00:15:15.880
There's just one big buffer that is the attributes.

00:15:15.880 --> 00:15:17.950
And I have a matrix packed in there.

00:15:17.950 --> 00:15:22.310
So each individual gear gets it's own
matrix that represents its orientation,

00:15:22.310 --> 00:15:25.190
the turning animation, and its position in space.

00:15:25.190 --> 00:15:30.600
And finally I have a camera matrix that
controls the camera so I can move around this --

00:15:30.600 --> 00:15:35.400
this cube of moving sphere -- moving gears.

00:15:35.400 --> 00:15:38.380
This is also available for you to download.

00:15:38.380 --> 00:15:39.720
You can check it out.

00:15:39.720 --> 00:15:44.040
This is really common in a lot of games, for say
tree rendering if you want to render some foliage

00:15:44.040 --> 00:15:46.610
or some tufts of grass, anything like that.

00:15:46.610 --> 00:15:49.550
Even particles are great for instancing.

00:15:49.550 --> 00:15:51.820
Any time you have to render something over and over again

00:15:51.820 --> 00:15:55.250
that looks really similar this
is a great technique to leverage.

00:15:59.130 --> 00:16:01.320
All right, let's talk about frame buffer objects.

00:16:01.320 --> 00:16:05.050
This is a big one that a lot of people have
asked for, so we've implemented it for you guys.

00:16:05.050 --> 00:16:09.040
Our frame buffer object is a generalized
off-screen render target.

00:16:09.040 --> 00:16:11.570
Now we recommend when you do your
rendering, you do render to an FBO.

00:16:11.570 --> 00:16:12.960
This is an off-screen target.

00:16:12.960 --> 00:16:15.240
You can render to a texture or a render buffer.

00:16:15.240 --> 00:16:18.060
If you're familiar with the iPhone
you have to render to an FBO.

00:16:18.060 --> 00:16:22.650
So you should also be doing this on the desktop.

00:16:22.650 --> 00:16:27.780
You can attach different dimensions to your
FBO now, and you can attach different formats.

00:16:27.780 --> 00:16:31.090
This is something you can't do on
the iPhone, but you can do it here.

00:16:31.090 --> 00:16:35.170
And there's a bunch of reasons you might want to.

00:16:35.170 --> 00:16:38.360
Now you might, FBOs themselves are not
new, this is a technique that's been

00:16:38.360 --> 00:16:42.230
around for a long time, capability
that we've had for a while.

00:16:42.230 --> 00:16:46.100
But now you can attach different size
buffers or different types of buffers.

00:16:46.100 --> 00:16:48.210
So you can do things like reuse the Z buffer.

00:16:48.210 --> 00:16:50.240
Say you want to render something at full size.

00:16:50.240 --> 00:16:52.630
So you have a full resolution Z buffer.

00:16:52.630 --> 00:16:54.860
Then you want to render at a quarter size or half size.

00:16:54.860 --> 00:16:58.110
You can reuse that Z buffer so you
don't have to rebuild that information,

00:16:58.110 --> 00:17:01.250
and you can get the benefits of
having some early Z optimizations.

00:17:01.250 --> 00:17:05.060
You can also use this to render data to a texture.

00:17:05.060 --> 00:17:07.970
Now you could always do this before,
but you had four components

00:17:07.970 --> 00:17:10.040
and you were pretty much forced to use RGBA or RGB.

00:17:10.040 --> 00:17:12.360
But you may not always need that.

00:17:12.360 --> 00:17:14.720
We'll get a little more on this later.

00:17:14.720 --> 00:17:21.930
So with that in mind, let's move
on to performance and memory.

00:17:21.930 --> 00:17:24.150
First let's talk about texture_RG.

00:17:24.150 --> 00:17:28.580
Texture_RG is a one- or a two-channel
texture, R or RG, respectively.

00:17:28.580 --> 00:17:34.830
There's many formats, 8-bit, 16-bit, 32-bit on sign
in, and we also have 16-bit, 32-bit floating point.

00:17:34.830 --> 00:17:36.210
And this is mainly for data storage.

00:17:36.210 --> 00:17:40.480
And it can also be a render target which
fits nicely into the ARB FBO extension.

00:17:40.480 --> 00:17:43.630
So you can see here on the right we have a teapot.

00:17:43.630 --> 00:17:48.320
And you might wonder well, why do I
care about one- or two-channel textures.

00:17:48.320 --> 00:17:51.040
It's only going to give me red
and it's going to give me green.

00:17:51.040 --> 00:17:52.210
Like this teapot is red and green.

00:17:52.210 --> 00:17:54.320
Right? What am I looking at?

00:17:54.320 --> 00:17:57.460
Well, you can combine this with ARB FBO to render to.

00:17:57.460 --> 00:17:59.080
Render data to a texture.

00:17:59.080 --> 00:17:59.820
What type of data.

00:17:59.820 --> 00:18:03.130
Oops, let's move on.

00:18:03.130 --> 00:18:04.440
Sorry, luminance.

00:18:04.440 --> 00:18:07.760
You think I can render to luminance,
which is a one-channel texture, right?

00:18:07.760 --> 00:18:11.400
Well, luminance is not renderable, so that won't quite work.

00:18:11.400 --> 00:18:15.160
But going back to data, you might say why do I care.

00:18:15.160 --> 00:18:19.100
Why don't -- why do I need four components?

00:18:19.100 --> 00:18:22.640
Well, it saves screen space motion blur.

00:18:22.640 --> 00:18:26.680
Screen space motion blur really only
needs two components, an X and a Y vector.

00:18:26.680 --> 00:18:33.570
So you can write your X and Y vectors out to an RG texture
and then sample along those two vectors to get a nice blur.

00:18:33.570 --> 00:18:37.270
This is also really useful for a
technique called deferred shading.

00:18:37.270 --> 00:18:43.930
Which -- so deferred shading, let's go into that, how
many people have heard of this, by the way, anyone?

00:18:43.930 --> 00:18:46.340
This is commonly used in a lot of games.

00:18:46.340 --> 00:18:49.030
And you need two passes.

00:18:49.030 --> 00:18:53.600
On your first pass you're going transform your geometry
as usually , then you'll render the lighting attributes

00:18:53.600 --> 00:18:57.160
for the calculations to what's called a G buffer.

00:18:57.160 --> 00:19:00.760
Your second pass you draw a full screen
quad and you read from the G buffer

00:19:00.760 --> 00:19:03.560
to perform lighting calculations in screen space.

00:19:03.560 --> 00:19:08.230
Now let me give you an example
of a possible G-buffer layout.

00:19:08.230 --> 00:19:13.240
So here I have three render targets, three separate
textures that I'm going render to at the same time.

00:19:13.240 --> 00:19:15.500
My first texture will store my position.

00:19:15.500 --> 00:19:19.000
This is typically going to be your
position in world space or camera space.

00:19:19.000 --> 00:19:22.170
I've chosen to do it in camera space, because
I think it's easier, but it's up to you.

00:19:22.170 --> 00:19:25.960
Just make sure everything's in the same
coordinate space so your lighting looks right.

00:19:25.960 --> 00:19:31.990
So my first texture will contain
my X, my Y, and my Z position.

00:19:31.990 --> 00:19:37.540
My second render target, my second texture will actually
represent the color of that pixel, the unlit colors.

00:19:37.540 --> 00:19:39.670
So if I have a texture map, it will be that color.

00:19:39.670 --> 00:19:47.500
Or if I don't have a texture map it can be an ambient color
or the material color too, so red, green, blue, and alpha.

00:19:47.500 --> 00:19:50.030
Lastly, I'm going to store my normal.

00:19:50.030 --> 00:19:52.930
And you see here I actually only have the X and the Y.

00:19:52.930 --> 00:19:57.350
That's because I have a two-channel texture, and
I can reconstruct the Z component and the shader.

00:19:57.350 --> 00:20:01.200
Consider that your normal XYZ, you
know the length is going to be 1.

00:20:01.200 --> 00:20:02.540
It's normalized.

00:20:02.540 --> 00:20:06.010
So that way you can reconstruct that you know
1 has to be the length of your final thing.

00:20:06.010 --> 00:20:08.710
So the Z component is pretty easy to reconstruct.

00:20:08.710 --> 00:20:12.360
You also know that the Z is going to be
at least facing moderately towards you,

00:20:12.360 --> 00:20:15.440
if it's in screen space, or if you store it in camera space.

00:20:15.440 --> 00:20:19.610
Because if it's facing away from
you it wouldn't be lit at all.

00:20:19.610 --> 00:20:21.720
Each of my components here is a 16-bit float.

00:20:21.720 --> 00:20:26.180
So the whole thing here, you can see
how much space I'm going to take up.

00:20:26.180 --> 00:20:29.950
Space is important to always keep in mind.

00:20:29.950 --> 00:20:35.150
So as I start out attributes, here's the pixel shader,
the fragment shader, I have a varying position,

00:20:35.150 --> 00:20:38.130
a varying normal, and I have my color as well.

00:20:38.130 --> 00:20:42.390
So frag data is what you use to store
to multiple render targets in OpenGL.

00:20:42.390 --> 00:20:47.370
So my first frag data 0, my first render target,
I'm storing at X, Y, and Z of the position.

00:20:47.370 --> 00:20:49.760
My second render target, I'm just storing the color.

00:20:49.760 --> 00:20:55.650
And my last one I'm going to store
the X and Y components of my normal.

00:20:55.650 --> 00:20:56.150
Here we go.

00:20:56.150 --> 00:21:02.080
So let's take a look at what deferred shading looks like.

00:21:02.080 --> 00:21:10.540
Here I have the Utah teapot with some lights.

00:21:10.540 --> 00:21:17.220
So the big advantage with deferred shading,
you might wonder why you want to use it,

00:21:17.220 --> 00:21:19.240
all your lights will be done in screen space.

00:21:19.240 --> 00:21:23.230
Normally, you would do lighting either at
the vertex stage or at the fragment stage.

00:21:23.230 --> 00:21:30.700
The vertex stage you're going to apply your lights once
per vertex, it will be interpolated across your primitive.

00:21:30.700 --> 00:21:35.220
In a forward render, if you apply your light at the fragment
stage you can redo the lighting calculations any number

00:21:35.220 --> 00:21:36.090
of times.

00:21:36.090 --> 00:21:38.870
Typically, you've have lots of overdraw in your scene.

00:21:38.870 --> 00:21:41.150
Which means that everything you're
rendering may not be visible

00:21:41.150 --> 00:21:44.100
because it may be behind something else, occluded by it.

00:21:44.100 --> 00:21:46.040
That still means you have to do the lighting calculations

00:21:46.040 --> 00:21:48.860
because you don't know if it will
be visible till the over end.

00:21:48.860 --> 00:21:53.280
The good thing about deferred shading is you
only do lighting calculations once per pixel.

00:21:53.280 --> 00:21:57.600
So you're guaranteed everything that
you're actually lighting will be visible.

00:21:57.600 --> 00:22:01.540
So let's visualize these buffers
that we had, we talked about before.

00:22:01.540 --> 00:22:05.760
Move the teapot a little bit so we get a better view.

00:22:05.760 --> 00:22:08.560
This is the position buffer, the X, Y, and Z.

00:22:08.560 --> 00:22:12.930
Now consider that the Z is probably
going to be pretty consistent across it

00:22:12.930 --> 00:22:17.460
because the teapot is an equal length away,
so you can't really see the blue part.

00:22:17.460 --> 00:22:19.430
But the X and the Y are going to be red and green.

00:22:19.430 --> 00:22:21.900
And notice there's a big black part.

00:22:21.900 --> 00:22:24.630
Well that's because those are negative coordinates, right?

00:22:24.630 --> 00:22:26.220
And there's no negative color.

00:22:26.220 --> 00:22:28.780
So that would be like negative 1 would be in the lower left.

00:22:28.780 --> 00:22:34.730
And you just can't see it with color
because that's how we're visualizing it.

00:22:34.730 --> 00:22:36.540
This is the color buffer.

00:22:36.540 --> 00:22:38.740
So my teapot is actually one color, it's just gray.

00:22:38.740 --> 00:22:41.190
If you had a texture map, the texture map would appear here.

00:22:41.190 --> 00:22:42.540
It's the unlit color of the screen.

00:22:42.540 --> 00:22:44.760
This is commonly referred to as the albedo.

00:22:44.760 --> 00:22:46.740
You may have heard that term.

00:22:46.740 --> 00:22:48.370
That's -- this is the color buffer.

00:22:48.370 --> 00:22:51.740
Lastly, we have the normal buffer.

00:22:51.740 --> 00:22:57.540
This is the transform normal that we
use in our final lighting calculation.

00:22:57.540 --> 00:23:04.260
You can see the depth -- phases being
called in the teapot's spout there.

00:23:04.260 --> 00:23:12.050
The normals are nicely smooth around the side so
you can see that I'm reconstructing them correctly.

00:23:12.050 --> 00:23:15.300
Finally, we have the deferred shaded teapot.

00:23:19.150 --> 00:23:22.700
It's pretty cool, you can see it has
full specular lighting per pixel.

00:23:22.700 --> 00:23:24.590
And it's running at 60 frames a second no problem.

00:23:24.590 --> 00:23:28.160
I was going to show this with like,
18 lights, because it's easy to do.

00:23:28.160 --> 00:23:32.310
But it's so overwhelming when you have a bunch
of colors dancing, it's almost seizure-inducing.

00:23:32.310 --> 00:23:37.960
So I decided to keep it a little simple.

00:23:37.960 --> 00:23:41.550
Next we'll talk about packed floats.

00:23:41.550 --> 00:23:48.110
This is a new format, it allows you to pack
three floating point numbers into a 32-bit value.

00:23:48.110 --> 00:23:54.620
New internal formats, R11, G11, B10, so 11, 11, 10 textures.

00:23:54.620 --> 00:23:57.910
You may have heard that if you've
been familiar with other APIs.

00:23:57.910 --> 00:24:01.460
So you can see how this is packed in.

00:24:01.460 --> 00:24:07.150
You have 11 bits for the red, 11 bits
for the green, 10 bits for the blue.

00:24:07.150 --> 00:24:08.260
So what is this useful for.

00:24:08.260 --> 00:24:11.740
Well, this is mainly for HDR rendering, high dynamic range.

00:24:11.740 --> 00:24:17.310
And you can do this because if you look at the sun or say
you look at a bright light, like these here are shining

00:24:17.310 --> 00:24:19.760
on me, they're very bright, or
look at the projector's light.

00:24:19.760 --> 00:24:24.930
And then if you look at the ground at something in
shadow, that's orders and orders of magnitude difference.

00:24:24.930 --> 00:24:27.850
So if you looked at the sun and then you
look at something that's completely dark,

00:24:27.850 --> 00:24:30.760
that's like a million times brighter, right?

00:24:30.760 --> 00:24:32.650
Just this huge magnitude.

00:24:32.650 --> 00:24:35.910
And 8 bits, not really enough to express that.

00:24:35.910 --> 00:24:39.780
Floating point is way better at doing
something that's vastly different.

00:24:39.780 --> 00:24:43.000
So you could say well, I could just
use some floating point numbers.

00:24:43.000 --> 00:24:45.480
We have 16-bit floats, we have 32-bit floats.

00:24:45.480 --> 00:24:47.130
That's true, but that's a lot of space.

00:24:47.130 --> 00:24:49.670
It would be much better if you could
somehow pack that into just 32 bits.

00:24:49.670 --> 00:24:51.080
So that's what this allows you to do.

00:24:51.080 --> 00:24:57.150
The next thing I'm going to talk
about is called conditional rendering.

00:24:57.150 --> 00:25:00.310
Now conditional rendering is rendering
based on the values of an occlusion query.

00:25:00.310 --> 00:25:03.200
Who here is heard the term occlusion query?

00:25:03.200 --> 00:25:05.570
Okay, good.

00:25:05.570 --> 00:25:10.830
An occlusion query is a test to see how many
pixels are actually rendered by the GPU.

00:25:10.830 --> 00:25:13.550
You can use this to do a lot of different rendering.

00:25:13.550 --> 00:25:16.010
It will give you a value back called samples passed.

00:25:16.010 --> 00:25:21.960
And you can say like, oh, these last rendering calls
rendered 100 pixels, these last rendered 1,000.

00:25:21.960 --> 00:25:27.230
You can do rendering based on that to see like,
oh, is this house behind a skyscraper, is it not.

00:25:27.230 --> 00:25:30.950
The problem is you have to query the GPU and
it has to wait to give you that value back.

00:25:30.950 --> 00:25:33.100
So there's a whole round trip involved here.

00:25:33.100 --> 00:25:36.360
And we like to remove any round trip we possibly can.

00:25:36.360 --> 00:25:39.080
So conditional render allows you to do that.

00:25:39.080 --> 00:25:42.640
You can just give it the query, which is here, as ID.

00:25:42.640 --> 00:25:46.400
You can give it a mode which tells it to wait or not.

00:25:46.400 --> 00:25:49.880
So you would say begin conditional
render with this information,

00:25:49.880 --> 00:25:53.180
put in all your rendering commands,
and then end conditional render.

00:25:53.180 --> 00:25:56.540
And the stuff that's bracketed between those
two will be conditionally rendered based

00:25:56.540 --> 00:25:58.330
on the result of your occlusion query.

00:25:58.330 --> 00:26:02.070
Little code here.

00:26:02.070 --> 00:26:05.320
The first thing to keep in mind when you're
rendering an occlusion query is you want some sort

00:26:05.320 --> 00:26:06.550
of course bounding volume.

00:26:06.550 --> 00:26:10.370
But you don't want to actually draw that volume
because you'll have some bounding box, right?

00:26:10.370 --> 00:26:15.370
You have a complicated guy, he might be behind some house
or skyscraper, you don't want to draw the whole guy,

00:26:15.370 --> 00:26:16.920
you just need a box that goes around him.

00:26:16.920 --> 00:26:20.140
You know, sort of like the cone of silence or something.

00:26:20.140 --> 00:26:22.700
So you turn color mask and depth mask off.

00:26:22.700 --> 00:26:26.860
It is much faster to render to nothing than it is
to actually render to something to a frame buffer,

00:26:26.860 --> 00:26:28.590
and you don't need to actually draw this stuff.

00:26:28.590 --> 00:26:31.520
So you want to turn these off before
you render your occlusion query.

00:26:31.520 --> 00:26:34.730
Next, you render the occlusion query as normal.

00:26:34.730 --> 00:26:36.900
The course bounding volume.

00:26:36.900 --> 00:26:40.490
Begin query, samples past with your query name.

00:26:40.490 --> 00:26:43.240
Draw elements or whatever your draw
calls are, and then you end the query.

00:26:43.240 --> 00:26:49.230
Now I actually want to start drawing
again, so I have to turn my state back on.

00:26:49.230 --> 00:26:54.650
Lastly, pretty simple, begin conditional
render based on the same query I used before.

00:26:54.650 --> 00:26:58.350
Draw all my other stuff, and then end conditional render.

00:26:58.350 --> 00:27:01.140
Pretty simple technique, and could be pretty powerful.

00:27:04.110 --> 00:27:07.990
Now the funny thing about conditional rendering
demos is there really isn't much to see,

00:27:07.990 --> 00:27:12.150
because if it's working you're
not actually rendering anything.

00:27:14.550 --> 00:27:19.130
Now here are something like 10,000
gears stretching off into infinity.

00:27:19.130 --> 00:27:21.910
And this is just drawing them all normally.

00:27:21.910 --> 00:27:27.640
I have a whole bunch of them, they're all lit
per pixel and kind of multicolored and shiny.

00:27:27.640 --> 00:27:33.910
And I put something between the
camera and the back of the gears.

00:27:33.910 --> 00:27:37.720
So here the problem is I'm only
rendering like three rows of gears.

00:27:37.720 --> 00:27:42.850
There's still, you know, 9,000 something rows
behind that white plain that you can't see.

00:27:42.850 --> 00:27:44.270
But they're still all being rendered.

00:27:44.270 --> 00:27:46.760
That's wasting time that doesn't need to be wasted.

00:27:46.760 --> 00:27:49.570
So I press this.

00:27:49.570 --> 00:27:52.610
And you notice that it jumped and the
frame rate actually got a little better.

00:27:52.610 --> 00:27:56.910
That's because all the other 9,000
rows are not being drawn anymore.

00:27:56.910 --> 00:27:58.710
So back to normal.

00:28:01.890 --> 00:28:07.620
So sometimes you can get, like, a good 10 FPS or maybe
even more, depending on the complexity of your rendering.

00:28:07.620 --> 00:28:10.790
This is something you have to build
into your engine or your app.

00:28:10.790 --> 00:28:15.130
But it's not that hard to do if you're already using
occlusion queries, that could be a very powerful technique.

00:28:15.130 --> 00:28:18.720
I would urge you to take a look at the sample code
because it's a lot easier to see and understand

00:28:18.720 --> 00:28:20.910
when you're looking at the code than it is for a demo.

00:28:20.910 --> 00:28:25.330
Because as I said before, it's doing
its job, there's nothing to see.

00:28:31.310 --> 00:28:33.370
So now we move on to performance.

00:28:33.370 --> 00:28:37.090
I promised you I'd talk a little bit about
performance, and we're going to do that.

00:28:37.090 --> 00:28:39.410
There's a bunch of performance
characteristics on the desktop

00:28:39.410 --> 00:28:42.740
that you may not be familiar with
if you're an iPhone programmer.

00:28:42.740 --> 00:28:46.980
There's some stuff -- so let's begin with stuff to avoid.

00:28:46.980 --> 00:28:49.750
First of all, I want to advise
you not to use immediate mode.

00:28:49.750 --> 00:28:51.120
Immediate mode is costly.

00:28:51.120 --> 00:28:56.620
So when you do immediate mode, you say GL begin,
GL vertex, GL vertex, GL vertex, GL vertex,

00:28:56.620 --> 00:28:58.860
GL vertex, you're specifying every point.

00:28:58.860 --> 00:29:00.190
And that's really slow.

00:29:00.190 --> 00:29:04.060
Consider your average model, which could
be anywhere from 2,000 to 10,000 points.

00:29:04.060 --> 00:29:11.490
So you really want to specify 10,000 points with GL vertex,
GL vertex, you know, thousands of times, probably not.

00:29:11.490 --> 00:29:14.400
Also, you have to send that data
over the bus every single frame.

00:29:14.400 --> 00:29:19.470
Every single time you say GL vertex that's
some more data to be sent over the bus.

00:29:19.470 --> 00:29:20.560
You have all this VRAM.

00:29:20.560 --> 00:29:27.620
All of our desktops have tons and tons of VRAM, 128
Megs, 256 Megs, 512 Megs, you want to use this stuff.

00:29:27.620 --> 00:29:33.050
So send all your data up to the card and render
from there instead of specifying it every time.

00:29:33.050 --> 00:29:37.710
So if you have any code that looks like this in your
application I want you to go and cut it all out.

00:29:37.710 --> 00:29:40.960
Just get rid of it.

00:29:40.960 --> 00:29:46.840
Use VBOs. Draw arrays, draw elements, this is the way to go.

00:29:46.840 --> 00:29:49.850
By the same token, if you've ever heard of a display list,

00:29:49.850 --> 00:29:53.430
I'm here to say that display lists
probably don't really help you.

00:29:53.430 --> 00:29:55.700
They're really not much of a performance boost.

00:29:55.700 --> 00:30:00.030
You may see a little, but it's really not good.

00:30:00.030 --> 00:30:01.620
You're caching commands in the display list.

00:30:01.620 --> 00:30:04.220
But what really hurts you is caching state.

00:30:04.220 --> 00:30:07.930
Now if you went to my colleague's talk yesterday,
he talked about state validation in the driver.

00:30:07.930 --> 00:30:11.420
This is really where a lot of the CPU
overhead with the drawing is going to go.

00:30:11.420 --> 00:30:16.190
And since display lists inherit state,
we can't really cache it for you.

00:30:16.190 --> 00:30:20.480
You could say call list, but you can
change all the state in between each call.

00:30:20.480 --> 00:30:25.110
So we still have to revalidate all that state, which FBO
is bound, which texture is bound, you have depth tests,

00:30:25.110 --> 00:30:28.960
you have alpha tests, all that could be
different, different fragment programs.

00:30:28.960 --> 00:30:32.380
We can't validate that, so you're really not
getting any benefit of caching these draw commands.

00:30:32.380 --> 00:30:37.770
So if you have stuff that looks like this
in your apps, begin list, a bunch of stuff,

00:30:37.770 --> 00:30:40.720
end list, call list, that also needs to go away.

00:30:40.720 --> 00:30:47.660
[inaudible] isn't available on the phone anyway, so
if you really wanted to port any code or you wanted

00:30:47.660 --> 00:30:49.980
to share code between the two platforms you couldn't.

00:30:49.980 --> 00:30:55.200
So it's much better just to use draw arrays,
draw elements, use vertex buffer objects to draw.

00:30:58.810 --> 00:31:03.550
So to reiterate what you might have
heard yesterday, batch your state.

00:31:03.550 --> 00:31:08.920
This is an important way to improve performance, because
all state changes require validation by the driver.

00:31:08.920 --> 00:31:13.090
There's a ton of state in OpenGL, and it all has
to be consistent before you get good rendering.

00:31:13.090 --> 00:31:17.290
So the driver has to go validate all
this stuff, make sure it's coherent.

00:31:17.290 --> 00:31:20.900
It also requires a vector to be sent down
to the hardware of all your current state.

00:31:20.900 --> 00:31:26.340
So if you're batching this all the time between your draws
it's constantly revalidating and constantly resending back

00:31:26.340 --> 00:31:29.700
down to the driver, or the driver
is resending back to the hardware.

00:31:29.700 --> 00:31:31.060
And that takes time.

00:31:31.060 --> 00:31:35.550
This is expensive, that's precious time
you could be doing something else with.

00:31:35.550 --> 00:31:39.180
So you want to avoid it, if you batch
all your similar draw calls together,

00:31:39.180 --> 00:31:42.490
all your similar objects, you don't have to repeat this.

00:31:42.490 --> 00:31:46.670
Now as my colleague said yesterday there's sort of
a hierarchy of what costs more, what costs less,

00:31:46.670 --> 00:31:50.370
and I would urge you to go look at
his presentation, take a look at that

00:31:50.370 --> 00:31:56.310
and think about how you can re-architect your app to take
advantage of grouping all your similar draws together.

00:31:56.310 --> 00:31:59.000
You can also use Shark to check to see where time is spent.

00:31:59.000 --> 00:32:02.320
We have a tool called OpenGL Driver
Monitor that can help you as well.

00:32:02.320 --> 00:32:06.600
You can look for things like CPU wait
for GPU, or GPU wait for CPU to find

00:32:06.600 --> 00:32:09.250
out if you're bound by the CPU, if you're bound by the GPU.

00:32:09.250 --> 00:32:13.990
If your GPU is constantly waiting for the CPU
that means there's probably something you can do

00:32:13.990 --> 00:32:20.670
in your app to help your rendering go faster.

00:32:20.670 --> 00:32:22.120
Also you may have heard of hoisting.

00:32:22.120 --> 00:32:25.860
How many people have heard the term hoisting?

00:32:25.860 --> 00:32:30.800
Okay, hoisting is moving something up, you want to
pick it up, you want to move it up the pipeline.

00:32:30.800 --> 00:32:32.400
So consider you have a vertex shader.

00:32:32.400 --> 00:32:37.840
If I have a model with 10,000 vertices, that
vertex shader is going to run 10,000 times.

00:32:37.840 --> 00:32:41.310
Now consider I'm rendering at 16 by 12.

00:32:41.310 --> 00:32:43.240
That's almost 2 million pixels.

00:32:43.240 --> 00:32:48.610
My fragment shader is going to run on the order
of 2 million times, maybe even more with overdraw.

00:32:48.610 --> 00:32:51.160
A common scene may have four layers of overdraw, right?

00:32:51.160 --> 00:32:55.020
Someone could be inside a house and you could have
the front row of the house, so you could have a window

00:32:55.020 --> 00:32:58.850
so you can see inside the house, so you still have
to draw everything inside because you don't know

00:32:58.850 --> 00:33:01.670
if the window's going to be able to see it or not, right?

00:33:01.670 --> 00:33:06.620
That's way too much overdraw, and you're going to run
this shader millions and millions of times per frame.

00:33:06.620 --> 00:33:09.770
So if it's possible to move any
calculations out of the fragment shader

00:33:09.770 --> 00:33:12.190
into the vertex shader your performance is going to jump.

00:33:12.190 --> 00:33:16.080
Because would you rather run something
10,000 times or over 2 million times.

00:33:16.080 --> 00:33:21.530
Pretty simple idea, but something
I think a lot of people overlook.

00:33:21.530 --> 00:33:24.320
Another thing to keep an eye out is fall back.

00:33:24.320 --> 00:33:29.710
To keep our platform fairly homogenous,
we implement everything in software.

00:33:29.710 --> 00:33:32.040
So if something's not supported on
the particular hardware you have,

00:33:32.040 --> 00:33:37.080
like if you're running on an Intel integrated
part, if may fall back to the software path.

00:33:37.080 --> 00:33:42.480
There's two parameters you can check to see, there's a
separate vertex fallback and a separate fragment fallback.

00:33:42.480 --> 00:33:46.690
And of course the software path is going
to be much slower than the hardware path.

00:33:46.690 --> 00:33:50.520
So if you just change the shader and your
performance went down to like 1 or 2 frames a second,

00:33:50.520 --> 00:33:52.680
you might think, this is weird, something's wrong.

00:33:52.680 --> 00:33:55.460
Well the first thing to check to see if
you're falling back to the software path.

00:33:55.460 --> 00:33:58.440
And if you are, you can figure out
exactly where you're falling back

00:33:58.440 --> 00:34:01.060
and then fix your app so you stay on the hardware.

00:34:01.060 --> 00:34:09.360
Now the other thing I'm going to talk about
is what's commonly referred to as a Z prepass.

00:34:09.360 --> 00:34:12.990
A Z prepass is just drawing the
depth information into a buffer.

00:34:12.990 --> 00:34:16.870
So you can do this quickly and early in your drawing cycle.

00:34:16.870 --> 00:34:19.240
You would draw all your objects just into the depth buffer.

00:34:19.240 --> 00:34:21.390
So turn the color buffer off.

00:34:21.390 --> 00:34:24.710
Solo depth rights are about two
times as fast as color rights.

00:34:24.710 --> 00:34:28.090
And since we're only interested in
the depth information and constructing

00:34:28.090 --> 00:34:30.800
that information, we want to turn color rights off.

00:34:30.800 --> 00:34:35.370
And this is done via GL color mask as
we did in the occlusion query example.

00:34:35.370 --> 00:34:39.320
And why would you want to do this?

00:34:39.320 --> 00:34:45.260
Well typically you've seen some diagrams of the pipeline,
and at the end of the pipeline you saw the fragment stage.

00:34:45.260 --> 00:34:47.570
Well the Z test is done after the fragment stage.

00:34:47.570 --> 00:34:52.520
This gets back to what I said earlier about rerunning
the same fragment shader on stuff you can't see.

00:34:52.520 --> 00:34:56.180
Normally, stuff you can't see is wiped
out by the depth test, the Z test.

00:34:56.180 --> 00:35:00.510
But if you already did all the expensive calculations,
this doesn't help you much with performance.

00:35:00.510 --> 00:35:06.210
If you have a pre-made Z buffer, it can allow
your GPU to perform early Z optimizations

00:35:06.210 --> 00:35:11.790
and actually not do those expensive fragment operations
if the resulting pixel won't actually be visible.

00:35:11.790 --> 00:35:17.220
So it's important to do a Z prepass if you have
really expensive shaders or lots of overdraw.

00:35:17.220 --> 00:35:20.180
This can be mitigated by certain
techniques such as deferred shading.

00:35:20.180 --> 00:35:28.170
But there are things that happen even in those
techniques that you can use this to take advantage of.

00:35:28.170 --> 00:35:31.730
There's also rendering techniques
that need an incoming Z value.

00:35:31.730 --> 00:35:37.010
If you were just doing normal forward render, no Z
prepass, you wouldn't have a depth value of that pixel.

00:35:37.010 --> 00:35:39.800
You could write to it, but you can't get it back.

00:35:39.800 --> 00:35:44.480
Certain techniques, like screen space
ambient occlusion, need an incoming Z value.

00:35:44.480 --> 00:35:49.770
Now if any of you have played the game Crisis they used
this technique, they detailed it in a paper I'll cite later.

00:35:49.770 --> 00:35:54.070
And this reads from the Z buffer of
the pixel and the surrounding pixels

00:35:54.070 --> 00:35:59.770
to determine this ambient occlusive factor,
which is sort of like how ambient light works.

00:35:59.770 --> 00:36:04.480
It's just an emulation of the real
ambient lighting in the real world.

00:36:04.480 --> 00:36:10.030
So if I'm just writing to my depth buffer
it's going to look something like this.

00:36:10.030 --> 00:36:12.190
This is the terrain demo I showed you earlier.

00:36:12.190 --> 00:36:13.910
This is just the Z pass.

00:36:13.910 --> 00:36:18.710
You can see the closer part to me, it's going to be
darker, the further away it's going to be lighter.

00:36:18.710 --> 00:36:24.180
That's just visualizing the depth of
value as sort of a gray scale color.

00:36:26.290 --> 00:36:29.270
So let's talk about extensions that are specific to the Mac.

00:36:29.270 --> 00:36:34.020
The first one I'm going to talk
about is FlushMappedBufferRange.

00:36:34.020 --> 00:36:38.230
Normally when you modify a buffer you're
going to use glMapBuffer and glUnmapbuffer.

00:36:38.230 --> 00:36:43.230
This will actually map what's in the VRAM into your
system RAM, then you can modify it or take a look at it.

00:36:43.230 --> 00:36:46.090
It allows you to asynchronously modify that VBO,

00:36:46.090 --> 00:36:50.020
which is important if you're doing
animation and you're updating things.

00:36:50.020 --> 00:36:53.390
Now if you flush the buffer, you
can only flush a small amount.

00:36:53.390 --> 00:36:58.450
Normally when you unmap it, you're going to
DMA the entire buffer back up to the GPU.

00:36:58.450 --> 00:37:02.160
And so you have about a megabyte of buffer
data, you have a big complicated model,

00:37:02.160 --> 00:37:05.060
and just the vertex position is about a Meg.

00:37:05.060 --> 00:37:09.550
Probably don't want to be pushing a Meg back up
every frame if you're only modifying like 10 bytes.

00:37:09.550 --> 00:37:14.050
So FlushMappedBufferRange allows
you to only flush those 10 bytes.

00:37:14.050 --> 00:37:17.650
This also minimizes data that needs
to be copied back to system memory.

00:37:17.650 --> 00:37:21.930
Normally, when you map a buffer the system
doesn't know if you're going to read from it.

00:37:21.930 --> 00:37:25.890
If you're going to read from the whole buffer,
say the first 10 bytes and the last 10 bytes,

00:37:25.890 --> 00:37:28.890
actually has to copy the entire
thing back to your CPU memory.

00:37:28.890 --> 00:37:33.900
This can be really slow, especially if you're constantly
copying back, modifying, sending back up to the GPU,

00:37:33.900 --> 00:37:36.180
copying back down to the CPU, sending back up to the GPU.

00:37:36.180 --> 00:37:38.490
You can imagine that makes a lot of time.

00:37:38.490 --> 00:37:43.020
So if you're only mapping and flushing a
portion of it, you can minimize the copying.

00:37:43.020 --> 00:37:46.160
So to do this, here's some sample code.

00:37:46.160 --> 00:37:52.350
You would set the buffer parameter
to false, the flushing parameter.

00:37:52.350 --> 00:37:56.120
Then you could do some unrelated work,
your app goes along, does some things.

00:37:56.120 --> 00:37:59.320
Then you map your buffer, you get this data pointer.

00:37:59.320 --> 00:38:05.010
You update your buffer, and finally you
say FlushMappedBufferRange with the offset

00:38:05.010 --> 00:38:07.990
that you started modifying and
the number of bytes you modified.

00:38:07.990 --> 00:38:11.880
Then later on when you're done with all
your modifications you can do your unmap,

00:38:11.880 --> 00:38:14.450
start drawing with it, and go on your way.

00:38:14.450 --> 00:38:16.250
Pretty simple.

00:38:18.070 --> 00:38:22.120
This also ties into our next thing, which is glFence.

00:38:22.120 --> 00:38:26.240
A fence let's you test the command when a command is done.

00:38:26.240 --> 00:38:31.600
So you could be adding commands to the command
stream, you can say like, I want to say GL bind buffer

00:38:31.600 --> 00:38:36.830
and then GL draw elements, GL draw elements, GL
draw elements, then I want to say glMapBuffer,

00:38:36.830 --> 00:38:39.290
modify some things, GL FlushMappedBufferRange.

00:38:39.290 --> 00:38:41.990
And then I'm going to say GL set fence.

00:38:41.990 --> 00:38:45.490
And then I can see when my flush is done.

00:38:45.490 --> 00:38:49.150
So you think I mention this is asynchronous.

00:38:49.150 --> 00:38:53.830
When I say this, it's going to tell
OpenGL flush this up to the GPU via DMA.

00:38:53.830 --> 00:38:56.960
And you don't know when the DMA
is going to complete, exactly.

00:38:56.960 --> 00:39:00.410
It's going to give you control back right away.

00:39:00.410 --> 00:39:04.460
Later on if you want to actually draw with this, you
want to make sure that the data's gotten up to the GPU.

00:39:04.460 --> 00:39:08.240
So an easy way to check is to set a
fence after your FlushMappedBufferRange.

00:39:08.240 --> 00:39:11.160
And later on you can test to see in the fence is complete.

00:39:11.160 --> 00:39:15.030
If the fence is complete you're guaranteed that
everything before it has actually executed.

00:39:15.030 --> 00:39:20.750
If you ever used a multithreaded engine
with OpenGL, this is absolutely necessary.

00:39:20.750 --> 00:39:24.500
Because there can be latency between
the time you modify your thing,

00:39:24.500 --> 00:39:29.030
the time you say FlushMappedBufferRange,
and the time you want to draw.

00:39:29.030 --> 00:39:32.040
So if you start drawing and then you start modifying again,

00:39:32.040 --> 00:39:35.220
you don't know if anyone's actually using
that buffer you modified as you draw.

00:39:35.220 --> 00:39:41.150
But with fences you can make sure I'm not modifying
it as I draw, and I'm not drawing it as I modify.

00:39:41.150 --> 00:39:45.050
You can also use this for other
multithreaded synchronization.

00:39:45.050 --> 00:39:51.930
You may have seen multicontext and people mentioning
you can upload textures on a background context.

00:39:51.930 --> 00:39:53.270
Well, you can do this, sure.

00:39:53.270 --> 00:39:56.790
But you also want to make sure that your texture
upload is done before you start rendering with it.

00:39:56.790 --> 00:40:01.610
If you have two contexts, you can set a fence
after your texture upload and then check it,

00:40:01.610 --> 00:40:06.520
and then signal your first context, yeah, my texture
upload's done, you can start drawing with this texture.

00:40:06.520 --> 00:40:09.520
This is great for texture streaming in the background.

00:40:11.630 --> 00:40:14.740
So this is a little bit how a fence would look like.

00:40:14.740 --> 00:40:20.630
I would map buffer, write some data,
FlushMappedBufferRange, set my fence, and then unmap it.

00:40:20.630 --> 00:40:23.790
And somewhere later on in my application
I would call GL test fence.

00:40:23.790 --> 00:40:28.050
It would test that same fence that I set before
and tell me, yeah, we're done, we're good.

00:40:28.050 --> 00:40:29.300
Or no, we're not done.

00:40:29.300 --> 00:40:31.070
So you might want to wait.

00:40:31.070 --> 00:40:32.560
Sample code is really easy.

00:40:32.560 --> 00:40:38.420
You gen your fence, you do some work, you set
your fence, and then later on, you test it.

00:40:41.270 --> 00:40:45.600
Now might wonder if we can put this all together.

00:40:45.600 --> 00:40:48.520
We talked about a bunch of different
techniques, and we want to bring them all

00:40:48.520 --> 00:40:54.210
into one application, one demo, leveraging all this stuff.

00:40:54.210 --> 00:40:56.440
So leveraging every technique we've talked about.

00:40:56.440 --> 00:40:57.300
So what did we talk about.

00:40:57.300 --> 00:40:58.660
Well, we talked about instancing.

00:40:58.660 --> 00:41:02.780
So let's think of something that has a bunch of objects.

00:41:02.780 --> 00:41:03.990
Talked about texture RGs.

00:41:03.990 --> 00:41:08.860
So we want to do some data storage, some
form of deferred rendering would be cool.

00:41:08.860 --> 00:41:10.410
We talked about array textures.

00:41:10.410 --> 00:41:14.290
We had that cool terrain demo, can we
bring this together into something else.

00:41:14.290 --> 00:41:21.720
So let me show you a little something that I put together.

00:41:21.720 --> 00:41:24.630
So this was the previous array.

00:41:24.630 --> 00:41:27.800
This is just forward rendering.

00:41:27.800 --> 00:41:29.080
Not as interesting.

00:41:29.080 --> 00:41:36.050
Now I can switch it to deferred rendering and I
can have multicolored lights flying around it.

00:41:36.050 --> 00:41:37.240
Kind of crazy.

00:41:37.240 --> 00:41:40.760
You can see I have these little robot
guys which is from the Quest demo.

00:41:40.760 --> 00:41:42.240
And he is actually being lit correctly.

00:41:42.240 --> 00:41:47.130
And it's one draw call drawing all
these, and they're actually all

00:41:47.130 --> 00:41:49.530
over the mountain, you just can't see them super-well.

00:41:49.530 --> 00:41:55.310
See some of them there.

00:41:55.310 --> 00:42:01.930
And I can throw on some animation of
the ground swallowing up this guy.

00:42:01.930 --> 00:42:02.890
This puts everything together.

00:42:02.890 --> 00:42:04.600
This is using deferred shading to draw.

00:42:04.600 --> 00:42:07.800
So you can see, you can use texture
mapping with deferred shading.

00:42:07.800 --> 00:42:10.410
And it's perfectly compatible with instancing as well.

00:42:10.410 --> 00:42:12.960
And array texture.

00:42:12.960 --> 00:42:16.440
So this is putting it all together, and
it runs at a perfectly fine frame rate.

00:42:16.440 --> 00:42:19.850
You know, we have quite a few things that are being drawn.

00:42:19.850 --> 00:42:23.350
The textures aren't super-high
resolution, but they do the job for this.

00:42:23.350 --> 00:42:30.270
So all this sample code is available, you can
go onto the web, onto the WWDC attendees site

00:42:30.270 --> 00:42:33.250
and download it, take a look at it, play around with it.

00:42:33.250 --> 00:42:37.400
I highly urge you to try to integrate
it into your apps, into your games,

00:42:37.400 --> 00:42:39.910
or if you just want to learn, take
a look at it, see how we do things.

00:42:39.910 --> 00:42:47.060
Feel free to look on the forums or send us email.

00:42:47.060 --> 00:42:47.890
Here are some sources.

00:42:47.890 --> 00:42:52.920
There's a lot of information on deferred shading
on the Web, on NVIDIA's site, on other sites.

00:42:52.920 --> 00:42:57.630
We have some sources from Crytek and other
game companies to talk about deferred shading,

00:42:57.630 --> 00:43:01.910
the Crytek paper has information on screen
space ambient occlusion, if you're interested.

00:43:01.910 --> 00:43:06.480
If you have more information, you should
e-mail Alan Schaffer, he is our Game

00:43:06.480 --> 00:43:08.740
and Technology Graphics Technology Evangelist.

00:43:08.740 --> 00:43:12.400
We also have a lot of documentation that's
really good on the OpenGL Dev Center,

00:43:12.400 --> 00:43:15.500
our programming guide and some other things.

00:43:15.500 --> 00:43:17.380
Lastly, we have our developer forums.

00:43:17.380 --> 00:43:23.630
You can go on, take a look, talk
to your peers, get answers from us.

00:43:23.630 --> 00:43:28.360
Now this is the second-to-last session, although
the game sessions will be repeated tomorrow,

00:43:28.360 --> 00:43:33.980
but I urge you to go online and take a look at some of the
past ones and see the presentations, the design practices,

00:43:33.980 --> 00:43:36.960
and all the ES overview and advanced rendering sessions.

00:43:36.960 --> 00:43:41.860
Next up is Taking Advantage of Multiple GPUs and they
have some cool techniques that you can use for desktops

00:43:41.860 --> 00:43:45.150
that have multiple graphics cards in them.

00:43:45.150 --> 00:43:47.830
Thanks for coming, hope this was a
little informative and enjoyable.

00:43:47.830 --> 00:43:50.750
If you have any questions, you
can come talk to me on the side.

00:43:50.750 --> 00:43:53.040
Have a good day, and enjoy the rest of your WWDC.

