WEBVTT

00:00:06.150 --> 00:00:09.500
>> Eric Lee: My name is Eric Lee,
and I work on media technologies.

00:00:09.500 --> 00:00:20.810
Today, I have the pleasure of presenting to you the new
editing APIs and AV Foundation. In iOS 4, We've added a powerful new set

00:00:20.810 --> 00:00:24.800
of APIs so that you can incorporate
editing in your application.

00:00:24.800 --> 00:00:32.140
These are the same APIs that were used to build
iMovie for iPhone like you saw in yesterday's keynote.

00:00:32.140 --> 00:00:40.220
Throughout the session, I'll be giving a series of demos.

00:00:40.220 --> 00:00:45.680
The applications I'll be using
are AVPlayerDemo and AVEditDemo.

00:00:45.680 --> 00:00:51.030
The source code for these applications are available
for you to download on the developer/attendee web site.

00:00:51.030 --> 00:00:55.460
So I encourage you, if you haven't already,
to go ahead and download these applications.

00:00:55.460 --> 00:01:02.850
Let's quickly recap where AV Foundation sits
in the context of other iPhone OS frameworks.

00:01:02.850 --> 00:01:09.790
Many of you may already be familiar with
the Media Player and UIKit frameworks.

00:01:09.790 --> 00:01:15.760
AV Foundation sits below these frameworks and
builds upon the low level services provided

00:01:15.760 --> 00:01:20.320
by Core Audio, Core Media and Core Animation.

00:01:21.910 --> 00:01:29.380
Simple editing features have been available
to you as a user since iPhone OS 3.

00:01:29.380 --> 00:01:35.380
When you open up a movie in a camera roll,
you'll see a timeline slider with thumbnails.

00:01:35.380 --> 00:01:39.790
These thumbnails show you snapshots
of the movie at various times.

00:01:39.790 --> 00:01:44.160
We also provide a UI for trimming.

00:01:44.160 --> 00:01:52.180
Trimming allows you to select a region of the movie
that you find interesting and save it to a new file.

00:01:52.180 --> 00:01:58.630
While these features were available to you
as a user, we didn't provide a way for you

00:01:58.630 --> 00:02:02.290
to incorporate this functionality in your apps.

00:02:02.290 --> 00:02:10.990
Well, -- with iOS 4, using AV Foundation,
we're giving you this functionality.

00:02:10.990 --> 00:02:18.590
Of course, the APIs in AV Foundation editing go beyond
much more than just allowing you to create an image

00:02:18.590 --> 00:02:22.660
for a time and trimming a movie to a time range.

00:02:22.660 --> 00:02:28.740
And today, I'll be going through in this session
a series of scenarios showing you the kinds

00:02:28.740 --> 00:02:33.560
of things you can do with the editing APIs in AV Foundation.

00:02:33.560 --> 00:02:36.790
I'll show you how you can combine
clips from multiple movies.

00:02:36.790 --> 00:02:42.470
I'll show you how you can mix in additional audio tracks.

00:02:42.470 --> 00:02:49.430
I'll also show you how you can spice up your -- spice
up your movie by using video transitions such as zones.

00:02:49.430 --> 00:02:58.080
And I'll show you how you can incorporate some amazing
graphics and animation using Core Animation into your movie.

00:02:58.080 --> 00:03:05.780
But before I dive into these topics,
let me quickly reintroduce Core Media.

00:03:05.780 --> 00:03:11.080
Core Media is a new C base framework
that we're introducing in iOS 4.

00:03:11.080 --> 00:03:17.360
Core Media provides some basic data types and data
structures that AV Foundation uses for working with media.

00:03:17.360 --> 00:03:23.320
And one that is particularly important that we will be
seeing throughout the rest of this session is CMTime.

00:03:23.320 --> 00:03:32.650
CMTime is a C struct for representing time much like
CGSize and CGRect are structs for representing geometry.

00:03:32.650 --> 00:03:38.950
CMTime represents times as a rational number
with the 64-bit numerator, the time value,

00:03:38.950 --> 00:03:42.930
and a 32-bit denominator known as the time scale.

00:03:42.930 --> 00:03:48.310
We like rational numbers because that allows us
to preserve precision when we do calculations.

00:03:48.310 --> 00:03:58.870
We provide interested constants for interesting time such
as 0, positive infinity, negative infinity and invalid.

00:03:58.870 --> 00:04:06.790
We provide utilities for you to add and compare times.

00:04:06.790 --> 00:04:09.770
We also provide a data type for time ranges.

00:04:09.770 --> 00:04:16.000
A time range consists of a start time and a
duration, both of which are CMTime values.

00:04:16.000 --> 00:04:21.380
And we also provide a data type for mapping
one time range to another time range.

00:04:21.380 --> 00:04:24.100
But enough of Core Media.

00:04:24.100 --> 00:04:26.390
Let's talk about AV Foundation.

00:04:26.390 --> 00:04:32.360
In the last session, Discovering AV Foundation, Kevin
introduced AVAsset as an abstract model for working

00:04:32.360 --> 00:04:39.840
with assets and AV URL Assets allow
you to represent movies in files.

00:04:39.840 --> 00:04:46.340
An AVAsset consists of one or more AVAssetTracks
and each track, AVAssetTrack, represents --

00:04:46.340 --> 00:04:51.670
corresponds to a track whether it is
video or audio in your movie file.

00:04:51.670 --> 00:04:59.570
And to quickly recap, once you have an AVAsset, you can play it using AVPlayerItem.

00:04:59.570 --> 00:05:02.700
So now that -- what other things kinds
of things can we do with an AVAsset?

00:05:02.700 --> 00:05:09.300
Well, one of the things we're going to want
to do is to create an image for our time.

00:05:09.300 --> 00:05:15.220
And let me quickly switch to the
demo and show you what I mean.

00:05:16.650 --> 00:05:18.700
So here I have my demo.

00:05:18.700 --> 00:05:22.350
I'm going to launch AVPlayerDemo here.

00:05:22.350 --> 00:05:28.560
AVPlayerDemo, which you may remember seeing in
yesterday's State of the Union, Graphics and Media State

00:05:28.560 --> 00:05:31.650
of the Union, is an app written using AV Foundation.

00:05:31.650 --> 00:05:39.530
In the center of the display, you see your movie, and
at the bottom are a series of scrolling thumbnails.

00:05:39.530 --> 00:05:47.020
So when I hit Play, you'll notice that the thumbnails
slide along synchronously with the movie playback.

00:05:55.390 --> 00:06:03.520
So you'll notice as I scrub through
the movie, these thumbnails continue

00:06:03.520 --> 00:06:08.210
to show what you currently see in the movie.

00:06:08.210 --> 00:06:08.520
All right.

00:06:08.520 --> 00:06:12.980
Let's go back to the slides and take a
look at how these images were generated.

00:06:15.770 --> 00:06:21.190
Here is a short code snippet showing you
how you can use AVAssetImageGenerator

00:06:21.190 --> 00:06:24.620
to extract images from a file, from a movie.

00:06:24.620 --> 00:06:33.210
You start by creating an AssetImageGenerator and you
pass in the AVAsset that you want to extract images from.

00:06:33.210 --> 00:06:39.180
Then you can go ahead and start requesting
images asynchronously using the Generate CGImages

00:06:39.180 --> 00:06:41.430
Asynchronously API.

00:06:41.430 --> 00:06:48.000
When you call this method, you will pass in an
array of movie times that you will want images for,

00:06:48.000 --> 00:06:53.110
and you will also pass in a handerBlock, which will
be called when an image is ready for you to consume.

00:06:53.110 --> 00:06:59.000
If you're not familiar with blocks, think of it
as a callback function with some extra context.

00:06:59.000 --> 00:07:06.060
Like many other AV Foundation APIs,
this method is asynchronous.

00:07:06.060 --> 00:07:13.060
This means that your handlerBlock won't be
called until sometime after this method returns.

00:07:13.060 --> 00:07:18.890
So you should make sure is that you
retain your ImageGenerator object

00:07:18.890 --> 00:07:21.950
until you've received all of your images.

00:07:24.970 --> 00:07:32.050
This is an example of what a typical handlerBlock that
you pass into the AVAssetImageGenerator will look like.

00:07:32.050 --> 00:07:40.470
This handlerBlock will be called for each image request
that you make, and it's important that you check the result.

00:07:40.470 --> 00:07:43.510
The result can take on one of three values.

00:07:43.510 --> 00:07:46.760
In most cases, of course, it will
succeed, and you can go ahead

00:07:46.760 --> 00:07:52.340
and use the image object passed to you through handlerBlock.

00:07:52.340 --> 00:07:55.580
In certain cases, however, the image generation can fail

00:07:55.580 --> 00:08:01.290
and you can retrieve more information
about the error using the Error Object.

00:08:01.290 --> 00:08:06.840
Finally, you can also -- we provide a way for
you to cancel any outstanding image requests.

00:08:06.840 --> 00:08:15.320
And any image request that has been cancelled will result
in the handlerBlock being called with a cancelled status.

00:08:15.320 --> 00:08:19.380
So we saw how to create images from
an asset using AVAssetImageGenerator.

00:08:19.380 --> 00:08:25.460
Let's move on and look at how you can
trim a movie and save it to a new file.

00:08:25.460 --> 00:08:30.510
And the way you do that is with AVAssetExportSession.

00:08:30.510 --> 00:08:36.950
Here's some codes showing you how
to use AVAssetExportSession.

00:08:36.950 --> 00:08:39.820
When you create an AVAssetExportSession object,

00:08:39.820 --> 00:08:46.110
you will pass in the source asset
that you want to export and a preset.

00:08:46.110 --> 00:08:50.500
We provide a variety of presets for you to choose from.

00:08:50.500 --> 00:08:58.160
These presets have varying bit rates and quality
settings so you can choose from, based on your needs.

00:08:58.160 --> 00:09:09.610
Once you've created an asset -- an ExportSession, you will
want to specify an upward destination URL and a file type.

00:09:09.610 --> 00:09:14.220
You can also optionally specify a
time range that you want to trim.

00:09:14.220 --> 00:09:17.530
If you don't specify a time range, then by default,

00:09:17.530 --> 00:09:23.670
AVAssetExportSession will export
the entire duration of your movie.

00:09:23.670 --> 00:09:27.710
If you like, you can also optionally add or change metadata.

00:09:27.710 --> 00:09:31.960
And finally, this is how your start
your ExportSession asynchronously.

00:09:31.960 --> 00:09:36.800
Again, you will pass in a handlerBlock which
will be called when the export finishes.

00:09:36.800 --> 00:09:44.220
This is what a handlerBlock that you pass
into AVAssetExportSession looks like.

00:09:44.220 --> 00:09:52.040
And you'll notice that it looks remarkably similar to the
handlerBlock that you pass into AVAssetImageGenerator.

00:09:52.040 --> 00:10:00.260
And once again, you will want to examine the return status
for one of three values; completed, failed or cancelled.

00:10:00.260 --> 00:10:06.980
I'd like to take a moment and talk about error handling.

00:10:06.980 --> 00:10:11.910
It's important that in your code you
handle export failures gracefully.

00:10:11.910 --> 00:10:16.060
So what are some ways that an export can fail?

00:10:16.060 --> 00:10:21.180
Well, an AVAssetExportSession will
not let you overwrite an existing file,

00:10:21.180 --> 00:10:27.010
and attempting to do so will cause your
handlerBlock to be called with a failed status.

00:10:27.010 --> 00:10:31.840
If you'd like to overwrite an existing
file, you should remove the old one first.

00:10:31.840 --> 00:10:42.010
Perhaps you already know this, AVAssetExportSession
will also not let you write two files outside

00:10:42.010 --> 00:10:43.670
of your application sandbox.

00:10:43.670 --> 00:10:49.340
iOS 4 is a multitasking OS.

00:10:49.340 --> 00:10:55.340
This means that you can have your export continue
in the background while your user switches

00:10:55.340 --> 00:10:58.670
over to check her mail or update her Facebook.

00:10:58.670 --> 00:11:00.960
Well, this is great.

00:11:00.960 --> 00:11:05.750
But it does introduce a few other
situations why your export can fail.

00:11:05.750 --> 00:11:10.480
Again, the message here is to handle failures gracefully.

00:11:10.480 --> 00:11:15.280
For example, if your application
is exporting in the background

00:11:15.280 --> 00:11:20.660
and your user switches over to Pandora or the YouTube app.

00:11:20.660 --> 00:11:24.240
Well, starting media playback will interrupt your export.

00:11:24.240 --> 00:11:30.370
Even if you're exporting in the foreground, an
incoming phone call will interrupt your export.

00:11:30.370 --> 00:11:37.980
In situations like these, our recommendation
is that you let the user restart the export.

00:11:37.980 --> 00:11:45.560
So we saw how you can export a
movie using AVAssetExportSession.

00:11:45.560 --> 00:11:50.560
Let's switch gears now, and I'm
going to introduce AVComposition,

00:11:50.560 --> 00:11:54.330
which together with AVAsset form
the cornerstones of editing

00:11:54.330 --> 00:11:58.910
and which we will see throughout the rest of this hour.

00:11:58.910 --> 00:12:04.710
So we saw how AVAsset can be used as
a source object for a single movie.

00:12:04.710 --> 00:12:14.540
Once you have an asset, you can play it using AVPlayerItem,
extract images from it using AVAssetImageGenerator

00:12:14.540 --> 00:12:18.420
and export it using AVAssetExportSession.

00:12:18.420 --> 00:12:20.690
Well, now, what if you have multiple movies?

00:12:20.690 --> 00:12:27.400
The tool we give you to work with
multiple movies is AVComposition.

00:12:27.400 --> 00:12:31.140
And AVComposition is a subclass of AVAsset.

00:12:31.140 --> 00:12:36.270
This means that you can use it in the
same great ways that you use an AVAsset.

00:12:36.270 --> 00:12:44.360
You can play it, you can extract images
from it, and, of course, you can export it.

00:12:47.090 --> 00:12:52.520
So let's take a look at a first example
of how we can use AVComposition.

00:12:52.520 --> 00:12:56.720
And what we're going to look at is how we
can combine clips from multiple movies.

00:12:56.720 --> 00:13:01.180
And to illustrate, I think it's best if I just show you.

00:13:01.180 --> 00:13:10.610
So we're going to leave AVPlayerDemo now, and I'm
going to launch my second demo app, AVEditDemo.

00:13:10.610 --> 00:13:18.940
The first thing you'll notice about AVEditDemo is that
it's not the typical user interface that you would see

00:13:18.940 --> 00:13:21.720
in an application that you see in the app store.

00:13:21.720 --> 00:13:25.590
That's because AVEditDemo was not meant for end-users.

00:13:25.590 --> 00:13:31.950
With the target audience for AVEditDemo are people such
as yourselves, developers, and think of it as a playground

00:13:31.950 --> 00:13:37.150
for exploring the various AV Foundation editing APIs.

00:13:37.150 --> 00:13:41.730
Again, the source code for this application
is available for you to download,

00:13:41.730 --> 00:13:45.530
so I encourage you to play with this on your own.

00:13:45.530 --> 00:13:49.270
The first thing I'm going to do is select some clips.

00:13:49.270 --> 00:13:57.990
These clips were synched over to this phone using iTunes
file sharing, and they were taken on an iPhone OS 4.

00:13:57.990 --> 00:14:03.160
And these movies were taken in full 720p HD quality.

00:14:03.160 --> 00:14:15.060
So I'm going to select this first clip of a cat here, and
I'm going to select a range that I want this movie to play.

00:14:15.060 --> 00:14:16.350
So I'll say from here to here.

00:14:16.350 --> 00:14:18.500
I'm going to select a second clip.

00:14:18.500 --> 00:14:24.680
Let's take this beach scene here and
play about 8 seconds of that too.

00:14:24.680 --> 00:14:38.510
And I'll select a third clip, and I will take
another 8 seconds or so of this scene as well.

00:14:38.510 --> 00:14:50.200
So let's see what happens when I hit Play.

00:14:59.900 --> 00:15:12.290
OK. Let's go back to slides and
review what we just saw in this demo.

00:15:12.290 --> 00:15:26.860
We started out with three clips, with the cat, the
beach and the flowers, and we took clips from each movie

00:15:26.860 --> 00:15:29.340
and composed them together on a timeline.

00:15:29.340 --> 00:15:33.070
AVComposition is the tool that we
provide to allow you to do this.

00:15:33.070 --> 00:15:38.100
AVComposition allows you to lay
out asset segments on a timeline.

00:15:38.100 --> 00:15:45.670
And AVComposition has one or more AVCompositionTracks much like AVAsset has AVAssetTracks.

00:15:45.670 --> 00:15:52.780
And AVCompositionTrack -- each AVCompositionTrack has an array of AVCompositionTrack segments.

00:15:52.780 --> 00:15:56.510
Let's take a look at what is inside a track segment.

00:15:56.510 --> 00:16:04.680
Each track segment contains information to identify
the source movie, the track inside the source movie

00:16:04.680 --> 00:16:10.380
and the time range that you want
to include in your composition.

00:16:12.210 --> 00:16:17.980
The mutable variant of AVComposition is
AV MutableComposition, as you might expect.

00:16:17.980 --> 00:16:25.130
And we provide a number of APIs for you to
insert assets into your MutableComposition.

00:16:25.130 --> 00:16:34.000
For example, if you want to insert all of the tracks of
an asset into your composition, this is how you do that.

00:16:34.000 --> 00:16:39.960
You can also insert just a single part of a
single track of an asset into your composition.

00:16:39.960 --> 00:16:47.550
In your application, you may have your own representation
of how movies -- you want movies to be combined together,

00:16:47.550 --> 00:16:57.460
in which case, it may be simpler to just give
us the array of track segments and set them

00:16:57.460 --> 00:17:02.080
on your composition track directly, and we
provide a way for you to do that as well.

00:17:02.080 --> 00:17:03.900
This is how you create a MutableComposition.

00:17:03.900 --> 00:17:17.480
You start with an empty MutableComposition, then you
can add -- start adding MutableComposition tracks.

00:17:17.480 --> 00:17:21.820
In this case, we're adding a video MutableComposition track.

00:17:21.820 --> 00:17:26.070
And once you have your tracks, you can go
ahead and start inserting asset segments.

00:17:32.170 --> 00:17:34.970
A note on working with MutableCompositions.

00:17:34.970 --> 00:17:45.020
It is not safe to modify a MutableComposition while you are
playing it back, extracting images from it or exporting it.

00:17:45.020 --> 00:17:47.600
Well, why, you may ask.

00:17:47.600 --> 00:17:51.700
Well, remember that AV Foundation
uses an asynchronous model.

00:17:51.700 --> 00:17:57.230
So taking the example of playback, if
you're playing back your MutableComposition,

00:17:57.230 --> 00:18:01.030
AV Foundation will be accessing it continuously,

00:18:01.030 --> 00:18:05.610
periodically from another thread
or maybe even another process.

00:18:05.610 --> 00:18:10.420
Well, now, if you go ahead and try to change it
essentially behind AV Foundations back, well,

00:18:10.420 --> 00:18:14.260
you can imagine that bad things can happen.

00:18:14.260 --> 00:18:20.270
So our recommendation is that you
pass a copy for these tasks,

00:18:20.270 --> 00:18:23.790
and then you can go ahead and safely modify the original.

00:18:23.790 --> 00:18:30.600
In this example of code snippet, I'm making
an immutable copy of my MutableComposition

00:18:30.600 --> 00:18:34.880
and create -- using that to create my player item.

00:18:36.430 --> 00:18:43.700
In your application, you may wish to have a live
view of your composition, and you want this live view

00:18:43.700 --> 00:18:47.550
to update whenever your composition changes.

00:18:50.090 --> 00:18:58.310
The way you can do that is by periodically creating a new
snapshot of your composition, creating a new player item

00:18:58.310 --> 00:19:07.840
and using the ReplaceCurrentItemWithPlayerItem API to safely
and seamlessly update your player with this new snapshot.

00:19:11.390 --> 00:19:16.860
So we saw how to cut together multiple
clips using AVComposition.

00:19:16.860 --> 00:19:23.690
Well, that was a good start, but let's
do something a little more interesting

00:19:23.690 --> 00:19:26.920
and add an additional audio track to our movie.

00:19:26.920 --> 00:19:29.490
And, again, I'd like to start by showing you.

00:19:29.490 --> 00:19:37.230
So we're going to go back to our controls here, and
we're going to go down, scroll down to these options,

00:19:37.230 --> 00:19:39.400
and I'm going to enable an audio commentary track.

00:19:39.400 --> 00:19:48.810
I'll select an audio clip, and
I'm going to set the start time,

00:19:48.810 --> 00:19:54.370
the time at which I want this audio
commentary track to start.

00:19:54.370 --> 00:19:58.520
And I'm going to set it to start at around 11 seconds.

00:19:58.520 --> 00:20:07.550
So now if I hit Play, you should expect to hear
an audio commentary track at around 11 seconds.

00:20:12.890 --> 00:20:27.950
>> You know, it's true, when something exceeds your ability
to understand how it works, it sort of becomes magical.

00:20:27.950 --> 00:20:29.920
>> Eric: All right.

00:20:29.920 --> 00:20:32.250
So let me play that for you again.

00:20:32.250 --> 00:20:39.800
I won't play it quite from the beginning, but this
time I want you to listen and notice how the main --

00:20:39.800 --> 00:20:46.440
the volume of the main audio track quiets down
just before the audio commentary kicks in.

00:20:46.440 --> 00:21:01.930
>> You know, it's true, when something exceeds your ability
to understand how it works, it sort of becomes magical.

00:21:01.930 --> 00:21:04.850
>> Eric: That was Johnny Ives, by the
way, in case you didn't recognize his voice.

00:21:04.850 --> 00:21:10.680
So let's go back to slides and review
again what we just heard in this demo.

00:21:10.680 --> 00:21:14.750
So we added an audio commentary track.

00:21:14.750 --> 00:21:19.680
We started out with our composition
with the video and audio track,

00:21:19.680 --> 00:21:23.260
we added a third audio track for the audio commentary.

00:21:23.260 --> 00:21:29.850
Notice how that this new audio track doesn't
start at the same time as the other audio tracks.

00:21:29.850 --> 00:21:35.900
There are gaps, and we call these
gaps empty edits or empty segments.

00:21:35.900 --> 00:21:41.870
The second thing that I showed you was the volume

00:21:41.870 --> 00:21:47.520
of the main audio track quieted down
just before Johnny's voice came on.

00:21:47.520 --> 00:21:55.450
This technique is known as ducking, and the
way we do that is with audio volume ramps.

00:21:55.450 --> 00:22:00.610
So let's look at the AV Foundation
objects involved in making this happen.

00:22:00.610 --> 00:22:05.600
Again, we started with our AVComposition,
video and audio track.

00:22:05.600 --> 00:22:08.530
We added a third audio track.

00:22:11.610 --> 00:22:18.030
And to do the volume ducking, we
created a new object, AVAudioMix.

00:22:18.030 --> 00:22:27.980
AVAudioMix allows you to add volume ramps
to the audio tracks in your composition.

00:22:27.980 --> 00:22:34.250
So AVAudioMix is a tool for adding
volume adjustments to your composition.

00:22:34.250 --> 00:22:42.320
An AVAudioMix has an array of AVAudioMixInputParameter objects.

00:22:42.320 --> 00:22:49.050
And each InputParameter object allows you to
adjust the volume of a single audio track.

00:22:49.050 --> 00:22:54.630
If you don't have an AudioMixInputParameter
object associated with a track,

00:22:54.630 --> 00:22:57.250
that track will simply get the default volume.

00:22:57.250 --> 00:23:01.290
Here's how you create an audio mix.

00:23:01.290 --> 00:23:03.610
Let me walk you through this.

00:23:03.610 --> 00:23:10.650
Start by creating an empty MutableAudioMixInputParameters
object.

00:23:10.650 --> 00:23:18.200
Then you can set the volume either at a specific
time, such as I'm setting the volume to 1 and 0.

00:23:18.200 --> 00:23:22.090
You can also set a -- you can also ramp the volume.

00:23:22.090 --> 00:23:29.210
So here I am setting the volume to ramp
from 1 to 0.2 between times X and Y.

00:23:29.210 --> 00:23:36.840
Note that in between the times that I specify explicitly,
the last value of the volume continues automatically.

00:23:36.840 --> 00:23:41.720
So by setting -- specifying the
volume at time 0 in between X and Y,

00:23:41.720 --> 00:23:47.510
that is enough to describe the yellow
volume curve that you see to your right.

00:23:47.510 --> 00:23:55.070
Once you've created your InputParameter objects,
you can go ahead and create an AudioMix object.

00:23:55.070 --> 00:24:05.920
To use AVAudioMix, simply set it on your player
item for playback or your ExportSession for export.

00:24:05.920 --> 00:24:13.600
So we saw how to add in additional audio track and
adjust the volume of our audio tracks using AVAudioMix.

00:24:13.600 --> 00:24:18.620
Let's move on and talk about video transitions.

00:24:24.070 --> 00:24:33.870
So go back here to our options, and
we're going to turn on Transitions.

00:24:33.870 --> 00:24:38.900
I'm going to leave the Default
Transition Duration at 1 second.

00:24:38.900 --> 00:24:42.950
And let's see what push transitions look like.

00:24:42.950 --> 00:25:07.400
>> You know, it's true when something exceeds your ability
to understand how it works, it sort of becomes magical.

00:25:07.400 --> 00:25:11.470
>> Eric: So let's go back and take a
look at what cross-fades look like.

00:25:11.470 --> 00:25:36.210
>> You know, it's true, when something exceeds your ability
to understand how it works, it sort of becomes magical.

00:25:36.210 --> 00:25:37.960
>> Eric: All right.

00:25:39.850 --> 00:25:41.970
Let's go back to slides.

00:25:41.970 --> 00:25:50.580
So what did we just see?

00:25:50.580 --> 00:25:53.910
We added our old friend AVComposition.

00:25:53.910 --> 00:25:59.230
We have our -- again, our video and audio and track.

00:25:59.230 --> 00:26:06.430
But this time, instead of simply cutting from one clip
to the next, we're going to add an additional video track

00:26:06.430 --> 00:26:12.160
and an additional audio track, and
we're going to overlap between the --

00:26:12.160 --> 00:26:16.590
overlap the video tracks and audio
tracks during the transition.

00:26:16.590 --> 00:26:24.280
During this overlap, we're going to be decoding and playing
two video tracks and two audio tracks at the same time.

00:26:24.280 --> 00:26:26.920
When you play two audio tracks, they mix together naturally.

00:26:26.920 --> 00:26:31.090
You just hear both audio tracks at the same time.

00:26:31.090 --> 00:26:37.700
But for video, we're going to need a way to describe
explicitly how to combine the two video tracks,

00:26:37.700 --> 00:26:41.360
and the way we do that is with AVVideoComposition.

00:26:41.360 --> 00:26:52.190
AVVideoComposition allows you to specify when
to play one track, when to play the other track

00:26:52.190 --> 00:26:54.210
and when to play a combination of the two.

00:26:54.210 --> 00:27:02.590
And the result of applying the video composition that
you see to the video tracks is something like this.

00:27:07.350 --> 00:27:09.800
Let's talk a little bit more about AVVideoComposition.

00:27:09.800 --> 00:27:16.980
AVVideoComposition has an array of
AVVideoComposition instructions.

00:27:16.980 --> 00:27:26.940
Each instruction describes the output
video in terms of input layers,

00:27:26.940 --> 00:27:31.650
and we call these layers AVVideoCompositionLayerInstructions.

00:27:31.650 --> 00:27:42.540
Each layer instruction allows you to modify the opacity
or the affine transform of the original video track.

00:27:42.540 --> 00:27:50.390
And you can ramp these values, what we call tweening,
and this allows you to get transition effects.

00:27:50.390 --> 00:27:56.570
So, for example, if you tween the
opacity value, you can get a cross-fade.

00:27:56.570 --> 00:28:01.300
Or if you tween the affine transform,
you can get a push transition.

00:28:01.300 --> 00:28:07.560
Let's take a look at how we can construct
an AVVideoCompositionInstruction.

00:28:07.560 --> 00:28:10.810
Again, I'll walk you through this code snippet here.

00:28:10.810 --> 00:28:15.750
We start by creating an empty
MutableVideoCompositionInstruction.

00:28:15.750 --> 00:28:20.820
First thing we're going to want to is set a time range.

00:28:20.820 --> 00:28:28.890
This is the time range over which we
want this instruction to be executed.

00:28:28.890 --> 00:28:35.320
In this case, I'm describing this transition here.

00:28:35.320 --> 00:28:40.490
Then we can go ahead and create layers
instructions for this instruction.

00:28:40.490 --> 00:28:47.160
We're going to want to create a layer instruction
for Track A, and we're going to fade out Track A

00:28:47.160 --> 00:28:53.310
by setting a ramp on its opacity from 1 to 0.

00:28:53.310 --> 00:28:57.420
We'll also want to create a second
layer instruction for Track B.

00:28:57.420 --> 00:29:02.890
For this layer instruction, we're going to
leave the opacity at its default value of 1.

00:29:02.890 --> 00:29:11.630
And once we have our layer instructions, we can add
them to our transition object in top to bottom order.

00:29:11.630 --> 00:29:16.010
Once we have our instruction objects,
we can create a video composition.

00:29:16.010 --> 00:29:26.420
Start with an empty MutableVideoComposition and set
the instructions on this video composition object.

00:29:26.420 --> 00:29:32.100
There's going to be a few properties you will
want to set on your video composition object.

00:29:33.190 --> 00:29:39.240
To specify the frame rate at which you will want your
composition to run, use the FrameDuration property.

00:29:39.240 --> 00:29:42.970
So, for example, if you want your
composition to run at 30 frames per second,

00:29:42.970 --> 00:29:47.990
you will want to set your FrameDuration at 1 over 30.

00:29:47.990 --> 00:29:55.440
The render slides tells AV Foundation how
large of a canvass to use when rendering

00:29:55.440 --> 00:29:58.670
and compositing your video frames together.

00:29:58.670 --> 00:30:08.370
In my case, I'm rendering HD 720p video, so I'm
just going to set the render slides to 1280 by 720.

00:30:08.370 --> 00:30:15.500
In certain cases, it may be unnecessary to be rendering
your video composition at its full resolution.

00:30:15.500 --> 00:30:24.880
For example, if my source material is 1280 pixels
wide but my view is only 640 pixels wide, well,

00:30:24.880 --> 00:30:27.730
I don't really need to be rendering every single pixel.

00:30:27.730 --> 00:30:34.930
And we allow you to set a render scale on
your video composition, and this allows --

00:30:34.930 --> 00:30:38.650
this tells AV Foundation it can do
less work, and it will also ensure

00:30:38.650 --> 00:30:42.480
that your playback runs as silky smooth as possible.

00:30:42.480 --> 00:30:48.020
Using an AVVideoComposition is
very much like using an AVAudioMix.

00:30:48.020 --> 00:30:51.990
You can set it on your player item for playback.

00:30:51.990 --> 00:30:58.780
You can also set it on an AssetImageGenerator
for extracting images from a composition.

00:30:58.780 --> 00:31:03.020
And, of course, you can set it on
an AssetExportSession for export.

00:31:03.020 --> 00:31:08.790
There's a few things I would like to point out
to you when working with AVVideoCompositions.

00:31:08.790 --> 00:31:15.680
The instructions inside your AVVideoComposition
must not overlap or contain any gaps.

00:31:15.680 --> 00:31:24.550
You should ensure that the time range of each instruction in
your video composition immediately follows the previous one.

00:31:24.550 --> 00:31:31.900
Your video composition may also not -- must
not be shorter than your AVComposition.

00:31:31.900 --> 00:31:37.660
And you should ensure that all of the instructions

00:31:37.660 --> 00:31:43.660
in your video composition span the
entire duration of your AVComposition.

00:31:43.660 --> 00:31:47.190
I'd like to talk briefly about hardware requirements.

00:31:47.190 --> 00:31:54.880
If you would like to use AVVideoComposition in your
application, it must be running on an iPhone OS 3 GS

00:31:54.880 --> 00:31:58.920
or higher or a third generation iPod touch.

00:31:58.920 --> 00:32:05.690
While we're on the topic of hardware requirements, I'd
like to quickly point out that there is a practical limit

00:32:05.690 --> 00:32:13.980
to the number of video streams that a device can decode
simultaneously, and this limitation is hardware specific.

00:32:13.980 --> 00:32:18.360
For those of you in the audience who are
familiar video compression techniques,

00:32:18.360 --> 00:32:22.480
you may be wondering to yourself,
"Well, what about i and p Frames?

00:32:22.480 --> 00:32:27.420
Does AV Foundation restrict me to
do my edits on I-frame boundaries?"

00:32:27.420 --> 00:32:30.320
And the answer is "No."

00:32:30.320 --> 00:32:34.790
AV Foundation allows you to place
your edits anywhere you like.

00:32:34.790 --> 00:32:42.840
If your edit doesn't begin on a key frame, however,
AV Foundation will need to start decoding starting

00:32:42.840 --> 00:32:47.670
from an earlier key frame, and this
extra decoding is known at catchup.

00:32:47.670 --> 00:32:53.220
Our recommendation to you is that you
alternate your edits in your composition.

00:32:53.220 --> 00:32:56.190
What do I mean by that?

00:32:56.190 --> 00:33:00.890
Well, in this example, I have an AVComposition with two video tracks.

00:33:00.890 --> 00:33:08.850
I start with my first edit, video edit, in the lower video
track, my upper video edit is in the second video track,

00:33:08.850 --> 00:33:14.420
and I alternate back and forth in this
manner for the duration of my composition.

00:33:14.420 --> 00:33:23.470
Laying out your edits in this manner allows AV Foundation
to do the catchup decoding during the empty edits.

00:33:23.470 --> 00:33:29.250
And, again, this will ensure that your
playback is as smooth as possible.

00:33:29.250 --> 00:33:35.670
If you employ this technique, however, you
will need to use an AVVideoComposition

00:33:35.670 --> 00:33:39.720
to tell AV Foundation when to use which track.

00:33:39.720 --> 00:33:44.280
I'd like to briefly talk about some
other uses for AVVideoComposition.

00:33:44.280 --> 00:33:51.680
If you insert two assets with different video sizes
into your composition, AV Foundation will, by default,

00:33:51.680 --> 00:33:55.030
place your edits in two different video tracks.

00:33:55.030 --> 00:33:58.750
AVPlayer, however, will only play one of them.

00:33:58.750 --> 00:34:04.980
And just like in the situation I showed you in the
last slide, you will need to add an AVVideoComposition

00:34:04.980 --> 00:34:08.460
to tell AVPlayer when to play which track.

00:34:08.460 --> 00:34:16.770
If you're working with movies captured on an iPhone
device, these movies will have a rotation matrix associated

00:34:16.770 --> 00:34:19.480
with them, and you can examine this rotation matrix

00:34:19.480 --> 00:34:23.290
by querying the PreferredTransform
property on your video track.

00:34:23.290 --> 00:34:29.540
If you play this asset directly using
AVPlayer, then AVPlayer will take care

00:34:29.540 --> 00:34:32.200
of doing the rotation for you automatically.

00:34:32.200 --> 00:34:39.990
But if you now insert this asset into a
composition, the rotation will be ignored,

00:34:39.990 --> 00:34:45.400
and you will need to use an AVVideoComposition to reinstate the rotation.

00:34:45.400 --> 00:34:55.020
So we saw how to use video transitions in
your composition using AVVideoComposition.

00:34:55.020 --> 00:35:06.620
Let's move to our last topic, and I'm going to show you
how you can incorporate Core Animation into your movie.

00:35:06.620 --> 00:35:11.960
And again, I'd like to show you with a demo.

00:35:11.960 --> 00:35:14.190
So we're back in AVEditDemo here.

00:35:14.190 --> 00:35:21.900
I'm going to go back to my options, and I'm
going to go to the last option here, Titles,

00:35:21.900 --> 00:35:26.890
and I'm going to add an animated title to my movie.

00:35:26.890 --> 00:35:30.800
So let's say "Magic."

00:35:30.800 --> 00:35:44.950
Let's see what happens now when I hit Play.

00:35:44.950 --> 00:35:58.240
>> You know, it's true, when something exceeds your ability
to understand how it works, it sort of becomes magical.

00:35:58.240 --> 00:36:05.350
>> Eric: So this animated title sequence was drawn
using Core Animation, rendered using Core Animation

00:36:05.350 --> 00:36:08.300
and composited directly on your video frame.

00:36:08.300 --> 00:36:14.010
But it's actually -- even though it's drawn using
Core Animation, it's actually part of the movie.

00:36:14.010 --> 00:36:20.600
So if I scroll -- scrub back through my composition,
you'll notice that my animation reappears.

00:36:20.600 --> 00:36:27.660
And if I scrub forward, you'll see
that the stars will rotate clockwise.

00:36:27.660 --> 00:36:33.860
And if I scrub backwards, they'll
be animating counterclockwise.

00:36:33.860 --> 00:36:44.380
So I hope you indulge me here, and I'm
going to play this for you one last time.

00:36:44.380 --> 00:36:53.240
I'd like to point out, once again, that what we're looking
at here is HD video, 720p HD video edited together.

00:36:53.240 --> 00:37:00.660
We've added video transitions, so we're decoding
and compositing multiple HD video streams,

00:37:00.660 --> 00:37:06.330
we've added an extra commentary track, and now
we've just thrown in Core Animation into the mix.

00:37:06.330 --> 00:37:09.450
And all of this is happening in real time on an iPhone.

00:37:09.450 --> 00:37:29.930
>> You know, it's true, when something exceeds your ability
to understand How it works, it sort of becomes magical.

00:37:29.930 --> 00:37:32.300
>> Eric: All right.

00:37:32.300 --> 00:37:34.510
Let's go back to slides.

00:37:34.510 --> 00:37:40.240
[ Applause ]

00:37:40.240 --> 00:37:44.830
So, again, to quickly review what we just saw,

00:37:44.830 --> 00:37:49.820
we had our good old friend AVComposition
with our video and audio tracks.

00:37:49.820 --> 00:37:59.440
What we did was add some Core Animation layers, and we
added a layer for the magic title and for the ring of stars.

00:37:59.440 --> 00:38:06.860
We also some animations to spend the stars and fade
out the entire title sequence after 10 seconds.

00:38:06.860 --> 00:38:13.030
Let's take a look briefly at the Core
Animation objects involved in this.

00:38:13.030 --> 00:38:23.270
We had a single animated title layer with two sublayers; one
for the title, the text and another for the ring of stars.

00:38:23.270 --> 00:38:28.620
I added an explicit animation to spend the ring
of stars layer and another explicit animation

00:38:28.620 --> 00:38:36.630
on the parent animated title layer to fade
out the entire title after 10 seconds.

00:38:36.630 --> 00:38:43.860
If you like more information on Core Animation,
I encourage you to attend Sessions 424 and 425.

00:38:43.860 --> 00:38:49.100
And now, I'd like to a bit about animation video and timing.

00:38:49.100 --> 00:38:56.680
So animation, as you know, is the result of changing
a property such as position or size over time.

00:38:56.680 --> 00:39:03.020
Some of you may already be familiar with incorporating
Core Animation in your application for real time effects.

00:39:03.020 --> 00:39:12.790
With AV Foundation, we're allowing you to use these same
great tools, same Core Animation, but put it in your movie.

00:39:12.790 --> 00:39:21.660
And the only difference is that instead of your animations
running in real time, they're running on the movie timeline.

00:39:21.660 --> 00:39:24.490
Let's take a look at how this works.

00:39:24.490 --> 00:39:28.370
We start with a UIView.

00:39:28.370 --> 00:39:32.520
This UIView will have a layer associated with it.

00:39:32.520 --> 00:39:34.950
This layer will have some sort of layer hierarchy.

00:39:34.950 --> 00:39:39.320
One of these layers will be your AVPlayer layer.

00:39:39.320 --> 00:39:45.450
This AVPlayer layer actually has
a private sublayer for the video.

00:39:45.450 --> 00:39:50.270
One thing I'd like to point out is
all of the objects in this diagram,

00:39:50.270 --> 00:39:54.080
except for the video, are running in real time.

00:39:54.080 --> 00:39:56.200
What do I mean by real time?

00:39:56.200 --> 00:40:02.630
Well, Core Animation counts time in seconds since boot.

00:40:02.630 --> 00:40:08.660
This time is always monotonically
increasing and is outside of your control.

00:40:08.660 --> 00:40:12.330
The video, on the other hand, is running in movie time.

00:40:12.330 --> 00:40:15.350
The movie time is counted in seconds
since the start of the movie.

00:40:15.350 --> 00:40:20.500
Movie time is under the control of
you, the user, or you, the developer.

00:40:20.500 --> 00:40:24.660
If I start playback, movie time will advance.

00:40:24.660 --> 00:40:28.010
But I can also pause movie time by pausing playback.

00:40:28.010 --> 00:40:33.380
I can even make movie time go backwards by
scrubbing back to an earlier point in the movie.

00:40:33.380 --> 00:40:40.920
When I add my animated title sequence to the movie, I
want my animations to be running on the movie timeline.

00:40:40.920 --> 00:40:46.720
And the way we let you do that is with AV SynchronizedLayer.

00:40:46.720 --> 00:40:51.810
So when you're playing back with Core
Animation, we give you AV SynchronizedLayer

00:40:51.810 --> 00:40:57.730
to make the animation run according to movie time.

00:40:57.730 --> 00:41:02.450
The actual rendering is still done by Core
Animation's onscreen rendering facilities.

00:41:02.450 --> 00:41:05.860
It's just the timing that we modify.

00:41:05.860 --> 00:41:14.510
But what happens if you want to export
your composition with Core Animation?

00:41:14.510 --> 00:41:19.520
Well, we're going to have to do something
slightly different because we can't rely

00:41:19.520 --> 00:41:23.020
on Core Animation's onscreen rendering facilities anymore.

00:41:23.020 --> 00:41:29.120
So what we're going to do is introduce a
post-processing stage to our video composition.

00:41:29.120 --> 00:41:36.910
We're telling -- we're essentially removing the Core
Animation from the onscreen layers and we're going to add it

00:41:36.910 --> 00:41:41.210
to our video composition as a post-processing stage.

00:41:41.210 --> 00:41:49.430
And the way we do that is with AVVideoComposition Core Animation Tool, which I think has a distinction

00:41:49.430 --> 00:41:52.090
of being the longest class in AV Foundation.

00:41:52.090 --> 00:41:57.690
The way AVVideoComposition Core Animation Tool
works is very similar to AV SynchronizedLayer.

00:41:57.690 --> 00:41:59.570
There's actually a couple of ways where you can set it up.

00:41:59.570 --> 00:42:06.010
I'll show you one here, and you can
look in the header for more information

00:42:06.010 --> 00:42:12.190
on other ways you can set this up, or
you can come talk to us in the lab.

00:42:12.190 --> 00:42:18.750
We're going to have a single parent layer
in our VideoComposition Core Animation Tool,

00:42:18.750 --> 00:42:25.940
and this parent layer will have both our
video sublayer and our animation title layer.

00:42:25.940 --> 00:42:32.340
Now using Core Animation -- using -- rendering
Core Animation offline can be expensive.

00:42:32.340 --> 00:42:38.720
And you're going to want to disable this
postprocessing when it's not needed.

00:42:38.720 --> 00:42:46.380
And the way you do that is by setting
the EnablePostProcessing property

00:42:46.380 --> 00:42:49.670
in your composition instruction to No.

00:42:49.670 --> 00:42:55.880
And this tells AV Foundation it can skip the Core
Animation Postprocessing stage for the duration

00:42:55.880 --> 00:43:00.180
of that instruction, and this will speed up your export.

00:43:00.180 --> 00:43:02.750
Quick note on multitasking.

00:43:02.750 --> 00:43:07.460
Core Animation is disallowed in the background.

00:43:07.460 --> 00:43:15.210
This means that your export is running in the background
and you suddenly hit on a Core Animation that you need

00:43:15.210 --> 00:43:24.580
to do some postprocessing, your export will fail and
the handlerBlock will be called with the failed status.

00:43:24.580 --> 00:43:29.070
Core Animation provides a number
of very useful default behaviors

00:43:29.070 --> 00:43:34.080
that help you when working with real time animations.

00:43:34.080 --> 00:43:37.860
But these default behaviors can
introduce some unexpected behavior

00:43:37.860 --> 00:43:40.290
when you're trying to add your animation to your movies.

00:43:40.290 --> 00:43:48.520
For example, if you set your begin time in your animation
to 0, Core Animation will automatically translate 0

00:43:48.520 --> 00:43:52.450
to the current media time using CACurrentMediaTime.

00:43:52.450 --> 00:43:58.170
This is actually the current real time,
and it's most likely not what you want.

00:43:58.170 --> 00:43:58.950
You really want 0.

00:43:58.950 --> 00:44:05.350
So you're going to want to set your
begin time to a small non-0 number,

00:44:05.350 --> 00:44:11.290
and we provide a constant AVCoreAnimation
BeginTimeZero for this purpose.

00:44:11.290 --> 00:44:17.650
Core Animation will, by default, remove
any animations that it thinks have passed.

00:44:17.650 --> 00:44:24.080
So if you want your animation to run
and run multiple times, which you will,

00:44:24.080 --> 00:44:30.320
then you'll need to set the RemovedOnCompletion
property on your animation to No.

00:44:30.320 --> 00:44:34.030
When you change a property on a
Core Animation layer, by default,

00:44:34.030 --> 00:44:38.160
Core Animation will add what we call an implicit animation.

00:44:38.160 --> 00:44:43.780
This implicit animation will animate your
property from its old value to its new value.

00:44:43.780 --> 00:44:49.530
But these implicit animations -- you probably
don't want these implicit animations in your movie

00:44:49.530 --> 00:44:52.120
because you want to control them yourself.

00:44:52.120 --> 00:44:58.640
So you're going to want to probably
disable implicit animations.

00:44:58.640 --> 00:45:04.420
And the way you do that is by surrounding
your property changes with a transaction

00:45:04.420 --> 00:45:12.110
and disabling actions using the
SetDisable Actions method on CATransaction.

00:45:12.110 --> 00:45:20.230
In certain cases, you may want your Core Animation
Animations to continue past the end of your video.

00:45:20.230 --> 00:45:21.440
This is OK.

00:45:21.440 --> 00:45:27.340
But you will need to explicitly tell AV Foundation
how long your playback or your export should run,

00:45:27.340 --> 00:45:32.340
and the way you do that is by setting the
ForwardPlaybackEndTime property on your player item

00:45:32.340 --> 00:45:38.290
for playback or setting the TimeRange
property on your ExportSession for export.

00:45:38.290 --> 00:45:45.070
So we saw how to add Core Animation Animations
to your composition using AV SynchronizedLayer

00:45:45.070 --> 00:45:48.090
and AVVideoComposition Core Animation Tool.

00:45:48.090 --> 00:45:51.220
At the beginning of the session, I
promised to show you how to do these things

00:45:51.220 --> 00:45:54.360
with the aid of the APIs of the AV Foundation.

00:45:54.360 --> 00:45:56.390
Let's quickly review.

00:45:56.390 --> 00:46:03.090
If you want to extract images from an asset,
you want to use AVAssetImageGenerator.

00:46:03.090 --> 00:46:09.390
If you want to export your movie with some
optional trimming, use AVAssetExportSession.

00:46:09.390 --> 00:46:17.200
If you want to combine clips from multiple
movies, you want to use AVComposition.

00:46:17.200 --> 00:46:20.780
If you've added additional audio
tracks and want to adjust the volume

00:46:20.780 --> 00:46:24.290
of these audio tracks, you want to use AVAudioMix.

00:46:24.290 --> 00:46:28.370
If you want to spice up your movie
with some video transitions

00:46:28.370 --> 00:46:32.540
such as cross-fades, we provide AVVideoComposition.

00:46:32.540 --> 00:46:40.290
And finally, if you've added Core Animation animations
to your movie and you want them to run synchronously

00:46:40.290 --> 00:46:45.880
with your movie on the movie timeline, we
provide AVSynchronizedLayer for playback

00:46:45.880 --> 00:46:50.070
and AVVideoComposition Core Animation Tool for export.

00:46:50.070 --> 00:46:55.870
If you have any questions on any of the
material I presented in this session,

00:46:55.870 --> 00:46:59.600
feel free to contact Eryk Vershen,
our Media Technologies Evangelist.

00:46:59.600 --> 00:47:07.280
And if you missed Kevin's wonderful session
on Discovering AV Foundation, don't panic,

00:47:07.280 --> 00:47:10.650
he'll be giving the session again on Thursday at 4:30.

00:47:10.650 --> 00:47:16.790
And please stay tuned for our next
session in the series on using the camera,

00:47:16.790 --> 00:47:31.440
which will take place right here
immediately following this session.

