WEBVTT

00:00:07.516 --> 00:00:17.500 A:middle
[ Music ]

00:00:22.516 --> 00:00:26.086 A:middle
[ Applause ]

00:00:26.586 --> 00:00:27.746 A:middle
&gt;&gt; So, good morning.

00:00:29.806 --> 00:00:31.406 A:middle
Welcome to our session on What's

00:00:31.476 --> 00:00:34.516 A:middle
New in ARKit 2.

00:00:34.806 --> 00:00:36.736 A:middle
My name is Arsalan, and I am an

00:00:36.736 --> 00:00:41.276 A:middle
engineer from ARKit team.

00:00:41.616 --> 00:00:42.906 A:middle
Last year, we were really

00:00:42.906 --> 00:00:45.536 A:middle
excited to give ARKit in your

00:00:45.536 --> 00:00:48.976 A:middle
hands as part of iOS 11 update.

00:00:49.386 --> 00:00:53.496 A:middle
ARKit has been deployed to

00:00:53.496 --> 00:00:55.266 A:middle
hundreds of millions of devices,

00:00:56.086 --> 00:00:58.296 A:middle
making iOS the biggest and most

00:00:58.296 --> 00:00:59.816 A:middle
advanced AR platform.

00:01:03.226 --> 00:01:05.206 A:middle
ARKit gives you simple to use

00:01:05.266 --> 00:01:06.986 A:middle
interface for powerful set of

00:01:07.016 --> 00:01:07.476 A:middle
features.

00:01:10.136 --> 00:01:12.416 A:middle
We have been truly amazed by

00:01:12.416 --> 00:01:14.396 A:middle
what you have created with ARKit

00:01:14.396 --> 00:01:15.286 A:middle
so far.

00:01:15.486 --> 00:01:17.456 A:middle
So let's see some examples from

00:01:17.456 --> 00:01:17.876 A:middle
App Store.

00:01:20.386 --> 00:01:23.156 A:middle
Civilisations is an AR app that

00:01:23.156 --> 00:01:25.066 A:middle
brings historical artifacts in

00:01:25.066 --> 00:01:25.536 A:middle
front of you.

00:01:26.296 --> 00:01:27.966 A:middle
You can view them from every

00:01:27.966 --> 00:01:28.326 A:middle
angle.

00:01:28.816 --> 00:01:32.206 A:middle
You can also enable x-ray modes

00:01:32.436 --> 00:01:33.746 A:middle
to have mode interaction.

00:01:35.206 --> 00:01:36.906 A:middle
You can bring them in your

00:01:37.086 --> 00:01:40.226 A:middle
backyard, and you can even bring

00:01:40.226 --> 00:01:42.336 A:middle
them to life exactly they look

00:01:42.336 --> 00:01:43.596 A:middle
like hundreds of years ago.

00:01:45.096 --> 00:01:46.416 A:middle
So this is a great tool to

00:01:46.416 --> 00:01:48.016 A:middle
browse historical artifacts.

00:01:50.356 --> 00:01:52.376 A:middle
Boulevard AR is an all right app

00:01:52.516 --> 00:01:55.346 A:middle
that lets you browse the work of

00:01:55.346 --> 00:01:57.446 A:middle
arts in a way that's never been

00:01:57.446 --> 00:01:58.176 A:middle
possible before.

00:01:58.796 --> 00:02:00.486 A:middle
You can put them on ground or

00:01:58.796 --> 00:02:00.486 A:middle
You can put them on ground or

00:02:00.486 --> 00:02:02.736 A:middle
wall, and you can really go

00:02:02.736 --> 00:02:04.456 A:middle
close to them, and you can see

00:02:04.456 --> 00:02:04.996 A:middle
all the details.

00:02:04.996 --> 00:02:07.756 A:middle
It's just a great way to tell

00:02:07.756 --> 00:02:09.386 A:middle
you story of arts.

00:02:16.316 --> 00:02:18.216 A:middle
ARKit is a fun way to educate

00:02:18.216 --> 00:02:19.326 A:middle
everyone.

00:02:19.976 --> 00:02:21.936 A:middle
Free reverse is an app that

00:02:22.126 --> 00:02:24.246 A:middle
places immersive landscape in

00:02:24.246 --> 00:02:24.726 A:middle
front of you.

00:02:25.586 --> 00:02:27.336 A:middle
You can follow a flow of a river

00:02:27.336 --> 00:02:29.786 A:middle
going through landscape and see

00:02:30.046 --> 00:02:31.276 A:middle
communities and wild life.

00:02:32.146 --> 00:02:34.006 A:middle
You can see how human activity

00:02:35.006 --> 00:02:37.506 A:middle
impacts those communities and

00:02:37.836 --> 00:02:40.056 A:middle
wildlife by constructions.

00:02:42.386 --> 00:02:43.966 A:middle
So it's a great way to educate

00:02:43.966 --> 00:02:45.726 A:middle
everyone about keeping the

00:02:45.726 --> 00:02:48.046 A:middle
environment green and through

00:02:48.046 --> 00:02:48.966 A:middle
sustainable development.

00:02:49.836 --> 00:02:51.016 A:middle
So those were some of the

00:02:51.016 --> 00:02:51.936 A:middle
examples.

00:02:52.246 --> 00:02:54.516 A:middle
Do check a lot more examples

00:02:54.626 --> 00:02:57.546 A:middle
from App Store.

00:02:57.886 --> 00:02:59.926 A:middle
So some of you are new to ARKit,

00:03:00.446 --> 00:03:01.666 A:middle
so let me give you a quick

00:03:02.016 --> 00:03:04.286 A:middle
overview of what ARKit is.

00:03:08.336 --> 00:03:10.376 A:middle
Tracking is the core component

00:03:10.376 --> 00:03:10.806 A:middle
of ARKit.

00:03:11.586 --> 00:03:12.886 A:middle
It gives you position and

00:03:12.886 --> 00:03:14.556 A:middle
orientation of your device in

00:03:14.556 --> 00:03:15.326 A:middle
physical world.

00:03:15.796 --> 00:03:22.216 A:middle
It can also track objects such

00:03:22.216 --> 00:03:23.126 A:middle
as human faces.

00:03:23.796 --> 00:03:29.046 A:middle
Scene understanding enhances

00:03:29.106 --> 00:03:30.066 A:middle
tracking by learning more

00:03:30.066 --> 00:03:31.036 A:middle
attributes about the

00:03:31.036 --> 00:03:31.596 A:middle
environment.

00:03:32.256 --> 00:03:35.666 A:middle
So we can detect horizontal

00:03:35.666 --> 00:03:37.976 A:middle
planes such as ground planes or

00:03:37.976 --> 00:03:39.006 A:middle
tabletops.

00:03:39.736 --> 00:03:41.116 A:middle
We can also detect vertical

00:03:41.116 --> 00:03:41.466 A:middle
planes.

00:03:41.836 --> 00:03:43.646 A:middle
So this lets you place your

00:03:43.646 --> 00:03:45.466 A:middle
virtual objects in the scene.

00:03:51.366 --> 00:03:53.576 A:middle
Scene understanding also learns

00:03:53.806 --> 00:03:56.096 A:middle
about lighting conditions in the

00:03:56.096 --> 00:03:56.636 A:middle
environment.

00:03:57.736 --> 00:04:00.386 A:middle
So you can use lighting to

00:03:57.736 --> 00:04:00.386 A:middle
So you can use lighting to

00:04:00.386 --> 00:04:02.156 A:middle
accurately reflect the real

00:04:02.156 --> 00:04:03.566 A:middle
environment in your virtual

00:04:03.646 --> 00:04:03.906 A:middle
scene.

00:04:04.216 --> 00:04:06.736 A:middle
So your objects don't look too

00:04:06.736 --> 00:04:07.746 A:middle
bright or too dark.

00:04:09.736 --> 00:04:11.276 A:middle
Rendering is what actually a

00:04:11.276 --> 00:04:12.986 A:middle
user sees on the device and

00:04:12.986 --> 00:04:15.076 A:middle
interacts with the augmented

00:04:15.076 --> 00:04:15.986 A:middle
reality scene.

00:04:16.416 --> 00:04:18.926 A:middle
So ARKit makes it very easy for

00:04:18.926 --> 00:04:21.366 A:middle
you to integrate any rendering

00:04:21.366 --> 00:04:22.125 A:middle
engine of your choice.

00:04:25.936 --> 00:04:29.166 A:middle
ARKit offers built-in views for

00:04:29.336 --> 00:04:30.716 A:middle
SceneKit and SpriteKit.

00:04:31.196 --> 00:04:35.106 A:middle
In Xcode, we also have a

00:04:35.106 --> 00:04:36.606 A:middle
Metal template for you to

00:04:36.606 --> 00:04:38.246 A:middle
quickly get started with your

00:04:38.246 --> 00:04:39.666 A:middle
own augmented reality

00:04:41.326 --> 00:04:41.706 A:middle
experience.

00:04:41.706 --> 00:04:43.936 A:middle
Note also that Unity and Unreal

00:04:43.936 --> 00:04:46.116 A:middle
have integrated full feature set

00:04:46.116 --> 00:04:48.016 A:middle
of ARKit into their popular

00:04:48.016 --> 00:04:48.606 A:middle
gaming engines.

00:04:49.006 --> 00:04:51.006 A:middle
So you have all these rendering

00:04:51.006 --> 00:04:53.286 A:middle
technologies available to you to

00:04:53.286 --> 00:04:54.866 A:middle
get started with ARKit.

00:04:58.696 --> 00:05:00.416 A:middle
So let's see, what is new this

00:04:58.696 --> 00:05:00.416 A:middle
So let's see, what is new this

00:05:00.446 --> 00:05:02.316 A:middle
year in ARKit 2.

00:05:07.836 --> 00:05:09.436 A:middle
Okay. So we have saving and

00:05:09.436 --> 00:05:11.566 A:middle
loading maps that enables

00:05:11.566 --> 00:05:13.156 A:middle
powerful new features of

00:05:13.356 --> 00:05:15.426 A:middle
persistence and multiuser

00:05:15.426 --> 00:05:16.206 A:middle
experiences.

00:05:16.796 --> 00:05:21.026 A:middle
We are also giving you

00:05:21.246 --> 00:05:22.906 A:middle
environment texturing so you can

00:05:22.906 --> 00:05:24.246 A:middle
realistically render your

00:05:24.246 --> 00:05:25.526 A:middle
augmented reality scene.

00:05:25.986 --> 00:05:30.376 A:middle
ARKit can now track 2D images in

00:05:30.376 --> 00:05:31.516 A:middle
real-time.

00:05:33.116 --> 00:05:34.836 A:middle
We are not limited to 2D.

00:05:35.076 --> 00:05:37.466 A:middle
We can also detect 3D objects in

00:05:38.046 --> 00:05:41.316 A:middle
a scene.

00:05:41.536 --> 00:05:43.146 A:middle
And last, we have some fun

00:05:43.146 --> 00:05:44.756 A:middle
enhancements for face tracking.

00:05:47.916 --> 00:05:50.136 A:middle
So let's start with saving and

00:05:50.136 --> 00:05:51.696 A:middle
loading maps.

00:05:56.316 --> 00:05:58.616 A:middle
Saving and loading maps is part

00:05:58.616 --> 00:05:59.656 A:middle
of world tracking.

00:06:00.446 --> 00:06:01.576 A:middle
World tracking gives you

00:06:01.576 --> 00:06:03.296 A:middle
position and orientation of your

00:06:03.296 --> 00:06:05.616 A:middle
device as our six degrees of

00:06:05.616 --> 00:06:07.666 A:middle
freedom pose in real world.

00:06:08.156 --> 00:06:11.476 A:middle
This lets you place objects in

00:06:11.476 --> 00:06:14.456 A:middle
the scene such as this table and

00:06:14.456 --> 00:06:16.226 A:middle
chair you can see in this video.

00:06:16.736 --> 00:06:20.066 A:middle
World tracking also gives you

00:06:20.066 --> 00:06:21.906 A:middle
accurate physical scale so you

00:06:21.906 --> 00:06:24.946 A:middle
can place your objects up to the

00:06:24.946 --> 00:06:25.566 A:middle
correct scale.

00:06:26.186 --> 00:06:28.006 A:middle
So your objects don't look too

00:06:28.006 --> 00:06:28.976 A:middle
big or too small.

00:06:34.086 --> 00:06:36.126 A:middle
This can also be used to

00:06:36.126 --> 00:06:38.696 A:middle
implement accurate measurements,

00:06:39.406 --> 00:06:40.666 A:middle
such as the Measure app we saw

00:06:40.666 --> 00:06:41.126 A:middle
yesterday.

00:06:41.696 --> 00:06:46.296 A:middle
World tracking also gives you 3D

00:06:46.296 --> 00:06:48.016 A:middle
feature points so you can, you

00:06:48.096 --> 00:06:50.446 A:middle
can, you know some physical

00:06:50.446 --> 00:06:51.636 A:middle
structure of the environment,

00:06:52.116 --> 00:06:54.076 A:middle
and this can be used to perform

00:06:54.076 --> 00:06:56.486 A:middle
hit testing to place objects in

00:06:56.996 --> 00:07:00.236 A:middle
the scene.

00:06:56.996 --> 00:07:00.236 A:middle
the scene.

00:07:00.446 --> 00:07:02.886 A:middle
In iOS 11.3, we introduced

00:07:02.886 --> 00:07:03.876 A:middle
relocalization.

00:07:04.776 --> 00:07:07.226 A:middle
This feature lets you restore

00:07:07.226 --> 00:07:08.816 A:middle
your tracking state after AR

00:07:09.526 --> 00:07:11.436 A:middle
session was interrupted.

00:07:11.946 --> 00:07:13.806 A:middle
So this could happen, for

00:07:13.806 --> 00:07:14.766 A:middle
example, your app is

00:07:14.866 --> 00:07:17.186 A:middle
backgrounded or you're using

00:07:17.236 --> 00:07:23.886 A:middle
picture in picture mode on iPad.

00:07:24.086 --> 00:07:29.326 A:middle
So relocalization works with a

00:07:29.326 --> 00:07:32.086 A:middle
map that is continuously built

00:07:32.086 --> 00:07:32.966 A:middle
by world tracking.

00:07:34.066 --> 00:07:35.966 A:middle
So the more we move around the

00:07:35.966 --> 00:07:39.566 A:middle
environment, the more it is able

00:07:39.566 --> 00:07:41.116 A:middle
to extend and learn about

00:07:41.286 --> 00:07:42.126 A:middle
different features of the

00:07:42.126 --> 00:07:43.216 A:middle
environment.

00:07:48.186 --> 00:07:51.536 A:middle
So this map was only available

00:07:51.656 --> 00:07:53.336 A:middle
as long as your AR session was

00:07:53.336 --> 00:07:56.306 A:middle
alive, but not we are giving

00:07:56.306 --> 00:08:00.026 A:middle
this map available to you.

00:07:56.306 --> 00:08:00.026 A:middle
this map available to you.

00:08:00.256 --> 00:08:03.066 A:middle
In ARKit API, this map is given

00:08:03.066 --> 00:08:05.396 A:middle
to you as ARWorldMap object.

00:08:14.426 --> 00:08:16.406 A:middle
ARWorldMap represents mapping of

00:08:16.446 --> 00:08:19.346 A:middle
physical 3D space, similar to

00:08:19.346 --> 00:08:22.036 A:middle
what we see in this, on the

00:08:22.036 --> 00:08:25.676 A:middle
visual, on the right.

00:08:25.886 --> 00:08:27.436 A:middle
We also know that anchors are

00:08:27.436 --> 00:08:29.046 A:middle
important points in physical

00:08:29.076 --> 00:08:29.376 A:middle
space.

00:08:30.066 --> 00:08:31.286 A:middle
So these are the places where

00:08:31.286 --> 00:08:33.306 A:middle
you want to place your virtual

00:08:33.306 --> 00:08:33.666 A:middle
objects.

00:08:34.576 --> 00:08:36.535 A:middle
So we have also included plain

00:08:36.535 --> 00:08:38.566 A:middle
anchors by default in

00:08:38.566 --> 00:08:39.746 A:middle
ARWorldMap.

00:08:40.716 --> 00:08:42.895 A:middle
Moreover, you can also add your

00:08:42.895 --> 00:08:44.646 A:middle
custom anchors to this list

00:08:45.276 --> 00:08:46.546 A:middle
since it is mutable list.

00:08:46.546 --> 00:08:48.866 A:middle
So you can create your custom

00:08:48.866 --> 00:08:50.016 A:middle
anchors in the scene and add

00:08:50.016 --> 00:08:51.726 A:middle
them to World Map.

00:08:57.546 --> 00:08:59.236 A:middle
For your visualization and

00:08:59.236 --> 00:09:01.776 A:middle
debugging, World Map also give

00:08:59.236 --> 00:09:01.776 A:middle
debugging, World Map also give

00:09:01.776 --> 00:09:03.596 A:middle
you raw feature points and

00:09:03.596 --> 00:09:06.116 A:middle
extend, so you know the real

00:09:06.216 --> 00:09:12.856 A:middle
physical space you just scanned.

00:09:12.856 --> 00:09:15.636 A:middle
More importantly, World Map is a

00:09:15.636 --> 00:09:18.056 A:middle
serializable object, so it can

00:09:18.056 --> 00:09:20.356 A:middle
be serialized to any data stream

00:09:20.356 --> 00:09:22.546 A:middle
of your choice, such as file on

00:09:22.546 --> 00:09:25.756 A:middle
local system or to a shared

00:09:25.806 --> 00:09:27.126 A:middle
network place.

00:09:28.336 --> 00:09:33.636 A:middle
So this ARWorldMap object enable

00:09:33.636 --> 00:09:34.976 A:middle
two powerful set of new

00:09:34.976 --> 00:09:37.116 A:middle
experiences in ARKit.

00:09:37.116 --> 00:09:41.376 A:middle
The first is persistence.

00:09:44.076 --> 00:09:46.526 A:middle
So just to show you an example

00:09:46.526 --> 00:09:49.816 A:middle
how it works, we have a user

00:09:49.816 --> 00:09:52.376 A:middle
starting world tracking, and he

00:09:52.426 --> 00:09:53.956 A:middle
places an object in the scene

00:09:54.626 --> 00:09:56.126 A:middle
through ARKit hit testing.

00:09:56.646 --> 00:10:00.956 A:middle
And before leaves the scene, he

00:09:56.646 --> 00:10:00.956 A:middle
And before leaves the scene, he

00:10:00.956 --> 00:10:03.896 A:middle
will save World Map on the

00:10:04.436 --> 00:10:04.686 A:middle
device.

00:10:09.046 --> 00:10:12.066 A:middle
So some point, sometime later,

00:10:12.066 --> 00:10:15.866 A:middle
the user comes back, and he is

00:10:15.866 --> 00:10:17.846 A:middle
able to load the same World Map,

00:10:17.846 --> 00:10:20.686 A:middle
and he will find the same

00:10:20.726 --> 00:10:22.086 A:middle
augmented reality experience.

00:10:22.696 --> 00:10:24.616 A:middle
So he can repeat this experience

00:10:24.616 --> 00:10:26.946 A:middle
as many times he wants, and he

00:10:27.026 --> 00:10:28.546 A:middle
will find these objects on the

00:10:28.586 --> 00:10:30.386 A:middle
table every time he will start

00:10:30.386 --> 00:10:31.006 A:middle
his experience.

00:10:31.566 --> 00:10:34.376 A:middle
So this is persistence in world

00:10:34.376 --> 00:10:34.716 A:middle
tracking

00:10:36.016 --> 00:10:37.626 A:middle
[applause].

00:10:37.626 --> 00:10:37.956 A:middle
Thank you.

00:10:38.508 --> 00:10:40.508 A:middle
[applause]

00:10:44.346 --> 00:10:45.946 A:middle
ARWorldMap also enables

00:10:45.946 --> 00:10:47.506 A:middle
multiuser experiences.

00:10:49.336 --> 00:10:51.016 A:middle
Now your augmented reality

00:10:51.016 --> 00:10:52.236 A:middle
experience is not limited to a

00:10:52.306 --> 00:10:53.616 A:middle
single device or single user.

00:10:54.936 --> 00:10:56.956 A:middle
It can be shared with many

00:10:56.956 --> 00:10:57.426 A:middle
users.

00:10:59.996 --> 00:11:03.766 A:middle
One user can create World Map

00:10:59.996 --> 00:11:03.766 A:middle
One user can create World Map

00:11:03.826 --> 00:11:05.986 A:middle
and share with one or more

00:11:06.186 --> 00:11:06.716 A:middle
users.

00:11:07.226 --> 00:11:10.866 A:middle
Note that World Map represents a

00:11:10.916 --> 00:11:13.876 A:middle
single coordinate system in real

00:11:13.876 --> 00:11:14.176 A:middle
world.

00:11:15.126 --> 00:11:17.226 A:middle
So what it means that every user

00:11:17.606 --> 00:11:18.946 A:middle
will share the same working

00:11:19.006 --> 00:11:19.356 A:middle
space.

00:11:20.426 --> 00:11:22.326 A:middle
They are able to experience the

00:11:22.396 --> 00:11:23.506 A:middle
same augmented reality

00:11:23.506 --> 00:11:25.416 A:middle
experience from different point

00:11:25.936 --> 00:11:27.436 A:middle
of view.

00:11:27.676 --> 00:11:29.106 A:middle
So this is a great new feature.

00:11:29.716 --> 00:11:33.346 A:middle
You can use World Map to enable

00:11:33.346 --> 00:11:36.476 A:middle
multiuser games, such as the one

00:11:36.476 --> 00:11:37.406 A:middle
we saw yesterday.

00:11:37.976 --> 00:11:42.756 A:middle
We can also use ARWorldMap to

00:11:42.756 --> 00:11:44.426 A:middle
create multiuser shared

00:11:44.426 --> 00:11:45.626 A:middle
educational experiences.

00:11:49.856 --> 00:11:51.536 A:middle
Note that we are giving

00:11:51.536 --> 00:11:53.366 A:middle
ARWorldMap object in your hands,

00:11:53.906 --> 00:11:55.856 A:middle
so you are free to choose any

00:11:56.636 --> 00:12:00.076 A:middle
technology to share with every

00:11:56.636 --> 00:12:00.076 A:middle
technology to share with every

00:12:00.076 --> 00:12:00.436 A:middle
user.

00:12:02.156 --> 00:12:04.336 A:middle
For example, for sharing you can

00:12:04.406 --> 00:12:06.706 A:middle
use air drop or multipeer

00:12:06.706 --> 00:12:08.336 A:middle
connectivity that relies on

00:12:08.336 --> 00:12:10.136 A:middle
local Bluetooth or WiFi

00:12:10.136 --> 00:12:10.636 A:middle
connection.

00:12:10.636 --> 00:12:13.186 A:middle
So it means that you don't

00:12:13.186 --> 00:12:14.296 A:middle
really need an internet

00:12:14.296 --> 00:12:16.226 A:middle
connection for this feature to

00:12:16.746 --> 00:12:16.846 A:middle
work.

00:12:22.416 --> 00:12:24.226 A:middle
:15 So let's see how ARKit API

00:12:24.226 --> 00:12:25.856 A:middle
makes it very easy for you to

00:12:26.406 --> 00:12:28.606 A:middle
retrieve and load World Map.

00:12:30.736 --> 00:12:33.516 A:middle
On your AR session object, you

00:12:33.516 --> 00:12:35.576 A:middle
will need to call get current

00:12:35.576 --> 00:12:39.666 A:middle
world map at any point in time.

00:12:39.836 --> 00:12:41.146 A:middle
This method comes with a

00:12:41.146 --> 00:12:43.846 A:middle
completion handler in which it

00:12:43.846 --> 00:12:46.586 A:middle
will return you and ARWorldMap

00:12:48.446 --> 00:12:48.656 A:middle
object.

00:12:49.006 --> 00:12:50.676 A:middle
Note also that it can also

00:12:50.676 --> 00:12:52.746 A:middle
return and other in case World

00:12:52.746 --> 00:12:53.846 A:middle
Map is not available.

00:12:54.186 --> 00:12:55.676 A:middle
So it's important to handle this

00:12:55.676 --> 00:12:57.486 A:middle
error in your application code.

00:12:59.116 --> 00:13:03.146 A:middle
So once you have ARWorldMap, you

00:12:59.116 --> 00:13:03.146 A:middle
So once you have ARWorldMap, you

00:13:03.146 --> 00:13:08.946 A:middle
can simply set initial World Map

00:13:08.946 --> 00:13:10.686 A:middle
property in world tracking

00:13:10.686 --> 00:13:13.596 A:middle
configuration and run your

00:13:13.596 --> 00:13:13.966 A:middle
session.

00:13:14.566 --> 00:13:17.356 A:middle
Note that this can be

00:13:17.356 --> 00:13:18.976 A:middle
dynamically changed as well, so

00:13:18.976 --> 00:13:20.646 A:middle
you can also reconfigure AR

00:13:20.986 --> 00:13:22.466 A:middle
session by running a new

00:13:22.466 --> 00:13:23.046 A:middle
configuration.

00:13:23.626 --> 00:13:27.606 A:middle
So once AR session is started

00:13:27.696 --> 00:13:31.266 A:middle
with ARWorldMap, it will follow

00:13:31.266 --> 00:13:33.086 A:middle
the exact same behavior of

00:13:33.086 --> 00:13:34.526 A:middle
relocalization that we

00:13:34.526 --> 00:13:36.976 A:middle
introduced in iOS 11.3.

00:13:44.086 --> 00:13:46.276 A:middle
It is important for your

00:13:46.906 --> 00:13:49.946 A:middle
experience that relocalization

00:13:49.946 --> 00:13:50.836 A:middle
works reliably.

00:13:50.836 --> 00:13:54.076 A:middle
So it is good to, it is

00:13:54.076 --> 00:13:55.296 A:middle
important to acquire good World

00:13:55.296 --> 00:13:55.626 A:middle
Maps.

00:13:56.406 --> 00:13:57.996 A:middle
Note that you can call get a

00:13:57.996 --> 00:13:59.906 A:middle
current world map at any point

00:14:00.646 --> 00:14:02.526 A:middle
in time.

00:14:02.526 --> 00:14:04.976 A:middle
So, it's important to scan your

00:14:04.976 --> 00:14:07.626 A:middle
physical space from multiple

00:14:07.666 --> 00:14:09.226 A:middle
point of views.

00:14:09.256 --> 00:14:11.266 A:middle
So tracking system can really

00:14:11.266 --> 00:14:12.516 A:middle
learn about physical structure

00:14:12.516 --> 00:14:13.316 A:middle
of the environment.

00:14:14.956 --> 00:14:17.996 A:middle
The environment should be static

00:14:17.996 --> 00:14:19.976 A:middle
and well textured so we can

00:14:19.976 --> 00:14:22.326 A:middle
learn, extract more features of

00:14:22.326 --> 00:14:23.936 A:middle
it and learn more about the

00:14:23.936 --> 00:14:24.376 A:middle
environment.

00:14:27.596 --> 00:14:30.116 A:middle
And also, it's important to have

00:14:30.116 --> 00:14:31.986 A:middle
dense feature points on the map,

00:14:32.296 --> 00:14:34.936 A:middle
so it can reliably relocalize.

00:14:37.076 --> 00:14:38.716 A:middle
But you don't have to worry

00:14:38.716 --> 00:14:40.256 A:middle
about all those points.

00:14:41.676 --> 00:14:43.916 A:middle
In ARKit, API really makes

00:14:43.976 --> 00:14:46.076 A:middle
things easier for you by giving

00:14:46.076 --> 00:14:47.776 A:middle
you WorldMappingStatus on

00:14:47.776 --> 00:14:48.186 A:middle
ARFrame.

00:14:49.366 --> 00:14:51.516 A:middle
WorldMappingStatus is updated in

00:14:51.516 --> 00:14:53.856 A:middle
every ARFrame and can be

00:14:53.856 --> 00:14:55.776 A:middle
retrieved by WorldMappingStatus

00:14:55.956 --> 00:14:56.376 A:middle
property.

00:14:56.896 --> 00:14:58.456 A:middle
So let's see how this works.

00:14:59.106 --> 00:15:02.866 A:middle
So when we start world tracking,

00:14:59.106 --> 00:15:02.866 A:middle
So when we start world tracking,

00:15:02.866 --> 00:15:04.186 A:middle
WorldMappingStatus will be not

00:15:04.186 --> 00:15:04.666 A:middle
available.

00:15:05.056 --> 00:15:06.936 A:middle
As soon as we start scanning the

00:15:06.936 --> 00:15:08.156 A:middle
physical space, it will be

00:15:08.266 --> 00:15:08.786 A:middle
limited.

00:15:10.356 --> 00:15:12.786 A:middle
The more we move in the physical

00:15:12.786 --> 00:15:14.526 A:middle
world, world tracking will

00:15:14.526 --> 00:15:19.406 A:middle
continue to extend the map.

00:15:19.546 --> 00:15:21.196 A:middle
And if we have scanned enough

00:15:21.336 --> 00:15:23.656 A:middle
physical world from current

00:15:23.656 --> 00:15:24.206 A:middle
point of view,

00:15:24.366 --> 00:15:25.586 A:middle
WorldMappingStatus will be

00:15:25.756 --> 00:15:26.096 A:middle
mapped.

00:15:34.236 --> 00:15:36.486 A:middle
So note that if you point away

00:15:36.486 --> 00:15:39.356 A:middle
from a map physical space,

00:15:39.926 --> 00:15:41.766 A:middle
WorldMappingStatus may go back

00:15:41.766 --> 00:15:42.526 A:middle
to limited.

00:15:43.126 --> 00:15:44.756 A:middle
So it will start to learn more

00:15:44.756 --> 00:15:46.996 A:middle
about the new environment that

00:15:46.996 --> 00:15:51.076 A:middle
we are starting to see.

00:15:51.306 --> 00:15:52.196 A:middle
So how you can use

00:15:52.196 --> 00:15:53.386 A:middle
WorldMappingStatus in your

00:15:53.386 --> 00:15:54.096 A:middle
application code.

00:15:54.586 --> 00:15:58.076 A:middle
Let's say you have an app that

00:15:58.076 --> 00:15:59.806 A:middle
lets you share your World Map

00:15:59.876 --> 00:16:02.346 A:middle
with another user, and you have

00:15:59.876 --> 00:16:02.346 A:middle
with another user, and you have

00:16:02.346 --> 00:16:04.906 A:middle
a shared map button on your user

00:16:04.906 --> 00:16:05.356 A:middle
interface.

00:16:05.896 --> 00:16:09.096 A:middle
It's a good practice to disable

00:16:09.096 --> 00:16:10.046 A:middle
this button when

00:16:10.046 --> 00:16:11.146 A:middle
WorldMappingStatus is not

00:16:11.146 --> 00:16:12.576 A:middle
available or limited.

00:16:13.096 --> 00:16:16.166 A:middle
And when WorldMappingStatus is

00:16:16.196 --> 00:16:19.386 A:middle
extending, you may want to show

00:16:19.386 --> 00:16:21.446 A:middle
an activity indicator on UI.

00:16:22.046 --> 00:16:23.936 A:middle
So this encourages your end user

00:16:24.426 --> 00:16:25.786 A:middle
to continue moving in the

00:16:25.786 --> 00:16:27.476 A:middle
physical world and continue

00:16:27.546 --> 00:16:29.526 A:middle
scanning it and extending the

00:16:29.526 --> 00:16:31.446 A:middle
map, because you need that for

00:16:31.446 --> 00:16:32.146 A:middle
relocalization.

00:16:36.256 --> 00:16:38.416 A:middle
Once WorldMappingStatus is fully

00:16:38.446 --> 00:16:42.476 A:middle
mapped, you may enable your

00:16:42.476 --> 00:16:44.346 A:middle
share map button and hide your

00:16:44.466 --> 00:16:45.366 A:middle
activity indicator.

00:16:46.096 --> 00:16:47.886 A:middle
So this will let your user to

00:16:47.886 --> 00:16:49.046 A:middle
share the map.

00:16:53.716 --> 00:16:55.676 A:middle
So let's see a demo of saving

00:16:55.676 --> 00:16:57.146 A:middle
and loading World Map.

00:16:58.516 --> 00:17:06.546 A:middle
[ Applause ]

00:16:58.516 --> 00:17:06.546 A:middle
[ Applause ]

00:17:07.046 --> 00:17:11.036 A:middle
Okay. So can we switch to AR 1.

00:17:13.306 --> 00:17:15.976 A:middle
Okay. So for this demo, I have

00:17:16.116 --> 00:17:16.955 A:middle
two apps.

00:17:17.665 --> 00:17:20.586 A:middle
In one app I will retrieve and

00:17:20.616 --> 00:17:22.576 A:middle
save World Map to a local file,

00:17:23.366 --> 00:17:26.046 A:middle
and in my second app, I will

00:17:26.046 --> 00:17:28.406 A:middle
load the same World Map to

00:17:28.406 --> 00:17:30.096 A:middle
restore the same augmented

00:17:30.096 --> 00:17:31.146 A:middle
reality experience.

00:17:31.626 --> 00:17:32.266 A:middle
So let's start.

00:17:32.266 --> 00:17:36.896 A:middle
So as you can see,

00:17:36.896 --> 00:17:38.886 A:middle
WorldMappingStatus on top right

00:17:38.886 --> 00:17:39.376 A:middle
corner.

00:17:39.876 --> 00:17:41.466 A:middle
It was not available.

00:17:41.826 --> 00:17:43.476 A:middle
As soon as I start to move in

00:17:43.476 --> 00:17:46.416 A:middle
the environment, it is now

00:17:46.416 --> 00:17:47.846 A:middle
extending my World Map.

00:17:47.846 --> 00:17:50.666 A:middle
So if I continue to map and move

00:17:50.666 --> 00:17:53.476 A:middle
in this environment, the

00:17:53.476 --> 00:17:55.336 A:middle
WorldMappingStatus will go

00:17:55.336 --> 00:17:56.016 A:middle
mapped.

00:17:57.206 --> 00:17:58.956 A:middle
So it means that it has seen

00:17:58.956 --> 00:18:01.356 A:middle
enough features from this point

00:17:58.956 --> 00:18:01.356 A:middle
enough features from this point

00:18:01.356 --> 00:18:03.216 A:middle
of view for relocalization to

00:18:03.216 --> 00:18:03.446 A:middle
work.

00:18:03.876 --> 00:18:06.406 A:middle
So it is a good time to retrieve

00:18:06.486 --> 00:18:08.326 A:middle
and serialize World Map object.

00:18:09.956 --> 00:18:12.546 A:middle
But let's make this augmented

00:18:12.546 --> 00:18:14.576 A:middle
reality scene more interesting

00:18:14.636 --> 00:18:16.116 A:middle
by placing a custom anchor.

00:18:17.176 --> 00:18:19.466 A:middle
So through hit testing, I have

00:18:19.466 --> 00:18:21.816 A:middle
created a custom anchor, and I

00:18:21.816 --> 00:18:23.926 A:middle
am overlaying this object,

00:18:23.926 --> 00:18:27.266 A:middle
basically it's a old TV.

00:18:27.936 --> 00:18:29.116 A:middle
I think most of you may have

00:18:29.166 --> 00:18:30.586 A:middle
seen in the past.

00:18:33.136 --> 00:18:34.806 A:middle
So of course I can still

00:18:34.806 --> 00:18:38.156 A:middle
continue mapping the world, and

00:18:38.156 --> 00:18:40.276 A:middle
let's save the World Map.

00:18:41.426 --> 00:18:44.246 A:middle
So when I saved my World Map, I

00:18:44.246 --> 00:18:45.916 A:middle
could also show raw feature

00:18:45.916 --> 00:18:47.136 A:middle
points that belongs to this

00:18:47.136 --> 00:18:47.586 A:middle
World Map.

00:18:47.866 --> 00:18:49.416 A:middle
So those blue dots that you see,

00:18:49.756 --> 00:18:52.126 A:middle
they are all part of my World

00:18:52.736 --> 00:18:52.866 A:middle
Map.

00:18:55.236 --> 00:18:58.926 A:middle
And also as a good practice, I

00:18:58.926 --> 00:19:02.036 A:middle
saved a screen shot of my point

00:18:58.926 --> 00:19:02.036 A:middle
saved a screen shot of my point

00:19:02.036 --> 00:19:04.346 A:middle
of view where I saved World Map.

00:19:07.096 --> 00:19:09.696 A:middle
So now we have serialized World

00:19:09.696 --> 00:19:11.276 A:middle
Map to our file.

00:19:12.216 --> 00:19:13.986 A:middle
We can now restore the same

00:19:13.986 --> 00:19:15.636 A:middle
augmented reality experience in

00:19:15.696 --> 00:19:16.226 A:middle
another app.

00:19:17.096 --> 00:19:18.096 A:middle
So let's try that.

00:19:18.836 --> 00:19:20.126 A:middle
I will start this app from a

00:19:20.126 --> 00:19:24.516 A:middle
different position, and you can

00:19:24.516 --> 00:19:26.806 A:middle
see this is my world origin.

00:19:26.806 --> 00:19:28.526 A:middle
It is defined on this side of

00:19:28.526 --> 00:19:30.606 A:middle
the table, and my world tracking

00:19:30.606 --> 00:19:32.506 A:middle
is now in relocalizing state.

00:19:33.216 --> 00:19:34.526 A:middle
So this is the same opening

00:19:34.526 --> 00:19:36.366 A:middle
relocalization behavior that we

00:19:36.426 --> 00:19:40.296 A:middle
introduced in iOS 11.3.

00:19:40.296 --> 00:19:44.366 A:middle
So let me point my device to the

00:19:44.446 --> 00:19:46.496 A:middle
physical place where I created

00:19:46.496 --> 00:19:47.526 A:middle
World Map.

00:19:48.416 --> 00:19:50.706 A:middle
So as soon as I point to that

00:19:50.776 --> 00:19:53.126 A:middle
same space, it restored my world

00:19:53.126 --> 00:19:57.016 A:middle
origin back to where it was, and

00:19:57.016 --> 00:19:59.306 A:middle
at the same time it also

00:19:59.306 --> 00:20:00.636 A:middle
restored my custom anchor.

00:19:59.306 --> 00:20:00.636 A:middle
restored my custom anchor.

00:20:00.986 --> 00:20:02.596 A:middle
So I have the exact same AR

00:20:02.596 --> 00:20:03.026 A:middle
experience.

00:20:04.016 --> 00:20:08.916 A:middle
[ Applause ]

00:20:09.416 --> 00:20:09.916 A:middle
Thank you.

00:20:11.586 --> 00:20:13.176 A:middle
So now note that I can start

00:20:13.176 --> 00:20:15.276 A:middle
this app as many times I want,

00:20:15.776 --> 00:20:17.456 A:middle
and it will show me the same

00:20:17.456 --> 00:20:18.936 A:middle
experience every time I start.

00:20:19.556 --> 00:20:20.696 A:middle
So this is persistence.

00:20:21.306 --> 00:20:23.566 A:middle
And of course, this can be

00:20:23.566 --> 00:20:25.146 A:middle
shared with another device.

00:20:25.826 --> 00:20:28.756 A:middle
So back to slides.

00:20:34.196 --> 00:20:36.616 A:middle
So this was saving and loading

00:20:36.746 --> 00:20:37.046 A:middle
map.

00:20:38.036 --> 00:20:39.726 A:middle
It's a powerful new feature in

00:20:39.726 --> 00:20:43.006 A:middle
ARKit 2 that enables persistence

00:20:43.516 --> 00:20:44.766 A:middle
and multiuser shared

00:20:44.766 --> 00:20:45.856 A:middle
experiences.

00:20:49.766 --> 00:20:51.426 A:middle
In ARKit 2, we have faster

00:20:51.426 --> 00:20:53.326 A:middle
initialization and plane

00:20:53.326 --> 00:20:53.806 A:middle
detection.

00:20:54.296 --> 00:20:58.226 A:middle
World tracking is now more

00:20:58.226 --> 00:21:00.536 A:middle
robust, and we can detect planes

00:20:58.226 --> 00:21:00.536 A:middle
robust, and we can detect planes

00:21:00.656 --> 00:21:02.276 A:middle
in more difficult environments.

00:21:07.396 --> 00:21:09.286 A:middle
Both horizontal and vertical

00:21:09.286 --> 00:21:11.506 A:middle
planes have more accurate extent

00:21:11.506 --> 00:21:13.416 A:middle
and boundaries, so it means that

00:21:13.416 --> 00:21:14.816 A:middle
you can accurately place your

00:21:14.816 --> 00:21:15.846 A:middle
objects in the scene.

00:21:19.916 --> 00:21:22.576 A:middle
In iOS 11.3, we introduced

00:21:22.776 --> 00:21:25.436 A:middle
continuous autofocus for your

00:21:25.436 --> 00:21:26.866 A:middle
augmented reality experiences.

00:21:27.346 --> 00:21:31.326 A:middle
IOS 12 comes with even more

00:21:31.326 --> 00:21:33.816 A:middle
optimizations specifically for

00:21:33.816 --> 00:21:35.146 A:middle
augmented reality experiences.

00:21:38.816 --> 00:21:41.466 A:middle
We are also introducing 4 by 3

00:21:41.466 --> 00:21:44.176 A:middle
video formats in ARKit.

00:21:44.606 --> 00:21:49.346 A:middle
Four by three is a -angle video

00:21:49.346 --> 00:21:51.896 A:middle
format that greatly enhances

00:21:51.896 --> 00:21:54.766 A:middle
your visualization on iPad

00:21:54.766 --> 00:21:56.496 A:middle
because iPad also have 4 by 3

00:21:56.626 --> 00:21:57.826 A:middle
display aspect ratios.

00:21:58.346 --> 00:22:01.676 A:middle
Note that 4 by 3 video format

00:21:58.346 --> 00:22:01.676 A:middle
Note that 4 by 3 video format

00:22:01.676 --> 00:22:03.606 A:middle
will be the default video format

00:22:03.606 --> 00:22:06.556 A:middle
in ARKit 2.

00:22:06.816 --> 00:22:08.326 A:middle
So all of these enhancements,

00:22:08.966 --> 00:22:10.896 A:middle
they will be applied to all

00:22:10.896 --> 00:22:12.486 A:middle
existing apps in the App Store

00:22:13.176 --> 00:22:15.406 A:middle
except 4 by 3 video format.

00:22:15.536 --> 00:22:18.176 A:middle
For that, you will have to build

00:22:18.176 --> 00:22:20.086 A:middle
your app with the new STK.

00:22:21.776 --> 00:22:26.506 A:middle
So coming back to improving

00:22:26.506 --> 00:22:30.636 A:middle
end-user experience, we are

00:22:30.876 --> 00:22:32.316 A:middle
introducing environment

00:22:32.316 --> 00:22:32.806 A:middle
texturing.

00:22:33.876 --> 00:22:36.116 A:middle
So this greatly enhances your

00:22:36.116 --> 00:22:38.176 A:middle
rendering for end-user

00:22:38.176 --> 00:22:38.876 A:middle
experiences.

00:22:40.976 --> 00:22:43.826 A:middle
So let's say your designer have

00:22:44.016 --> 00:22:45.496 A:middle
worked really hard to create

00:22:45.496 --> 00:22:47.486 A:middle
these virtual objects for you,

00:22:47.776 --> 00:22:49.156 A:middle
for your augmented reality

00:22:49.696 --> 00:22:49.786 A:middle
scene.

00:22:50.616 --> 00:22:53.466 A:middle
This looks really great, but you

00:22:53.466 --> 00:22:56.226 A:middle
need to do more for your

00:22:56.226 --> 00:22:57.316 A:middle
augmented reality scene.

00:22:57.316 --> 00:23:03.046 A:middle
You need to have position and

00:22:57.316 --> 00:23:03.046 A:middle
You need to have position and

00:23:03.046 --> 00:23:05.026 A:middle
orientation correct in your AR

00:23:05.436 --> 00:23:08.376 A:middle
scene so that object really

00:23:08.376 --> 00:23:10.716 A:middle
looks like it is placed in the

00:23:10.716 --> 00:23:11.746 A:middle
real world.

00:23:13.366 --> 00:23:15.256 A:middle
It is also important to get the

00:23:15.256 --> 00:23:17.106 A:middle
scale right so your object is

00:23:17.106 --> 00:23:18.666 A:middle
not too big or not too small.

00:23:19.176 --> 00:23:21.236 A:middle
So ARKit helps you by giving you

00:23:21.236 --> 00:23:22.876 A:middle
the correct transform in world

00:23:23.106 --> 00:23:24.606 A:middle
tracking.

00:23:28.456 --> 00:23:30.386 A:middle
For realistic rendering, it is

00:23:30.386 --> 00:23:31.886 A:middle
important to also consider

00:23:32.346 --> 00:23:33.496 A:middle
lighting in the environment.

00:23:33.916 --> 00:23:38.836 A:middle
ARKit gives you ambient light

00:23:38.836 --> 00:23:40.296 A:middle
estimator that you can use in

00:23:40.296 --> 00:23:43.576 A:middle
your rendering to correct the

00:23:43.576 --> 00:23:45.066 A:middle
brightness of your objects.

00:23:45.436 --> 00:23:47.136 A:middle
So your objects don't look too

00:23:47.136 --> 00:23:48.776 A:middle
bright or too dark.

00:23:49.386 --> 00:23:51.746 A:middle
They just blend into the

00:23:54.676 --> 00:23:55.056 A:middle
environment.

00:23:55.056 --> 00:23:56.966 A:middle
If you are placing your objects

00:23:56.966 --> 00:23:58.716 A:middle
on physical surfaces such as

00:23:58.716 --> 00:24:01.076 A:middle
horizontal planes, it is also

00:23:58.716 --> 00:24:01.076 A:middle
horizontal planes, it is also

00:24:01.076 --> 00:24:03.416 A:middle
important to add a shadow for

00:24:03.416 --> 00:24:03.866 A:middle
the object.

00:24:04.506 --> 00:24:06.916 A:middle
So this greatly improves human

00:24:06.916 --> 00:24:07.776 A:middle
visual perception.

00:24:08.036 --> 00:24:09.106 A:middle
They can really perceive that

00:24:09.106 --> 00:24:13.256 A:middle
objection is on the surface.

00:24:13.426 --> 00:24:16.876 A:middle
And last, in case of reflective

00:24:16.876 --> 00:24:20.156 A:middle
objects, humans wants to see

00:24:20.916 --> 00:24:22.576 A:middle
reflection of the environment

00:24:22.716 --> 00:24:24.376 A:middle
from the surface of the virtual

00:24:24.376 --> 00:24:24.696 A:middle
objects.

00:24:25.886 --> 00:24:28.166 A:middle
So this is what environment

00:24:28.166 --> 00:24:28.946 A:middle
texturing enables.

00:24:29.006 --> 00:24:32.496 A:middle
So let's see how this object

00:24:32.496 --> 00:24:34.866 A:middle
looks like in an augmented

00:24:34.866 --> 00:24:37.976 A:middle
reality scene.

00:24:38.196 --> 00:24:39.426 A:middle
So I created this scene

00:24:39.426 --> 00:24:41.076 A:middle
yesterday evening when I was

00:24:41.156 --> 00:24:42.696 A:middle
preparing for this presentation.

00:24:43.246 --> 00:24:47.186 A:middle
So while eating those fruits, I

00:24:47.186 --> 00:24:48.346 A:middle
also wanted to place this

00:24:48.346 --> 00:24:49.606 A:middle
virtual object.

00:24:49.606 --> 00:24:54.886 A:middle
And you can see, it is correct

00:24:54.996 --> 00:24:57.486 A:middle
to scale, and you can see more

00:24:57.486 --> 00:24:59.356 A:middle
importantly you can see a

00:24:59.356 --> 00:25:00.956 A:middle
reflection of the environment in

00:24:59.356 --> 00:25:00.956 A:middle
reflection of the environment in

00:25:01.476 --> 00:25:02.336 A:middle
the object.

00:25:02.496 --> 00:25:04.326 A:middle
On your right side of this

00:25:04.326 --> 00:25:06.766 A:middle
object, you can see this yellow

00:25:06.766 --> 00:25:09.376 A:middle
and orange reflection of those

00:25:09.376 --> 00:25:11.386 A:middle
fruits on the right, and on the

00:25:11.386 --> 00:25:13.646 A:middle
left, you can notice the green

00:25:13.646 --> 00:25:14.596 A:middle
texture from the leaves.

00:25:15.906 --> 00:25:17.196 A:middle
And in the middle, you can also

00:25:17.196 --> 00:25:19.336 A:middle
see reflection of the surface of

00:25:20.136 --> 00:25:21.386 A:middle
the bench.

00:25:21.616 --> 00:25:23.286 A:middle
So this is enabled by

00:25:23.286 --> 00:25:25.366 A:middle
environment texturing in ARKit

00:25:25.906 --> 00:25:25.976 A:middle
2.

00:25:29.336 --> 00:25:29.606 A:middle
Thank you.

00:25:30.476 --> 00:25:33.636 A:middle
[ Applause ]

00:25:34.136 --> 00:25:35.826 A:middle
So environment texturing gathers

00:25:35.906 --> 00:25:37.456 A:middle
scene texture information.

00:25:40.616 --> 00:25:43.176 A:middle
Usually it is represented as a

00:25:43.176 --> 00:25:44.666 A:middle
cube map, but there are other

00:25:44.666 --> 00:25:48.956 A:middle
representations as well.

00:25:49.036 --> 00:25:51.426 A:middle
Environment texture or this cube

00:25:51.426 --> 00:25:53.746 A:middle
map can be used as a reflection

00:25:53.746 --> 00:25:56.146 A:middle
probe in your rendering engines.

00:25:58.636 --> 00:26:01.696 A:middle
This reflection probe can apply

00:25:58.636 --> 00:26:01.696 A:middle
This reflection probe can apply

00:26:01.696 --> 00:26:03.646 A:middle
this as texture information onto

00:26:03.646 --> 00:26:05.426 A:middle
virtual objects, such as the one

00:26:05.426 --> 00:26:06.476 A:middle
we saw in the last slide.

00:26:07.286 --> 00:26:10.146 A:middle
So it greatly improves

00:26:11.326 --> 00:26:13.156 A:middle
visualization of reflective

00:26:13.156 --> 00:26:13.626 A:middle
objects.

00:26:14.936 --> 00:26:16.996 A:middle
So let's see how this works in

00:26:18.136 --> 00:26:20.026 A:middle
this short video clip.

00:26:22.076 --> 00:26:24.796 A:middle
So ARKit, while running world

00:26:24.796 --> 00:26:25.816 A:middle
tracking and scene

00:26:25.816 --> 00:26:27.596 A:middle
understanding, continues to

00:26:27.596 --> 00:26:28.506 A:middle
learn more about the

00:26:28.506 --> 00:26:29.036 A:middle
environment.

00:26:30.226 --> 00:26:32.706 A:middle
Using computer vision, it can

00:26:33.066 --> 00:26:35.676 A:middle
extract textured information and

00:26:35.676 --> 00:26:37.646 A:middle
start to fill this cube map.

00:26:38.136 --> 00:26:41.676 A:middle
And this cube map is accurately

00:26:41.676 --> 00:26:42.636 A:middle
placed in the scene.

00:26:43.166 --> 00:26:46.456 A:middle
Note that this cube map is

00:26:46.456 --> 00:26:50.456 A:middle
partially filled, and to set up

00:26:50.506 --> 00:26:52.186 A:middle
reflection probes, we need to

00:26:52.186 --> 00:26:53.926 A:middle
have a fully completed cube map.

00:26:54.486 --> 00:26:58.756 A:middle
To have a fully completed cube

00:26:58.756 --> 00:27:01.396 A:middle
map, you will need to scan your

00:26:58.756 --> 00:27:01.396 A:middle
map, you will need to scan your

00:27:01.466 --> 00:27:03.966 A:middle
full physical space, something

00:27:03.966 --> 00:27:06.286 A:middle
like a 360-degree scan you do

00:27:06.286 --> 00:27:07.376 A:middle
with your panoramas.

00:27:08.586 --> 00:27:10.856 A:middle
But this is not practical for

00:27:10.956 --> 00:27:11.516 A:middle
end-users.

00:27:13.296 --> 00:27:15.526 A:middle
So ARKit makes it very easy for

00:27:15.526 --> 00:27:18.626 A:middle
you by automatically completing

00:27:18.626 --> 00:27:20.756 A:middle
this cube map using advanced

00:27:20.756 --> 00:27:21.946 A:middle
machine learning algorithms.

00:27:24.016 --> 00:27:29.460 A:middle
[ Applause ]

00:27:31.536 --> 00:27:33.446 A:middle
Note also that all of this

00:27:33.446 --> 00:27:35.296 A:middle
processing happens locally on

00:27:35.296 --> 00:27:37.416 A:middle
your device in real-time.

00:27:39.556 --> 00:27:41.666 A:middle
So once we have a cube map, we

00:27:41.666 --> 00:27:44.116 A:middle
can set up reflection probe and

00:27:44.116 --> 00:27:46.066 A:middle
as soon as we place virtual

00:27:46.066 --> 00:27:48.186 A:middle
objects in the scene, they start

00:27:48.186 --> 00:27:49.506 A:middle
to reflect the real environment.

00:27:50.006 --> 00:27:52.726 A:middle
So this was a quick overview of

00:27:52.726 --> 00:27:54.416 A:middle
how this environment texturing

00:27:54.416 --> 00:27:55.116 A:middle
process works.

00:27:55.116 --> 00:28:00.286 A:middle
Let's see how ARKit API makes it

00:27:55.116 --> 00:28:00.286 A:middle
Let's see how ARKit API makes it

00:28:00.286 --> 00:28:03.446 A:middle
very easy for you to enable this

00:28:07.516 --> 00:28:07.686 A:middle
feature.

00:28:07.836 --> 00:28:09.966 A:middle
So all you have to do in your

00:28:09.966 --> 00:28:12.516 A:middle
world tracking configuration to

00:28:12.516 --> 00:28:14.006 A:middle
set environment texturing

00:28:14.006 --> 00:28:17.776 A:middle
property to automatic and run

00:28:17.776 --> 00:28:18.206 A:middle
the session.

00:28:19.196 --> 00:28:21.206 A:middle
So this is as simple as this.

00:28:22.516 --> 00:28:28.576 A:middle
[ Applause ]

00:28:29.076 --> 00:28:31.186 A:middle
AR session will automatically

00:28:31.186 --> 00:28:32.946 A:middle
run this environment texturing

00:28:32.946 --> 00:28:34.976 A:middle
process in the background and

00:28:34.976 --> 00:28:36.326 A:middle
will give you environment

00:28:36.546 --> 00:28:39.316 A:middle
texture as an environment probe

00:28:39.316 --> 00:28:39.616 A:middle
anchor.

00:28:40.996 --> 00:28:43.416 A:middle
AREnvironmentProbeAnchor is an

00:28:43.416 --> 00:28:45.226 A:middle
extension of AR anchor, so it

00:28:45.226 --> 00:28:46.916 A:middle
means it has a six degrees of

00:28:46.916 --> 00:28:48.496 A:middle
freedom position and orientation

00:28:48.496 --> 00:28:49.066 A:middle
transform.

00:28:50.716 --> 00:28:53.346 A:middle
Moreover, it has a cube map in

00:28:53.346 --> 00:28:58.596 A:middle
the form of metal texture.

00:28:58.596 --> 00:29:00.336 A:middle
ARKit also gives you physical

00:28:58.596 --> 00:29:00.336 A:middle
ARKit also gives you physical

00:29:00.336 --> 00:29:02.356 A:middle
extent of the cube map.

00:29:02.846 --> 00:29:04.546 A:middle
So this is area of the influence

00:29:04.836 --> 00:29:08.176 A:middle
of the reflection probe, and it

00:29:08.176 --> 00:29:10.786 A:middle
can be used by rendering agents

00:29:11.246 --> 00:29:12.846 A:middle
to correct for parallels.

00:29:12.846 --> 00:29:14.176 A:middle
So such as in case your object

00:29:14.176 --> 00:29:16.186 A:middle
is moving in the scene, it will

00:29:16.186 --> 00:29:18.636 A:middle
automatically adapt to new

00:29:18.636 --> 00:29:21.226 A:middle
position and new texture will be

00:29:21.226 --> 00:29:22.226 A:middle
reflected in the environment.

00:29:22.686 --> 00:29:26.666 A:middle
Note that this follows same

00:29:26.666 --> 00:29:28.476 A:middle
lifecycle as every other anchor

00:29:29.036 --> 00:29:31.166 A:middle
such as AR plane anchor or AR

00:29:31.166 --> 00:29:31.676 A:middle
image anchor.

00:29:36.676 --> 00:29:38.396 A:middle
Furthermore, it is fully

00:29:38.396 --> 00:29:40.566 A:middle
integrated into ARSCNView.

00:29:41.016 --> 00:29:42.396 A:middle
So in case you are using

00:29:42.646 --> 00:29:44.216 A:middle
SceneKit as your rendering

00:29:44.216 --> 00:29:47.136 A:middle
technology, you just need to

00:29:47.136 --> 00:29:49.586 A:middle
enable this feature in world

00:29:49.586 --> 00:29:50.486 A:middle
tracking configuration.

00:29:51.056 --> 00:29:52.706 A:middle
The rest is done automatically

00:29:52.796 --> 00:29:54.076 A:middle
by ARSCNView.

00:29:58.996 --> 00:30:02.146 A:middle
Note that for advanced use

00:29:58.996 --> 00:30:02.146 A:middle
Note that for advanced use

00:30:02.146 --> 00:30:04.496 A:middle
cases, you may want to place

00:30:04.496 --> 00:30:05.666 A:middle
environment probe anchors

00:30:05.876 --> 00:30:11.406 A:middle
manually in the scene.

00:30:11.726 --> 00:30:13.246 A:middle
So for this, you will need to

00:30:13.246 --> 00:30:14.796 A:middle
set environment texturing mode

00:30:14.856 --> 00:30:18.626 A:middle
to manual, and then you can

00:30:18.626 --> 00:30:20.366 A:middle
create environment probe anchors

00:30:21.086 --> 00:30:23.066 A:middle
at your desired position and

00:30:23.066 --> 00:30:24.836 A:middle
orientation and add them to AR

00:30:24.836 --> 00:30:25.476 A:middle
session object.

00:30:25.886 --> 00:30:30.306 A:middle
Note that this only enables you

00:30:30.306 --> 00:30:32.936 A:middle
to place the probe anchors in

00:30:33.516 --> 00:30:34.006 A:middle
the scene.

00:30:34.006 --> 00:30:35.666 A:middle
AR session will automatically

00:30:35.666 --> 00:30:37.606 A:middle
update its texture as soon as it

00:30:37.656 --> 00:30:39.596 A:middle
gets more information about the

00:30:39.596 --> 00:30:39.996 A:middle
environment.

00:30:42.016 --> 00:30:45.906 A:middle
So you may use this mode in case

00:30:45.906 --> 00:30:48.306 A:middle
your augmented reality scene has

00:30:48.306 --> 00:30:49.136 A:middle
a single object.

00:30:49.296 --> 00:30:51.176 A:middle
You don't want to overload

00:30:51.576 --> 00:30:53.346 A:middle
system with too many environment

00:30:53.916 --> 00:30:57.046 A:middle
probe anchors.

00:30:57.246 --> 00:30:59.306 A:middle
So let's see a quick demo of

00:30:59.306 --> 00:31:00.926 A:middle
environment texturing and see

00:30:59.306 --> 00:31:00.926 A:middle
environment texturing and see

00:31:01.426 --> 00:31:03.506 A:middle
how we can realistically render

00:31:03.866 --> 00:31:05.806 A:middle
augmented reality scene.

00:31:06.516 --> 00:31:10.500 A:middle
[ Applause ]

00:31:16.316 --> 00:31:18.646 A:middle
So we can switch to AR 1.

00:31:23.626 --> 00:31:25.916 A:middle
Okay. So for this demo, I am

00:31:26.116 --> 00:31:27.856 A:middle
running world tracking

00:31:27.856 --> 00:31:29.986 A:middle
configuration without

00:31:29.986 --> 00:31:31.516 A:middle
environment texturing feature

00:31:31.516 --> 00:31:31.896 A:middle
enabled.

00:31:33.176 --> 00:31:37.656 A:middle
So as you can see on the bottom

00:31:37.706 --> 00:31:39.626 A:middle
switch controller, it's just

00:31:39.626 --> 00:31:41.026 A:middle
using ambient light estimate.

00:31:41.456 --> 00:31:44.146 A:middle
And let's place the same object

00:31:44.146 --> 00:31:45.856 A:middle
that we have seen before.

00:31:47.116 --> 00:31:52.376 A:middle
And you can see it is, it looks

00:31:52.376 --> 00:31:52.746 A:middle
okay.

00:31:52.746 --> 00:31:53.766 A:middle
I mean you can see this on the

00:31:53.766 --> 00:31:54.056 A:middle
table.

00:31:54.056 --> 00:31:55.656 A:middle
You can see the shadow of it,

00:31:56.096 --> 00:31:57.886 A:middle
and it looks like a really good

00:31:57.886 --> 00:31:58.356 A:middle
AR scene.

00:31:59.686 --> 00:32:01.536 A:middle
But what we are missing is that

00:31:59.686 --> 00:32:01.536 A:middle
But what we are missing is that

00:32:01.536 --> 00:32:03.776 A:middle
it does not reflect wooden

00:32:03.776 --> 00:32:06.786 A:middle
surface of the table.

00:32:06.916 --> 00:32:08.286 A:middle
So moreover, if I place

00:32:08.286 --> 00:32:11.526 A:middle
something in the scene such as

00:32:11.526 --> 00:32:17.516 A:middle
real fruit, we don't see a

00:32:17.516 --> 00:32:20.516 A:middle
reflection of it in the virtual

00:32:20.936 --> 00:32:21.126 A:middle
object.

00:32:21.656 --> 00:32:23.616 A:middle
So let's enable environment

00:32:23.616 --> 00:32:25.896 A:middle
texturing and see how it can

00:32:26.206 --> 00:32:29.156 A:middle
realistically represent this

00:32:29.216 --> 00:32:29.576 A:middle
texture.

00:32:30.636 --> 00:32:32.326 A:middle
So as you can see, as soon as I

00:32:32.326 --> 00:32:33.766 A:middle
enable environment texturing,

00:32:34.526 --> 00:32:36.366 A:middle
the object started to reflect

00:32:36.366 --> 00:32:38.616 A:middle
the wooden surface of the table

00:32:39.016 --> 00:32:41.686 A:middle
as well as the texture from this

00:32:41.746 --> 00:32:42.176 A:middle
banana.

00:32:43.516 --> 00:32:50.546 A:middle
[ Applause ]

00:32:51.046 --> 00:32:51.266 A:middle
Thank you.

00:32:52.626 --> 00:32:55.326 A:middle
So this greatly enhances you

00:32:55.326 --> 00:32:56.706 A:middle
augmented reality scene.

00:32:57.346 --> 00:32:59.586 A:middle
So it looks as real as possible,

00:33:00.776 --> 00:33:04.726 A:middle
as if it is really on the table.

00:33:05.056 --> 00:33:06.796 A:middle
Okay. Back to slides.

00:33:12.806 --> 00:33:14.086 A:middle
So this was environment

00:33:14.206 --> 00:33:14.686 A:middle
texturing.

00:33:14.866 --> 00:33:17.116 A:middle
It's a powerful new feature in

00:33:17.116 --> 00:33:20.616 A:middle
ARKit 2 that lets you create

00:33:20.616 --> 00:33:22.436 A:middle
your augmented reality scene as

00:33:22.436 --> 00:33:26.256 A:middle
realistic as possible.

00:33:26.256 --> 00:33:28.116 A:middle
Now, to continue with the rest

00:33:28.116 --> 00:33:30.296 A:middle
of the great new features, I

00:33:30.296 --> 00:33:32.376 A:middle
will invite Reinhard on stage.

00:33:34.476 --> 00:33:38.660 A:middle
[ Applause ]

00:33:42.226 --> 00:33:42.866 A:middle
&gt;&gt; It's working?

00:33:43.206 --> 00:33:43.856 A:middle
Oh, okay, great.

00:33:46.066 --> 00:33:46.496 A:middle
Good morning.

00:33:47.376 --> 00:33:48.936 A:middle
My name is Reinhard, and I'm an

00:33:48.936 --> 00:33:50.336 A:middle
engineer on the ARKit team.

00:33:50.746 --> 00:33:52.446 A:middle
So next let's talk about image

00:33:52.446 --> 00:33:52.816 A:middle
tracking.

00:33:52.816 --> 00:33:56.566 A:middle
In iOS 11.3, we introduced image

00:33:56.566 --> 00:33:58.116 A:middle
detection as part of world

00:33:58.116 --> 00:33:58.536 A:middle
tracking.

00:33:59.646 --> 00:34:01.326 A:middle
Image detection searches for

00:33:59.646 --> 00:34:01.326 A:middle
Image detection searches for

00:34:01.326 --> 00:34:03.086 A:middle
known 2D images in the scene.

00:34:03.776 --> 00:34:05.836 A:middle
The term detection here implies

00:34:05.996 --> 00:34:07.996 A:middle
that these images are static and

00:34:07.996 --> 00:34:09.126 A:middle
are therefore not supposed to

00:34:09.126 --> 00:34:09.396 A:middle
move.

00:34:10.326 --> 00:34:11.626 A:middle
Great examples for such images

00:34:11.626 --> 00:34:13.576 A:middle
could be movie posters or

00:34:13.576 --> 00:34:14.746 A:middle
paintings in a museum.

00:34:16.416 --> 00:34:18.536 A:middle
ARKit will estimate the position

00:34:18.636 --> 00:34:20.156 A:middle
and orientation of such an image

00:34:20.466 --> 00:34:22.216 A:middle
in six degrees of freedom once

00:34:22.216 --> 00:34:23.416 A:middle
an image has been detected.

00:34:24.536 --> 00:34:26.446 A:middle
This pose can be used to trigger

00:34:26.446 --> 00:34:28.005 A:middle
content in your rendered scene.

00:34:28.525 --> 00:34:31.576 A:middle
As I mentioned earlier, all this

00:34:31.626 --> 00:34:33.065 A:middle
is fully integrated world

00:34:33.065 --> 00:34:33.505 A:middle
tracking.

00:34:34.065 --> 00:34:35.065 A:middle
So all you need to do is set

00:34:35.065 --> 00:34:37.626 A:middle
once in your property to set it

00:34:38.666 --> 00:34:38.746 A:middle
up.

00:34:39.025 --> 00:34:40.255 A:middle
In order to load images to be

00:34:40.255 --> 00:34:42.386 A:middle
used for image detection, you

00:34:42.386 --> 00:34:44.275 A:middle
made load them from file or use

00:34:44.346 --> 00:34:46.196 A:middle
Xcode's asset catalog, which

00:34:46.196 --> 00:34:47.946 A:middle
also gives you the detection

00:34:47.946 --> 00:34:49.056 A:middle
quality for an image.

00:34:50.406 --> 00:34:51.496 A:middle
So image detection is already

00:34:51.496 --> 00:34:54.275 A:middle
great, but now in iOS 12, we can

00:34:54.275 --> 00:34:54.735 A:middle
do better.

00:34:54.926 --> 00:34:56.636 A:middle
So let's talk about image

00:34:56.636 --> 00:34:56.976 A:middle
tracking.

00:34:57.846 --> 00:34:59.636 A:middle
Image tracking is an extension

00:34:59.636 --> 00:35:01.546 A:middle
to image detection with a big

00:34:59.636 --> 00:35:01.546 A:middle
to image detection with a big

00:35:01.546 --> 00:35:03.776 A:middle
advantage that images no longer

00:35:03.776 --> 00:35:07.406 A:middle
need to be static and may move.

00:35:07.616 --> 00:35:09.036 A:middle
ARKit will now estimate the

00:35:09.036 --> 00:35:10.806 A:middle
position and orientation for

00:35:10.806 --> 00:35:12.516 A:middle
every frame at 60 frames per

00:35:12.516 --> 00:35:12.886 A:middle
second.

00:35:13.706 --> 00:35:15.206 A:middle
This allows you to accurately

00:35:15.466 --> 00:35:18.316 A:middle
augment 2D images, say

00:35:18.906 --> 00:35:20.626 A:middle
magazines, board games, or

00:35:20.626 --> 00:35:21.856 A:middle
pretty much anything that

00:35:21.856 --> 00:35:23.396 A:middle
features a real image.

00:35:24.986 --> 00:35:27.136 A:middle
And ARKit can also track

00:35:27.516 --> 00:35:29.066 A:middle
multiple images simultaneously.

00:35:30.886 --> 00:35:32.356 A:middle
By default it only selects 1,

00:35:32.646 --> 00:35:34.596 A:middle
but in cases, for example, the

00:35:34.596 --> 00:35:36.166 A:middle
cover of a magazine, you may

00:35:36.166 --> 00:35:39.156 A:middle
want to keep this set to 1, or

00:35:39.156 --> 00:35:41.046 A:middle
in case of a double-page

00:35:41.046 --> 00:35:42.866 A:middle
magazine inside a magazine, you

00:35:42.866 --> 00:35:43.716 A:middle
want to set this to 2.

00:35:45.416 --> 00:35:49.496 A:middle
And in ARKit 2 on iOS 12, we

00:35:49.736 --> 00:35:51.086 A:middle
have a brand-new configuration

00:35:51.086 --> 00:35:52.556 A:middle
called the AR Image Tracking

00:35:52.556 --> 00:35:54.626 A:middle
Configuration that lets you do

00:35:55.076 --> 00:35:56.546 A:middle
stand-alone image tracking.

00:35:57.356 --> 00:35:58.596 A:middle
So let's see how to set it up.

00:36:00.016 --> 00:36:01.566 A:middle
We start by loading a set of

00:36:01.656 --> 00:36:02.736 A:middle
reference images, either from

00:36:02.736 --> 00:36:04.456 A:middle
file or from the asset catalog.

00:36:05.676 --> 00:36:07.246 A:middle
Once I'm done loading such a set

00:36:07.246 --> 00:36:09.276 A:middle
of reference images, I use this

00:36:09.966 --> 00:36:11.596 A:middle
to set up my session that can be

00:36:11.676 --> 00:36:13.726 A:middle
of type world tracking by

00:36:13.806 --> 00:36:15.226 A:middle
specifying its detection images

00:36:15.286 --> 00:36:17.026 A:middle
property or of type

00:36:17.026 --> 00:36:19.386 A:middle
ARImageTrackingConfiguration by

00:36:19.386 --> 00:36:20.786 A:middle
specifying the tracking images

00:36:20.826 --> 00:36:20.986 A:middle
one.

00:36:22.406 --> 00:36:24.036 A:middle
Once I'm done setting up my

00:36:24.036 --> 00:36:26.316 A:middle
configuration, I use this to run

00:36:26.316 --> 00:36:26.846 A:middle
my session.

00:36:28.296 --> 00:36:30.276 A:middle
And just as usual, once the

00:36:30.326 --> 00:36:31.966 A:middle
session is running, I'll get an

00:36:31.966 --> 00:36:33.496 A:middle
ARFrame at every update.

00:36:34.476 --> 00:36:35.776 A:middle
And such and ARFrame will

00:36:35.776 --> 00:36:37.486 A:middle
continue an object of type

00:36:37.676 --> 00:36:40.116 A:middle
ARImageAnchor, once an image has

00:36:40.156 --> 00:36:40.676 A:middle
been detected.

00:36:41.036 --> 00:36:44.086 A:middle
Such an ARImageAnchor is now a

00:36:44.086 --> 00:36:45.066 A:middle
trackable object.

00:36:45.406 --> 00:36:46.836 A:middle
I can see this by conforming to

00:36:46.836 --> 00:36:48.086 A:middle
the AR trackable protocol.

00:36:48.786 --> 00:36:51.346 A:middle
This means it comes as a boolean

00:36:51.546 --> 00:36:55.036 A:middle
isTracked, which informs you about

00:36:55.036 --> 00:36:56.466 A:middle
the tracking state of the image.

00:36:56.976 --> 00:36:58.566 A:middle
It's true if it's tracked and

00:36:58.566 --> 00:36:59.246 A:middle
false otherwise.

00:37:00.516 --> 00:37:01.956 A:middle
It also informs about which

00:37:01.956 --> 00:37:03.566 A:middle
image has been detected and

00:37:03.566 --> 00:37:06.176 A:middle
where it is by giving me it's

00:37:06.406 --> 00:37:08.536 A:middle
position and orientation as a 4

00:37:08.536 --> 00:37:09.956 A:middle
by 4 matrix.

00:37:11.496 --> 00:37:13.326 A:middle
So in order to get such image

00:37:13.326 --> 00:37:14.896 A:middle
anchors, it all starts by

00:37:14.896 --> 00:37:15.646 A:middle
loading images.

00:37:15.726 --> 00:37:16.676 A:middle
So that's good.

00:37:16.906 --> 00:37:18.176 A:middle
Let's have a look at what good

00:37:18.216 --> 00:37:19.096 A:middle
images could be.

00:37:19.846 --> 00:37:21.426 A:middle
This image here could be found

00:37:21.486 --> 00:37:23.476 A:middle
in a book for children, and in

00:37:23.476 --> 00:37:25.686 A:middle
fact, it works great for image

00:37:25.686 --> 00:37:26.066 A:middle
tracking.

00:37:26.436 --> 00:37:27.976 A:middle
It has a lot of distinct visual

00:37:27.976 --> 00:37:28.496 A:middle
features.

00:37:28.806 --> 00:37:30.346 A:middle
It's we'll textured and shows

00:37:30.346 --> 00:37:31.096 A:middle
really good contrast.

00:37:32.566 --> 00:37:34.236 A:middle
On the other hand, an image like

00:37:34.236 --> 00:37:36.076 A:middle
this, which could also be found

00:37:36.076 --> 00:37:39.446 A:middle
in a textbook for kids, is not

00:37:39.446 --> 00:37:39.986 A:middle
recommended.

00:37:40.756 --> 00:37:41.646 A:middle
It has a lot of repetitive

00:37:41.646 --> 00:37:43.326 A:middle
structures, uniform color

00:37:43.326 --> 00:37:44.876 A:middle
regions, and a pretty narrow

00:37:44.876 --> 00:37:46.666 A:middle
histogram once converted to gray

00:37:46.666 --> 00:37:46.946 A:middle
scale.

00:37:48.436 --> 00:37:49.586 A:middle
But you don't have to identify

00:37:49.586 --> 00:37:50.966 A:middle
these statistics yourself as

00:37:51.066 --> 00:37:52.066 A:middle
Xcode is here to help.

00:37:52.926 --> 00:37:54.716 A:middle
So if I import these two images

00:37:54.716 --> 00:37:57.286 A:middle
to Xcode, I see the sea life one

00:37:57.586 --> 00:37:59.216 A:middle
without any warning, which means

00:37:59.216 --> 00:38:01.296 A:middle
it's recommended, and the one

00:37:59.216 --> 00:38:01.296 A:middle
it's recommended, and the one

00:38:01.296 --> 00:38:02.346 A:middle
about the three kids reading

00:38:02.346 --> 00:38:03.676 A:middle
showing a warning icon, meaning

00:38:03.886 --> 00:38:04.776 A:middle
it's not recommended.

00:38:06.096 --> 00:38:07.756 A:middle
If I click this icon, I get a

00:38:07.756 --> 00:38:09.856 A:middle
precise description why this

00:38:09.886 --> 00:38:13.046 A:middle
image is not recommended to use

00:38:13.046 --> 00:38:13.676 A:middle
image tracking.

00:38:14.186 --> 00:38:15.556 A:middle
I get information about the

00:38:15.556 --> 00:38:17.236 A:middle
histogram, uniform color

00:38:17.236 --> 00:38:19.206 A:middle
regions, as well as the

00:38:19.676 --> 00:38:19.946 A:middle
histogram.

00:38:21.136 --> 00:38:23.866 A:middle
So once I'm done loading images,

00:38:23.866 --> 00:38:25.326 A:middle
I'm left with two choices of

00:38:25.376 --> 00:38:26.226 A:middle
configurations.

00:38:26.766 --> 00:38:27.646 A:middle
First one is

00:38:27.646 --> 00:38:29.416 A:middle
ARWorldTrackingConfiguration.

00:38:29.596 --> 00:38:31.826 A:middle
So let's talk about that.

00:38:32.816 --> 00:38:34.656 A:middle
When we use image tracking with

00:38:34.656 --> 00:38:36.726 A:middle
world tracking, image anchors

00:38:36.726 --> 00:38:38.056 A:middle
are represented in a world

00:38:38.056 --> 00:38:38.816 A:middle
coordinates system.

00:38:39.346 --> 00:38:41.426 A:middle
This means that image anchors

00:38:41.476 --> 00:38:43.016 A:middle
optionally plane anchors.

00:38:44.186 --> 00:38:45.946 A:middle
The camera and the world origin

00:38:46.116 --> 00:38:48.516 A:middle
itself all appear in the same

00:38:48.516 --> 00:38:49.276 A:middle
coordinate system.

00:38:49.826 --> 00:38:51.256 A:middle
This makes their interaction

00:38:51.346 --> 00:38:54.286 A:middle
very easy and intuitive, and

00:38:54.286 --> 00:38:57.676 A:middle
what's new in iOS 12 now images

00:38:57.676 --> 00:38:58.666 A:middle
that could previously only be

00:38:58.666 --> 00:39:00.286 A:middle
detected can now be tracked.

00:38:58.666 --> 00:39:00.286 A:middle
detected can now be tracked.

00:39:00.726 --> 00:39:03.626 A:middle
And we have a new configuration,

00:39:03.626 --> 00:39:03.746 A:middle
the

00:39:03.746 --> 00:39:05.486 A:middle
ARImageTrackingConfiguration,

00:39:05.846 --> 00:39:07.456 A:middle
which performs stand-alone image

00:39:07.456 --> 00:39:07.836 A:middle
tracking.

00:39:09.086 --> 00:39:10.396 A:middle
This means it's independent from

00:39:10.396 --> 00:39:12.636 A:middle
world tracking and does not rely

00:39:12.706 --> 00:39:14.906 A:middle
on the motion sensor to perform

00:39:14.906 --> 00:39:15.406 A:middle
the tracking.

00:39:16.206 --> 00:39:18.386 A:middle
This means this configuration is

00:39:18.386 --> 00:39:20.966 A:middle
not to initialize before it

00:39:20.966 --> 00:39:23.306 A:middle
starts to identify images and

00:39:23.306 --> 00:39:25.046 A:middle
could also succeed in scenarios

00:39:25.046 --> 00:39:26.696 A:middle
in which world tracking fails,

00:39:26.856 --> 00:39:28.776 A:middle
such as moving platform like an

00:39:28.816 --> 00:39:30.076 A:middle
elevator or a train.

00:39:31.336 --> 00:39:33.766 A:middle
I think in this case ARKit would

00:39:33.816 --> 00:39:35.276 A:middle
estimate the position and

00:39:35.276 --> 00:39:36.946 A:middle
orientation for every frame at

00:39:37.036 --> 00:39:39.286 A:middle
60 frames per second.

00:39:39.406 --> 00:39:40.696 A:middle
And implementing this can be

00:39:40.696 --> 00:39:42.546 A:middle
done in four simple lines of

00:39:42.586 --> 00:39:43.126 A:middle
code.

00:39:44.096 --> 00:39:46.026 A:middle
So all you need to do, I create

00:39:46.026 --> 00:39:46.916 A:middle
a configuration type

00:39:47.096 --> 00:39:49.566 A:middle
ARImageTrackingConfiguration and

00:39:49.566 --> 00:39:52.006 A:middle
specify a set of images I'd like

00:39:52.006 --> 00:39:52.396 A:middle
to track.

00:39:53.146 --> 00:39:54.836 A:middle
In this case, I specified a

00:39:54.836 --> 00:39:56.806 A:middle
photo of a cat, a dog, and a

00:39:56.806 --> 00:39:57.076 A:middle
bird.

00:39:59.556 --> 00:40:00.816 A:middle
I tell the configuration how

00:39:59.556 --> 00:40:00.816 A:middle
I tell the configuration how

00:40:00.816 --> 00:40:02.426 A:middle
many images I'd like to track.

00:40:03.016 --> 00:40:04.236 A:middle
In this case, I specified this

00:40:04.276 --> 00:40:04.816 A:middle
to be 2.

00:40:05.576 --> 00:40:08.126 A:middle
In my use case, I imagined only

00:40:08.126 --> 00:40:10.676 A:middle
2 images will interact but not 3

00:40:10.676 --> 00:40:11.496 A:middle
at the same time.

00:40:12.526 --> 00:40:14.116 A:middle
Note that if I'm tracking 2

00:40:14.226 --> 00:40:16.076 A:middle
images and a third comes into

00:40:16.246 --> 00:40:19.076 A:middle
its view, it won't be tracked,

00:40:19.076 --> 00:40:20.856 A:middle
but it will still get a

00:40:20.856 --> 00:40:21.666 A:middle
detection update.

00:40:23.096 --> 00:40:24.266 A:middle
And then I use this

00:40:24.266 --> 00:40:26.016 A:middle
configuration to run my session.

00:40:26.596 --> 00:40:28.926 A:middle
And as I mentioned earlier, you

00:40:29.146 --> 00:40:30.906 A:middle
can also do this using world

00:40:30.906 --> 00:40:32.796 A:middle
tracking by simply switching out

00:40:33.136 --> 00:40:33.786 A:middle
these two lines.

00:40:34.596 --> 00:40:36.216 A:middle
The only difference between

00:40:36.216 --> 00:40:38.266 A:middle
image detection and tracking is

00:40:38.266 --> 00:40:39.466 A:middle
the maximum number of tracking

00:40:39.466 --> 00:40:39.946 A:middle
images.

00:40:40.786 --> 00:40:44.616 A:middle
So if you have an app that uses

00:40:44.616 --> 00:40:46.066 A:middle
image detection, you could

00:40:46.066 --> 00:40:47.856 A:middle
simply add this, recompile, and

00:40:47.856 --> 00:40:49.686 A:middle
your app may use tracking.

00:40:51.026 --> 00:40:52.866 A:middle
So in order to show you how easy

00:40:52.866 --> 00:40:54.376 A:middle
this really is, let's do a demo

00:40:54.486 --> 00:40:55.046 A:middle
in Xcode.

00:40:56.676 --> 00:41:02.236 A:middle
[ Applause ]

00:40:56.676 --> 00:41:02.236 A:middle
[ Applause ]

00:41:02.736 --> 00:41:04.056 A:middle
Can we go to AR 2?

00:41:04.266 --> 00:41:07.346 A:middle
Yes. So for this demo I'd like

00:41:07.416 --> 00:41:10.656 A:middle
to build a AR photo frame, and

00:41:10.656 --> 00:41:12.176 A:middle
for this, I brought a photo of

00:41:12.176 --> 00:41:13.036 A:middle
my cat from home.

00:41:13.846 --> 00:41:15.346 A:middle
So let's build this using Xcode.

00:41:16.256 --> 00:41:19.996 A:middle
So I started by creating a iOS

00:41:20.936 --> 00:41:22.666 A:middle
app template using Xcode.

00:41:23.056 --> 00:41:24.796 A:middle
As you can see by now it's

00:41:24.796 --> 00:41:26.396 A:middle
pretty empty.

00:41:26.776 --> 00:41:28.496 A:middle
Next, I need to specify which

00:41:28.526 --> 00:41:29.736 A:middle
image I'd like to attach.

00:41:30.596 --> 00:41:32.266 A:middle
For this I imported the photo of

00:41:32.266 --> 00:41:33.456 A:middle
my cat, Daisy.

00:41:33.456 --> 00:41:36.436 A:middle
Let's open her up here.

00:41:37.056 --> 00:41:37.606 A:middle
That's my cat.

00:41:37.606 --> 00:41:41.176 A:middle
I need to specify a name.

00:41:41.256 --> 00:41:43.576 A:middle
I give it the name Daisy, which

00:41:43.576 --> 00:41:45.016 A:middle
is the name of my cat, and I

00:41:45.016 --> 00:41:47.816 A:middle
specify here the physical width

00:41:48.176 --> 00:41:49.576 A:middle
of the image found in the real

00:41:49.576 --> 00:41:50.756 A:middle
world, which is my photo frame.

00:41:52.296 --> 00:41:55.156 A:middle
I also loaded a movie of my cat.

00:41:55.956 --> 00:41:56.986 A:middle
So let's bring this all

00:41:56.986 --> 00:41:57.326 A:middle
together.

00:41:58.456 --> 00:42:00.696 A:middle
First, I will create a

00:41:58.456 --> 00:42:00.696 A:middle
First, I will create a

00:42:00.696 --> 00:42:03.176 A:middle
configuration, which will be a

00:42:03.176 --> 00:42:04.166 A:middle
configuration of type

00:42:04.756 --> 00:42:06.406 A:middle
ARImageTrackingConfiguration.

00:42:07.426 --> 00:42:08.976 A:middle
I load a set of tracking images

00:42:08.976 --> 00:42:11.426 A:middle
from the asset catalog by using

00:42:11.556 --> 00:42:13.176 A:middle
the group name photos.

00:42:13.836 --> 00:42:15.086 A:middle
This will contain only one

00:42:15.086 --> 00:42:17.146 A:middle
image, which is the photo of my

00:42:17.146 --> 00:42:17.736 A:middle
cat, Daisy.

00:42:18.936 --> 00:42:22.066 A:middle
Next, I set up the configuration

00:42:22.066 --> 00:42:23.616 A:middle
image tracking by specifying the

00:42:23.616 --> 00:42:25.486 A:middle
tracking images property here,

00:42:26.236 --> 00:42:28.106 A:middle
and I specify the max number of

00:42:28.156 --> 00:42:30.066 A:middle
tracked images that we want.

00:42:30.446 --> 00:42:31.556 A:middle
At this point, the app will

00:42:31.556 --> 00:42:34.126 A:middle
already start an AR session and

00:42:34.126 --> 00:42:35.356 A:middle
provide you with image anchors

00:42:35.466 --> 00:42:36.596 A:middle
once an image has been detected.

00:42:37.096 --> 00:42:38.106 A:middle
But let's add some content.

00:42:38.936 --> 00:42:40.716 A:middle
I will load the video

00:42:41.916 --> 00:42:45.586 A:middle
by trading a AV player from the

00:42:46.106 --> 00:42:47.046 A:middle
video by loading it from the

00:42:47.046 --> 00:42:47.656 A:middle
resource panel.

00:42:49.136 --> 00:42:51.016 A:middle
Now let's add it on top of the

00:42:51.016 --> 00:42:52.016 A:middle
real image.

00:42:52.586 --> 00:42:56.296 A:middle
So for this, I'm checking

00:42:56.296 --> 00:42:57.636 A:middle
whether the anchor is of type

00:42:57.686 --> 00:43:00.616 A:middle
image anchor, and I create an

00:42:57.686 --> 00:43:00.616 A:middle
image anchor, and I create an

00:43:00.716 --> 00:43:02.296 A:middle
SCN plane having the same

00:43:02.366 --> 00:43:04.106 A:middle
physical dimension as the image

00:43:04.166 --> 00:43:04.876 A:middle
found in the scene.

00:43:06.256 --> 00:43:08.136 A:middle
I assign the video player as the

00:43:08.176 --> 00:43:10.796 A:middle
texture to my plane, and I start

00:43:10.796 --> 00:43:11.766 A:middle
playing my video player.

00:43:12.356 --> 00:43:15.446 A:middle
I create an SCN note from

00:43:15.446 --> 00:43:17.356 A:middle
geometry, and I counter rotate

00:43:17.666 --> 00:43:20.646 A:middle
to match the anchor's coordinate

00:43:20.866 --> 00:43:21.116 A:middle
system.

00:43:21.906 --> 00:43:22.896 A:middle
So that's it.

00:43:22.896 --> 00:43:24.026 A:middle
This will run.

00:43:24.446 --> 00:43:26.086 A:middle
Let's see it live.

00:43:27.716 --> 00:43:32.086 A:middle
So once I bring the frame of my

00:43:32.086 --> 00:43:33.936 A:middle
cat into the camera's view, the

00:43:34.146 --> 00:43:36.036 A:middle
video starts playing, and I can

00:43:36.096 --> 00:43:37.126 A:middle
see my cat interact.

00:43:37.676 --> 00:43:43.946 A:middle
[ Applause ]

00:43:44.446 --> 00:43:46.516 A:middle
Since ARKit estimates position

00:43:46.516 --> 00:43:48.186 A:middle
in real-time, I can move my

00:43:48.186 --> 00:43:50.156 A:middle
device freely, or I can move the

00:43:50.156 --> 00:43:50.616 A:middle
object.

00:43:50.616 --> 00:43:52.546 A:middle
So I can really see that there's

00:43:52.546 --> 00:43:54.056 A:middle
an update at every frame.

00:43:54.056 --> 00:43:56.626 A:middle
Oh, oh, she just left.

00:43:56.966 --> 00:43:59.176 A:middle
I guess it's the end of the

00:43:59.176 --> 00:44:00.316 A:middle
demo, let's go back to the

00:43:59.176 --> 00:44:00.316 A:middle
demo, let's go back to the

00:44:00.316 --> 00:44:00.676 A:middle
slides.

00:44:02.016 --> 00:44:07.936 A:middle
[ Applause ]

00:44:08.436 --> 00:44:09.876 A:middle
So as you can see, it's really

00:44:09.876 --> 00:44:12.106 A:middle
easy to use image tracking in

00:44:12.106 --> 00:44:12.546 A:middle
ARKit.

00:44:13.216 --> 00:44:14.626 A:middle
In fact, it's much harder to

00:44:14.626 --> 00:44:15.696 A:middle
make a video of your cat.

00:44:18.136 --> 00:44:20.306 A:middle
So image tracking is great at

00:44:20.306 --> 00:44:22.476 A:middle
interacting with 2D objects, but

00:44:22.476 --> 00:44:24.476 A:middle
we're not limited to plainer 2D

00:44:24.476 --> 00:44:28.286 A:middle
objects, so let's talk next

00:44:28.856 --> 00:44:31.326 A:middle
about object detection.

00:44:32.036 --> 00:44:35.576 A:middle
Object detection can be used to

00:44:35.576 --> 00:44:38.236 A:middle
detect known 3D objects in the

00:44:38.346 --> 00:44:38.636 A:middle
scene.

00:44:39.916 --> 00:44:41.216 A:middle
Just like image detection here,

00:44:41.216 --> 00:44:42.906 A:middle
the term detection means that

00:44:42.906 --> 00:44:44.716 A:middle
this object needs to be static

00:44:44.906 --> 00:44:46.176 A:middle
and can therefore, or should

00:44:46.176 --> 00:44:47.186 A:middle
therefore not move.

00:44:48.366 --> 00:44:50.156 A:middle
Great examples of such objects

00:44:50.156 --> 00:44:51.946 A:middle
could be exhibits in a museum,

00:44:52.196 --> 00:44:53.496 A:middle
certain toys, or household

00:44:53.496 --> 00:44:53.836 A:middle
items.

00:44:56.586 --> 00:44:57.656 A:middle
And like image detection,

00:44:58.096 --> 00:44:59.636 A:middle
objects need to be scanned first

00:44:59.636 --> 00:45:01.756 A:middle
using an iOS app running ARKit.

00:44:59.636 --> 00:45:01.756 A:middle
using an iOS app running ARKit.

00:45:02.686 --> 00:45:05.016 A:middle
For this we offered the full

00:45:05.016 --> 00:45:06.666 A:middle
source code of a full-featured

00:45:07.036 --> 00:45:09.256 A:middle
iOS app that allows you to scan

00:45:09.256 --> 00:45:10.296 A:middle
your own 3D objects.

00:45:11.436 --> 00:45:13.006 A:middle
Such objects have a few

00:45:13.096 --> 00:45:15.236 A:middle
properties such that they need

00:45:15.236 --> 00:45:17.336 A:middle
to be well textured, rigid, and

00:45:17.376 --> 00:45:18.056 A:middle
nonreflective.

00:45:18.576 --> 00:45:20.396 A:middle
And they need to have roughly

00:45:20.396 --> 00:45:23.866 A:middle
the size of a tabletop.

00:45:23.866 --> 00:45:25.586 A:middle
ARKit can be used to estimate

00:45:25.586 --> 00:45:27.356 A:middle
the position and orientation of

00:45:27.356 --> 00:45:28.796 A:middle
such objects in six degrees of

00:45:28.796 --> 00:45:29.166 A:middle
freedom.

00:45:29.726 --> 00:45:33.716 A:middle
And all of this is fully

00:45:33.716 --> 00:45:34.936 A:middle
integrated into world tracking.

00:45:35.396 --> 00:45:37.026 A:middle
So all you need to do is set one

00:45:37.026 --> 00:45:38.726 A:middle
single property to get started

00:45:38.726 --> 00:45:39.526 A:middle
with object detection.

00:45:40.296 --> 00:45:41.976 A:middle
So let's have a look how it can

00:45:41.976 --> 00:45:42.356 A:middle
be set up.

00:45:42.406 --> 00:45:45.206 A:middle
I load a set of AR reference

00:45:45.296 --> 00:45:47.486 A:middle
images from file or from Xcode

00:45:47.486 --> 00:45:48.166 A:middle
asset catalog.

00:45:49.066 --> 00:45:50.726 A:middle
I will talk about the reference

00:45:50.726 --> 00:45:51.506 A:middle
objects in a second.

00:45:52.496 --> 00:45:53.586 A:middle
Once I'm done loading these

00:45:53.586 --> 00:45:54.926 A:middle
reference objects, I used them

00:45:55.776 --> 00:45:59.716 A:middle
to set up my configuration of

00:45:59.716 --> 00:46:00.056 A:middle
type

00:45:59.716 --> 00:46:00.056 A:middle
type

00:46:00.226 --> 00:46:02.096 A:middle
ARWorldTrackingConfiguration by

00:46:02.096 --> 00:46:03.776 A:middle
specifying the detection objects

00:46:03.806 --> 00:46:04.196 A:middle
property.

00:46:04.706 --> 00:46:07.166 A:middle
When I'm done setting up my

00:46:07.236 --> 00:46:09.706 A:middle
configuration, again I run my

00:46:09.786 --> 00:46:10.346 A:middle
session with it.

00:46:11.406 --> 00:46:12.696 A:middle
And just as image detection,

00:46:13.326 --> 00:46:14.466 A:middle
once the AR session is running,

00:46:14.466 --> 00:46:15.496 A:middle
I get an ARFrame with every

00:46:15.496 --> 00:46:18.936 A:middle
update, and in this case, once

00:46:18.936 --> 00:46:20.386 A:middle
an object has been detected in

00:46:20.386 --> 00:46:22.606 A:middle
the scene, I will find an AR

00:46:23.106 --> 00:46:25.966 A:middle
object anchor as part of my AR

00:46:25.966 --> 00:46:26.336 A:middle
frame.

00:46:28.926 --> 00:46:30.866 A:middle
Such an AR object is a simple

00:46:30.866 --> 00:46:32.506 A:middle
subclass of AR anchor.

00:46:33.156 --> 00:46:34.336 A:middle
So it comes with a transform,

00:46:34.336 --> 00:46:35.606 A:middle
which represents its position

00:46:35.796 --> 00:46:37.016 A:middle
and orientation and six degrees

00:46:37.016 --> 00:46:39.656 A:middle
of freedom as well as it tells

00:46:39.656 --> 00:46:41.706 A:middle
me which objects has been

00:46:41.706 --> 00:46:43.056 A:middle
detected by giving me a

00:46:43.056 --> 00:46:44.296 A:middle
reference to the AR reference

00:46:44.296 --> 00:46:44.676 A:middle
object.

00:46:46.326 --> 00:46:49.596 A:middle
And implementing this can be

00:46:49.596 --> 00:46:51.866 A:middle
done with three simple lines of

00:46:51.936 --> 00:46:52.186 A:middle
code.

00:46:52.976 --> 00:46:54.286 A:middle
I create a configuration of type

00:46:54.486 --> 00:46:56.876 A:middle
ARWorldTrackingConfiguration and

00:46:56.876 --> 00:46:59.116 A:middle
specify a set of objects I'd

00:46:59.116 --> 00:46:59.756 A:middle
like to detect.

00:47:00.596 --> 00:47:01.936 A:middle
In this case, I envision to

00:47:01.936 --> 00:47:04.896 A:middle
build a simple AR museum app by

00:47:04.896 --> 00:47:07.016 A:middle
detecting an ancient bust and a

00:47:07.016 --> 00:47:07.546 A:middle
clay pot.

00:47:07.546 --> 00:47:10.726 A:middle
And I use this to run my

00:47:10.806 --> 00:47:11.126 A:middle
session.

00:47:12.436 --> 00:47:14.696 A:middle
So in fact, at the office, we

00:47:14.696 --> 00:47:16.616 A:middle
build a very simple AR museum

00:47:16.616 --> 00:47:18.556 A:middle
app, so let's have a look.

00:47:19.126 --> 00:47:23.166 A:middle
So once this bust gets into view

00:47:23.166 --> 00:47:25.456 A:middle
of my iOS app, I get a six

00:47:25.456 --> 00:47:26.996 A:middle
degrees of freedom pose and can

00:47:26.996 --> 00:47:29.426 A:middle
use this to show the scene, very

00:47:29.426 --> 00:47:31.246 A:middle
simple infographics floating

00:47:31.246 --> 00:47:32.026 A:middle
about the statue.

00:47:32.906 --> 00:47:33.926 A:middle
In this case, we have simply

00:47:33.926 --> 00:47:36.366 A:middle
added date of birth, the name of

00:47:36.366 --> 00:47:37.496 A:middle
this Egyptian queen, which was

00:47:37.496 --> 00:47:39.906 A:middle
Nefertiti, but you could add any

00:47:39.906 --> 00:47:40.956 A:middle
content that your rendering

00:47:40.956 --> 00:47:43.576 A:middle
engine allows you to use.

00:47:43.956 --> 00:47:45.846 A:middle
In order to build this app, I

00:47:45.896 --> 00:47:47.386 A:middle
had to scan the object first.

00:47:48.066 --> 00:47:49.266 A:middle
So let's talk about object

00:47:49.266 --> 00:47:49.756 A:middle
scanning.

00:47:50.236 --> 00:47:53.306 A:middle
Object scanning extracts

00:47:53.426 --> 00:47:54.956 A:middle
accumulated scene information

00:47:55.216 --> 00:47:55.736 A:middle
from the world.

00:47:56.636 --> 00:47:58.506 A:middle
This is very much related to

00:47:58.506 --> 00:48:00.736 A:middle
plane estimation in which we use

00:47:58.506 --> 00:48:00.736 A:middle
plane estimation in which we use

00:48:00.776 --> 00:48:02.186 A:middle
accumulated scene information to

00:48:02.516 --> 00:48:03.566 A:middle
estimate the position of a

00:48:03.566 --> 00:48:05.106 A:middle
horizontal or vertical plane.

00:48:06.046 --> 00:48:07.556 A:middle
In this case, we use this

00:48:08.326 --> 00:48:11.606 A:middle
information to gather

00:48:11.606 --> 00:48:13.286 A:middle
information about the 3D object.

00:48:13.776 --> 00:48:17.556 A:middle
In order to specify which area

00:48:17.556 --> 00:48:19.086 A:middle
to look for the object, I just

00:48:19.086 --> 00:48:21.326 A:middle
specify a transform and extend

00:48:21.366 --> 00:48:21.986 A:middle
in the center.

00:48:22.796 --> 00:48:24.036 A:middle
This is essentially a bounding

00:48:24.036 --> 00:48:25.746 A:middle
box around the object just to

00:48:25.846 --> 00:48:29.696 A:middle
define where it is in the scene.

00:48:29.876 --> 00:48:31.266 A:middle
Extracted objects are fully

00:48:31.266 --> 00:48:33.126 A:middle
supported by Xcode's asset

00:48:33.126 --> 00:48:34.736 A:middle
catalog, so it makes it really

00:48:34.736 --> 00:48:38.486 A:middle
easy to port them to a new app

00:48:38.556 --> 00:48:40.756 A:middle
and reuse them as many times as

00:48:40.756 --> 00:48:41.116 A:middle
you want.

00:48:42.606 --> 00:48:43.986 A:middle
And for scanning, we added a new

00:48:43.986 --> 00:48:45.266 A:middle
configuration, the

00:48:45.266 --> 00:48:46.696 A:middle
ARObjectScanningConfiguration.

00:48:48.156 --> 00:48:49.896 A:middle
But you do not need to go ahead

00:48:49.896 --> 00:48:51.246 A:middle
and implement your own scanning

00:48:51.246 --> 00:48:53.826 A:middle
app as the full sample code is

00:48:53.826 --> 00:48:55.386 A:middle
available for full-featured

00:48:55.486 --> 00:48:57.616 A:middle
scanning app called Scanning and

00:48:57.616 --> 00:48:58.746 A:middle
Detecting 3D Objects.

00:49:00.186 --> 00:49:01.356 A:middle
So let's have a look how this

00:49:01.396 --> 00:49:02.066 A:middle
app works.

00:49:02.756 --> 00:49:04.396 A:middle
I start by creating a bounding

00:49:04.396 --> 00:49:05.786 A:middle
box around the object of

00:49:05.786 --> 00:49:07.136 A:middle
interest, in this case, the

00:49:07.136 --> 00:49:07.976 A:middle
statue of Nefertiti.

00:49:07.976 --> 00:49:10.486 A:middle
Note that the bounding box does

00:49:10.486 --> 00:49:11.856 A:middle
not need to be really strict

00:49:11.856 --> 00:49:12.616 A:middle
around the object.

00:49:12.896 --> 00:49:14.806 A:middle
All we care is that the most

00:49:14.806 --> 00:49:16.626 A:middle
important feature points are

00:49:16.766 --> 00:49:17.716 A:middle
within its bounds.

00:49:19.226 --> 00:49:20.166 A:middle
When I'm satisfied with the

00:49:20.166 --> 00:49:23.366 A:middle
bounding box, I can click press

00:49:23.516 --> 00:49:26.056 A:middle
scan, and we start scanning the

00:49:26.056 --> 00:49:26.416 A:middle
object.

00:49:27.106 --> 00:49:28.326 A:middle
I can see the progress going up

00:49:28.326 --> 00:49:30.216 A:middle
and this tile representation

00:49:30.916 --> 00:49:32.446 A:middle
indicating how much of the

00:49:32.446 --> 00:49:33.976 A:middle
object has been scanned in a

00:49:33.976 --> 00:49:34.736 A:middle
spatial manner.

00:49:35.946 --> 00:49:37.066 A:middle
Note that you do not have to

00:49:37.166 --> 00:49:38.566 A:middle
scan the object from all sides.

00:49:39.546 --> 00:49:41.336 A:middle
For example, if you know that a

00:49:41.436 --> 00:49:43.496 A:middle
statue will be facing a wall in

00:49:43.496 --> 00:49:46.426 A:middle
a museum, and there is no way

00:49:46.426 --> 00:49:47.626 A:middle
that you could detect it from

00:49:47.626 --> 00:49:49.546 A:middle
one specific viewpoint, you do

00:49:49.546 --> 00:49:51.626 A:middle
not need to scan it from that

00:49:52.636 --> 00:49:52.756 A:middle
side.

00:49:53.426 --> 00:49:55.156 A:middle
Once you're satisfied with the

00:49:55.226 --> 00:50:00.126 A:middle
scan, you can adjust the center

00:49:55.226 --> 00:50:00.126 A:middle
scan, you can adjust the center

00:50:00.226 --> 00:50:02.186 A:middle
of the extent which corresponds

00:50:02.186 --> 00:50:03.336 A:middle
to the origin of the object.

00:50:04.346 --> 00:50:05.516 A:middle
The only requirement here is

00:50:05.516 --> 00:50:07.446 A:middle
that the center stays within the

00:50:07.446 --> 00:50:08.336 A:middle
object's extent.

00:50:09.006 --> 00:50:12.026 A:middle
And lastly, the scanning app

00:50:12.026 --> 00:50:13.736 A:middle
lets you perform detection

00:50:13.736 --> 00:50:13.886 A:middle
tests.

00:50:14.216 --> 00:50:16.696 A:middle
So in this case, detection was

00:50:16.696 --> 00:50:18.286 A:middle
successful from various

00:50:18.286 --> 00:50:19.906 A:middle
viewpoints, which means it's a

00:50:19.906 --> 00:50:20.406 A:middle
good scan.

00:50:21.766 --> 00:50:22.796 A:middle
And our recommendation here is

00:50:22.796 --> 00:50:24.796 A:middle
also to move the object to

00:50:24.796 --> 00:50:27.186 A:middle
different location to test

00:50:27.186 --> 00:50:29.676 A:middle
whether detection works with

00:50:29.676 --> 00:50:31.046 A:middle
different texture and under

00:50:31.046 --> 00:50:32.046 A:middle
different lighting conditions.

00:50:34.476 --> 00:50:35.926 A:middle
Once you're done scanning, you

00:50:35.926 --> 00:50:37.186 A:middle
will obtain an object of type

00:50:37.296 --> 00:50:39.926 A:middle
ARReferenceObject, which we have

00:50:40.286 --> 00:50:41.306 A:middle
seen earlier in the diagram.

00:50:42.296 --> 00:50:44.816 A:middle
This object can be serialized to

00:50:44.816 --> 00:50:46.286 A:middle
usually and AR object file

00:50:46.286 --> 00:50:46.956 A:middle
extension type.

00:50:47.636 --> 00:50:49.306 A:middle
It has a name, which will also

00:50:49.306 --> 00:50:51.856 A:middle
be visible in your asset catalog

00:50:52.386 --> 00:50:53.576 A:middle
as well as the center and the

00:50:53.576 --> 00:50:55.236 A:middle
extent used for scanning it.

00:50:56.146 --> 00:50:57.666 A:middle
And you will also get all the

00:50:57.666 --> 00:51:00.016 A:middle
raw feature points found within

00:50:57.666 --> 00:51:00.016 A:middle
raw feature points found within

00:51:00.016 --> 00:51:02.236 A:middle
the area when you performed your

00:51:02.326 --> 00:51:02.486 A:middle
scan.

00:51:05.386 --> 00:51:06.686 A:middle
So this was object detection.

00:51:07.256 --> 00:51:08.896 A:middle
Keep in mind, before detection

00:51:08.896 --> 00:51:10.616 A:middle
object, you need to scan them,

00:51:10.616 --> 00:51:11.956 A:middle
but there is the full source

00:51:11.956 --> 00:51:13.196 A:middle
code available for you to

00:51:13.196 --> 00:51:16.286 A:middle
download it right now.

00:51:16.406 --> 00:51:18.926 A:middle
So let's talk next about face

00:51:18.926 --> 00:51:19.266 A:middle
tracking.

00:51:24.546 --> 00:51:26.296 A:middle
When we released the iPhone X

00:51:26.296 --> 00:51:28.166 A:middle
last year, we added robust face

00:51:28.166 --> 00:51:29.776 A:middle
detection and tracking to ARKit.

00:51:30.746 --> 00:51:32.276 A:middle
Here, ARKit estimates the

00:51:32.276 --> 00:51:33.816 A:middle
position and orientation of a

00:51:33.876 --> 00:51:36.186 A:middle
face for every frame at 60

00:51:36.186 --> 00:51:37.006 A:middle
frames per second.

00:51:37.826 --> 00:51:39.586 A:middle
Here we can use the, this pose

00:51:39.586 --> 00:51:41.576 A:middle
can be used to augment a user's

00:51:41.576 --> 00:51:44.206 A:middle
face by adding masks, hats, or

00:51:44.206 --> 00:51:45.746 A:middle
replace the full texture of a

00:51:46.776 --> 00:51:46.906 A:middle
face.

00:51:47.816 --> 00:51:48.956 A:middle
ARKit also provides you with a

00:51:48.956 --> 00:51:50.536 A:middle
fitted triangle mesh coming to

00:51:50.536 --> 00:51:52.016 A:middle
form of the ARFaceGeometry.

00:51:52.566 --> 00:51:56.136 A:middle
This type, the ARFaceGeometry,

00:51:56.136 --> 00:51:57.636 A:middle
contains all the information

00:51:57.636 --> 00:51:59.326 A:middle
needed to render this facial

00:51:59.326 --> 00:52:01.916 A:middle
mesh, and it comes in the form

00:51:59.326 --> 00:52:01.916 A:middle
mesh, and it comes in the form

00:52:01.976 --> 00:52:05.566 A:middle
of all vertices, triangles, as

00:52:05.566 --> 00:52:07.296 A:middle
well as detection coordinates.

00:52:08.556 --> 00:52:10.356 A:middle
The main anchor type of face

00:52:10.356 --> 00:52:12.186 A:middle
tracking is ARFaceAnchor, which

00:52:12.186 --> 00:52:13.876 A:middle
contains all information needed

00:52:13.876 --> 00:52:15.266 A:middle
to perform face tracking.

00:52:16.666 --> 00:52:18.486 A:middle
And in order to render such

00:52:18.486 --> 00:52:20.886 A:middle
geometry realistically, we added

00:52:20.956 --> 00:52:22.506 A:middle
a directional light estimate.

00:52:23.616 --> 00:52:25.426 A:middle
Here, ARKit uses your light as a

00:52:25.426 --> 00:52:27.786 A:middle
light probe and estimates this

00:52:28.616 --> 00:52:30.986 A:middle
ARDirectionLightEstimate, which

00:52:31.316 --> 00:52:33.026 A:middle
consists of the light intensity,

00:52:33.176 --> 00:52:34.696 A:middle
direction, as well as the color

00:52:34.696 --> 00:52:35.096 A:middle
temperature.

00:52:36.086 --> 00:52:39.066 A:middle
This estimate will be sufficient

00:52:39.346 --> 00:52:41.406 A:middle
to make most apps already look

00:52:41.506 --> 00:52:43.456 A:middle
great, but if your app has more

00:52:43.456 --> 00:52:45.896 A:middle
sophisticated needs, we also

00:52:45.896 --> 00:52:47.686 A:middle
provide the second-degree

00:52:47.686 --> 00:52:48.986 A:middle
spherical harmonics coefficients

00:52:49.396 --> 00:52:51.046 A:middle
that gather lighting conditions

00:52:51.086 --> 00:52:53.266 A:middle
throughout the entire scene for

00:52:53.356 --> 00:52:55.606 A:middle
you to make your content even

00:52:56.216 --> 00:52:57.726 A:middle
look better.

00:52:57.926 --> 00:52:59.106 A:middle
And ARKit can also track

00:52:59.106 --> 00:53:00.426 A:middle
expressions in real-time.

00:52:59.106 --> 00:53:00.426 A:middle
expressions in real-time.

00:53:01.176 --> 00:53:02.436 A:middle
These expressions are so-called

00:53:02.806 --> 00:53:05.236 A:middle
blend shapes, and there's 50 or

00:53:05.306 --> 00:53:06.616 A:middle
more of them.

00:53:08.186 --> 00:53:09.296 A:middle
Such a blend shape assume a

00:53:09.296 --> 00:53:10.516 A:middle
value between 0 and 1.

00:53:11.236 --> 00:53:12.356 A:middle
One means there's full

00:53:12.356 --> 00:53:13.116 A:middle
activation.

00:53:13.116 --> 00:53:13.856 A:middle
Zero means there is none.

00:53:14.386 --> 00:53:15.666 A:middle
For example, the jaw

00:53:15.666 --> 00:53:17.836 A:middle
open coefficient will assume a

00:53:17.836 --> 00:53:19.156 A:middle
value close to 1 if I open my

00:53:19.156 --> 00:53:20.796 A:middle
mouth and a value close to 0 if

00:53:20.796 --> 00:53:21.236 A:middle
I close it.

00:53:22.106 --> 00:53:24.456 A:middle
And this is great to animate

00:53:24.456 --> 00:53:25.416 A:middle
your own virtual character.

00:53:26.186 --> 00:53:27.706 A:middle
This example here, I've used the

00:53:27.706 --> 00:53:29.466 A:middle
jaw open and eye blink left and

00:53:29.466 --> 00:53:31.236 A:middle
eye blink right to animate this

00:53:31.236 --> 00:53:32.276 A:middle
really simple box face

00:53:32.276 --> 00:53:32.616 A:middle
character.

00:53:34.156 --> 00:53:35.276 A:middle
But it can do better than that.

00:53:36.286 --> 00:53:38.156 A:middle
In fact, when we built Animoji,

00:53:38.156 --> 00:53:39.856 A:middle
we used a handful more of such

00:53:39.856 --> 00:53:40.406 A:middle
blend shapes.

00:53:41.176 --> 00:53:42.256 A:middle
So all the blue bars you see

00:53:42.256 --> 00:53:44.446 A:middle
moving here were used to get

00:53:44.446 --> 00:53:46.106 A:middle
over the head post to map my

00:53:46.106 --> 00:53:47.856 A:middle
facial expressions on the panda

00:53:47.856 --> 00:53:48.076 A:middle
bear.

00:53:49.706 --> 00:53:50.986 A:middle
Note that ARKit offers

00:53:51.056 --> 00:53:52.616 A:middle
everything needed for you to

00:53:52.616 --> 00:53:54.896 A:middle
animate your own character just

00:53:54.896 --> 00:53:56.086 A:middle
like we did with Animoji.

00:53:56.696 --> 00:53:58.036 A:middle
Thank you.

00:53:59.516 --> 00:54:04.276 A:middle
[ Applause ]

00:53:59.516 --> 00:54:04.276 A:middle
[ Applause ]

00:54:04.776 --> 00:54:06.196 A:middle
So let's see what's new for face

00:54:06.196 --> 00:54:07.736 A:middle
tracking in ARKit 2.

00:54:08.736 --> 00:54:11.106 A:middle
We added gaze tracking that will

00:54:11.106 --> 00:54:12.826 A:middle
track the left and the right eye

00:54:12.966 --> 00:54:15.326 A:middle
both in six degrees of freedom.

00:54:16.516 --> 00:54:21.046 A:middle
[ Applause ]

00:54:21.546 --> 00:54:22.646 A:middle
You will find these properties

00:54:22.646 --> 00:54:24.956 A:middle
as members of ARFaceAnchor as

00:54:24.956 --> 00:54:26.516 A:middle
well as a look-at point, this

00:54:26.516 --> 00:54:28.346 A:middle
corresponds to reintersection of

00:54:28.346 --> 00:54:29.316 A:middle
the two gaze directions.

00:54:30.326 --> 00:54:32.256 A:middle
You may use this information to

00:54:32.296 --> 00:54:34.076 A:middle
animate again your own character

00:54:34.496 --> 00:54:36.456 A:middle
or of any other form of input to

00:54:36.456 --> 00:54:36.796 A:middle
your app.

00:54:36.796 --> 00:54:38.446 A:middle
And there's more.

00:54:39.716 --> 00:54:40.816 A:middle
We added support for tongue,

00:54:42.176 --> 00:54:43.186 A:middle
which comes in the form of a new

00:54:43.186 --> 00:54:43.746 A:middle
blend shape.

00:54:44.636 --> 00:54:45.566 A:middle
This blend shape will assume a

00:54:45.566 --> 00:54:47.786 A:middle
value of 1 if my tongue is out 0

00:54:48.096 --> 00:54:48.516 A:middle
if not.

00:54:49.516 --> 00:54:51.276 A:middle
Again, you could use this to

00:54:51.276 --> 00:54:53.086 A:middle
animate your own character or

00:54:53.086 --> 00:54:55.896 A:middle
use this as a form of input to

00:54:55.896 --> 00:54:56.946 A:middle
your app.

00:55:00.636 --> 00:55:01.086 A:middle
Thank you.

00:55:01.821 --> 00:55:03.821 A:middle
[ Applause ]

00:55:04.126 --> 00:55:05.216 A:middle
So seeing myself sticking my

00:55:05.216 --> 00:55:06.766 A:middle
tongue out over and over is a

00:55:06.766 --> 00:55:07.936 A:middle
good time for summary.

00:55:09.086 --> 00:55:11.796 A:middle
So, what's new in ARKit 2.

00:55:11.796 --> 00:55:12.966 A:middle
Let's have a look.

00:55:13.816 --> 00:55:15.306 A:middle
We've seen saving and loading

00:55:15.306 --> 00:55:16.606 A:middle
maps, which are powerful new

00:55:16.606 --> 00:55:18.016 A:middle
features for persistence and

00:55:18.206 --> 00:55:20.436 A:middle
multiuser collaboration.

00:55:21.726 --> 00:55:23.086 A:middle
World tracking enhancements

00:55:23.506 --> 00:55:25.236 A:middle
simply shows better and fasting

00:55:25.236 --> 00:55:27.746 A:middle
plane detection as well as new

00:55:27.746 --> 00:55:29.356 A:middle
video formats.

00:55:29.566 --> 00:55:31.056 A:middle
And with environment texturing,

00:55:31.726 --> 00:55:34.256 A:middle
we can make the content really

00:55:34.506 --> 00:55:35.876 A:middle
look as if it was really in the

00:55:35.976 --> 00:55:38.526 A:middle
scene by gathering texture of

00:55:38.526 --> 00:55:39.876 A:middle
the scene and applying it as a

00:55:39.906 --> 00:55:40.616 A:middle
textured object.

00:55:41.846 --> 00:55:44.136 A:middle
And with image tracking, with

00:55:44.836 --> 00:55:48.196 A:middle
image tracking, we are now able

00:55:48.196 --> 00:55:50.516 A:middle
to track 2D objects in the form

00:55:50.516 --> 00:55:50.986 A:middle
of images.

00:55:51.506 --> 00:55:53.236 A:middle
But ARKit can also detect 3D

00:55:53.236 --> 00:55:53.586 A:middle
objects.

00:55:54.576 --> 00:55:56.386 A:middle
And for face tracking, we have

00:55:56.916 --> 00:55:59.116 A:middle
gaze and tongue.

00:55:59.926 --> 00:56:01.226 A:middle
All of this is made available

00:55:59.926 --> 00:56:01.226 A:middle
All of this is made available

00:56:01.226 --> 00:56:02.736 A:middle
for you in the form of the

00:56:02.736 --> 00:56:04.256 A:middle
building blocks of ARKit.

00:56:05.336 --> 00:56:08.016 A:middle
In iOS 12, ARKit features five

00:56:08.066 --> 00:56:09.456 A:middle
different configurations with

00:56:09.456 --> 00:56:10.876 A:middle
two new additions, the

00:56:10.876 --> 00:56:12.556 A:middle
ARImageTrackingConfiguration for

00:56:12.556 --> 00:56:15.116 A:middle
stand-alone image tracking and

00:56:15.196 --> 00:56:15.306 A:middle
the

00:56:15.306 --> 00:56:16.766 A:middle
ARObjectScanningConfiguration.

00:56:18.056 --> 00:56:19.146 A:middle
And there's a series of

00:56:19.746 --> 00:56:21.456 A:middle
supplementary types used to

00:56:21.456 --> 00:56:22.716 A:middle
interact with the AR session.

00:56:23.426 --> 00:56:25.036 A:middle
The ARFrame, the ARCamera, for

00:56:25.166 --> 00:56:25.486 A:middle
example.

00:56:26.686 --> 00:56:27.906 A:middle
And this got two new additions,

00:56:27.996 --> 00:56:29.546 A:middle
the ARReferenceObject for object

00:56:29.546 --> 00:56:31.706 A:middle
detection and the ARWorldMap for

00:56:31.766 --> 00:56:33.366 A:middle
persistence and multiuser.

00:56:33.896 --> 00:56:36.306 A:middle
And the AR anchors, which

00:56:36.306 --> 00:56:37.836 A:middle
represent positions in the real

00:56:37.836 --> 00:56:39.276 A:middle
world, the anchor types.

00:56:39.586 --> 00:56:41.166 A:middle
Got two new additions, the

00:56:41.166 --> 00:56:43.016 A:middle
ARObjectAnchor and the

00:56:43.016 --> 00:56:44.176 A:middle
AREnvironmentProbeAnchor.

00:56:45.236 --> 00:56:46.976 A:middle
I'm really excited to see what

00:56:46.976 --> 00:56:48.156 A:middle
you guys will build with all

00:56:48.156 --> 00:56:49.226 A:middle
these building blocks in the

00:56:49.226 --> 00:56:51.886 A:middle
ARKit available in iOS 12 as of

00:56:51.936 --> 00:56:52.176 A:middle
today.

00:56:54.516 --> 00:57:00.506 A:middle
[ Applause ]

00:56:54.516 --> 00:57:00.506 A:middle
[ Applause ]

00:57:01.006 --> 00:57:01.846 A:middle
There's another real cool

00:57:01.906 --> 00:57:03.286 A:middle
session about integrating

00:57:03.286 --> 00:57:04.656 A:middle
ARQuickLook into your own

00:57:04.656 --> 00:57:06.596 A:middle
application to make your content

00:57:06.596 --> 00:57:07.396 A:middle
look simply great.

00:57:09.026 --> 00:57:11.396 A:middle
With this, thanks a lot, and

00:57:11.396 --> 00:57:11.906 A:middle
enjoy the rest of the

00:57:11.906 --> 00:57:12.256 A:middle
conference.

00:57:13.508 --> 00:57:15.508 A:middle
[ Applause ]
