WEBVTT

00:00:06.516 --> 00:00:15.500 A:middle
[ Music ]

00:00:21.836 --> 00:00:23.076 A:middle
&gt;&gt; [Applause] Hey, everyone.

00:00:25.266 --> 00:00:25.736 A:middle
[Applause] Thank you.

00:00:25.736 --> 00:00:27.126 A:middle
Good afternoon, and welcome to

00:00:27.126 --> 00:00:28.726 A:middle
our session on Turi Create.

00:00:30.286 --> 00:00:31.676 A:middle
This session builds upon

00:00:31.676 --> 00:00:33.236 A:middle
yesterday's session on Create

00:00:33.236 --> 00:00:33.586 A:middle
ML.

00:00:34.076 --> 00:00:35.316 A:middle
That session covered many of the

00:00:35.316 --> 00:00:36.826 A:middle
foundations of machine learning

00:00:36.826 --> 00:00:37.336 A:middle
in Swift.

00:00:37.336 --> 00:00:38.596 A:middle
So if you didn't catch that

00:00:38.596 --> 00:00:40.006 A:middle
session I do recommend you add

00:00:40.006 --> 00:00:40.916 A:middle
it to your watch list.

00:00:42.486 --> 00:00:44.396 A:middle
The goal of Turi Create is to

00:00:44.396 --> 00:00:46.236 A:middle
help you add intelligent user

00:00:46.236 --> 00:00:48.866 A:middle
experiences to your apps.

00:00:49.516 --> 00:00:51.516 A:middle
For example, you might want to

00:00:51.516 --> 00:00:52.606 A:middle
be able to take a picture of

00:00:52.606 --> 00:00:53.266 A:middle
your breakfast.

00:00:53.526 --> 00:00:54.916 A:middle
And tap on the different food

00:00:54.916 --> 00:00:56.726 A:middle
items to see how many calories

00:00:56.726 --> 00:00:57.386 A:middle
you're consuming.

00:00:59.076 --> 00:01:01.136 A:middle
Or maybe you want to control a

00:00:59.076 --> 00:01:01.136 A:middle
Or maybe you want to control a

00:01:01.136 --> 00:01:03.496 A:middle
lightbulb using your iPhone and

00:01:03.496 --> 00:01:04.486 A:middle
simple gestures.

00:01:07.356 --> 00:01:08.736 A:middle
Maybe you want to track an

00:01:08.736 --> 00:01:11.096 A:middle
object in real time like a dog

00:01:11.156 --> 00:01:12.866 A:middle
or a picture of a dog if you

00:01:12.866 --> 00:01:13.976 A:middle
don't have dogs in the office.

00:01:14.516 --> 00:01:17.266 A:middle
[ Laughter ]

00:01:17.766 --> 00:01:20.116 A:middle
Maybe you have custom avatars in

00:01:20.116 --> 00:01:21.566 A:middle
your game, and you want to

00:01:21.696 --> 00:01:22.516 A:middle
provide personalized

00:01:22.516 --> 00:01:24.136 A:middle
recommendations like hairstyles

00:01:24.496 --> 00:01:26.186 A:middle
based on the beard that the user

00:01:26.186 --> 00:01:26.826 A:middle
has selected.

00:01:28.216 --> 00:01:29.676 A:middle
Or maybe you want to let your

00:01:29.676 --> 00:01:31.846 A:middle
users apply artistic styles or

00:01:31.846 --> 00:01:33.756 A:middle
filters to their own photos.

00:01:35.096 --> 00:01:37.056 A:middle
These are very different user

00:01:37.056 --> 00:01:37.806 A:middle
experiences.

00:01:38.256 --> 00:01:39.756 A:middle
But they have several things in

00:01:39.756 --> 00:01:40.136 A:middle
common.

00:01:41.046 --> 00:01:42.836 A:middle
First and foremost, they use

00:01:42.836 --> 00:01:43.536 A:middle
machine learning.

00:01:44.846 --> 00:01:46.556 A:middle
These experiences all require

00:01:46.556 --> 00:01:49.906 A:middle
very little data to create.

00:01:50.036 --> 00:01:51.516 A:middle
All these models were made with

00:01:51.516 --> 00:01:53.646 A:middle
Turi Create and deployed with

00:01:53.646 --> 00:01:54.186 A:middle
Core ML.

00:01:55.656 --> 00:01:57.176 A:middle
They all follow the five, the

00:01:57.176 --> 00:01:59.096 A:middle
same five-step recipe that we'll

00:01:59.096 --> 00:02:00.226 A:middle
go over today.

00:01:59.096 --> 00:02:00.226 A:middle
go over today.

00:02:01.776 --> 00:02:02.906 A:middle
And all these demo apps will

00:02:02.906 --> 00:02:04.366 A:middle
also be available in our labs.

00:02:04.366 --> 00:02:06.056 A:middle
So please join us today or

00:02:06.056 --> 00:02:08.326 A:middle
Friday for the ML labs to get

00:02:08.326 --> 00:02:09.376 A:middle
hands-on experience.

00:02:11.696 --> 00:02:14.026 A:middle
Turi Create is a Python package

00:02:14.436 --> 00:02:15.846 A:middle
that helps you create Core ML

00:02:15.846 --> 00:02:16.186 A:middle
models.

00:02:17.436 --> 00:02:19.446 A:middle
It's easy to use, so you don't

00:02:19.446 --> 00:02:20.816 A:middle
need to be an ML expert or even

00:02:20.816 --> 00:02:22.066 A:middle
have a background in machine

00:02:22.066 --> 00:02:23.326 A:middle
learning to create these

00:02:23.326 --> 00:02:24.676 A:middle
exciting user experiences.

00:02:25.626 --> 00:02:27.366 A:middle
We make it easy to use by

00:02:27.366 --> 00:02:29.646 A:middle
focusing on tasks first and

00:02:29.646 --> 00:02:30.206 A:middle
foremost.

00:02:30.206 --> 00:02:31.576 A:middle
What we do is we abstract away

00:02:31.576 --> 00:02:32.906 A:middle
the complicated machine-learning

00:02:32.906 --> 00:02:34.776 A:middle
algorithms so you can just focus

00:02:34.776 --> 00:02:35.866 A:middle
on the user experience that

00:02:35.866 --> 00:02:36.746 A:middle
you're trying to create.

00:02:38.056 --> 00:02:39.796 A:middle
Turi Create is cross platform so

00:02:39.796 --> 00:02:41.836 A:middle
you can use it both on Mac and

00:02:41.836 --> 00:02:42.226 A:middle
Linux.

00:02:43.066 --> 00:02:44.436 A:middle
And it's also open source.

00:02:45.726 --> 00:02:47.446 A:middle
We have a repo on GitHub and we

00:02:47.446 --> 00:02:48.056 A:middle
hope you'll visit.

00:02:48.056 --> 00:02:49.406 A:middle
There's a lot of great resources

00:02:49.406 --> 00:02:50.186 A:middle
to get started.

00:02:51.456 --> 00:02:52.786 A:middle
And we look forward to working

00:02:52.786 --> 00:02:54.156 A:middle
with you and the rest of the

00:02:54.156 --> 00:02:55.716 A:middle
developer community to make Turi

00:02:55.716 --> 00:02:57.856 A:middle
Create even better over time.

00:02:58.676 --> 00:03:00.276 A:middle
Today we're excited to announce

00:02:58.676 --> 00:03:00.276 A:middle
Today we're excited to announce

00:03:00.276 --> 00:03:01.886 A:middle
that the beta release of Turi

00:03:01.886 --> 00:03:04.216 A:middle
Create 5.0 is now available.

00:03:04.986 --> 00:03:06.026 A:middle
This has some powerful new

00:03:06.026 --> 00:03:06.576 A:middle
features.

00:03:06.896 --> 00:03:08.336 A:middle
Like GPU acceleration.

00:03:08.556 --> 00:03:09.846 A:middle
And we'll go into these features

00:03:09.846 --> 00:03:11.396 A:middle
in detail later on today.

00:03:12.776 --> 00:03:14.756 A:middle
The main focus today is going to

00:03:14.756 --> 00:03:17.086 A:middle
be the five-step recipe for

00:03:17.086 --> 00:03:18.366 A:middle
creating Core ML models.

00:03:18.746 --> 00:03:20.306 A:middle
I'm going to start by going over

00:03:20.306 --> 00:03:21.676 A:middle
these steps at a high level.

00:03:22.086 --> 00:03:23.196 A:middle
And then we'll dive into some

00:03:23.196 --> 00:03:24.486 A:middle
demos and code.

00:03:25.026 --> 00:03:28.746 A:middle
So the first step you need is to

00:03:28.746 --> 00:03:30.166 A:middle
understand the task you're

00:03:30.166 --> 00:03:31.126 A:middle
trying to accomplish.

00:03:31.566 --> 00:03:33.276 A:middle
And how we refer to that task in

00:03:33.276 --> 00:03:34.316 A:middle
machine learning terms.

00:03:35.686 --> 00:03:37.536 A:middle
Second, you need to understand

00:03:37.866 --> 00:03:39.656 A:middle
the type of data you need for

00:03:39.656 --> 00:03:40.616 A:middle
this task.

00:03:41.026 --> 00:03:42.526 A:middle
And how much of it.

00:03:43.696 --> 00:03:45.876 A:middle
Third, you need to create your

00:03:45.876 --> 00:03:46.156 A:middle
model.

00:03:48.056 --> 00:03:50.096 A:middle
Fourth, you need to evaluate

00:03:50.096 --> 00:03:50.626 A:middle
that model.

00:03:50.766 --> 00:03:52.066 A:middle
That means understanding the

00:03:52.066 --> 00:03:53.536 A:middle
quality of the model and wheth--

00:03:53.536 --> 00:03:54.416 A:middle
whether it's ready for

00:03:54.416 --> 00:03:54.926 A:middle
production.

00:03:56.106 --> 00:03:57.946 A:middle
And finally, when your model's

00:03:57.946 --> 00:03:59.566 A:middle
ready to deploy, it's really

00:03:59.566 --> 00:04:00.856 A:middle
easy using Core ML.

00:03:59.566 --> 00:04:00.856 A:middle
easy using Core ML.

00:04:02.356 --> 00:04:04.066 A:middle
Let's dig a bit deeper into each

00:04:04.066 --> 00:04:04.786 A:middle
of these steps.

00:04:06.076 --> 00:04:07.656 A:middle
Turi Create lets you accomplish

00:04:07.656 --> 00:04:09.816 A:middle
a wide variety of common machine

00:04:09.816 --> 00:04:10.566 A:middle
learning tasks.

00:04:10.836 --> 00:04:11.976 A:middle
And you can work with many

00:04:11.976 --> 00:04:13.306 A:middle
different types of data.

00:04:13.926 --> 00:04:16.296 A:middle
For example, if you have images,

00:04:16.616 --> 00:04:17.796 A:middle
you might be interested in image

00:04:17.796 --> 00:04:18.646 A:middle
classification.

00:04:18.805 --> 00:04:19.815 A:middle
Or object detection.

00:04:20.856 --> 00:04:21.805 A:middle
You might want to provide

00:04:21.805 --> 00:04:23.216 A:middle
personalized recommendations for

00:04:23.216 --> 00:04:23.796 A:middle
your users.

00:04:24.976 --> 00:04:25.876 A:middle
You might want to be able to

00:04:25.876 --> 00:04:27.756 A:middle
detect automatically activities

00:04:27.756 --> 00:04:30.226 A:middle
like walking or jumping jacks.

00:04:30.416 --> 00:04:33.056 A:middle
You might want to understand

00:04:33.056 --> 00:04:34.986 A:middle
user sentiment given a block of

00:04:35.016 --> 00:04:35.426 A:middle
text.

00:04:36.256 --> 00:04:37.606 A:middle
Or you might be interested in

00:04:37.606 --> 00:04:39.006 A:middle
more traditional machine

00:04:39.006 --> 00:04:40.306 A:middle
learning algorithms like

00:04:40.306 --> 00:04:42.316 A:middle
classification and regression.

00:04:44.636 --> 00:04:46.316 A:middle
Now we know this can get really

00:04:46.316 --> 00:04:47.806 A:middle
confusing to those of you who

00:04:47.806 --> 00:04:49.236 A:middle
are new to machine learning.

00:04:49.696 --> 00:04:51.906 A:middle
So we've taken a stab at making

00:04:51.906 --> 00:04:52.976 A:middle
this really easy for you in our

00:04:52.976 --> 00:04:53.866 A:middle
documentation.

00:04:54.266 --> 00:04:55.496 A:middle
We begin by helping you

00:04:55.496 --> 00:04:56.986 A:middle
understand the types of tasks

00:04:57.286 --> 00:04:59.156 A:middle
that are possible and then how

00:04:59.156 --> 00:05:00.436 A:middle
we reference them in machine

00:04:59.156 --> 00:05:00.436 A:middle
we reference them in machine

00:05:00.436 --> 00:05:01.176 A:middle
learning terms.

00:05:01.716 --> 00:05:03.196 A:middle
So what we can do now is revisit

00:05:03.196 --> 00:05:04.596 A:middle
those intelligent experiences

00:05:04.596 --> 00:05:05.326 A:middle
that we walked through at the

00:05:05.326 --> 00:05:06.606 A:middle
beginning of this presentation

00:05:06.956 --> 00:05:08.176 A:middle
and assign them to these machine

00:05:08.176 --> 00:05:09.026 A:middle
learning tasks.

00:05:09.626 --> 00:05:10.856 A:middle
For example, if you want to

00:05:10.856 --> 00:05:12.616 A:middle
recognize different types of

00:05:12.616 --> 00:05:14.676 A:middle
flowers in photos we call that

00:05:14.676 --> 00:05:15.826 A:middle
image classification.

00:05:17.236 --> 00:05:19.136 A:middle
If you want to take pictures of

00:05:19.406 --> 00:05:20.766 A:middle
your breakfast and understand

00:05:20.766 --> 00:05:22.096 A:middle
the different food objects

00:05:22.096 --> 00:05:24.066 A:middle
within them, we call them, that

00:05:24.066 --> 00:05:24.876 A:middle
object detection.

00:05:25.436 --> 00:05:27.986 A:middle
If you want to apply artistic

00:05:27.986 --> 00:05:30.246 A:middle
styles to your own photos, we

00:05:30.246 --> 00:05:31.546 A:middle
call that style transfer.

00:05:33.606 --> 00:05:35.256 A:middle
And if you want to recognize

00:05:35.356 --> 00:05:37.046 A:middle
gestures or motions or different

00:05:37.046 --> 00:05:38.816 A:middle
activities using sensors of

00:05:38.816 --> 00:05:40.556 A:middle
different devices, we call that

00:05:40.556 --> 00:05:41.896 A:middle
activity classification.

00:05:43.996 --> 00:05:45.616 A:middle
Finally, if you want to make

00:05:45.656 --> 00:05:46.906 A:middle
personalized recommendations to

00:05:46.906 --> 00:05:48.886 A:middle
your users, we call this task

00:05:49.106 --> 00:05:50.086 A:middle
recommender systems.

00:05:50.766 --> 00:05:53.936 A:middle
Now the great thing is that the

00:05:53.936 --> 00:05:55.756 A:middle
same five-step recipe we just

00:05:55.756 --> 00:05:57.596 A:middle
walked through also applies to

00:05:57.596 --> 00:05:58.106 A:middle
your code.

00:05:59.156 --> 00:06:00.786 A:middle
We begin by importing Turi

00:05:59.156 --> 00:06:00.786 A:middle
We begin by importing Turi

00:06:00.786 --> 00:06:01.236 A:middle
Create.

00:06:02.526 --> 00:06:04.796 A:middle
We proceed to load our data into

00:06:04.796 --> 00:06:06.046 A:middle
a data structure called an

00:06:06.046 --> 00:06:06.466 A:middle
SFrame.

00:06:06.816 --> 00:06:07.796 A:middle
And we'll go into a bit more

00:06:07.796 --> 00:06:09.156 A:middle
detail on the SFrame data

00:06:09.156 --> 00:06:10.006 A:middle
structure shortly.

00:06:10.486 --> 00:06:13.106 A:middle
We'll proceed to create our

00:06:13.106 --> 00:06:14.736 A:middle
model with a simple function,

00:06:14.816 --> 00:06:15.446 A:middle
.create.

00:06:15.966 --> 00:06:18.116 A:middle
This, this function extracts

00:06:18.116 --> 00:06:19.336 A:middle
away the complicated machine

00:06:19.336 --> 00:06:22.066 A:middle
learning behind the scenes.

00:06:22.956 --> 00:06:24.966 A:middle
We proceed to evaluate our model

00:06:24.966 --> 00:06:25.956 A:middle
with the simple function

00:06:26.176 --> 00:06:26.916 A:middle
.evaluate.

00:06:27.476 --> 00:06:30.266 A:middle
And finally we can export the

00:06:30.266 --> 00:06:32.586 A:middle
resulting model to Core ML's

00:06:32.626 --> 00:06:34.396 A:middle
ML-model format to be easily

00:06:34.396 --> 00:06:36.686 A:middle
dragged and dropped into Xcode.

00:06:37.356 --> 00:06:39.226 A:middle
Now I mentioned that this same

00:06:39.226 --> 00:06:41.166 A:middle
five-step template applies to

00:06:41.166 --> 00:06:42.866 A:middle
all the different tasks within

00:06:42.866 --> 00:06:43.506 A:middle
Turi Create.

00:06:44.296 --> 00:06:45.146 A:middle
So whether you're working on

00:06:45.146 --> 00:06:47.186 A:middle
object detection, image

00:06:47.186 --> 00:06:49.716 A:middle
classification or activity

00:06:49.716 --> 00:06:51.896 A:middle
classification, the same code

00:06:51.896 --> 00:06:52.806 A:middle
template applies.

00:06:52.806 --> 00:06:56.826 A:middle
For our first demo today, we're

00:06:57.066 --> 00:06:58.016 A:middle
going to walk through a

00:06:58.016 --> 00:06:59.846 A:middle
calorie-counting app that uses

00:06:59.846 --> 00:07:01.196 A:middle
an object detection model.

00:06:59.846 --> 00:07:01.196 A:middle
an object detection model.

00:07:01.746 --> 00:07:02.866 A:middle
So we'll want to recognize

00:07:03.186 --> 00:07:04.486 A:middle
different foods within an image.

00:07:04.726 --> 00:07:05.636 A:middle
And we'll need to know where

00:07:05.636 --> 00:07:07.046 A:middle
those, where in the image those

00:07:07.046 --> 00:07:08.396 A:middle
foods are so that we could tap

00:07:08.396 --> 00:07:09.346 A:middle
on them to see the different

00:07:09.346 --> 00:07:10.000 A:middle
calorie counts.

00:07:13.196 --> 00:07:14.636 A:middle
So let's take a look at the type

00:07:14.636 --> 00:07:16.036 A:middle
of data that we'll need to

00:07:16.036 --> 00:07:17.576 A:middle
create this machine learning

00:07:17.576 --> 00:07:17.846 A:middle
model.

00:07:18.436 --> 00:07:20.906 A:middle
Of course we need images.

00:07:20.906 --> 00:07:21.866 A:middle
And if we were just building a

00:07:21.866 --> 00:07:24.006 A:middle
simple image classifier model,

00:07:24.306 --> 00:07:25.286 A:middle
we would just need our set of

00:07:25.286 --> 00:07:27.316 A:middle
images and labels that describe

00:07:27.316 --> 00:07:28.356 A:middle
the images overall.

00:07:29.366 --> 00:07:30.506 A:middle
But because we're performing

00:07:30.746 --> 00:07:32.506 A:middle
object detection, we need a bit

00:07:32.506 --> 00:07:33.316 A:middle
more information.

00:07:33.956 --> 00:07:35.416 A:middle
We need to understand not just

00:07:35.416 --> 00:07:36.226 A:middle
what's in the image.

00:07:36.496 --> 00:07:37.766 A:middle
But where those objects are.

00:07:38.146 --> 00:07:40.126 A:middle
Now if we zoom in a bit closer

00:07:40.126 --> 00:07:42.596 A:middle
to one example, we see a red box

00:07:42.646 --> 00:07:43.756 A:middle
around a cup of coffee.

00:07:44.616 --> 00:07:45.866 A:middle
And a green box around a

00:07:45.866 --> 00:07:46.376 A:middle
croissant.

00:07:47.336 --> 00:07:48.916 A:middle
We call those boxes bounding

00:07:48.916 --> 00:07:50.996 A:middle
boxes and we represent those in

00:07:50.996 --> 00:07:51.936 A:middle
JSON format.

00:07:52.296 --> 00:07:53.806 A:middle
With a label, and then with

00:07:53.806 --> 00:07:55.796 A:middle
coordinates x, y, width and

00:07:55.796 --> 00:07:56.086 A:middle
height.

00:07:56.656 --> 00:07:58.186 A:middle
Where x and y refer to the

00:07:58.186 --> 00:07:59.926 A:middle
center of that bounding box.

00:08:00.216 --> 00:08:01.426 A:middle
So it's also worth noting that

00:08:01.426 --> 00:08:03.066 A:middle
with object detection, you can

00:08:03.066 --> 00:08:05.196 A:middle
reference or detect multiple

00:08:05.196 --> 00:08:07.486 A:middle
images, multiple objects within

00:08:07.486 --> 00:08:07.996 A:middle
each image.

00:08:07.996 --> 00:08:11.086 A:middle
So I mentioned that we'd be

00:08:11.086 --> 00:08:12.816 A:middle
loading our data into this

00:08:12.816 --> 00:08:14.246 A:middle
tabular data structure called an

00:08:14.246 --> 00:08:14.686 A:middle
SFrame.

00:08:15.406 --> 00:08:16.716 A:middle
And in this example, we will end

00:08:16.716 --> 00:08:17.926 A:middle
up with two columns.

00:08:18.136 --> 00:08:19.326 A:middle
The first column will contain

00:08:19.326 --> 00:08:19.836 A:middle
your images.

00:08:20.466 --> 00:08:22.086 A:middle
The second column will contain

00:08:22.086 --> 00:08:24.000 A:middle
your annotations in JSON format.

00:08:27.476 --> 00:08:29.306 A:middle
Let's or by now you're probably

00:08:29.306 --> 00:08:30.886 A:middle
wondering what is an SFrame?

00:08:30.886 --> 00:08:32.506 A:middle
So let's take a step back and,

00:08:32.506 --> 00:08:34.706 A:middle
and learn more about it.

00:08:34.706 --> 00:08:36.596 A:middle
SFrame is a [inaudible] tabular

00:08:36.596 --> 00:08:37.376 A:middle
data structure.

00:08:37.566 --> 00:08:39.006 A:middle
And what this means is you can

00:08:39.395 --> 00:08:40.976 A:middle
create machine learning models

00:08:40.976 --> 00:08:41.806 A:middle
on your laptop.

00:08:41.966 --> 00:08:43.015 A:middle
Even if you have enormous

00:08:43.015 --> 00:08:45.226 A:middle
amounts of data.

00:08:45.366 --> 00:08:46.656 A:middle
SFrame allows you to perform

00:08:46.656 --> 00:08:48.676 A:middle
common data manipulation tasks.

00:08:49.026 --> 00:08:50.816 A:middle
Like joining two SFrames or

00:08:50.816 --> 00:08:52.686 A:middle
filtering to specific rows or

00:08:52.686 --> 00:08:53.476 A:middle
columns of data.

00:08:55.296 --> 00:08:57.046 A:middle
SFrames let you work with all

00:08:57.046 --> 00:08:57.976 A:middle
different data types.

00:08:58.926 --> 00:08:59.986 A:middle
And once you have your data

00:09:00.046 --> 00:09:02.486 A:middle
loaded into an SFrame, it's easy

00:09:02.486 --> 00:09:04.446 A:middle
to visually explore and inspect

00:09:04.446 --> 00:09:05.000 A:middle
your data.

00:09:08.936 --> 00:09:10.426 A:middle
Let's zoom in a bit more on

00:09:10.426 --> 00:09:11.796 A:middle
what's possible with SFrame.

00:09:12.796 --> 00:09:13.946 A:middle
With our object detector

00:09:13.946 --> 00:09:14.396 A:middle
example.

00:09:15.446 --> 00:09:17.026 A:middle
So after we import Turi Create,

00:09:17.426 --> 00:09:18.436 A:middle
in the case of our object

00:09:18.436 --> 00:09:20.206 A:middle
detector, we're actually going

00:09:20.276 --> 00:09:21.606 A:middle
to load two different SFrames.

00:09:22.086 --> 00:09:23.406 A:middle
The first containing our

00:09:23.406 --> 00:09:25.526 A:middle
annotations, and the second

00:09:26.036 --> 00:09:27.166 A:middle
containing our images.

00:09:27.896 --> 00:09:29.556 A:middle
We have a simple function

00:09:29.556 --> 00:09:31.526 A:middle
.explore that will allow you to

00:09:31.526 --> 00:09:32.806 A:middle
visually inspect the data you've

00:09:32.806 --> 00:09:33.276 A:middle
imported.

00:09:34.276 --> 00:09:35.876 A:middle
We can do things like access

00:09:35.876 --> 00:09:36.896 A:middle
specific rows.

00:09:37.386 --> 00:09:38.496 A:middle
Or columns of our data.

00:09:39.866 --> 00:09:40.976 A:middle
And of course we can do common

00:09:40.976 --> 00:09:43.266 A:middle
operations like joining our two

00:09:43.266 --> 00:09:44.286 A:middle
SFrames into one.

00:09:44.826 --> 00:09:46.546 A:middle
And saving the resulting SFrame

00:09:46.986 --> 00:09:49.476 A:middle
for later use or to share with a

00:09:51.176 --> 00:09:51.356 A:middle
colleague.

00:09:51.486 --> 00:09:52.746 A:middle
Next we create our model.

00:09:53.146 --> 00:09:54.306 A:middle
So I mentioned we have this

00:09:54.396 --> 00:09:56.746 A:middle
simple function .create that

00:09:56.746 --> 00:09:58.126 A:middle
does all the heavy lifting for

00:09:58.126 --> 00:09:59.236 A:middle
the creation of the actual

00:09:59.236 --> 00:09:59.576 A:middle
model.

00:10:00.016 --> 00:10:01.486 A:middle
And what we do behind the scenes

00:10:01.486 --> 00:10:03.026 A:middle
is we ensure that the model we

00:10:03.026 --> 00:10:04.546 A:middle
create for you is customized to

00:10:04.546 --> 00:10:06.076 A:middle
the task and that it's state of

00:10:06.076 --> 00:10:06.496 A:middle
the art.

00:10:06.496 --> 00:10:07.916 A:middle
Meaning it's as high quality and

00:10:07.956 --> 00:10:10.016 A:middle
high accuracy as we can get.

00:10:10.016 --> 00:10:11.206 A:middle
And we're able to do this

00:10:11.206 --> 00:10:12.256 A:middle
whether you have large amounts

00:10:12.256 --> 00:10:13.956 A:middle
of data or small amounts of

00:10:13.956 --> 00:10:14.206 A:middle
data.

00:10:14.516 --> 00:10:16.336 A:middle
It's very important for us that

00:10:16.386 --> 00:10:17.926 A:middle
all of our tasks work whether

00:10:17.926 --> 00:10:19.846 A:middle
you have even a small amount of

00:10:19.846 --> 00:10:22.116 A:middle
data as small as about 40 images

00:10:22.176 --> 00:10:23.266 A:middle
per item that you're trying to

00:10:23.266 --> 00:10:24.676 A:middle
detect in the class of object.

00:10:25.106 --> 00:10:26.276 A:middle
In the case of object detection.

00:10:26.826 --> 00:10:30.866 A:middle
Let's move on to evaluation.

00:10:31.236 --> 00:10:32.446 A:middle
So I mentioned we have a simple

00:10:32.446 --> 00:10:34.936 A:middle
function .evaluate that will

00:10:34.936 --> 00:10:36.566 A:middle
give you an idea of the quality

00:10:36.566 --> 00:10:37.106 A:middle
of your model.

00:10:38.216 --> 00:10:40.006 A:middle
In the case of object detectors.

00:10:40.416 --> 00:10:42.086 A:middle
We have two factors to consider.

00:10:42.406 --> 00:10:43.846 A:middle
First, we want to know did we

00:10:43.846 --> 00:10:44.766 A:middle
get the label right?

00:10:45.386 --> 00:10:46.966 A:middle
But we also have to know if we

00:10:46.966 --> 00:10:48.306 A:middle
got that bounding box right

00:10:48.666 --> 00:10:49.476 A:middle
around the object.

00:10:50.616 --> 00:10:51.876 A:middle
So we can establish a simple

00:10:51.876 --> 00:10:53.846 A:middle
metric with these two factors

00:10:53.846 --> 00:10:55.906 A:middle
and go through a test data set

00:10:55.906 --> 00:10:57.696 A:middle
scoring predictions against

00:10:57.696 --> 00:10:59.996 A:middle
known what we call ground-truth

00:11:00.316 --> 00:11:00.616 A:middle
data.

00:11:01.446 --> 00:11:02.726 A:middle
And so we want to make sure that

00:11:02.726 --> 00:11:04.026 A:middle
we have correct labels.

00:11:04.506 --> 00:11:07.046 A:middle
And then a standard metric is at

00:11:07.046 --> 00:11:08.906 A:middle
least 50% overlap in the

00:11:08.906 --> 00:11:10.616 A:middle
predicted bounding box when

00:11:10.616 --> 00:11:11.296 A:middle
compared with to the

00:11:11.296 --> 00:11:12.756 A:middle
ground-truth bounding box.

00:11:13.206 --> 00:11:14.676 A:middle
Let's look at a few examples.

00:11:15.236 --> 00:11:18.296 A:middle
In this prediction we see that

00:11:18.296 --> 00:11:19.806 A:middle
the model got the label right

00:11:20.336 --> 00:11:21.316 A:middle
with a cup of coffee.

00:11:21.906 --> 00:11:23.316 A:middle
But that bounding box is not

00:11:23.316 --> 00:11:24.676 A:middle
really covering the whole cup of

00:11:24.676 --> 00:11:25.016 A:middle
coffee.

00:11:25.016 --> 00:11:26.066 A:middle
It's only about ten percent

00:11:26.066 --> 00:11:27.286 A:middle
overlapping the ground truth.

00:11:27.726 --> 00:11:29.256 A:middle
So we're going to consider that

00:11:29.666 --> 00:11:31.676 A:middle
a bad prediction.

00:11:31.676 --> 00:11:33.136 A:middle
Here we see a highly accurate

00:11:33.136 --> 00:11:35.106 A:middle
bounding box, but we got the

00:11:35.106 --> 00:11:35.816 A:middle
label wrong.

00:11:35.896 --> 00:11:36.786 A:middle
That's not a banana.

00:11:37.206 --> 00:11:38.706 A:middle
So let's not consider that a

00:11:38.706 --> 00:11:39.896 A:middle
successful prediction either.

00:11:41.006 --> 00:11:42.236 A:middle
Now this middle example's what

00:11:42.236 --> 00:11:42.866 A:middle
we want to see.

00:11:43.336 --> 00:11:44.906 A:middle
We have 70% overlap of our

00:11:44.906 --> 00:11:46.836 A:middle
bounding box, and the correct

00:11:46.836 --> 00:11:47.896 A:middle
label, coffee.

00:11:48.796 --> 00:11:49.776 A:middle
So what we can do is

00:11:49.776 --> 00:11:51.416 A:middle
systematically go through all of

00:11:51.416 --> 00:11:52.806 A:middle
our predictions with a test data

00:11:52.806 --> 00:11:53.066 A:middle
set.

00:11:53.656 --> 00:11:55.026 A:middle
And get an overall accuracy

00:11:55.026 --> 00:11:56.806 A:middle
score for a new model.

00:11:57.356 --> 00:12:00.676 A:middle
And finally, we move to

00:11:57.356 --> 00:12:00.676 A:middle
And finally, we move to

00:12:00.676 --> 00:12:01.196 A:middle
deployment.

00:12:01.896 --> 00:12:03.146 A:middle
We have an export to Core ML

00:12:03.146 --> 00:12:04.556 A:middle
function that saves your model

00:12:04.626 --> 00:12:06.386 A:middle
to Core ML's ML model format.

00:12:06.816 --> 00:12:08.056 A:middle
So you can then drag and drop

00:12:08.056 --> 00:12:09.486 A:middle
that model in to Xcode.

00:12:10.696 --> 00:12:12.046 A:middle
This week we've actually some

00:12:12.046 --> 00:12:13.806 A:middle
exciting new features related to

00:12:13.806 --> 00:12:15.296 A:middle
object detection specifically.

00:12:15.856 --> 00:12:16.876 A:middle
So I encourage you to attend

00:12:16.876 --> 00:12:18.716 A:middle
tomorrow's Vision with Core ML

00:12:18.716 --> 00:12:20.506 A:middle
session to learn more.

00:12:20.876 --> 00:12:21.886 A:middle
In that session, the speaker

00:12:21.886 --> 00:12:23.076 A:middle
will actually take the object

00:12:23.076 --> 00:12:24.036 A:middle
detection model that we're

00:12:24.036 --> 00:12:26.146 A:middle
building today and go into more

00:12:26.146 --> 00:12:27.706 A:middle
detail about deployment options.

00:12:28.316 --> 00:12:30.996 A:middle
And there you have it!

00:12:31.536 --> 00:12:33.486 A:middle
The five-step recipe for Turi

00:12:33.486 --> 00:12:33.826 A:middle
Create.

00:12:35.516 --> 00:12:38.946 A:middle
[ Applause ]

00:12:39.446 --> 00:12:40.036 A:middle
Thank you.

00:12:40.316 --> 00:12:41.256 A:middle
So with that, I'm going to hand

00:12:41.256 --> 00:12:42.896 A:middle
off to my colleague Zach Nation,

00:12:42.896 --> 00:12:43.426 A:middle
for a demo.

00:12:45.516 --> 00:12:50.436 A:middle
[ Applause ]

00:12:50.936 --> 00:12:51.536 A:middle
&gt;&gt; Thanks, Aaron.

00:12:52.466 --> 00:12:54.126 A:middle
I think let's just jump straight

00:12:54.126 --> 00:12:54.616 A:middle
into code.

00:12:54.616 --> 00:12:55.616 A:middle
Who wants to write some code

00:12:55.616 --> 00:12:56.516 A:middle
live today?

00:12:56.946 --> 00:12:58.096 A:middle
We're going to go ahead and

00:12:58.096 --> 00:12:59.496 A:middle
build an object detector model

00:12:59.496 --> 00:13:00.000 A:middle
right now.

00:13:10.046 --> 00:13:11.416 A:middle
So I'm going to start out in

00:13:11.416 --> 00:13:11.956 A:middle
Finder.

00:13:12.336 --> 00:13:14.216 A:middle
Here I've got a folder of images

00:13:14.596 --> 00:13:15.906 A:middle
that I want to use to train a

00:13:15.906 --> 00:13:16.266 A:middle
model.

00:13:17.206 --> 00:13:18.546 A:middle
We can see this folder's named

00:13:18.546 --> 00:13:21.476 A:middle
Data, and it's full of images of

00:13:21.506 --> 00:13:22.296 A:middle
breakfast foods.

00:13:22.786 --> 00:13:25.046 A:middle
I've got a croissant, some eggs,

00:13:25.396 --> 00:13:25.936 A:middle
and so on.

00:13:26.516 --> 00:13:29.006 A:middle
This is, this is a good data set

00:13:29.006 --> 00:13:29.736 A:middle
for breakfast food.

00:13:29.736 --> 00:13:31.086 A:middle
I think let's go ahead and write

00:13:31.086 --> 00:13:31.746 A:middle
some code with it.

00:13:33.016 --> 00:13:34.806 A:middle
I'm going to switch over to an

00:13:34.806 --> 00:13:35.986 A:middle
environment called Jupyter

00:13:35.986 --> 00:13:36.466 A:middle
notebook.

00:13:37.096 --> 00:13:38.546 A:middle
This is an interactive Python

00:13:38.546 --> 00:13:40.576 A:middle
environment where you can run

00:13:40.576 --> 00:13:42.026 A:middle
snippets of Python code and

00:13:42.026 --> 00:13:43.256 A:middle
immediately see the output.

00:13:43.526 --> 00:13:45.126 A:middle
So this is a great way to

00:13:45.126 --> 00:13:46.526 A:middle
interactively work with a model.

00:13:46.776 --> 00:13:48.616 A:middle
And it's very similar in concept

00:13:48.816 --> 00:13:50.066 A:middle
to Xcode Playgrounds.

00:13:51.056 --> 00:13:52.116 A:middle
The first thing we're going to

00:13:52.116 --> 00:13:55.996 A:middle
do is import Turi Create as TC.

00:13:56.396 --> 00:14:00.376 A:middle
And that we way we can refer to

00:13:56.396 --> 00:14:00.376 A:middle
And that we way we can refer to

00:14:00.376 --> 00:14:01.946 A:middle
it as TC throughout the rest of

00:14:01.946 --> 00:14:02.416 A:middle
the script.

00:14:03.576 --> 00:14:05.326 A:middle
Now, the first task we want to

00:14:06.166 --> 00:14:07.336 A:middle
do is load data.

00:14:07.916 --> 00:14:12.086 A:middle
And we're going to load it up

00:14:12.086 --> 00:14:13.356 A:middle
into SFrame format.

00:14:14.256 --> 00:14:15.846 A:middle
So first we can say images

00:14:15.846 --> 00:14:18.046 A:middle
equals TC.loadimages.

00:14:18.536 --> 00:14:19.386 A:middle
And we're going to give it that

00:14:19.386 --> 00:14:21.216 A:middle
folder day that I just showed in

00:14:21.216 --> 00:14:21.616 A:middle
Finder.

00:14:22.166 --> 00:14:26.476 A:middle
And Turi Create provides

00:14:26.476 --> 00:14:28.206 A:middle
utilities to interactively

00:14:28.206 --> 00:14:29.766 A:middle
explore and visualize our data.

00:14:30.006 --> 00:14:31.346 A:middle
So let's make sure those images

00:14:31.346 --> 00:14:32.866 A:middle
loaded correctly and we got the

00:14:32.866 --> 00:14:34.016 A:middle
resulting SFrame that we

00:14:34.016 --> 00:14:34.496 A:middle
expected.

00:14:35.216 --> 00:14:36.696 A:middle
I'm just going to call .explore,

00:14:37.456 --> 00:14:38.826 A:middle
and this is going to open up a

00:14:38.826 --> 00:14:40.346 A:middle
visualization window where we

00:14:40.346 --> 00:14:41.976 A:middle
can see that we have two columns

00:14:41.976 --> 00:14:42.696 A:middle
in our SFrame.

00:14:43.166 --> 00:14:44.746 A:middle
The first is called path, and

00:14:44.746 --> 00:14:46.256 A:middle
it's the relative path to that

00:14:46.256 --> 00:14:47.106 A:middle
image on disk.

00:14:47.536 --> 00:14:48.816 A:middle
And the second column is called

00:14:48.816 --> 00:14:49.296 A:middle
image.

00:14:49.566 --> 00:14:50.876 A:middle
And that's actually the contents

00:14:50.876 --> 00:14:51.866 A:middle
of the image itself.

00:14:52.096 --> 00:14:53.166 A:middle
And we can see our breakfast

00:14:53.206 --> 00:14:53.906 A:middle
foods right here.

00:14:54.676 --> 00:14:55.586 A:middle
It looks like these loaded

00:14:55.586 --> 00:14:56.956 A:middle
correctly, so I'm going to

00:14:56.956 --> 00:14:57.356 A:middle
proceed.

00:14:57.906 --> 00:15:01.026 A:middle
Back in Jupyter notebook.

00:14:57.906 --> 00:15:01.026 A:middle
Back in Jupyter notebook.

00:15:01.416 --> 00:15:02.786 A:middle
Now I'm also going to load up a

00:15:02.786 --> 00:15:04.196 A:middle
second SFrame called

00:15:04.196 --> 00:15:04.996 A:middle
annotations.

00:15:05.536 --> 00:15:09.416 A:middle
And this I'm just going to call

00:15:09.416 --> 00:15:11.066 A:middle
the SFrame instructor and

00:15:11.066 --> 00:15:12.346 A:middle
provide a file name to

00:15:12.346 --> 00:15:13.896 A:middle
annotations.csv.

00:15:14.326 --> 00:15:16.286 A:middle
This is a CSV file containing

00:15:16.286 --> 00:15:17.776 A:middle
the annotations that correspond

00:15:17.776 --> 00:15:18.546 A:middle
to those images.

00:15:19.236 --> 00:15:23.256 A:middle
And let's take a look at that.

00:15:23.876 --> 00:15:25.206 A:middle
Right in Jupyter notebook, we

00:15:25.206 --> 00:15:26.296 A:middle
can see that this SFrame

00:15:26.296 --> 00:15:28.146 A:middle
contains a path column, again

00:15:28.146 --> 00:15:29.476 A:middle
pointing to that relative path

00:15:29.476 --> 00:15:30.706 A:middle
on disk of the image.

00:15:31.206 --> 00:15:32.926 A:middle
And an annotation column

00:15:33.156 --> 00:15:34.606 A:middle
containing a JSON object

00:15:34.806 --> 00:15:36.326 A:middle
describing the bounding box and

00:15:36.326 --> 00:15:37.966 A:middle
labels associated with that

00:15:37.966 --> 00:15:38.366 A:middle
image.

00:15:39.806 --> 00:15:40.866 A:middle
But now we have two different

00:15:40.866 --> 00:15:42.636 A:middle
data sources and we need to

00:15:42.826 --> 00:15:44.286 A:middle
provide one data source to train

00:15:44.286 --> 00:15:44.776 A:middle
our model.

00:15:45.316 --> 00:15:46.406 A:middle
Let's join them together.

00:15:47.096 --> 00:15:48.986 A:middle
In Turi Create, this is as easy

00:15:48.986 --> 00:15:50.186 A:middle
as calling the join method.

00:15:50.616 --> 00:15:52.626 A:middle
I'm going to say data equals

00:15:52.956 --> 00:15:57.946 A:middle
images.joinannotations and now

00:15:58.066 --> 00:15:59.916 A:middle
we can see we have a single

00:16:00.036 --> 00:16:01.656 A:middle
SFrame with three columns.

00:16:02.216 --> 00:16:03.766 A:middle
It joined on that path column.

00:16:04.016 --> 00:16:05.956 A:middle
So for each image with a path,

00:16:06.206 --> 00:16:07.766 A:middle
it combined the annotations for

00:16:07.766 --> 00:16:08.246 A:middle
that path.

00:16:09.006 --> 00:16:10.566 A:middle
And so now for each image, we

00:16:10.566 --> 00:16:11.806 A:middle
have annotations available.

00:16:12.656 --> 00:16:13.486 A:middle
Now we're ready to train a

00:16:13.486 --> 00:16:13.786 A:middle
model.

00:16:14.386 --> 00:16:17.936 A:middle
So I'm going to create a new

00:16:17.936 --> 00:16:20.396 A:middle
section here called train a

00:16:20.396 --> 00:16:20.716 A:middle
model.

00:16:23.406 --> 00:16:26.006 A:middle
And that's just one line of code

00:16:26.006 --> 00:16:26.276 A:middle
here.

00:16:26.276 --> 00:16:28.096 A:middle
I'm going to say model equals

00:16:28.426 --> 00:16:30.606 A:middle
TC.objectdetector.create.

00:16:30.936 --> 00:16:31.896 A:middle
And this is our simple

00:16:31.896 --> 00:16:33.636 A:middle
task-focused API for object

00:16:33.636 --> 00:16:35.166 A:middle
detection that expects data in

00:16:35.166 --> 00:16:35.696 A:middle
this format.

00:16:36.476 --> 00:16:37.906 A:middle
I'm going to pass in that data

00:16:37.906 --> 00:16:39.226 A:middle
SFrame that I just created.

00:16:39.686 --> 00:16:41.126 A:middle
And for the purposes of today's

00:16:41.126 --> 00:16:42.816 A:middle
demo, I'm going to pass another

00:16:42.816 --> 00:16:44.686 A:middle
parameter called max iterations

00:16:45.136 --> 00:16:46.706 A:middle
and normally you wouldn't need

00:16:46.706 --> 00:16:48.046 A:middle
to pass this parameter because

00:16:48.086 --> 00:16:49.366 A:middle
Turi Create will pick the

00:16:49.366 --> 00:16:50.846 A:middle
correct number of iterations for

00:16:50.846 --> 00:16:51.076 A:middle
you.

00:16:51.226 --> 00:16:52.206 A:middle
Based on the data that you

00:16:52.206 --> 00:16:52.676 A:middle
provide.

00:16:53.456 --> 00:16:54.916 A:middle
In this case, I'm going to say

00:16:54.916 --> 00:16:56.876 A:middle
max iterations equals one just

00:16:56.876 --> 00:16:58.216 A:middle
to give an example of what

00:16:58.216 --> 00:16:59.076 A:middle
training would look like.

00:16:59.886 --> 00:17:01.216 A:middle
And the reason this is going to

00:16:59.886 --> 00:17:01.216 A:middle
And the reason this is going to

00:17:01.216 --> 00:17:02.556 A:middle
take a minute is it actually

00:17:02.556 --> 00:17:03.856 A:middle
goes through and resizes all of

00:17:03.856 --> 00:17:05.445 A:middle
those images in order to get

00:17:05.445 --> 00:17:06.856 A:middle
them ready to run through the

00:17:06.856 --> 00:17:07.435 A:middle
neural network.

00:17:07.435 --> 00:17:08.836 A:middle
That is under the hood of this

00:17:08.836 --> 00:17:09.665 A:middle
object detector.

00:17:10.465 --> 00:17:12.036 A:middle
And then it will perform just

00:17:12.036 --> 00:17:14.856 A:middle
one iteration on this Mac GPO.

00:17:16.116 --> 00:17:17.965 A:middle
But this is probably not the

00:17:17.965 --> 00:17:19.435 A:middle
best model we could get because

00:17:19.435 --> 00:17:20.496 A:middle
I just wanted to train it in a

00:17:20.496 --> 00:17:21.306 A:middle
couple of seconds.

00:17:21.656 --> 00:17:22.906 A:middle
So I'm going to go ahead and

00:17:22.906 --> 00:17:24.685 A:middle
switch over to like cooking show

00:17:24.685 --> 00:17:25.016 A:middle
mode.

00:17:25.056 --> 00:17:26.406 A:middle
And I'm going to take one out of

00:17:26.406 --> 00:17:27.445 A:middle
the oven that we've had in there

00:17:27.445 --> 00:17:28.036 A:middle
for an hour [laughter].

00:17:28.726 --> 00:17:30.826 A:middle
[Applause] So I'm going to say

00:17:30.826 --> 00:17:34.676 A:middle
TC.loadmodel and it's called

00:17:34.796 --> 00:17:36.696 A:middle
breakfastmodel.model.

00:17:36.696 --> 00:17:39.546 A:middle
And this is one that I've had an

00:17:39.546 --> 00:17:40.896 A:middle
opportunity to train for a bit

00:17:40.896 --> 00:17:41.316 A:middle
longer.

00:17:41.806 --> 00:17:43.466 A:middle
So let's inspect that right here

00:17:43.466 --> 00:17:44.026 A:middle
in the notebook.

00:17:44.266 --> 00:17:45.396 A:middle
And we can see that it's an

00:17:45.396 --> 00:17:46.576 A:middle
object detector model.

00:17:47.226 --> 00:17:48.356 A:middle
It's been trained on six

00:17:48.386 --> 00:17:50.336 A:middle
classes, and we trained it for

00:17:50.336 --> 00:17:51.486 A:middle
55 minutes.

00:17:52.026 --> 00:17:53.006 A:middle
This is means, this means you

00:17:53.006 --> 00:17:54.296 A:middle
can train a useful

00:17:54.296 --> 00:17:55.966 A:middle
object-detector model in under

00:17:55.966 --> 00:17:58.000 A:middle
an hour on your Mac.

00:18:01.096 --> 00:18:02.866 A:middle
Next, let's test the predictions

00:18:02.866 --> 00:18:04.336 A:middle
of this model and see if it's

00:18:04.336 --> 00:18:05.000 A:middle
any good.

00:18:11.046 --> 00:18:11.876 A:middle
So I'm going to make a new

00:18:11.876 --> 00:18:13.096 A:middle
section here called inspect

00:18:13.166 --> 00:18:13.676 A:middle
predictions.

00:18:14.056 --> 00:18:15.506 A:middle
And we're going to go ahead and

00:18:15.716 --> 00:18:17.436 A:middle
load up a test data set.

00:18:18.026 --> 00:18:19.496 A:middle
And here I've already prepared

00:18:19.496 --> 00:18:20.676 A:middle
one in SFrame format.

00:18:20.676 --> 00:18:21.716 A:middle
So I'm just going to load it,

00:18:22.436 --> 00:18:23.266 A:middle
and I called it

00:18:23.266 --> 00:18:25.046 A:middle
testbreakfastdata.sframe.

00:18:25.666 --> 00:18:26.606 A:middle
There are two important

00:18:26.606 --> 00:18:28.756 A:middle
properties of this test SFrame.

00:18:29.146 --> 00:18:31.126 A:middle
One is that it contains the same

00:18:31.126 --> 00:18:33.256 A:middle
types of images that the model

00:18:33.366 --> 00:18:34.316 A:middle
would have trained on.

00:18:34.656 --> 00:18:36.216 A:middle
But the second important

00:18:36.216 --> 00:18:37.756 A:middle
property is the model has never

00:18:37.756 --> 00:18:39.266 A:middle
seen these images before.

00:18:39.556 --> 00:18:41.136 A:middle
So this is a good test for

00:18:41.136 --> 00:18:42.126 A:middle
whether that model can

00:18:42.126 --> 00:18:44.176 A:middle
generalize to users' real data.

00:18:44.756 --> 00:18:48.466 A:middle
I'm going to make predictions

00:18:48.566 --> 00:18:50.176 A:middle
from that whole test set by

00:18:50.176 --> 00:18:52.016 A:middle
calling model.predict and

00:18:52.016 --> 00:18:54.196 A:middle
providing that test SFrame.

00:18:54.396 --> 00:18:55.626 A:middle
And we'll get a batch prediction

00:18:55.626 --> 00:18:56.546 A:middle
for the whole SFrame.

00:18:57.096 --> 00:19:00.656 A:middle
And that'll just take a few

00:18:57.096 --> 00:19:00.656 A:middle
And that'll just take a few

00:19:00.656 --> 00:19:01.136 A:middle
seconds.

00:19:01.996 --> 00:19:04.306 A:middle
And then we're going to inspect.

00:19:04.516 --> 00:19:05.556 A:middle
I'm just going to pick a random

00:19:05.556 --> 00:19:06.346 A:middle
prediction here.

00:19:06.626 --> 00:19:08.856 A:middle
Let's say index two.

00:19:09.606 --> 00:19:11.676 A:middle
Here we can see the JSON object

00:19:11.676 --> 00:19:13.346 A:middle
that was predicted in just the

00:19:13.346 --> 00:19:14.966 A:middle
same format that the training

00:19:14.966 --> 00:19:16.106 A:middle
data is provided in.

00:19:16.446 --> 00:19:18.316 A:middle
So here we have coordinates,

00:19:18.486 --> 00:19:19.776 A:middle
height, width, x and y.

00:19:20.056 --> 00:19:21.196 A:middle
And a label, banana.

00:19:21.796 --> 00:19:23.116 A:middle
And we get a confidence score

00:19:23.116 --> 00:19:23.816 A:middle
from the model.

00:19:23.966 --> 00:19:25.876 A:middle
In this case about .87.

00:19:26.886 --> 00:19:28.466 A:middle
This is a little bit hard for me

00:19:28.466 --> 00:19:29.976 A:middle
as a human to interpret though.

00:19:30.436 --> 00:19:32.516 A:middle
I can't really tell if this

00:19:32.516 --> 00:19:33.786 A:middle
image is really supposed to be a

00:19:33.786 --> 00:19:35.446 A:middle
banana or whether these

00:19:35.446 --> 00:19:36.866 A:middle
coordinates are where the banana

00:19:36.866 --> 00:19:38.526 A:middle
would appear in that image.

00:19:39.686 --> 00:19:41.526 A:middle
Turi Create produces a function

00:19:41.706 --> 00:19:42.996 A:middle
to take the predicted bounding

00:19:42.996 --> 00:19:44.476 A:middle
boxes or the ground-truth

00:19:44.476 --> 00:19:46.036 A:middle
bounding boxes and draw them

00:19:46.066 --> 00:19:47.096 A:middle
right onto the images.

00:19:47.576 --> 00:19:48.836 A:middle
So let's go and do that.

00:19:49.516 --> 00:19:50.976 A:middle
I'm going to create a new column

00:19:51.046 --> 00:19:52.846 A:middle
in my test SFrame called

00:19:52.906 --> 00:19:53.856 A:middle
predicted image.

00:19:54.936 --> 00:19:56.926 A:middle
And I'm going to assign it the

00:19:56.926 --> 00:19:58.906 A:middle
output of the object detector

00:19:58.906 --> 00:20:00.406 A:middle
utility called draw bounding

00:19:58.906 --> 00:20:00.406 A:middle
utility called draw bounding

00:20:00.406 --> 00:20:00.896 A:middle
boxes.

00:20:01.756 --> 00:20:03.736 A:middle
And I'm going to pass into draw

00:20:03.736 --> 00:20:06.536 A:middle
bounding boxes that test image

00:20:06.536 --> 00:20:06.946 A:middle
column.

00:20:07.016 --> 00:20:09.176 A:middle
So that's the image itself and

00:20:09.176 --> 00:20:11.616 A:middle
then I'm also going to pass the

00:20:11.616 --> 00:20:13.226 A:middle
predictions that I just got from

00:20:13.226 --> 00:20:13.626 A:middle
the model.

00:20:13.766 --> 00:20:15.616 A:middle
That's going to draw those

00:20:15.656 --> 00:20:17.316 A:middle
predicted bounding boxes onto

00:20:17.316 --> 00:20:18.126 A:middle
each image.

00:20:18.656 --> 00:20:19.996 A:middle
Now let's take a look at that

00:20:19.996 --> 00:20:21.286 A:middle
number two prediction again.

00:20:21.566 --> 00:20:23.096 A:middle
This time in image form.

00:20:24.676 --> 00:20:25.586 A:middle
So I can say

00:20:25.586 --> 00:20:28.396 A:middle
testpredictedimage2.show.

00:20:28.836 --> 00:20:30.296 A:middle
And it will render right here in

00:20:30.296 --> 00:20:30.786 A:middle
the notebook.

00:20:31.516 --> 00:20:38.016 A:middle
[ Applause ]

00:20:38.516 --> 00:20:39.946 A:middle
And this is great as a spot

00:20:39.946 --> 00:20:41.596 A:middle
check because at least for one

00:20:41.596 --> 00:20:42.396 A:middle
picture, we know that the

00:20:42.396 --> 00:20:43.146 A:middle
model's working.

00:20:43.616 --> 00:20:44.706 A:middle
But this doesn't tell us if

00:20:44.706 --> 00:20:45.996 A:middle
it'll work for say the next

00:20:45.996 --> 00:20:47.786 A:middle
50,000 images that we pass in.

00:20:48.636 --> 00:20:49.986 A:middle
So for that, we're going to

00:20:49.986 --> 00:20:50.916 A:middle
evaluate the model

00:20:50.976 --> 00:20:51.846 A:middle
quantitatively.

00:20:52.446 --> 00:20:53.966 A:middle
And I'm going to start a new

00:20:53.966 --> 00:20:55.106 A:middle
section here in the notebook

00:20:55.106 --> 00:20:56.326 A:middle
called evaluate the model.

00:20:56.426 --> 00:20:58.286 A:middle
And what we're going to do is

00:20:58.286 --> 00:21:01.226 A:middle
call model.evaluate and once

00:20:58.286 --> 00:21:01.226 A:middle
call model.evaluate and once

00:21:01.226 --> 00:21:02.436 A:middle
again, I'm going to pass in just

00:21:02.436 --> 00:21:04.186 A:middle
that whole test data set.

00:21:05.936 --> 00:21:08.096 A:middle
Here the evaluation function is

00:21:08.096 --> 00:21:09.436 A:middle
going to run the metric that

00:21:09.436 --> 00:21:11.526 A:middle
Aaron described, testing whether

00:21:11.526 --> 00:21:12.546 A:middle
the bounding boxes are

00:21:12.546 --> 00:21:14.556 A:middle
overlapping at least 50% and

00:21:14.556 --> 00:21:15.586 A:middle
have a correct label.

00:21:15.586 --> 00:21:17.226 A:middle
And it's going to give us that

00:21:17.226 --> 00:21:18.756 A:middle
result across each of the six

00:21:18.756 --> 00:21:19.926 A:middle
classes that we trained on.

00:21:20.516 --> 00:21:22.036 A:middle
So here we can see that our

00:21:22.356 --> 00:21:24.096 A:middle
overlapping bounding boxes with

00:21:24.096 --> 00:21:25.636 A:middle
the correct label are happening

00:21:25.736 --> 00:21:27.696 A:middle
about 80% of the time for bagel.

00:21:28.106 --> 00:21:29.946 A:middle
About 67% of the time for

00:21:29.946 --> 00:21:30.416 A:middle
banana.

00:21:30.706 --> 00:21:31.276 A:middle
And so on.

00:21:32.456 --> 00:21:34.016 A:middle
That's pretty good, so I think

00:21:34.096 --> 00:21:35.616 A:middle
let's, let's see if this model's

00:21:35.616 --> 00:21:36.966 A:middle
actually going to work in a real

00:21:36.966 --> 00:21:37.226 A:middle
app.

00:21:37.866 --> 00:21:39.526 A:middle
I'm going to go ahead and call

00:21:39.806 --> 00:21:42.366 A:middle
exportcoreml to create a Core ML

00:21:42.366 --> 00:21:43.806 A:middle
model from the model we just

00:21:43.806 --> 00:21:44.076 A:middle
trained.

00:21:44.226 --> 00:21:45.666 A:middle
And I'm going to call it

00:21:45.666 --> 00:21:47.536 A:middle
breakfastmodel.mlmodel.

00:21:47.826 --> 00:21:49.036 A:middle
And then as soon as that's done

00:21:49.036 --> 00:21:50.546 A:middle
training, I'm going to go ahead

00:21:50.546 --> 00:21:51.656 A:middle
and open it in finder.

00:21:52.236 --> 00:21:55.206 A:middle
Or sorry. As soon as that's done

00:21:55.206 --> 00:21:56.000 A:middle
exporting.

00:22:00.046 --> 00:22:01.686 A:middle
So here in finder, I've got my

00:22:01.686 --> 00:22:03.316 A:middle
breakfastmodel.mlmodel.

00:22:03.316 --> 00:22:05.636 A:middle
And when I open it in Xcode, I

00:22:05.636 --> 00:22:07.106 A:middle
can see that it looks just like

00:22:07.106 --> 00:22:08.306 A:middle
any Core ML model.

00:22:08.896 --> 00:22:12.176 A:middle
It takes an input image, and as

00:22:12.176 --> 00:22:14.526 A:middle
output we get confidence and

00:22:14.526 --> 00:22:15.206 A:middle
coordinates.

00:22:15.616 --> 00:22:16.706 A:middle
And that's going to tell us the

00:22:16.706 --> 00:22:18.336 A:middle
predicted bounding box and label

00:22:18.336 --> 00:22:19.436 A:middle
for the image that we have.

00:22:20.376 --> 00:22:22.206 A:middle
Now let's switch over to the

00:22:22.246 --> 00:22:23.646 A:middle
iPhone app where we're going to

00:22:23.646 --> 00:22:24.616 A:middle
consume this model.

00:22:25.186 --> 00:22:30.306 A:middle
So here on my iPhone, I've got

00:22:30.306 --> 00:22:31.716 A:middle
an app called Food Predictor.

00:22:32.356 --> 00:22:33.336 A:middle
And this is going to use the

00:22:33.336 --> 00:22:34.456 A:middle
model that we just trained.

00:22:35.356 --> 00:22:36.646 A:middle
Here I'm going to choose from

00:22:36.646 --> 00:22:37.096 A:middle
photos.

00:22:37.416 --> 00:22:39.026 A:middle
And I've got a picture of this

00:22:39.026 --> 00:22:40.036 A:middle
morning's breakfast.

00:22:40.546 --> 00:22:41.506 A:middle
This is a pretty typical

00:22:41.506 --> 00:22:42.916 A:middle
breakfast for me: coffee and a

00:22:42.916 --> 00:22:43.326 A:middle
banana.

00:22:43.796 --> 00:22:45.546 A:middle
Well, often I skip the banana.

00:22:46.316 --> 00:22:48.856 A:middle
But suppose I ate a banana this

00:22:48.856 --> 00:22:49.346 A:middle
morning.

00:22:50.456 --> 00:22:53.316 A:middle
We can just tap right on the

00:22:53.316 --> 00:22:53.796 A:middle
image.

00:22:53.796 --> 00:22:54.976 A:middle
And because we know the bounding

00:22:54.976 --> 00:22:57.196 A:middle
box, we can identify the object

00:22:57.196 --> 00:22:58.386 A:middle
within that bounding box.

00:22:58.386 --> 00:22:59.716 A:middle
And here we see the model tells

00:22:59.716 --> 00:23:02.296 A:middle
us this is a banana, and this is

00:22:59.716 --> 00:23:02.296 A:middle
us this is a banana, and this is

00:23:02.296 --> 00:23:02.976 A:middle
a cup of coffee.

00:23:03.516 --> 00:23:09.500 A:middle
[ Applause ]

00:23:16.136 --> 00:23:17.886 A:middle
So let's recap what we just saw.

00:23:19.886 --> 00:23:21.756 A:middle
First, we loaded images and

00:23:21.756 --> 00:23:23.896 A:middle
annotations into SFrame format

00:23:24.146 --> 00:23:25.626 A:middle
and joined them together with a

00:23:25.626 --> 00:23:26.556 A:middle
simple function call.

00:23:27.296 --> 00:23:28.976 A:middle
We interactively explored that

00:23:28.976 --> 00:23:30.786 A:middle
data using the explore method.

00:23:31.826 --> 00:23:33.616 A:middle
We created a model just with a

00:23:33.616 --> 00:23:35.606 A:middle
simple high-level API&lt; passing

00:23:35.606 --> 00:23:37.286 A:middle
in that data object containing

00:23:37.286 --> 00:23:38.756 A:middle
both the images and the bounding

00:23:38.756 --> 00:23:39.936 A:middle
boxes and labels.

00:23:40.906 --> 00:23:42.676 A:middle
We then evaluated that model

00:23:42.836 --> 00:23:43.956 A:middle
both qualitatively,

00:23:44.026 --> 00:23:45.596 A:middle
spot-checking the output as a

00:23:45.596 --> 00:23:46.176 A:middle
human would.

00:23:46.556 --> 00:23:48.566 A:middle
And quantitatively, asking for a

00:23:48.566 --> 00:23:50.486 A:middle
specific metric that applies to

00:23:50.486 --> 00:23:51.526 A:middle
the task that we're doing.

00:23:52.326 --> 00:23:54.206 A:middle
Then we exported that model to

00:23:54.206 --> 00:23:56.886 A:middle
Core ML format for use in an

00:23:58.366 --> 00:23:58.446 A:middle
app.

00:23:58.726 --> 00:24:00.306 A:middle
Next, I'd like to switch gears

00:23:58.726 --> 00:24:00.306 A:middle
Next, I'd like to switch gears

00:24:00.576 --> 00:24:01.976 A:middle
and talk about some exciting new

00:24:01.976 --> 00:24:04.836 A:middle
features in Turi Create 5.0.

00:24:06.776 --> 00:24:09.806 A:middle
Turi Create 5.0 has a new task

00:24:10.076 --> 00:24:11.186 A:middle
called style transfer.

00:24:12.556 --> 00:24:13.716 A:middle
We have major performance

00:24:13.716 --> 00:24:16.126 A:middle
improvements from native GPU

00:24:16.126 --> 00:24:18.166 A:middle
acceleration on your Mac.

00:24:19.016 --> 00:24:20.626 A:middle
And we have new deployment

00:24:20.626 --> 00:24:22.516 A:middle
options including recommender

00:24:22.516 --> 00:24:24.626 A:middle
models for personalization and

00:24:24.676 --> 00:24:25.956 A:middle
vision feature print-powered

00:24:25.956 --> 00:24:27.466 A:middle
models so that you can reduce

00:24:27.466 --> 00:24:28.386 A:middle
the size of your app.

00:24:28.676 --> 00:24:29.956 A:middle
Taking advantage of models that

00:24:29.956 --> 00:24:30.986 A:middle
are already in the operating

00:24:30.986 --> 00:24:31.386 A:middle
system.

00:24:31.906 --> 00:24:34.696 A:middle
Let's talk a little bit more

00:24:34.696 --> 00:24:36.176 A:middle
about that style transfer task.

00:24:37.116 --> 00:24:39.186 A:middle
Imagine we've got some style

00:24:39.186 --> 00:24:41.296 A:middle
images and these are really cool

00:24:41.296 --> 00:24:43.836 A:middle
looking recognizable stylistic

00:24:43.836 --> 00:24:44.376 A:middle
images.

00:24:45.016 --> 00:24:46.826 A:middle
Here we've got sort of a light

00:24:46.826 --> 00:24:48.156 A:middle
honeycomb pattern and a very

00:24:48.156 --> 00:24:49.426 A:middle
colorful flower pattern.

00:24:49.666 --> 00:24:51.406 A:middle
And we want apply those as

00:24:51.406 --> 00:24:53.416 A:middle
filters to our own images that

00:24:53.416 --> 00:24:54.246 A:middle
we take with a camera.

00:24:54.836 --> 00:24:57.846 A:middle
We've got a dog photo here and

00:24:57.896 --> 00:24:59.186 A:middle
what it would look like to apply

00:24:59.186 --> 00:25:01.496 A:middle
those styles to that dog is

00:24:59.186 --> 00:25:01.496 A:middle
those styles to that dog is

00:25:01.496 --> 00:25:02.236 A:middle
something like that.

00:25:02.586 --> 00:25:05.006 A:middle
And with a style transfer model,

00:25:05.196 --> 00:25:06.956 A:middle
we can take the same styles and

00:25:06.956 --> 00:25:08.296 A:middle
apply them to more photos.

00:25:08.646 --> 00:25:10.246 A:middle
Let's say a cat and another dog.

00:25:10.916 --> 00:25:12.046 A:middle
And that's the sort of effect we

00:25:12.046 --> 00:25:13.000 A:middle
would get.

00:25:16.046 --> 00:25:17.566 A:middle
Here's an example of an app that

00:25:17.566 --> 00:25:19.646 A:middle
uses style transfer for filters

00:25:19.816 --> 00:25:21.216 A:middle
on photos that a user would

00:25:21.846 --> 00:25:21.946 A:middle
take.

00:25:24.556 --> 00:25:26.526 A:middle
The code to create the style

00:25:26.526 --> 00:25:28.386 A:middle
transfer model follows the same

00:25:28.516 --> 00:25:30.466 A:middle
five-step recipe as any other

00:25:30.466 --> 00:25:32.046 A:middle
high-level task in Turi Create.

00:25:32.296 --> 00:25:33.956 A:middle
So you can start by importing

00:25:33.956 --> 00:25:36.076 A:middle
Turi Create, loading data into

00:25:36.076 --> 00:25:38.166 A:middle
the SFrame format, creating the

00:25:38.166 --> 00:25:39.906 A:middle
model with a simple high-level

00:25:39.906 --> 00:25:40.176 A:middle
API.

00:25:41.326 --> 00:25:42.906 A:middle
Then we make predictions, in

00:25:42.906 --> 00:25:44.166 A:middle
this case with a function called

00:25:44.166 --> 00:25:46.186 A:middle
stylize to take an image and

00:25:46.186 --> 00:25:47.536 A:middle
apply that style filter.

00:25:48.166 --> 00:25:49.746 A:middle
Finally, we can export it for

00:25:49.746 --> 00:25:51.576 A:middle
deployment into Core ML format,

00:25:51.576 --> 00:25:52.726 A:middle
just like any other model in

00:25:52.726 --> 00:25:53.000 A:middle
Turi Create.

00:25:56.266 --> 00:25:57.506 A:middle
So let's take a look at another

00:25:57.506 --> 00:25:57.926 A:middle
demo.

00:25:58.146 --> 00:26:00.106 A:middle
This time, we're going to build

00:25:58.146 --> 00:26:00.106 A:middle
This time, we're going to build

00:26:00.106 --> 00:26:02.000 A:middle
a style-transfer model.

00:26:14.476 --> 00:26:15.926 A:middle
So switching back over to that

00:26:15.926 --> 00:26:17.196 A:middle
Jupyter notebook environment.

00:26:17.546 --> 00:26:19.386 A:middle
I'm going to start once again by

00:26:19.386 --> 00:26:23.476 A:middle
importing Turi Create.

00:26:23.936 --> 00:26:25.000 A:middle
As TC.

00:26:29.056 --> 00:26:30.556 A:middle
Then, I'm going to load up two

00:26:30.556 --> 00:26:32.836 A:middle
SFrames, each containing images.

00:26:33.276 --> 00:26:35.236 A:middle
One, is the style images I'm

00:26:35.236 --> 00:26:36.766 A:middle
going to call tc.loadimages, and

00:26:36.766 --> 00:26:37.766 A:middle
I'm going to give it a directory

00:26:37.766 --> 00:26:38.416 A:middle
name, styles.

00:26:39.106 --> 00:26:40.876 A:middle
And then the other is content

00:26:40.876 --> 00:26:41.466 A:middle
images.

00:26:42.956 --> 00:26:44.226 A:middle
And the way that this works is

00:26:44.266 --> 00:26:46.106 A:middle
the style images are the styles

00:26:46.106 --> 00:26:47.236 A:middle
that you want to turn into

00:26:47.236 --> 00:26:48.376 A:middle
filters you can apply.

00:26:48.376 --> 00:26:50.586 A:middle
And the content images can be

00:26:50.686 --> 00:26:51.596 A:middle
any images that are

00:26:51.596 --> 00:26:53.286 A:middle
representative of the types of

00:26:53.286 --> 00:26:54.346 A:middle
photograph that you would want

00:26:54.346 --> 00:26:55.836 A:middle
to apply those filters to.

00:26:56.266 --> 00:26:57.596 A:middle
So in this case, it's just a

00:26:57.596 --> 00:26:58.896 A:middle
variety of photographs.

00:26:59.796 --> 00:27:01.776 A:middle
We're going to load a folder

00:26:59.796 --> 00:27:01.776 A:middle
We're going to load a folder

00:27:01.776 --> 00:27:03.546 A:middle
called content into an SFrame

00:27:03.546 --> 00:27:04.146 A:middle
for that one.

00:27:05.226 --> 00:27:06.786 A:middle
And then we're ready to go ahead

00:27:06.786 --> 00:27:07.556 A:middle
and train a model.

00:27:08.386 --> 00:27:10.276 A:middle
So I'm going to say model equals

00:27:10.846 --> 00:27:13.366 A:middle
tc.styletransfer.create.

00:27:13.786 --> 00:27:15.986 A:middle
And I'm going to pass in style

00:27:16.226 --> 00:27:18.886 A:middle
and content and that's all we

00:27:18.886 --> 00:27:19.116 A:middle
need.

00:27:19.486 --> 00:27:21.096 A:middle
But that's going to take a bit

00:27:21.096 --> 00:27:22.446 A:middle
too long to train for today's

00:27:22.446 --> 00:27:22.806 A:middle
demo.

00:27:23.276 --> 00:27:24.796 A:middle
So once again, I'm going to do

00:27:24.796 --> 00:27:25.746 A:middle
it like a cooking show, and

00:27:25.746 --> 00:27:26.596 A:middle
we're going to load up one that

00:27:26.596 --> 00:27:27.766 A:middle
we've had in the oven already.

00:27:28.526 --> 00:27:29.936 A:middle
I'm going to say model equals

00:27:29.936 --> 00:27:32.426 A:middle
tc.loadmodel and I'm going to

00:27:32.426 --> 00:27:34.576 A:middle
load up my already trained style

00:27:34.576 --> 00:27:35.296 A:middle
transfer model.

00:27:35.826 --> 00:27:38.546 A:middle
Let's take a look at some of

00:27:38.546 --> 00:27:40.026 A:middle
these style images to see what

00:27:40.026 --> 00:27:41.306 A:middle
we should expect this model to

00:27:41.306 --> 00:27:41.876 A:middle
produce.

00:27:42.876 --> 00:27:45.516 A:middle
We have a style image col-- we

00:27:45.516 --> 00:27:46.476 A:middle
have an image column in our

00:27:46.476 --> 00:27:47.336 A:middle
style SFrame.

00:27:47.746 --> 00:27:49.026 A:middle
And let's take a look at just

00:27:49.026 --> 00:27:50.336 A:middle
style number three and see what

00:27:50.336 --> 00:27:50.946 A:middle
that looks like.

00:27:51.796 --> 00:27:53.486 A:middle
It-- sort of like a pile of

00:27:53.486 --> 00:27:54.056 A:middle
firewood.

00:27:54.416 --> 00:27:57.036 A:middle
And this is pretty stylistic.

00:27:57.266 --> 00:27:57.966 A:middle
I think this would be

00:27:57.966 --> 00:27:59.626 A:middle
recognizable if we were to apply

00:27:59.626 --> 00:28:01.326 A:middle
it as a filter to another image.

00:27:59.626 --> 00:28:01.326 A:middle
it as a filter to another image.

00:28:02.676 --> 00:28:04.666 A:middle
Now let's take a look at some

00:28:04.666 --> 00:28:05.566 A:middle
content images.

00:28:06.016 --> 00:28:07.616 A:middle
I'm going to load up a test data

00:28:07.616 --> 00:28:07.916 A:middle
set.

00:28:08.126 --> 00:28:10.566 A:middle
And once again this is a data

00:28:10.566 --> 00:28:12.096 A:middle
set that is representative of

00:28:12.156 --> 00:28:13.936 A:middle
the types of images that users

00:28:13.936 --> 00:28:15.136 A:middle
will have at runtime in your

00:28:15.136 --> 00:28:15.326 A:middle
app.

00:28:15.776 --> 00:28:16.906 A:middle
And the important thing is that

00:28:16.906 --> 00:28:18.606 A:middle
the model never saw these at

00:28:18.606 --> 00:28:19.346 A:middle
training time.

00:28:19.656 --> 00:28:21.366 A:middle
So by evaluating with the test

00:28:21.366 --> 00:28:22.836 A:middle
images, we'll know whether the

00:28:22.836 --> 00:28:24.786 A:middle
model can generalize to users'

00:28:24.786 --> 00:28:25.096 A:middle
data.

00:28:26.206 --> 00:28:28.636 A:middle
I'm going to load up a test data

00:28:29.166 --> 00:28:30.496 A:middle
set now.

00:28:30.606 --> 00:28:32.746 A:middle
With tc.loadimages function once

00:28:32.746 --> 00:28:33.086 A:middle
again.

00:28:33.656 --> 00:28:34.906 A:middle
And we're going to call that

00:28:34.906 --> 00:28:36.006 A:middle
folder test.

00:28:37.046 --> 00:28:38.406 A:middle
And I'm going to pull out one

00:28:38.406 --> 00:28:39.696 A:middle
image from the test data set

00:28:39.696 --> 00:28:40.736 A:middle
called ample image.

00:28:41.216 --> 00:28:43.666 A:middle
And I'm just going to take the

00:28:43.666 --> 00:28:44.576 A:middle
first image there.

00:28:45.156 --> 00:28:48.016 A:middle
And I'm going to call .show.

00:28:48.016 --> 00:28:51.446 A:middle
So that we can we see what that

00:28:51.446 --> 00:28:52.526 A:middle
image looks like without any

00:28:52.526 --> 00:28:53.256 A:middle
filters applied.

00:28:54.016 --> 00:28:58.216 A:middle
That's my cat, seven of nine.

00:28:59.046 --> 00:29:02.306 A:middle
She always looks like that.

00:28:59.046 --> 00:29:02.306 A:middle
She always looks like that.

00:29:02.306 --> 00:29:04.546 A:middle
And we're going to go ahead and

00:29:04.546 --> 00:29:06.096 A:middle
stylize that image using the

00:29:06.096 --> 00:29:07.036 A:middle
model that we just trained.

00:29:08.516 --> 00:29:10.526 A:middle
So I'm going to say stylized

00:29:10.526 --> 00:29:13.236 A:middle
image equals model.stylize.

00:29:13.956 --> 00:29:15.876 A:middle
And in this case, the function

00:29:15.876 --> 00:29:17.486 A:middle
is called stylize because the

00:29:17.486 --> 00:29:19.386 A:middle
model is specific to the task of

00:29:19.386 --> 00:29:20.186 A:middle
style transfer.

00:29:20.416 --> 00:29:22.806 A:middle
And we're going to pass in that

00:29:22.806 --> 00:29:23.606 A:middle
sample image.

00:29:23.956 --> 00:29:25.416 A:middle
And I'm going to say style

00:29:25.416 --> 00:29:27.206 A:middle
equals three because that's the

00:29:27.206 --> 00:29:28.956 A:middle
style that we picked earlier

00:29:28.956 --> 00:29:30.146 A:middle
that looks like firewood here.

00:29:32.116 --> 00:29:33.956 A:middle
So let's see what that stylized

00:29:33.956 --> 00:29:34.656 A:middle
image looks like.

00:29:35.196 --> 00:29:38.646 A:middle
I can call .show on that, and

00:29:38.646 --> 00:29:39.976 A:middle
here is my cat looking like a

00:29:39.976 --> 00:29:40.746 A:middle
pile of firewood.

00:29:41.516 --> 00:29:46.426 A:middle
[ Applause ]

00:29:46.926 --> 00:29:48.376 A:middle
Let's make sure this works on

00:29:48.376 --> 00:29:49.256 A:middle
other styles, too.

00:29:49.946 --> 00:29:52.336 A:middle
I'm going to go ahead and make a

00:29:52.336 --> 00:29:58.496 A:middle
stylized image out of that

00:29:58.496 --> 00:29:59.256 A:middle
sample image.

00:29:59.576 --> 00:30:02.276 A:middle
And I'm going to specify a style

00:29:59.576 --> 00:30:02.276 A:middle
And I'm going to specify a style

00:30:02.276 --> 00:30:02.966 A:middle
equals seven.

00:30:03.556 --> 00:30:05.986 A:middle
And then let's see what that

00:30:05.986 --> 00:30:07.000 A:middle
looks like.

00:30:13.056 --> 00:30:13.896 A:middle
That looks pretty good.

00:30:13.896 --> 00:30:15.236 A:middle
I wonder what the style was that

00:30:15.236 --> 00:30:16.236 A:middle
we just applied to that.

00:30:16.716 --> 00:30:18.496 A:middle
Let's take a look at style

00:30:20.826 --> 00:30:21.000 A:middle
images.

00:30:25.306 --> 00:30:26.516 A:middle
Style image seven.

00:30:27.046 --> 00:30:30.066 A:middle
And once again we can just call

00:30:30.066 --> 00:30:31.436 A:middle
.show to see what that style

00:30:31.436 --> 00:30:33.496 A:middle
image looks like and yeah, that

00:30:33.496 --> 00:30:34.736 A:middle
looks like the filter that we

00:30:34.736 --> 00:30:35.746 A:middle
just applied to my cat.

00:30:36.426 --> 00:30:38.696 A:middle
Now that we've got a good style

00:30:38.696 --> 00:30:40.886 A:middle
transfer model, we can just call

00:30:41.216 --> 00:30:43.716 A:middle
model.exportcoreml exactly the

00:30:43.716 --> 00:30:45.206 A:middle
same as any other model, and

00:30:45.206 --> 00:30:47.000 A:middle
save it into Core ML format.

00:30:52.296 --> 00:30:54.126 A:middle
Now, let's switch over to the

00:30:54.126 --> 00:30:55.436 A:middle
iPhone where we have a style

00:30:55.436 --> 00:30:57.306 A:middle
transfer app ready to apply the

00:30:57.306 --> 00:30:58.306 A:middle
filters in this model.

00:30:58.886 --> 00:31:03.446 A:middle
So here I've got my iPhone once

00:30:58.886 --> 00:31:03.446 A:middle
So here I've got my iPhone once

00:31:03.446 --> 00:31:03.726 A:middle
again.

00:31:03.726 --> 00:31:05.426 A:middle
And I have an app called style

00:31:05.426 --> 00:31:05.936 A:middle
transfer.

00:31:06.696 --> 00:31:08.066 A:middle
I'm going to choose a photo from

00:31:08.066 --> 00:31:09.946 A:middle
my photo library to apply these

00:31:09.946 --> 00:31:11.256 A:middle
styles to.

00:31:11.796 --> 00:31:13.846 A:middle
These are my dogs.

00:31:16.136 --> 00:31:19.696 A:middle
This is Ryker and we're going to

00:31:19.696 --> 00:31:20.656 A:middle
see what styles we have

00:31:20.656 --> 00:31:21.696 A:middle
available in this app.

00:31:22.206 --> 00:31:23.706 A:middle
We can scroll through all of the

00:31:23.706 --> 00:31:26.126 A:middle
styles here and what's important

00:31:26.126 --> 00:31:27.766 A:middle
to note is that a single style

00:31:27.766 --> 00:31:29.596 A:middle
transfer model was trained on

00:31:29.596 --> 00:31:30.636 A:middle
all of these files.

00:31:30.976 --> 00:31:32.836 A:middle
And one model can include any

00:31:32.836 --> 00:31:33.676 A:middle
number of styles.

00:31:34.126 --> 00:31:35.636 A:middle
So to have multiple filters, you

00:31:35.636 --> 00:31:37.116 A:middle
don't need to greatly increase

00:31:37.166 --> 00:31:37.976 A:middle
the size of your app.

00:31:39.156 --> 00:31:40.376 A:middle
Let's see what those styles look

00:31:40.376 --> 00:31:43.036 A:middle
like applied to Ryker.

00:31:43.716 --> 00:31:46.000 A:middle
Pretty cool.

00:31:52.646 --> 00:31:52.976 A:middle
So--

00:31:53.516 --> 00:31:58.316 A:middle
[ Applause ]

00:31:58.816 --> 00:32:01.266 A:middle
So to recap what we just saw, we

00:31:58.816 --> 00:32:01.266 A:middle
So to recap what we just saw, we

00:32:01.266 --> 00:32:02.886 A:middle
loaded images into SFrame

00:32:02.886 --> 00:32:03.336 A:middle
format.

00:32:03.646 --> 00:32:05.576 A:middle
This time style and content

00:32:05.576 --> 00:32:07.346 A:middle
images into two SFrames.

00:32:07.836 --> 00:32:09.656 A:middle
We created a model using a

00:32:09.656 --> 00:32:10.966 A:middle
high-level API for style

00:32:10.966 --> 00:32:12.816 A:middle
transfer that operates directly

00:32:12.946 --> 00:32:14.576 A:middle
on a set of style images and a

00:32:14.576 --> 00:32:15.646 A:middle
set of content images.

00:32:16.436 --> 00:32:18.956 A:middle
We then stylize images to check

00:32:19.256 --> 00:32:20.546 A:middle
whether the model is performing

00:32:20.546 --> 00:32:20.836 A:middle
well.

00:32:21.356 --> 00:32:22.876 A:middle
We visualized those predictions

00:32:22.876 --> 00:32:23.706 A:middle
in Turi Create.

00:32:24.226 --> 00:32:25.686 A:middle
And finally we exported the

00:32:25.686 --> 00:32:27.566 A:middle
model in Core ML format for use

00:32:27.566 --> 00:32:29.996 A:middle
in our app.

00:32:30.636 --> 00:32:31.566 A:middle
Switching gears a bit.

00:32:31.616 --> 00:32:32.656 A:middle
I want to talk about some other

00:32:32.656 --> 00:32:34.336 A:middle
features in Turi Create 5.0.

00:32:35.066 --> 00:32:37.186 A:middle
We now have Mac GPU acceleration

00:32:37.536 --> 00:32:39.626 A:middle
offering up to a 12x performance

00:32:39.626 --> 00:32:40.726 A:middle
increase in image

00:32:40.726 --> 00:32:41.586 A:middle
classification.

00:32:41.756 --> 00:32:43.966 A:middle
And 9x in object detection, and

00:32:43.966 --> 00:32:45.226 A:middle
that's on an iMac Pro.

00:32:46.516 --> 00:32:50.586 A:middle
[ Applause ]

00:32:51.086 --> 00:32:53.096 A:middle
We have a new task available for

00:32:53.096 --> 00:32:54.616 A:middle
export into Core ML format.

00:32:54.876 --> 00:32:55.776 A:middle
Personalization.

00:32:56.466 --> 00:32:58.096 A:middle
The task here is to recommend

00:32:58.096 --> 00:33:00.496 A:middle
items for users based on user's

00:32:58.096 --> 00:33:00.496 A:middle
items for users based on user's

00:33:00.496 --> 00:33:01.686 A:middle
historical preferences.

00:33:02.896 --> 00:33:04.636 A:middle
This type of model is deployed

00:33:04.636 --> 00:33:06.506 A:middle
using Core ML's new custom model

00:33:06.506 --> 00:33:08.586 A:middle
support that's available on

00:33:08.586 --> 00:33:11.026 A:middle
macOS Mojave and on iOS 12.

00:33:11.686 --> 00:33:12.966 A:middle
This has been a top community

00:33:12.966 --> 00:33:14.576 A:middle
feature request since we open

00:33:14.576 --> 00:33:15.546 A:middle
sourced Turi Create.

00:33:15.806 --> 00:33:16.956 A:middle
So I'm really excited to bring

00:33:16.956 --> 00:33:17.576 A:middle
it to you today.

00:33:18.516 --> 00:33:23.546 A:middle
[ Applause ]

00:33:24.046 --> 00:33:25.846 A:middle
The recommender model in Core ML

00:33:26.076 --> 00:33:27.376 A:middle
looks just like any other Core

00:33:27.376 --> 00:33:27.956 A:middle
ML model.

00:33:28.266 --> 00:33:29.656 A:middle
But what's worth noting is

00:33:29.656 --> 00:33:30.876 A:middle
there's a section at the bottom

00:33:30.876 --> 00:33:32.496 A:middle
here called Dependencies.

00:33:33.046 --> 00:33:34.416 A:middle
And in this section, you can see

00:33:34.416 --> 00:33:36.156 A:middle
that this model uses a custom

00:33:36.156 --> 00:33:37.986 A:middle
model and that model is called

00:33:37.986 --> 00:33:39.006 A:middle
TC recommender.

00:33:39.506 --> 00:33:40.886 A:middle
And this is just Turi Create

00:33:41.036 --> 00:33:42.056 A:middle
providing support for

00:33:42.056 --> 00:33:44.206 A:middle
recommenders in Core ML through

00:33:44.206 --> 00:33:45.346 A:middle
that custom model API.

00:33:46.016 --> 00:33:49.476 A:middle
Using that model in Core ML look

00:33:49.536 --> 00:33:50.916 A:middle
very similar to any other Core

00:33:50.916 --> 00:33:51.776 A:middle
ML model as well.

00:33:52.316 --> 00:33:53.506 A:middle
You can just instantiate the

00:33:53.506 --> 00:33:55.696 A:middle
model, create your input.

00:33:55.776 --> 00:33:57.696 A:middle
So in this case, we've got that

00:33:57.696 --> 00:33:59.046 A:middle
avatar creation app.

00:33:59.386 --> 00:34:01.066 A:middle
And a user might have picked a

00:33:59.386 --> 00:34:01.066 A:middle
And a user might have picked a

00:34:01.066 --> 00:34:02.626 A:middle
brown beard and a brown

00:34:02.626 --> 00:34:04.276 A:middle
handlebar moustache and brown

00:34:04.276 --> 00:34:05.966 A:middle
long hair for their avatar.

00:34:06.346 --> 00:34:07.956 A:middle
And we can make predictions from

00:34:07.956 --> 00:34:08.426 A:middle
the model.

00:34:08.626 --> 00:34:10.246 A:middle
By providing those interactions

00:34:10.246 --> 00:34:10.886 A:middle
as input.

00:34:11.315 --> 00:34:13.416 A:middle
And where we say k10 means we'll

00:34:13.416 --> 00:34:14.996 A:middle
get the top ten predictions

00:34:15.346 --> 00:34:16.426 A:middle
given those inputs.

00:34:17.045 --> 00:34:20.686 A:middle
So to recap what we've learned

00:34:20.686 --> 00:34:21.116 A:middle
today.

00:34:22.286 --> 00:34:24.255 A:middle
Turi Create allows you to create

00:34:24.255 --> 00:34:26.196 A:middle
Core ML models to power

00:34:26.196 --> 00:34:27.755 A:middle
intelligent features in your

00:34:27.985 --> 00:34:28.286 A:middle
apps.

00:34:28.606 --> 00:34:30.775 A:middle
It uses a simple five-step

00:34:30.775 --> 00:34:33.235 A:middle
recipe starting with identifying

00:34:33.235 --> 00:34:34.275 A:middle
the task that you're doing.

00:34:34.485 --> 00:34:35.735 A:middle
And mapping it to a machine

00:34:35.735 --> 00:34:36.496 A:middle
learning task.

00:34:37.025 --> 00:34:39.045 A:middle
Gathering and annotating data

00:34:39.226 --> 00:34:41.126 A:middle
for use in training that model.

00:34:42.146 --> 00:34:43.946 A:middle
Training the model itself using

00:34:43.946 --> 00:34:45.246 A:middle
a simple, high-level API

00:34:45.755 --> 00:34:47.096 A:middle
specific to the task that you're

00:34:47.096 --> 00:34:47.505 A:middle
doing.

00:34:48.466 --> 00:34:50.235 A:middle
Evaluating that model in Turi

00:34:50.235 --> 00:34:51.996 A:middle
Create both qualitatively and

00:34:51.996 --> 00:34:52.826 A:middle
quantitatively.

00:34:53.366 --> 00:34:55.755 A:middle
And finally, deploying in Core

00:34:55.755 --> 00:34:56.406 A:middle
ML format.

00:34:58.936 --> 00:35:01.196 A:middle
That five-step recipe maps to

00:34:58.936 --> 00:35:01.196 A:middle
That five-step recipe maps to

00:35:01.196 --> 00:35:03.266 A:middle
code starting with import Turi

00:35:03.266 --> 00:35:03.646 A:middle
Create.

00:35:04.406 --> 00:35:05.726 A:middle
You can load data into the

00:35:05.726 --> 00:35:06.526 A:middle
SFrame format.

00:35:07.026 --> 00:35:08.566 A:middle
Create a model using that

00:35:08.596 --> 00:35:10.026 A:middle
task-specific API.

00:35:11.126 --> 00:35:12.726 A:middle
Evaluate the model with an

00:35:12.726 --> 00:35:14.076 A:middle
evaluate function that's once

00:35:14.076 --> 00:35:15.576 A:middle
again specific to the task that

00:35:15.576 --> 00:35:16.086 A:middle
you're doing.

00:35:16.646 --> 00:35:18.096 A:middle
And export for deployment,

00:35:18.356 --> 00:35:19.666 A:middle
calling the export Core ML

00:35:19.666 --> 00:35:20.066 A:middle
function.

00:35:20.536 --> 00:35:23.576 A:middle
Turi Create supports a broad

00:35:23.576 --> 00:35:24.736 A:middle
variety of machine learning

00:35:24.736 --> 00:35:25.296 A:middle
tasks.

00:35:25.736 --> 00:35:27.196 A:middle
Ranging from high-level tasks

00:35:27.196 --> 00:35:29.286 A:middle
like image classification and

00:35:29.286 --> 00:35:31.296 A:middle
text classification, all the way

00:35:31.296 --> 00:35:32.896 A:middle
to low-level machine learning

00:35:32.896 --> 00:35:33.436 A:middle
essentials.

00:35:33.436 --> 00:35:34.186 A:middle
Like regression and

00:35:34.186 --> 00:35:35.976 A:middle
classification on any type of

00:35:35.976 --> 00:35:36.246 A:middle
data.

00:35:38.006 --> 00:35:39.806 A:middle
And using the resulting models,

00:35:40.106 --> 00:35:41.266 A:middle
you can power intelligent

00:35:41.266 --> 00:35:42.986 A:middle
features in your apps like

00:35:42.986 --> 00:35:45.036 A:middle
object detection or style

00:35:45.036 --> 00:35:47.196 A:middle
transfer for use as a filter.

00:35:48.216 --> 00:35:50.306 A:middle
For more information, please see

00:35:50.306 --> 00:35:52.606 A:middle
the Developer.Apple.com session

00:35:52.806 --> 00:35:53.306 A:middle
URL.

00:35:53.716 --> 00:35:55.316 A:middle
And please come to our labs.

00:35:55.316 --> 00:35:56.736 A:middle
We've got a lab this afternoon

00:35:56.886 --> 00:35:58.056 A:middle
and Friday afternoon.

00:35:58.306 --> 00:35:59.726 A:middle
And we welcome your feedback.

00:36:00.096 --> 00:36:01.276 A:middle
We're happy to answer any

00:36:01.276 --> 00:36:02.126 A:middle
questions you have.

00:36:02.386 --> 00:36:04.136 A:middle
And we'll have all of the demos

00:36:04.136 --> 00:36:05.936 A:middle
we showed today available to

00:36:05.936 --> 00:36:06.376 A:middle
explore.

00:36:07.186 --> 00:36:07.506 A:middle
Thank you.

00:36:08.516 --> 00:36:11.500 A:middle
[ Applause ]
