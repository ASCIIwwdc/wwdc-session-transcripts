WEBVTT

00:00:07.016 --> 00:00:15.500 A:middle
[ Music ]

00:00:21.516 --> 00:00:28.316 A:middle
[ Applause ]

00:00:28.816 --> 00:00:30.896 A:middle
&gt;&gt; Good afternoon, everyone.

00:00:31.826 --> 00:00:33.356 A:middle
Welcome to our talk on Metal for

00:00:33.356 --> 00:00:34.666 A:middle
Accelerating Machine Learning.

00:00:35.596 --> 00:00:37.366 A:middle
My name is Anna Tikhonova, and

00:00:37.366 --> 00:00:38.606 A:middle
I'm an Engineer on the GPU

00:00:38.606 --> 00:00:40.006 A:middle
Software Team.

00:00:42.056 --> 00:00:44.126 A:middle
The Metal Performance Shaders

00:00:44.126 --> 00:00:45.596 A:middle
Framework is built on top of

00:00:45.596 --> 00:00:45.926 A:middle
Metal.

00:00:46.576 --> 00:00:48.216 A:middle
And it provides GPU accelerated

00:00:48.256 --> 00:00:49.886 A:middle
primitives that are optimized

00:00:50.036 --> 00:00:51.646 A:middle
for both iOS and macOS.

00:00:52.916 --> 00:00:54.516 A:middle
We provide primitives for image

00:00:54.516 --> 00:00:56.846 A:middle
processing, linear algebra, and

00:00:56.846 --> 00:00:57.566 A:middle
machine learning.

00:00:58.636 --> 00:01:00.106 A:middle
We talked extensively about

00:00:58.636 --> 00:01:00.106 A:middle
We talked extensively about

00:01:00.106 --> 00:01:01.956 A:middle
inference in our past WWDC

00:01:01.956 --> 00:01:03.416 A:middle
sessions, so I just want to

00:01:03.416 --> 00:01:05.316 A:middle
highlight them here.

00:01:06.456 --> 00:01:08.466 A:middle
And this year, we've also added

00:01:08.466 --> 00:01:10.326 A:middle
support for training on both iOS

00:01:10.326 --> 00:01:10.896 A:middle
and macOS.

00:01:12.516 --> 00:01:15.436 A:middle
[ Applause ]

00:01:15.936 --> 00:01:16.376 A:middle
Thank you.

00:01:18.876 --> 00:01:20.136 A:middle
We've also added support for

00:01:20.136 --> 00:01:21.586 A:middle
accelerated ray tracing on our

00:01:21.586 --> 00:01:23.946 A:middle
platform, and we had an entire

00:01:23.946 --> 00:01:25.936 A:middle
session on this topic earlier

00:01:25.936 --> 00:01:26.406 A:middle
this week.

00:01:26.676 --> 00:01:28.026 A:middle
So, it was titled Metal for Ray

00:01:28.026 --> 00:01:29.136 A:middle
Tracing Acceleration.

00:01:29.886 --> 00:01:31.666 A:middle
And the video for the session

00:01:31.666 --> 00:01:32.686 A:middle
will be available online

00:01:32.686 --> 00:01:33.086 A:middle
shortly.

00:01:34.406 --> 00:01:35.846 A:middle
In this session, I will talk

00:01:35.846 --> 00:01:36.996 A:middle
primarily about machine

00:01:36.996 --> 00:01:38.886 A:middle
learning, specifically training.

00:01:39.506 --> 00:01:43.206 A:middle
So, I mentioned training and

00:01:43.206 --> 00:01:43.586 A:middle
inference.

00:01:44.706 --> 00:01:46.316 A:middle
Deep learning algorithms consist

00:01:46.316 --> 00:01:47.256 A:middle
of these two phases.

00:01:47.646 --> 00:01:49.086 A:middle
The first phase is the training

00:01:49.086 --> 00:01:49.476 A:middle
phase.

00:01:50.526 --> 00:01:52.096 A:middle
So, let's use an example where

00:01:52.096 --> 00:01:53.866 A:middle
we want to train a model, to

00:01:53.866 --> 00:01:55.756 A:middle
categorize images into classes

00:01:56.236 --> 00:01:58.056 A:middle
like cats, dogs, giraffes,

00:01:58.056 --> 00:01:58.536 A:middle
etcetera.

00:02:00.036 --> 00:02:02.016 A:middle
So, in order to train a model to

00:02:02.016 --> 00:02:03.896 A:middle
recognize cats, we need to feed

00:02:03.896 --> 00:02:05.586 A:middle
it a large number of labeled

00:02:05.586 --> 00:02:06.476 A:middle
images of cats.

00:02:07.116 --> 00:02:09.156 A:middle
And same for the rabbits and all

00:02:09.156 --> 00:02:10.446 A:middle
of the other animals you want

00:02:10.446 --> 00:02:11.416 A:middle
your model to be able to

00:02:11.416 --> 00:02:11.936 A:middle
recognize.

00:02:12.436 --> 00:02:15.606 A:middle
Training is a computationally

00:02:15.606 --> 00:02:17.396 A:middle
expensive and time-consuming,

00:02:17.466 --> 00:02:18.406 A:middle
iterative process.

00:02:19.456 --> 00:02:20.806 A:middle
The result of training are

00:02:20.806 --> 00:02:21.766 A:middle
trained parameters.

00:02:23.956 --> 00:02:25.786 A:middle
The trained parameters are

00:02:25.786 --> 00:02:27.236 A:middle
required for the next phase, the

00:02:27.236 --> 00:02:27.966 A:middle
inference phase.

00:02:28.746 --> 00:02:30.396 A:middle
This is when your model is

00:02:30.396 --> 00:02:31.836 A:middle
presented with a new image, that

00:02:31.836 --> 00:02:33.286 A:middle
is never seen before, and it

00:02:33.286 --> 00:02:34.846 A:middle
needs to classify it based on

00:02:34.846 --> 00:02:35.746 A:middle
the trained parameters.

00:02:36.266 --> 00:02:36.836 A:middle
This is a cat.

00:02:38.336 --> 00:02:40.266 A:middle
We now provide GPU acceleration

00:02:40.516 --> 00:02:41.976 A:middle
for both the training and

00:02:41.976 --> 00:02:42.826 A:middle
inference phases.

00:02:43.466 --> 00:02:46.896 A:middle
But before I talk about

00:02:46.896 --> 00:02:48.336 A:middle
training, let me tell you about

00:02:48.336 --> 00:02:49.886 A:middle
some enhancements to CNN

00:02:49.886 --> 00:02:51.106 A:middle
Inference we've added this year.

00:02:51.976 --> 00:02:53.566 A:middle
We now have support for FP16

00:02:53.626 --> 00:02:56.116 A:middle
accumulation for the convolution

00:02:56.116 --> 00:02:57.536 A:middle
and convolution transpose

00:02:57.536 --> 00:02:57.966 A:middle
primitives.

00:02:58.996 --> 00:03:00.556 A:middle
This new feature is available on

00:02:58.996 --> 00:03:00.556 A:middle
This new feature is available on

00:03:00.556 --> 00:03:02.936 A:middle
devices with an Apple A11 Bionic

00:03:02.936 --> 00:03:03.216 A:middle
GPU.

00:03:04.446 --> 00:03:06.516 A:middle
We find that using FP16

00:03:06.546 --> 00:03:07.856 A:middle
accumulation for inference

00:03:07.856 --> 00:03:09.266 A:middle
workloads is more than

00:03:09.266 --> 00:03:10.956 A:middle
sufficient in terms of precision

00:03:11.996 --> 00:03:13.636 A:middle
for many commonly used neural

00:03:13.636 --> 00:03:14.036 A:middle
networks.

00:03:15.656 --> 00:03:17.866 A:middle
FP16 accumulation offers better

00:03:17.866 --> 00:03:19.926 A:middle
precision and significant power

00:03:19.926 --> 00:03:20.556 A:middle
benefits.

00:03:20.736 --> 00:03:22.196 A:middle
So, please take advantage of it

00:03:22.706 --> 00:03:23.926 A:middle
in your inference workloads.

00:03:25.216 --> 00:03:26.996 A:middle
And this is an example of how

00:03:26.996 --> 00:03:29.046 A:middle
you can enable FP16 accumulation

00:03:29.306 --> 00:03:30.536 A:middle
for a convolution primitive.

00:03:30.996 --> 00:03:31.806 A:middle
You just need to set the

00:03:31.806 --> 00:03:33.446 A:middle
accumulatorPrecisionOption

00:03:33.446 --> 00:03:33.906 A:middle
property.

00:03:36.126 --> 00:03:38.536 A:middle
And now, let's talk in depth

00:03:38.536 --> 00:03:40.296 A:middle
about the main topic of this

00:03:40.296 --> 00:03:41.986 A:middle
session, training neural

00:03:41.986 --> 00:03:42.536 A:middle
networks.

00:03:43.136 --> 00:03:44.356 A:middle
And let's start with training

00:03:44.356 --> 00:03:46.476 A:middle
convolutional neural networks.

00:03:48.316 --> 00:03:50.296 A:middle
So, here we have a simple,

00:03:50.296 --> 00:03:51.856 A:middle
handwritten, digit recognition

00:03:51.856 --> 00:03:54.606 A:middle
network that takes an image of a

00:03:54.606 --> 00:03:57.336 A:middle
handwritten image as input, and

00:03:57.646 --> 00:03:59.256 A:middle
assigns it to one of 10 classes,

00:03:59.506 --> 00:04:00.386 A:middle
from 0 to 9.

00:03:59.506 --> 00:04:00.386 A:middle
from 0 to 9.

00:04:00.386 --> 00:04:02.826 A:middle
In this example, we are

00:04:02.826 --> 00:04:04.546 A:middle
correctly classifying this image

00:04:04.826 --> 00:04:06.406 A:middle
as an image of a digit 7.

00:04:07.086 --> 00:04:11.496 A:middle
For inference, we initialize our

00:04:11.496 --> 00:04:12.886 A:middle
network with trained parameters.

00:04:14.086 --> 00:04:15.436 A:middle
So, in this example, the trained

00:04:15.436 --> 00:04:16.716 A:middle
parameters add the weights for

00:04:16.716 --> 00:04:18.196 A:middle
the convolution, and fully

00:04:18.196 --> 00:04:19.106 A:middle
connected primitives.

00:04:20.426 --> 00:04:21.886 A:middle
The goal of a training algorithm

00:04:21.926 --> 00:04:23.046 A:middle
is to compute these trained

00:04:23.046 --> 00:04:24.586 A:middle
parameters, so the network can

00:04:24.586 --> 00:04:26.706 A:middle
use them to map inputs to

00:04:26.706 --> 00:04:27.896 A:middle
correct outputs during

00:04:27.926 --> 00:04:28.416 A:middle
inference.

00:04:29.076 --> 00:04:31.436 A:middle
When we start the training

00:04:31.436 --> 00:04:32.796 A:middle
process, we don't have any

00:04:32.796 --> 00:04:33.106 A:middle
weights.

00:04:33.496 --> 00:04:34.536 A:middle
We need to compute them.

00:04:34.786 --> 00:04:37.116 A:middle
So, the first step is to

00:04:37.246 --> 00:04:38.446 A:middle
initialize the weights with

00:04:38.446 --> 00:04:39.386 A:middle
small, random numbers.

00:04:40.026 --> 00:04:41.106 A:middle
And now we are ready to train

00:04:41.106 --> 00:04:41.676 A:middle
this network.

00:04:41.946 --> 00:04:43.386 A:middle
So, let's take a look at all the

00:04:43.436 --> 00:04:44.696 A:middle
steps involved in a training

00:04:44.696 --> 00:04:45.236 A:middle
process.

00:04:47.836 --> 00:04:49.146 A:middle
Training is an iterative

00:04:49.216 --> 00:04:51.006 A:middle
process, and each iteration of

00:04:51.006 --> 00:04:52.506 A:middle
training can be divided into

00:04:52.506 --> 00:04:53.056 A:middle
four steps.

00:04:53.296 --> 00:04:55.256 A:middle
The first step is the forward

00:04:55.256 --> 00:04:55.376 A:middle
pass.

00:04:56.026 --> 00:04:57.556 A:middle
This is when we take an input

00:04:57.696 --> 00:04:59.366 A:middle
and pass it to our network to

00:04:59.366 --> 00:05:00.296 A:middle
produce an output.

00:04:59.366 --> 00:05:00.296 A:middle
produce an output.

00:05:01.106 --> 00:05:02.396 A:middle
It's very similar to inference.

00:05:04.226 --> 00:05:05.416 A:middle
And next, we need to compute

00:05:05.416 --> 00:05:05.766 A:middle
loss.

00:05:06.346 --> 00:05:08.156 A:middle
So, loss intuitively measures

00:05:08.196 --> 00:05:09.326 A:middle
the difference between the

00:05:09.326 --> 00:05:10.906 A:middle
network's output and the ground

00:05:10.906 --> 00:05:11.196 A:middle
truth.

00:05:13.336 --> 00:05:14.726 A:middle
The objective of a training

00:05:14.726 --> 00:05:16.216 A:middle
algorithm is to minimize loss.

00:05:17.076 --> 00:05:20.596 A:middle
Our next step is the gradient

00:05:21.246 --> 00:05:21.426 A:middle
pass.

00:05:21.536 --> 00:05:22.926 A:middle
This is when we propagate this

00:05:22.926 --> 00:05:24.136 A:middle
difference when the network's

00:05:24.136 --> 00:05:26.166 A:middle
output and the ground truth,

00:05:26.166 --> 00:05:28.506 A:middle
back to the network to update

00:05:28.506 --> 00:05:28.756 A:middle
weights.

00:05:29.966 --> 00:05:32.486 A:middle
The idea is that as training

00:05:32.486 --> 00:05:34.036 A:middle
continues, our network is

00:05:34.036 --> 00:05:35.656 A:middle
becoming better trained, so it's

00:05:35.656 --> 00:05:37.886 A:middle
better able to map inputs to

00:05:37.886 --> 00:05:40.486 A:middle
correct outputs, which in turn

00:05:40.486 --> 00:05:41.426 A:middle
helps to minimize loss.

00:05:42.346 --> 00:05:45.136 A:middle
So, this is an overview and now

00:05:45.136 --> 00:05:46.466 A:middle
let's take a look at each one of

00:05:46.466 --> 00:05:47.686 A:middle
these steps in more detail.

00:05:47.986 --> 00:05:50.986 A:middle
The forward pass involves

00:05:51.586 --> 00:05:53.226 A:middle
propagation forward to the

00:05:53.226 --> 00:05:55.046 A:middle
network, to compute an output.

00:05:56.116 --> 00:05:57.416 A:middle
As you can see, during this

00:05:57.416 --> 00:05:59.246 A:middle
first situation of training, our

00:05:59.246 --> 00:06:00.616 A:middle
network is not doing so well.

00:05:59.246 --> 00:06:00.616 A:middle
network is not doing so well.

00:06:01.256 --> 00:06:03.136 A:middle
It's outputting a result that's

00:06:03.136 --> 00:06:03.806 A:middle
clearly wrong.

00:06:03.806 --> 00:06:05.056 A:middle
So, why is it doing so badly?

00:06:05.656 --> 00:06:06.896 A:middle
Well, this is expected.

00:06:06.896 --> 00:06:08.756 A:middle
We just initialized our weights

00:06:08.756 --> 00:06:09.746 A:middle
with some random numbers.

00:06:09.836 --> 00:06:11.046 A:middle
We haven't trained the network

00:06:11.046 --> 00:06:12.626 A:middle
to do any better yet.

00:06:13.656 --> 00:06:15.636 A:middle
So, now, we need some weight to

00:06:15.636 --> 00:06:18.296 A:middle
quantify how well or how badly

00:06:18.376 --> 00:06:19.636 A:middle
our network is currently doing.

00:06:20.086 --> 00:06:21.886 A:middle
So, we can use this information

00:06:22.476 --> 00:06:24.206 A:middle
to improve our weights, so that

00:06:24.206 --> 00:06:25.686 A:middle
hopefully after more iterations

00:06:25.686 --> 00:06:27.096 A:middle
of training, the network can

00:06:27.096 --> 00:06:28.106 A:middle
produce a better result.

00:06:28.776 --> 00:06:31.696 A:middle
But in order to know how well

00:06:31.696 --> 00:06:33.006 A:middle
we're doing, we need to know

00:06:33.006 --> 00:06:34.146 A:middle
what the right answers are.

00:06:34.666 --> 00:06:36.326 A:middle
So, the ground truth, which I

00:06:36.326 --> 00:06:38.406 A:middle
will call labels from now on, is

00:06:38.406 --> 00:06:40.276 A:middle
an input to the network along

00:06:40.276 --> 00:06:41.256 A:middle
with the input image.

00:06:42.356 --> 00:06:43.646 A:middle
So, in this case, it's a vector

00:06:43.646 --> 00:06:45.276 A:middle
of 10 values, where we have 1

00:06:45.276 --> 00:06:47.006 A:middle
for the correct class, Class 7,

00:06:47.376 --> 00:06:48.756 A:middle
and zeros for all the other

00:06:49.566 --> 00:06:49.786 A:middle
classes.

00:06:51.376 --> 00:06:53.526 A:middle
The output of the network is our

00:06:53.526 --> 00:06:54.496 A:middle
10 probabilities.

00:06:54.926 --> 00:06:55.526 A:middle
One per class.

00:06:56.156 --> 00:06:58.136 A:middle
So, as you can see in this first

00:06:58.136 --> 00:06:59.236 A:middle
situation of training, the

00:06:59.236 --> 00:07:01.116 A:middle
network is producing a very low

00:06:59.236 --> 00:07:01.116 A:middle
network is producing a very low

00:07:01.116 --> 00:07:03.026 A:middle
result for the correct Class 7,

00:07:03.656 --> 00:07:05.336 A:middle
and it's assigning the highest

00:07:05.336 --> 00:07:07.686 A:middle
probability to a Class 9, which

00:07:07.686 --> 00:07:08.976 A:middle
is why the network is returning

00:07:08.976 --> 00:07:09.756 A:middle
9 as the answer.

00:07:11.486 --> 00:07:12.566 A:middle
So, now we take all of this

00:07:12.566 --> 00:07:14.576 A:middle
information and we pass it to

00:07:14.776 --> 00:07:15.646 A:middle
our loss primitive.

00:07:16.316 --> 00:07:20.386 A:middle
And as I mentioned previously,

00:07:21.476 --> 00:07:23.266 A:middle
loss measures the difference

00:07:23.476 --> 00:07:25.506 A:middle
between the network's output and

00:07:25.666 --> 00:07:26.466 A:middle
the ground truth.

00:07:27.266 --> 00:07:28.836 A:middle
And the objective of a training

00:07:28.836 --> 00:07:30.216 A:middle
algorithm is to minimize loss.

00:07:32.306 --> 00:07:33.756 A:middle
And now, we also need the second

00:07:33.756 --> 00:07:36.106 A:middle
half of the graph.

00:07:36.616 --> 00:07:37.646 A:middle
The second half of the graph

00:07:37.876 --> 00:07:40.736 A:middle
contains gradient primitives for

00:07:40.736 --> 00:07:41.876 A:middle
each responding forward

00:07:41.876 --> 00:07:42.226 A:middle
primitive.

00:07:43.286 --> 00:07:45.456 A:middle
The gradient primitives compute

00:07:45.456 --> 00:07:47.166 A:middle
gradients that are needed to

00:07:47.166 --> 00:07:48.306 A:middle
update weights.

00:07:49.136 --> 00:07:52.366 A:middle
So, the loss primitive computes

00:07:52.786 --> 00:07:54.856 A:middle
the first gradient, which is a

00:07:54.856 --> 00:07:56.146 A:middle
derivative of a chosen loss

00:07:56.146 --> 00:07:57.376 A:middle
function with respect to its

00:07:57.376 --> 00:07:57.756 A:middle
inputs.

00:07:58.286 --> 00:07:59.646 A:middle
And then we take this gradient

00:08:00.006 --> 00:08:02.926 A:middle
and back propagate it, backward

00:08:02.926 --> 00:08:04.596 A:middle
through the network, backward

00:08:04.596 --> 00:08:07.586 A:middle
through the first gradient

00:08:07.586 --> 00:08:08.966 A:middle
primitive in the backward

00:08:08.966 --> 00:08:09.496 A:middle
direction.

00:08:09.556 --> 00:08:11.196 A:middle
In this case, it's the SoftMax

00:08:12.026 --> 00:08:12.836 A:middle
gradient primitive.

00:08:14.036 --> 00:08:15.266 A:middle
And we use the Chain Rule to do

00:08:15.266 --> 00:08:15.486 A:middle
that.

00:08:15.576 --> 00:08:16.796 A:middle
So, the Chain Rule allows us to

00:08:16.796 --> 00:08:18.116 A:middle
back propagate gradients,

00:08:18.116 --> 00:08:19.106 A:middle
backwards through the network.

00:08:20.486 --> 00:08:21.556 A:middle
And we're computing these

00:08:21.556 --> 00:08:23.396 A:middle
gradients so that we can update

00:08:23.396 --> 00:08:23.796 A:middle
weights.

00:08:24.166 --> 00:08:25.736 A:middle
So, we're computing very small

00:08:25.736 --> 00:08:27.376 A:middle
deltas to apply to the weights,

00:08:28.016 --> 00:08:29.216 A:middle
in each iteration of training.

00:08:29.766 --> 00:08:32.645 A:middle
And then we can use these

00:08:32.645 --> 00:08:34.056 A:middle
updated weights in the next

00:08:34.056 --> 00:08:36.395 A:middle
iteration of training, to

00:08:36.395 --> 00:08:37.785 A:middle
ideally produce a lower loss

00:08:37.785 --> 00:08:38.816 A:middle
value, which is what we're

00:08:38.816 --> 00:08:39.626 A:middle
trying to minimize.

00:08:43.606 --> 00:08:45.156 A:middle
In practice, any situation of

00:08:45.156 --> 00:08:47.086 A:middle
training, we're not going to

00:08:47.086 --> 00:08:48.506 A:middle
operate on a single image.

00:08:49.116 --> 00:08:50.666 A:middle
We're going to operate on a

00:08:50.666 --> 00:08:52.226 A:middle
group or a batch of images.

00:08:52.226 --> 00:08:54.396 A:middle
For example, a batch of size 32

00:08:54.396 --> 00:08:55.056 A:middle
or 64.

00:08:55.566 --> 00:08:57.176 A:middle
And we need a corresponding

00:08:57.176 --> 00:08:59.916 A:middle
batch of labels, for loss

00:08:59.916 --> 00:09:00.576 A:middle
computation.

00:08:59.916 --> 00:09:00.576 A:middle
computation.

00:09:00.736 --> 00:09:02.096 A:middle
So, in this case, we have a

00:09:02.096 --> 00:09:04.046 A:middle
batch of labels, was 1 for the

00:09:04.046 --> 00:09:05.426 A:middle
correct class and zeroes

00:09:05.426 --> 00:09:05.976 A:middle
everywhere else.

00:09:09.506 --> 00:09:10.596 A:middle
And in each situation of

00:09:10.596 --> 00:09:12.176 A:middle
training, we're going to use a

00:09:12.176 --> 00:09:14.366 A:middle
different batch of images and a

00:09:14.416 --> 00:09:15.716 A:middle
responding batch of labels.

00:09:16.166 --> 00:09:17.166 A:middle
So, let's now run through

00:09:17.166 --> 00:09:18.596 A:middle
several iterations of training.

00:09:21.066 --> 00:09:23.686 A:middle
For the first batch of images,

00:09:23.686 --> 00:09:25.006 A:middle
we're doing a forward pass,

00:09:25.086 --> 00:09:27.276 A:middle
computing loss, and doing a

00:09:27.276 --> 00:09:28.846 A:middle
gradient pass.

00:09:28.976 --> 00:09:29.926 A:middle
And updating weights.

00:09:30.356 --> 00:09:31.906 A:middle
So, what happens with the second

00:09:31.906 --> 00:09:32.276 A:middle
batch?

00:09:32.536 --> 00:09:33.876 A:middle
Exactly the same process.

00:09:34.306 --> 00:09:35.446 A:middle
The forward pass, then we

00:09:35.446 --> 00:09:37.276 A:middle
compute loss, to the gradient

00:09:37.276 --> 00:09:38.656 A:middle
pass, and update weights.

00:09:40.156 --> 00:09:41.566 A:middle
And as we go through iterations

00:09:41.566 --> 00:09:44.126 A:middle
of training, we want the loss

00:09:44.616 --> 00:09:47.006 A:middle
for our network to decrease and

00:09:47.066 --> 00:09:48.796 A:middle
the accuracy of the network to

00:09:48.796 --> 00:09:49.186 A:middle
increase.

00:09:49.576 --> 00:09:51.526 A:middle
And we continue training until

00:09:51.526 --> 00:09:52.736 A:middle
the loss falls below a

00:09:52.736 --> 00:09:54.756 A:middle
particular threshold and the

00:09:54.756 --> 00:09:56.916 A:middle
accuracy of our network reaches

00:09:56.916 --> 00:09:57.626 A:middle
a desired level.

00:09:58.426 --> 00:09:59.666 A:middle
And then we know that the

00:09:59.666 --> 00:10:01.206 A:middle
network is fully trained and now

00:09:59.666 --> 00:10:01.206 A:middle
network is fully trained and now

00:10:01.206 --> 00:10:02.496 A:middle
we can use the computed trained

00:10:02.526 --> 00:10:03.976 A:middle
parameters for inference.

00:10:04.826 --> 00:10:06.196 A:middle
And now, let's take a look at

00:10:06.666 --> 00:10:08.286 A:middle
the steps necessary to train a

00:10:08.286 --> 00:10:10.046 A:middle
neural network using the Metal

00:10:10.046 --> 00:10:11.336 A:middle
Performance Shaders Framework.

00:10:11.516 --> 00:10:13.116 A:middle
Neural networks are often

00:10:13.116 --> 00:10:14.826 A:middle
described using graph

00:10:14.826 --> 00:10:15.516 A:middle
abstraction.

00:10:15.816 --> 00:10:17.726 A:middle
So, in MPS, we enable you to

00:10:17.726 --> 00:10:18.936 A:middle
describe your networks as a

00:10:18.936 --> 00:10:19.316 A:middle
graph.

00:10:20.996 --> 00:10:22.326 A:middle
So, the first step is to create

00:10:22.326 --> 00:10:22.916 A:middle
a training graph.

00:10:24.526 --> 00:10:25.526 A:middle
Then we need to prepare our

00:10:25.526 --> 00:10:26.216 A:middle
inputs.

00:10:26.456 --> 00:10:27.876 A:middle
We need to specify weights.

00:10:28.066 --> 00:10:29.306 A:middle
And then we execute the graph.

00:10:29.476 --> 00:10:31.186 A:middle
So, we run the forward paths,

00:10:31.346 --> 00:10:33.166 A:middle
compute loss, do the gradient

00:10:33.226 --> 00:10:34.496 A:middle
pass, and update weights.

00:10:35.266 --> 00:10:37.086 A:middle
And training is an iterative

00:10:37.176 --> 00:10:37.646 A:middle
process.

00:10:38.706 --> 00:10:40.486 A:middle
It can take many iterations to

00:10:40.486 --> 00:10:41.246 A:middle
train a network.

00:10:41.246 --> 00:10:42.936 A:middle
So, we'll also need to know when

00:10:42.936 --> 00:10:43.806 A:middle
we can stop training.

00:10:43.806 --> 00:10:45.306 A:middle
So, let's now discuss each one

00:10:45.306 --> 00:10:47.046 A:middle
of these topics in more detail.

00:10:47.576 --> 00:10:51.246 A:middle
Let's start with creating a

00:10:51.936 --> 00:10:52.486 A:middle
training graph.

00:10:52.806 --> 00:10:54.626 A:middle
So, as I said, in MPS, we enable

00:10:54.626 --> 00:10:56.236 A:middle
you to describe your networks as

00:10:56.236 --> 00:10:57.636 A:middle
a graph using a neural network

00:10:57.636 --> 00:10:58.336 A:middle
graph API.

00:10:58.886 --> 00:11:00.296 A:middle
So, here we again have a

00:10:58.886 --> 00:11:00.296 A:middle
So, here we again have a

00:11:00.296 --> 00:11:02.106 A:middle
visualization of our

00:11:02.106 --> 00:11:03.576 A:middle
handwritten, digit recognition

00:11:03.576 --> 00:11:03.966 A:middle
network.

00:11:04.656 --> 00:11:06.276 A:middle
But in this visualization, you

00:11:06.276 --> 00:11:08.026 A:middle
can also see the image notes.

00:11:08.026 --> 00:11:09.846 A:middle
They're the small white notes.

00:11:10.576 --> 00:11:12.666 A:middle
The image notes are for your

00:11:12.666 --> 00:11:12.936 A:middle
data.

00:11:13.426 --> 00:11:15.026 A:middle
For your input, your outputs,

00:11:15.026 --> 00:11:16.356 A:middle
and all of the intermediate

00:11:17.136 --> 00:11:17.346 A:middle
results.

00:11:18.256 --> 00:11:20.576 A:middle
They describe how data moves

00:11:20.576 --> 00:11:21.866 A:middle
between different operations.

00:11:22.766 --> 00:11:24.026 A:middle
And then, operations on the

00:11:24.026 --> 00:11:25.786 A:middle
data, like convolution and

00:11:25.816 --> 00:11:28.976 A:middle
pooling, are described with your

00:11:29.276 --> 00:11:29.826 A:middle
filter nodes.

00:11:30.626 --> 00:11:32.416 A:middle
We support all of the nodes

00:11:32.416 --> 00:11:34.236 A:middle
necessary to create commonly

00:11:34.236 --> 00:11:35.716 A:middle
used neural networks.

00:11:36.306 --> 00:11:38.316 A:middle
And now, let's take a look at

00:11:38.316 --> 00:11:39.716 A:middle
how easy it is to use the neural

00:11:39.716 --> 00:11:40.696 A:middle
network graph API.

00:11:41.346 --> 00:11:43.916 A:middle
So, here's an example of how you

00:11:43.916 --> 00:11:47.006 A:middle
can create an MPSImageNode using

00:11:47.006 --> 00:11:48.136 A:middle
the neural network graph API.

00:11:48.786 --> 00:11:49.906 A:middle
And this is how you would create

00:11:49.906 --> 00:11:51.656 A:middle
a convolution node using the

00:11:51.656 --> 00:11:52.296 A:middle
graph API.

00:11:53.416 --> 00:11:55.676 A:middle
And now, for every forward node,

00:11:56.046 --> 00:11:58.016 A:middle
we support a corresponding

00:11:58.066 --> 00:11:59.416 A:middle
gradient node for training.

00:11:59.796 --> 00:12:01.356 A:middle
It takes a single line of code

00:11:59.796 --> 00:12:01.356 A:middle
It takes a single line of code

00:12:01.686 --> 00:12:03.176 A:middle
to create a gradient node from

00:12:03.176 --> 00:12:03.856 A:middle
the forward node.

00:12:04.226 --> 00:12:05.976 A:middle
So, here is an example of how

00:12:05.976 --> 00:12:07.296 A:middle
you can create a gradient

00:12:07.296 --> 00:12:08.746 A:middle
convolution node from the

00:12:08.746 --> 00:12:10.266 A:middle
convolution node.

00:12:12.656 --> 00:12:14.376 A:middle
And now, let's build an entire

00:12:14.376 --> 00:12:14.796 A:middle
graph.

00:12:16.206 --> 00:12:18.016 A:middle
So, here we have a very small

00:12:18.016 --> 00:12:18.476 A:middle
network.

00:12:18.476 --> 00:12:19.946 A:middle
We have a convolution node

00:12:19.946 --> 00:12:21.226 A:middle
followed by a pooling node,

00:12:21.356 --> 00:12:22.776 A:middle
followed by another convolution

00:12:22.776 --> 00:12:22.976 A:middle
node.

00:12:23.916 --> 00:12:25.116 A:middle
So, how do we connect these

00:12:25.116 --> 00:12:27.356 A:middle
nodes into a graph?

00:12:27.966 --> 00:12:28.886 A:middle
So, that's easy.

00:12:29.636 --> 00:12:32.396 A:middle
We take the result node of --

00:12:32.396 --> 00:12:34.796 A:middle
the result image of one node and

00:12:34.836 --> 00:12:36.926 A:middle
pass it as a source image to the

00:12:36.926 --> 00:12:37.776 A:middle
subsequent node.

00:12:38.976 --> 00:12:40.306 A:middle
And here we have an entire

00:12:40.306 --> 00:12:41.576 A:middle
connected graph.

00:12:42.716 --> 00:12:44.416 A:middle
And now, let's build a training

00:12:44.416 --> 00:12:44.806 A:middle
graph.

00:12:45.286 --> 00:12:47.776 A:middle
So first, we need to add a loss

00:12:47.776 --> 00:12:49.956 A:middle
node to the graph.

00:12:50.056 --> 00:12:51.516 A:middle
And now, let's add some gradient

00:12:51.516 --> 00:12:51.776 A:middle
nodes.

00:12:52.136 --> 00:12:53.386 A:middle
So, as I said, it takes a single

00:12:53.386 --> 00:12:54.866 A:middle
line of code to create a

00:12:54.866 --> 00:12:56.766 A:middle
gradient node from its

00:12:56.766 --> 00:12:58.466 A:middle
corresponding forward node.

00:12:58.466 --> 00:12:59.526 A:middle
And then we connect them as

00:12:59.526 --> 00:13:01.376 A:middle
previously, and now you have a

00:12:59.526 --> 00:13:01.376 A:middle
previously, and now you have a

00:13:01.376 --> 00:13:03.206 A:middle
complete training graph.

00:13:05.156 --> 00:13:06.766 A:middle
So, as you can see from this

00:13:06.766 --> 00:13:09.576 A:middle
example, the graph API is very

00:13:09.576 --> 00:13:10.396 A:middle
simple to use.

00:13:11.666 --> 00:13:12.586 A:middle
The graph does a lot for you

00:13:12.586 --> 00:13:13.236 A:middle
automatically.

00:13:13.346 --> 00:13:14.906 A:middle
It manages all the intermediate

00:13:14.906 --> 00:13:17.786 A:middle
results, and even the output

00:13:17.786 --> 00:13:18.156 A:middle
image.

00:13:19.246 --> 00:13:21.476 A:middle
It minimizes the memory

00:13:21.476 --> 00:13:23.326 A:middle
footprint of your networks, by

00:13:23.656 --> 00:13:25.516 A:middle
aliasing memory for all your

00:13:25.516 --> 00:13:27.456 A:middle
intermediate images, using Metal

00:13:28.386 --> 00:13:28.926 A:middle
heaps.

00:13:28.926 --> 00:13:30.386 A:middle
It can also fuse graph nodes.

00:13:30.386 --> 00:13:32.386 A:middle
For example, it can fuse batch

00:13:32.386 --> 00:13:34.186 A:middle
normalization and neural nodes.

00:13:34.626 --> 00:13:36.306 A:middle
And it can optimize away nodes.

00:13:36.736 --> 00:13:38.056 A:middle
For example, it optimizes the

00:13:38.056 --> 00:13:39.186 A:middle
way you can cut nation nodes.

00:13:40.416 --> 00:13:41.996 A:middle
The graph also automatically

00:13:41.996 --> 00:13:44.046 A:middle
handles padding and manages

00:13:44.046 --> 00:13:45.336 A:middle
state objects for you, which we

00:13:45.336 --> 00:13:46.276 A:middle
will discuss later in this

00:13:46.276 --> 00:13:46.656 A:middle
session.

00:13:47.456 --> 00:13:49.186 A:middle
So, please take advantage of the

00:13:49.186 --> 00:13:49.876 A:middle
graph API.

00:13:54.196 --> 00:13:55.906 A:middle
So, now that we know how to

00:13:55.906 --> 00:13:57.736 A:middle
create a training graph, let's

00:13:57.736 --> 00:14:00.266 A:middle
now take a look at the inputs we

00:13:57.736 --> 00:14:00.266 A:middle
now take a look at the inputs we

00:14:00.266 --> 00:14:01.386 A:middle
need to pass to the graph.

00:14:02.556 --> 00:14:03.966 A:middle
And for this, let's take a look

00:14:03.966 --> 00:14:05.546 A:middle
at the encode call we will use

00:14:05.816 --> 00:14:07.266 A:middle
to encode the graph to the GPU.

00:14:08.296 --> 00:14:09.886 A:middle
So, as I already mentioned,

00:14:09.886 --> 00:14:11.636 A:middle
we're not going to send in one

00:14:11.676 --> 00:14:13.026 A:middle
image at a time for training.

00:14:13.156 --> 00:14:14.926 A:middle
We're going to operate on groups

00:14:14.926 --> 00:14:16.236 A:middle
or batches of images.

00:14:16.576 --> 00:14:17.856 A:middle
So, one of the inputs to the

00:14:17.856 --> 00:14:19.536 A:middle
graph, is a batch of images.

00:14:20.926 --> 00:14:22.746 A:middle
And as you recall, for every

00:14:22.746 --> 00:14:24.566 A:middle
batch of images, we also need a

00:14:24.566 --> 00:14:26.346 A:middle
corresponding batch of labels

00:14:26.346 --> 00:14:27.446 A:middle
for loss computation.

00:14:28.696 --> 00:14:31.836 A:middle
The labels for loss computation

00:14:31.916 --> 00:14:33.366 A:middle
are passed to the graph as

00:14:33.446 --> 00:14:33.786 A:middle
states.

00:14:34.226 --> 00:14:36.536 A:middle
So, the code call also takes a

00:14:36.536 --> 00:14:37.786 A:middle
batch of states as input.

00:14:38.756 --> 00:14:40.496 A:middle
And now, let's talk about these

00:14:40.496 --> 00:14:41.406 A:middle
batches and states.

00:14:41.936 --> 00:14:42.456 A:middle
What are they?

00:14:42.596 --> 00:14:43.516 A:middle
Let's start with batches.

00:14:44.226 --> 00:14:46.496 A:middle
So, batches are just arrays of

00:14:46.756 --> 00:14:47.996 A:middle
images or states.

00:14:48.286 --> 00:14:49.416 A:middle
We've added them this year

00:14:49.416 --> 00:14:50.676 A:middle
specifically to support

00:14:50.676 --> 00:14:51.086 A:middle
training.

00:14:51.596 --> 00:14:53.416 A:middle
There are two new MPS types for

00:14:53.416 --> 00:14:56.376 A:middle
you to use: MPSImageBatch and

00:14:56.376 --> 00:14:57.696 A:middle
MPSStateBatch.

00:14:58.266 --> 00:15:00.106 A:middle
So, here's an example of how you

00:14:58.266 --> 00:15:00.106 A:middle
So, here's an example of how you

00:15:00.106 --> 00:15:01.966 A:middle
can create a single image, using

00:15:01.966 --> 00:15:02.696 A:middle
our API.

00:15:04.136 --> 00:15:05.536 A:middle
So, here we're creating one from

00:15:05.536 --> 00:15:06.736 A:middle
an existing Metal texture.

00:15:07.306 --> 00:15:09.646 A:middle
And this is an example of how

00:15:09.646 --> 00:15:11.206 A:middle
you can create a batch of

00:15:11.206 --> 00:15:13.676 A:middle
images, using our API and append

00:15:13.676 --> 00:15:15.116 A:middle
a new image to the batch, so you

00:15:15.116 --> 00:15:18.566 A:middle
can pass it to the graph.

00:15:18.566 --> 00:15:20.316 A:middle
And now, what are state objects?

00:15:20.426 --> 00:15:23.976 A:middle
An MPS state is an opaque data

00:15:23.976 --> 00:15:24.446 A:middle
container.

00:15:24.446 --> 00:15:27.356 A:middle
In training, it's frequently

00:15:27.356 --> 00:15:29.366 A:middle
used to capture a state of a

00:15:29.366 --> 00:15:32.366 A:middle
forward node, when it's called.

00:15:32.916 --> 00:15:35.206 A:middle
And so, it can later be used by

00:15:35.206 --> 00:15:35.996 A:middle
the gradient node.

00:15:37.106 --> 00:15:39.036 A:middle
So, the graph manages all of the

00:15:39.036 --> 00:15:39.776 A:middle
state objects.

00:15:39.776 --> 00:15:41.056 A:middle
So, as a developer, you

00:15:41.056 --> 00:15:42.286 A:middle
generally don't need to worry

00:15:42.286 --> 00:15:42.996 A:middle
about states.

00:15:43.306 --> 00:15:44.366 A:middle
But it's nice to know how they

00:15:44.366 --> 00:15:44.716 A:middle
work.

00:15:44.876 --> 00:15:46.196 A:middle
So, let's use a specific

00:15:46.196 --> 00:15:46.686 A:middle
example.

00:15:48.776 --> 00:15:50.116 A:middle
So, let's go back to our

00:15:50.116 --> 00:15:51.476 A:middle
handwritten digit recognition

00:15:51.476 --> 00:15:51.876 A:middle
network.

00:15:52.886 --> 00:15:55.096 A:middle
And take a look specifically at

00:15:55.096 --> 00:15:56.416 A:middle
the drop-out and drop-out

00:15:56.416 --> 00:15:57.956 A:middle
gradient nodes.

00:16:00.196 --> 00:16:02.926 A:middle
The forward drop-out node drops,

00:16:02.996 --> 00:16:04.636 A:middle
or it zeroes out, values in its

00:16:04.636 --> 00:16:05.676 A:middle
input, with a certain

00:16:05.676 --> 00:16:06.366 A:middle
probability.

00:16:06.996 --> 00:16:08.736 A:middle
And then, the dropout state

00:16:08.736 --> 00:16:10.826 A:middle
object captures information

00:16:10.826 --> 00:16:11.926 A:middle
about the forward drop-out

00:16:11.926 --> 00:16:14.486 A:middle
operation, so it can later be

00:16:14.486 --> 00:16:16.186 A:middle
used by the drop-out gradient

00:16:16.186 --> 00:16:18.576 A:middle
node because it used to zero out

00:16:19.886 --> 00:16:22.376 A:middle
values in its input gradient at

00:16:22.376 --> 00:16:24.156 A:middle
the exact same locations as was

00:16:24.156 --> 00:16:25.316 A:middle
zeroed out by the forward

00:16:25.316 --> 00:16:25.756 A:middle
operation.

00:16:26.176 --> 00:16:30.056 A:middle
So, as I said, you don't

00:16:30.056 --> 00:16:31.126 A:middle
generally need to worry about

00:16:31.126 --> 00:16:32.216 A:middle
states, because the graph

00:16:32.216 --> 00:16:32.946 A:middle
manages them.

00:16:33.416 --> 00:16:35.396 A:middle
But because the labels for loss

00:16:35.396 --> 00:16:37.346 A:middle
computation are passed as states

00:16:37.346 --> 00:16:39.786 A:middle
to the graph, and because they

00:16:39.786 --> 00:16:40.756 A:middle
require user input.

00:16:40.756 --> 00:16:42.396 A:middle
So, that's your ground truth or

00:16:42.396 --> 00:16:43.516 A:middle
correct results.

00:16:44.016 --> 00:16:45.536 A:middle
You need to create a batch of

00:16:45.536 --> 00:16:47.436 A:middle
labels for loss computation and

00:16:47.436 --> 00:16:49.036 A:middle
pass this batch as input to the

00:16:49.776 --> 00:16:50.026 A:middle
graph.

00:16:50.186 --> 00:16:51.436 A:middle
So, this is an example of how

00:16:51.436 --> 00:16:53.106 A:middle
you would create a single label

00:16:53.506 --> 00:16:54.926 A:middle
for loss computation.

00:16:55.276 --> 00:16:56.676 A:middle
You first need to create a loss

00:16:56.746 --> 00:16:58.856 A:middle
data descriptor which describes

00:16:58.856 --> 00:17:00.326 A:middle
how the label's data is laid out

00:16:58.856 --> 00:17:00.326 A:middle
how the label's data is laid out

00:17:00.326 --> 00:17:00.836 A:middle
in memory.

00:17:01.246 --> 00:17:03.886 A:middle
And then you need to create an

00:17:03.886 --> 00:17:05.665 A:middle
MPSCNNLossLabel object, with

00:17:05.665 --> 00:17:06.415 A:middle
this descriptor.

00:17:06.976 --> 00:17:09.445 A:middle
And then you create a batch of

00:17:09.445 --> 00:17:11.586 A:middle
these for training, and when the

00:17:11.586 --> 00:17:13.066 A:middle
GPU's done running the graph,

00:17:13.506 --> 00:17:15.236 A:middle
your batch of labels will

00:17:15.236 --> 00:17:16.675 A:middle
contain the per image loss

00:17:16.675 --> 00:17:18.626 A:middle
values for the batch.

00:17:18.955 --> 00:17:20.006 A:middle
And you can inspect these

00:17:20.006 --> 00:17:21.496 A:middle
values, or you can compute a

00:17:21.496 --> 00:17:22.955 A:middle
single value across the batch

00:17:22.955 --> 00:17:23.976 A:middle
and inspect that value.

00:17:27.356 --> 00:17:28.946 A:middle
So, now that we have a training

00:17:28.946 --> 00:17:30.626 A:middle
graph and we talked about how to

00:17:30.796 --> 00:17:32.706 A:middle
provide inputs to our graph,

00:17:32.706 --> 00:17:34.186 A:middle
let's talk about how to provide

00:17:34.186 --> 00:17:35.726 A:middle
weights to the graph nodes that

00:17:35.726 --> 00:17:36.316 A:middle
require weights.

00:17:38.336 --> 00:17:40.606 A:middle
The only way to provide weights

00:17:40.606 --> 00:17:42.546 A:middle
to convolution fully connected,

00:17:42.786 --> 00:17:45.456 A:middle
batch normalization and instance

00:17:45.456 --> 00:17:47.356 A:middle
normalization nodes, is through

00:17:47.356 --> 00:17:48.966 A:middle
data source provider protocols.

00:17:50.146 --> 00:17:52.216 A:middle
This is an example of how to

00:17:52.216 --> 00:17:54.116 A:middle
create a convolution node, with

00:17:54.116 --> 00:17:55.166 A:middle
a data source provider.

00:17:56.206 --> 00:17:58.636 A:middle
You need to implement a class

00:17:58.636 --> 00:18:00.106 A:middle
that conforms to the protocol.

00:17:58.636 --> 00:18:00.106 A:middle
that conforms to the protocol.

00:18:00.416 --> 00:18:01.706 A:middle
We call it MyWeights in this

00:18:01.706 --> 00:18:02.116 A:middle
example.

00:18:02.596 --> 00:18:06.886 A:middle
Data source providers are very

00:18:06.886 --> 00:18:08.066 A:middle
useful in many ways.

00:18:08.646 --> 00:18:10.996 A:middle
For example, if you have many

00:18:10.996 --> 00:18:12.136 A:middle
convolution nodes in your

00:18:12.136 --> 00:18:14.486 A:middle
network, the overall size of the

00:18:14.486 --> 00:18:15.526 A:middle
weights for the network can be

00:18:15.526 --> 00:18:16.406 A:middle
quite considerable.

00:18:17.006 --> 00:18:18.606 A:middle
And we do not want the weights

00:18:18.606 --> 00:18:19.956 A:middle
for all of your convolution

00:18:19.956 --> 00:18:21.486 A:middle
nodes to be in memory all at the

00:18:21.486 --> 00:18:22.086 A:middle
same time.

00:18:22.806 --> 00:18:24.206 A:middle
We want to keep the memory

00:18:24.206 --> 00:18:25.806 A:middle
footprints of your networks as

00:18:25.806 --> 00:18:26.566 A:middle
low as possible.

00:18:27.466 --> 00:18:28.876 A:middle
And data source providers come

00:18:28.876 --> 00:18:30.746 A:middle
into play here because they

00:18:30.746 --> 00:18:33.306 A:middle
provide just in time loading and

00:18:33.466 --> 00:18:34.556 A:middle
purging of weights data.

00:18:35.726 --> 00:18:37.076 A:middle
So, we load the weights for one

00:18:37.076 --> 00:18:39.186 A:middle
convolution kernel, when we

00:18:39.186 --> 00:18:39.846 A:middle
process it.

00:18:40.076 --> 00:18:41.626 A:middle
And then we purge them before

00:18:41.626 --> 00:18:43.436 A:middle
moving on the next convolution.

00:18:43.906 --> 00:18:47.726 A:middle
So, here's an implementation of

00:18:47.726 --> 00:18:48.366 A:middle
MyWeights.

00:18:49.516 --> 00:18:51.056 A:middle
You need to provide an

00:18:51.246 --> 00:18:52.996 A:middle
initialization method that is

00:18:52.996 --> 00:18:54.646 A:middle
responsible for pulling in

00:18:54.646 --> 00:18:55.856 A:middle
memory and making it ready.

00:18:56.226 --> 00:18:57.936 A:middle
And then the graph will call the

00:18:57.936 --> 00:18:58.686 A:middle
load function.

00:18:59.136 --> 00:19:00.946 A:middle
And then when the purge method

00:18:59.136 --> 00:19:00.946 A:middle
And then when the purge method

00:19:00.946 --> 00:19:02.406 A:middle
is called, you can release the

00:19:02.406 --> 00:19:02.656 A:middle
weights.

00:19:03.706 --> 00:19:05.366 A:middle
Data source providers are also

00:19:05.366 --> 00:19:06.866 A:middle
essential for training, and we

00:19:06.866 --> 00:19:08.206 A:middle
will discuss this later in this

00:19:08.206 --> 00:19:08.526 A:middle
session.

00:19:11.746 --> 00:19:13.216 A:middle
So, now that we have a training

00:19:13.216 --> 00:19:14.666 A:middle
graph and we've prepared our

00:19:14.666 --> 00:19:16.146 A:middle
inputs and specified weights,

00:19:16.546 --> 00:19:17.976 A:middle
we're ready to execute the graph

00:19:17.976 --> 00:19:18.566 A:middle
on the GPU.

00:19:20.486 --> 00:19:21.616 A:middle
To change the [inaudible] graph

00:19:21.616 --> 00:19:23.396 A:middle
on the GPU, we first need to do

00:19:23.656 --> 00:19:24.826 A:middle
the usual Metal setup.

00:19:25.466 --> 00:19:26.846 A:middle
We need to initialize our

00:19:26.846 --> 00:19:27.686 A:middle
training graph.

00:19:27.956 --> 00:19:29.516 A:middle
So, we have prepared our inputs.

00:19:29.766 --> 00:19:31.326 A:middle
And now, let's train a network

00:19:31.326 --> 00:19:34.836 A:middle
on the GPU.

00:19:35.206 --> 00:19:36.326 A:middle
Training is an iterative

00:19:36.326 --> 00:19:36.696 A:middle
process.

00:19:38.156 --> 00:19:39.466 A:middle
So, we want to set up a training

00:19:39.466 --> 00:19:39.666 A:middle
loop.

00:19:40.316 --> 00:19:42.266 A:middle
And we usually want to execute

00:19:42.266 --> 00:19:43.536 A:middle
our graph over a number of

00:19:43.536 --> 00:19:44.186 A:middle
EPOCHS.

00:19:44.856 --> 00:19:46.336 A:middle
The number of EPOCHS is the

00:19:46.566 --> 00:19:48.606 A:middle
total number -- is the number of

00:19:48.606 --> 00:19:49.986 A:middle
times we want to iterate over

00:19:49.986 --> 00:19:51.906 A:middle
our entire data set.

00:19:51.906 --> 00:19:53.486 A:middle
And we want there to be multiple

00:19:53.656 --> 00:19:54.886 A:middle
iterations in each EPOCH.

00:19:55.006 --> 00:19:56.646 A:middle
So, the number of iterations is

00:19:56.646 --> 00:19:57.966 A:middle
the total number of images in

00:19:57.966 --> 00:19:59.546 A:middle
your data set divided by batch

00:19:59.546 --> 00:20:01.216 A:middle
size, like 32 or 64.

00:19:59.546 --> 00:20:01.216 A:middle
size, like 32 or 64.

00:20:02.256 --> 00:20:03.426 A:middle
And now, let's take a look at

00:20:03.426 --> 00:20:04.766 A:middle
each training iteration.

00:20:06.296 --> 00:20:10.126 A:middle
In each training iteration, we

00:20:10.126 --> 00:20:11.506 A:middle
encode a batch of images for

00:20:11.506 --> 00:20:11.906 A:middle
training.

00:20:13.146 --> 00:20:14.976 A:middle
But we don't want the CPU to

00:20:14.976 --> 00:20:17.116 A:middle
wait for the GPU to finish

00:20:17.116 --> 00:20:19.616 A:middle
running one run of the graph,

00:20:20.036 --> 00:20:22.226 A:middle
with one batch of images before

00:20:22.226 --> 00:20:24.296 A:middle
the CPU can start encoding

00:20:24.296 --> 00:20:25.526 A:middle
commands to the command buffer

00:20:25.526 --> 00:20:26.786 A:middle
for the next run of the graph.

00:20:27.536 --> 00:20:30.056 A:middle
We want the CPU and the GPU to

00:20:30.056 --> 00:20:30.976 A:middle
work concurrently.

00:20:31.466 --> 00:20:32.566 A:middle
And for this, we're going to use

00:20:32.666 --> 00:20:33.486 A:middle
double buffering.

00:20:34.106 --> 00:20:36.336 A:middle
So, in this setup, we're going

00:20:36.336 --> 00:20:38.936 A:middle
to create a counting semaphore

00:20:39.056 --> 00:20:40.426 A:middle
with an initial value of 2.

00:20:40.566 --> 00:20:42.266 A:middle
It's because we want only two

00:20:42.266 --> 00:20:43.586 A:middle
encodes to be in flight at the

00:20:43.586 --> 00:20:44.146 A:middle
same time.

00:20:45.726 --> 00:20:46.916 A:middle
And then when we enter the

00:20:46.916 --> 00:20:48.496 A:middle
training iteration function,

00:20:48.796 --> 00:20:50.066 A:middle
we're going to call weight on

00:20:50.066 --> 00:20:50.696 A:middle
the semaphore.

00:20:50.846 --> 00:20:51.866 A:middle
That's decrementing it.

00:20:52.656 --> 00:20:54.596 A:middle
So, if the value of the count

00:20:54.596 --> 00:20:55.816 A:middle
has already been decremented to

00:20:55.816 --> 00:20:57.016 A:middle
zero, we wait.

00:20:57.016 --> 00:20:58.126 A:middle
Otherwise, we continue.

00:20:59.176 --> 00:21:00.966 A:middle
And then we encode our graph,

00:20:59.176 --> 00:21:00.966 A:middle
And then we encode our graph,

00:21:01.346 --> 00:21:02.946 A:middle
and the encode call returns

00:21:02.976 --> 00:21:03.566 A:middle
immediately.

00:21:04.196 --> 00:21:06.006 A:middle
And a user specified callback is

00:21:06.006 --> 00:21:07.886 A:middle
called, when the GPU is done

00:21:07.886 --> 00:21:08.426 A:middle
running the graph.

00:21:09.086 --> 00:21:10.136 A:middle
So, now we know.

00:21:10.236 --> 00:21:11.446 A:middle
The GPU is done running the

00:21:11.446 --> 00:21:13.896 A:middle
graph, and the CPU can continue

00:21:14.316 --> 00:21:16.566 A:middle
encoding more work to the GPU,

00:21:17.746 --> 00:21:19.226 A:middle
work that was previously waiting

00:21:19.226 --> 00:21:19.916 A:middle
on the semaphore.

00:21:20.936 --> 00:21:22.386 A:middle
So, why are we using double

00:21:22.386 --> 00:21:22.906 A:middle
buffering?

00:21:22.906 --> 00:21:24.856 A:middle
Why not encode more runs of the

00:21:24.856 --> 00:21:27.536 A:middle
graph, to the GPU concurrently?

00:21:28.766 --> 00:21:30.336 A:middle
Well, it takes a lot less time

00:21:30.396 --> 00:21:31.446 A:middle
to encode commands to the

00:21:31.446 --> 00:21:33.066 A:middle
command buffer, than to run the

00:21:33.066 --> 00:21:33.476 A:middle
graph.

00:21:33.786 --> 00:21:35.146 A:middle
So, we don't want to encode too

00:21:35.146 --> 00:21:36.446 A:middle
many runs of the graph

00:21:36.446 --> 00:21:37.926 A:middle
concurrently to minimize memory

00:21:37.926 --> 00:21:38.386 A:middle
footprint.

00:21:38.656 --> 00:21:42.576 A:middle
Okay, we've talked about

00:21:42.576 --> 00:21:43.676 A:middle
executing the graph.

00:21:43.936 --> 00:21:45.396 A:middle
When we execute the graph, we do

00:21:45.396 --> 00:21:47.146 A:middle
the forward pass, we compute

00:21:47.146 --> 00:21:49.206 A:middle
loss, we do the gradient pass,

00:21:49.356 --> 00:21:50.756 A:middle
and the graph will also update

00:21:50.756 --> 00:21:51.196 A:middle
weights.

00:21:51.676 --> 00:21:53.136 A:middle
So now, let's talk about weight

00:21:53.176 --> 00:21:53.516 A:middle
updates.

00:21:54.196 --> 00:21:57.286 A:middle
As I mentioned, data source

00:21:57.286 --> 00:22:00.176 A:middle
providers are essential for

00:21:57.286 --> 00:22:00.176 A:middle
providers are essential for

00:22:00.176 --> 00:22:00.616 A:middle
training.

00:22:01.456 --> 00:22:02.946 A:middle
All of your weight updates need

00:22:02.946 --> 00:22:04.246 A:middle
to happen through an optional

00:22:04.246 --> 00:22:05.926 A:middle
update method on a data source

00:22:05.926 --> 00:22:06.346 A:middle
provider.

00:22:07.806 --> 00:22:08.996 A:middle
The graph will call the update

00:22:08.996 --> 00:22:10.526 A:middle
method automatically.

00:22:11.116 --> 00:22:12.256 A:middle
So, what does the weight update

00:22:12.256 --> 00:22:13.486 A:middle
step actually involve?

00:22:13.706 --> 00:22:14.906 A:middle
Let's take a look.

00:22:16.316 --> 00:22:18.296 A:middle
So, recall that we're computing

00:22:18.296 --> 00:22:19.706 A:middle
gradients during the gradient

00:22:19.926 --> 00:22:21.526 A:middle
pass that we can apply small

00:22:21.566 --> 00:22:22.986 A:middle
deltas to the weights, in each

00:22:22.986 --> 00:22:23.976 A:middle
situation of training.

00:22:25.546 --> 00:22:26.926 A:middle
How these deltas are applied to

00:22:26.926 --> 00:22:29.296 A:middle
the weights, is described by an

00:22:29.296 --> 00:22:29.996 A:middle
optimizer.

00:22:30.536 --> 00:22:32.436 A:middle
It's just a function that takes

00:22:32.516 --> 00:22:34.186 A:middle
the old weights, the computed

00:22:34.186 --> 00:22:36.836 A:middle
gradients as input, and produces

00:22:37.696 --> 00:22:39.246 A:middle
updated weights as outputs.

00:22:40.336 --> 00:22:43.096 A:middle
You will use an optimizer in the

00:22:43.096 --> 00:22:44.286 A:middle
update method of your data

00:22:44.286 --> 00:22:44.996 A:middle
source provider.

00:22:45.976 --> 00:22:47.226 A:middle
And we support a number of

00:22:47.226 --> 00:22:48.476 A:middle
different variants of the weight

00:22:48.476 --> 00:22:50.356 A:middle
update step on the GPU,

00:22:50.556 --> 00:22:52.116 A:middle
including Adam, Stochastic

00:22:52.116 --> 00:22:53.786 A:middle
Gradient Descent, and RMSProp.

00:22:54.896 --> 00:22:57.376 A:middle
And you can even define your own

00:22:57.436 --> 00:22:58.946 A:middle
custom update weight step if you

00:22:58.946 --> 00:22:59.326 A:middle
prefer.

00:23:00.046 --> 00:23:01.276 A:middle
So now, let's take a look at how

00:23:01.276 --> 00:23:04.336 A:middle
to use an optimizer in MPS.

00:23:05.436 --> 00:23:07.526 A:middle
So, recall that your data source

00:23:07.526 --> 00:23:09.276 A:middle
provider has an init method.

00:23:09.676 --> 00:23:11.066 A:middle
This is where you want to create

00:23:11.066 --> 00:23:12.726 A:middle
your optimizer because you only

00:23:12.726 --> 00:23:13.746 A:middle
want to create it once.

00:23:14.356 --> 00:23:16.626 A:middle
And now, let's take a look at

00:23:16.626 --> 00:23:18.176 A:middle
the implementation of our update

00:23:18.176 --> 00:23:18.496 A:middle
method.

00:23:19.016 --> 00:23:21.536 A:middle
The update method receives the

00:23:21.536 --> 00:23:23.446 A:middle
source state and gradient state

00:23:23.446 --> 00:23:23.956 A:middle
as inputs.

00:23:24.676 --> 00:23:27.726 A:middle
So, the source state contains

00:23:27.726 --> 00:23:29.176 A:middle
the old weights, the gradient

00:23:29.176 --> 00:23:30.546 A:middle
state contains the computed

00:23:30.546 --> 00:23:32.706 A:middle
gradients, and now we can encode

00:23:32.706 --> 00:23:34.736 A:middle
our optimizer with this data,

00:23:34.736 --> 00:23:36.666 A:middle
and the last step is to return

00:23:36.666 --> 00:23:38.276 A:middle
the source state, which now has

00:23:38.326 --> 00:23:39.226 A:middle
the update weights.

00:23:39.636 --> 00:23:40.466 A:middle
So, pretty simple.

00:23:40.936 --> 00:23:44.936 A:middle
And now we have just one more

00:23:44.936 --> 00:23:45.856 A:middle
step to discuss.

00:23:46.116 --> 00:23:47.546 A:middle
So, as I said, training is an

00:23:47.546 --> 00:23:48.526 A:middle
iterative process.

00:23:48.526 --> 00:23:50.416 A:middle
It can take many iterations to

00:23:50.416 --> 00:23:51.186 A:middle
train a network.

00:23:52.396 --> 00:23:53.906 A:middle
And you will need to know when

00:23:53.906 --> 00:23:54.676 A:middle
to stop training.

00:23:55.316 --> 00:23:57.036 A:middle
So, let's now discuss how can

00:23:57.036 --> 00:23:58.716 A:middle
you make this decision in the

00:23:58.716 --> 00:24:00.586 A:middle
context of your training loop?

00:23:58.716 --> 00:24:00.586 A:middle
context of your training loop?

00:24:02.716 --> 00:24:04.546 A:middle
So, here we again have our

00:24:04.546 --> 00:24:05.526 A:middle
training loop, where we're

00:24:05.526 --> 00:24:06.836 A:middle
training a neural network for a

00:24:06.836 --> 00:24:07.696 A:middle
number of EPOCHS.

00:24:09.276 --> 00:24:10.826 A:middle
To check whether you can stop

00:24:10.826 --> 00:24:11.926 A:middle
training, you need to have a

00:24:11.926 --> 00:24:13.076 A:middle
test set of images.

00:24:13.426 --> 00:24:14.726 A:middle
So, a test set of images

00:24:15.046 --> 00:24:17.056 A:middle
contains images that are not

00:24:17.056 --> 00:24:17.866 A:middle
used for training.

00:24:18.126 --> 00:24:19.976 A:middle
They're only used to evaluate

00:24:19.976 --> 00:24:21.546 A:middle
the accuracy of your network.

00:24:22.486 --> 00:24:24.336 A:middle
So, after each EPOCH, you can

00:24:24.446 --> 00:24:26.426 A:middle
optionally wait for the graph to

00:24:27.096 --> 00:24:28.686 A:middle
-- for the GPU to stop running

00:24:28.686 --> 00:24:31.056 A:middle
the graph, and then you can use

00:24:31.306 --> 00:24:33.066 A:middle
the current trained parameters

00:24:33.846 --> 00:24:35.236 A:middle
to initialize an inference

00:24:35.236 --> 00:24:35.646 A:middle
network.

00:24:36.916 --> 00:24:38.216 A:middle
And then you can run this

00:24:38.216 --> 00:24:39.636 A:middle
inference network on your test

00:24:39.676 --> 00:24:41.476 A:middle
set, and you can optionally stop

00:24:41.476 --> 00:24:43.356 A:middle
training when the accuracy of

00:24:43.356 --> 00:24:44.906 A:middle
your network on this test set,

00:24:45.216 --> 00:24:46.426 A:middle
reaches a particular level.

00:24:49.116 --> 00:24:51.486 A:middle
So, now that we've discussed all

00:24:51.486 --> 00:24:53.816 A:middle
of the steps that are necessary

00:24:53.816 --> 00:24:54.996 A:middle
to train a neural network in

00:24:55.036 --> 00:24:57.026 A:middle
MPS, it's time for a demo.

00:24:58.416 --> 00:25:00.326 A:middle
So, as was already mentioned in

00:24:58.416 --> 00:25:00.326 A:middle
So, as was already mentioned in

00:25:00.326 --> 00:25:01.786 A:middle
the platform State of the Union,

00:25:02.776 --> 00:25:03.826 A:middle
the Metal Performance Shaders

00:25:03.826 --> 00:25:07.726 A:middle
Framework powers Core ML, Create

00:25:07.726 --> 00:25:09.026 A:middle
ML, and Turi Create.

00:25:09.926 --> 00:25:12.636 A:middle
To Turi Create is an easy to

00:25:12.636 --> 00:25:15.746 A:middle
use, flexible, high-performance

00:25:15.746 --> 00:25:17.236 A:middle
tool set for creating Core ML

00:25:17.236 --> 00:25:20.426 A:middle
models for tasks such as image

00:25:20.426 --> 00:25:22.206 A:middle
classification, object

00:25:22.206 --> 00:25:24.586 A:middle
detection, recommendations, and

00:25:24.586 --> 00:25:24.726 A:middle
more.

00:25:25.276 --> 00:25:26.636 A:middle
For more information on Turi

00:25:26.636 --> 00:25:28.756 A:middle
Create, we want to refer you to

00:25:28.756 --> 00:25:29.996 A:middle
the A Guide to Turi Create

00:25:29.996 --> 00:25:30.666 A:middle
Session Video.

00:25:32.336 --> 00:25:34.196 A:middle
We've prepared a demo where we

00:25:34.196 --> 00:25:36.516 A:middle
will be using an -- we'll be

00:25:36.516 --> 00:25:38.056 A:middle
training an object detection

00:25:38.056 --> 00:25:40.626 A:middle
network in Turi Create powered

00:25:40.626 --> 00:25:41.566 A:middle
by MPS.

00:25:41.566 --> 00:25:44.536 A:middle
As was mentioned in the platform

00:25:44.536 --> 00:25:47.266 A:middle
State of the Union, this is nine

00:25:47.266 --> 00:25:48.846 A:middle
times faster than without MPS.

00:25:50.116 --> 00:25:51.636 A:middle
An object detection network

00:25:52.326 --> 00:25:53.986 A:middle
draws bounding boxes around

00:25:54.076 --> 00:25:55.166 A:middle
recognized objects.

00:26:00.696 --> 00:26:05.266 A:middle
So, in this demo, I will be

00:26:05.266 --> 00:26:06.856 A:middle
using a MacBook Pro, with a

00:26:06.856 --> 00:26:08.196 A:middle
connected external GPU.

00:26:08.986 --> 00:26:12.066 A:middle
I will be running Turi Create on

00:26:12.066 --> 00:26:14.816 A:middle
the MacBook Pro and I will use

00:26:14.816 --> 00:26:16.526 A:middle
an external GPU to train the

00:26:16.526 --> 00:26:17.596 A:middle
network with MPS.

00:26:18.606 --> 00:26:20.276 A:middle
This is a great example of how

00:26:20.276 --> 00:26:22.196 A:middle
you can use an external GPU to

00:26:22.196 --> 00:26:23.806 A:middle
enhance the computational power

00:26:23.806 --> 00:26:24.526 A:middle
of a MacBook Pro.

00:26:24.526 --> 00:26:26.916 A:middle
The external GPU we're using is

00:26:26.916 --> 00:26:28.116 A:middle
an AMD Vega GPU.

00:26:29.006 --> 00:26:30.876 A:middle
So, in this demo setup, I've

00:26:30.876 --> 00:26:32.486 A:middle
already imported Turi Create,

00:26:32.956 --> 00:26:34.956 A:middle
and preloaded the object

00:26:34.956 --> 00:26:36.606 A:middle
detection network, and a

00:26:36.606 --> 00:26:37.436 A:middle
training data set.

00:26:37.996 --> 00:26:41.556 A:middle
So, now let's train this network

00:26:41.556 --> 00:26:42.606 A:middle
for 10 iterations.

00:26:43.246 --> 00:26:46.206 A:middle
And now, the entire object

00:26:46.206 --> 00:26:47.456 A:middle
detection network, all the

00:26:47.456 --> 00:26:49.386 A:middle
primitives, the optimizer, the

00:26:49.386 --> 00:26:52.906 A:middle
weight update step, everything

00:26:52.906 --> 00:26:54.706 A:middle
is running on the external GPU.

00:26:58.206 --> 00:26:59.256 A:middle
Okay, so we're already done with

00:26:59.296 --> 00:27:01.476 A:middle
10 iterations of training, it

00:26:59.296 --> 00:27:01.476 A:middle
10 iterations of training, it

00:27:01.476 --> 00:27:02.366 A:middle
would take more than 10

00:27:02.366 --> 00:27:03.496 A:middle
iterations to train this

00:27:03.496 --> 00:27:04.606 A:middle
network, and we're not going to

00:27:04.606 --> 00:27:05.576 A:middle
do this on stage.

00:27:06.116 --> 00:27:07.366 A:middle
But what I'm going to do right

00:27:07.366 --> 00:27:09.546 A:middle
now, is to load a network that

00:27:09.546 --> 00:27:11.796 A:middle
we pretrained in advance, run it

00:27:11.796 --> 00:27:13.246 A:middle
on a test set of images and

00:27:13.246 --> 00:27:14.696 A:middle
visualize some of the results.

00:27:14.696 --> 00:27:15.586 A:middle
So, let's take a look.

00:27:16.216 --> 00:27:20.306 A:middle
Okay, so here we have a banana,

00:27:20.346 --> 00:27:21.776 A:middle
that's correctly classified as a

00:27:21.776 --> 00:27:22.286 A:middle
banana.

00:27:22.656 --> 00:27:24.706 A:middle
And we have a bounding box, and

00:27:25.036 --> 00:27:26.866 A:middle
now we have a perfect breakfast

00:27:26.866 --> 00:27:27.976 A:middle
of a cup of coffee and a

00:27:27.976 --> 00:27:30.796 A:middle
croissant, and very,

00:27:30.796 --> 00:27:31.496 A:middle
mean-looking egg.

00:27:32.136 --> 00:27:35.776 A:middle
Okay, so that's it for the Turi

00:27:35.776 --> 00:27:36.396 A:middle
Create demo.

00:27:38.516 --> 00:27:43.046 A:middle
[ Applause ]

00:27:43.546 --> 00:27:47.016 A:middle
Thank you very much.

00:27:47.556 --> 00:27:49.036 A:middle
And now, let's switch gears and

00:27:49.036 --> 00:27:50.526 A:middle
talk about training recurrent

00:27:50.526 --> 00:27:51.266 A:middle
neural networks.

00:27:51.996 --> 00:27:53.876 A:middle
But first, let's do a recap of

00:27:53.876 --> 00:27:54.986 A:middle
what are the recurrent neural

00:27:54.986 --> 00:27:55.396 A:middle
networks?

00:27:57.296 --> 00:27:58.716 A:middle
One of the disadvantages of

00:27:58.716 --> 00:28:00.516 A:middle
convolutional neural networks is

00:27:58.716 --> 00:28:00.516 A:middle
convolutional neural networks is

00:28:00.516 --> 00:28:02.906 A:middle
their inability to remember

00:28:02.906 --> 00:28:03.816 A:middle
anything that happened

00:28:03.816 --> 00:28:04.366 A:middle
previously.

00:28:05.336 --> 00:28:07.076 A:middle
They can take one input, such as

00:28:07.076 --> 00:28:09.776 A:middle
an image, and generate a single

00:28:09.776 --> 00:28:11.306 A:middle
output, such as a set of

00:28:11.366 --> 00:28:12.466 A:middle
probabilities of what is

00:28:12.466 --> 00:28:13.136 A:middle
depicted in the image.

00:28:13.136 --> 00:28:19.296 A:middle
RNNs on the other hand, have

00:28:19.296 --> 00:28:19.756 A:middle
memory.

00:28:19.936 --> 00:28:21.636 A:middle
And they're good at operating on

00:28:21.636 --> 00:28:23.676 A:middle
sequences of inputs and outputs.

00:28:24.676 --> 00:28:26.146 A:middle
For example, they can take one

00:28:26.146 --> 00:28:27.546 A:middle
set of probabilities, so what is

00:28:27.546 --> 00:28:29.556 A:middle
depicted in an image, which is

00:28:29.556 --> 00:28:32.026 A:middle
an output of a CNN, and generate

00:28:32.026 --> 00:28:33.886 A:middle
a sequence of outputs, which is

00:28:33.886 --> 00:28:35.436 A:middle
a sequence of words that make up

00:28:35.436 --> 00:28:36.656 A:middle
a caption for this image.

00:28:37.196 --> 00:28:40.136 A:middle
They can also take a sequence of

00:28:40.136 --> 00:28:42.336 A:middle
inputs, such as a sequence of

00:28:42.516 --> 00:28:44.306 A:middle
words that make up a sentence

00:28:44.536 --> 00:28:45.666 A:middle
and generate a sequence of

00:28:45.666 --> 00:28:48.996 A:middle
outputs which is a same sentence

00:28:49.296 --> 00:28:50.586 A:middle
but translated to a different

00:28:50.586 --> 00:28:51.096 A:middle
language.

00:28:51.166 --> 00:28:52.166 A:middle
For example, to ration or

00:28:52.166 --> 00:28:52.596 A:middle
finish.

00:28:53.186 --> 00:28:56.146 A:middle
With support, a number of

00:28:56.146 --> 00:28:57.416 A:middle
different variance of RNNs.

00:28:58.426 --> 00:29:00.306 A:middle
The most commonly used one is

00:28:58.426 --> 00:29:00.306 A:middle
The most commonly used one is

00:29:00.396 --> 00:29:02.456 A:middle
the Long Short-Term Memory RNN,

00:29:02.486 --> 00:29:03.606 A:middle
or LSTM for short.

00:29:04.636 --> 00:29:06.706 A:middle
In our last year's WWDC Session,

00:29:06.946 --> 00:29:08.596 A:middle
we talked extensively about the

00:29:08.596 --> 00:29:10.896 A:middle
gates inside LSTM and walked

00:29:11.006 --> 00:29:12.686 A:middle
through a LSTM inference

00:29:12.686 --> 00:29:13.116 A:middle
example.

00:29:13.816 --> 00:29:15.536 A:middle
So, please refer to that session

00:29:15.596 --> 00:29:17.526 A:middle
for more information on LSTM

00:29:17.526 --> 00:29:17.996 A:middle
inference.

00:29:19.296 --> 00:29:21.526 A:middle
This year, we've added support

00:29:21.526 --> 00:29:23.176 A:middle
for training, for all of these

00:29:23.176 --> 00:29:24.176 A:middle
variants of RNNs.

00:29:25.256 --> 00:29:27.106 A:middle
And in this session, I'm going

00:29:27.106 --> 00:29:28.826 A:middle
to talk about training LSTMs.

00:29:28.826 --> 00:29:33.606 A:middle
So, let's use a specific

00:29:33.606 --> 00:29:34.086 A:middle
example.

00:29:34.306 --> 00:29:36.026 A:middle
So, here we have an activity

00:29:36.026 --> 00:29:38.586 A:middle
classifier network which takes

00:29:38.656 --> 00:29:40.476 A:middle
motion sensory data as input.

00:29:40.476 --> 00:29:42.206 A:middle
For example, reading some

00:29:42.206 --> 00:29:44.146 A:middle
sensors like an accelerometer or

00:29:44.146 --> 00:29:44.826 A:middle
a gyroscope.

00:29:45.306 --> 00:29:46.936 A:middle
And then the network uses this

00:29:46.936 --> 00:29:49.096 A:middle
data to identify a physical

00:29:49.096 --> 00:29:50.706 A:middle
activity performed by the user.

00:29:51.226 --> 00:29:52.716 A:middle
So, for example, we want to know

00:29:52.716 --> 00:29:55.296 A:middle
if a user is cycling, skiing, or

00:29:55.296 --> 00:29:55.886 A:middle
walking.

00:29:56.476 --> 00:30:00.676 A:middle
As you can see, this network is

00:29:56.476 --> 00:30:00.676 A:middle
As you can see, this network is

00:30:00.676 --> 00:30:03.416 A:middle
set up in an interesting way.

00:30:03.636 --> 00:30:07.496 A:middle
So, it contains a series of CNN

00:30:07.496 --> 00:30:09.556 A:middle
primitives, followed by LSTM

00:30:09.556 --> 00:30:11.656 A:middle
primitive, followed by more CNN

00:30:11.656 --> 00:30:12.096 A:middle
primitives.

00:30:12.666 --> 00:30:13.986 A:middle
So, why is it set up this way?

00:30:13.986 --> 00:30:15.326 A:middle
Let's take a look.

00:30:16.296 --> 00:30:18.716 A:middle
So, even though our input is

00:30:18.716 --> 00:30:21.786 A:middle
sensor data, it's represented by

00:30:21.786 --> 00:30:23.696 A:middle
a batch of 1D images with six

00:30:23.696 --> 00:30:24.336 A:middle
feature channels.

00:30:24.336 --> 00:30:26.466 A:middle
So, one feature channel for

00:30:26.576 --> 00:30:28.466 A:middle
access in the accelerometer and

00:30:28.466 --> 00:30:29.386 A:middle
gyroscope readings.

00:30:30.716 --> 00:30:33.296 A:middle
And each 1D image has 2,000

00:30:33.296 --> 00:30:33.676 A:middle
pixels.

00:30:33.936 --> 00:30:35.516 A:middle
And you can think of them as

00:30:36.206 --> 00:30:38.176 A:middle
samples in time because the

00:30:38.386 --> 00:30:39.706 A:middle
activity we're trying to

00:30:39.706 --> 00:30:41.546 A:middle
identify, occurs over time.

00:30:43.346 --> 00:30:46.656 A:middle
And then we pass these images

00:30:46.656 --> 00:30:47.976 A:middle
through a 1D convolution

00:30:47.976 --> 00:30:51.026 A:middle
primitive which compresses these

00:30:51.086 --> 00:30:53.186 A:middle
2,000 samples, to just 20

00:30:53.186 --> 00:30:53.626 A:middle
samples.

00:30:54.346 --> 00:30:57.236 A:middle
But it expends a number of

00:30:57.236 --> 00:30:59.316 A:middle
feature channels, because -- so,

00:30:59.366 --> 00:31:01.256 A:middle
we're not losing any features in

00:30:59.366 --> 00:31:01.256 A:middle
we're not losing any features in

00:31:01.836 --> 00:31:02.706 A:middle
the data.

00:31:03.276 --> 00:31:04.446 A:middle
And then, this new

00:31:04.446 --> 00:31:06.426 A:middle
representation of the data, is

00:31:06.426 --> 00:31:08.116 A:middle
passed to LSTM primitive as a

00:31:08.116 --> 00:31:09.306 A:middle
sequence of lengths 20.

00:31:10.146 --> 00:31:11.826 A:middle
And we ran LSTM for 20

00:31:11.826 --> 00:31:12.376 A:middle
iterations.

00:31:12.936 --> 00:31:14.506 A:middle
So, our LSTM is operating on a

00:31:14.506 --> 00:31:16.106 A:middle
sequence of lengths 20 instead

00:31:16.106 --> 00:31:18.246 A:middle
of 2,000, so it's operating on a

00:31:18.246 --> 00:31:19.126 A:middle
higher-level feature

00:31:19.126 --> 00:31:20.416 A:middle
representation of the data.

00:31:21.036 --> 00:31:24.056 A:middle
And then we have additional CNN

00:31:24.056 --> 00:31:26.796 A:middle
primitives that we find

00:31:26.906 --> 00:31:28.326 A:middle
high-level features in the data.

00:31:29.366 --> 00:31:30.626 A:middle
And the last primitive in this

00:31:30.626 --> 00:31:32.846 A:middle
network is the SoftMax primitive

00:31:33.236 --> 00:31:34.906 A:middle
which generates probabilities

00:31:34.906 --> 00:31:35.896 A:middle
for the different activity

00:31:35.896 --> 00:31:37.306 A:middle
classes, which is the output of

00:31:37.306 --> 00:31:37.756 A:middle
the network.

00:31:38.666 --> 00:31:39.746 A:middle
And now, let's take a look at

00:31:39.746 --> 00:31:40.896 A:middle
how to train this network.

00:31:42.346 --> 00:31:44.166 A:middle
So, we again need a loss

00:31:44.166 --> 00:31:45.626 A:middle
primitive, which takes the

00:31:45.626 --> 00:31:46.886 A:middle
output of the network and the

00:31:46.886 --> 00:31:47.906 A:middle
labels as input.

00:31:48.386 --> 00:31:49.936 A:middle
And then we need the second half

00:31:49.936 --> 00:31:50.296 A:middle
of the graph.

00:31:50.926 --> 00:31:52.146 A:middle
So, in the second half of the

00:31:52.146 --> 00:31:53.956 A:middle
graph, we again have gradient

00:31:53.956 --> 00:31:55.496 A:middle
primitives for the corresponding

00:31:55.496 --> 00:31:57.086 A:middle
forward primitives, including

00:31:57.146 --> 00:31:58.176 A:middle
the LSTM primitive.

00:31:59.036 --> 00:32:02.216 A:middle
And now, for training, we do the

00:31:59.036 --> 00:32:02.216 A:middle
And now, for training, we do the

00:32:02.216 --> 00:32:03.696 A:middle
forward pass through the

00:32:03.696 --> 00:32:06.296 A:middle
network, then we compute loss,

00:32:07.646 --> 00:32:09.756 A:middle
and we do the gradient pass to

00:32:09.756 --> 00:32:11.096 A:middle
compute gradients that will be

00:32:11.096 --> 00:32:12.126 A:middle
used to update weights.

00:32:12.686 --> 00:32:14.386 A:middle
So, this is a very similar setup

00:32:15.316 --> 00:32:16.866 A:middle
that we have for a CNN training.

00:32:17.156 --> 00:32:18.406 A:middle
And the last step is of course

00:32:18.406 --> 00:32:20.466 A:middle
to update the weights and as you

00:32:20.466 --> 00:32:22.236 A:middle
know, the LSTM also has weights,

00:32:22.236 --> 00:32:24.366 A:middle
so they need to be updated as

00:32:25.476 --> 00:32:25.606 A:middle
well.

00:32:26.076 --> 00:32:27.286 A:middle
And now, let's take a look at

00:32:27.286 --> 00:32:29.856 A:middle
how to train this network in

00:32:29.926 --> 00:32:30.116 A:middle
MPS.

00:32:30.116 --> 00:32:31.826 A:middle
But first, let's take a look at

00:32:31.826 --> 00:32:33.756 A:middle
how we can create LSTM layer for

00:32:33.756 --> 00:32:35.436 A:middle
training using our framework.

00:32:36.306 --> 00:32:38.036 A:middle
So, first, you need to create

00:32:38.036 --> 00:32:39.396 A:middle
LSTM layer descriptor.

00:32:40.646 --> 00:32:42.536 A:middle
And we initialize the descriptor

00:32:42.536 --> 00:32:44.106 A:middle
with initial training parameters

00:32:44.776 --> 00:32:45.996 A:middle
using data source providers.

00:32:46.526 --> 00:32:47.556 A:middle
So, these initial training

00:32:47.586 --> 00:32:49.066 A:middle
parameters are, use smaller

00:32:49.066 --> 00:32:50.746 A:middle
random number or some checkpoint

00:32:50.746 --> 00:32:51.196 A:middle
values.

00:32:52.466 --> 00:32:53.576 A:middle
The descriptor setup for

00:32:53.576 --> 00:32:55.826 A:middle
training, is exactly the same as

00:32:55.826 --> 00:32:56.776 A:middle
it is for inference.

00:32:58.646 --> 00:33:00.656 A:middle
And we discussed the layer

00:32:58.646 --> 00:33:00.656 A:middle
And we discussed the layer

00:33:00.656 --> 00:33:02.986 A:middle
descriptor setup in our last

00:33:02.986 --> 00:33:04.676 A:middle
year WWDC session in a lot more

00:33:04.676 --> 00:33:05.146 A:middle
detail.

00:33:05.146 --> 00:33:06.766 A:middle
So, I want to refer you to the

00:33:06.766 --> 00:33:08.616 A:middle
session for more information on

00:33:08.616 --> 00:33:10.376 A:middle
LSTM layer descriptor setup.

00:33:11.196 --> 00:33:12.586 A:middle
Once you have the descriptor,

00:33:13.936 --> 00:33:15.936 A:middle
the next step is to create LSTM

00:33:15.936 --> 00:33:17.046 A:middle
training layer with this

00:33:17.076 --> 00:33:17.596 A:middle
descriptor.

00:33:19.836 --> 00:33:22.156 A:middle
MPS will populate training

00:33:22.156 --> 00:33:24.146 A:middle
weights using the data sources

00:33:24.146 --> 00:33:25.576 A:middle
specified in the descriptor.

00:33:25.906 --> 00:33:27.506 A:middle
And we also need to have some

00:33:27.506 --> 00:33:29.116 A:middle
matrices to hold the computed

00:33:29.116 --> 00:33:29.626 A:middle
gradients.

00:33:30.816 --> 00:33:31.496 A:middle
You will use the

00:33:31.496 --> 00:33:34.376 A:middle
createWeightGradientMatrices API

00:33:34.376 --> 00:33:36.346 A:middle
on the training layer to create

00:33:36.346 --> 00:33:37.036 A:middle
these matrices.

00:33:37.446 --> 00:33:39.456 A:middle
And then, the training weights

00:33:39.886 --> 00:33:41.426 A:middle
will be used in a forward and

00:33:41.426 --> 00:33:43.526 A:middle
gradient passes and will be

00:33:43.526 --> 00:33:45.026 A:middle
passed to an optimizer along

00:33:45.026 --> 00:33:46.246 A:middle
with the computed gradients,

00:33:46.336 --> 00:33:47.106 A:middle
job, to date, weights.

00:33:47.636 --> 00:33:50.726 A:middle
And now we need to prepare some

00:33:50.726 --> 00:33:52.736 A:middle
inputs and outputs for training

00:33:52.736 --> 00:33:53.516 A:middle
our LSTM.

00:33:53.996 --> 00:33:55.836 A:middle
So, here's an example of how you

00:33:55.836 --> 00:33:58.266 A:middle
can create the matrices to hold

00:33:58.266 --> 00:33:59.776 A:middle
the input and output sequences

00:33:59.776 --> 00:34:01.286 A:middle
for both the forward and

00:33:59.776 --> 00:34:01.286 A:middle
for both the forward and

00:34:01.286 --> 00:34:02.146 A:middle
gradient passes.

00:34:02.446 --> 00:34:03.926 A:middle
You will need 20 matrices for

00:34:03.926 --> 00:34:05.906 A:middle
each one of those.

00:34:05.906 --> 00:34:06.896 A:middle
And here is how you would

00:34:06.896 --> 00:34:08.496 A:middle
initialize these matrices with

00:34:08.536 --> 00:34:08.746 A:middle
data.

00:34:09.366 --> 00:34:13.346 A:middle
And now, we are ready to train

00:34:13.346 --> 00:34:14.906 A:middle
our activity classifier network

00:34:15.346 --> 00:34:15.795 A:middle
in MPS.

00:34:16.166 --> 00:34:17.516 A:middle
So, in this code example, I will

00:34:17.516 --> 00:34:19.335 A:middle
be highlighting only the LSTM

00:34:19.335 --> 00:34:23.246 A:middle
filter in the interest of time.

00:34:23.406 --> 00:34:24.976 A:middle
So, in the forward pass, we ran

00:34:24.976 --> 00:34:26.585 A:middle
a sequence of 20 matrices

00:34:26.585 --> 00:34:28.196 A:middle
forward through the LSTM

00:34:28.196 --> 00:34:28.806 A:middle
training layer.

00:34:29.726 --> 00:34:30.735 A:middle
And then in the backward pass,

00:34:30.735 --> 00:34:33.166 A:middle
we ran a sequence of 20 matrices

00:34:33.275 --> 00:34:34.936 A:middle
though the LSTM layer to compute

00:34:34.936 --> 00:34:35.545 A:middle
gradients.

00:34:36.676 --> 00:34:38.706 A:middle
And now, you have the training

00:34:38.706 --> 00:34:39.755 A:middle
weights, and you have the

00:34:39.755 --> 00:34:41.406 A:middle
computed gradients, and you can

00:34:41.406 --> 00:34:43.186 A:middle
pass them to an optimizer to

00:34:43.186 --> 00:34:43.926 A:middle
update weights.

00:34:44.646 --> 00:34:46.896 A:middle
So, there's just one more thing

00:34:46.896 --> 00:34:47.786 A:middle
I'd like to mention.

00:34:49.466 --> 00:34:50.735 A:middle
[Inaudible] neural networks

00:34:50.735 --> 00:34:53.676 A:middle
operate on images and LSTMs

00:34:53.676 --> 00:34:54.886 A:middle
operate on matrices.

00:34:55.946 --> 00:34:57.316 A:middle
And we'll provide convenience

00:34:57.316 --> 00:34:59.616 A:middle
kernels in the framework to make

00:34:59.616 --> 00:35:00.966 A:middle
it easy to convert between

00:34:59.616 --> 00:35:00.966 A:middle
it easy to convert between

00:35:00.966 --> 00:35:02.006 A:middle
images and matrices.

00:35:02.836 --> 00:35:06.166 A:middle
So, in order to copy an image to

00:35:06.166 --> 00:35:07.406 A:middle
a matrix, you need to use the

00:35:07.406 --> 00:35:09.546 A:middle
MPI's Image Copy to Matrix

00:35:09.746 --> 00:35:10.056 A:middle
Kernel.

00:35:10.256 --> 00:35:11.456 A:middle
So, this is how you can create

00:35:11.456 --> 00:35:13.206 A:middle
one, and this is how you can

00:35:13.206 --> 00:35:15.746 A:middle
encode one on a batch of images.

00:35:17.186 --> 00:35:19.506 A:middle
Here, each row in a destination

00:35:19.506 --> 00:35:21.586 A:middle
matrix, will contain one source

00:35:21.586 --> 00:35:21.926 A:middle
image.

00:35:23.026 --> 00:35:25.036 A:middle
And to copy from a matrix to an

00:35:25.036 --> 00:35:27.066 A:middle
image, you need to use the MPS

00:35:27.486 --> 00:35:29.216 A:middle
Matrix Copy to Image Kernel.

00:35:29.306 --> 00:35:30.676 A:middle
This is how you can create one

00:35:30.996 --> 00:35:32.476 A:middle
and this is how you encode one

00:35:32.476 --> 00:35:33.166 A:middle
to the GPU.

00:35:34.456 --> 00:35:37.586 A:middle
So, we just showed you how to

00:35:37.586 --> 00:35:40.376 A:middle
train CNNs and RNNs using MPS.

00:35:41.886 --> 00:35:43.656 A:middle
We also showed you a demo of

00:35:43.716 --> 00:35:45.226 A:middle
Turi Create which is now powered

00:35:45.226 --> 00:35:45.646 A:middle
by MPS.

00:35:45.646 --> 00:35:47.526 A:middle
And now it's time for one more

00:35:47.526 --> 00:35:47.806 A:middle
demo.

00:35:49.576 --> 00:35:51.276 A:middle
We have been working with Google

00:35:51.276 --> 00:35:52.376 A:middle
to add support to the Metal

00:35:52.376 --> 00:35:54.236 A:middle
Performance Shaders Framework to

00:35:54.236 --> 00:35:58.086 A:middle
TensorFlow to accelerate machine

00:35:58.086 --> 00:35:59.716 A:middle
learning on macOS, and we would

00:35:59.716 --> 00:36:00.966 A:middle
love to show you a demo of that

00:35:59.716 --> 00:36:00.966 A:middle
love to show you a demo of that

00:36:00.966 --> 00:36:01.476 A:middle
in action.

00:36:01.646 --> 00:36:03.276 A:middle
Specifically, we want to show

00:36:03.276 --> 00:36:04.706 A:middle
you a demo of training the

00:36:04.706 --> 00:36:06.006 A:middle
InceptionV3 Object

00:36:06.006 --> 00:36:08.566 A:middle
Classification Network, using

00:36:08.566 --> 00:36:11.736 A:middle
TensorFlow, powered by MPS.

00:36:11.806 --> 00:36:15.396 A:middle
So, for this demo, I will again

00:36:15.396 --> 00:36:17.216 A:middle
be using a MacBook Pro with an

00:36:17.216 --> 00:36:18.456 A:middle
attached external GPU.

00:36:19.006 --> 00:36:20.856 A:middle
So, I will be running TensorFlow

00:36:21.216 --> 00:36:24.336 A:middle
on this MacBook Pro, and I will

00:36:24.336 --> 00:36:25.876 A:middle
use an external GPU to train a

00:36:25.876 --> 00:36:27.446 A:middle
network using MPS.

00:36:27.836 --> 00:36:29.806 A:middle
So, in this demo setup, I've

00:36:29.806 --> 00:36:32.116 A:middle
already imported TensorFlow and

00:36:32.496 --> 00:36:34.276 A:middle
preloaded the InceptionV3

00:36:34.276 --> 00:36:35.986 A:middle
Network and a training data set.

00:36:36.236 --> 00:36:37.226 A:middle
So, now, let's train this

00:36:37.286 --> 00:36:39.376 A:middle
network for 30 iterations.

00:36:39.376 --> 00:36:42.516 A:middle
So, you can see how fast this is

00:36:42.516 --> 00:36:42.896 A:middle
going.

00:36:43.476 --> 00:36:45.076 A:middle
Again, the entire network, all

00:36:45.076 --> 00:36:46.066 A:middle
of the primitives, the

00:36:46.066 --> 00:36:47.506 A:middle
optimizer, and the weight update

00:36:47.506 --> 00:36:49.316 A:middle
step, everything is running on

00:36:49.316 --> 00:36:50.266 A:middle
the external GPU.

00:36:50.726 --> 00:36:51.816 A:middle
And we're already done.

00:36:52.516 --> 00:36:54.266 A:middle
And as you can see, the training

00:36:54.266 --> 00:36:56.576 A:middle
rate is approximately 100 images

00:36:56.606 --> 00:36:57.086 A:middle
per second.

00:36:57.546 --> 00:36:58.906 A:middle
So, as was stated in the

00:36:59.336 --> 00:37:00.736 A:middle
platform State of the Union,

00:36:59.336 --> 00:37:00.736 A:middle
platform State of the Union,

00:37:01.296 --> 00:37:03.056 A:middle
training the InceptionV3

00:37:03.056 --> 00:37:05.386 A:middle
Network, in TensorFlow powered

00:37:05.386 --> 00:37:09.316 A:middle
by MPS, is up to 20 times faster

00:37:09.316 --> 00:37:10.166 A:middle
than without MPS.

00:37:10.336 --> 00:37:12.056 A:middle
So, this is it for the

00:37:12.056 --> 00:37:12.996 A:middle
TensorFlow demo.

00:37:13.536 --> 00:37:20.486 A:middle
Thank you very much.

00:37:21.836 --> 00:37:23.256 A:middle
And now, let's summarize this

00:37:23.256 --> 00:37:23.636 A:middle
session.

00:37:24.926 --> 00:37:26.596 A:middle
This year, we've added a FP16

00:37:26.686 --> 00:37:29.176 A:middle
accumulation for the convolution

00:37:29.176 --> 00:37:30.486 A:middle
and convolution transpose

00:37:30.486 --> 00:37:33.056 A:middle
primitives to improve the

00:37:33.056 --> 00:37:34.596 A:middle
performance of CNN inference.

00:37:35.246 --> 00:37:36.966 A:middle
We've also added GPU accelerate

00:37:37.106 --> 00:37:38.786 A:middle
primitives for training neural

00:37:38.786 --> 00:37:39.296 A:middle
networks.

00:37:39.536 --> 00:37:41.016 A:middle
These primitives are optimized

00:37:41.086 --> 00:37:43.036 A:middle
for both iOS and macOS.

00:37:44.806 --> 00:37:45.866 A:middle
We've also added the neural

00:37:45.866 --> 00:37:47.526 A:middle
network graph API for training.

00:37:48.476 --> 00:37:50.186 A:middle
It makes it very easy to train

00:37:50.186 --> 00:37:52.016 A:middle
neural networks on the GPU and

00:37:52.016 --> 00:37:54.346 A:middle
enables us to provide the best

00:37:54.346 --> 00:37:55.996 A:middle
performance across different

00:37:56.706 --> 00:37:56.866 A:middle
GPUs.

00:37:58.066 --> 00:38:00.046 A:middle
For more information on this

00:37:58.066 --> 00:38:00.046 A:middle
For more information on this

00:38:00.046 --> 00:38:01.406 A:middle
session and links to related

00:38:01.406 --> 00:38:02.876 A:middle
resources, please go to our

00:38:02.876 --> 00:38:03.866 A:middle
developer website.

00:38:05.616 --> 00:38:07.016 A:middle
We have the Metal for Machine

00:38:07.016 --> 00:38:08.726 A:middle
Learning Lab tomorrow at 9 a.m.

00:38:09.156 --> 00:38:10.356 A:middle
So, we would love to talk to

00:38:10.356 --> 00:38:10.576 A:middle
you.

00:38:10.576 --> 00:38:12.026 A:middle
So, please come talk to us.

00:38:12.316 --> 00:38:16.226 A:middle
And thank you for coming and

00:38:16.226 --> 00:38:17.766 A:middle
have a great WWDC.
