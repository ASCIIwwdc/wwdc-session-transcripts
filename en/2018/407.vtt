WEBVTT

00:00:07.516 --> 00:00:18.516 A:middle
[ Music ]

00:00:19.516 --> 00:00:25.416 A:middle
[ Applause ]

00:00:25.916 --> 00:00:26.946 A:middle
&gt;&gt; Good afternoon everyone.

00:00:27.406 --> 00:00:28.456 A:middle
My name is John Hess.

00:00:28.456 --> 00:00:29.466 A:middle
Today I'm going to be joined by

00:00:29.466 --> 00:00:30.586 A:middle
Matthew Lucas, and we are going

00:00:30.586 --> 00:00:31.606 A:middle
to be talking to all of you

00:00:31.606 --> 00:00:33.166 A:middle
about practical approaches to

00:00:33.166 --> 00:00:34.506 A:middle
great app performance.

00:00:35.406 --> 00:00:36.906 A:middle
Now, I'm an engineer on the

00:00:36.906 --> 00:00:38.286 A:middle
Xcode team, and I've had the

00:00:38.346 --> 00:00:39.796 A:middle
luxury of spending the last

00:00:39.796 --> 00:00:41.546 A:middle
several years focused on

00:00:41.546 --> 00:00:42.236 A:middle
performance work.

00:00:42.736 --> 00:00:44.226 A:middle
First, with Project Find, and

00:00:44.226 --> 00:00:47.186 A:middle
Open Quickly, two areas of Xcode

00:00:47.826 --> 00:00:49.126 A:middle
that treat performance as the

00:00:49.126 --> 00:00:49.896 A:middle
primary feature.

00:00:50.766 --> 00:00:52.056 A:middle
Most recently, I've had the

00:00:52.056 --> 00:00:54.136 A:middle
opportunity to do a survey of

00:00:54.136 --> 00:00:55.846 A:middle
Xcode GY responsiveness, and I

00:00:55.846 --> 00:00:57.126 A:middle
want to share with you the

00:00:57.126 --> 00:00:58.326 A:middle
approaches that I take to

00:00:58.326 --> 00:01:00.296 A:middle
performance work, both in code


00:00:58.326 --> 00:01:00.296 A:middle
performance work, both in code

00:01:00.296 --> 00:01:01.376 A:middle
that I'm intimately familiar

00:01:01.376 --> 00:01:03.136 A:middle
with, and in code that I'm just

00:01:03.136 --> 00:01:04.596 A:middle
experiencing for the first time.

00:01:05.936 --> 00:01:07.716 A:middle
Now, if I could get everyone in

00:01:07.716 --> 00:01:09.496 A:middle
today's presentation to just

00:01:09.496 --> 00:01:11.886 A:middle
take one lesson away, it is that

00:01:11.946 --> 00:01:13.276 A:middle
all of your performance work

00:01:13.276 --> 00:01:14.716 A:middle
should be based on measurement.

00:01:15.696 --> 00:01:17.096 A:middle
Before you start solving a

00:01:17.096 --> 00:01:18.816 A:middle
performance problem, you should

00:01:18.816 --> 00:01:21.126 A:middle
measure, to establish a baseline

00:01:21.366 --> 00:01:22.536 A:middle
so you know where you stand.

00:01:23.666 --> 00:01:25.196 A:middle
As you iterate on solving a

00:01:25.196 --> 00:01:26.716 A:middle
performance problem, you should

00:01:26.716 --> 00:01:28.146 A:middle
measure it each step of the way

00:01:28.576 --> 00:01:29.826 A:middle
to ensure that your performance

00:01:29.826 --> 00:01:31.376 A:middle
changes are having the impact

00:01:31.466 --> 00:01:32.026 A:middle
that you expect.

00:01:33.336 --> 00:01:34.346 A:middle
When you're done solving a

00:01:34.346 --> 00:01:35.916 A:middle
performance problem, you should

00:01:35.916 --> 00:01:37.656 A:middle
measure again, so that you can

00:01:37.656 --> 00:01:38.846 A:middle
compare to your original

00:01:38.846 --> 00:01:41.046 A:middle
baseline, and make a quantified

00:01:41.046 --> 00:01:43.166 A:middle
claim about just how much you've

00:01:43.166 --> 00:01:44.226 A:middle
improved the performance of your

00:01:44.226 --> 00:01:44.746 A:middle
application.

00:01:45.196 --> 00:01:46.766 A:middle
You want to share this with your

00:01:46.766 --> 00:01:48.896 A:middle
boss, your colleagues, and your

00:01:48.896 --> 00:01:49.506 A:middle
users.

00:01:50.566 --> 00:01:51.416 A:middle
Now, when you think about

00:01:51.416 --> 00:01:52.966 A:middle
improving performance for your

00:01:52.966 --> 00:01:55.166 A:middle
users, you need to think about

00:01:55.166 --> 00:01:56.826 A:middle
what I like to call the total

00:01:56.826 --> 00:01:57.786 A:middle
performance impact.

00:01:58.656 --> 00:02:01.246 A:middle
If you improve the functionality


00:01:58.656 --> 00:02:01.246 A:middle
If you improve the functionality

00:02:01.246 --> 00:02:03.216 A:middle
and performance of one area of

00:02:03.216 --> 00:02:06.706 A:middle
your application, by 50%, but

00:02:06.706 --> 00:02:08.136 A:middle
it's something that just 1% of

00:02:08.136 --> 00:02:10.006 A:middle
your users encounter, that does

00:02:10.006 --> 00:02:11.456 A:middle
not have nearly the breadth of

00:02:11.456 --> 00:02:13.286 A:middle
impact as improving some other

00:02:13.286 --> 00:02:15.526 A:middle
feature by just 10% that all of

00:02:15.526 --> 00:02:16.806 A:middle
your users use all the time.

00:02:17.336 --> 00:02:18.096 A:middle
So make sure you're not

00:02:18.096 --> 00:02:19.676 A:middle
optimizing edge cases, and make

00:02:19.676 --> 00:02:20.816 A:middle
sure that your changes are

00:02:20.816 --> 00:02:22.596 A:middle
impacting all of your users.

00:02:24.536 --> 00:02:27.736 A:middle
Now how do we fix performance

00:02:27.736 --> 00:02:28.086 A:middle
bugs?

00:02:28.086 --> 00:02:29.106 A:middle
Well, how do we fix regular

00:02:29.106 --> 00:02:29.526 A:middle
bugs?

00:02:29.966 --> 00:02:31.586 A:middle
Normally it starts with some

00:02:31.586 --> 00:02:33.036 A:middle
sort of defect report from

00:02:33.036 --> 00:02:35.026 A:middle
users, and we take this report

00:02:35.026 --> 00:02:36.466 A:middle
of the application not behaving

00:02:36.466 --> 00:02:38.216 A:middle
the way that people expect, and

00:02:38.216 --> 00:02:39.946 A:middle
we find some way to synthesize

00:02:40.066 --> 00:02:41.696 A:middle
steps to reproduce so that we

00:02:41.696 --> 00:02:42.866 A:middle
can cause the failure at will.

00:02:43.646 --> 00:02:45.346 A:middle
Once we've done this, we attach

00:02:45.346 --> 00:02:46.526 A:middle
a debugger to our program, so

00:02:46.526 --> 00:02:47.846 A:middle
that we can see just what our

00:02:47.846 --> 00:02:48.826 A:middle
program is doing while it is

00:02:48.826 --> 00:02:49.376 A:middle
misbehaving.

00:02:50.866 --> 00:02:51.706 A:middle
We combine that with our

00:02:51.706 --> 00:02:52.656 A:middle
knowledge of how the code is

00:02:52.656 --> 00:02:54.576 A:middle
supposed to work, to modify it

00:02:54.576 --> 00:02:56.176 A:middle
as necessary and eliminate the

00:02:56.176 --> 00:02:57.156 A:middle
undesired behavior.

00:02:57.936 --> 00:02:58.966 A:middle
We verify that we haven't

00:02:58.966 --> 00:03:00.516 A:middle
introduced any unwanted side


00:02:58.966 --> 00:03:00.516 A:middle
introduced any unwanted side

00:03:00.516 --> 00:03:02.046 A:middle
effects, and we repeat as

00:03:02.046 --> 00:03:03.546 A:middle
necessary until we've completely

00:03:03.546 --> 00:03:04.186 A:middle
solved the bug.

00:03:05.736 --> 00:03:07.686 A:middle
I've fixed performance bugs in

00:03:07.686 --> 00:03:08.996 A:middle
just the same way.

00:03:10.086 --> 00:03:11.136 A:middle
Except instead of using a

00:03:11.136 --> 00:03:13.766 A:middle
debugger, I use a profiler, and

00:03:13.826 --> 00:03:15.666 A:middle
a profiler is just a fancy tool

00:03:15.666 --> 00:03:16.246 A:middle
for measuring.

00:03:16.996 --> 00:03:18.666 A:middle
I find some set of steps to

00:03:18.666 --> 00:03:20.806 A:middle
reproduce the program being

00:03:20.806 --> 00:03:21.216 A:middle
slow.

00:03:21.966 --> 00:03:23.386 A:middle
And I run those steps with a

00:03:23.386 --> 00:03:25.106 A:middle
profiler attached, so that I can

00:03:25.106 --> 00:03:26.606 A:middle
get an insight into what my code

00:03:26.606 --> 00:03:27.656 A:middle
is doing while it's running

00:03:27.656 --> 00:03:28.106 A:middle
slowly.

00:03:29.226 --> 00:03:31.016 A:middle
I combine that knowledge with

00:03:31.016 --> 00:03:32.556 A:middle
what my program has to do to

00:03:32.556 --> 00:03:34.206 A:middle
accomplish the task at hand, and

00:03:34.266 --> 00:03:36.056 A:middle
I find steps that are happening

00:03:36.236 --> 00:03:37.606 A:middle
and remove them, because the

00:03:37.606 --> 00:03:39.926 A:middle
primary way you make your code

00:03:39.926 --> 00:03:42.286 A:middle
faster is you remove redundant

00:03:42.286 --> 00:03:43.756 A:middle
steps from whatever is that is

00:03:43.756 --> 00:03:44.326 A:middle
calculating.

00:03:45.736 --> 00:03:47.456 A:middle
Now, I make the modifications to

00:03:47.456 --> 00:03:49.136 A:middle
the source code, and I repeat

00:03:49.136 --> 00:03:50.486 A:middle
and measure as necessary until

00:03:50.486 --> 00:03:52.886 A:middle
I'm happy with the total result.

00:03:54.936 --> 00:03:56.186 A:middle
When I'm doing this type of

00:03:56.186 --> 00:03:57.666 A:middle
performance work, I often find

00:03:57.666 --> 00:03:59.486 A:middle
myself in one of a handful of

00:03:59.486 --> 00:04:00.176 A:middle
scenarios.


00:03:59.486 --> 00:04:00.176 A:middle
scenarios.

00:04:00.736 --> 00:04:02.026 A:middle
And these different scenarios

00:04:02.056 --> 00:04:03.406 A:middle
change the way that I go about

00:04:03.496 --> 00:04:05.166 A:middle
testing the code in question to

00:04:05.196 --> 00:04:06.126 A:middle
reproduce the bugs.

00:04:06.776 --> 00:04:09.046 A:middle
Sometimes I'm up against a big

00:04:09.096 --> 00:04:10.926 A:middle
performance regression, right?

00:04:11.006 --> 00:04:12.086 A:middle
Everything was moving along

00:04:12.086 --> 00:04:14.116 A:middle
smoothly, then someone checked

00:04:14.116 --> 00:04:15.396 A:middle
something in on our team, maybe

00:04:15.446 --> 00:04:17.086 A:middle
it was me, and performance has

00:04:17.086 --> 00:04:18.226 A:middle
fallen through the floor, and

00:04:18.226 --> 00:04:19.495 A:middle
now we have to go back and find

00:04:19.495 --> 00:04:21.296 A:middle
out what caused this regression.

00:04:22.065 --> 00:04:23.246 A:middle
If this regression is very

00:04:23.246 --> 00:04:25.986 A:middle
pronounced, or it's in an area

00:04:25.986 --> 00:04:27.186 A:middle
that I don't think it's likely

00:04:27.186 --> 00:04:28.086 A:middle
to regress again in the

00:04:28.086 --> 00:04:29.576 A:middle
immediate future, I may just

00:04:29.676 --> 00:04:31.966 A:middle
test it with my hands, manually,

00:04:32.086 --> 00:04:33.216 A:middle
with the profiler attached.

00:04:34.386 --> 00:04:36.116 A:middle
However, your performance

00:04:36.116 --> 00:04:37.376 A:middle
victories are going to be

00:04:37.376 --> 00:04:40.056 A:middle
hard-won battles, and they can

00:04:40.056 --> 00:04:42.126 A:middle
easily be lost through a slow

00:04:42.126 --> 00:04:43.196 A:middle
stream of regressions.

00:04:43.986 --> 00:04:45.806 A:middle
I would encourage all of you to

00:04:45.806 --> 00:04:46.926 A:middle
write automated performance

00:04:46.926 --> 00:04:48.986 A:middle
tests to capture your app's

00:04:48.986 --> 00:04:50.356 A:middle
performance, so that you can

00:04:50.356 --> 00:04:51.836 A:middle
ensure that it's not regressing

00:04:51.836 --> 00:04:52.316 A:middle
over time.

00:04:55.256 --> 00:04:56.596 A:middle
Another scenario I often find

00:04:56.596 --> 00:04:58.726 A:middle
myself in, is, are applications

00:04:58.726 --> 00:05:00.326 A:middle
performing the same as it has


00:04:58.726 --> 00:05:00.326 A:middle
performing the same as it has

00:05:00.326 --> 00:05:01.246 A:middle
been for a long time?

00:05:01.656 --> 00:05:03.356 A:middle
Maybe it is running at 45 frames

00:05:03.356 --> 00:05:04.666 A:middle
a second in some drawing test,

00:05:05.156 --> 00:05:06.826 A:middle
but we expect it to run at 60.

00:05:06.826 --> 00:05:07.886 A:middle
It needs to be improved

00:05:07.886 --> 00:05:09.426 A:middle
marginally, and we have reason

00:05:09.426 --> 00:05:10.986 A:middle
to believe through our previous

00:05:10.986 --> 00:05:12.736 A:middle
performance work that we can get

00:05:12.736 --> 00:05:14.126 A:middle
there through spot fixes and

00:05:14.126 --> 00:05:15.546 A:middle
incremental changes.

00:05:16.326 --> 00:05:17.726 A:middle
Now, in this type of scenario, I

00:05:17.726 --> 00:05:19.186 A:middle
probably also have automated

00:05:19.186 --> 00:05:20.876 A:middle
tests already in play, because I

00:05:20.876 --> 00:05:22.216 A:middle
understand my performance over

00:05:24.796 --> 00:05:24.896 A:middle
time.

00:05:25.106 --> 00:05:26.856 A:middle
And a third scenario, our

00:05:26.856 --> 00:05:28.176 A:middle
application is just suffering

00:05:28.176 --> 00:05:29.336 A:middle
from a poor design and

00:05:29.446 --> 00:05:30.666 A:middle
performance is orders of

00:05:30.666 --> 00:05:32.036 A:middle
magnitude worse than it should

00:05:32.036 --> 00:05:32.226 A:middle
be.

00:05:33.516 --> 00:05:34.726 A:middle
We know that we can't improve it

00:05:34.726 --> 00:05:36.626 A:middle
with simple spot fixes, because

00:05:36.626 --> 00:05:37.666 A:middle
we've tried them in the past,

00:05:37.906 --> 00:05:39.356 A:middle
and we are still stuck here with

00:05:39.606 --> 00:05:41.416 A:middle
a very sub-par performance.

00:05:42.006 --> 00:05:43.856 A:middle
In a situation like this, you'd

00:05:43.856 --> 00:05:45.096 A:middle
want to do a total performance

00:05:45.096 --> 00:05:45.986 A:middle
overhaul, where you are

00:05:45.986 --> 00:05:47.446 A:middle
redesigning some core part of

00:05:47.446 --> 00:05:48.716 A:middle
the feature, or the algorithms

00:05:48.716 --> 00:05:50.516 A:middle
in question, so that performance

00:05:50.786 --> 00:05:51.916 A:middle
is a primary constraint.

00:05:52.456 --> 00:05:53.746 A:middle
And definitely in these cases,

00:05:53.906 --> 00:05:55.216 A:middle
you would have performance tests

00:05:55.536 --> 00:05:56.686 A:middle
to measure that you're actually

00:05:56.686 --> 00:05:57.626 A:middle
hitting your performance

00:05:57.626 --> 00:05:58.136 A:middle
targets.

00:05:59.246 --> 00:06:00.856 A:middle
Now, it is important that you


00:05:59.246 --> 00:06:00.856 A:middle
Now, it is important that you

00:06:00.856 --> 00:06:01.936 A:middle
know just what to test.

00:06:02.346 --> 00:06:03.686 A:middle
I want to caution you that I

00:06:03.686 --> 00:06:05.096 A:middle
don't ever immediately jump to

00:06:05.096 --> 00:06:06.086 A:middle
these sort of performance

00:06:06.086 --> 00:06:08.106 A:middle
overhauls as a way of fixing a

00:06:08.106 --> 00:06:08.896 A:middle
performance problem.

00:06:09.296 --> 00:06:10.816 A:middle
I love to do that.

00:06:10.816 --> 00:06:12.046 A:middle
It's sort of Greenfield

00:06:12.046 --> 00:06:13.106 A:middle
engineering, where you get to

00:06:13.106 --> 00:06:14.326 A:middle
design things from the ground

00:06:14.326 --> 00:06:16.126 A:middle
up, but it's very risky.

00:06:16.556 --> 00:06:17.346 A:middle
You're going to end up with a

00:06:17.346 --> 00:06:18.666 A:middle
better product at the end, but

00:06:18.666 --> 00:06:19.686 A:middle
it's going to be a turbulent

00:06:19.686 --> 00:06:21.376 A:middle
path getting there as you rework

00:06:21.376 --> 00:06:23.976 A:middle
an entire feature.

00:06:24.116 --> 00:06:25.186 A:middle
When you're doing this style of

00:06:25.186 --> 00:06:26.666 A:middle
work, it is imperative you

00:06:26.666 --> 00:06:28.156 A:middle
understand not only the

00:06:28.286 --> 00:06:29.436 A:middle
functional constraints of the

00:06:29.436 --> 00:06:31.336 A:middle
code in question, but also the

00:06:31.336 --> 00:06:32.986 A:middle
performance constraints, and the

00:06:32.986 --> 00:06:34.356 A:middle
typical use patterns that your

00:06:34.356 --> 00:06:35.616 A:middle
users are most frequently

00:06:35.616 --> 00:06:37.386 A:middle
applying to this feature, and

00:06:37.386 --> 00:06:39.106 A:middle
you only get that by having done

00:06:39.256 --> 00:06:40.276 A:middle
performance work in the area in

00:06:40.276 --> 00:06:40.736 A:middle
the past.

00:06:41.636 --> 00:06:43.326 A:middle
I'd like to share an anecdote

00:06:43.326 --> 00:06:45.046 A:middle
about our work on a situation

00:06:45.046 --> 00:06:46.216 A:middle
like this, within Xcode.

00:06:47.216 --> 00:06:49.406 A:middle
In Xcode 9, we reworked Project

00:06:49.406 --> 00:06:50.606 A:middle
Find, with performance as a

00:06:50.606 --> 00:06:51.406 A:middle
primary goal.

00:06:52.366 --> 00:06:53.716 A:middle
It was our goal to deliver

00:06:53.716 --> 00:06:55.376 A:middle
search results in just tens of

00:06:55.376 --> 00:06:56.076 A:middle
milliseconds.

00:06:56.926 --> 00:06:59.156 A:middle
When we were going to discuss

00:06:59.156 --> 00:07:00.006 A:middle
this feature with our


00:06:59.156 --> 00:07:00.006 A:middle
this feature with our

00:07:00.006 --> 00:07:01.366 A:middle
colleagues, we were often

00:07:01.366 --> 00:07:03.536 A:middle
challenged to perform searches

00:07:03.536 --> 00:07:05.286 A:middle
across large projects for things

00:07:05.286 --> 00:07:07.106 A:middle
like string, or even the letter

00:07:07.106 --> 00:07:07.336 A:middle
E.

00:07:07.446 --> 00:07:08.976 A:middle
Things that produce millions of

00:07:08.976 --> 00:07:10.446 A:middle
results, right?

00:07:10.446 --> 00:07:12.106 A:middle
And certainly if our application

00:07:12.216 --> 00:07:13.426 A:middle
could produce millions of

00:07:13.426 --> 00:07:14.866 A:middle
results quickly, it would be

00:07:14.866 --> 00:07:15.776 A:middle
fast on anything.

00:07:16.476 --> 00:07:17.896 A:middle
But if you consider what typical

00:07:17.896 --> 00:07:20.516 A:middle
patterns are, we search for APIs

00:07:20.516 --> 00:07:22.046 A:middle
we use, the names of our own

00:07:22.046 --> 00:07:24.336 A:middle
classes, the names of, you know,

00:07:24.496 --> 00:07:25.616 A:middle
images that we're referencing.

00:07:25.616 --> 00:07:26.286 A:middle
Things like that.

00:07:26.346 --> 00:07:27.546 A:middle
They produce dozens, maybe

00:07:27.546 --> 00:07:28.606 A:middle
hundreds of results.

00:07:28.936 --> 00:07:30.276 A:middle
Certainly, it is essential that

00:07:30.276 --> 00:07:32.076 A:middle
the application works decently

00:07:32.076 --> 00:07:33.236 A:middle
when you get a million results,

00:07:33.496 --> 00:07:35.086 A:middle
but the normal use case is

00:07:35.156 --> 00:07:36.026 A:middle
hundreds of results.

00:07:36.806 --> 00:07:38.486 A:middle
Now, some of your work in doing

00:07:38.486 --> 00:07:40.186 A:middle
a task like search is going to

00:07:40.186 --> 00:07:41.396 A:middle
be proportional on things like

00:07:41.746 --> 00:07:43.816 A:middle
generating the raw results, and

00:07:43.816 --> 00:07:45.326 A:middle
other work is going to be based

00:07:45.326 --> 00:07:46.916 A:middle
on how efficiently you can index

00:07:46.916 --> 00:07:48.296 A:middle
the text in the project, and

00:07:48.296 --> 00:07:49.666 A:middle
avoid work in the first place.

00:07:50.156 --> 00:07:51.996 A:middle
In these two scenarios, you're

00:07:51.996 --> 00:07:53.976 A:middle
likely to have completely

00:07:53.976 --> 00:07:55.286 A:middle
different targets for what you

00:07:55.286 --> 00:07:56.826 A:middle
would optimize to make one of

00:07:56.826 --> 00:07:57.916 A:middle
these searches faster than the

00:07:57.916 --> 00:07:59.046 A:middle
other, right?

00:07:59.046 --> 00:08:00.156 A:middle
So it's essential that you


00:07:59.046 --> 00:08:00.156 A:middle
So it's essential that you

00:08:00.156 --> 00:08:02.426 A:middle
understand how your users are

00:08:02.426 --> 00:08:03.316 A:middle
going to use the product, so

00:08:03.506 --> 00:08:04.696 A:middle
that you can optimize for the

00:08:04.726 --> 00:08:05.536 A:middle
right cases.

00:08:07.956 --> 00:08:09.696 A:middle
Now, in all of these cases, I

00:08:09.696 --> 00:08:11.206 A:middle
need to do some form of testing,

00:08:11.686 --> 00:08:13.066 A:middle
whether it's manual, or

00:08:13.066 --> 00:08:13.556 A:middle
automated.

00:08:16.246 --> 00:08:17.556 A:middle
I want to share with you two

00:08:17.556 --> 00:08:18.886 A:middle
types of performance tests that

00:08:18.886 --> 00:08:20.196 A:middle
I will typically write to

00:08:20.196 --> 00:08:21.516 A:middle
measure the performance of

00:08:22.026 --> 00:08:22.186 A:middle
Xcode.

00:08:23.436 --> 00:08:25.436 A:middle
We will either do unit tests, or

00:08:25.436 --> 00:08:26.376 A:middle
integration tests.

00:08:26.956 --> 00:08:28.176 A:middle
Let's compare and contrast them.

00:08:29.376 --> 00:08:31.306 A:middle
In a performance unit test, it's

00:08:31.306 --> 00:08:33.616 A:middle
your goal to isolate some

00:08:33.616 --> 00:08:35.096 A:middle
feature of your application and

00:08:35.096 --> 00:08:36.356 A:middle
measure it all by itself.

00:08:36.966 --> 00:08:37.726 A:middle
You might mock out its

00:08:37.756 --> 00:08:39.236 A:middle
dependencies, and you might

00:08:39.236 --> 00:08:41.126 A:middle
launch it in a context where it

00:08:41.126 --> 00:08:42.736 A:middle
has been isolated.

00:08:43.496 --> 00:08:45.666 A:middle
If I were to write performance

00:08:45.666 --> 00:08:47.266 A:middle
unit tests for Xcode's code

00:08:47.266 --> 00:08:48.676 A:middle
completion, I might write a

00:08:48.676 --> 00:08:50.406 A:middle
series of three small tests.

00:08:51.076 --> 00:08:52.896 A:middle
One of these tests would measure

00:08:53.256 --> 00:08:54.616 A:middle
talking to the compiler and

00:08:54.616 --> 00:08:56.426 A:middle
getting the raw results, the raw

00:08:56.426 --> 00:08:57.266 A:middle
set of code completion

00:08:57.266 --> 00:08:57.876 A:middle
candidates back.

00:08:58.946 --> 00:09:01.056 A:middle
Another performance test would


00:08:58.946 --> 00:09:01.056 A:middle
Another performance test would

00:09:01.056 --> 00:09:02.906 A:middle
measure correlating, ranking and

00:09:02.906 --> 00:09:04.386 A:middle
scoring those results, so we

00:09:04.386 --> 00:09:05.406 A:middle
knew which ones to display to

00:09:05.406 --> 00:09:05.806 A:middle
the user.

00:09:06.926 --> 00:09:08.896 A:middle
A third test might take those

00:09:08.926 --> 00:09:10.636 A:middle
already prepared results, and

00:09:10.636 --> 00:09:11.636 A:middle
measure putting them into UI

00:09:11.636 --> 00:09:13.156 A:middle
elements for final display.

00:09:13.156 --> 00:09:15.016 A:middle
And in covering all three of

00:09:15.016 --> 00:09:16.846 A:middle
these areas, I would have pretty

00:09:16.846 --> 00:09:17.986 A:middle
good coverage over the major

00:09:17.986 --> 00:09:20.056 A:middle
components of code completion in

00:09:20.056 --> 00:09:20.546 A:middle
the IDE.

00:09:23.136 --> 00:09:24.796 A:middle
Now, there are some great

00:09:24.886 --> 00:09:26.276 A:middle
aspects to these performance

00:09:26.276 --> 00:09:26.976 A:middle
unit tests.

00:09:27.596 --> 00:09:28.326 A:middle
They're going to be highly

00:09:28.326 --> 00:09:30.026 A:middle
focused, which means if they

00:09:30.026 --> 00:09:31.276 A:middle
regress in the future, I'm going

00:09:31.276 --> 00:09:32.706 A:middle
to have a very good idea on

00:09:32.706 --> 00:09:33.986 A:middle
where the regression is, because

00:09:34.026 --> 00:09:35.066 A:middle
the code that is running has

00:09:35.066 --> 00:09:36.086 A:middle
been scoped so well.

00:09:36.706 --> 00:09:38.976 A:middle
They are also going to produce

00:09:39.286 --> 00:09:40.626 A:middle
much more repeatable results

00:09:40.626 --> 00:09:41.336 A:middle
from run to run.

00:09:41.466 --> 00:09:42.436 A:middle
They're not going to have a big

00:09:42.436 --> 00:09:44.556 A:middle
variance in the times that they

00:09:44.556 --> 00:09:45.036 A:middle
produce.

00:09:45.426 --> 00:09:46.676 A:middle
Again, because the code is so

00:09:46.676 --> 00:09:47.156 A:middle
focused.

00:09:48.176 --> 00:09:49.186 A:middle
Now, let's contrast that to an

00:09:49.186 --> 00:09:50.056 A:middle
integration test.

00:09:51.076 --> 00:09:52.936 A:middle
In an integration test, your job

00:09:52.936 --> 00:09:54.796 A:middle
is to measure the performance of

00:09:54.796 --> 00:09:56.616 A:middle
your application as your users

00:09:56.616 --> 00:09:57.336 A:middle
experience it.

00:09:58.326 --> 00:09:59.016 A:middle
Holistically.

00:09:59.866 --> 00:10:01.506 A:middle
So, if I was writing code


00:09:59.866 --> 00:10:01.506 A:middle
So, if I was writing code

00:10:01.506 --> 00:10:03.106 A:middle
completion unit tests for Xcode,

00:10:03.756 --> 00:10:05.996 A:middle
I'm sorry, integration tests, I

00:10:05.996 --> 00:10:08.466 A:middle
would launch the full Xcode app.

00:10:08.466 --> 00:10:09.566 A:middle
I would open a source file.

00:10:09.566 --> 00:10:11.136 A:middle
I would navigate to the source

00:10:11.136 --> 00:10:13.366 A:middle
file, and I would type, and I

00:10:13.366 --> 00:10:14.396 A:middle
would bring up code completion

00:10:14.486 --> 00:10:15.306 A:middle
over and over again.

00:10:16.076 --> 00:10:17.636 A:middle
When I profile this, to see what

00:10:17.636 --> 00:10:18.686 A:middle
Xcode is doing, and how much

00:10:18.686 --> 00:10:20.316 A:middle
time it is taking, I am going to

00:10:20.316 --> 00:10:21.886 A:middle
find that this test is anything

00:10:21.886 --> 00:10:22.956 A:middle
but focused and quiet.

00:10:24.006 --> 00:10:25.476 A:middle
Xcode is going to be doing

00:10:25.476 --> 00:10:26.986 A:middle
drawing and layout as I type.

00:10:26.986 --> 00:10:28.996 A:middle
It is going to be doing syntax

00:10:29.066 --> 00:10:29.906 A:middle
coloring as I type.

00:10:30.556 --> 00:10:31.536 A:middle
In the background, it might be

00:10:31.536 --> 00:10:33.636 A:middle
indexing, fetching get status,

00:10:34.086 --> 00:10:35.506 A:middle
deciding to show new files in

00:10:35.506 --> 00:10:35.976 A:middle
the Assistant Editor,

00:10:36.056 --> 00:10:36.866 A:middle
and all of these things are

00:10:37.166 --> 00:10:40.056 A:middle
going to be competing for CPU

00:10:40.116 --> 00:10:41.806 A:middle
resources, along with code

00:10:41.806 --> 00:10:42.246 A:middle
completion.

00:10:43.086 --> 00:10:44.046 A:middle
Maybe when I look in the

00:10:44.046 --> 00:10:45.786 A:middle
Profiler, I'll see that we spend

00:10:45.786 --> 00:10:47.636 A:middle
80% of our time syntax coloring,

00:10:47.916 --> 00:10:50.136 A:middle
and 20% of our time in code

00:10:50.136 --> 00:10:50.626 A:middle
completion.

00:10:51.086 --> 00:10:52.636 A:middle
And with this data, I would know

00:10:52.636 --> 00:10:54.776 A:middle
that the best way to improve

00:10:54.816 --> 00:10:55.976 A:middle
code completion performance

00:10:56.256 --> 00:10:57.696 A:middle
would be to defer syntax

00:10:57.746 --> 00:10:58.076 A:middle
coloring.

00:10:58.686 --> 00:11:00.256 A:middle
I will never gain that type of


00:10:58.686 --> 00:11:00.256 A:middle
I will never gain that type of

00:11:00.256 --> 00:11:01.946 A:middle
knowledge with a highly focused

00:11:01.946 --> 00:11:02.546 A:middle
unit test.

00:11:02.546 --> 00:11:04.366 A:middle
So if I can get everyone here to

00:11:04.366 --> 00:11:05.606 A:middle
take two things away from this

00:11:05.606 --> 00:11:07.476 A:middle
presentation, the second one

00:11:07.746 --> 00:11:08.866 A:middle
should be that your performance

00:11:08.866 --> 00:11:10.936 A:middle
investigations should absolutely

00:11:10.936 --> 00:11:12.506 A:middle
start with these wide

00:11:12.506 --> 00:11:14.226 A:middle
integration tests that measure

00:11:14.226 --> 00:11:15.846 A:middle
how the users experience your

00:11:15.846 --> 00:11:16.406 A:middle
application.

00:11:18.026 --> 00:11:19.296 A:middle
So I'm talking about testing,

00:11:19.626 --> 00:11:21.026 A:middle
measuring and profiling.

00:11:21.456 --> 00:11:22.346 A:middle
And right now, I'd like to

00:11:22.346 --> 00:11:24.166 A:middle
introduce you to profiling in

00:11:24.216 --> 00:11:25.546 A:middle
Xcode with instruments.

00:11:25.786 --> 00:11:26.646 A:middle
Let's head over to the demo

00:11:26.646 --> 00:11:27.166 A:middle
machine.

00:11:35.056 --> 00:11:35.926 A:middle
Today we are going to be looking

00:11:35.926 --> 00:11:37.146 A:middle
at a performance problem that we

00:11:37.146 --> 00:11:39.186 A:middle
fixed between Xcode 9 and Xcode

00:11:39.186 --> 00:11:39.516 A:middle
10.

00:11:39.516 --> 00:11:41.216 A:middle
I want to show it to you.

00:11:41.696 --> 00:11:44.436 A:middle
I'm going to launch Xcode 9, and

00:11:44.436 --> 00:11:45.286 A:middle
open our solar system

00:11:45.286 --> 00:11:45.856 A:middle
application.

00:11:47.056 --> 00:11:47.766 A:middle
Now the problem that we are

00:11:47.766 --> 00:11:48.836 A:middle
going to be looking at is

00:11:48.836 --> 00:11:49.796 A:middle
creating tabs.

00:11:50.456 --> 00:11:51.486 A:middle
I'm going to just press

00:11:51.486 --> 00:11:52.956 A:middle
Command-T quickly a couple of

00:11:52.956 --> 00:11:54.996 A:middle
times, and as you can see, the

00:11:54.996 --> 00:11:56.896 A:middle
whole screen flashes black, and

00:11:56.896 --> 00:11:58.166 A:middle
it takes several seconds to

00:11:58.166 --> 00:11:58.996 A:middle
create those tabs.

00:11:59.626 --> 00:12:01.116 A:middle
That definitely doesn't meet my


00:11:59.626 --> 00:12:01.116 A:middle
That definitely doesn't meet my

00:12:01.116 --> 00:12:02.216 A:middle
expectations as far as

00:12:02.216 --> 00:12:04.036 A:middle
performance goes, and we need to

00:12:04.036 --> 00:12:04.596 A:middle
fix this.

00:12:04.956 --> 00:12:06.376 A:middle
So let's take a look at how you

00:12:06.376 --> 00:12:06.826 A:middle
would do that.

00:12:08.266 --> 00:12:09.106 A:middle
First, I'm going to launch

00:12:09.106 --> 00:12:09.566 A:middle
Instruments.

00:12:09.606 --> 00:12:10.716 A:middle
That is our profiling tool.

00:12:11.436 --> 00:12:12.686 A:middle
You can do that from the Xcode

00:12:12.686 --> 00:12:14.586 A:middle
menu, under Open Developer Tool,

00:12:14.886 --> 00:12:15.506 A:middle
Instruments.

00:12:15.976 --> 00:12:17.766 A:middle
Now, I'm currently in Xcode 9,

00:12:18.106 --> 00:12:19.146 A:middle
so if I choose this, it's going

00:12:19.146 --> 00:12:20.036 A:middle
to launch the Instruments from

00:12:20.036 --> 00:12:21.476 A:middle
Xcode 9, and of course, I want

00:12:21.476 --> 00:12:22.606 A:middle
the Instruments from Xcode 10,

00:12:22.706 --> 00:12:23.766 A:middle
which I've put here in my doc.

00:12:24.066 --> 00:12:26.066 A:middle
So I'm going to hide Xcode, and

00:12:26.066 --> 00:12:28.956 A:middle
bring up Instruments.

00:12:29.146 --> 00:12:30.366 A:middle
Now, when Instruments launches,

00:12:31.796 --> 00:12:33.026 A:middle
we're presented with a list of

00:12:33.026 --> 00:12:34.226 A:middle
profiling tools that we could

00:12:34.226 --> 00:12:35.546 A:middle
use to measure our application.

00:12:36.356 --> 00:12:37.426 A:middle
There's all kinds of tools here.

00:12:37.786 --> 00:12:38.736 A:middle
They can measure graphics

00:12:38.736 --> 00:12:41.186 A:middle
utilization, memory consumption,

00:12:41.836 --> 00:12:44.006 A:middle
IO, and time in general.

00:12:45.726 --> 00:12:47.096 A:middle
It can be intimidating to know

00:12:47.096 --> 00:12:48.406 A:middle
which one of these profilers to

00:12:48.406 --> 00:12:49.676 A:middle
start with.

00:12:51.236 --> 00:12:53.936 A:middle
I would encourage all of you, if

00:12:53.936 --> 00:12:55.596 A:middle
you just learn one of these

00:12:55.596 --> 00:12:56.976 A:middle
tools, it should be the Time

00:12:56.976 --> 00:12:57.516 A:middle
Profiler.

00:12:58.296 --> 00:13:00.426 A:middle
I use it for 95% or more of my


00:12:58.296 --> 00:13:00.426 A:middle
I use it for 95% or more of my

00:13:00.426 --> 00:13:01.166 A:middle
performance work.

00:13:01.736 --> 00:13:03.246 A:middle
When your users complain about

00:13:03.246 --> 00:13:04.546 A:middle
your app being slow, they're

00:13:04.546 --> 00:13:05.726 A:middle
complaining about it taking too

00:13:05.726 --> 00:13:07.796 A:middle
long, and long is time.

00:13:08.746 --> 00:13:10.116 A:middle
If it turns out that you're slow

00:13:10.116 --> 00:13:10.926 A:middle
because you're doing too much

00:13:10.926 --> 00:13:12.636 A:middle
IO, that is going to correlate

00:13:12.636 --> 00:13:13.706 A:middle
with time, and you will be able

00:13:13.706 --> 00:13:14.696 A:middle
to see this with the Time

00:13:14.696 --> 00:13:15.036 A:middle
Profiler.

00:13:15.036 --> 00:13:17.146 A:middle
So if you learn just one

00:13:17.146 --> 00:13:18.376 A:middle
instrument, it should be the

00:13:18.376 --> 00:13:19.126 A:middle
Time Profiler.

00:13:20.276 --> 00:13:21.756 A:middle
Let's take a look at how that

00:13:22.506 --> 00:13:22.636 A:middle
works.

00:13:25.346 --> 00:13:26.646 A:middle
I'm going to launch the Time

00:13:26.646 --> 00:13:28.496 A:middle
Profiler by just double clicking

00:13:28.496 --> 00:13:31.246 A:middle
on it here, and make Instruments

00:13:31.336 --> 00:13:32.226 A:middle
take the full best op.

00:13:33.646 --> 00:13:35.396 A:middle
Now, we'd like to record Xcode.

00:13:36.416 --> 00:13:38.086 A:middle
In the upper left-hand corner of

00:13:38.256 --> 00:13:39.836 A:middle
the Instruments window, you can

00:13:39.836 --> 00:13:41.126 A:middle
control which process you're

00:13:41.126 --> 00:13:42.466 A:middle
going to attach to and record.

00:13:43.096 --> 00:13:45.236 A:middle
By default, hitting this record

00:13:45.236 --> 00:13:46.726 A:middle
button would record all

00:13:46.726 --> 00:13:47.636 A:middle
processes on my Mac.

00:13:48.286 --> 00:13:50.926 A:middle
I just want to focus on Xcode.

00:13:54.856 --> 00:13:56.866 A:middle
I'll switch this popover to

00:13:56.956 --> 00:13:59.046 A:middle
Xcode and hit record.

00:13:59.536 --> 00:14:00.786 A:middle
Now, I like to keep an eye on


00:13:59.536 --> 00:14:00.786 A:middle
Now, I like to keep an eye on

00:14:00.786 --> 00:14:02.256 A:middle
this area of the window to track

00:14:02.256 --> 00:14:03.396 A:middle
view while I'm recording.

00:14:03.786 --> 00:14:05.216 A:middle
So I'm going to resize the Xcode

00:14:05.216 --> 00:14:06.866 A:middle
window to be a little shorter,

00:14:06.866 --> 00:14:08.026 A:middle
so I can still see that, and

00:14:08.256 --> 00:14:09.336 A:middle
then I'm going to do the thing

00:14:09.336 --> 00:14:09.896 A:middle
that was slow.

00:14:09.896 --> 00:14:10.736 A:middle
I'm going to create a couple

00:14:10.736 --> 00:14:11.316 A:middle
more tabs.

00:14:12.726 --> 00:14:15.006 A:middle
And you can see the graph

00:14:15.246 --> 00:14:15.826 A:middle
changed here.

00:14:15.826 --> 00:14:17.016 A:middle
Now, I'm going to go ahead and

00:14:17.086 --> 00:14:19.636 A:middle
quit, and return to Instruments.

00:14:21.316 --> 00:14:23.056 A:middle
So what just happened?

00:14:23.936 --> 00:14:25.266 A:middle
While the Profiler was running,

00:14:26.126 --> 00:14:27.476 A:middle
it was attached to our process

00:14:27.476 --> 00:14:28.076 A:middle
like a debugger.

00:14:28.076 --> 00:14:30.586 A:middle
And it stopped it, thousands of

00:14:30.586 --> 00:14:32.816 A:middle
times per second, and as it was

00:14:32.816 --> 00:14:34.336 A:middle
stopping it, it gathered back

00:14:34.366 --> 00:14:34.936 A:middle
traces.

00:14:35.236 --> 00:14:37.026 A:middle
Now, just a reminder, a back

00:14:37.026 --> 00:14:38.546 A:middle
trace is a description of how

00:14:38.546 --> 00:14:39.706 A:middle
your program got to where it

00:14:39.706 --> 00:14:40.386 A:middle
currently is.

00:14:40.876 --> 00:14:42.006 A:middle
So if you're on line 6 of

00:14:42.006 --> 00:14:43.716 A:middle
function C and you got there

00:14:43.716 --> 00:14:45.286 A:middle
because main called A, called B,

00:14:45.326 --> 00:14:46.926 A:middle
called C, then your back trace

00:14:47.016 --> 00:14:48.256 A:middle
is Main, A, B, C.

00:14:49.006 --> 00:14:50.346 A:middle
When Instruments captures one of

00:14:50.346 --> 00:14:51.946 A:middle
these back traces, it notes,

00:14:52.226 --> 00:14:53.356 A:middle
hey, we just spent one

00:14:53.356 --> 00:14:54.686 A:middle
millisecond in function C.

00:14:54.686 --> 00:14:56.916 A:middle
It says one millisecond, because

00:14:56.916 --> 00:14:58.056 A:middle
that is our sampling interval

00:14:58.056 --> 00:14:59.016 A:middle
for recording once every

00:14:59.016 --> 00:14:59.546 A:middle
millisecond.


00:15:01.016 --> 00:15:02.696 A:middle
Now, on the main thread, all

00:15:02.696 --> 00:15:03.626 A:middle
these back traces are going to

00:15:03.626 --> 00:15:04.556 A:middle
start with the Main function,

00:15:04.556 --> 00:15:05.596 A:middle
and they're probably going to

00:15:05.596 --> 00:15:06.666 A:middle
call Application Main, and

00:15:06.796 --> 00:15:08.356 A:middle
they're going to branch out, all

00:15:08.356 --> 00:15:09.256 A:middle
through your source code after

00:15:09.256 --> 00:15:09.536 A:middle
that.

00:15:10.206 --> 00:15:11.896 A:middle
We can collapse these back

00:15:11.956 --> 00:15:13.266 A:middle
traces together, and overlay

00:15:13.266 --> 00:15:15.316 A:middle
them into a prefix tree, so they

00:15:15.316 --> 00:15:16.916 A:middle
start at Main and work their way

00:15:16.916 --> 00:15:16.983 A:middle
out.

00:15:17.156 --> 00:15:18.646 A:middle
And we can bubble up those

00:15:18.646 --> 00:15:19.836 A:middle
millisecond counters that we

00:15:19.836 --> 00:15:21.386 A:middle
captured at the top, so that we

00:15:21.386 --> 00:15:23.416 A:middle
can hierarchically see how much

00:15:23.486 --> 00:15:24.716 A:middle
time was spent in all the

00:15:24.716 --> 00:15:25.896 A:middle
different areas of our source

00:15:25.896 --> 00:15:26.126 A:middle
code.

00:15:26.686 --> 00:15:27.636 A:middle
And we are going to look at this

00:15:27.636 --> 00:15:29.416 A:middle
data to try and find redundant

00:15:29.416 --> 00:15:31.066 A:middle
and unnecessary operations that

00:15:31.066 --> 00:15:32.696 A:middle
we can make faster, and that is

00:15:32.696 --> 00:15:33.836 A:middle
our primary method that we are

00:15:33.836 --> 00:15:34.916 A:middle
going to use to improve the

00:15:34.916 --> 00:15:36.076 A:middle
performance of our application.

00:15:37.026 --> 00:15:39.316 A:middle
Now, as you can imagine, we're

00:15:39.316 --> 00:15:40.606 A:middle
capturing thousands of back

00:15:40.606 --> 00:15:41.456 A:middle
traces per second.

00:15:41.456 --> 00:15:43.326 A:middle
There is an overwhelming amount

00:15:43.326 --> 00:15:44.666 A:middle
of data for you to wade through

00:15:44.666 --> 00:15:45.246 A:middle
in instruments.

00:15:46.146 --> 00:15:48.356 A:middle
My primary advice to you is that

00:15:48.356 --> 00:15:49.946 A:middle
you want to filter this data as

00:15:49.946 --> 00:15:51.596 A:middle
much as possible so that you can

00:15:51.596 --> 00:15:53.166 A:middle
see the course grain performance

00:15:53.166 --> 00:15:55.616 A:middle
leads, and not focus on minutia.

00:15:55.616 --> 00:15:56.376 A:middle
All right?

00:15:56.376 --> 00:15:57.786 A:middle
So I want to show you how to

00:15:57.786 --> 00:15:59.046 A:middle
apply a bunch of powerful

00:15:59.046 --> 00:16:00.086 A:middle
filters and instruments.


00:15:59.046 --> 00:16:00.086 A:middle
filters and instruments.

00:16:04.276 --> 00:16:06.196 A:middle
So as I did the recording, you

00:16:06.196 --> 00:16:07.436 A:middle
remember, I had the track view

00:16:07.436 --> 00:16:07.806 A:middle
visible.

00:16:09.356 --> 00:16:10.476 A:middle
I did that because I wanted to

00:16:10.476 --> 00:16:12.296 A:middle
see how the CPU utilization

00:16:12.296 --> 00:16:13.766 A:middle
changed and where it was

00:16:13.766 --> 00:16:15.836 A:middle
changing, while I was creating

00:16:15.836 --> 00:16:18.156 A:middle
new tabs, and I noted to myself

00:16:18.156 --> 00:16:19.416 A:middle
that it was right here.

00:16:20.186 --> 00:16:21.786 A:middle
I simply dragged and selected

00:16:21.856 --> 00:16:26.076 A:middle
over that area of the trace, and

00:16:26.076 --> 00:16:27.786 A:middle
I've caused instruments to only

00:16:27.786 --> 00:16:31.666 A:middle
focus its back trace data on

00:16:31.666 --> 00:16:32.706 A:middle
just that time interval.

00:16:33.126 --> 00:16:34.356 A:middle
Everything over here, this is

00:16:34.356 --> 00:16:35.556 A:middle
before I was creating tabs.

00:16:36.026 --> 00:16:37.516 A:middle
Everything over here, this is

00:16:37.626 --> 00:16:38.666 A:middle
after I was creating tabs, when

00:16:38.666 --> 00:16:39.786 A:middle
I was quitting the application.

00:16:40.056 --> 00:16:40.976 A:middle
That's not what I'm trying to

00:16:40.976 --> 00:16:42.576 A:middle
optimize right now, so I don't

00:16:42.676 --> 00:16:45.016 A:middle
need to see that data.

00:16:45.196 --> 00:16:48.376 A:middle
Now, in the bottom area of the

00:16:48.376 --> 00:16:49.836 A:middle
Instruments window, Instruments

00:16:49.836 --> 00:16:50.926 A:middle
is showing me all the traces it

00:16:50.926 --> 00:16:51.366 A:middle
collected.

00:16:51.786 --> 00:16:55.376 A:middle
By default, there is one row per

00:16:55.446 --> 00:16:56.206 A:middle
thread that was running.

00:16:56.646 --> 00:16:57.756 A:middle
And in this example it looks

00:16:57.756 --> 00:16:58.856 A:middle
like there was only four threads

00:16:58.856 --> 00:16:59.126 A:middle
running.

00:16:59.386 --> 00:17:00.556 A:middle
Sometimes you'll have much more.


00:16:59.386 --> 00:17:00.556 A:middle
Sometimes you'll have much more.

00:17:00.626 --> 00:17:01.716 A:middle
Depends on how concurrent your

00:17:01.716 --> 00:17:02.436 A:middle
application is.

00:17:03.306 --> 00:17:04.796 A:middle
I often like to collapse these

00:17:04.796 --> 00:17:06.276 A:middle
in the name of focusing, and I

00:17:06.276 --> 00:17:07.756 A:middle
also like to collapse them so

00:17:07.756 --> 00:17:10.356 A:middle
they're based on the top level

00:17:10.356 --> 00:17:11.976 A:middle
functions executing in each of

00:17:11.976 --> 00:17:13.346 A:middle
the threads, rather than the

00:17:13.346 --> 00:17:14.636 A:middle
thread IDs, because that

00:17:14.636 --> 00:17:16.165 A:middle
corresponds better with how I

00:17:16.165 --> 00:17:17.406 A:middle
use Grand Central Dispatch.

00:17:18.616 --> 00:17:19.715 A:middle
Down in the bottom of the

00:17:19.715 --> 00:17:21.076 A:middle
Instruments window, I'm going to

00:17:21.076 --> 00:17:22.236 A:middle
click on this button that says

00:17:22.266 --> 00:17:24.576 A:middle
Call Tree, and I'm going to zoom

00:17:24.576 --> 00:17:25.536 A:middle
in on it, so you can see what

00:17:25.536 --> 00:17:26.076 A:middle
I'm about to do.

00:17:26.806 --> 00:17:27.935 A:middle
There are several filters

00:17:27.935 --> 00:17:28.556 A:middle
available here.

00:17:28.906 --> 00:17:30.136 A:middle
One of them is separate by

00:17:30.136 --> 00:17:30.516 A:middle
thread.

00:17:30.516 --> 00:17:31.756 A:middle
It is on by default.

00:17:31.886 --> 00:17:33.176 A:middle
I am going to go ahead and

00:17:33.176 --> 00:17:35.466 A:middle
disable that, and instead, all

00:17:35.466 --> 00:17:36.326 A:middle
of the threads are going to be

00:17:36.326 --> 00:17:37.586 A:middle
grouped by their top level entry

00:17:37.586 --> 00:17:38.926 A:middle
point, rather than their thread

00:17:39.596 --> 00:17:39.666 A:middle
ID.

00:17:42.356 --> 00:17:45.646 A:middle
Now, looking at this trace, I

00:17:45.646 --> 00:17:46.946 A:middle
can see that of all these

00:17:46.946 --> 00:17:49.336 A:middle
threads running, which by the

00:17:49.336 --> 00:17:50.816 A:middle
way, below the main trace, which

00:17:50.816 --> 00:17:53.126 A:middle
is the aggregate CPU usage, the

00:17:53.126 --> 00:17:54.416 A:middle
CPU usage is broken down per

00:17:54.416 --> 00:17:56.086 A:middle
thread, I can see that almost

00:17:56.086 --> 00:17:57.046 A:middle
all the other threads were

00:17:57.176 --> 00:17:58.456 A:middle
largely inactive during this

00:17:58.456 --> 00:17:58.826 A:middle
trace.

00:17:59.416 --> 00:18:00.836 A:middle
I can focus on just the main


00:17:59.416 --> 00:18:00.836 A:middle
I can focus on just the main

00:18:00.836 --> 00:18:03.036 A:middle
thread by selecting it here, and

00:18:03.036 --> 00:18:04.626 A:middle
now I'm only looking at traces

00:18:04.776 --> 00:18:06.476 A:middle
from the main thread during this

00:18:06.526 --> 00:18:07.046 A:middle
time period.

00:18:08.086 --> 00:18:09.606 A:middle
I'm ready to start digging into

00:18:09.606 --> 00:18:11.336 A:middle
this call hierarchy, so I can

00:18:11.336 --> 00:18:12.376 A:middle
see what my application was

00:18:12.416 --> 00:18:12.676 A:middle
doing.

00:18:13.606 --> 00:18:15.106 A:middle
Often, I'll walk this with the

00:18:15.106 --> 00:18:17.116 A:middle
keyboard, by just pressing right

00:18:17.116 --> 00:18:18.356 A:middle
arrow and down, over and over

00:18:18.356 --> 00:18:18.666 A:middle
again.

00:18:19.366 --> 00:18:21.026 A:middle
But I'd like to show you the

00:18:21.026 --> 00:18:22.526 A:middle
heaviest back trace inspector

00:18:22.526 --> 00:18:24.136 A:middle
that Instruments offers.

00:18:24.496 --> 00:18:25.416 A:middle
If your Inspector is not

00:18:25.416 --> 00:18:26.886 A:middle
visible, you can toggle it with

00:18:26.886 --> 00:18:28.756 A:middle
this button, and the heaviest

00:18:28.756 --> 00:18:29.746 A:middle
back trace will be available

00:18:29.836 --> 00:18:31.706 A:middle
here, in this tab, Extended

00:18:31.706 --> 00:18:32.046 A:middle
Detail.

00:18:32.866 --> 00:18:34.296 A:middle
Now, the heaviest back trace is

00:18:34.296 --> 00:18:35.496 A:middle
just the trace that occurred

00:18:35.496 --> 00:18:36.566 A:middle
most frequently.

00:18:36.566 --> 00:18:37.486 A:middle
It's the back trace that

00:18:37.486 --> 00:18:39.196 A:middle
happened most frequently while

00:18:39.196 --> 00:18:40.706 A:middle
we were recording under the

00:18:40.706 --> 00:18:41.476 A:middle
current selection.

00:18:42.116 --> 00:18:43.516 A:middle
And you can use this to quickly

00:18:43.516 --> 00:18:45.176 A:middle
navigate many frames deep at a

00:18:45.176 --> 00:18:45.556 A:middle
time.

00:18:46.496 --> 00:18:47.846 A:middle
I typically look through here,

00:18:48.096 --> 00:18:49.366 A:middle
looking for my own APIs, and

00:18:49.656 --> 00:18:50.816 A:middle
things that would surprise me

00:18:50.816 --> 00:18:51.856 A:middle
for taking up this amount of

00:18:51.856 --> 00:18:54.336 A:middle
time, or for areas where we make

00:18:54.336 --> 00:18:56.036 A:middle
a significant branching point in

00:18:56.036 --> 00:18:57.306 A:middle
the number of samples.

00:18:58.356 --> 00:18:59.996 A:middle
Now, looking through here, I see

00:18:59.996 --> 00:19:02.036 A:middle
this call, which is to IDE


00:18:59.996 --> 00:19:02.036 A:middle
this call, which is to IDE

00:19:02.036 --> 00:19:04.636 A:middle
Navigator, replacement view, did

00:19:04.636 --> 00:19:05.576 A:middle
install view controller.

00:19:05.936 --> 00:19:07.106 A:middle
Now, I'm familiar with this API,

00:19:07.106 --> 00:19:08.746 A:middle
because it's an internal API of

00:19:08.746 --> 00:19:09.176 A:middle
Xcode.

00:19:10.156 --> 00:19:12.686 A:middle
And in the trace, I can see over

00:19:12.686 --> 00:19:13.636 A:middle
here on the left-hand side of

00:19:13.636 --> 00:19:14.686 A:middle
the window that it is

00:19:14.686 --> 00:19:18.656 A:middle
responsible for 1.19 seconds of

00:19:18.656 --> 00:19:19.846 A:middle
the total time we're recording,

00:19:20.116 --> 00:19:21.596 A:middle
or 45% of the time.

00:19:22.176 --> 00:19:24.196 A:middle
That is far and away above my

00:19:24.196 --> 00:19:25.356 A:middle
expectations for how much this

00:19:25.356 --> 00:19:27.756 A:middle
method should cost.

00:19:27.936 --> 00:19:29.526 A:middle
However, it's hard to focus on

00:19:29.526 --> 00:19:30.386 A:middle
what is happening here.

00:19:30.586 --> 00:19:32.336 A:middle
Right? I'm, there is all this

00:19:32.336 --> 00:19:33.346 A:middle
other stuff at the bottom of the

00:19:33.346 --> 00:19:35.926 A:middle
trace, and it looks like I'm,

00:19:35.926 --> 00:19:37.596 A:middle
you know, 30 or 40 stack ranges

00:19:37.596 --> 00:19:37.736 A:middle
deep.

00:19:38.056 --> 00:19:39.096 A:middle
That can be intimidating.

00:19:39.456 --> 00:19:40.726 A:middle
I want to show you how to focus.

00:19:41.276 --> 00:19:43.006 A:middle
The first technique is back here

00:19:43.006 --> 00:19:46.976 A:middle
in that call tree popover again.

00:19:47.176 --> 00:19:49.126 A:middle
I'm going to use this popover to

00:19:49.126 --> 00:19:50.516 A:middle
choose the flattened recursion.

00:19:51.756 --> 00:19:55.126 A:middle
Let's go ahead and do that.

00:19:55.196 --> 00:19:56.326 A:middle
And now you can see that, that

00:19:56.326 --> 00:19:57.526 A:middle
repeated set of method calls

00:19:57.526 --> 00:20:00.466 A:middle
that was right here, oops, has


00:19:57.526 --> 00:20:00.466 A:middle
that was right here, oops, has

00:20:00.466 --> 00:20:01.086 A:middle
been collapsed.

00:20:02.396 --> 00:20:04.536 A:middle
I'm sorry, let me scroll down.

00:20:05.586 --> 00:20:06.466 A:middle
That has been collapsed.

00:20:06.816 --> 00:20:08.436 A:middle
In fact, I'm confident that I

00:20:08.436 --> 00:20:09.586 A:middle
want to continue my performance

00:20:09.586 --> 00:20:11.556 A:middle
investigation inside of this IDE

00:20:11.556 --> 00:20:14.506 A:middle
Navigator area, API call, and I

00:20:14.506 --> 00:20:16.336 A:middle
can refocus the entire call tree

00:20:17.216 --> 00:20:19.376 A:middle
by context, clicking here, and

00:20:19.376 --> 00:20:20.746 A:middle
choosing Focus on Subtree.

00:20:21.516 --> 00:20:22.446 A:middle
And Instruments is going to take

00:20:22.446 --> 00:20:23.896 A:middle
that symbol up to the top of the

00:20:23.896 --> 00:20:25.386 A:middle
call graph, it's going to remove

00:20:25.386 --> 00:20:26.556 A:middle
everything else, and it is going

00:20:26.556 --> 00:20:28.456 A:middle
to reset the percentages at 100%

00:20:28.726 --> 00:20:30.166 A:middle
so I can focus on just this.

00:20:30.796 --> 00:20:33.096 A:middle
Now, I can continue to walk this

00:20:33.096 --> 00:20:35.686 A:middle
sample with the arrow keys to

00:20:35.686 --> 00:20:36.486 A:middle
see what we're doing.

00:20:36.686 --> 00:20:38.496 A:middle
And I'm familiar with these

00:20:38.496 --> 00:20:38.906 A:middle
APIs.

00:20:38.906 --> 00:20:40.046 A:middle
And it looks like we're doing

00:20:40.206 --> 00:20:41.196 A:middle
state restoration.

00:20:41.766 --> 00:20:43.136 A:middle
And as I continue to expand

00:20:43.136 --> 00:20:45.936 A:middle
this, I can see that we are sort

00:20:45.936 --> 00:20:47.176 A:middle
of deep inside the table view,

00:20:47.466 --> 00:20:49.696 A:middle
and in addition to there being

00:20:49.696 --> 00:20:51.476 A:middle
this sort of hot call path, you

00:20:51.476 --> 00:20:52.986 A:middle
know, that is taking large

00:20:52.986 --> 00:20:54.116 A:middle
number of the total percentage,

00:20:54.436 --> 00:20:55.246 A:middle
there's all these other

00:20:55.246 --> 00:20:56.566 A:middle
incidental samples as well.

00:20:58.266 --> 00:20:59.896 A:middle
It's easy to get distracted by

00:20:59.896 --> 00:21:00.236 A:middle
these.


00:20:59.896 --> 00:21:00.236 A:middle
these.

00:21:01.286 --> 00:21:03.766 A:middle
One of them here is OPC Message

00:21:03.766 --> 00:21:04.076 A:middle
Send.

00:21:04.646 --> 00:21:06.926 A:middle
This can occur all over your

00:21:06.926 --> 00:21:07.676 A:middle
tracers if you're writing

00:21:07.676 --> 00:21:08.296 A:middle
objective C.

00:21:08.606 --> 00:21:09.916 A:middle
Even if you're writing Swift

00:21:09.916 --> 00:21:10.936 A:middle
code, as you work your way into

00:21:10.936 --> 00:21:11.966 A:middle
the system libraries, you'll see

00:21:11.966 --> 00:21:12.296 A:middle
this.

00:21:12.636 --> 00:21:13.856 A:middle
You'll often see its counterpart

00:21:13.856 --> 00:21:15.916 A:middle
functions, OPC, Load Strong,

00:21:15.916 --> 00:21:18.726 A:middle
Load Weak, etc., Retain, you can

00:21:18.726 --> 00:21:20.936 A:middle
remove all that content from the

00:21:20.936 --> 00:21:23.826 A:middle
call tree by context clicking on

00:21:23.866 --> 00:21:28.096 A:middle
it, and choosing Charge OPC to

00:21:28.096 --> 00:21:28.706 A:middle
Callers.

00:21:29.406 --> 00:21:30.436 A:middle
That's going to tell Instruments

00:21:30.466 --> 00:21:31.886 A:middle
to take all the samples that

00:21:31.886 --> 00:21:33.686 A:middle
came from lib OPC and remove

00:21:33.686 --> 00:21:35.176 A:middle
them from the call data, but

00:21:35.176 --> 00:21:36.456 A:middle
keep the time as attributed to

00:21:36.456 --> 00:21:37.636 A:middle
the parent frames that called

00:21:37.636 --> 00:21:37.846 A:middle
them.

00:21:38.176 --> 00:21:39.776 A:middle
I tend to treat those objective

00:21:39.776 --> 00:21:41.126 A:middle
C runtime functions as just the

00:21:41.126 --> 00:21:42.266 A:middle
cost of doing business when

00:21:42.266 --> 00:21:43.306 A:middle
writing objective C code.

00:21:43.706 --> 00:21:45.196 A:middle
It's rarely the case that I'm

00:21:45.196 --> 00:21:46.136 A:middle
going to attempt to optimize

00:21:46.136 --> 00:21:48.396 A:middle
them out, so I just prefer to

00:21:48.456 --> 00:21:49.596 A:middle
remove them from the data, so I

00:21:49.596 --> 00:21:50.886 A:middle
can focus on the things that I'm

00:21:50.886 --> 00:21:51.916 A:middle
likely to take action on.

00:21:53.176 --> 00:21:55.466 A:middle
Another very powerful filter

00:21:55.466 --> 00:21:56.866 A:middle
that you can apply, and one that

00:21:56.866 --> 00:21:59.076 A:middle
I'm going to use to remove all

00:21:59.076 --> 00:22:00.356 A:middle
these small samples that


00:21:59.076 --> 00:22:00.356 A:middle
these small samples that

00:22:00.356 --> 00:22:02.186 A:middle
occurred during this set of

00:22:02.226 --> 00:22:04.676 A:middle
frames, is here in the call tree

00:22:04.676 --> 00:22:05.596 A:middle
constraint section.

00:22:06.126 --> 00:22:07.646 A:middle
Let me show you.

00:22:11.146 --> 00:22:12.716 A:middle
I'm going to tell Instruments

00:22:12.716 --> 00:22:14.006 A:middle
that I would only like to see

00:22:14.486 --> 00:22:16.236 A:middle
areas of the trace that

00:22:16.236 --> 00:22:18.256 A:middle
accounted for let's say 20 or

00:22:18.256 --> 00:22:18.966 A:middle
more samples.

00:22:19.256 --> 00:22:20.566 A:middle
I'm picking 20 because I know

00:22:20.566 --> 00:22:21.606 A:middle
that I've selected about a two

00:22:21.606 --> 00:22:23.066 A:middle
second interval and 20

00:22:23.066 --> 00:22:24.376 A:middle
milliseconds is going to

00:22:24.376 --> 00:22:26.076 A:middle
represent about 1% of the total

00:22:26.076 --> 00:22:27.036 A:middle
work, and that is about the

00:22:27.036 --> 00:22:28.376 A:middle
granularity that I like to work

00:22:28.376 --> 00:22:29.846 A:middle
at by default.

00:22:31.336 --> 00:22:32.926 A:middle
So with call tree constraints

00:22:33.986 --> 00:22:37.206 A:middle
set to a minimum of 20, I now

00:22:37.206 --> 00:22:38.846 A:middle
focus this down much more

00:22:38.846 --> 00:22:39.516 A:middle
significantly.

00:22:40.456 --> 00:22:41.346 A:middle
Now, I mentioned here that we

00:22:41.346 --> 00:22:42.856 A:middle
were expanding out my view

00:22:42.856 --> 00:22:43.296 A:middle
items.

00:22:43.336 --> 00:22:45.026 A:middle
I see that in the fact that

00:22:45.026 --> 00:22:46.446 A:middle
we're calling NS outline view,

00:22:46.446 --> 00:22:47.836 A:middle
expand item, expand children.

00:22:48.436 --> 00:22:50.476 A:middle
Now, a lot of people would stop

00:22:50.946 --> 00:22:51.816 A:middle
with the call graph at this

00:22:51.876 --> 00:22:52.146 A:middle
point.

00:22:52.556 --> 00:22:54.136 A:middle
They'd see I'm calling into a

00:22:54.136 --> 00:22:55.226 A:middle
system framework, and I'm

00:22:55.226 --> 00:22:56.346 A:middle
spending a lot of time there.

00:22:56.706 --> 00:22:58.086 A:middle
This isn't my fault, right?

00:22:58.086 --> 00:22:58.926 A:middle
What can I do about this?

00:22:58.926 --> 00:23:00.486 A:middle
I can't optimize NS Outline


00:22:58.926 --> 00:23:00.486 A:middle
I can't optimize NS Outline

00:23:00.486 --> 00:23:01.976 A:middle
View, Expand Items.

00:23:03.126 --> 00:23:04.606 A:middle
You absolutely have the power to

00:23:04.606 --> 00:23:05.806 A:middle
influence these situations.

00:23:06.336 --> 00:23:07.706 A:middle
For example, the system

00:23:07.706 --> 00:23:08.936 A:middle
framework could be spending all

00:23:08.936 --> 00:23:10.976 A:middle
of this time because it's

00:23:10.976 --> 00:23:11.966 A:middle
operating on data that you

00:23:11.966 --> 00:23:12.526 A:middle
provided it.

00:23:13.366 --> 00:23:14.546 A:middle
It could be taking a lot of time

00:23:14.616 --> 00:23:15.496 A:middle
because you are calling this

00:23:15.496 --> 00:23:16.996 A:middle
method thousands or millions of

00:23:16.996 --> 00:23:17.476 A:middle
times.

00:23:18.366 --> 00:23:19.526 A:middle
It could be taking a lot of time

00:23:19.526 --> 00:23:20.666 A:middle
because it's calling back into

00:23:20.666 --> 00:23:22.376 A:middle
your code through delegation.

00:23:22.376 --> 00:23:24.566 A:middle
And most importantly, you can

00:23:24.566 --> 00:23:25.906 A:middle
get an insight into what the

00:23:25.906 --> 00:23:27.836 A:middle
system framework is doing by

00:23:27.836 --> 00:23:28.886 A:middle
expanding down through the

00:23:28.886 --> 00:23:30.186 A:middle
Instruments tree, and looking at

00:23:30.186 --> 00:23:31.256 A:middle
the names of functions that are

00:23:31.256 --> 00:23:31.816 A:middle
being called.

00:23:32.216 --> 00:23:33.766 A:middle
In fact, that's exactly how I

00:23:33.766 --> 00:23:36.966 A:middle
learned to fix this bug.

00:23:37.166 --> 00:23:39.166 A:middle
As I expand the trace into the

00:23:39.166 --> 00:23:41.406 A:middle
outline view, I can see that it

00:23:41.406 --> 00:23:42.726 A:middle
is calling these two methods

00:23:42.726 --> 00:23:42.966 A:middle
here.

00:23:44.716 --> 00:23:47.106 A:middle
Batch Expand Items with item

00:23:47.106 --> 00:23:49.266 A:middle
entries, expand children, and do

00:23:49.266 --> 00:23:50.686 A:middle
work after end updates.

00:23:51.756 --> 00:23:53.356 A:middle
Now, those are big clues to me

00:23:53.356 --> 00:23:54.366 A:middle
that there is probably some

00:23:54.366 --> 00:23:55.686 A:middle
opportunity for efficiency

00:23:55.686 --> 00:23:56.226 A:middle
through batching.

00:23:56.226 --> 00:23:58.326 A:middle
As you could imagine, the

00:23:58.326 --> 00:24:00.886 A:middle
outline view starts with a small


00:23:58.326 --> 00:24:00.886 A:middle
outline view starts with a small

00:24:00.886 --> 00:24:02.386 A:middle
set of items, and then we are

00:24:02.386 --> 00:24:03.906 A:middle
trying to restore expansion

00:24:03.906 --> 00:24:05.676 A:middle
state in this area of our code,

00:24:05.676 --> 00:24:06.666 A:middle
and so we are telling it to

00:24:06.666 --> 00:24:08.256 A:middle
open, for example, the top item.

00:24:08.506 --> 00:24:09.436 A:middle
And when we tell it to open the

00:24:09.436 --> 00:24:11.406 A:middle
top item, internally you might

00:24:11.406 --> 00:24:12.576 A:middle
imagine that it moves all the

00:24:12.576 --> 00:24:13.296 A:middle
other items down.

00:24:14.056 --> 00:24:15.096 A:middle
Then you ask me to expand the

00:24:15.096 --> 00:24:15.716 A:middle
second item.

00:24:16.106 --> 00:24:17.196 A:middle
It moves all the items down

00:24:17.196 --> 00:24:17.516 A:middle
again.

00:24:17.906 --> 00:24:19.386 A:middle
And the third item, and so on.

00:24:19.386 --> 00:24:20.666 A:middle
And by the time you're done,

00:24:20.966 --> 00:24:22.546 A:middle
you've moved those bottom items

00:24:22.586 --> 00:24:24.246 A:middle
down thousands of times.

00:24:25.166 --> 00:24:26.396 A:middle
That is all redundant work, and

00:24:26.396 --> 00:24:27.626 A:middle
that is exactly the sort of

00:24:27.656 --> 00:24:28.976 A:middle
thing I'm looking to eliminate

00:24:29.206 --> 00:24:30.126 A:middle
when I'm trying to improve

00:24:30.126 --> 00:24:30.736 A:middle
performance.

00:24:31.406 --> 00:24:32.596 A:middle
Now the fact of these method

00:24:32.596 --> 00:24:35.376 A:middle
calls talk about batching leads

00:24:35.376 --> 00:24:36.666 A:middle
me to believe that there is

00:24:36.666 --> 00:24:38.006 A:middle
probably some API where I can

00:24:38.006 --> 00:24:39.416 A:middle
ask the outline view to do the

00:24:39.416 --> 00:24:41.436 A:middle
work in bulk so it computes all

00:24:41.436 --> 00:24:43.336 A:middle
the positions just once, instead

00:24:43.336 --> 00:24:44.386 A:middle
of over and over again as I make

00:24:44.426 --> 00:24:44.986 A:middle
the calls.

00:24:46.236 --> 00:24:48.256 A:middle
I also see a call that says to

00:24:48.256 --> 00:24:50.056 A:middle
do the work after end updates.

00:24:50.406 --> 00:24:52.616 A:middle
Now, sometimes an API will offer

00:24:52.726 --> 00:24:53.956 A:middle
sort of bulk method that

00:24:53.956 --> 00:24:55.696 A:middle
operates on an array, and other

00:24:55.696 --> 00:24:57.416 A:middle
times, it will offer a sort of

00:24:57.416 --> 00:24:59.456 A:middle
transactional API that says I'm

00:24:59.456 --> 00:25:00.806 A:middle
going to begin making changes,


00:24:59.456 --> 00:25:00.806 A:middle
going to begin making changes,

00:25:01.046 --> 00:25:01.716 A:middle
then you make a bunch of

00:25:01.716 --> 00:25:02.996 A:middle
changes, and then you say you're

00:25:02.996 --> 00:25:05.046 A:middle
done, and it computes something

00:25:05.046 --> 00:25:05.856 A:middle
that happened for the whole

00:25:05.856 --> 00:25:07.356 A:middle
range of your changes, more

00:25:07.356 --> 00:25:08.656 A:middle
efficiently than if it had done

00:25:08.656 --> 00:25:10.116 A:middle
them all individually.

00:25:11.126 --> 00:25:12.306 A:middle
So at this point, I would head

00:25:12.306 --> 00:25:14.336 A:middle
over to the NS Outline View, or

00:25:14.336 --> 00:25:15.996 A:middle
NS Table View API, and I would

00:25:15.996 --> 00:25:17.296 A:middle
look for some such method.

00:25:17.686 --> 00:25:19.646 A:middle
And there is exactly one there.

00:25:19.646 --> 00:25:20.936 A:middle
In NS Table View, there is

00:25:20.936 --> 00:25:22.176 A:middle
methods for beginning and end

00:25:22.176 --> 00:25:23.546 A:middle
updating, that allow the table

00:25:23.546 --> 00:25:25.096 A:middle
view to coalesce, and make all

00:25:25.096 --> 00:25:26.296 A:middle
this work significantly more

00:25:26.296 --> 00:25:26.666 A:middle
efficient.

00:25:27.426 --> 00:25:28.856 A:middle
Of course, we adopted that in

00:25:28.896 --> 00:25:29.606 A:middle
Xcode 10.

00:25:30.246 --> 00:25:32.966 A:middle
Let me show you.

00:25:33.046 --> 00:25:34.376 A:middle
I'm going to launch Xcode 10.

00:25:38.056 --> 00:25:39.136 A:middle
I'm going to open the source as

00:25:39.136 --> 00:25:43.086 A:middle
an application, and I'm going to

00:25:43.086 --> 00:25:44.056 A:middle
create a couple of tabs.

00:25:44.586 --> 00:25:46.116 A:middle
And you can see, there is no

00:25:46.116 --> 00:25:47.666 A:middle
awful flashing, and the tabs

00:25:47.666 --> 00:25:48.626 A:middle
open much more quickly.

00:25:49.506 --> 00:25:52.686 A:middle
Now, I'd like the tabs to open

00:25:52.876 --> 00:25:54.846 A:middle
even quicker than that, right?

00:25:54.846 --> 00:25:55.916 A:middle
So what am I going to do next?

00:25:56.596 --> 00:25:57.586 A:middle
I got lucky here.

00:25:58.536 --> 00:25:59.496 A:middle
It's not every day that you're

00:25:59.496 --> 00:26:00.956 A:middle
going to go into the trace, and


00:25:59.496 --> 00:26:00.956 A:middle
going to go into the trace, and

00:26:00.956 --> 00:26:02.406 A:middle
find something so obvious and

00:26:02.406 --> 00:26:03.996 A:middle
easy to fix, that is responsible

00:26:03.996 --> 00:26:05.156 A:middle
for 50% of the sample.

00:26:05.916 --> 00:26:08.456 A:middle
Right? In fact, there is not

00:26:08.456 --> 00:26:09.896 A:middle
going to be any other huge lead

00:26:09.896 --> 00:26:10.806 A:middle
sitting there waiting for me.

00:26:11.686 --> 00:26:12.746 A:middle
Instead, what I'm going to need

00:26:12.746 --> 00:26:14.626 A:middle
to do is go through that whole

00:26:14.626 --> 00:26:15.656 A:middle
sample, with those course

00:26:15.656 --> 00:26:17.616 A:middle
filters applied, so I'm only

00:26:17.616 --> 00:26:18.696 A:middle
looking at operations that take

00:26:18.696 --> 00:26:20.286 A:middle
about 1% of the time or more,

00:26:20.286 --> 00:26:21.816 A:middle
and I'm going to look for every

00:26:21.816 --> 00:26:23.436 A:middle
single thing that I see that I

00:26:23.436 --> 00:26:24.836 A:middle
think I can come up with some

00:26:24.836 --> 00:26:25.986 A:middle
mechanism for making a little

00:26:25.986 --> 00:26:26.536 A:middle
bit faster.

00:26:28.056 --> 00:26:29.016 A:middle
I'm going to note them all down

00:26:29.016 --> 00:26:30.496 A:middle
on a piece of paper or in a text

00:26:30.496 --> 00:26:32.216 A:middle
document or something, and then

00:26:32.216 --> 00:26:33.436 A:middle
I'm going to start solving them.

00:26:33.746 --> 00:26:34.736 A:middle
Now, I need to pick an order to

00:26:34.736 --> 00:26:35.656 A:middle
solve them in, right?

00:26:35.656 --> 00:26:37.326 A:middle
Because sometimes the fifth

00:26:37.326 --> 00:26:38.716 A:middle
thing on the list, fixing it

00:26:38.716 --> 00:26:40.016 A:middle
with an obsolete, whatever fix

00:26:40.016 --> 00:26:40.816 A:middle
you would do for the second

00:26:40.816 --> 00:26:42.516 A:middle
thing on the list, and it feels

00:26:42.516 --> 00:26:43.646 A:middle
bad to do them in the wrong

00:26:43.646 --> 00:26:44.516 A:middle
order, such that you did

00:26:44.516 --> 00:26:45.536 A:middle
redundant work, because that's

00:26:45.586 --> 00:26:46.456 A:middle
the whole thing we're trying to

00:26:46.456 --> 00:26:47.506 A:middle
remove in the first place, is

00:26:47.506 --> 00:26:48.116 A:middle
redundant work.

00:26:48.746 --> 00:26:50.476 A:middle
But it's very hard to predict

00:26:50.476 --> 00:26:51.376 A:middle
how these things are all going

00:26:51.376 --> 00:26:51.826 A:middle
to play out.

00:26:52.066 --> 00:26:53.316 A:middle
And you often can't know until

00:26:53.316 --> 00:26:54.316 A:middle
you've already done the work.

00:26:54.746 --> 00:26:57.746 A:middle
So do not let this stop you from

00:26:57.746 --> 00:26:59.446 A:middle
getting started, because you're

00:26:59.446 --> 00:27:00.956 A:middle
going to get your second 30%


00:26:59.446 --> 00:27:00.956 A:middle
going to get your second 30%

00:27:00.956 --> 00:27:03.536 A:middle
improvement by stacking 10 3%

00:27:03.536 --> 00:27:04.186 A:middle
improvements.

00:27:05.706 --> 00:27:05.976 A:middle
Okay?

00:27:07.316 --> 00:27:10.756 A:middle
Now, I want to go back to the

00:27:10.756 --> 00:27:13.516 A:middle
slides, and show you some of the

00:27:13.516 --> 00:27:14.766 A:middle
techniques we typically use to

00:27:14.766 --> 00:27:15.606 A:middle
make those continued

00:27:15.606 --> 00:27:16.126 A:middle
improvements.

00:27:21.346 --> 00:27:22.326 A:middle
Far and away, the thing that

00:27:22.326 --> 00:27:23.896 A:middle
comes up the most frequently is

00:27:23.896 --> 00:27:25.246 A:middle
using those same techniques the

00:27:25.246 --> 00:27:26.236 A:middle
outline view was using.

00:27:26.396 --> 00:27:28.276 A:middle
Batching and deferring, right?

00:27:28.276 --> 00:27:29.736 A:middle
You have an API, and when the

00:27:29.736 --> 00:27:31.526 A:middle
API is called, it has some side

00:27:31.526 --> 00:27:31.836 A:middle
effect.

00:27:32.196 --> 00:27:33.226 A:middle
And then you have some code

00:27:33.226 --> 00:27:34.426 A:middle
calling your API in the loop.

00:27:34.426 --> 00:27:35.396 A:middle
That's what you're doing-- the

00:27:35.586 --> 00:27:36.536 A:middle
primary piece of work that is

00:27:36.536 --> 00:27:37.996 A:middle
being requested, and having a

00:27:37.996 --> 00:27:38.566 A:middle
side effect.

00:27:39.206 --> 00:27:40.986 A:middle
Well, if no one was reading the

00:27:40.986 --> 00:27:42.516 A:middle
result of the side effect, then

00:27:42.516 --> 00:27:43.416 A:middle
you're doing that work

00:27:43.416 --> 00:27:44.536 A:middle
redundantly, over and over

00:27:44.536 --> 00:27:44.916 A:middle
again.

00:27:45.736 --> 00:27:47.016 A:middle
You can often get a much more

00:27:47.016 --> 00:27:48.696 A:middle
efficient interface by using a

00:27:48.696 --> 00:27:50.366 A:middle
batch interface, where a client

00:27:50.366 --> 00:27:52.376 A:middle
gives you an array or some sort

00:27:52.376 --> 00:27:53.476 A:middle
of collection of all the work to

00:27:53.476 --> 00:27:54.796 A:middle
be done, so that you can compute

00:27:54.796 --> 00:27:56.056 A:middle
that side effect just once.

00:27:57.156 --> 00:27:58.176 A:middle
Now, sometimes you have many

00:27:58.176 --> 00:27:59.526 A:middle
clients, right?

00:27:59.526 --> 00:28:00.766 A:middle
And they can't batch across each


00:27:59.526 --> 00:28:00.766 A:middle
And they can't batch across each

00:28:00.766 --> 00:28:02.186 A:middle
other, and you can get even--

00:28:02.596 --> 00:28:03.606 A:middle
you can still get that same

00:28:03.606 --> 00:28:04.946 A:middle
style of performance through

00:28:04.946 --> 00:28:06.346 A:middle
deferring the work and doing it

00:28:06.346 --> 00:28:06.796 A:middle
lazily.

00:28:09.196 --> 00:28:10.996 A:middle
A third easy way to improve

00:28:10.996 --> 00:28:11.966 A:middle
performance is you look through

00:28:11.966 --> 00:28:14.026 A:middle
that instrument's trace, is to

00:28:14.026 --> 00:28:15.156 A:middle
find areas where you see the

00:28:15.156 --> 00:28:17.016 A:middle
same thing being computed over

00:28:17.016 --> 00:28:17.656 A:middle
and over again.

00:28:18.236 --> 00:28:19.556 A:middle
For example, you have a method

00:28:19.676 --> 00:28:20.856 A:middle
in its computing, the size of

00:28:20.856 --> 00:28:22.526 A:middle
some text, then you see the same

00:28:22.526 --> 00:28:24.156 A:middle
thing happening several frames

00:28:24.156 --> 00:28:25.946 A:middle
later, for the same text, and

00:28:25.946 --> 00:28:27.006 A:middle
again, and again.

00:28:27.436 --> 00:28:28.426 A:middle
Now, in this situation, of

00:28:28.496 --> 00:28:29.536 A:middle
course, you want to try to just

00:28:29.536 --> 00:28:31.076 A:middle
compute that value one time.

00:28:32.076 --> 00:28:33.226 A:middle
Compute it at the top, and pass

00:28:33.226 --> 00:28:35.406 A:middle
it down or maybe cache it.

00:28:36.476 --> 00:28:37.846 A:middle
Another technique you have

00:28:37.846 --> 00:28:38.876 A:middle
available in your UI

00:28:38.876 --> 00:28:41.166 A:middle
applications is considering how

00:28:41.166 --> 00:28:42.296 A:middle
many views you are using to

00:28:42.296 --> 00:28:43.146 A:middle
render your UI.

00:28:43.146 --> 00:28:46.466 A:middle
It can be very great for your

00:28:46.466 --> 00:28:48.106 A:middle
source code organization to use

00:28:48.106 --> 00:28:50.216 A:middle
very small views, with small

00:28:50.216 --> 00:28:51.306 A:middle
sets of functionality, and to

00:28:51.306 --> 00:28:52.286 A:middle
compose them together into

00:28:52.286 --> 00:28:53.066 A:middle
larger pieces.

00:28:53.516 --> 00:28:55.216 A:middle
But the more views you use, the

00:28:55.216 --> 00:28:57.516 A:middle
harder you tax the rendering and

00:28:57.516 --> 00:28:58.276 A:middle
layout systems.

00:28:59.306 --> 00:29:01.066 A:middle
Now, this is a two-way street,


00:28:59.306 --> 00:29:01.066 A:middle
Now, this is a two-way street,

00:29:01.336 --> 00:29:02.776 A:middle
because smaller views often led

00:29:02.776 --> 00:29:04.086 A:middle
you to have more fine-grain

00:29:04.086 --> 00:29:05.376 A:middle
caching, which can be good for

00:29:05.376 --> 00:29:06.156 A:middle
performance as well.

00:29:07.266 --> 00:29:08.896 A:middle
But generally, you can tweak the

00:29:08.896 --> 00:29:10.446 A:middle
number of views that you have in

00:29:10.446 --> 00:29:11.606 A:middle
order to have a significant

00:29:11.606 --> 00:29:12.666 A:middle
impact on performance.

00:29:12.786 --> 00:29:14.596 A:middle
It is not always best to have

00:29:14.596 --> 00:29:16.556 A:middle
fewer views, otherwise all of

00:29:16.556 --> 00:29:17.606 A:middle
our applications would just have

00:29:17.686 --> 00:29:18.866 A:middle
one giant view for the whole

00:29:18.866 --> 00:29:19.116 A:middle
thing.

00:29:21.266 --> 00:29:22.396 A:middle
Another technique that comes up

00:29:22.396 --> 00:29:23.816 A:middle
pretty frequently is using

00:29:23.816 --> 00:29:24.806 A:middle
direct observation.

00:29:25.356 --> 00:29:26.916 A:middle
We often have two areas of our

00:29:26.916 --> 00:29:29.716 A:middle
source code that are loosely

00:29:29.716 --> 00:29:30.136 A:middle
coupled.

00:29:30.286 --> 00:29:31.466 A:middle
Maybe one area knows about the

00:29:31.466 --> 00:29:33.296 A:middle
other, and they're communicating

00:29:33.296 --> 00:29:34.996 A:middle
with each other through some

00:29:34.996 --> 00:29:36.016 A:middle
indirect mechanism.

00:29:36.456 --> 00:29:37.796 A:middle
Maybe they're using NS

00:29:37.796 --> 00:29:39.916 A:middle
Notification Center, some

00:29:39.966 --> 00:29:41.316 A:middle
block-based call backs,

00:29:41.516 --> 00:29:43.146 A:middle
delegation, or key value

00:29:43.146 --> 00:29:43.606 A:middle
observing.

00:29:45.006 --> 00:29:46.156 A:middle
Now something that I see very

00:29:46.216 --> 00:29:47.326 A:middle
frequently is we'll have some

00:29:47.326 --> 00:29:49.076 A:middle
model code, and it's going in a

00:29:49.076 --> 00:29:50.946 A:middle
loop, being changed, and every

00:29:50.946 --> 00:29:51.856 A:middle
time it is going to that loop,

00:29:52.206 --> 00:29:54.146 A:middle
it is firing lots of KVO

00:29:54.326 --> 00:29:55.136 A:middle
notifications.

00:29:55.386 --> 00:29:56.286 A:middle
You can't actually see that in

00:29:56.286 --> 00:29:57.876 A:middle
the model code, of course, but

00:29:57.956 --> 00:29:59.236 A:middle
over in some other controller,

00:29:59.526 --> 00:30:00.946 A:middle
it's madly responding and trying


00:29:59.526 --> 00:30:00.946 A:middle
it's madly responding and trying

00:30:00.946 --> 00:30:01.966 A:middle
to keep up with whatever is

00:30:01.966 --> 00:30:03.126 A:middle
changing in the model, and

00:30:03.126 --> 00:30:04.786 A:middle
you're burning lots of CPU time

00:30:04.786 --> 00:30:06.636 A:middle
doing this, that ends up being

00:30:06.636 --> 00:30:07.656 A:middle
redundant when you consider the

00:30:07.656 --> 00:30:08.806 A:middle
whole scope of changes.

00:30:09.496 --> 00:30:12.306 A:middle
Now, if this was direct callouts

00:30:12.776 --> 00:30:13.826 A:middle
from the model code, either

00:30:13.826 --> 00:30:14.866 A:middle
through notifications,

00:30:15.416 --> 00:30:17.106 A:middle
delegation or manual block-based

00:30:17.106 --> 00:30:18.426 A:middle
call backs, it would be much

00:30:18.426 --> 00:30:19.506 A:middle
more obvious that this was

00:30:19.506 --> 00:30:20.516 A:middle
happening as you edited that

00:30:20.516 --> 00:30:20.936 A:middle
model code.

00:30:21.396 --> 00:30:22.556 A:middle
And you might decide that it is

00:30:22.556 --> 00:30:24.366 A:middle
totally appropriate to pull some

00:30:24.366 --> 00:30:26.126 A:middle
of those notifications out from

00:30:26.126 --> 00:30:27.916 A:middle
inside the loop to outside the

00:30:27.916 --> 00:30:29.276 A:middle
loop, to have a big impact on

00:30:29.276 --> 00:30:29.906 A:middle
performance.

00:30:30.556 --> 00:30:31.856 A:middle
Now, alternatively, on the

00:30:31.856 --> 00:30:33.476 A:middle
controller side, you could use

00:30:33.476 --> 00:30:35.206 A:middle
one of these deferring and

00:30:35.206 --> 00:30:36.946 A:middle
batching techniques to avoid the

00:30:36.946 --> 00:30:38.336 A:middle
redundant work and just not

00:30:38.336 --> 00:30:39.246 A:middle
respond synchronously.

00:30:41.136 --> 00:30:42.216 A:middle
Last, this is an easy one.

00:30:42.836 --> 00:30:44.716 A:middle
Once your code is already on the

00:30:45.046 --> 00:30:46.386 A:middle
[inaudible] happy path, you

00:30:46.386 --> 00:30:47.586 A:middle
know, it's already linear, and

00:30:47.586 --> 00:30:48.736 A:middle
it's not going to get any better

00:30:48.736 --> 00:30:49.366 A:middle
than linear.

00:30:49.366 --> 00:30:50.346 A:middle
That's sort of the minimum

00:30:51.796 --> 00:30:52.766 A:middle
performance that you're going to

00:30:52.766 --> 00:30:52.966 A:middle
get.

00:30:53.626 --> 00:30:54.876 A:middle
You're after all the constant

00:30:54.876 --> 00:30:57.186 A:middle
time improvements that you can.

00:30:57.246 --> 00:30:58.676 A:middle
Now, an easy one is that if

00:30:58.676 --> 00:31:00.096 A:middle
you're using dictionaries like


00:30:58.676 --> 00:31:00.096 A:middle
you're using dictionaries like

00:31:00.096 --> 00:31:01.366 A:middle
they were objects, then you

00:31:01.366 --> 00:31:02.636 A:middle
probably know you're doing this,

00:31:02.926 --> 00:31:04.216 A:middle
if you have a bunch of string

00:31:04.216 --> 00:31:06.166 A:middle
constants for all the keys, then

00:31:06.166 --> 00:31:07.466 A:middle
you can get a big improvement to

00:31:07.466 --> 00:31:09.186 A:middle
code clarity, to code

00:31:09.186 --> 00:31:11.396 A:middle
completion, to re-factoring, to

00:31:11.396 --> 00:31:12.396 A:middle
making the validating your

00:31:12.396 --> 00:31:14.046 A:middle
source code, by using specific

00:31:14.526 --> 00:31:14.966 A:middle
types.

00:31:15.076 --> 00:31:16.136 A:middle
It couldn't be easier with

00:31:16.136 --> 00:31:18.066 A:middle
strucks and swift with their

00:31:18.066 --> 00:31:19.196 A:middle
implicit initializers and

00:31:19.196 --> 00:31:20.816 A:middle
conformance to equitable hash.

00:31:21.336 --> 00:31:23.646 A:middle
And this can just be hands-down

00:31:23.646 --> 00:31:24.586 A:middle
an improvement to your source

00:31:24.586 --> 00:31:26.206 A:middle
code, and you'd be surprised at

00:31:26.206 --> 00:31:27.916 A:middle
how much time you're spending in

00:31:27.916 --> 00:31:29.546 A:middle
string hashing and string

00:31:29.546 --> 00:31:31.126 A:middle
equation if you were doing this

00:31:31.126 --> 00:31:32.546 A:middle
millions of times on lots of

00:31:32.546 --> 00:31:33.316 A:middle
small objects.

00:31:34.516 --> 00:31:35.736 A:middle
So with that, I'd like to turn

00:31:35.736 --> 00:31:37.386 A:middle
it over to Matthew to talk to

00:31:37.386 --> 00:31:38.966 A:middle
you about how we've applied

00:31:39.056 --> 00:31:40.226 A:middle
these techniques inside of

00:31:40.226 --> 00:31:40.686 A:middle
photos.

00:31:42.516 --> 00:31:47.866 A:middle
[ Applause ]

00:31:48.366 --> 00:31:48.806 A:middle
&gt;&gt; Thanks Jim.

00:31:49.966 --> 00:31:50.656 A:middle
Hi everyone.

00:31:50.826 --> 00:31:52.746 A:middle
I'm Matthew Lucas, an engineer

00:31:52.806 --> 00:31:56.076 A:middle
in the photos team, and today I

00:31:56.076 --> 00:31:57.536 A:middle
want to give you some practical

00:31:57.536 --> 00:31:59.316 A:middle
examples on performance from

00:31:59.316 --> 00:32:00.296 A:middle
directly from photos.


00:31:59.316 --> 00:32:00.296 A:middle
directly from photos.

00:32:01.306 --> 00:32:02.556 A:middle
So first, let's talk about

00:32:02.556 --> 00:32:03.536 A:middle
photos for a second.

00:32:04.076 --> 00:32:05.276 A:middle
We are all familiar with this

00:32:05.276 --> 00:32:05.466 A:middle
app.

00:32:06.026 --> 00:32:07.766 A:middle
It lets you store, browse, and

00:32:07.846 --> 00:32:09.296 A:middle
experience your favorite

00:32:09.296 --> 00:32:09.696 A:middle
moments.

00:32:10.236 --> 00:32:11.686 A:middle
So you can browse your favorite

00:32:11.716 --> 00:32:13.526 A:middle
moments from the moments view,

00:32:13.646 --> 00:32:14.596 A:middle
that you can see here.

00:32:14.596 --> 00:32:15.496 A:middle
It's is the default view.

00:32:15.926 --> 00:32:17.526 A:middle
But you can also get another

00:32:17.526 --> 00:32:19.456 A:middle
view from the collection, or the

00:32:19.456 --> 00:32:19.926 A:middle
years.

00:32:20.566 --> 00:32:22.166 A:middle
And I'll talk more about this

00:32:22.166 --> 00:32:22.736 A:middle
view later.

00:32:23.446 --> 00:32:25.306 A:middle
Now, libraries today can go from

00:32:25.306 --> 00:32:28.346 A:middle
1,000 to 100,000 assets previous

00:32:29.126 --> 00:32:30.066 A:middle
depending on your love for

00:32:30.066 --> 00:32:30.636 A:middle
photography.

00:32:31.196 --> 00:32:33.036 A:middle
And we all love capturing those

00:32:33.036 --> 00:32:34.696 A:middle
fun and precious moments we live

00:32:34.696 --> 00:32:34.976 A:middle
every day.

00:32:36.336 --> 00:32:37.366 A:middle
So we are patient enough to

00:32:37.366 --> 00:32:38.846 A:middle
capture them, but we are less

00:32:38.846 --> 00:32:40.156 A:middle
patient when something like this

00:32:40.156 --> 00:32:40.576 A:middle
appears.

00:32:41.286 --> 00:32:42.346 A:middle
How would you feel if something

00:32:42.346 --> 00:32:44.226 A:middle
moments like this would be

00:32:44.226 --> 00:32:45.296 A:middle
displayed in Photos the first

00:32:45.296 --> 00:32:46.926 A:middle
time you launch the app?

00:32:47.386 --> 00:32:48.636 A:middle
Now, you may also experience

00:32:48.636 --> 00:32:50.596 A:middle
something like this, where we

00:32:50.596 --> 00:32:51.716 A:middle
are showing a lot of

00:32:51.716 --> 00:32:53.106 A:middle
placeholders, and that's really

00:32:53.106 --> 00:32:53.586 A:middle
not great.

00:32:54.266 --> 00:32:55.356 A:middle
Maybe you're soft scrolling,

00:32:55.856 --> 00:32:57.216 A:middle
you'll be lost in this gray

00:32:57.216 --> 00:32:58.936 A:middle
area, the [inaudible] would

00:32:58.936 --> 00:33:00.736 A:middle
start to load, but then you'll


00:32:58.936 --> 00:33:00.736 A:middle
start to load, but then you'll

00:33:00.736 --> 00:33:01.766 A:middle
keep scrolling and then you'll

00:33:01.766 --> 00:33:02.886 A:middle
experience some frame drops

00:33:02.886 --> 00:33:03.876 A:middle
because the views are being

00:33:03.876 --> 00:33:04.326 A:middle
updated.

00:33:05.556 --> 00:33:06.836 A:middle
Well, our goal is to not show

00:33:06.836 --> 00:33:07.626 A:middle
views like this.

00:33:08.666 --> 00:33:09.876 A:middle
We think this is not providing a

00:33:09.926 --> 00:33:12.066 A:middle
great user experience, but we

00:33:12.066 --> 00:33:13.366 A:middle
understand that sometimes it's

00:33:13.366 --> 00:33:14.156 A:middle
unavoidable.

00:33:14.556 --> 00:33:15.706 A:middle
But when it's too frequent, this

00:33:15.706 --> 00:33:16.666 A:middle
isn't really great.

00:33:18.546 --> 00:33:19.666 A:middle
Now, when you work on an app,

00:33:19.666 --> 00:33:20.756 A:middle
you want to make sure that it's

00:33:20.756 --> 00:33:22.456 A:middle
responsive, and usable at once.

00:33:23.576 --> 00:33:25.296 A:middle
You also want to make sure that

00:33:25.296 --> 00:33:26.516 A:middle
the animations are smooth.

00:33:27.226 --> 00:33:30.516 A:middle
And these two attributes are

00:33:30.516 --> 00:33:31.796 A:middle
really crucial to providing a

00:33:31.796 --> 00:33:32.786 A:middle
great user experience.

00:33:33.446 --> 00:33:35.766 A:middle
If the users don't find your app

00:33:35.766 --> 00:33:37.256 A:middle
relatable or pertinent, they

00:33:37.256 --> 00:33:38.146 A:middle
might stop using it.

00:33:39.526 --> 00:33:40.706 A:middle
Now, to illustrate these two

00:33:40.706 --> 00:33:42.626 A:middle
points, I would like to give you

00:33:42.626 --> 00:33:43.426 A:middle
two examples.

00:33:43.716 --> 00:33:45.726 A:middle
And the first one is going to be

00:33:45.726 --> 00:33:47.406 A:middle
how we optimize launching to

00:33:47.406 --> 00:33:48.166 A:middle
this moment view.

00:33:48.886 --> 00:33:50.506 A:middle
The second one is how we build

00:33:50.506 --> 00:33:52.576 A:middle
the collections and years view

00:33:52.576 --> 00:33:53.866 A:middle
for good scrolling preference.

00:33:56.696 --> 00:33:59.876 A:middle
First, let's do launching


00:34:00.296 --> 00:34:02.296 A:middle
[inaudible].

00:34:02.716 --> 00:34:03.876 A:middle
So what is launch?

00:34:04.046 --> 00:34:04.986 A:middle
There are three kinds of

00:34:04.986 --> 00:34:05.386 A:middle
launches.

00:34:06.696 --> 00:34:08.176 A:middle
The first and more expensive one

00:34:08.176 --> 00:34:09.476 A:middle
is the find referred as called,

00:34:09.476 --> 00:34:11.406 A:middle
and it depends the first time

00:34:11.406 --> 00:34:12.335 A:middle
you are going to relaunch your

00:34:12.335 --> 00:34:13.186 A:middle
app after it reboots.

00:34:14.346 --> 00:34:15.606 A:middle
So basically, nothing has been

00:34:15.606 --> 00:34:17.446 A:middle
cached yet, and it might require

00:34:17.446 --> 00:34:19.096 A:middle
some bug run processes or some

00:34:19.096 --> 00:34:19.946 A:middle
libraries to load.

00:34:21.136 --> 00:34:23.116 A:middle
Now, it also happens when the

00:34:23.206 --> 00:34:24.916 A:middle
system goes under memory

00:34:24.916 --> 00:34:27.136 A:middle
pressure and starts reclaiming

00:34:27.735 --> 00:34:29.686 A:middle
some memory.

00:34:30.045 --> 00:34:31.485 A:middle
Now, if you kill an app, it

00:34:31.485 --> 00:34:32.906 A:middle
might not trigger a code launch,

00:34:32.906 --> 00:34:34.606 A:middle
because the system decides when

00:34:34.606 --> 00:34:38.766 A:middle
the resources should be paged

00:34:38.766 --> 00:34:38.976 A:middle
out.

00:34:39.065 --> 00:34:40.466 A:middle
And when you kill an app, and

00:34:40.466 --> 00:34:41.646 A:middle
you relaunch it a few second

00:34:41.726 --> 00:34:43.835 A:middle
later, it's almost guaranteed

00:34:43.835 --> 00:34:45.565 A:middle
that you'll hit a warm launch.

00:34:46.036 --> 00:34:47.706 A:middle
And we call it warm, because the

00:34:47.706 --> 00:34:50.386 A:middle
resources or the dependents are

00:34:50.386 --> 00:34:52.116 A:middle
still in the cache, so it's

00:34:52.116 --> 00:34:52.996 A:middle
faster to launch.

00:34:54.525 --> 00:34:56.636 A:middle
Now, the last type is-- we call

00:34:56.636 --> 00:34:59.026 A:middle
it hot, and it's basically a

00:34:59.026 --> 00:35:00.926 A:middle
resume, because it's when your


00:34:59.026 --> 00:35:00.926 A:middle
resume, because it's when your

00:35:00.926 --> 00:35:02.526 A:middle
app is already running and is

00:35:02.526 --> 00:35:03.666 A:middle
being brought back to the

00:35:03.666 --> 00:35:04.206 A:middle
foreground.

00:35:05.046 --> 00:35:06.136 A:middle
So when you start measuring

00:35:06.136 --> 00:35:07.656 A:middle
launch, you should start by

00:35:07.656 --> 00:35:08.786 A:middle
measuring the warm launch.

00:35:09.456 --> 00:35:12.636 A:middle
And the time it takes to launch

00:35:12.636 --> 00:35:14.036 A:middle
during this warm is less

00:35:14.036 --> 00:35:17.326 A:middle
variable than the cold launch,

00:35:17.326 --> 00:35:18.656 A:middle
and the test iteration is much

00:35:18.656 --> 00:35:19.656 A:middle
faster as you don't need to

00:35:19.656 --> 00:35:20.536 A:middle
reboot your device.

00:35:21.846 --> 00:35:23.226 A:middle
Now, the way we measure launch

00:35:23.226 --> 00:35:25.156 A:middle
is by evaluating the time it

00:35:25.156 --> 00:35:26.566 A:middle
takes from the moment you hit

00:35:26.676 --> 00:35:28.236 A:middle
the application icon, and until

00:35:28.236 --> 00:35:29.706 A:middle
you can start interacting with

00:35:29.706 --> 00:35:30.696 A:middle
the app.

00:35:30.986 --> 00:35:32.316 A:middle
And what I mean by interacting

00:35:32.316 --> 00:35:34.386 A:middle
is that it's really using and

00:35:34.386 --> 00:35:35.726 A:middle
not interacting with a spinner.

00:35:37.436 --> 00:35:38.826 A:middle
A common pattern is to dispatch

00:35:38.856 --> 00:35:40.536 A:middle
some work and display a spinner

00:35:40.536 --> 00:35:41.956 A:middle
in the meantime, well that

00:35:41.956 --> 00:35:43.126 A:middle
doesn't make the app usable

00:35:43.126 --> 00:35:44.526 A:middle
sooner, so we are trying to

00:35:44.526 --> 00:35:47.086 A:middle
avoid that here.

00:35:47.386 --> 00:35:48.656 A:middle
Now there are three goals that

00:35:48.656 --> 00:35:49.886 A:middle
we are shooting for at Photos,

00:35:50.576 --> 00:35:52.056 A:middle
and the first one is that we

00:35:52.056 --> 00:35:54.486 A:middle
want to instant, we don't want

00:35:54.486 --> 00:35:57.666 A:middle
to display any spinner, and we

00:35:57.666 --> 00:35:59.266 A:middle
don't want to display any


00:36:00.996 --> 00:36:02.256 A:middle
placeholder or [inaudible].

00:36:03.286 --> 00:36:04.346 A:middle
And I Have to be honest with

00:36:04.346 --> 00:36:06.686 A:middle
you, we-- you might see some

00:36:06.686 --> 00:36:07.886 A:middle
placeholders the first time you

00:36:07.886 --> 00:36:09.536 A:middle
synchronize with iClub, but when

00:36:09.536 --> 00:36:11.196 A:middle
the data is local, we really try

00:36:11.266 --> 00:36:13.746 A:middle
our best to not display any.

00:36:13.996 --> 00:36:15.446 A:middle
Now, what do we mean by instant?

00:36:16.356 --> 00:36:17.606 A:middle
Well, the time it takes to

00:36:17.606 --> 00:36:18.836 A:middle
launch should be the same time

00:36:18.836 --> 00:36:20.106 A:middle
as the zoom animation from the

00:36:20.106 --> 00:36:20.646 A:middle
home screen.

00:36:21.086 --> 00:36:22.506 A:middle
That is usually between 500 and

00:36:22.506 --> 00:36:24.796 A:middle
600 milliseconds, and that way,

00:36:25.176 --> 00:36:26.386 A:middle
the transition from the home

00:36:26.386 --> 00:36:27.726 A:middle
screen to the application is

00:36:27.836 --> 00:36:29.426 A:middle
seamless for the user, and the

00:36:29.426 --> 00:36:31.036 A:middle
user can start interacting with

00:36:31.036 --> 00:36:32.576 A:middle
it, as soon as the animation is

00:36:32.626 --> 00:36:32.876 A:middle
done.

00:36:33.446 --> 00:36:34.666 A:middle
And by the way, this is the

00:36:34.666 --> 00:36:35.986 A:middle
lowest recommendation, not

00:36:35.986 --> 00:36:37.546 A:middle
something just for photos, so

00:36:37.546 --> 00:36:40.186 A:middle
it's valid for any apps.

00:36:40.346 --> 00:36:41.666 A:middle
Now, let's look at how photos

00:36:41.666 --> 00:36:42.266 A:middle
launches today.

00:36:43.436 --> 00:36:44.956 A:middle
If we look more closely at what

00:36:44.956 --> 00:36:46.576 A:middle
is happening exactly, you can

00:36:46.576 --> 00:36:48.656 A:middle
see that photos is all set up

00:36:48.656 --> 00:36:50.146 A:middle
and ready before the animation

00:36:50.146 --> 00:36:50.576 A:middle
is done.

00:36:53.466 --> 00:36:55.216 A:middle
And if we dive into the launch

00:36:55.216 --> 00:36:57.356 A:middle
anatomy, you will see there is

00:36:57.356 --> 00:36:58.326 A:middle
mainly two parts.

00:36:58.746 --> 00:37:00.256 A:middle
The first part is being spent in


00:36:58.746 --> 00:37:00.256 A:middle
The first part is being spent in

00:37:00.256 --> 00:37:02.156 A:middle
DYD, this is the loader that is

00:37:02.156 --> 00:37:03.466 A:middle
going to load and link all of

00:37:03.466 --> 00:37:05.416 A:middle
your dependent libraries, but

00:37:05.416 --> 00:37:06.436 A:middle
it's also going to run your

00:37:06.436 --> 00:37:07.576 A:middle
static initializers.

00:37:08.766 --> 00:37:10.316 A:middle
And your control over that part

00:37:10.426 --> 00:37:11.476 A:middle
is limited, but it's not

00:37:11.476 --> 00:37:11.886 A:middle
impossible.

00:37:12.576 --> 00:37:14.886 A:middle
I would encourage you to watch

00:37:14.886 --> 00:37:17.166 A:middle
the DYD session from last year

00:37:18.196 --> 00:37:21.496 A:middle
in order to get more details on

00:37:21.496 --> 00:37:21.896 A:middle
that part.

00:37:23.566 --> 00:37:25.686 A:middle
Now DYD is also calling Main in

00:37:25.686 --> 00:37:27.486 A:middle
your object table, which leads

00:37:27.486 --> 00:37:28.716 A:middle
us to the second part here,

00:37:29.106 --> 00:37:30.356 A:middle
where you have lots of control

00:37:30.356 --> 00:37:32.236 A:middle
over, and this part, you need to

00:37:32.236 --> 00:37:34.016 A:middle
make sure that it stays under

00:37:34.016 --> 00:37:35.056 A:middle
500 milliseconds.

00:37:35.976 --> 00:37:37.376 A:middle
Now, the first [inaudible] pass

00:37:37.376 --> 00:37:38.386 A:middle
that is being scheduled right

00:37:38.386 --> 00:37:39.786 A:middle
after the Did Finish launching

00:37:40.276 --> 00:37:41.286 A:middle
will mark the end of your

00:37:41.286 --> 00:37:42.796 A:middle
launch, and this is basically

00:37:42.796 --> 00:37:43.946 A:middle
when your app should be usable.

00:37:46.016 --> 00:37:47.556 A:middle
There are a few principles that

00:37:47.606 --> 00:37:49.116 A:middle
we will be referring to during

00:37:49.116 --> 00:37:51.056 A:middle
this session, and these are

00:37:51.056 --> 00:37:52.316 A:middle
really the common pillars of the

00:37:52.316 --> 00:37:53.456 A:middle
performance work that we

00:37:53.456 --> 00:37:53.846 A:middle
achieved.

00:37:55.116 --> 00:37:56.976 A:middle
The first one is that we want to

00:37:56.976 --> 00:37:59.566 A:middle
be lazy and defer the work that

00:37:59.616 --> 00:38:00.876 A:middle
we don't need.


00:37:59.616 --> 00:38:00.876 A:middle
we don't need.

00:38:01.396 --> 00:38:02.546 A:middle
The second one is that we want

00:38:02.546 --> 00:38:04.506 A:middle
to be proactive, and it's valid

00:38:04.506 --> 00:38:05.256 A:middle
for two things.

00:38:05.256 --> 00:38:07.866 A:middle
It's valid for being proactive

00:38:08.006 --> 00:38:09.716 A:middle
in order to anticipate the work

00:38:09.716 --> 00:38:12.296 A:middle
that we are making it later, we

00:38:12.296 --> 00:38:13.526 A:middle
also want to be proactive and

00:38:13.526 --> 00:38:15.176 A:middle
catch regressions quickly, so

00:38:15.176 --> 00:38:16.116 A:middle
you should make sure that you

00:38:16.116 --> 00:38:17.586 A:middle
have continuous integration

00:38:17.916 --> 00:38:18.716 A:middle
testing in place.

00:38:21.536 --> 00:38:23.116 A:middle
And the last point is we want to

00:38:23.116 --> 00:38:24.726 A:middle
be constant, regardless of the

00:38:24.806 --> 00:38:26.046 A:middle
total amount of data that we

00:38:26.046 --> 00:38:26.566 A:middle
need to load.

00:38:29.496 --> 00:38:31.646 A:middle
Now, if we were taking a nave

00:38:31.646 --> 00:38:32.986 A:middle
approach, and we were loading

00:38:32.986 --> 00:38:34.186 A:middle
everything we needed during

00:38:34.186 --> 00:38:35.366 A:middle
launch, this is how long it

00:38:35.366 --> 00:38:37.806 A:middle
would take roughly for a 30,000

00:38:37.806 --> 00:38:38.556 A:middle
item library.

00:38:39.696 --> 00:38:41.106 A:middle
First you need to initialize the

00:38:41.106 --> 00:38:42.696 A:middle
database, then you need to

00:38:42.696 --> 00:38:43.986 A:middle
prepare some view controllers.

00:38:44.356 --> 00:38:45.516 A:middle
You need to configure the data

00:38:45.516 --> 00:38:47.236 A:middle
sources, load some library

00:38:47.236 --> 00:38:48.586 A:middle
images, and fetch the cloud

00:38:48.586 --> 00:38:49.066 A:middle
status.

00:38:49.986 --> 00:38:52.236 A:middle
And keep in mind that this might

00:38:52.306 --> 00:38:54.496 A:middle
vary as the data grow, and in

00:38:54.496 --> 00:38:56.666 A:middle
fact, the data will grow forever

00:38:56.666 --> 00:38:58.606 A:middle
as people takes pictures every

00:38:59.526 --> 00:38:59.593 A:middle
day.


00:39:00.046 --> 00:39:01.666 A:middle
So at Photos, really keep in

00:39:01.666 --> 00:39:02.646 A:middle
mind that we are dealing with a

00:39:02.646 --> 00:39:05.526 A:middle
non-bonded data sets.

00:39:05.766 --> 00:39:07.016 A:middle
Now, let's see how we optimize

00:39:07.016 --> 00:39:09.166 A:middle
each of these steps for Photos,

00:39:09.166 --> 00:39:09.836 A:middle
and let's start with

00:39:09.836 --> 00:39:11.846 A:middle
initializing the database.

00:39:13.236 --> 00:39:15.146 A:middle
So first, usually, the database

00:39:15.146 --> 00:39:16.606 A:middle
is initialized and loaded when

00:39:16.606 --> 00:39:18.056 A:middle
the first query is being fired.

00:39:18.656 --> 00:39:19.886 A:middle
One optimization that we have

00:39:19.886 --> 00:39:21.806 A:middle
found was to do it as early as

00:39:21.806 --> 00:39:22.796 A:middle
possible in the background

00:39:22.796 --> 00:39:24.586 A:middle
thread, so that it doesn't have

00:39:24.586 --> 00:39:26.346 A:middle
to do the initialization when

00:39:26.346 --> 00:39:27.636 A:middle
the first query has been fired.

00:39:28.996 --> 00:39:30.736 A:middle
And this is an issue, especially

00:39:30.946 --> 00:39:32.256 A:middle
if the first query is being done

00:39:32.256 --> 00:39:33.006 A:middle
from the main thread.

00:39:34.756 --> 00:39:39.696 A:middle
Now, we spend a lot of time and

00:39:39.696 --> 00:39:40.646 A:middle
we are still spending a lot of

00:39:40.706 --> 00:39:41.956 A:middle
time reviewing all the queries

00:39:41.956 --> 00:39:43.116 A:middle
that we're doing during launch,

00:39:43.626 --> 00:39:44.766 A:middle
and we want to make sure that

00:39:44.846 --> 00:39:46.396 A:middle
the work that we are doing is

00:39:46.396 --> 00:39:47.786 A:middle
only the necessary one, and we

00:39:47.786 --> 00:39:49.276 A:middle
are not doing more.

00:39:53.246 --> 00:39:56.106 A:middle
Now, lastly, we want to ensure

00:39:56.106 --> 00:39:57.586 A:middle
that all the queries that we are

00:39:57.586 --> 00:39:59.576 A:middle
doing are efficient as possible,

00:39:59.576 --> 00:40:01.086 A:middle
and we want to avoid the complex


00:39:59.576 --> 00:40:01.086 A:middle
and we want to avoid the complex

00:40:01.086 --> 00:40:04.006 A:middle
query as much as possible as

00:40:04.636 --> 00:40:04.876 A:middle
well.

00:40:05.276 --> 00:40:06.986 A:middle
And we sometimes we understand

00:40:06.986 --> 00:40:08.646 A:middle
that we need this, and for these

00:40:08.686 --> 00:40:10.676 A:middle
cases, we are setting up some

00:40:10.676 --> 00:40:12.016 A:middle
indexes, so that we can speed

00:40:12.016 --> 00:40:12.276 A:middle
them up.

00:40:15.676 --> 00:40:17.396 A:middle
Now we are aiming for, at most,

00:40:17.396 --> 00:40:19.546 A:middle
30 milliseconds spent in that

00:40:19.546 --> 00:40:20.406 A:middle
initialization.

00:40:21.286 --> 00:40:22.526 A:middle
So next, let's look at how we

00:40:22.526 --> 00:40:23.246 A:middle
are preparing our view

00:40:23.246 --> 00:40:23.826 A:middle
controllers.

00:40:25.106 --> 00:40:25.986 A:middle
So we have four tabs

00:40:25.986 --> 00:40:27.796 A:middle
representing the main features

00:40:27.906 --> 00:40:29.486 A:middle
of the app.

00:40:29.656 --> 00:40:30.966 A:middle
And so the first thing that we

00:40:30.966 --> 00:40:32.826 A:middle
need to be careful of is we want

00:40:32.826 --> 00:40:33.926 A:middle
to minimize the work that is

00:40:33.926 --> 00:40:35.756 A:middle
being done in the initialization

00:40:35.756 --> 00:40:37.306 A:middle
of these three non-visible ones,

00:40:37.746 --> 00:40:39.896 A:middle
and the rule that we are trying

00:40:39.896 --> 00:40:41.516 A:middle
to follow here is to do as

00:40:41.566 --> 00:40:42.906 A:middle
little work as possible in the

00:40:42.906 --> 00:40:43.666 A:middle
initializers.

00:40:44.396 --> 00:40:45.436 A:middle
We really want to do the bare

00:40:45.436 --> 00:40:47.246 A:middle
minimum, and note all the data

00:40:47.246 --> 00:40:47.946 A:middle
in the view that loads.

00:40:50.486 --> 00:40:52.716 A:middle
This also allows us to

00:40:52.786 --> 00:40:54.646 A:middle
initialize our controllers in

00:40:54.706 --> 00:40:56.446 A:middle
constant time.

00:40:58.206 --> 00:40:59.936 A:middle
Now, lastly, we also want to

00:40:59.936 --> 00:41:01.756 A:middle
ensure that only the visible


00:40:59.936 --> 00:41:01.756 A:middle
ensure that only the visible

00:41:01.756 --> 00:41:02.376 A:middle
views are loaded.

00:41:02.896 --> 00:41:06.116 A:middle
It's easy, and we often regress

00:41:06.116 --> 00:41:07.806 A:middle
on that part, so you should

00:41:07.806 --> 00:41:11.376 A:middle
really be careful about that.

00:41:12.016 --> 00:41:12.706 A:middle
So preparing the view

00:41:12.706 --> 00:41:14.106 A:middle
controllers, we are now aiming

00:41:14.106 --> 00:41:15.696 A:middle
for 120 milliseconds.

00:41:16.626 --> 00:41:18.376 A:middle
But preparing view controllers

00:41:18.376 --> 00:41:19.646 A:middle
implies configuring the data

00:41:19.646 --> 00:41:21.586 A:middle
sources, and let's look at that

00:41:21.586 --> 00:41:22.216 A:middle
chunk next.

00:41:25.056 --> 00:41:26.716 A:middle
So the Moments view is a

00:41:26.716 --> 00:41:27.996 A:middle
representation of these things,

00:41:27.996 --> 00:41:30.086 A:middle
events in your life, and the UI

00:41:30.086 --> 00:41:31.376 A:middle
represents that by having this

00:41:31.426 --> 00:41:32.796 A:middle
group of photos, and these

00:41:32.866 --> 00:41:33.266 A:middle
headers.

00:41:34.206 --> 00:41:35.866 A:middle
In this library, for example, we

00:41:35.866 --> 00:41:38.596 A:middle
might have 500 moments, and in

00:41:38.596 --> 00:41:40.026 A:middle
order to build a view, we need

00:41:40.026 --> 00:41:40.766 A:middle
to load all the moments up

00:41:40.766 --> 00:41:40.976 A:middle
front.

00:41:43.236 --> 00:41:44.706 A:middle
But the only thing we need

00:41:44.956 --> 00:41:46.846 A:middle
really for these moments is only

00:41:46.846 --> 00:41:48.666 A:middle
the meta data so we can build

00:41:48.666 --> 00:41:48.986 A:middle
the view.

00:41:49.706 --> 00:41:50.676 A:middle
We don't need your content.

00:41:51.226 --> 00:41:54.846 A:middle
So the first thing we do is we

00:41:54.846 --> 00:41:56.366 A:middle
fire that query, which is super

00:41:56.366 --> 00:41:56.726 A:middle
fast.

00:41:56.926 --> 00:41:59.356 A:middle
And then we are only loading the

00:41:59.396 --> 00:42:01.086 A:middle
content that we need here.


00:41:59.396 --> 00:42:01.086 A:middle
content that we need here.

00:42:02.286 --> 00:42:04.046 A:middle
In that case here, we are only

00:42:04.046 --> 00:42:05.016 A:middle
going to load the visible

00:42:05.016 --> 00:42:07.466 A:middle
content, which in our case is

00:42:07.466 --> 00:42:09.096 A:middle
going to be between 7 to 10

00:42:09.096 --> 00:42:09.616 A:middle
Moments.

00:42:10.956 --> 00:42:12.536 A:middle
Since our deficit is limited,

00:42:12.876 --> 00:42:14.616 A:middle
and finite, we can allow

00:42:14.616 --> 00:42:16.066 A:middle
ourselves to do it synchronously

00:42:16.066 --> 00:42:18.376 A:middle
on the main thread.

00:42:18.696 --> 00:42:20.896 A:middle
Now, we also want to anticipate

00:42:20.896 --> 00:42:23.526 A:middle
and schedule the work so that we

00:42:23.526 --> 00:42:25.546 A:middle
can start loading the remaining

00:42:25.546 --> 00:42:26.596 A:middle
data as synchronously.

00:42:27.156 --> 00:42:28.406 A:middle
And we do that on the bug run

00:42:28.406 --> 00:42:30.236 A:middle
thread, with the right quality

00:42:30.316 --> 00:42:31.356 A:middle
of service to make sure that it

00:42:31.356 --> 00:42:32.556 A:middle
doesn't preempt the main thread

00:42:32.556 --> 00:42:33.886 A:middle
from running.

00:42:38.416 --> 00:42:40.516 A:middle
Now we are aiming at 100

00:42:40.516 --> 00:42:41.416 A:middle
milliseconds here.

00:42:44.706 --> 00:42:48.266 A:middle
So lastly, our data sources are

00:42:48.266 --> 00:42:50.226 A:middle
also providing some images and

00:42:50.226 --> 00:42:51.456 A:middle
let's see how we optimize that

00:42:51.506 --> 00:42:51.736 A:middle
part.

00:42:53.666 --> 00:42:54.916 A:middle
So this was by far the biggest

00:42:54.916 --> 00:42:55.936 A:middle
chunk here that we are all

00:42:55.936 --> 00:42:57.986 A:middle
attacking, and when we realized

00:42:57.986 --> 00:42:59.066 A:middle
that we were spending multiple

00:42:59.066 --> 00:43:00.376 A:middle
seconds loading this image


00:42:59.066 --> 00:43:00.376 A:middle
seconds loading this image

00:43:00.376 --> 00:43:02.536 A:middle
during launch, we realized that

00:43:02.586 --> 00:43:04.686 A:middle
we were doing too much work.

00:43:05.086 --> 00:43:06.296 A:middle
So the first thing that we did

00:43:06.296 --> 00:43:08.686 A:middle
is that we evaluated the number

00:43:08.686 --> 00:43:10.246 A:middle
of images that we needed during

00:43:10.246 --> 00:43:12.556 A:middle
launch, and we are only loading

00:43:12.556 --> 00:43:13.536 A:middle
that during that first

00:43:13.536 --> 00:43:14.566 A:middle
transaction.

00:43:15.286 --> 00:43:17.216 A:middle
In that case, that can be up to

00:43:17.216 --> 00:43:19.436 A:middle
60 including some piling above

00:43:19.436 --> 00:43:19.876 A:middle
and below.

00:43:20.576 --> 00:43:23.386 A:middle
And next, in order to load those

00:43:23.386 --> 00:43:25.036 A:middle
images firstly, we need to make

00:43:25.036 --> 00:43:26.676 A:middle
sure that we are all loading

00:43:26.676 --> 00:43:28.046 A:middle
only low-resolutions one.

00:43:28.806 --> 00:43:29.956 A:middle
That way we are loading fewer

00:43:29.956 --> 00:43:32.026 A:middle
pixels in memory, and it is much

00:43:32.026 --> 00:43:32.546 A:middle
more efficient.

00:43:35.316 --> 00:43:36.566 A:middle
That chunk is now representing

00:43:36.566 --> 00:43:37.486 A:middle
200 milliseconds.

00:43:39.316 --> 00:43:40.846 A:middle
And this is, by far, the biggest

00:43:40.846 --> 00:43:41.566 A:middle
gain that we had.

00:43:42.296 --> 00:43:43.466 A:middle
Which I need to be a constant

00:43:43.466 --> 00:43:46.966 A:middle
time, and that's really great.

00:43:47.786 --> 00:43:49.346 A:middle
Now, sometimes you have to ask

00:43:49.346 --> 00:43:50.806 A:middle
yourself the question, is this

00:43:50.806 --> 00:43:52.056 A:middle
really needed during launch?

00:43:52.286 --> 00:43:54.116 A:middle
And one of our examples here is

00:43:54.116 --> 00:43:54.896 A:middle
this footer view.

00:43:55.486 --> 00:43:57.256 A:middle
That pulls information via the

00:43:57.256 --> 00:44:00.316 A:middle
network or the database, and


00:43:57.256 --> 00:44:00.316 A:middle
network or the database, and

00:44:00.316 --> 00:44:01.666 A:middle
literally first our design was

00:44:01.666 --> 00:44:03.616 A:middle
to not show it during launch.

00:44:04.086 --> 00:44:05.806 A:middle
To prioritize all the images

00:44:05.806 --> 00:44:06.636 A:middle
that we are seeing here.

00:44:06.906 --> 00:44:08.366 A:middle
We wanted to show as much images

00:44:08.366 --> 00:44:08.946 A:middle
as possible.

00:44:09.366 --> 00:44:10.356 A:middle
So that may be simpler.

00:44:11.456 --> 00:44:12.936 A:middle
We are now only scheduling that

00:44:12.996 --> 00:44:14.596 A:middle
work post-launch, and we cache

00:44:14.596 --> 00:44:16.216 A:middle
to process information for

00:44:16.216 --> 00:44:18.756 A:middle
raising later.

00:44:20.686 --> 00:44:21.716 A:middle
Now, if we would have had the

00:44:21.716 --> 00:44:22.936 A:middle
requirement of displaying this

00:44:22.936 --> 00:44:24.606 A:middle
information, one approach could

00:44:24.606 --> 00:44:25.786 A:middle
have been to leverage the

00:44:25.786 --> 00:44:27.176 A:middle
register background at refresh

00:44:27.176 --> 00:44:29.506 A:middle
API from UA kit, that will

00:44:29.506 --> 00:44:31.036 A:middle
proactively clear your app so

00:44:31.086 --> 00:44:32.376 A:middle
that you can start preparing

00:44:32.376 --> 00:44:33.856 A:middle
some content when the user is

00:44:33.856 --> 00:44:35.446 A:middle
going to launch your app.

00:44:37.156 --> 00:44:38.836 A:middle
So now, that part has gone from

00:44:38.836 --> 00:44:40.726 A:middle
launch, and that saves us 400

00:44:40.726 --> 00:44:42.066 A:middle
milliseconds of CPU time.

00:44:43.486 --> 00:44:45.276 A:middle
If we look at the updated

00:44:45.276 --> 00:44:47.046 A:middle
breakdown here, we can see that

00:44:47.046 --> 00:44:48.866 A:middle
we now have only 450

00:44:48.866 --> 00:44:50.216 A:middle
milliseconds worth of work.

00:44:50.896 --> 00:44:53.776 A:middle
We are now fitting into that 500

00:44:53.836 --> 00:44:55.866 A:middle
millisecond time window, and

00:44:55.866 --> 00:44:58.006 A:middle
regardless of how things can be

00:44:58.006 --> 00:44:59.486 A:middle
represented concurrently here,

00:44:59.486 --> 00:45:00.816 A:middle
the most important part of that


00:44:59.486 --> 00:45:00.816 A:middle
the most important part of that

00:45:01.246 --> 00:45:02.626 A:middle
is to really make sure that you

00:45:02.626 --> 00:45:03.596 A:middle
think about the cost of

00:45:03.636 --> 00:45:04.656 A:middle
preparing your content.

00:45:05.296 --> 00:45:07.466 A:middle
And what I mean by think is

00:45:07.466 --> 00:45:09.086 A:middle
really measure it.

00:45:10.606 --> 00:45:12.806 A:middle
Now, you should strive for doing

00:45:12.806 --> 00:45:13.746 A:middle
work in constant time,

00:45:13.746 --> 00:45:14.926 A:middle
regardless of the total amount

00:45:14.926 --> 00:45:15.896 A:middle
of data you are loading.

00:45:16.676 --> 00:45:17.796 A:middle
In our case, really have

00:45:17.796 --> 00:45:19.526 A:middle
unbonded data assets, and we

00:45:19.746 --> 00:45:21.976 A:middle
need to stay constant.

00:45:24.756 --> 00:45:25.846 A:middle
Now that we have launched the

00:45:25.846 --> 00:45:27.746 A:middle
app, we need to start using it.

00:45:27.746 --> 00:45:28.866 A:middle
And let's see how we did

00:45:29.096 --> 00:45:30.256 A:middle
collections and [inaudible] for

00:45:30.256 --> 00:45:31.146 A:middle
good [inaudible] performance.

00:45:31.226 --> 00:45:34.416 A:middle
So as I mentioned earlier, our

00:45:34.416 --> 00:45:37.236 A:middle
users can seamlessly transition

00:45:37.236 --> 00:45:39.136 A:middle
with animation from the Moments,

00:45:39.436 --> 00:45:40.966 A:middle
through the collections, to the

00:45:40.966 --> 00:45:41.496 A:middle
years view.

00:45:44.316 --> 00:45:46.206 A:middle
And this is a complex hierarchy.

00:45:46.886 --> 00:45:48.306 A:middle
We have thousands of pictures to

00:45:48.306 --> 00:45:48.746 A:middle
display.

00:45:49.606 --> 00:45:51.116 A:middle
We need to support live updates,

00:45:51.686 --> 00:45:53.436 A:middle
we need to also support

00:45:53.436 --> 00:45:55.186 A:middle
animation between these layers,

00:45:55.816 --> 00:45:57.276 A:middle
and we also have some gestures.


00:46:00.436 --> 00:46:01.886 A:middle
Now, we also have some goals

00:46:01.886 --> 00:46:02.076 A:middle
here.

00:46:02.956 --> 00:46:04.096 A:middle
For the experience we want to

00:46:04.096 --> 00:46:05.356 A:middle
provide to our users.

00:46:06.426 --> 00:46:07.726 A:middle
The first one is the same as

00:46:07.726 --> 00:46:08.706 A:middle
before, we don't want to have

00:46:08.706 --> 00:46:09.436 A:middle
any spinner.

00:46:09.436 --> 00:46:10.156 A:middle
We don't want to have

00:46:10.256 --> 00:46:12.586 A:middle
placeholders, but we also want

00:46:12.586 --> 00:46:13.806 A:middle
to have smooth animations.

00:46:13.996 --> 00:46:15.576 A:middle
And by smooth animations, I mean

00:46:15.846 --> 00:46:19.396 A:middle
60 or 120 frames per second,

00:46:19.446 --> 00:46:20.586 A:middle
depending on the screen you're

00:46:20.586 --> 00:46:21.686 A:middle
running on.

00:46:23.266 --> 00:46:24.416 A:middle
Now, remember the principles

00:46:24.416 --> 00:46:25.356 A:middle
that we've seen before.

00:46:25.876 --> 00:46:26.966 A:middle
Well, they are all applicable

00:46:26.966 --> 00:46:27.236 A:middle
here.

00:46:27.586 --> 00:46:28.926 A:middle
We want to be lazy and defer the

00:46:28.926 --> 00:46:30.036 A:middle
work we donate up front.

00:46:30.786 --> 00:46:31.876 A:middle
We want to be proactive, and

00:46:31.876 --> 00:46:34.316 A:middle
catch regressions quickly, but

00:46:34.316 --> 00:46:35.956 A:middle
we also want to be constant in

00:46:35.956 --> 00:46:37.476 A:middle
our layout passes, and

00:46:37.476 --> 00:46:39.096 A:middle
regardless of a lot of data that

00:46:39.166 --> 00:46:39.686 A:middle
we are loading.

00:46:41.566 --> 00:46:42.886 A:middle
Now, this time, we also want to

00:46:42.886 --> 00:46:44.396 A:middle
be timely, and we want to

00:46:44.396 --> 00:46:45.526 A:middle
remember the rendering loop

00:46:45.526 --> 00:46:46.046 A:middle
cycle.

00:46:47.076 --> 00:46:48.426 A:middle
And what I mean by that is that

00:46:48.426 --> 00:46:49.676 A:middle
I want you to remember that we

00:46:49.676 --> 00:46:52.096 A:middle
only have 8 or 16 milliseconds

00:46:52.096 --> 00:46:53.426 A:middle
to render that frame, so we need

00:46:53.426 --> 00:46:54.206 A:middle
to make sure that we are not

00:46:54.256 --> 00:46:55.876 A:middle
going over that time, otherwise

00:46:55.916 --> 00:46:57.156 A:middle
we would start dropping frames.

00:46:59.356 --> 00:47:01.486 A:middle
Now, let's take a step back, and


00:46:59.356 --> 00:47:01.486 A:middle
Now, let's take a step back, and

00:47:01.486 --> 00:47:02.636 A:middle
look at what we are trying to

00:47:02.636 --> 00:47:03.176 A:middle
achieve here.

00:47:03.866 --> 00:47:05.076 A:middle
We wanted to have this portable

00:47:05.076 --> 00:47:06.896 A:middle
view, with sections and mini

00:47:06.896 --> 00:47:07.466 A:middle
cells in it.

00:47:09.846 --> 00:47:11.226 A:middle
And that is basically what your

00:47:11.226 --> 00:47:12.836 A:middle
Collection view is providing,

00:47:12.836 --> 00:47:13.076 A:middle
right?

00:47:13.636 --> 00:47:15.036 A:middle
Except that in this extreme

00:47:15.036 --> 00:47:16.246 A:middle
case, we are restricting the

00:47:16.246 --> 00:47:17.506 A:middle
limit of what we could achieve

00:47:17.506 --> 00:47:18.576 A:middle
with a basic approach.

00:47:18.746 --> 00:47:20.546 A:middle
And that resulted in too many

00:47:20.546 --> 00:47:21.616 A:middle
views, too many layers.

00:47:23.796 --> 00:47:26.256 A:middle
But also in an increased layered

00:47:26.256 --> 00:47:28.396 A:middle
complexity, and that also had an

00:47:28.396 --> 00:47:30.086 A:middle
increased memory cost.

00:47:31.706 --> 00:47:33.086 A:middle
So we needed to innovate here,

00:47:33.846 --> 00:47:35.126 A:middle
and we did that by restricting

00:47:35.126 --> 00:47:36.436 A:middle
the number of views drastically

00:47:36.436 --> 00:47:37.826 A:middle
while still using a collection

00:47:37.826 --> 00:47:37.966 A:middle
view.

00:47:40.176 --> 00:47:42.066 A:middle
We used a technique more

00:47:42.066 --> 00:47:43.466 A:middle
commonly used in video games,

00:47:43.466 --> 00:47:44.606 A:middle
that is called atlasing.

00:47:45.146 --> 00:47:47.106 A:middle
And it basically consists of

00:47:47.106 --> 00:47:48.766 A:middle
combining a set of images into a

00:47:48.766 --> 00:47:49.406 A:middle
single one.

00:47:50.536 --> 00:47:52.186 A:middle
We do that efficiently by using

00:47:52.186 --> 00:47:53.806 A:middle
only very small thumbnails

00:47:53.806 --> 00:47:56.736 A:middle
first, then we stamp all the raw

00:47:56.736 --> 00:47:58.856 A:middle
image data on the canvas we are

00:47:58.856 --> 00:47:59.716 A:middle
using as a strip.


00:48:01.156 --> 00:48:03.336 A:middle
Now, we use image raw data so

00:48:03.336 --> 00:48:04.866 A:middle
that we can avoid decoding each

00:48:04.866 --> 00:48:07.766 A:middle
thumbnail as we send.

00:48:08.376 --> 00:48:09.576 A:middle
So basically we are displaying a

00:48:09.576 --> 00:48:10.726 A:middle
random strip of images.

00:48:12.406 --> 00:48:14.286 A:middle
Now, we generate and cache them

00:48:14.286 --> 00:48:15.566 A:middle
on the fly so that we can be

00:48:15.566 --> 00:48:16.206 A:middle
more flexible.

00:48:18.436 --> 00:48:20.086 A:middle
And as we render multiple images

00:48:20.086 --> 00:48:22.026 A:middle
into a single one, we are

00:48:22.026 --> 00:48:23.316 A:middle
registering the number of cells,

00:48:23.316 --> 00:48:24.716 A:middle
layers, objects drastically,

00:48:24.716 --> 00:48:26.006 A:middle
which simplifies the layout and

00:48:26.006 --> 00:48:29.066 A:middle
the time spent building it.

00:48:29.686 --> 00:48:31.266 A:middle
Now, the separate works well,

00:48:31.266 --> 00:48:32.356 A:middle
but it has trade offs to

00:48:32.356 --> 00:48:34.386 A:middle
consider as well, and this is

00:48:34.386 --> 00:48:34.966 A:middle
one of them.

00:48:36.806 --> 00:48:38.606 A:middle
So if someone tries to long

00:48:38.606 --> 00:48:40.996 A:middle
press or force search an item

00:48:40.996 --> 00:48:42.866 A:middle
here, we will need to figure its

00:48:42.916 --> 00:48:44.536 A:middle
position so that we can achieve

00:48:44.536 --> 00:48:45.426 A:middle
the preview correctly.

00:48:45.996 --> 00:48:48.136 A:middle
And as we display a single

00:48:48.136 --> 00:48:50.776 A:middle
image, we need to maintain the

00:48:50.776 --> 00:48:53.156 A:middle
mapping of each individual

00:48:53.156 --> 00:48:54.736 A:middle
image, and its render strip.

00:48:56.086 --> 00:48:57.226 A:middle
Now, you might be thinking, why

00:48:57.226 --> 00:48:58.216 A:middle
are we generating them on the

00:48:58.216 --> 00:48:58.536 A:middle
fly?


00:49:00.016 --> 00:49:01.736 A:middle
Well, we need to support live

00:49:01.736 --> 00:49:03.626 A:middle
updates, that's the reason.

00:49:04.416 --> 00:49:05.526 A:middle
We need also to support

00:49:05.526 --> 00:49:06.536 A:middle
different view sizes.

00:49:07.426 --> 00:49:08.656 A:middle
For example, we have landscape

00:49:08.656 --> 00:49:09.016 A:middle
here.

00:49:09.516 --> 00:49:11.476 A:middle
But we also have portraits.

00:49:12.976 --> 00:49:16.276 A:middle
And also we can do that because

00:49:16.276 --> 00:49:17.096 A:middle
we can [inaudible] because our

00:49:17.096 --> 00:49:18.786 A:middle
user's labor typically grows

00:49:18.786 --> 00:49:20.606 A:middle
organically over a long period

00:49:20.606 --> 00:49:22.766 A:middle
of time, and the cases where we

00:49:22.766 --> 00:49:24.076 A:middle
might need to generate thousands

00:49:24.076 --> 00:49:25.016 A:middle
of them are pretty rare.

00:49:27.716 --> 00:49:29.086 A:middle
Now, you may be wondering also

00:49:29.086 --> 00:49:30.236 A:middle
why are we not generating the

00:49:30.236 --> 00:49:31.016 A:middle
whole section then?

00:49:32.616 --> 00:49:33.776 A:middle
Well the answer is that our

00:49:33.776 --> 00:49:35.306 A:middle
design record is to do this cool

00:49:35.306 --> 00:49:36.966 A:middle
animation, where you can see

00:49:36.966 --> 00:49:37.926 A:middle
that the collections are

00:49:37.926 --> 00:49:39.036 A:middle
expanding into their own

00:49:39.036 --> 00:49:40.436 A:middle
sections or collapsing into

00:49:40.436 --> 00:49:42.196 A:middle
group ones, and the other way

00:49:42.846 --> 00:49:42.986 A:middle
around.

00:49:45.616 --> 00:49:47.206 A:middle
So if there is one thing that

00:49:47.206 --> 00:49:48.376 A:middle
you should also remember from

00:49:48.376 --> 00:49:49.776 A:middle
that second part is you should

00:49:49.776 --> 00:49:50.916 A:middle
really think about the layout

00:49:50.916 --> 00:49:53.036 A:middle
course of your hierarchy and

00:49:53.036 --> 00:49:54.506 A:middle
measure it.

00:49:56.356 --> 00:49:58.326 A:middle
Lastly, you should always think

00:49:58.326 --> 00:49:59.106 A:middle
about performance.

00:49:59.566 --> 00:50:01.066 A:middle
At Photos, we care deeply about


00:49:59.566 --> 00:50:01.066 A:middle
At Photos, we care deeply about

00:50:01.066 --> 00:50:02.266 A:middle
it, and this is really part of

00:50:02.266 --> 00:50:02.916 A:middle
our daily job.

00:50:04.906 --> 00:50:06.796 A:middle
For more information, you can

00:50:06.796 --> 00:50:09.026 A:middle
come and see us in these three

00:50:09.026 --> 00:50:10.146 A:middle
labs that are mentioned here,

00:50:10.246 --> 00:50:12.486 A:middle
and I hope that you have a great

00:50:12.486 --> 00:50:13.026 A:middle
conference.

00:50:13.526 --> 00:50:13.806 A:middle
Thank you.

00:50:14.516 --> 00:50:20.450 A:middle
[ Applause ]
