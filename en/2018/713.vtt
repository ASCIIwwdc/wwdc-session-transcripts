WEBVTT

00:00:07.016 --> 00:00:15.500 A:middle
[ Music ]

00:00:20.516 --> 00:00:25.636 A:middle
[ Applause ]

00:00:26.136 --> 00:00:26.966 A:middle
&gt;&gt; Hello and good afternoon

00:00:26.966 --> 00:00:27.406 A:middle
everyone.

00:00:27.806 --> 00:00:29.096 A:middle
Welcome to our session on

00:00:29.096 --> 00:00:30.336 A:middle
natural language processing.

00:00:30.486 --> 00:00:32.226 A:middle
I'm delighted to see so many of

00:00:32.226 --> 00:00:33.836 A:middle
you here today, and I'm really

00:00:33.836 --> 00:00:35.356 A:middle
excited to tell you about some

00:00:35.356 --> 00:00:36.896 A:middle
of the new and cool features

00:00:37.126 --> 00:00:38.206 A:middle
we've been working in the NLP

00:00:38.206 --> 00:00:39.526 A:middle
space for you.

00:00:40.206 --> 00:00:42.066 A:middle
I'm Vivek, and I'll be jointly

00:00:42.066 --> 00:00:43.526 A:middle
presenting this session with my

00:00:43.526 --> 00:00:44.676 A:middle
colleague, Doug Davidson.

00:00:45.176 --> 00:00:47.756 A:middle
Let's get started.

00:00:47.756 --> 00:00:49.646 A:middle
Last year, we placed your app

00:00:49.646 --> 00:00:52.166 A:middle
center stage and told you how

00:00:52.166 --> 00:00:53.336 A:middle
you could harness the power of

00:00:53.416 --> 00:00:56.426 A:middle
NLP to make your apps smarter

00:00:56.426 --> 00:00:57.186 A:middle
and more intelligent.

00:00:57.586 --> 00:00:59.926 A:middle
We did this by walking you


00:01:00.236 --> 00:01:02.206 A:middle
through the NLP APIs available

00:01:02.506 --> 00:01:03.736 A:middle
in NSLinguisticTagger.

00:01:04.976 --> 00:01:06.706 A:middle
NSLinguisticTagger, as most of

00:01:06.706 --> 00:01:07.906 A:middle
you are familiar with or have

00:01:07.906 --> 00:01:10.426 A:middle
used at some point, is a class

00:01:10.426 --> 00:01:12.266 A:middle
and foundation that provides the

00:01:12.336 --> 00:01:13.636 A:middle
fundamental building blocks for

00:01:13.676 --> 00:01:13.916 A:middle
NLP.

00:01:14.676 --> 00:01:15.646 A:middle
Everything from language

00:01:15.646 --> 00:01:17.376 A:middle
identification to organization,

00:01:17.376 --> 00:01:19.306 A:middle
part of speech tagging, and so

00:01:19.906 --> 00:01:19.973 A:middle
on.

00:01:20.406 --> 00:01:21.426 A:middle
We achieve this in

00:01:21.476 --> 00:01:23.546 A:middle
NSLinguisticTagger by seamlessly

00:01:23.546 --> 00:01:25.346 A:middle
blending linguistics and machine

00:01:25.346 --> 00:01:26.386 A:middle
learning behind the scenes.

00:01:26.736 --> 00:01:28.996 A:middle
So you, as a developer, can just

00:01:28.996 --> 00:01:30.856 A:middle
focus on using these APIs and

00:01:30.856 --> 00:01:33.206 A:middle
focus on your task.

00:01:33.206 --> 00:01:34.066 A:middle
All that's great.

00:01:34.586 --> 00:01:36.016 A:middle
So what's new in NLP for this

00:01:36.016 --> 00:01:36.216 A:middle
year?

00:01:36.916 --> 00:01:38.346 A:middle
Well, we are delighted to

00:01:38.346 --> 00:01:39.356 A:middle
announce that we have a

00:01:39.356 --> 00:01:40.816 A:middle
brand-new framework for NLP

00:01:40.816 --> 00:01:42.446 A:middle
called Natural Language.

00:01:43.216 --> 00:01:44.736 A:middle
Natural Language is now going to

00:01:44.736 --> 00:01:47.116 A:middle
be a one-stop shop for doing all

00:01:47.116 --> 00:01:49.536 A:middle
things NLP on device across all

00:01:49.536 --> 00:01:50.486 A:middle
Apple platforms.

00:01:51.176 --> 00:01:52.856 A:middle
Natural Language has some really

00:01:52.856 --> 00:01:54.496 A:middle
cool features, and let me talk

00:01:54.496 --> 00:01:55.396 A:middle
about each of those.

00:01:55.846 --> 00:01:58.846 A:middle
First, it has a completely

00:01:58.846 --> 00:02:01.476 A:middle
redesigned API surface, so it


00:01:58.846 --> 00:02:01.476 A:middle
redesigned API surface, so it

00:02:01.476 --> 00:02:02.936 A:middle
supports all the functionalities

00:02:02.936 --> 00:02:04.496 A:middle
that NSLinguisticTagger used to

00:02:04.496 --> 00:02:07.206 A:middle
and still does but with really,

00:02:07.296 --> 00:02:08.376 A:middle
really Swift APIs.

00:02:09.326 --> 00:02:10.446 A:middle
But that's not it.

00:02:11.026 --> 00:02:12.746 A:middle
We now have support for custom

00:02:12.866 --> 00:02:13.716 A:middle
NLP models.

00:02:14.056 --> 00:02:15.136 A:middle
These are models that you can

00:02:15.136 --> 00:02:17.226 A:middle
create using Create ML and

00:02:17.226 --> 00:02:18.856 A:middle
deploy the model either using

00:02:18.856 --> 00:02:20.576 A:middle
Code ML API or through Natural

00:02:20.576 --> 00:02:20.976 A:middle
Language.

00:02:22.396 --> 00:02:23.716 A:middle
Everything that we support in

00:02:23.716 --> 00:02:24.886 A:middle
Natural Language, all of the

00:02:24.886 --> 00:02:26.956 A:middle
machine learning NLP is high

00:02:27.026 --> 00:02:27.566 A:middle
performed.

00:02:27.776 --> 00:02:29.076 A:middle
It is optimized for Apple

00:02:29.076 --> 00:02:30.586 A:middle
hardware and also for model

00:02:30.586 --> 00:02:30.946 A:middle
size.

00:02:32.366 --> 00:02:35.106 A:middle
And finally, everything is

00:02:35.106 --> 00:02:35.966 A:middle
completely private.

00:02:36.186 --> 00:02:37.566 A:middle
All of the machine learning in

00:02:37.566 --> 00:02:39.326 A:middle
NLP that is powered in Natural

00:02:39.326 --> 00:02:41.256 A:middle
Language is done on device to

00:02:41.256 --> 00:02:42.486 A:middle
protect user's privacy.

00:02:42.906 --> 00:02:44.626 A:middle
This is the very same technology

00:02:44.626 --> 00:02:46.776 A:middle
that we use at Apple to bring

00:02:46.776 --> 00:02:48.916 A:middle
NLP on device for our own

00:02:48.916 --> 00:02:49.446 A:middle
features.

00:02:50.306 --> 00:02:51.716 A:middle
So let me talk about each of

00:02:51.716 --> 00:02:53.336 A:middle
these features of Natural

00:02:53.336 --> 00:02:53.686 A:middle
Language.

00:02:54.026 --> 00:02:55.756 A:middle
Let's start with the Swift APIs.

00:02:56.286 --> 00:02:59.996 A:middle
As I mentioned, Natural Language

00:02:59.996 --> 00:03:01.136 A:middle
supports all the fundamental


00:02:59.996 --> 00:03:01.136 A:middle
supports all the fundamental

00:03:01.136 --> 00:03:01.966 A:middle
building blocks that

00:03:01.966 --> 00:03:03.866 A:middle
NSLinguisticTagger does but with

00:03:04.176 --> 00:03:05.976 A:middle
significantly better and easier

00:03:05.976 --> 00:03:07.516 A:middle
to use APIs.

00:03:08.056 --> 00:03:09.726 A:middle
In order to provide some of

00:03:09.726 --> 00:03:11.336 A:middle
these APIs and go over them, I'm

00:03:11.336 --> 00:03:12.346 A:middle
going to illustrate them with

00:03:12.346 --> 00:03:13.506 A:middle
hypothetical apps.

00:03:14.066 --> 00:03:16.396 A:middle
So the first app that we have

00:03:16.396 --> 00:03:18.356 A:middle
here is an app that you wrote,

00:03:19.656 --> 00:03:20.976 A:middle
and as part of the app, you

00:03:20.976 --> 00:03:22.656 A:middle
enable a social messaging or

00:03:22.656 --> 00:03:23.936 A:middle
peer-to-peer messaging feature.

00:03:24.426 --> 00:03:26.586 A:middle
And an add-on feature in this

00:03:26.586 --> 00:03:28.586 A:middle
app that you've created is the

00:03:28.586 --> 00:03:30.446 A:middle
ability to show the right

00:03:30.446 --> 00:03:30.966 A:middle
stickers.

00:03:31.526 --> 00:03:33.046 A:middle
So based on the content of the

00:03:33.136 --> 00:03:34.936 A:middle
message, which in this case is

00:03:34.936 --> 00:03:36.116 A:middle
"It's getting late, I'm tired,

00:03:36.456 --> 00:03:37.216 A:middle
we'll pick it up tomorrow

00:03:37.216 --> 00:03:38.076 A:middle
morning, good night."

00:03:38.406 --> 00:03:39.866 A:middle
Your app shows the appropriate

00:03:39.866 --> 00:03:40.116 A:middle
sticker.

00:03:40.116 --> 00:03:41.706 A:middle
You parsed this text, and you

00:03:41.706 --> 00:03:42.596 A:middle
bring up the sticker.

00:03:42.796 --> 00:03:44.166 A:middle
The user can attach it and send

00:03:44.166 --> 00:03:44.976 A:middle
it as a response.

00:03:45.476 --> 00:03:46.286 A:middle
So all of this is great.

00:03:46.286 --> 00:03:47.376 A:middle
This app has been doing really

00:03:47.376 --> 00:03:47.626 A:middle
well.

00:03:47.626 --> 00:03:48.426 A:middle
You've been getting rave

00:03:48.426 --> 00:03:48.936 A:middle
reviews.

00:03:49.926 --> 00:03:51.436 A:middle
But you also get feedback that

00:03:51.436 --> 00:03:52.776 A:middle
your app is not multilingual.

00:03:53.186 --> 00:03:55.266 A:middle
So it so happens that users are

00:03:55.416 --> 00:03:56.426 A:middle
bilingual these days.

00:03:56.426 --> 00:03:57.546 A:middle
They tend to communicate in

00:03:57.546 --> 00:03:59.186 A:middle
several different languages, and

00:03:59.186 --> 00:04:00.226 A:middle
your app, when it gets the


00:03:59.186 --> 00:04:00.226 A:middle
your app, when it gets the

00:04:00.226 --> 00:04:01.886 A:middle
message in Chinese, simply

00:04:01.886 --> 00:04:03.886 A:middle
doesn't know what to do with it.

00:04:04.086 --> 00:04:05.246 A:middle
So how can we use natural

00:04:05.246 --> 00:04:06.346 A:middle
language to overcome this

00:04:06.346 --> 00:04:06.756 A:middle
problem?

00:04:06.926 --> 00:04:09.816 A:middle
Well, we can do this with two

00:04:09.816 --> 00:04:11.266 A:middle
simple calls to two different

00:04:11.266 --> 00:04:11.636 A:middle
APIs.

00:04:12.216 --> 00:04:13.256 A:middle
The first is language

00:04:13.256 --> 00:04:13.986 A:middle
identification.

00:04:14.326 --> 00:04:16.106 A:middle
With the new Natural Language

00:04:16.106 --> 00:04:17.396 A:middle
framework, you start off by

00:04:17.456 --> 00:04:18.696 A:middle
importing Natural Language.

00:04:19.836 --> 00:04:21.226 A:middle
You create an instance of

00:04:21.226 --> 00:04:23.146 A:middle
NLLanguageRecognizer class.

00:04:24.006 --> 00:04:25.456 A:middle
You attach the string that you

00:04:25.456 --> 00:04:27.476 A:middle
would like to process, and you

00:04:27.476 --> 00:04:28.676 A:middle
simply call the dominant

00:04:28.676 --> 00:04:29.436 A:middle
language API.

00:04:30.036 --> 00:04:32.256 A:middle
Now this will return the single

00:04:32.256 --> 00:04:34.596 A:middle
best hypothesis in terms of

00:04:34.596 --> 00:04:35.746 A:middle
language for the string.

00:04:36.806 --> 00:04:38.036 A:middle
So the output here is

00:04:38.036 --> 00:04:39.446 A:middle
essentially simplified Chinese.

00:04:40.466 --> 00:04:41.856 A:middle
Now in Natural Language, we also

00:04:41.856 --> 00:04:42.906 A:middle
support a new API.

00:04:43.496 --> 00:04:44.766 A:middle
There are instances where you

00:04:44.766 --> 00:04:46.046 A:middle
would like to know the top-end

00:04:46.046 --> 00:04:47.506 A:middle
hypothesis for a particular

00:04:47.506 --> 00:04:47.876 A:middle
string.

00:04:48.146 --> 00:04:49.996 A:middle
So you'd like to know what are

00:04:49.996 --> 00:04:51.396 A:middle
the top languages along with

00:04:51.396 --> 00:04:52.796 A:middle
their associated probabilities.

00:04:52.836 --> 00:04:54.776 A:middle
So you can envision using this

00:04:54.776 --> 00:04:55.476 A:middle
in several different

00:04:55.476 --> 00:04:56.906 A:middle
applications where there's a lot

00:04:56.906 --> 00:04:58.636 A:middle
of multilinguality, and you want

00:04:58.636 --> 00:05:00.066 A:middle
that leeway in terms of what


00:04:58.636 --> 00:05:00.066 A:middle
that leeway in terms of what

00:05:00.066 --> 00:05:01.366 A:middle
could be the top hypothesis.

00:05:02.126 --> 00:05:03.636 A:middle
So you can do this with a new

00:05:03.636 --> 00:05:05.856 A:middle
API called Language Hypotheses.

00:05:06.176 --> 00:05:07.336 A:middle
You can specify the maximum

00:05:07.336 --> 00:05:08.306 A:middle
number of languages that you

00:05:08.306 --> 00:05:09.866 A:middle
want, and what you get back is

00:05:09.866 --> 00:05:11.126 A:middle
an object with the top-end

00:05:11.126 --> 00:05:12.706 A:middle
languages and their associated

00:05:12.706 --> 00:05:13.446 A:middle
probabilities.

00:05:14.596 --> 00:05:15.836 A:middle
Now in order to tokenize this

00:05:15.836 --> 00:05:17.816 A:middle
Chinese text, you can again see

00:05:17.816 --> 00:05:19.186 A:middle
the pattern is very similar.

00:05:20.066 --> 00:05:21.196 A:middle
You again import Natural

00:05:21.196 --> 00:05:21.646 A:middle
Language.

00:05:22.316 --> 00:05:23.616 A:middle
You create an instance of the

00:05:23.616 --> 00:05:25.856 A:middle
NLTokenizer, and in this

00:05:25.856 --> 00:05:27.576 A:middle
particular instance, you specify

00:05:27.576 --> 00:05:28.856 A:middle
the unit to be word because you

00:05:28.856 --> 00:05:30.126 A:middle
want to tokenize the string into

00:05:30.126 --> 00:05:30.666 A:middle
words.

00:05:31.176 --> 00:05:34.776 A:middle
You attach the string, and you

00:05:34.776 --> 00:05:36.486 A:middle
simply call the tokens method on

00:05:36.486 --> 00:05:38.006 A:middle
the string, on the object.

00:05:39.006 --> 00:05:40.446 A:middle
And what you get is an array of

00:05:40.516 --> 00:05:41.096 A:middle
tokens here.

00:05:41.526 --> 00:05:43.296 A:middle
Now with this array of tokens,

00:05:43.546 --> 00:05:44.896 A:middle
you can look up the particular

00:05:45.136 --> 00:05:47.756 A:middle
token here is goodnight, and lo

00:05:47.756 --> 00:05:48.676 A:middle
and behold, you have

00:05:48.676 --> 00:05:50.256 A:middle
multilingual support in your

00:05:50.716 --> 00:05:50.783 A:middle
app.

00:05:51.026 --> 00:05:52.746 A:middle
So your app can now support

00:05:52.746 --> 00:05:54.626 A:middle
Chinese with simple calls to

00:05:54.626 --> 00:05:56.446 A:middle
language identification and

00:05:56.636 --> 00:05:58.966 A:middle
tokenization APIs.

00:05:59.026 --> 00:06:00.456 A:middle
Now let's look at a different


00:05:59.026 --> 00:06:00.456 A:middle
Now let's look at a different

00:06:00.456 --> 00:06:01.046 A:middle
sort of an API.

00:06:01.046 --> 00:06:02.206 A:middle
I mean language identification

00:06:02.206 --> 00:06:03.586 A:middle
and tokenization are good, but

00:06:03.586 --> 00:06:05.406 A:middle
we would also like to use auto

00:06:05.406 --> 00:06:06.636 A:middle
speech tagging, named entity

00:06:06.636 --> 00:06:07.746 A:middle
recognition, and so on.

00:06:08.066 --> 00:06:09.616 A:middle
So let me illustrate how to use

00:06:09.616 --> 00:06:10.936 A:middle
named entity recognition API

00:06:11.356 --> 00:06:14.106 A:middle
again with the hypothetical app.

00:06:14.346 --> 00:06:15.276 A:middle
So here's an app.

00:06:15.506 --> 00:06:17.026 A:middle
It's a news recommendation app.

00:06:17.646 --> 00:06:18.906 A:middle
So as part of this app, your

00:06:18.906 --> 00:06:20.576 A:middle
user has been going and reading

00:06:20.576 --> 00:06:21.906 A:middle
a lot of things about the royal

00:06:21.906 --> 00:06:23.206 A:middle
wedding, so a really curious

00:06:23.206 --> 00:06:23.456 A:middle
user.

00:06:23.456 --> 00:06:24.326 A:middle
They want to find everything

00:06:24.326 --> 00:06:25.076 A:middle
about the royal wedding.

00:06:25.466 --> 00:06:26.806 A:middle
So they've perused a lot of

00:06:26.806 --> 00:06:28.886 A:middle
pages in your app, and then they

00:06:28.886 --> 00:06:30.556 A:middle
go on to the search bar, and

00:06:30.556 --> 00:06:31.556 A:middle
they type Harry.

00:06:32.276 --> 00:06:34.406 A:middle
And what they see is completely

00:06:34.686 --> 00:06:35.756 A:middle
things that are not pertinent to

00:06:35.756 --> 00:06:37.026 A:middle
what they've been looking for.

00:06:37.286 --> 00:06:38.686 A:middle
You get Harry Potter and so on

00:06:38.686 --> 00:06:39.246 A:middle
and so forth.

00:06:39.616 --> 00:06:42.376 A:middle
What you'd like to see is Prince

00:06:42.376 --> 00:06:44.036 A:middle
Harry, something related to the

00:06:44.116 --> 00:06:44.716 A:middle
royal wedding.

00:06:45.296 --> 00:06:46.656 A:middle
So now you can overcome this

00:06:46.656 --> 00:06:48.436 A:middle
issue in your app by using the

00:06:48.436 --> 00:06:50.056 A:middle
name entity recognition API.

00:06:51.376 --> 00:06:52.776 A:middle
Again, as I mentioned, the

00:06:52.776 --> 00:06:54.346 A:middle
syntax here is very familiar.

00:06:54.586 --> 00:06:56.006 A:middle
Those of you who have been used

00:06:56.006 --> 00:06:57.506 A:middle
to using NSLinguisticTagger,

00:06:57.776 --> 00:06:58.836 A:middle
they should look familiar and

00:06:58.836 --> 00:07:00.276 A:middle
feel familiar, but it's much


00:06:58.836 --> 00:07:00.276 A:middle
feel familiar, but it's much

00:07:00.276 --> 00:07:01.656 A:middle
easier to remember and to use.

00:07:02.126 --> 00:07:03.986 A:middle
You import Natural Language.

00:07:04.866 --> 00:07:06.246 A:middle
You now create an instance of

00:07:06.306 --> 00:07:08.516 A:middle
NLTagger, and you specify the

00:07:08.516 --> 00:07:09.996 A:middle
scheme type to be name type.

00:07:10.926 --> 00:07:11.896 A:middle
If you want part of speech

00:07:11.896 --> 00:07:13.076 A:middle
tagging, then you would specify

00:07:13.076 --> 00:07:14.426 A:middle
the scheme type to be lexical

00:07:14.426 --> 00:07:14.906 A:middle
class.

00:07:15.656 --> 00:07:17.556 A:middle
You again specify the string

00:07:17.556 --> 00:07:18.546 A:middle
that you want to process.

00:07:19.466 --> 00:07:21.336 A:middle
In this particular instance, you

00:07:21.336 --> 00:07:23.446 A:middle
specify the language, so you set

00:07:23.446 --> 00:07:24.636 A:middle
the language to be English.

00:07:24.866 --> 00:07:27.016 A:middle
So if you were not familiar or

00:07:27.016 --> 00:07:28.026 A:middle
if you're not sure about what

00:07:28.026 --> 00:07:29.646 A:middle
the language is, Natural

00:07:29.646 --> 00:07:30.956 A:middle
Language will automatically

00:07:30.956 --> 00:07:32.726 A:middle
recognize the language using the

00:07:32.726 --> 00:07:34.076 A:middle
language identification API

00:07:34.076 --> 00:07:34.886 A:middle
under the hood.

00:07:35.116 --> 00:07:37.816 A:middle
And finally, you call the tags

00:07:38.296 --> 00:07:39.936 A:middle
method on this object that you

00:07:39.936 --> 00:07:40.556 A:middle
just created.

00:07:40.836 --> 00:07:42.456 A:middle
You specify the unit to be word

00:07:42.456 --> 00:07:44.026 A:middle
and the scheme to be name type.

00:07:44.536 --> 00:07:46.826 A:middle
And what you get as an output is

00:07:47.166 --> 00:07:49.006 A:middle
the person names here, Prince

00:07:49.006 --> 00:07:50.426 A:middle
Harry and Meghan Markle, and the

00:07:50.426 --> 00:07:51.526 A:middle
location to be Windsor.

00:07:51.776 --> 00:07:53.376 A:middle
Now if the user were to go back

00:07:53.376 --> 00:07:55.246 A:middle
to the search bar, based on the

00:07:55.246 --> 00:07:56.596 A:middle
contextual information of what

00:07:56.596 --> 00:07:58.006 A:middle
the user has been browsing, you

00:07:58.006 --> 00:07:59.326 A:middle
can significantly enhance the

00:07:59.326 --> 00:08:01.386 A:middle
search experience in your app.


00:07:59.326 --> 00:08:01.386 A:middle
search experience in your app.

00:08:03.526 --> 00:08:04.976 A:middle
So there's a lot more

00:08:04.976 --> 00:08:06.256 A:middle
information about how to use

00:08:06.256 --> 00:08:06.666 A:middle
these APIs.

00:08:06.666 --> 00:08:07.906 A:middle
You can go to the developer

00:08:07.906 --> 00:08:09.326 A:middle
documentation and find more

00:08:09.326 --> 00:08:09.936 A:middle
information.

00:08:10.376 --> 00:08:11.926 A:middle
What I'd like to emphasize here

00:08:11.976 --> 00:08:15.106 A:middle
is NSLinguisticTagger is still

00:08:15.106 --> 00:08:17.006 A:middle
supported, but the future of NLP

00:08:17.006 --> 00:08:18.596 A:middle
is in Natural Language.

00:08:18.596 --> 00:08:20.296 A:middle
So we recommend that and

00:08:20.296 --> 00:08:22.026 A:middle
encourage you to move to Natural

00:08:22.026 --> 00:08:23.566 A:middle
Language so that you can get all

00:08:23.566 --> 00:08:24.896 A:middle
the latest functionalities of

00:08:24.946 --> 00:08:26.226 A:middle
NLP in this framework.

00:08:26.996 --> 00:08:29.616 A:middle
Now let's shift gears and look

00:08:29.616 --> 00:08:31.996 A:middle
at a situation where you have an

00:08:31.996 --> 00:08:34.525 A:middle
idea for an app, or you need a

00:08:34.525 --> 00:08:36.376 A:middle
functionality within your app

00:08:36.376 --> 00:08:37.666 A:middle
that Natural Language does not

00:08:37.666 --> 00:08:38.076 A:middle
support.

00:08:38.506 --> 00:08:40.106 A:middle
What do you do?

00:08:40.106 --> 00:08:42.876 A:middle
So you can certainly create

00:08:42.876 --> 00:08:44.936 A:middle
something, which will be great,

00:08:45.306 --> 00:08:46.356 A:middle
but what if we gave you the

00:08:46.356 --> 00:08:48.176 A:middle
tools to make that much easier?

00:08:50.756 --> 00:08:53.376 A:middle
To talk about custom NLP models

00:08:53.376 --> 00:08:54.656 A:middle
and how to build custom NLP

00:08:54.656 --> 00:08:56.766 A:middle
models using Create ML and use

00:08:56.766 --> 00:08:58.706 A:middle
the subsequent models, which are

00:08:58.706 --> 00:09:00.126 A:middle
essentially Code ML models in


00:08:58.706 --> 00:09:00.126 A:middle
essentially Code ML models in

00:09:00.126 --> 00:09:01.496 A:middle
Natural Language, I'm going to

00:09:01.576 --> 00:09:02.816 A:middle
hand it over to Doug Davidson.

00:09:03.516 --> 00:09:09.206 A:middle
[ Applause ]

00:09:09.706 --> 00:09:10.366 A:middle
&gt;&gt; Thanks Vivek.

00:09:11.146 --> 00:09:13.816 A:middle
So I'm really excited about the

00:09:13.816 --> 00:09:15.386 A:middle
new Natural Language framework,

00:09:15.736 --> 00:09:17.226 A:middle
but the part I'm most excited

00:09:17.226 --> 00:09:19.586 A:middle
about is support for portraying

00:09:19.586 --> 00:09:21.226 A:middle
and using custom models.

00:09:21.536 --> 00:09:22.526 A:middle
And why is that?

00:09:23.426 --> 00:09:24.576 A:middle
I'd just like you to think for a

00:09:24.576 --> 00:09:27.636 A:middle
second about your apps, maybe

00:09:27.636 --> 00:09:29.366 A:middle
the apps you've written or the

00:09:29.366 --> 00:09:31.606 A:middle
apps that you want to write, and

00:09:31.606 --> 00:09:32.856 A:middle
think about how they could

00:09:33.336 --> 00:09:35.166 A:middle
improve the user experience if

00:09:35.166 --> 00:09:36.756 A:middle
they just knew a little more

00:09:37.536 --> 00:09:39.116 A:middle
about the text that they deal

00:09:39.116 --> 00:09:39.286 A:middle
with.

00:09:40.356 --> 00:09:42.206 A:middle
And then think for a second

00:09:42.646 --> 00:09:44.756 A:middle
about how you analyze text.

00:09:44.996 --> 00:09:46.756 A:middle
So maybe you look at some

00:09:46.756 --> 00:09:49.446 A:middle
examples of text, and you learn

00:09:49.446 --> 00:09:51.816 A:middle
from them, and then you

00:09:52.266 --> 00:09:53.876 A:middle
understand what's going on, and

00:09:53.876 --> 00:09:54.836 A:middle
then you can look at a piece of

00:09:54.836 --> 00:09:56.346 A:middle
text, and at a glance, you can

00:09:56.346 --> 00:09:57.476 A:middle
figure out something about

00:09:57.476 --> 00:09:58.386 A:middle
what's going on with it.

00:09:59.366 --> 00:10:01.306 A:middle
Well, if that's the case, then


00:09:59.366 --> 00:10:01.306 A:middle
Well, if that's the case, then

00:10:01.356 --> 00:10:02.566 A:middle
there's at least a reasonable

00:10:02.566 --> 00:10:05.746 A:middle
chance that you can train a

00:10:05.966 --> 00:10:08.216 A:middle
machine learning model to do

00:10:08.216 --> 00:10:09.686 A:middle
that sort of analysis in your

00:10:09.686 --> 00:10:11.206 A:middle
app automatically for you,

00:10:11.646 --> 00:10:14.166 A:middle
giving it examples that it can

00:10:14.166 --> 00:10:16.576 A:middle
train and learn from and produce

00:10:16.576 --> 00:10:18.396 A:middle
a model that can do that

00:10:18.396 --> 00:10:19.156 A:middle
analysis.

00:10:19.966 --> 00:10:23.316 A:middle
Now, there are many, many types

00:10:23.346 --> 00:10:24.776 A:middle
of machine learning models for

00:10:24.826 --> 00:10:26.176 A:middle
NLP, and there are many

00:10:26.176 --> 00:10:27.206 A:middle
different ways of training it.

00:10:27.206 --> 00:10:28.606 A:middle
Probably many of you are already

00:10:28.606 --> 00:10:29.546 A:middle
training machine learning

00:10:29.546 --> 00:10:32.516 A:middle
models, but our task here has

00:10:32.516 --> 00:10:35.286 A:middle
been to produce ways to make

00:10:35.286 --> 00:10:36.806 A:middle
this sort of training really,

00:10:36.806 --> 00:10:39.056 A:middle
really easy and to make it

00:10:39.056 --> 00:10:41.036 A:middle
integrate really well with the

00:10:41.036 --> 00:10:42.696 A:middle
Natural Language framework and

00:10:42.696 --> 00:10:43.146 A:middle
APIs.

00:10:43.556 --> 00:10:45.626 A:middle
So with that in mind, we are

00:10:45.626 --> 00:10:47.826 A:middle
supporting two types of models

00:10:48.366 --> 00:10:50.776 A:middle
that we think support a broad

00:10:50.776 --> 00:10:53.016 A:middle
range of functionality and that

00:10:53.016 --> 00:10:55.216 A:middle
work well with our paradigm in

00:10:55.216 --> 00:10:57.386 A:middle
NLTagger of applying labels to

00:10:57.386 --> 00:10:58.476 A:middle
pieces of text.

00:10:58.796 --> 00:11:00.016 A:middle
So the first of model we're


00:10:58.796 --> 00:11:00.016 A:middle
So the first of model we're

00:11:00.016 --> 00:11:02.366 A:middle
supporting is a text classifier.

00:11:02.896 --> 00:11:05.376 A:middle
A text classifier takes a chunk

00:11:05.376 --> 00:11:07.146 A:middle
of text, maybe it's a sentence

00:11:07.146 --> 00:11:09.126 A:middle
or a paragraph or an entire

00:11:09.126 --> 00:11:11.226 A:middle
document, and applies a label to

00:11:11.226 --> 00:11:11.366 A:middle
it.

00:11:11.786 --> 00:11:13.376 A:middle
Examples of this in our existing

00:11:13.376 --> 00:11:15.286 A:middle
APIs are things like language

00:11:15.286 --> 00:11:16.466 A:middle
identification, script

00:11:16.466 --> 00:11:17.216 A:middle
identification.

00:11:18.276 --> 00:11:19.436 A:middle
The second type of model we

00:11:19.436 --> 00:11:21.846 A:middle
support is a word tagger, and a

00:11:21.846 --> 00:11:23.836 A:middle
word tagger takes a sentence

00:11:23.886 --> 00:11:25.856 A:middle
considered as a sequence of

00:11:25.856 --> 00:11:28.196 A:middle
words, and then applies a label

00:11:28.196 --> 00:11:30.386 A:middle
to each word in a sentence in

00:11:30.386 --> 00:11:32.366 A:middle
context, and examples of

00:11:32.366 --> 00:11:34.916 A:middle
existing APIs are things like

00:11:34.916 --> 00:11:36.576 A:middle
speech tagging and named entity

00:11:36.576 --> 00:11:37.116 A:middle
recognition.

00:11:37.636 --> 00:11:39.316 A:middle
But those are sort of general

00:11:39.396 --> 00:11:42.656 A:middle
purpose examples of these kinds

00:11:42.656 --> 00:11:43.336 A:middle
of models.

00:11:44.006 --> 00:11:45.616 A:middle
You can do a lot more with them

00:11:46.026 --> 00:11:47.236 A:middle
if you have a special purpose

00:11:47.236 --> 00:11:48.446 A:middle
model for your specific

00:11:48.446 --> 00:11:49.006 A:middle
application.

00:11:49.006 --> 00:11:50.036 A:middle
Let me give you some

00:11:50.036 --> 00:11:51.366 A:middle
hypothetical examples.

00:11:51.956 --> 00:11:53.576 A:middle
So, for text classification,

00:11:53.946 --> 00:11:55.556 A:middle
suppose you're dealing with user

00:11:55.556 --> 00:11:57.066 A:middle
reviews, and you want to know

00:11:57.066 --> 00:11:59.406 A:middle
automatically whether a given

00:11:59.406 --> 00:12:02.016 A:middle
review is a positive review or a


00:11:59.406 --> 00:12:02.016 A:middle
review is a positive review or a

00:12:02.016 --> 00:12:03.356 A:middle
negative review or somewhere in

00:12:03.356 --> 00:12:03.816 A:middle
between.

00:12:04.296 --> 00:12:05.216 A:middle
Well, this is the sort of thing

00:12:05.216 --> 00:12:06.256 A:middle
you could train a text

00:12:06.286 --> 00:12:07.066 A:middle
classifier to do.

00:12:07.066 --> 00:12:07.746 A:middle
This is sentiment

00:12:07.816 --> 00:12:08.536 A:middle
classification.

00:12:10.516 --> 00:12:12.556 A:middle
Or suppose you have articles or

00:12:12.556 --> 00:12:14.206 A:middle
just article summaries or maybe

00:12:14.206 --> 00:12:15.596 A:middle
even just article headlines, and

00:12:15.596 --> 00:12:16.376 A:middle
you want to determine

00:12:16.376 --> 00:12:18.486 A:middle
automatically what topic they

00:12:18.486 --> 00:12:19.726 A:middle
belong to according to your

00:12:19.726 --> 00:12:21.866 A:middle
favorite topic classification

00:12:21.866 --> 00:12:22.266 A:middle
scheme.

00:12:22.746 --> 00:12:23.836 A:middle
This again is the sort of thing

00:12:23.836 --> 00:12:26.596 A:middle
that you can train a text

00:12:26.596 --> 00:12:28.096 A:middle
classifier to do for you.

00:12:28.656 --> 00:12:31.246 A:middle
Or going a little further,

00:12:31.246 --> 00:12:32.486 A:middle
suppose you're writing an

00:12:32.486 --> 00:12:35.286 A:middle
automated travel agent, and when

00:12:35.286 --> 00:12:36.976 A:middle
you get a request from a client,

00:12:37.246 --> 00:12:38.426 A:middle
the first thing you want to know

00:12:38.426 --> 00:12:40.216 A:middle
probably is what are they asking

00:12:40.216 --> 00:12:40.526 A:middle
about?

00:12:40.796 --> 00:12:42.506 A:middle
Is it hotels or restaurants or

00:12:42.506 --> 00:12:43.746 A:middle
flights or whatever else that

00:12:43.746 --> 00:12:44.266 A:middle
you handle.

00:12:44.886 --> 00:12:46.056 A:middle
This is the sort of thing that

00:12:46.056 --> 00:12:47.576 A:middle
you could train a text

00:12:47.636 --> 00:12:49.316 A:middle
classifier to answer for you.

00:12:50.946 --> 00:12:52.566 A:middle
Going on to word tagging.

00:12:53.106 --> 00:12:56.586 A:middle
So we provide word taggers that

00:12:56.586 --> 00:12:58.166 A:middle
do part of speech tagging for a

00:12:58.166 --> 00:12:59.326 A:middle
number of different languages,

00:12:59.696 --> 00:13:01.646 A:middle
but suppose you happen to need


00:12:59.696 --> 00:13:01.646 A:middle
but suppose you happen to need

00:13:01.646 --> 00:13:03.066 A:middle
to do part of speech tagging for

00:13:03.066 --> 00:13:04.296 A:middle
some language that we don't

00:13:04.296 --> 00:13:05.686 A:middle
happen to support quite yet.

00:13:06.426 --> 00:13:07.956 A:middle
Well, with custom model support,

00:13:07.956 --> 00:13:10.006 A:middle
you could train a word tagger to

00:13:10.006 --> 00:13:10.906 A:middle
do that for you.

00:13:12.266 --> 00:13:14.206 A:middle
Or named entity recognition.

00:13:14.746 --> 00:13:16.056 A:middle
So we provide built-in named

00:13:16.056 --> 00:13:16.976 A:middle
entity recognition that

00:13:16.976 --> 00:13:19.106 A:middle
recognizes names of people and

00:13:19.106 --> 00:13:21.516 A:middle
places and organizations, but

00:13:21.516 --> 00:13:22.766 A:middle
suppose you had some other kind

00:13:22.766 --> 00:13:23.356 A:middle
of name that you were

00:13:23.356 --> 00:13:24.686 A:middle
particularly interested in that

00:13:24.686 --> 00:13:25.906 A:middle
we don't happen to support right

00:13:25.906 --> 00:13:26.166 A:middle
now.

00:13:26.506 --> 00:13:28.136 A:middle
So, like for example, product

00:13:28.136 --> 00:13:28.456 A:middle
names.

00:13:28.456 --> 00:13:30.146 A:middle
So you could train your own

00:13:30.146 --> 00:13:31.876 A:middle
custom named entity recognizer

00:13:32.036 --> 00:13:33.656 A:middle
as a word tagger that would

00:13:33.656 --> 00:13:36.456 A:middle
recognize names or other terms

00:13:36.496 --> 00:13:37.526 A:middle
of whatever sort you are

00:13:37.526 --> 00:13:39.426 A:middle
particularly interested in.

00:13:40.616 --> 00:13:42.956 A:middle
Even further, for your automated

00:13:42.956 --> 00:13:44.356 A:middle
travel agent, once you know what

00:13:44.356 --> 00:13:45.646 A:middle
the user is asking about,

00:13:46.166 --> 00:13:47.326 A:middle
probably the next thing you want

00:13:47.326 --> 00:13:49.106 A:middle
to know is what are the relevant

00:13:49.106 --> 00:13:50.566 A:middle
terms in their request.

00:13:50.626 --> 00:13:51.816 A:middle
For example, if it's a flight

00:13:51.816 --> 00:13:52.416 A:middle
request.

00:13:52.676 --> 00:13:53.856 A:middle
Where do they want to go from

00:13:53.856 --> 00:13:54.386 A:middle
and to?

00:13:55.546 --> 00:13:57.566 A:middle
So a word tagger can identify

00:13:58.216 --> 00:14:01.386 A:middle
various kinds of terms in a


00:13:58.216 --> 00:14:01.386 A:middle
various kinds of terms in a

00:14:01.996 --> 00:14:02.236 A:middle
sentence.

00:14:02.326 --> 00:14:04.766 A:middle
Or another application, if you

00:14:04.766 --> 00:14:06.086 A:middle
need to take a sentence and

00:14:06.086 --> 00:14:07.966 A:middle
divide it up into phrases, noun

00:14:07.966 --> 00:14:09.356 A:middle
phrases, verb phrases,

00:14:09.426 --> 00:14:10.596 A:middle
propositional phrases.

00:14:10.996 --> 00:14:11.906 A:middle
With the appropriate sort of

00:14:11.906 --> 00:14:14.186 A:middle
labeling, you could train a word

00:14:14.186 --> 00:14:16.206 A:middle
tagger to do this, and many,

00:14:16.206 --> 00:14:19.556 A:middle
many other kinds of tasks can be

00:14:19.556 --> 00:14:21.796 A:middle
phrased in terms of labeling,

00:14:22.136 --> 00:14:23.946 A:middle
applying labels to portions of

00:14:23.946 --> 00:14:26.346 A:middle
text, either words in sequence

00:14:26.696 --> 00:14:29.176 A:middle
or chunks of text in the text

00:14:29.176 --> 00:14:29.756 A:middle
classifier.

00:14:33.676 --> 00:14:36.246 A:middle
So these are supervised machine

00:14:36.246 --> 00:14:37.526 A:middle
learning models, so there are

00:14:37.526 --> 00:14:39.946 A:middle
two phases always involved.

00:14:40.266 --> 00:14:41.806 A:middle
The first phase is training, and

00:14:41.996 --> 00:14:43.506 A:middle
the second phase is inference.

00:14:43.786 --> 00:14:46.016 A:middle
So training is what you do in

00:14:46.016 --> 00:14:46.996 A:middle
part of your development

00:14:46.996 --> 00:14:47.726 A:middle
process.

00:14:48.256 --> 00:14:50.926 A:middle
You take labeled training data,

00:14:51.936 --> 00:14:54.356 A:middle
and you feed it into Create ML

00:14:54.606 --> 00:14:55.806 A:middle
and produce a model.

00:14:57.266 --> 00:14:59.266 A:middle
Inference is then what happens

00:14:59.336 --> 00:15:01.246 A:middle
in your app when you incorporate


00:14:59.336 --> 00:15:01.246 A:middle
in your app when you incorporate

00:15:01.486 --> 00:15:03.036 A:middle
that model into your application

00:15:03.486 --> 00:15:05.406 A:middle
at run time when it encounters

00:15:05.406 --> 00:15:06.956 A:middle
some piece of data from the

00:15:06.956 --> 00:15:08.986 A:middle
user, and then it analyzes that

00:15:08.986 --> 00:15:09.976 A:middle
data and predicts the

00:15:09.976 --> 00:15:11.346 A:middle
appropriate labels for it.

00:15:11.806 --> 00:15:13.396 A:middle
So let's see how these phases

00:15:13.396 --> 00:15:13.676 A:middle
work.

00:15:14.936 --> 00:15:16.246 A:middle
So let's start with training,

00:15:17.076 --> 00:15:18.366 A:middle
and training always starts with

00:15:18.426 --> 00:15:18.786 A:middle
data.

00:15:19.406 --> 00:15:22.056 A:middle
You take your training data, and

00:15:22.056 --> 00:15:23.856 A:middle
then you feed it in to in this

00:15:23.856 --> 00:15:26.956 A:middle
case Create ML in a playground

00:15:26.956 --> 00:15:29.236 A:middle
let us say or a script

00:15:30.286 --> 00:15:30.986 A:middle
[inaudible] as you may have seen

00:15:30.986 --> 00:15:32.066 A:middle
in the Create ML session.

00:15:32.616 --> 00:15:34.606 A:middle
Create ML calls the Natural

00:15:34.606 --> 00:15:35.446 A:middle
Language framework under the

00:15:35.446 --> 00:15:38.196 A:middle
hood to do the training, and

00:15:38.196 --> 00:15:40.806 A:middle
what comes out is a core ML

00:15:40.806 --> 00:15:43.726 A:middle
model that's optimized for use

00:15:43.766 --> 00:15:44.586 A:middle
on device.

00:15:45.956 --> 00:15:47.616 A:middle
So let's look at what this data

00:15:47.616 --> 00:15:49.416 A:middle
might look like.

00:15:49.786 --> 00:15:51.396 A:middle
So Create ML supports a number

00:15:51.396 --> 00:15:52.856 A:middle
of different data formats.

00:15:53.276 --> 00:15:55.376 A:middle
Right here we're showing our

00:15:55.376 --> 00:15:57.666 A:middle
data in JSON because JSON makes

00:15:57.666 --> 00:16:00.946 A:middle
things perfectly clear, and this


00:15:57.666 --> 00:16:00.946 A:middle
things perfectly clear, and this

00:16:00.946 --> 00:16:04.436 A:middle
is a piece of training data for

00:16:04.816 --> 00:16:06.516 A:middle
a text classifier that's a

00:16:06.516 --> 00:16:07.666 A:middle
sediment classifier.

00:16:07.916 --> 00:16:11.396 A:middle
So each training example, like

00:16:11.396 --> 00:16:13.546 A:middle
this one, consists of two parts,

00:16:13.856 --> 00:16:16.686 A:middle
a chunk of text, and the

00:16:16.686 --> 00:16:17.986 A:middle
appropriate label for it.

00:16:18.676 --> 00:16:20.696 A:middle
And so this for example is a

00:16:20.696 --> 00:16:22.056 A:middle
positive sentence, so the label

00:16:22.056 --> 00:16:23.206 A:middle
is positive, but you can pick

00:16:23.246 --> 00:16:27.636 A:middle
whatever label set you want.

00:16:27.816 --> 00:16:29.896 A:middle
Now, then when you start using

00:16:29.896 --> 00:16:31.806 A:middle
Create ML, the Create ML

00:16:32.476 --> 00:16:34.066 A:middle
provides a very, very simple way

00:16:34.156 --> 00:16:36.296 A:middle
to train models in just a few

00:16:36.296 --> 00:16:36.986 A:middle
lines of code.

00:16:36.986 --> 00:16:40.046 A:middle
First line, we just load our

00:16:40.146 --> 00:16:42.446 A:middle
training data from our JSON

00:16:42.446 --> 00:16:42.846 A:middle
file.

00:16:42.886 --> 00:16:44.676 A:middle
So we give it a URL to the JSON

00:16:44.676 --> 00:16:48.116 A:middle
file, create a Create ML data

00:16:48.116 --> 00:16:48.836 A:middle
table from it.

00:16:49.996 --> 00:16:52.216 A:middle
Then in one line of code, create

00:16:52.216 --> 00:16:55.046 A:middle
and train a text classifier from

00:16:55.046 --> 00:16:55.586 A:middle
this data.

00:16:55.806 --> 00:16:57.086 A:middle
All you have to tell it is what

00:16:57.086 --> 00:16:58.456 A:middle
the names of the fields are,

00:16:58.866 --> 00:17:02.046 A:middle
text and label, and then once


00:16:58.866 --> 00:17:02.046 A:middle
text and label, and then once

00:17:02.046 --> 00:17:03.536 A:middle
you have it, one line of code

00:17:03.536 --> 00:17:07.116 A:middle
writes that model out to disk.

00:17:07.286 --> 00:17:08.675 A:middle
Now for training a Word Tagger,

00:17:08.776 --> 00:17:09.556 A:middle
it's very similar.

00:17:09.976 --> 00:17:11.286 A:middle
The data is just a little more

00:17:11.286 --> 00:17:13.526 A:middle
complicated because each example

00:17:13.526 --> 00:17:15.076 A:middle
is not a single piece of text.

00:17:15.306 --> 00:17:18.226 A:middle
It's a sequence of tokens, and

00:17:18.786 --> 00:17:20.316 A:middle
the labels are, again, a

00:17:20.316 --> 00:17:21.726 A:middle
sequence of labels, the same

00:17:21.726 --> 00:17:23.955 A:middle
number of labels, one label for

00:17:23.955 --> 00:17:24.546 A:middle
each token.

00:17:24.935 --> 00:17:26.776 A:middle
So this, for example, is

00:17:26.826 --> 00:17:29.976 A:middle
training data for a Word Tagger

00:17:29.976 --> 00:17:31.236 A:middle
that does name identity

00:17:31.236 --> 00:17:34.526 A:middle
recognition, and each word, each

00:17:34.526 --> 00:17:36.836 A:middle
token, has a label, either none,

00:17:36.836 --> 00:17:39.696 A:middle
it's not a name, or org, it's an

00:17:39.696 --> 00:17:42.376 A:middle
organization name or prod, it's

00:17:42.376 --> 00:17:44.296 A:middle
product name, or a number of

00:17:44.326 --> 00:17:45.856 A:middle
different other labels for

00:17:45.856 --> 00:17:47.146 A:middle
whatever kinds of names you're

00:17:47.146 --> 00:17:47.806 A:middle
recognizing.

00:17:48.236 --> 00:17:51.016 A:middle
So each token has a label, and

00:17:51.016 --> 00:17:54.306 A:middle
each sample consists of one

00:17:54.456 --> 00:17:55.906 A:middle
sequence of tokens and their

00:17:55.906 --> 00:17:56.986 A:middle
corresponding labels.

00:17:58.606 --> 00:18:01.066 A:middle
And then the Create ML to train


00:17:58.606 --> 00:18:01.066 A:middle
And then the Create ML to train

00:18:01.066 --> 00:18:02.886 A:middle
this is almost identical.

00:18:03.996 --> 00:18:06.276 A:middle
You load the training data into

00:18:06.276 --> 00:18:08.346 A:middle
a data table from the JSON.

00:18:09.896 --> 00:18:12.996 A:middle
Then you create and train a Word

00:18:12.996 --> 00:18:14.336 A:middle
Tagger, in this case instead of

00:18:14.336 --> 00:18:16.426 A:middle
a text classifier, and then you

00:18:16.426 --> 00:18:17.806 A:middle
write it out to disk.

00:18:18.306 --> 00:18:20.576 A:middle
Now, there are a number of other

00:18:20.576 --> 00:18:23.026 A:middle
options and APIs available in

00:18:23.026 --> 00:18:23.626 A:middle
Create ML.

00:18:23.626 --> 00:18:24.906 A:middle
I encourage you to, if you

00:18:24.906 --> 00:18:26.026 A:middle
haven't already, take a look at

00:18:26.026 --> 00:18:27.826 A:middle
the Create ML session, which

00:18:27.826 --> 00:18:29.696 A:middle
happened yesterday, and Create

00:18:29.696 --> 00:18:31.306 A:middle
ML documentation for more

00:18:31.306 --> 00:18:32.236 A:middle
information on that.

00:18:33.066 --> 00:18:35.086 A:middle
Now, once you have your model,

00:18:35.276 --> 00:18:36.236 A:middle
we then go to the inference

00:18:36.236 --> 00:18:36.506 A:middle
part.

00:18:36.696 --> 00:18:38.406 A:middle
So you take your model, you drag

00:18:38.406 --> 00:18:39.796 A:middle
it into your Xcode project.

00:18:40.186 --> 00:18:41.846 A:middle
Xcode compiles it and includes

00:18:41.846 --> 00:18:43.126 A:middle
it in your applications

00:18:43.226 --> 00:18:45.156 A:middle
resources, and then what do you

00:18:45.156 --> 00:18:45.996 A:middle
do at run time?

00:18:46.686 --> 00:18:49.056 A:middle
Well, it's a Core ML model.

00:18:49.056 --> 00:18:50.136 A:middle
You could use it like any other

00:18:50.136 --> 00:18:51.736 A:middle
Core ML model, but the

00:18:51.736 --> 00:18:53.626 A:middle
interesting thing is that these

00:18:53.626 --> 00:18:56.216 A:middle
models are able to work well

00:18:56.596 --> 00:18:58.706 A:middle
with the Natural Language APIs

00:18:59.356 --> 00:19:01.566 A:middle
just like our built-in models


00:18:59.356 --> 00:19:01.566 A:middle
just like our built-in models

00:19:01.566 --> 00:19:02.826 A:middle
that provide the existing

00:19:02.826 --> 00:19:04.956 A:middle
functionality for NLP.

00:19:06.666 --> 00:19:09.696 A:middle
So what will happen is data

00:19:09.696 --> 00:19:10.306 A:middle
comes in.

00:19:11.296 --> 00:19:12.976 A:middle
You pass it to Natural Language,

00:19:14.126 --> 00:19:16.226 A:middle
which will use that model and do

00:19:16.226 --> 00:19:18.936 A:middle
everything necessary to get all

00:19:18.936 --> 00:19:20.806 A:middle
of the labels out and then pass

00:19:20.856 --> 00:19:22.706 A:middle
back either a label, single

00:19:22.706 --> 00:19:24.196 A:middle
label for a classifier or a

00:19:24.196 --> 00:19:27.106 A:middle
sequence of labels for a tagger.

00:19:27.656 --> 00:19:32.316 A:middle
And so how do you do this in

00:19:32.316 --> 00:19:33.296 A:middle
Natural Language API?

00:19:34.326 --> 00:19:36.176 A:middle
First thing you have to do is

00:19:36.176 --> 00:19:38.366 A:middle
just locate that model in your

00:19:38.366 --> 00:19:40.296 A:middle
application's resources, and

00:19:40.296 --> 00:19:41.636 A:middle
then you create an instance of a

00:19:41.636 --> 00:19:43.406 A:middle
class in Natural Language called

00:19:43.456 --> 00:19:45.626 A:middle
ML Model from it.

00:19:46.026 --> 00:19:48.026 A:middle
And then, well, the simplest

00:19:48.026 --> 00:19:49.036 A:middle
thing you can do with it, at

00:19:49.076 --> 00:19:51.396 A:middle
least for a classifier, is just

00:19:51.396 --> 00:19:52.976 A:middle
pass it in a chunk of text and

00:19:52.976 --> 00:19:53.756 A:middle
get a label out.

00:19:54.696 --> 00:19:55.886 A:middle
But the more interesting thing

00:19:55.936 --> 00:19:59.116 A:middle
is that you can use these models

00:19:59.116 --> 00:20:02.226 A:middle
with NLTagger in exactly the


00:19:59.116 --> 00:20:02.226 A:middle
with NLTagger in exactly the

00:20:02.226 --> 00:20:03.866 A:middle
same way that you use our

00:20:03.866 --> 00:20:06.976 A:middle
built-in models for an existing

00:20:06.976 --> 00:20:07.716 A:middle
functionality.

00:20:08.176 --> 00:20:09.036 A:middle
So let me show you how that

00:20:09.036 --> 00:20:09.466 A:middle
works.

00:20:10.366 --> 00:20:12.326 A:middle
In addition to the existing tag

00:20:12.326 --> 00:20:13.776 A:middle
schemes that we have for things

00:20:13.776 --> 00:20:15.336 A:middle
like named identity recognition

00:20:15.336 --> 00:20:17.136 A:middle
part of speech tagging, you can

00:20:17.136 --> 00:20:18.676 A:middle
create your own custom tag

00:20:18.676 --> 00:20:22.446 A:middle
scheme, give it a name, and then

00:20:22.516 --> 00:20:24.636 A:middle
you can create a tagger that

00:20:24.636 --> 00:20:26.066 A:middle
includes any number of different

00:20:26.066 --> 00:20:26.776 A:middle
tag schemes.

00:20:27.146 --> 00:20:28.826 A:middle
Your custom tag scheme or any of

00:20:28.826 --> 00:20:30.426 A:middle
our built-in tag schemes or all

00:20:31.086 --> 00:20:33.086 A:middle
of them, and then all you have

00:20:33.086 --> 00:20:35.496 A:middle
to do is to tell the tagger to

00:20:35.496 --> 00:20:37.136 A:middle
use your custom model for your

00:20:37.136 --> 00:20:38.146 A:middle
custom tag scheme.

00:20:38.686 --> 00:20:40.886 A:middle
And then you just use it

00:20:42.186 --> 00:20:42.706 A:middle
normally.

00:20:43.246 --> 00:20:44.776 A:middle
You attach a string to the

00:20:44.776 --> 00:20:46.756 A:middle
tagger, and you can go through

00:20:46.756 --> 00:20:49.256 A:middle
and look at the tags for

00:20:49.706 --> 00:20:51.736 A:middle
whatever unit of text is

00:20:51.736 --> 00:20:52.996 A:middle
appropriate for your particular

00:20:52.996 --> 00:20:56.296 A:middle
model, and the tagger will

00:20:56.296 --> 00:20:58.246 A:middle
automatically call the model as

00:20:58.246 --> 00:20:59.886 A:middle
necessary to get the tags and

00:20:59.886 --> 00:21:01.436 A:middle
return the tags to you and will


00:20:59.886 --> 00:21:01.436 A:middle
return the tags to you and will

00:21:01.436 --> 00:21:03.616 A:middle
do all the other things that

00:21:03.616 --> 00:21:05.116 A:middle
NLTagger does automatically,

00:21:05.476 --> 00:21:06.886 A:middle
like language identification,

00:21:06.886 --> 00:21:08.246 A:middle
tokenization and so on and so

00:21:08.246 --> 00:21:08.526 A:middle
forth.

00:21:08.526 --> 00:21:12.386 A:middle
So I want to show this to you in

00:21:12.386 --> 00:21:14.016 A:middle
a simple hypothetical example.

00:21:14.606 --> 00:21:16.686 A:middle
And this hypothetical example is

00:21:17.726 --> 00:21:21.266 A:middle
an app that users will use to

00:21:21.266 --> 00:21:23.076 A:middle
store bookmarks to articles they

00:21:23.076 --> 00:21:24.526 A:middle
may have run across and then

00:21:24.596 --> 00:21:26.056 A:middle
might be intending to read later

00:21:26.056 --> 00:21:26.296 A:middle
on.

00:21:27.236 --> 00:21:28.836 A:middle
But the problem with this

00:21:28.836 --> 00:21:29.866 A:middle
application as it currently

00:21:29.866 --> 00:21:32.066 A:middle
stands is that the list of

00:21:32.066 --> 00:21:33.626 A:middle
bookmarks is just one long list

00:21:33.626 --> 00:21:34.996 A:middle
with no organization to it.

00:21:35.566 --> 00:21:37.176 A:middle
Wouldn't it be nice if we could

00:21:37.336 --> 00:21:39.056 A:middle
automatically classify these

00:21:39.056 --> 00:21:41.046 A:middle
articles and put them into some

00:21:41.046 --> 00:21:42.726 A:middle
organization according to topic?

00:21:43.316 --> 00:21:45.376 A:middle
Well, we can train a classifier

00:21:45.376 --> 00:21:46.276 A:middle
to do that for us.

00:21:47.066 --> 00:21:48.346 A:middle
And the other thing is that the

00:21:48.346 --> 00:21:49.526 A:middle
articles, when we look at them,

00:21:49.856 --> 00:21:51.346 A:middle
it's a long stream of text.

00:21:52.386 --> 00:21:53.666 A:middle
Maybe we'd like to highlight

00:21:53.666 --> 00:21:55.966 A:middle
some interesting things in those

00:21:55.966 --> 00:21:58.286 A:middle
articles like for example names.

00:21:58.796 --> 00:22:01.596 A:middle
Well, we have provided built-in


00:21:58.796 --> 00:22:01.596 A:middle
Well, we have provided built-in

00:22:01.596 --> 00:22:03.156 A:middle
name identity recognition for

00:22:03.156 --> 00:22:04.666 A:middle
names of people, places, and

00:22:04.666 --> 00:22:07.406 A:middle
organizations, but maybe we also

00:22:07.406 --> 00:22:08.426 A:middle
want to highlight names of

00:22:08.426 --> 00:22:10.016 A:middle
products, so we could train a

00:22:10.076 --> 00:22:12.366 A:middle
custom word tagger to identify

00:22:12.366 --> 00:22:14.086 A:middle
those names for us.

00:22:15.036 --> 00:22:16.726 A:middle
So let me go over to the demo

00:22:16.726 --> 00:22:17.086 A:middle
machine.

00:22:20.736 --> 00:22:25.746 A:middle
And so here's our application as

00:22:25.746 --> 00:22:27.586 A:middle
it stands before we apply any

00:22:27.856 --> 00:22:29.116 A:middle
natural language processing.

00:22:29.406 --> 00:22:30.706 A:middle
As you can see, even just one

00:22:30.706 --> 00:22:32.736 A:middle
long list of articles on the

00:22:32.736 --> 00:22:35.456 A:middle
side and a big chunk of text for

00:22:35.456 --> 00:22:36.606 A:middle
our article on the right.

00:22:36.606 --> 00:22:37.486 A:middle
Well let's fix that.

00:22:38.716 --> 00:22:42.506 A:middle
So, let's go into -- so the

00:22:42.506 --> 00:22:44.996 A:middle
first part of training a model

00:22:45.516 --> 00:22:48.776 A:middle
is data, and fortunately, I have

00:22:48.776 --> 00:22:49.576 A:middle
some very hard-working

00:22:49.576 --> 00:22:50.976 A:middle
colleagues at Apple who have

00:22:50.976 --> 00:22:52.696 A:middle
collected for me some training

00:22:52.696 --> 00:22:54.446 A:middle
data to train two models.

00:22:54.776 --> 00:22:57.066 A:middle
The first model is a text

00:22:57.066 --> 00:22:59.026 A:middle
classifier that will classify

00:22:59.026 --> 00:23:00.446 A:middle
articles according to topic.


00:22:59.026 --> 00:23:00.446 A:middle
articles according to topic.

00:23:00.856 --> 00:23:01.896 A:middle
So this is some of what the

00:23:01.896 --> 00:23:03.136 A:middle
training data looks like.

00:23:03.716 --> 00:23:05.466 A:middle
Each training example is a chunk

00:23:05.466 --> 00:23:07.106 A:middle
of text and the appropriate

00:23:07.106 --> 00:23:10.386 A:middle
label by topic, entertainment,

00:23:10.386 --> 00:23:12.016 A:middle
politics, sports, and so on and

00:23:12.016 --> 00:23:13.026 A:middle
so forth.

00:23:15.196 --> 00:23:18.436 A:middle
And I also have some training

00:23:18.436 --> 00:23:21.486 A:middle
data to train a word tagger that

00:23:21.486 --> 00:23:25.136 A:middle
will recognize product names in

00:23:25.136 --> 00:23:25.836 A:middle
sentences.

00:23:26.256 --> 00:23:27.766 A:middle
So this training data is pretty

00:23:27.766 --> 00:23:28.106 A:middle
simple.

00:23:28.666 --> 00:23:31.486 A:middle
Each example consists of a

00:23:31.486 --> 00:23:32.736 A:middle
sentence considered as a

00:23:32.736 --> 00:23:34.326 A:middle
sequence of tokens and then a

00:23:34.326 --> 00:23:35.936 A:middle
sequence of labels, and each

00:23:35.936 --> 00:23:38.456 A:middle
label is either none, it's not a

00:23:38.456 --> 00:23:40.716 A:middle
product name, or prod, it is a

00:23:40.716 --> 00:23:43.436 A:middle
product name.

00:23:43.696 --> 00:23:46.066 A:middle
So, let's try to train with

00:23:46.106 --> 00:23:46.436 A:middle
these.

00:23:47.186 --> 00:23:50.406 A:middle
So first thing I want to do is

00:23:50.926 --> 00:23:52.726 A:middle
bring up a playground that I

00:23:52.726 --> 00:23:55.786 A:middle
have using Create ML, and this

00:23:55.826 --> 00:23:58.576 A:middle
playground will just load.

00:23:58.646 --> 00:24:00.826 A:middle
In this case, this is my product


00:23:58.646 --> 00:24:00.826 A:middle
In this case, this is my product

00:24:00.826 --> 00:24:01.496 A:middle
word tagger.

00:24:01.716 --> 00:24:02.886 A:middle
It'll load the training data,

00:24:03.796 --> 00:24:05.206 A:middle
create a word tagger from it,

00:24:05.886 --> 00:24:07.036 A:middle
and write it out to disk.

00:24:07.036 --> 00:24:08.356 A:middle
So let me just fire that off,

00:24:09.476 --> 00:24:10.626 A:middle
and let it start running.

00:24:11.206 --> 00:24:14.326 A:middle
It's loaded the data, and so

00:24:14.326 --> 00:24:16.176 A:middle
under the hood, we automatically

00:24:16.176 --> 00:24:17.966 A:middle
handle all of the tokenization,

00:24:17.966 --> 00:24:19.086 A:middle
the feature extraction.

00:24:19.466 --> 00:24:20.316 A:middle
We do the training.

00:24:20.316 --> 00:24:22.596 A:middle
This is a fairly small model, so

00:24:22.596 --> 00:24:24.116 A:middle
it doesn't take all that long to

00:24:24.116 --> 00:24:27.796 A:middle
train, and I have it set to

00:24:27.796 --> 00:24:29.366 A:middle
automatically write my model out

00:24:29.366 --> 00:24:35.956 A:middle
to my desktop, and there it is.

00:24:36.196 --> 00:24:36.486 A:middle
All right.

00:24:36.486 --> 00:24:37.436 A:middle
So that's one model.

00:24:38.636 --> 00:24:40.636 A:middle
Now I have another playground

00:24:40.636 --> 00:24:41.876 A:middle
here that's set up to train my

00:24:41.876 --> 00:24:42.786 A:middle
text classifier.

00:24:43.136 --> 00:24:44.076 A:middle
As you can see, it looks very

00:24:44.076 --> 00:24:44.516 A:middle
similar.

00:24:45.046 --> 00:24:47.836 A:middle
Load the training data, create a

00:24:47.836 --> 00:24:49.396 A:middle
text classifier from it, and

00:24:49.396 --> 00:24:50.266 A:middle
write it out to disk.

00:24:51.716 --> 00:24:52.786 A:middle
So I start that off.

00:24:53.426 --> 00:24:56.876 A:middle
And again, automatically natural

00:24:56.876 --> 00:24:58.006 A:middle
language is loading all the

00:24:58.006 --> 00:25:00.126 A:middle
data, tokenizing it, extracting


00:24:58.006 --> 00:25:00.126 A:middle
data, tokenizing it, extracting

00:25:00.126 --> 00:25:00.856 A:middle
features from it.

00:25:01.266 --> 00:25:03.226 A:middle
This one is a bit larger model.

00:25:03.226 --> 00:25:04.226 A:middle
It takes a couple minutes to

00:25:04.226 --> 00:25:04.556 A:middle
train.

00:25:04.556 --> 00:25:06.746 A:middle
So let's just let that go, and

00:25:06.746 --> 00:25:08.696 A:middle
in the meantime, take a look at

00:25:08.696 --> 00:25:10.966 A:middle
some of the code we have to use

00:25:10.966 --> 00:25:12.026 A:middle
these at run time.

00:25:12.546 --> 00:25:14.166 A:middle
So I've written two very small

00:25:14.166 --> 00:25:16.106 A:middle
classes to do what I need to do

00:25:16.106 --> 00:25:16.576 A:middle
at run time.

00:25:17.106 --> 00:25:18.546 A:middle
The first one uses the text

00:25:18.546 --> 00:25:22.136 A:middle
classifier by finding that model

00:25:22.386 --> 00:25:24.386 A:middle
in my apps resources and

00:25:24.386 --> 00:25:25.826 A:middle
creating an NL model for it.

00:25:26.856 --> 00:25:28.656 A:middle
And then when I run across an

00:25:28.656 --> 00:25:32.016 A:middle
article, I just ask the model

00:25:32.016 --> 00:25:33.616 A:middle
for a predicted label for that

00:25:33.616 --> 00:25:35.856 A:middle
article, and that's really all

00:25:35.856 --> 00:25:38.246 A:middle
there is to it.

00:25:38.506 --> 00:25:42.726 A:middle
Slightly more code for use of my

00:25:42.726 --> 00:25:43.486 A:middle
word tagger.

00:25:44.176 --> 00:25:46.006 A:middle
So as you saw before, I have a

00:25:46.006 --> 00:25:49.026 A:middle
custom tag scheme for my product

00:25:49.196 --> 00:25:51.616 A:middle
name recognition, and the only

00:25:51.616 --> 00:25:53.566 A:middle
tag I'm really interested in is

00:25:53.566 --> 00:25:54.546 A:middle
the product tag.

00:25:54.716 --> 00:25:57.416 A:middle
So I create a custom tag for

00:25:58.036 --> 00:25:58.146 A:middle
that.

00:25:58.366 --> 00:26:00.396 A:middle
Again, I have to find the model


00:25:58.366 --> 00:26:00.396 A:middle
Again, I have to find the model

00:26:00.546 --> 00:26:03.366 A:middle
in my bundles resources, create

00:26:03.366 --> 00:26:05.536 A:middle
an NL model for it, and then

00:26:05.536 --> 00:26:07.586 A:middle
create an NLTagger, and this

00:26:07.736 --> 00:26:09.826 A:middle
NLTagger I'm specifying two

00:26:09.826 --> 00:26:10.376 A:middle
schemes.

00:26:10.416 --> 00:26:11.986 A:middle
The first is the built-in name

00:26:11.986 --> 00:26:14.876 A:middle
type scheme to do name identity

00:26:14.876 --> 00:26:16.426 A:middle
recognition, and the second one

00:26:16.426 --> 00:26:18.176 A:middle
is my custom product tag scheme,

00:26:18.516 --> 00:26:19.486 A:middle
and they'll both function in

00:26:19.486 --> 00:26:20.576 A:middle
exactly the same way.

00:26:21.546 --> 00:26:23.006 A:middle
And then I just have to tell

00:26:23.096 --> 00:26:24.766 A:middle
that tagger to use my custom

00:26:24.766 --> 00:26:26.866 A:middle
model for my custom scheme.

00:26:27.716 --> 00:26:29.176 A:middle
Now if I supported multiple

00:26:29.176 --> 00:26:30.286 A:middle
languages, I might have more

00:26:30.286 --> 00:26:31.956 A:middle
than one model in here for this

00:26:31.956 --> 00:26:32.216 A:middle
scheme.

00:26:32.806 --> 00:26:38.426 A:middle
And then what I'm going to do is

00:26:38.426 --> 00:26:40.306 A:middle
highlight text in this article

00:26:40.716 --> 00:26:42.466 A:middle
that is located, determined to

00:26:42.466 --> 00:26:43.896 A:middle
be a name of one sort or

00:26:43.896 --> 00:26:44.266 A:middle
another.

00:26:44.566 --> 00:26:46.586 A:middle
So I'm going to get a mutable

00:26:46.586 --> 00:26:47.716 A:middle
attributed string, and I'm going

00:26:47.716 --> 00:26:49.026 A:middle
to add some attributes to it.

00:26:50.106 --> 00:26:51.996 A:middle
So I'll take this string of that

00:26:52.206 --> 00:26:53.246 A:middle
mutable attributed string,

00:26:53.246 --> 00:26:56.196 A:middle
attach that to my tagger, and

00:26:56.196 --> 00:26:57.496 A:middle
then I'm going to do a couple of

00:26:57.496 --> 00:26:59.216 A:middle
enumerations over tags.

00:26:59.676 --> 00:27:01.916 A:middle
The first one uses the built-in


00:26:59.676 --> 00:27:01.916 A:middle
The first one uses the built-in

00:27:01.916 --> 00:27:03.926 A:middle
name-type scheme for name

00:27:03.926 --> 00:27:05.576 A:middle
identity recognition of people,

00:27:05.576 --> 00:27:07.576 A:middle
places, and organizations, and

00:27:07.576 --> 00:27:08.686 A:middle
if I find something that's

00:27:08.686 --> 00:27:11.436 A:middle
tagged as a person or place or

00:27:11.436 --> 00:27:13.226 A:middle
organization, then I'm going to

00:27:13.226 --> 00:27:14.946 A:middle
add an attribute to the

00:27:14.946 --> 00:27:17.326 A:middle
attributed string that will give

00:27:17.326 --> 00:27:17.976 A:middle
it some color.

00:27:20.256 --> 00:27:21.576 A:middle
And then we can do exactly the

00:27:21.576 --> 00:27:23.696 A:middle
same thing with our custom

00:27:23.696 --> 00:27:24.046 A:middle
model.

00:27:24.846 --> 00:27:26.336 A:middle
We're going to enumerate using

00:27:26.336 --> 00:27:28.176 A:middle
our custom product tag scheme,

00:27:29.586 --> 00:27:31.386 A:middle
and in that case, if we find

00:27:31.386 --> 00:27:32.516 A:middle
something that's labeled with

00:27:32.516 --> 00:27:34.586 A:middle
our custom product tag, then I

00:27:34.586 --> 00:27:37.106 A:middle
can add color to it in exactly

00:27:37.106 --> 00:27:37.786 A:middle
the same way.

00:27:39.106 --> 00:27:41.026 A:middle
So you can use custom models

00:27:41.626 --> 00:27:44.326 A:middle
with Natural Language API just

00:27:44.516 --> 00:27:45.916 A:middle
in the same way that you use

00:27:45.916 --> 00:27:46.916 A:middle
built-in models.

00:27:47.566 --> 00:27:48.736 A:middle
Now, let's go back to our

00:27:48.736 --> 00:27:50.936 A:middle
playground, and we see that the

00:27:50.936 --> 00:27:52.986 A:middle
model training has finished, and

00:27:52.986 --> 00:27:54.496 A:middle
in fact there are now two models

00:27:54.496 --> 00:27:55.996 A:middle
showing up on my desktop.

00:27:57.776 --> 00:27:59.936 A:middle
So all I need to do is drag

00:27:59.936 --> 00:28:01.176 A:middle
those into my application.


00:27:59.936 --> 00:28:01.176 A:middle
those into my application.

00:28:02.116 --> 00:28:05.286 A:middle
Let's take this one and drag it

00:28:05.286 --> 00:28:06.146 A:middle
right in.

00:28:08.026 --> 00:28:14.676 A:middle
Okay. And let's take this one

00:28:15.226 --> 00:28:19.786 A:middle
and drag it in, and Xcode will

00:28:19.786 --> 00:28:21.116 A:middle
automatically compile these and

00:28:21.116 --> 00:28:22.546 A:middle
include them in my application.

00:28:22.846 --> 00:28:25.656 A:middle
So all I have to do is build and

00:28:25.656 --> 00:28:25.946 A:middle
run it.

00:28:31.386 --> 00:28:34.336 A:middle
And let's hide that.

00:28:34.926 --> 00:28:36.796 A:middle
Here's my new application, and

00:28:36.796 --> 00:28:38.096 A:middle
you'll notice that my list of

00:28:38.096 --> 00:28:40.386 A:middle
articles is all neatly sorted

00:28:40.506 --> 00:28:47.166 A:middle
automatically by topic, and if I

00:28:47.166 --> 00:28:49.596 A:middle
go in and take a look at one of

00:28:49.596 --> 00:28:51.396 A:middle
these articles, you'll notice

00:28:51.396 --> 00:28:53.556 A:middle
that names are highlighted in

00:28:53.556 --> 00:28:55.296 A:middle
it, and you can see, using our

00:28:55.296 --> 00:28:56.566 A:middle
built-in name identity

00:28:56.566 --> 00:28:57.976 A:middle
recognition, we highlight names

00:28:57.976 --> 00:28:59.026 A:middle
of people, places, and

00:28:59.026 --> 00:29:00.806 A:middle
organizations, but if you look a


00:28:59.026 --> 00:29:00.806 A:middle
organizations, but if you look a

00:29:00.806 --> 00:29:03.456 A:middle
little further, you can see that

00:29:03.496 --> 00:29:05.696 A:middle
it has used our custom product

00:29:05.696 --> 00:29:07.546 A:middle
tagger to highlight the names of

00:29:07.546 --> 00:29:10.056 A:middle
products like iPad, MacBook,

00:29:10.356 --> 00:29:12.386 A:middle
iPad mini, and so forth.

00:29:13.256 --> 00:29:16.606 A:middle
So this shows how easy it is to

00:29:16.606 --> 00:29:18.966 A:middle
train your own custom models and

00:29:18.966 --> 00:29:21.346 A:middle
to use them with the natural

00:29:21.346 --> 00:29:22.866 A:middle
language APIs.

00:29:24.516 --> 00:29:30.546 A:middle
[ Applause ]

00:29:31.046 --> 00:29:32.836 A:middle
So now I'm going to turn things

00:29:32.886 --> 00:29:34.486 A:middle
back over to Vivek to talk about

00:29:34.486 --> 00:29:36.236 A:middle
some important considerations

00:29:36.286 --> 00:29:37.646 A:middle
for training models.

00:29:40.516 --> 00:29:43.506 A:middle
[ Applause ]

00:29:44.006 --> 00:29:45.316 A:middle
Thank you, Doug, for telling us

00:29:45.316 --> 00:29:46.536 A:middle
how to use these custom NLP

00:29:46.536 --> 00:29:46.966 A:middle
models.

00:29:46.966 --> 00:29:48.646 A:middle
We are really excited to sort of

00:29:48.646 --> 00:29:50.646 A:middle
have a very tight integration of

00:29:50.646 --> 00:29:52.686 A:middle
natural language with Create ML

00:29:52.686 --> 00:29:54.146 A:middle
and the Core ML [inaudible], and

00:29:54.146 --> 00:29:55.246 A:middle
we hope that you do some really

00:29:55.246 --> 00:29:56.416 A:middle
unbelievable things with this

00:29:56.416 --> 00:29:57.316 A:middle
new API.

00:29:57.316 --> 00:30:00.156 A:middle
So I'd like to shift attention


00:29:57.316 --> 00:30:00.156 A:middle
So I'd like to shift attention

00:30:00.156 --> 00:30:01.406 A:middle
now again and talk about

00:30:01.406 --> 00:30:01.996 A:middle
performance.

00:30:02.446 --> 00:30:04.106 A:middle
So as I mentioned before,

00:30:04.106 --> 00:30:05.656 A:middle
Natural Language is available

00:30:05.936 --> 00:30:08.166 A:middle
across all Apple platforms, and

00:30:08.166 --> 00:30:10.226 A:middle
it also offers you what we call

00:30:10.226 --> 00:30:12.296 A:middle
as standardized text processing.

00:30:12.646 --> 00:30:14.296 A:middle
So let's take a moment again to

00:30:14.296 --> 00:30:15.636 A:middle
understand what we mean by this.

00:30:16.426 --> 00:30:17.686 A:middle
Now if you were to look at a

00:30:17.686 --> 00:30:18.876 A:middle
conventional machine learning

00:30:18.876 --> 00:30:20.786 A:middle
pipeline that didn't use Create

00:30:20.786 --> 00:30:22.236 A:middle
ML, where would you start?

00:30:22.346 --> 00:30:23.526 A:middle
You would start with some amount

00:30:23.526 --> 00:30:24.336 A:middle
of training data.

00:30:25.346 --> 00:30:26.136 A:middle
You would take this training

00:30:26.136 --> 00:30:26.426 A:middle
data.

00:30:26.426 --> 00:30:27.436 A:middle
You would tokenize this data.

00:30:27.436 --> 00:30:28.716 A:middle
You'd probably extract some

00:30:28.716 --> 00:30:29.246 A:middle
features.

00:30:29.506 --> 00:30:30.896 A:middle
This is really important for

00:30:30.896 --> 00:30:32.076 A:middle
languages like Chinese and

00:30:32.076 --> 00:30:33.676 A:middle
Japanese where tokenization is

00:30:33.676 --> 00:30:34.286 A:middle
very important.

00:30:34.926 --> 00:30:36.386 A:middle
You would throw that into your

00:30:36.386 --> 00:30:37.236 A:middle
favorite machine learning

00:30:37.236 --> 00:30:40.236 A:middle
toolkit, and you'd get a machine

00:30:40.236 --> 00:30:41.516 A:middle
learning model out of it.

00:30:41.966 --> 00:30:43.226 A:middle
Now in order to use that machine

00:30:43.226 --> 00:30:44.196 A:middle
learning model on an Apple

00:30:44.196 --> 00:30:45.756 A:middle
device, you'd have to convert

00:30:45.756 --> 00:30:47.146 A:middle
that into a Core ML model.

00:30:47.606 --> 00:30:48.736 A:middle
So what would you do?

00:30:48.906 --> 00:30:49.716 A:middle
You would use a Core ML

00:30:49.716 --> 00:30:50.746 A:middle
converter to do this.

00:30:51.376 --> 00:30:53.176 A:middle
This is sort of the training

00:30:53.176 --> 00:30:55.426 A:middle
procedure in order to get from

00:30:55.426 --> 00:30:57.386 A:middle
data to a model and deploy it on

00:30:57.386 --> 00:30:59.896 A:middle
an Apple device.

00:30:59.896 --> 00:31:02.486 A:middle
Now, at inference time, what you


00:30:59.896 --> 00:31:02.486 A:middle
Now, at inference time, what you

00:31:02.486 --> 00:31:04.876 A:middle
do is you drop the model in your

00:31:05.186 --> 00:31:06.266 A:middle
app, but that's not it.

00:31:07.216 --> 00:31:09.406 A:middle
You also have to make sure that

00:31:09.406 --> 00:31:10.386 A:middle
you write the code for

00:31:10.386 --> 00:31:11.586 A:middle
tokenization and feature

00:31:11.586 --> 00:31:13.336 A:middle
extraction that is consistent

00:31:13.336 --> 00:31:14.626 A:middle
with what happened at training

00:31:15.996 --> 00:31:16.136 A:middle
time.

00:31:16.596 --> 00:31:17.956 A:middle
It's a lot of effort because you

00:31:17.956 --> 00:31:19.686 A:middle
have to think about maximizing

00:31:19.686 --> 00:31:20.836 A:middle
the fidelity of your model.

00:31:20.836 --> 00:31:22.776 A:middle
It's absolutely important that

00:31:22.776 --> 00:31:24.086 A:middle
the tokenization featured

00:31:24.086 --> 00:31:26.066 A:middle
extraction is identical at both

00:31:26.066 --> 00:31:26.996 A:middle
training and inference time.

00:31:27.916 --> 00:31:29.486 A:middle
But now with the use of Natural

00:31:29.486 --> 00:31:30.506 A:middle
Language, you can completely

00:31:30.506 --> 00:31:31.246 A:middle
obviate this.

00:31:31.516 --> 00:31:34.096 A:middle
So if you look at the sequence

00:31:34.096 --> 00:31:35.216 A:middle
at training time, you have

00:31:35.216 --> 00:31:35.886 A:middle
training data.

00:31:37.276 --> 00:31:38.526 A:middle
You just pass it to Create ML

00:31:38.596 --> 00:31:39.506 A:middle
through the APIs that we've

00:31:39.506 --> 00:31:40.276 A:middle
discussed so far.

00:31:41.176 --> 00:31:42.916 A:middle
Create ML calls Natural Language

00:31:42.956 --> 00:31:44.136 A:middle
under the hood, which does the

00:31:44.136 --> 00:31:45.986 A:middle
tokenization feature extraction,

00:31:46.356 --> 00:31:47.316 A:middle
chooses the machine learning

00:31:47.316 --> 00:31:49.456 A:middle
library, does all the work, and

00:31:49.456 --> 00:31:51.456 A:middle
returns a model which is a Core

00:31:51.456 --> 00:31:52.866 A:middle
ML model.

00:31:53.076 --> 00:31:54.366 A:middle
Now at inference time, what you

00:31:54.366 --> 00:31:56.236 A:middle
do is you still drop this model

00:31:56.236 --> 00:31:58.876 A:middle
in your app, but you don't have

00:31:58.876 --> 00:32:00.146 A:middle
to worry about tokenization


00:31:58.876 --> 00:32:00.146 A:middle
to worry about tokenization

00:32:00.146 --> 00:32:01.286 A:middle
feature extraction or anything

00:32:01.286 --> 00:32:01.496 A:middle
else.

00:32:01.706 --> 00:32:03.236 A:middle
In fact, you don't have to write

00:32:03.236 --> 00:32:04.376 A:middle
a single line of code because

00:32:04.636 --> 00:32:06.446 A:middle
Natural Language does all of

00:32:06.446 --> 00:32:07.036 A:middle
that for you.

00:32:07.356 --> 00:32:08.916 A:middle
You just focus on your app and

00:32:08.916 --> 00:32:10.296 A:middle
your task and simply drag and

00:32:10.296 --> 00:32:11.176 A:middle
drop the model in.

00:32:11.636 --> 00:32:15.026 A:middle
The other aspect of Natural

00:32:15.026 --> 00:32:16.226 A:middle
Language as I mentioned before

00:32:16.296 --> 00:32:17.856 A:middle
is it's optimized for Apple

00:32:17.856 --> 00:32:19.916 A:middle
hardware and for model sizes.

00:32:20.036 --> 00:32:21.626 A:middle
So let's look at this through a

00:32:21.626 --> 00:32:22.586 A:middle
couple of examples.

00:32:23.276 --> 00:32:25.066 A:middle
So Doug talked about named

00:32:25.066 --> 00:32:26.556 A:middle
entity recognition and chunking,

00:32:27.096 --> 00:32:28.146 A:middle
and here are two different

00:32:28.146 --> 00:32:28.746 A:middle
benchmarks.

00:32:28.746 --> 00:32:30.876 A:middle
So these are models that we

00:32:30.876 --> 00:32:32.726 A:middle
built using an open source tool

00:32:32.726 --> 00:32:34.396 A:middle
kit called CRF Suite, and

00:32:34.396 --> 00:32:35.336 A:middle
through Natural Language.

00:32:35.716 --> 00:32:36.706 A:middle
The models were built from

00:32:36.776 --> 00:32:38.856 A:middle
identical training data and

00:32:38.856 --> 00:32:40.346 A:middle
tested on identical test data.

00:32:40.856 --> 00:32:41.906 A:middle
The same sort of features were

00:32:41.906 --> 00:32:42.306 A:middle
used.

00:32:42.496 --> 00:32:43.836 A:middle
The accuracy obtained by both

00:32:43.836 --> 00:32:45.066 A:middle
these models is the same.

00:32:45.546 --> 00:32:47.316 A:middle
But you look at the model sizes

00:32:47.316 --> 00:32:48.496 A:middle
that Natural Language is able to

00:32:48.496 --> 00:32:48.886 A:middle
generate.

00:32:49.446 --> 00:32:50.926 A:middle
It's simply just about 1.4

00:32:50.926 --> 00:32:53.076 A:middle
megabytes of data size, model

00:32:53.076 --> 00:32:53.936 A:middle
size for named entity

00:32:53.936 --> 00:32:55.576 A:middle
recognition and 1.8 megabytes

00:32:55.576 --> 00:32:56.076 A:middle
for chunking.

00:32:56.576 --> 00:32:57.916 A:middle
That saves you an enormous

00:32:57.916 --> 00:32:59.296 A:middle
amount of space within your app

00:32:59.296 --> 00:33:00.056 A:middle
to do other things.


00:32:59.296 --> 00:33:00.056 A:middle
to do other things.

00:33:00.596 --> 00:33:03.976 A:middle
In terms of machine learning

00:33:03.976 --> 00:33:06.586 A:middle
algorithms, we support two

00:33:06.586 --> 00:33:07.516 A:middle
different options.

00:33:07.966 --> 00:33:09.636 A:middle
We can specify this for text

00:33:09.636 --> 00:33:10.216 A:middle
classification.

00:33:10.216 --> 00:33:11.416 A:middle
So for text classification, we

00:33:11.416 --> 00:33:12.486 A:middle
have two different choices.

00:33:12.966 --> 00:33:14.326 A:middle
One is maxEnt, which is an

00:33:14.326 --> 00:33:15.506 A:middle
abbreviation for Maximum

00:33:15.506 --> 00:33:15.956 A:middle
Entropy.

00:33:16.586 --> 00:33:18.596 A:middle
In NLP, we call maxEnt is

00:33:18.596 --> 00:33:19.576 A:middle
essentially a multinomial

00:33:19.576 --> 00:33:20.666 A:middle
logistic regression model.

00:33:20.906 --> 00:33:22.326 A:middle
We just call it Maximum Entropy

00:33:22.326 --> 00:33:22.986 A:middle
in NLP feed.

00:33:23.836 --> 00:33:25.666 A:middle
The other one is CRF, which is

00:33:25.666 --> 00:33:27.046 A:middle
an abbreviation for Conditional

00:33:27.046 --> 00:33:27.546 A:middle
Random Feed.

00:33:28.336 --> 00:33:29.606 A:middle
The choice of these two

00:33:29.606 --> 00:33:30.916 A:middle
algorithms really depends upon

00:33:30.916 --> 00:33:31.496 A:middle
your task.

00:33:31.946 --> 00:33:34.026 A:middle
So we encourage you to try both

00:33:34.026 --> 00:33:35.426 A:middle
these options, build the models.

00:33:35.426 --> 00:33:38.556 A:middle
Now in terms of word tagging,

00:33:38.966 --> 00:33:40.316 A:middle
that is one default option,

00:33:40.346 --> 00:33:41.386 A:middle
which is a conditional random

00:33:41.386 --> 00:33:41.626 A:middle
feed.

00:33:41.996 --> 00:33:43.496 A:middle
When you instantiate an ML word

00:33:43.566 --> 00:33:46.146 A:middle
tagger, specify data to it, the

00:33:46.146 --> 00:33:48.176 A:middle
default model that you get is a

00:33:48.176 --> 00:33:49.096 A:middle
conditional random feed.

00:33:49.956 --> 00:33:51.686 A:middle
Now as I mentioned, the choice

00:33:51.686 --> 00:33:52.736 A:middle
of these algorithms really

00:33:52.736 --> 00:33:54.626 A:middle
depends on your task, but what

00:33:54.626 --> 00:33:56.626 A:middle
I'd like to emphasize is sort of

00:33:56.626 --> 00:33:58.196 A:middle
draw [inaudible] between your

00:33:58.196 --> 00:33:59.536 A:middle
conventional development

00:33:59.536 --> 00:33:59.996 A:middle
process.


00:34:00.316 --> 00:34:01.496 A:middle
So when you have an idea for an

00:34:01.496 --> 00:34:02.836 A:middle
app, you go through a

00:34:02.836 --> 00:34:04.136 A:middle
development cycle, right.

00:34:04.226 --> 00:34:05.676 A:middle
So you can think of machine

00:34:05.676 --> 00:34:07.196 A:middle
learning to be a very similar

00:34:07.246 --> 00:34:08.136 A:middle
sort of a work flow.

00:34:08.235 --> 00:34:10.166 A:middle
Where do you start, you start

00:34:10.166 --> 00:34:12.416 A:middle
with data, and then you have

00:34:12.416 --> 00:34:14.196 A:middle
data, you have to ask a couple

00:34:14.196 --> 00:34:14.876 A:middle
of questions.

00:34:14.876 --> 00:34:16.565 A:middle
You have to validate your

00:34:16.565 --> 00:34:17.186 A:middle
training data.

00:34:17.315 --> 00:34:18.735 A:middle
You have to make sure that there

00:34:18.735 --> 00:34:20.166 A:middle
are no spurious examples in your

00:34:20.166 --> 00:34:21.315 A:middle
data, and it's not tainted.

00:34:22.275 --> 00:34:23.666 A:middle
Once you do that, you can

00:34:23.666 --> 00:34:24.896 A:middle
inspect the number of training

00:34:24.966 --> 00:34:26.315 A:middle
instances per class.

00:34:26.626 --> 00:34:27.735 A:middle
Let's say that your training a

00:34:27.735 --> 00:34:29.206 A:middle
sentiment classification model,

00:34:29.416 --> 00:34:30.646 A:middle
and you have a thousand examples

00:34:30.646 --> 00:34:31.775 A:middle
for positive sentiment, you have

00:34:31.856 --> 00:34:32.926 A:middle
five examples for negative

00:34:32.926 --> 00:34:33.406 A:middle
sentiment.

00:34:33.916 --> 00:34:36.606 A:middle
You can't train a robust model

00:34:36.606 --> 00:34:37.556 A:middle
that can determine or

00:34:37.556 --> 00:34:38.616 A:middle
distinguish between those two

00:34:38.616 --> 00:34:39.196 A:middle
classes.

00:34:39.565 --> 00:34:40.896 A:middle
You have to make sure that the

00:34:40.896 --> 00:34:42.146 A:middle
training samples for each of

00:34:42.146 --> 00:34:43.226 A:middle
those classes are reasonably

00:34:43.226 --> 00:34:43.775 A:middle
balanced.

00:34:44.585 --> 00:34:46.436 A:middle
So once you do that with data,

00:34:46.706 --> 00:34:48.226 A:middle
the next step is training.

00:34:48.536 --> 00:34:50.025 A:middle
As I mentioned before, our

00:34:50.025 --> 00:34:51.446 A:middle
recommendation is that you run

00:34:51.446 --> 00:34:52.396 A:middle
the different options that are

00:34:52.396 --> 00:34:54.525 A:middle
available and figure out what is

00:34:54.525 --> 00:34:56.866 A:middle
good, but how do you define what

00:34:56.866 --> 00:34:57.246 A:middle
is good?

00:34:57.686 --> 00:34:59.566 A:middle
You have to evaluate the model

00:34:59.766 --> 00:35:00.776 A:middle
in order to figure out what


00:34:59.766 --> 00:35:00.776 A:middle
in order to figure out what

00:35:00.776 --> 00:35:01.856 A:middle
suits your application.

00:35:01.926 --> 00:35:03.376 A:middle
So the next step here in the

00:35:03.376 --> 00:35:05.236 A:middle
work flow is evaluation.

00:35:06.956 --> 00:35:09.466 A:middle
Evaluation in convention

00:35:09.466 --> 00:35:10.356 A:middle
[inaudible] for machine learning

00:35:10.356 --> 00:35:11.366 A:middle
is that when you procure your

00:35:11.366 --> 00:35:13.326 A:middle
training data, you split your

00:35:13.326 --> 00:35:15.366 A:middle
data into training set, into a

00:35:15.366 --> 00:35:17.056 A:middle
validation set, and into a test

00:35:17.056 --> 00:35:18.836 A:middle
set, and you typically tune the

00:35:18.836 --> 00:35:20.106 A:middle
parameters of the algorithm

00:35:20.106 --> 00:35:21.566 A:middle
using the validation set, and

00:35:21.566 --> 00:35:22.686 A:middle
you test it on the test set.

00:35:22.956 --> 00:35:24.126 A:middle
So we encourage you to do the

00:35:24.126 --> 00:35:25.606 A:middle
same thing, apply the same sort

00:35:25.606 --> 00:35:27.166 A:middle
of guidelines that have stood

00:35:27.166 --> 00:35:28.286 A:middle
machine learning in good stead

00:35:28.286 --> 00:35:29.016 A:middle
for a long time.

00:35:29.556 --> 00:35:31.026 A:middle
The other thing that we also

00:35:31.026 --> 00:35:32.866 A:middle
encourage you to do is test on

00:35:32.866 --> 00:35:33.796 A:middle
out-of-domain data.

00:35:34.126 --> 00:35:35.066 A:middle
What do I mean by this?

00:35:35.496 --> 00:35:37.156 A:middle
So when you have an idea for an

00:35:37.156 --> 00:35:38.586 A:middle
app, you think of a certain type

00:35:38.586 --> 00:35:39.756 A:middle
of data that is going to be

00:35:39.826 --> 00:35:41.246 A:middle
ingested by your machine

00:35:41.246 --> 00:35:42.496 A:middle
learning model.

00:35:42.496 --> 00:35:43.836 A:middle
Now let's say you're building an

00:35:43.836 --> 00:35:46.056 A:middle
app for hotel reviews, and you

00:35:46.056 --> 00:35:48.806 A:middle
want to classify hotel reviews

00:35:48.806 --> 00:35:50.466 A:middle
into different sorts of ratings.

00:35:50.706 --> 00:35:53.186 A:middle
And the user throws a data that

00:35:53.186 --> 00:35:54.926 A:middle
is completely out of domain.

00:35:54.926 --> 00:35:56.106 A:middle
Perhaps it's something to do

00:35:56.106 --> 00:35:57.856 A:middle
with a restaurant review or a

00:35:57.856 --> 00:35:59.446 A:middle
movie review, is your model

00:35:59.446 --> 00:36:01.306 A:middle
robust enough to handle it.


00:35:59.446 --> 00:36:01.306 A:middle
robust enough to handle it.

00:36:01.646 --> 00:36:02.646 A:middle
That's a question that you ought

00:36:02.646 --> 00:36:03.366 A:middle
to ask yourself.

00:36:04.006 --> 00:36:06.066 A:middle
And the final step is well in a

00:36:06.166 --> 00:36:07.156 A:middle
conventional development

00:36:07.156 --> 00:36:09.086 A:middle
workflow you write patches, you

00:36:09.086 --> 00:36:11.516 A:middle
fix bugs, and you update your

00:36:11.516 --> 00:36:11.656 A:middle
app.

00:36:12.406 --> 00:36:13.576 A:middle
How do you do that with machine

00:36:13.576 --> 00:36:13.846 A:middle
learning?

00:36:14.096 --> 00:36:17.686 A:middle
Well, the way to do that or fix

00:36:17.956 --> 00:36:19.416 A:middle
issues with machine learning is

00:36:19.416 --> 00:36:21.276 A:middle
to find out where your models do

00:36:21.276 --> 00:36:22.876 A:middle
not perform well, and you have

00:36:22.876 --> 00:36:24.076 A:middle
to supplement it with the right

00:36:24.076 --> 00:36:24.706 A:middle
sort of data.

00:36:25.206 --> 00:36:26.776 A:middle
By adding data and retraining

00:36:26.776 --> 00:36:28.346 A:middle
your model, you can essentially

00:36:28.346 --> 00:36:29.716 A:middle
get a new model out.

00:36:29.716 --> 00:36:31.046 A:middle
So it's, as I mentioned, it's

00:36:31.046 --> 00:36:32.266 A:middle
very similar to sort of the

00:36:32.266 --> 00:36:34.196 A:middle
development workflow, and they

00:36:34.266 --> 00:36:34.676 A:middle
are very [inaudible].

00:36:34.676 --> 00:36:36.306 A:middle
So you can think of it as part

00:36:36.306 --> 00:36:37.786 A:middle
of your fabric if you're

00:36:38.176 --> 00:36:39.466 A:middle
employing machine learning

00:36:39.466 --> 00:36:40.906 A:middle
models as part of your app, you

00:36:40.906 --> 00:36:42.596 A:middle
can just combine it with the

00:36:42.596 --> 00:36:43.506 A:middle
word process itself.

00:36:44.006 --> 00:36:46.876 A:middle
The last thing I'd like to

00:36:46.876 --> 00:36:48.736 A:middle
emphasize here is privacy.

00:36:49.526 --> 00:36:50.706 A:middle
So everything that you saw in

00:36:50.706 --> 00:36:53.086 A:middle
this session, all of the machine

00:36:53.086 --> 00:36:54.576 A:middle
learning and Natural Language

00:36:54.576 --> 00:36:56.726 A:middle
processing happens completely on

00:36:56.726 --> 00:36:57.146 A:middle
device.

00:36:57.946 --> 00:36:59.246 A:middle
So we at Apple take privacy

00:36:59.246 --> 00:37:01.516 A:middle
really seriously, and this is a


00:36:59.246 --> 00:37:01.516 A:middle
really seriously, and this is a

00:37:01.516 --> 00:37:03.216 A:middle
remarkable opportunity to use

00:37:03.216 --> 00:37:04.456 A:middle
machine learning completely on

00:37:04.456 --> 00:37:05.546 A:middle
device to protect user's

00:37:05.546 --> 00:37:05.996 A:middle
privacy.

00:37:06.226 --> 00:37:09.126 A:middle
So in that vein, Natural

00:37:09.126 --> 00:37:10.716 A:middle
Language is another step towards

00:37:10.716 --> 00:37:11.976 A:middle
privacy preserving machine

00:37:11.976 --> 00:37:13.556 A:middle
learning but in this case apply

00:37:13.556 --> 00:37:14.846 A:middle
to NLP.

00:37:15.916 --> 00:37:19.266 A:middle
So in summary, we talked about a

00:37:19.266 --> 00:37:20.986 A:middle
new framework called Natural

00:37:20.986 --> 00:37:21.746 A:middle
Language framework.

00:37:22.126 --> 00:37:23.726 A:middle
It's tightly integrated with the

00:37:23.726 --> 00:37:24.936 A:middle
Apple machine learning

00:37:24.936 --> 00:37:25.626 A:middle
[inaudible].

00:37:25.626 --> 00:37:27.196 A:middle
You can now train models using

00:37:27.196 --> 00:37:29.536 A:middle
Create ML and then use those

00:37:29.536 --> 00:37:30.906 A:middle
models either with the Core ML

00:37:30.906 --> 00:37:32.816 A:middle
APIs or with Natural Language.

00:37:33.826 --> 00:37:35.446 A:middle
The models that we generate

00:37:35.446 --> 00:37:36.996 A:middle
using Natural Language and the

00:37:36.996 --> 00:37:38.386 A:middle
APIs are highly performed and

00:37:38.386 --> 00:37:40.226 A:middle
optimized on Apple hardware

00:37:40.326 --> 00:37:41.516 A:middle
across all the platforms.

00:37:41.976 --> 00:37:44.866 A:middle
And finally, it supports privacy

00:37:45.026 --> 00:37:46.066 A:middle
because all of the machine

00:37:46.066 --> 00:37:47.706 A:middle
learning in NLP happens on

00:37:47.706 --> 00:37:48.296 A:middle
user's device.

00:37:48.916 --> 00:37:52.076 A:middle
So there's more information

00:37:52.076 --> 00:37:52.376 A:middle
here.

00:37:52.376 --> 00:37:53.836 A:middle
We have a Natural Language lab

00:37:53.836 --> 00:37:55.396 A:middle
tomorrow, so we encourage you to

00:37:55.396 --> 00:37:57.016 A:middle
try out these APIs and come talk

00:37:57.016 --> 00:37:58.726 A:middle
to us and ask us questions about

00:37:58.726 --> 00:38:00.096 A:middle
where you'd like enhancements or


00:37:58.726 --> 00:38:00.096 A:middle
where you'd like enhancements or

00:38:00.096 --> 00:38:01.136 A:middle
perhaps some sort of

00:38:01.136 --> 00:38:02.256 A:middle
consultation with respect to

00:38:02.256 --> 00:38:03.156 A:middle
your app.

00:38:03.666 --> 00:38:04.766 A:middle
We also have a machine learning

00:38:04.766 --> 00:38:06.596 A:middle
get together, and there's a

00:38:06.936 --> 00:38:08.406 A:middle
subsequent [inaudible] Create ML

00:38:08.406 --> 00:38:09.666 A:middle
lab that's happening right now.

00:38:10.046 --> 00:38:11.476 A:middle
So you can continue coming and

00:38:11.476 --> 00:38:12.856 A:middle
talking to us as part of that

00:38:12.856 --> 00:38:13.126 A:middle
lab.

00:38:13.766 --> 00:38:15.466 A:middle
Thank you for your attention.

00:38:15.566 --> 00:38:15.746 A:middle
Thanks.

00:38:16.016 --> 00:38:18.000 A:middle
[ Applause ]
