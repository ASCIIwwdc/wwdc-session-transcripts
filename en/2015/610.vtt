WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:25.516 --> 00:00:31.016 A:middle
[ Applause ]

00:00:31.516 --> 00:00:32.536 A:middle
&gt;&gt; PHILIP BENNETT: Good morning,

00:00:32.536 --> 00:00:36.176 A:middle
and welcome to Metal Performance
Optimization Techniques.

00:00:36.526 --> 00:00:39.446 A:middle
I'm Phil Bennett of the GPU
Software Performance Group,

00:00:39.936 --> 00:00:42.936 A:middle
and I will be joined shortly by
our special guest Serhat Tekin

00:00:43.016 --> 00:00:46.916 A:middle
from the GPU Software
Developer Technologies Group

00:00:46.916 --> 00:00:50.876 A:middle
and he will be giving a demo
of a great new tool you can use

00:00:50.876 --> 00:00:52.126 A:middle
to profile your Metal apps.

00:00:52.126 --> 00:00:54.606 A:middle
I'm sure you're going
to love it.

00:00:54.996 --> 00:00:58.616 A:middle
So, Metal at the WWDC,
the story so far.

00:00:59.196 --> 00:01:03.136 A:middle
In What's New in Metal Part 1,
we covered great new features


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:00:59.196 --> 00:01:03.136 A:middle
In What's New in Metal Part 1,
we covered great new features

00:01:03.226 --> 00:01:10.186 A:middle
that have been added to Metal
as of iOS 9 and OS X El Capitan.

00:01:10.286 --> 00:01:11.816 A:middle
In What's New in Metal Part 2,

00:01:11.906 --> 00:01:14.526 A:middle
we introduced two new
frameworks, MetalKit

00:01:15.036 --> 00:01:16.506 A:middle
and Metal performance shaders.

00:01:16.866 --> 00:01:19.296 A:middle
These make developing
Metal apps even easier.

00:01:20.506 --> 00:01:22.396 A:middle
In this our final session,

00:01:22.546 --> 00:01:26.706 A:middle
we will be reviewing what tools
are available for debugging

00:01:26.706 --> 00:01:29.196 A:middle
and profiling your Metal
apps and we're going

00:01:29.196 --> 00:01:30.746 A:middle
to explore some best practices

00:01:30.746 --> 00:01:34.416 A:middle
from getting optimal performance
from your Metal apps.

00:01:35.276 --> 00:01:37.136 A:middle
So let's take a look
at the tools.

00:01:38.986 --> 00:01:42.906 A:middle
Now, if you have been doing any
Metal app development in iOS,

00:01:42.966 --> 00:01:45.836 A:middle
you are likely to be
familiar with Xcode

00:01:45.836 --> 00:01:47.586 A:middle
and its suite of Metal tools.

00:01:48.226 --> 00:01:52.796 A:middle
Now, we are going
to take a quick look

00:01:52.796 --> 00:01:54.056 A:middle
at the frame debugger.

00:01:55.686 --> 00:01:58.596 A:middle
So what we have here is a
capture of a single frame

00:01:58.596 --> 00:02:01.686 A:middle
from a Metal app,
and on the left,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:01:58.596 --> 00:02:01.686 A:middle
from a Metal app,
and on the left,

00:02:02.106 --> 00:02:06.206 A:middle
we have the frame navigator
which shows all of the states

00:02:06.206 --> 00:02:08.506 A:middle
and Draw calls present
in the frame.

00:02:08.925 --> 00:02:13.816 A:middle
These are grouped by render
encoder, command buffer,

00:02:13.816 --> 00:02:16.096 A:middle
and if you have been
using debug labels,

00:02:16.096 --> 00:02:19.526 A:middle
they will be grouped
by debug groups also.

00:02:21.406 --> 00:02:24.016 A:middle
Next we have the render
attachment viewer,

00:02:24.086 --> 00:02:27.836 A:middle
which shows all of the
color attachments associated

00:02:27.836 --> 00:02:30.206 A:middle
with the current render pass
in addition to any depth

00:02:30.256 --> 00:02:34.656 A:middle
and stencil attachments, and it
shows this wire frame highlight

00:02:34.696 --> 00:02:35.766 A:middle
of the current Draw call,

00:02:36.066 --> 00:02:38.536 A:middle
which makes navigating
your frame very convenient.

00:02:40.106 --> 00:02:43.456 A:middle
Next we have the
resource inspector

00:02:43.916 --> 00:02:46.836 A:middle
where you can inspect all of
the resources used by your app,

00:02:48.406 --> 00:02:53.106 A:middle
from buffers to textures
and render attachments.

00:02:53.106 --> 00:02:55.676 A:middle
You can view all
different formats,

00:02:55.676 --> 00:02:59.066 A:middle
you can individual
bitmap levels, cube maps,

00:02:59.436 --> 00:03:01.986 A:middle
TD arrays, it's fully featured.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:02:59.436 --> 00:03:01.986 A:middle
TD arrays, it's fully featured.

00:03:02.626 --> 00:03:06.586 A:middle
And then we have the state
inspector, which allows you

00:03:06.586 --> 00:03:10.396 A:middle
to inspect properties of all of
the Metal objects in your app.

00:03:11.826 --> 00:03:14.586 A:middle
Moving on, we have
the GPU report,

00:03:15.096 --> 00:03:17.026 A:middle
which gives you a frames
per second measurement

00:03:17.026 --> 00:03:21.766 A:middle
of the current frame and gives
you timings for CPU and GPU.

00:03:22.006 --> 00:03:27.266 A:middle
In addition, it also shows
the most expensive render

00:03:27.266 --> 00:03:30.456 A:middle
and compute encoders in your
frame so you can help narrow

00:03:30.456 --> 00:03:33.746 A:middle
down which shaders and
which Draw calls are the

00:03:33.746 --> 00:03:34.536 A:middle
most expensive.

00:03:36.676 --> 00:03:40.676 A:middle
And finally, we have the
shader profiler and editor.

00:03:41.236 --> 00:03:44.456 A:middle
And this is a wonderful
tool for both debugging

00:03:44.456 --> 00:03:48.156 A:middle
and profiling your shaders as it
allows you to tweak your shaders

00:03:48.326 --> 00:03:51.426 A:middle
and recompile them on the
fly, thus saving you having

00:03:51.526 --> 00:03:52.816 A:middle
to recompile your app.

00:03:53.336 --> 00:03:54.436 A:middle
It's really useful.

00:03:56.286 --> 00:03:58.206 A:middle
And as you probably
are aware now,

00:03:58.266 --> 00:04:00.566 A:middle
all of these great
tools are now available


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:58.266 --> 00:04:00.566 A:middle
all of these great
tools are now available

00:04:00.566 --> 00:04:05.606 A:middle
for debugging your Metal
apps on OS X El Capitan.

00:04:05.716 --> 00:04:09.276 A:middle
So Instruments is a
great companion to Xcode

00:04:09.326 --> 00:04:11.936 A:middle
as it allows you to profile
your app's performance

00:04:12.316 --> 00:04:16.005 A:middle
across the entire system,
and now we are enabling you

00:04:16.005 --> 00:04:20.426 A:middle
to profile Metal performance
in a similar manner with this,

00:04:20.426 --> 00:04:22.886 A:middle
the Metal System
Trace Instruments.

00:04:23.396 --> 00:04:25.956 A:middle
It's a brand-new tool for iOS 9.

00:04:26.466 --> 00:04:28.376 A:middle
It allows you to
profile your Metal apps

00:04:28.636 --> 00:04:30.346 A:middle
across your CPU and GPU.

00:04:30.346 --> 00:04:31.436 A:middle
Let's take a look here.

00:04:32.236 --> 00:04:37.376 A:middle
We can start by profiling Metal
API usage in the application,

00:04:38.686 --> 00:04:42.156 A:middle
down to the driver,
right onto the GPU

00:04:42.156 --> 00:04:45.046 A:middle
where we can see the
individual processing phases,

00:04:45.046 --> 00:04:47.596 A:middle
verse X fragments, and
optionally computes,

00:04:48.346 --> 00:04:50.306 A:middle
and then onto the
actual display hardware.

00:04:51.066 --> 00:04:54.176 A:middle
Now, here to give
us a demonstration

00:04:54.176 --> 00:04:55.176 A:middle
of this great new tool,

00:04:55.176 --> 00:04:58.026 A:middle
please welcome Serhat
Tekin to the stage.

00:04:59.016 --> 00:05:03.236 A:middle
[ Applause ]


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:59.016 --> 00:05:03.236 A:middle
[ Applause ]

00:05:03.736 --> 00:05:05.586 A:middle
&gt;&gt; SERHAT TEKIN: Thank you,
Philip, and hello, everyone.

00:05:06.606 --> 00:05:08.916 A:middle
I have something really
cool to show you today,

00:05:08.916 --> 00:05:11.666 A:middle
and it's brand new,
it's our latest addition

00:05:11.666 --> 00:05:15.616 A:middle
to our Metal development
tools, Metal System Trace.

00:05:16.656 --> 00:05:19.356 A:middle
Metal System Trace is
a performance analysis

00:05:19.356 --> 00:05:24.086 A:middle
and tracing tool for your
Metal iOS apps and is available

00:05:24.086 --> 00:05:25.096 A:middle
as part of Instruments.

00:05:26.056 --> 00:05:29.286 A:middle
It lets you get a system-wide
overview of your application

00:05:29.326 --> 00:05:35.636 A:middle
over time also giving you an
in-depth look at the graphics

00:05:35.636 --> 00:05:37.406 A:middle
down to the microsecond level.

00:05:37.406 --> 00:05:39.226 A:middle
It's important that
I should stress this.

00:05:40.396 --> 00:05:43.236 A:middle
This is available for the first
time ever on our platform.

00:05:43.456 --> 00:05:46.836 A:middle
This is all thanks
to Xcode 7 and iOS 9.

00:05:47.486 --> 00:05:50.696 A:middle
So without further ado, let's
go ahead and give it a shot.

00:05:52.266 --> 00:05:55.206 A:middle
So I'm going to launch
Instruments,

00:05:55.546 --> 00:05:57.476 A:middle
and we are at the
template chooser.

00:05:58.426 --> 00:06:01.556 A:middle
You can notice that we have
a new template icon here,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:05:58.426 --> 00:06:01.556 A:middle
You can notice that we have
a new template icon here,

00:06:01.556 --> 00:06:03.296 A:middle
Metal icon for Metal
System Trace.

00:06:03.296 --> 00:06:06.246 A:middle
I will go ahead and choose that.

00:06:06.446 --> 00:06:08.026 A:middle
Those of you familiar

00:06:08.026 --> 00:06:11.676 A:middle
with Instruments will realize
I just created a new document

00:06:11.736 --> 00:06:15.486 A:middle
with four instruments
in it, as you can see

00:06:15.486 --> 00:06:16.986 A:middle
on the left-hand side
of the timeline here.

00:06:18.036 --> 00:06:20.806 A:middle
I will give you a quick tour of
these instruments and the data

00:06:20.806 --> 00:06:22.236 A:middle
that they present
on the timeline.

00:06:22.236 --> 00:06:26.626 A:middle
So let's go ahead and select
my Metal app on the iPad

00:06:26.626 --> 00:06:32.116 A:middle
as my target app
and start recording.

00:06:33.176 --> 00:06:33.946 A:middle
All right.

00:06:34.726 --> 00:06:37.256 A:middle
Now, Metal System
Trace is set to record

00:06:37.256 --> 00:06:39.636 A:middle
in one instrument
called Windowed Mode.

00:06:39.896 --> 00:06:43.036 A:middle
It's essentially capturing
the trace into a ring buffer.

00:06:43.036 --> 00:06:45.436 A:middle
This lets you record
indefinitely.

00:06:45.536 --> 00:06:50.366 A:middle
And the important point here
is that when you see a problem

00:06:50.366 --> 00:06:52.566 A:middle
that you want to investigate,
you can stop recording.

00:06:53.296 --> 00:06:55.886 A:middle
At that point, Instruments
will gather all

00:06:55.886 --> 00:06:58.736 A:middle
of the trace data collected,
process it for a while,

00:06:58.736 --> 00:07:00.946 A:middle
and they will end up with a
timeline that looks like this.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:58.736 --> 00:07:00.946 A:middle
and they will end up with a
timeline that looks like this.

00:07:01.016 --> 00:07:04.736 A:middle
So there is quite a lot of stuff
going on here, so I will zoom

00:07:04.736 --> 00:07:05.806 A:middle
in to get a better look.

00:07:06.876 --> 00:07:09.146 A:middle
I can do that by holding
down the Option key

00:07:09.836 --> 00:07:12.556 A:middle
and selecting an area of
interest in the timeline

00:07:12.556 --> 00:07:13.456 A:middle
that I want to zoom in.

00:07:14.486 --> 00:07:17.526 A:middle
I can navigate the timeline
using the tracker gestures,

00:07:17.886 --> 00:07:22.436 A:middle
two fingers swipe to
scroll and pinch to zoom.

00:07:23.016 --> 00:07:24.966 A:middle
And you can see that
I get more detail

00:07:24.966 --> 00:07:29.806 A:middle
on the timeline as
I zoom further in.

00:07:30.176 --> 00:07:32.076 A:middle
So what are we looking at here?

00:07:33.076 --> 00:07:36.456 A:middle
Essentially what we have
here is an in-depth look

00:07:36.456 --> 00:07:40.746 A:middle
of your Metal application's
graphics workload over time

00:07:40.746 --> 00:07:43.926 A:middle
across all of the layers
of the graphics stack.

00:07:44.596 --> 00:07:48.636 A:middle
The different colors that we go

00:07:48.636 --> 00:07:53.016 A:middle
through in the timeline
represent different workloads

00:07:53.016 --> 00:07:53.936 A:middle
for individual frames.

00:07:55.036 --> 00:07:57.726 A:middle
And the tracks themselves
are fairly intuitive.

00:07:58.616 --> 00:08:02.636 A:middle
Each box you see here represents
an item's trace relative start


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:07:58.616 --> 00:08:02.636 A:middle
Each box you see here represents
an item's trace relative start

00:08:02.636 --> 00:08:05.846 A:middle
time, end time, and
how long it took.

00:08:06.406 --> 00:08:09.236 A:middle
Starting from the top
and working our way down,

00:08:09.236 --> 00:08:12.946 A:middle
we have your application's
usage of the Metal framework.

00:08:13.876 --> 00:08:18.266 A:middle
Next, we have the graphics
driver processing your command

00:08:18.266 --> 00:08:21.716 A:middle
buffers, and if you have any
shader compilation activity

00:08:21.716 --> 00:08:25.436 A:middle
midframe, it also
shows up in the track.

00:08:25.436 --> 00:08:28.086 A:middle
This is followed by
the GPU hardware track,

00:08:28.556 --> 00:08:30.466 A:middle
which shows your Render

00:08:30.466 --> 00:08:33.186 A:middle
and Compute commands
executing on the GPU.

00:08:33.706 --> 00:08:37.116 A:middle
And finally we have the
display surfaces track.

00:08:37.116 --> 00:08:40.316 A:middle
Essentially, this is your frame
getting displayed on the device.

00:08:40.476 --> 00:08:42.806 A:middle
All right.

00:08:43.506 --> 00:08:47.266 A:middle
So another thing you can
see here is these labels.

00:08:47.386 --> 00:08:52.276 A:middle
Now, note that these two labels
here, shadow buffer and G-buffer

00:08:52.276 --> 00:08:57.056 A:middle
and lighting, are labels I
assigned myself to my encoders

00:08:57.056 --> 00:09:00.486 A:middle
in my Metal code using the
encoder's Label property.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:08:57.056 --> 00:09:00.486 A:middle
in my Metal code using the
encoder's Label property.

00:09:01.726 --> 00:09:06.636 A:middle
These labels propagate their
way down the pipeline along

00:09:06.636 --> 00:09:08.456 A:middle
with the workload they
are associated with,

00:09:08.796 --> 00:09:10.296 A:middle
which makes it very easy

00:09:10.296 --> 00:09:12.126 A:middle
to track your scenes
rendering passes here

00:09:12.126 --> 00:09:13.156 A:middle
in Metal System Trace.

00:09:13.156 --> 00:09:15.136 A:middle
I highly recommend
taking advantage of this.

00:09:15.916 --> 00:09:19.176 A:middle
And if anything is too
small to fit its label,

00:09:20.056 --> 00:09:23.936 A:middle
you can always go hover over
the ruler and see a tool tip

00:09:24.006 --> 00:09:29.856 A:middle
that displays both the label and
the duration at the same time.

00:09:30.066 --> 00:09:36.176 A:middle
The order of the tracks
here basically map

00:09:36.346 --> 00:09:40.096 A:middle
to the same order your Metal
commands would work their way

00:09:40.226 --> 00:09:41.756 A:middle
down the graphics pipeline.

00:09:42.306 --> 00:09:46.486 A:middle
So let us go ahead and
follow this command buffer

00:09:46.916 --> 00:09:47.466 A:middle
down the pipe.

00:09:47.466 --> 00:09:53.886 A:middle
So at the top track I can
see my application's use

00:09:53.926 --> 00:09:56.136 A:middle
of Metal command
buffers and encoders,

00:09:56.966 --> 00:10:00.316 A:middle
specifically what I see
here is the creation time


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:09:56.966 --> 00:10:00.316 A:middle
specifically what I see
here is the creation time

00:10:00.316 --> 00:10:02.976 A:middle
and submission time for
both my command buffers

00:10:03.046 --> 00:10:04.336 A:middle
and rendering compute encoders.

00:10:05.376 --> 00:10:07.746 A:middle
At the top I have
my command buffer,

00:10:08.296 --> 00:10:14.986 A:middle
and at the bottom I have my
relevant encoders created

00:10:14.986 --> 00:10:17.616 A:middle
by this command buffer
directly nested underneath.

00:10:18.336 --> 00:10:24.116 A:middle
Now, note this arrow here
at the submission time

00:10:24.116 --> 00:10:27.376 A:middle
of the command buffer
going to the next track.

00:10:28.226 --> 00:10:30.156 A:middle
Dependencies between
different levels

00:10:30.156 --> 00:10:32.296 A:middle
of the pipeline are
represented by these arrows

00:10:32.396 --> 00:10:33.826 A:middle
in Metal System Trace.

00:10:34.436 --> 00:10:37.406 A:middle
So, for instance, when this
command buffer is submitted,

00:10:37.876 --> 00:10:40.926 A:middle
its next stop is going to be
the graphics display driver,

00:10:40.926 --> 00:10:44.926 A:middle
if I can zoom in there
and get a better look.

00:10:45.866 --> 00:10:47.776 A:middle
Look at how much
we are taking here.

00:10:47.776 --> 00:10:50.916 A:middle
It's really, really
fast, and they are still

00:10:50.916 --> 00:10:52.856 A:middle
on the CPU side barely
consuming anything.

00:10:54.066 --> 00:11:00.246 A:middle
Similarly, I can go and follow
the arrows once the encoders are


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:54.066 --> 00:11:00.246 A:middle
Similarly, I can go and follow
the arrows once the encoders are

00:11:00.246 --> 00:11:00.986 A:middle
done processing.

00:11:01.146 --> 00:11:04.006 A:middle
The encoders are going to get
submitted to the GPU track.

00:11:05.066 --> 00:11:06.676 A:middle
Following the arrows
the same way,

00:11:07.476 --> 00:11:12.526 A:middle
I can see my encoders
getting processed on my GPU.

00:11:13.546 --> 00:11:17.106 A:middle
This GPU track is separated
into three different lanes,

00:11:17.166 --> 00:11:18.536 A:middle
one for vertex processing,

00:11:18.536 --> 00:11:20.826 A:middle
one for fragment,
and one for compute.

00:11:22.026 --> 00:11:26.506 A:middle
So, for instance, here I can see
my shadow buffer rendering code

00:11:26.506 --> 00:11:29.146 A:middle
for my shadow buffer pass going

00:11:29.146 --> 00:11:31.646 A:middle
through its vertex
processing phase and moving

00:11:31.646 --> 00:11:34.226 A:middle
on to the fragment phase,
which happens to overlap

00:11:34.226 --> 00:11:35.876 A:middle
with my G-buffer and
lighting phase as well.

00:11:36.406 --> 00:11:39.646 A:middle
Something that is desirable.

00:11:39.646 --> 00:11:45.076 A:middle
A quick note here is that the
vertex fragment also compute

00:11:45.666 --> 00:11:51.106 A:middle
processing costs have more than
just the shader processing time.

00:11:51.266 --> 00:11:53.636 A:middle
For instance, we
are running on iOS,

00:11:53.856 --> 00:11:56.216 A:middle
and it's a tile-based
deferred architecture,

00:11:56.626 --> 00:11:59.066 A:middle
so the vertex processing
cost is going

00:11:59.066 --> 00:12:03.436 A:middle
to include the tiling
cost as well.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:11:59.066 --> 00:12:03.436 A:middle
to include the tiling
cost as well.

00:12:03.436 --> 00:12:05.996 A:middle
It's something to keep in mind.

00:12:05.996 --> 00:12:13.346 A:middle
Finally, once my frame is done
rendering, the surface is going

00:12:13.346 --> 00:12:15.486 A:middle
to end up on the
display, which is shown

00:12:15.486 --> 00:12:17.446 A:middle
in the track at the bottom.

00:12:18.776 --> 00:12:22.576 A:middle
Essentially, it's showing me
what time my frame was swapped

00:12:22.576 --> 00:12:24.576 A:middle
onto the display and how
long it stayed there.

00:12:25.616 --> 00:12:28.236 A:middle
Underneath that, we
have the resync track,

00:12:29.276 --> 00:12:32.426 A:middle
which shows us the
resync intervals separated

00:12:32.426 --> 00:12:39.366 A:middle
by these spikes that correspond
to individual resync events.

00:12:39.476 --> 00:12:42.926 A:middle
Finally, at the bottom,
we have our detail view.

00:12:43.906 --> 00:12:44.996 A:middle
The detail view is similar

00:12:44.996 --> 00:12:46.856 A:middle
to what you would see
in other instruments.

00:12:46.856 --> 00:12:49.336 A:middle
It offers contextual
detail based

00:12:49.336 --> 00:12:50.936 A:middle
on the instrument use selected.

00:12:51.516 --> 00:12:52.426 A:middle
For instance right now,

00:12:52.426 --> 00:12:55.046 A:middle
I have the Metal application
instrument selected,

00:12:55.116 --> 00:12:59.006 A:middle
so I can go ahead and expand
this to see all of my frames

00:12:59.466 --> 00:13:01.556 A:middle
and all of the command
buffers and encoders along


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:12:59.466 --> 00:13:01.556 A:middle
and all of the command
buffers and encoders along

00:13:01.556 --> 00:13:02.676 A:middle
with the hierarchy involved.

00:13:03.556 --> 00:13:07.746 A:middle
This track is useful if you want
to see, say, precise timing.

00:13:07.816 --> 00:13:09.156 A:middle
If I go to the encoder list,

00:13:09.606 --> 00:13:11.226 A:middle
precise creation
submission timings

00:13:11.226 --> 00:13:13.096 A:middle
or what process something
originated from.

00:13:13.296 --> 00:13:15.806 A:middle
It's very useful.

00:13:15.996 --> 00:13:21.576 A:middle
Cool! So this timeline look

00:13:22.636 --> 00:13:27.316 A:middle
at the graphics pipeline is
an incredibly powerful tool.

00:13:27.606 --> 00:13:31.446 A:middle
It's available for the first
time with iOS 9 and Metal.

00:13:32.786 --> 00:13:35.586 A:middle
So how do you use this to
help you solve your problems?

00:13:36.056 --> 00:13:37.876 A:middle
Or how does a problem app look?

00:13:37.876 --> 00:13:40.456 A:middle
Let me go ahead and
open a different trace

00:13:40.666 --> 00:13:41.636 A:middle
to show you that.

00:13:42.116 --> 00:13:45.686 A:middle
In a couple of minutes, Philip
will go into a lot more detail

00:13:45.686 --> 00:13:48.446 A:middle
than I will about
Metal performance

00:13:49.316 --> 00:13:52.826 A:middle
and how you can use this
tool for that purpose.

00:13:53.896 --> 00:13:55.976 A:middle
But I'm going to give
you a quick overview

00:13:55.976 --> 00:14:00.426 A:middle
of the tool's workflow and
a quick couple of tips.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:13:55.976 --> 00:14:00.426 A:middle
of the tool's workflow and
a quick couple of tips.

00:14:00.696 --> 00:14:03.676 A:middle
First and foremost, you
need to be concerned

00:14:03.676 --> 00:14:05.706 A:middle
about your CPU and
GPU parallelism.

00:14:06.846 --> 00:14:09.296 A:middle
You can see that this
trace that I opened,

00:14:09.576 --> 00:14:11.536 A:middle
labeled Problem Run
appropriately,

00:14:12.286 --> 00:14:15.866 A:middle
is already sparser than
the last trace we took.

00:14:16.286 --> 00:14:18.956 A:middle
This is because we have
a number of sync points

00:14:20.526 --> 00:14:22.466 A:middle
where the CPU is actually
waiting on the GPU.

00:14:22.516 --> 00:14:24.496 A:middle
You need to make sure
you eliminate these.

00:14:26.236 --> 00:14:32.486 A:middle
Also, another useful thing
to look for is the pattern

00:14:32.486 --> 00:14:33.816 A:middle
that you see on the timeline.

00:14:34.326 --> 00:14:37.916 A:middle
These frames are all part of the
same scene, so they are going

00:14:37.916 --> 00:14:39.716 A:middle
to have really high
temporal locality.

00:14:40.466 --> 00:14:42.846 A:middle
Any divergence you
see might point

00:14:42.846 --> 00:14:44.636 A:middle
at a problem you
should investigate.

00:14:45.176 --> 00:14:48.646 A:middle
Another important thing is
the display surfaces track.

00:14:50.106 --> 00:14:55.966 A:middle
So ideally, if your frame rate
target is 60 frames per second,

00:14:56.106 --> 00:14:59.676 A:middle
these surfaces should
be staying on display


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:15:00.596 --> 00:15:02.576 A:middle
for a single VSync interval.

00:15:03.146 --> 00:15:07.466 A:middle
So we should be seeing
surfaces getting swapped

00:15:07.466 --> 00:15:08.656 A:middle
at every VSync interval.

00:15:08.936 --> 00:15:11.476 A:middle
This particular frame, for
instance, stayed on for three,

00:15:11.476 --> 00:15:13.396 A:middle
so we are running at 20 fps.

00:15:16.336 --> 00:15:21.166 A:middle
Another thing that pretty useful
is the shader compilation track

00:15:21.466 --> 00:15:23.976 A:middle
directly shows you if the
shader compiler is kicking

00:15:23.976 --> 00:15:25.896 A:middle
in at any time during
your trace.

00:15:26.616 --> 00:15:27.566 A:middle
One thing that you want

00:15:27.566 --> 00:15:31.326 A:middle
to particularly avoid
is submitting work

00:15:31.326 --> 00:15:34.006 A:middle
to the shader compiler
midframe because it's going

00:15:34.006 --> 00:15:37.396 A:middle
to waste CPU cycles you
can use on other things.

00:15:38.076 --> 00:15:40.806 A:middle
Phil will explain this in a
couple more minutes in detail.

00:15:41.746 --> 00:15:46.946 A:middle
Finally, you should aim to
profile early and often.

00:15:47.826 --> 00:15:51.306 A:middle
A workflow like this will
help you figure out problems

00:15:51.816 --> 00:15:54.406 A:middle
as they occur and make
it easier to fix them.

00:15:54.406 --> 00:15:58.556 A:middle
And Xcode helps you with that by
offering a profile launch option

00:15:58.616 --> 00:15:59.716 A:middle
for your build products.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:00.176 --> 00:16:03.246 A:middle
It's going to automatically
build a release version

00:16:03.246 --> 00:16:05.346 A:middle
of your app, installed
on the device,

00:16:05.346 --> 00:16:08.986 A:middle
and start an instruments run
with a template of your choice.

00:16:10.366 --> 00:16:10.996 A:middle
All right.

00:16:11.086 --> 00:16:13.776 A:middle
So you have our first look
at Metal System Trace.

00:16:15.096 --> 00:16:19.106 A:middle
Available for all of your
Metal-capable iOS devices

00:16:19.106 --> 00:16:19.436 A:middle
out there.

00:16:20.546 --> 00:16:21.346 A:middle
Please give it a try.

00:16:21.346 --> 00:16:24.046 A:middle
We are looking forward to
your feedback and suggestions.

00:16:24.676 --> 00:16:27.606 A:middle
Now, I will leave the
stage back to Phil,

00:16:28.136 --> 00:16:32.816 A:middle
who will demonstrate a couple
of key Metal performance issues

00:16:33.276 --> 00:16:35.486 A:middle
and how you can use our
tools to identify these.

00:16:36.056 --> 00:16:36.336 A:middle
Thank you.

00:16:37.476 --> 00:16:43.196 A:middle
[ Applause ]

00:16:43.696 --> 00:16:44.276 A:middle
&gt;&gt; PHILIP BENNETT:
Thank you, Serhat,

00:16:44.276 --> 00:16:45.526 A:middle
that was very informative.

00:16:46.926 --> 00:16:51.066 A:middle
Now, we are going to cover the
aforementioned Metal performance

00:16:51.186 --> 00:16:56.376 A:middle
best practices, and we
are going to use the tools

00:16:56.376 --> 00:16:58.646 A:middle
to see how we can diagnose

00:16:58.716 --> 00:17:00.966 A:middle
and hopefully follow
these best practices.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:58.716 --> 00:17:00.966 A:middle
and hopefully follow
these best practices.

00:17:01.386 --> 00:17:06.656 A:middle
So let me introduce our sample
app, or rather a system trace

00:17:06.656 --> 00:17:10.685 A:middle
of our sample app, and
immediately we can see

00:17:10.685 --> 00:17:12.736 A:middle
that there are several
performance issues.

00:17:13.165 --> 00:17:15.376 A:middle
To begin with, there
is no parallelism

00:17:15.376 --> 00:17:17.435 A:middle
between the CPU and the GPU.

00:17:17.976 --> 00:17:21.435 A:middle
These are incredibly
powerful devices,

00:17:21.526 --> 00:17:23.066 A:middle
and the only way you are going

00:17:23.066 --> 00:17:25.086 A:middle
to obtain the maximum
performance is

00:17:25.086 --> 00:17:26.526 A:middle
by having them run
independently,

00:17:26.935 --> 00:17:29.166 A:middle
whereas here they seem to
be waiting on the other.

00:17:30.616 --> 00:17:33.276 A:middle
So we can see there
is a massive stall

00:17:33.276 --> 00:17:35.536 A:middle
between processing
frames on the CPU.

00:17:35.536 --> 00:17:37.756 A:middle
There is a whopping
22 milliseconds.

00:17:37.756 --> 00:17:39.016 A:middle
We shouldn't have any stalls.

00:17:39.326 --> 00:17:40.056 A:middle
What's going on there?

00:17:40.056 --> 00:17:45.646 A:middle
And if we look at the actual
active period of the CPU,

00:17:46.306 --> 00:17:48.566 A:middle
it exceeds our frame deadline.

00:17:48.596 --> 00:17:50.586 A:middle
We were hoping for
60 frames per second.

00:17:50.586 --> 00:17:53.136 A:middle
So we had to get everything
done within 16 milliseconds.

00:17:53.516 --> 00:17:54.506 A:middle
And we have blown past that.

00:17:55.606 --> 00:17:57.986 A:middle
And things don't look much
better on the GPU side, either.

00:17:58.576 --> 00:18:02.626 A:middle
There is a lengthy stall in
proportion to what is on the CPU


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:17:58.576 --> 00:18:02.626 A:middle
There is a lengthy stall in
proportion to what is on the CPU

00:18:02.626 --> 00:18:05.706 A:middle
because the CPU has been
spending all its time doing

00:18:05.706 --> 00:18:07.896 A:middle
nothing of note and
hasn't been able to queue

00:18:08.076 --> 00:18:09.226 A:middle
up work for the next frame.

00:18:09.926 --> 00:18:15.556 A:middle
Furthermore, the active GPU
period overshoots the frame

00:18:15.556 --> 00:18:19.646 A:middle
deadline, and we are shooting
for 60 frames per second,

00:18:19.646 --> 00:18:21.156 A:middle
but it looks like we
are only getting 20.

00:18:22.696 --> 00:18:24.676 A:middle
So what can we do about this?

00:18:25.776 --> 00:18:28.096 A:middle
Well, let's go back to basics.

00:18:28.536 --> 00:18:32.206 A:middle
Let's first examine one
of the key principles

00:18:32.206 --> 00:18:34.586 A:middle
of Metal design and performance.

00:18:35.786 --> 00:18:39.076 A:middle
And that's creating
your expensive objects

00:18:39.076 --> 00:18:40.156 A:middle
in state upfront.

00:18:44.586 --> 00:18:48.726 A:middle
Now, in a legacy app, typically
what would happen would be

00:18:49.006 --> 00:18:53.436 A:middle
during content loading, the app
would compile all of its shaders

00:18:53.436 --> 00:18:57.476 A:middle
from source, and that could be
dozens or even hundreds of them,

00:18:57.476 --> 00:18:59.926 A:middle
and this is a rather
time-consuming operation.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:01.226 --> 00:19:04.246 A:middle
Now, this is only half of the
shared accompilation story

00:19:04.906 --> 00:19:08.016 A:middle
because the shaders
themselves need to be compiled

00:19:08.016 --> 00:19:13.826 A:middle
into a GPU pipeline
state in combination

00:19:13.826 --> 00:19:15.546 A:middle
with the various state used.

00:19:16.346 --> 00:19:20.156 A:middle
So what some apps
might attempt to do is

00:19:20.156 --> 00:19:22.316 A:middle
to do something known
as prewarming.

00:19:22.316 --> 00:19:26.936 A:middle
Now, normally the device
compilation would occur

00:19:26.936 --> 00:19:30.836 A:middle
when the shaders and states
were first used in a Draw call.

00:19:31.406 --> 00:19:32.446 A:middle
That's bad news.

00:19:32.446 --> 00:19:35.906 A:middle
Imagine you have a racing game
and suddenly you turn a corner

00:19:35.906 --> 00:19:37.966 A:middle
and it draws in a
lot of new objects

00:19:37.966 --> 00:19:39.116 A:middle
and the frame rate drops.

00:19:39.116 --> 00:19:40.046 A:middle
That's really bad.

00:19:40.506 --> 00:19:47.746 A:middle
So what prewarming does is you
issue a load of W Draw calls

00:19:47.746 --> 00:19:50.956 A:middle
with various combinations of
graphic states and shaders

00:19:51.526 --> 00:19:56.226 A:middle
in the hope that the driver
will compile the relevant GPU

00:19:56.226 --> 00:19:57.106 A:middle
pipeline state.

00:19:57.106 --> 00:19:58.756 A:middle
So when the time comes

00:19:58.756 --> 00:20:02.636 A:middle
to actually draw using this
combination state and shaders,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:19:58.756 --> 00:20:02.636 A:middle
to actually draw using this
combination state and shaders,

00:20:02.636 --> 00:20:05.756 A:middle
everything is ready to go and
you don't get a frame rate drop.

00:20:06.876 --> 00:20:08.566 A:middle
Now, in the actual
rendering loop,

00:20:08.566 --> 00:20:11.506 A:middle
there would typically be
your setting of states,

00:20:12.096 --> 00:20:13.986 A:middle
and if you actually
get around to any,

00:20:13.986 --> 00:20:16.006 A:middle
maybe you will do some
Draw calls as well.

00:20:17.456 --> 00:20:22.426 A:middle
So the Metal approach is to
move the expensive stuff ahead

00:20:22.426 --> 00:20:22.956 A:middle
of time.

00:20:23.966 --> 00:20:26.906 A:middle
Shaders can be compiled
from source offline.

00:20:27.726 --> 00:20:30.066 A:middle
That's already saving
a chunk of work.

00:20:31.636 --> 00:20:34.796 A:middle
We move state's definition
ahead of time.

00:20:35.006 --> 00:20:37.056 A:middle
You define your state.

00:20:37.426 --> 00:20:40.346 A:middle
The GPU pipeline
state is compiled

00:20:40.346 --> 00:20:42.376 A:middle
into these state objects.

00:20:43.216 --> 00:20:46.596 A:middle
So when you come to actually do
the Draw calls, there is none

00:20:46.596 --> 00:20:50.326 A:middle
of that device compilation
nonsense, so there is no need

00:20:50.326 --> 00:20:51.596 A:middle
for a shade of warming anymore.

00:20:51.736 --> 00:20:52.886 A:middle
It's a thing of the past.

00:20:53.746 --> 00:20:56.906 A:middle
That leaves the rendering
loop free for Draw calls.

00:20:56.906 --> 00:20:58.676 A:middle
Loads of Draw calls.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:21:00.016 --> 00:21:01.606 A:middle
So fundamentally,

00:21:02.476 --> 00:21:05.896 A:middle
Metal facilitates
upfront state definition

00:21:06.336 --> 00:21:10.556 A:middle
by decoupling expensive state
validation and compilation

00:21:11.046 --> 00:21:13.556 A:middle
from the Draw commands, thus
allowing you to pull this

00:21:13.556 --> 00:21:16.216 A:middle
out of the rendering loop
and keep the rendering loop

00:21:16.216 --> 00:21:17.736 A:middle
for actual Draw calls.

00:21:18.326 --> 00:21:23.626 A:middle
Now, the expensive-to-create
state is encapsulated

00:21:23.676 --> 00:21:27.406 A:middle
in these immutable state
objects, and the intention is

00:21:27.406 --> 00:21:30.546 A:middle
that you will create these
once and reuse them many times.

00:21:31.726 --> 00:21:34.676 A:middle
Now, getting back
to our sample app,

00:21:35.936 --> 00:21:39.616 A:middle
here we see there is some shader
compilation going on midframe,

00:21:39.786 --> 00:21:41.756 A:middle
and we are wasting about
a millisecond here.

00:21:42.636 --> 00:21:43.736 A:middle
That's no good at all.

00:21:43.736 --> 00:21:49.676 A:middle
And if we look at the
Xcode's frame debugger,

00:21:49.676 --> 00:21:53.116 A:middle
look at all of this
happening in a single frame.

00:21:53.116 --> 00:21:55.556 A:middle
Look at all of these objects.

00:21:55.626 --> 00:21:56.886 A:middle
We don't want any of this.

00:21:56.886 --> 00:22:00.546 A:middle
All that you should be
seeing is this, the creation


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:21:56.886 --> 00:22:00.546 A:middle
All that you should be
seeing is this, the creation

00:22:00.546 --> 00:22:03.476 A:middle
of the command buffer for
the frame and the acquisition

00:22:03.476 --> 00:22:04.816 A:middle
of the drawable and its texture.

00:22:05.316 --> 00:22:07.536 A:middle
All of the rest is
completely superfluous.

00:22:08.756 --> 00:22:12.526 A:middle
So let's cover these
expensive objects

00:22:12.526 --> 00:22:13.856 A:middle
and when you should create them.

00:22:13.856 --> 00:22:16.296 A:middle
And we are going to begin
with shader libraries.

00:22:17.306 --> 00:22:21.346 A:middle
These are your library
of compiled shaders.

00:22:22.366 --> 00:22:26.056 A:middle
Now, what you really want to do
is compile all of them offline.

00:22:27.036 --> 00:22:31.596 A:middle
You can use Xcode,
any Metal source files

00:22:31.796 --> 00:22:33.936 A:middle
in your project will
automatically be compiled

00:22:34.096 --> 00:22:35.706 A:middle
into the default library.

00:22:36.626 --> 00:22:42.516 A:middle
Now, your app may have its
own custom content pipeline,

00:22:42.806 --> 00:22:45.116 A:middle
and you might not necessarily
want to use this approach.

00:22:45.676 --> 00:22:48.916 A:middle
So for that, we provide
command-line tools,

00:22:48.916 --> 00:22:51.746 A:middle
which you can integrate
into your pipeline.

00:22:52.446 --> 00:22:56.936 A:middle
If you absolutely cannot
avoid compiling your shaders

00:22:56.936 --> 00:23:01.816 A:middle
from source in runtime, the
best you can do is create


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:56.936 --> 00:23:01.816 A:middle
from source in runtime, the
best you can do is create

00:23:01.816 --> 00:23:02.796 A:middle
them asynchronously.

00:23:03.996 --> 00:23:08.296 A:middle
So you create the library,
and in the meantime, your app,

00:23:08.586 --> 00:23:09.816 A:middle
or rather, the calling threads,

00:23:10.136 --> 00:23:12.826 A:middle
can get on with doing
something else,

00:23:12.926 --> 00:23:16.526 A:middle
and once the shader
library has been created,

00:23:17.006 --> 00:23:18.926 A:middle
your app will be
asynchronously notified.

00:23:19.566 --> 00:23:25.266 A:middle
Now, one of the first
objects you will be creating

00:23:25.266 --> 00:23:27.546 A:middle
in your app will be the
device and command queue.

00:23:28.436 --> 00:23:34.416 A:middle
And these represent the GPU
you will be using and its queue

00:23:34.416 --> 00:23:36.386 A:middle
of ordered command buffers.

00:23:37.856 --> 00:23:40.106 A:middle
Now, as we said, you want

00:23:40.106 --> 00:23:42.366 A:middle
to create these during
app initialization

00:23:42.366 --> 00:23:44.756 A:middle
and because they are
expensive to create,

00:23:44.816 --> 00:23:47.846 A:middle
you want to reuse them
throughout the lifetime

00:23:47.846 --> 00:23:48.276 A:middle
of your app.

00:23:49.466 --> 00:23:52.796 A:middle
And, of course, you want
to create one per GPU used.

00:23:52.876 --> 00:23:57.246 A:middle
Now, next is the
interesting stuff, the render

00:23:57.246 --> 00:24:01.396 A:middle
and compute pipeline state,
which encapsulates all


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:23:57.246 --> 00:24:01.396 A:middle
and compute pipeline state,
which encapsulates all

00:24:01.396 --> 00:24:03.946 A:middle
of the programmable
GPU pipeline states,

00:24:04.336 --> 00:24:09.836 A:middle
so it takes all the descriptors,
your vertex formatter scripts,

00:24:09.836 --> 00:24:11.686 A:middle
render buffer formats,
and compiles it

00:24:11.686 --> 00:24:14.076 A:middle
down to the actual
raw pipeline state.

00:24:15.316 --> 00:24:17.496 A:middle
Now, as this is an
expensive operation,

00:24:17.496 --> 00:24:20.596 A:middle
you should be creating
these pipeline objects

00:24:20.636 --> 00:24:23.116 A:middle
when you load your
content, and you should aim

00:24:23.116 --> 00:24:24.996 A:middle
to reuse them as
often as you can.

00:24:26.546 --> 00:24:28.116 A:middle
Now, as with the libraries,

00:24:28.166 --> 00:24:31.066 A:middle
you can also create these
asynchronously using

00:24:31.066 --> 00:24:31.786 A:middle
these methods.

00:24:32.056 --> 00:24:34.436 A:middle
So once created, your
app will be notified

00:24:34.486 --> 00:24:37.086 A:middle
by a completion handler.

00:24:37.936 --> 00:24:42.396 A:middle
One point to mention is that
unless you actually need it,

00:24:42.996 --> 00:24:44.946 A:middle
you shouldn't obtain
the reflection data

00:24:45.056 --> 00:24:46.926 A:middle
as this is an expensive
operation.

00:24:46.996 --> 00:24:53.106 A:middle
So next we have the depth
stencil and sampler states.

00:24:53.666 --> 00:24:56.766 A:middle
These are the fixed-function
GPU pipeline states,

00:24:57.496 --> 00:25:01.546 A:middle
and you should be creating these
when you load your content along


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:24:57.496 --> 00:25:01.546 A:middle
and you should be creating these
when you load your content along

00:25:01.626 --> 00:25:02.936 A:middle
with the other pipeline states.

00:25:03.786 --> 00:25:09.566 A:middle
Now, you may end up with many,
many pieces of depth stencil

00:25:09.566 --> 00:25:11.936 A:middle
and sampler states, but you
needn't worry about this

00:25:11.936 --> 00:25:15.486 A:middle
because some Metal
implementations will internally

00:25:15.736 --> 00:25:19.216 A:middle
hash the states and
create loads of duplicates

00:25:19.276 --> 00:25:20.146 A:middle
so don't worry about that.

00:25:22.086 --> 00:25:26.026 A:middle
Now, next we have the actual
data consumed by the GPU.

00:25:26.106 --> 00:25:29.756 A:middle
You have got your
textures and your buffers.

00:25:30.496 --> 00:25:33.226 A:middle
And you should, once
again, be creating these

00:25:33.936 --> 00:25:37.756 A:middle
when you load your content, and
reuse them as often as possible,

00:25:37.876 --> 00:25:42.166 A:middle
because there is an overhead
associated with both allocating

00:25:42.166 --> 00:25:44.026 A:middle
and deallocating
these resources.

00:25:45.046 --> 00:25:48.866 A:middle
And even dynamic resources,
you might not be able

00:25:48.866 --> 00:25:51.846 A:middle
to fully initialize them
ahead of time, but you should

00:25:51.846 --> 00:25:54.816 A:middle
at least create the
underlying storage.

00:25:54.816 --> 00:25:57.696 A:middle
And we are going to be
covering more on that very soon.

00:25:58.876 --> 00:26:02.006 A:middle
So to briefly recap.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:25:58.876 --> 00:26:02.006 A:middle
So to briefly recap.

00:26:02.096 --> 00:26:06.856 A:middle
So the most expensive states
obviously should be created

00:26:06.856 --> 00:26:09.806 A:middle
ahead of time, so these
are the shader libraries

00:26:09.956 --> 00:26:11.966 A:middle
that you aim to build offline.

00:26:12.996 --> 00:26:15.696 A:middle
The device and the command
queue, which are created

00:26:16.166 --> 00:26:19.976 A:middle
when you initialize
your app, the render

00:26:19.976 --> 00:26:21.326 A:middle
and compute pipeline states,

00:26:22.026 --> 00:26:23.466 A:middle
created when you
load your content,

00:26:24.276 --> 00:26:26.806 A:middle
as are the fixed
function pipeline state,

00:26:26.806 --> 00:26:28.726 A:middle
the depth stencil
and sampler states,

00:26:29.976 --> 00:26:32.506 A:middle
and then finally the
textures and buffers

00:26:32.506 --> 00:26:33.446 A:middle
that are used by your app.

00:26:34.736 --> 00:26:38.896 A:middle
So we went ahead and we
applied this best practice

00:26:38.896 --> 00:26:42.546 A:middle
to our example app, which you
may remember looked like this.

00:26:42.746 --> 00:26:46.496 A:middle
We had some shader compilation
occurring midframe every frame,

00:26:47.606 --> 00:26:48.996 A:middle
and now we have got none.

00:26:49.386 --> 00:26:52.726 A:middle
So already we have saved about
a millisecond of CPU time.

00:26:52.916 --> 00:26:55.146 A:middle
This is a good start,
but we will see

00:26:55.146 --> 00:26:56.116 A:middle
if we can do better soon.

00:26:57.086 --> 00:27:02.086 A:middle
So in summary, create your
expensive state and objects


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:26:57.086 --> 00:27:02.086 A:middle
So in summary, create your
expensive state and objects

00:27:02.086 --> 00:27:05.846 A:middle
up front and aim to reuse them.

00:27:05.846 --> 00:27:10.756 A:middle
Expecially compile your shader
source offline, and you want

00:27:10.756 --> 00:27:13.106 A:middle
to keep the rendering loop
for what it's intended for.

00:27:13.106 --> 00:27:14.166 A:middle
It's for Draw calls.

00:27:14.696 --> 00:27:16.076 A:middle
Get rid of all of
the object creation.

00:27:16.786 --> 00:27:22.606 A:middle
Now, what about the resources
you can't entirely create

00:27:22.606 --> 00:27:23.016 A:middle
up front?

00:27:23.016 --> 00:27:26.256 A:middle
We are talking about
these dynamic resources,

00:27:26.856 --> 00:27:27.926 A:middle
so what do we do about them?

00:27:27.996 --> 00:27:30.916 A:middle
How can we efficiently
create and manage them?

00:27:32.286 --> 00:27:35.386 A:middle
Now, by dynamic resources,
we are talking

00:27:35.876 --> 00:27:40.186 A:middle
about resources which, once
created, may be modified many,

00:27:40.186 --> 00:27:43.636 A:middle
many times by the CPU.

00:27:44.076 --> 00:27:51.306 A:middle
And a good example of this
is buffer shader constants,

00:27:51.306 --> 00:27:55.646 A:middle
and also any dynamic vertex and
index buffers you might have

00:27:55.856 --> 00:27:58.896 A:middle
for things like particles
generated on the CPU,

00:27:59.816 --> 00:28:02.236 A:middle
in addition to dynamic textures,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:27:59.816 --> 00:28:02.236 A:middle
in addition to dynamic textures,

00:28:02.266 --> 00:28:05.066 A:middle
perhaps your app has some
textures which it modifies

00:28:05.066 --> 00:28:06.426 A:middle
in the CPU between frames.

00:28:07.656 --> 00:28:09.206 A:middle
So ideally given the choice,

00:28:09.206 --> 00:28:12.856 A:middle
you would put these resources
somewhere which is efficient

00:28:12.856 --> 00:28:15.486 A:middle
for both the CPU and
the GPU to access.

00:28:16.476 --> 00:28:20.366 A:middle
And you do this with the
shared storage mode option

00:28:20.426 --> 00:28:21.606 A:middle
when you create your resource.

00:28:22.196 --> 00:28:25.256 A:middle
And this creates
resources in memory shared

00:28:25.296 --> 00:28:27.306 A:middle
by both the CPU and the GPU.

00:28:27.826 --> 00:28:31.686 A:middle
Now, this is actually the
default storage mode on iOS,

00:28:31.736 --> 00:28:35.856 A:middle
iOS devices being unified
memory architecture,

00:28:35.996 --> 00:28:39.576 A:middle
so the same memory is shared
between the CPU and GPU.

00:28:40.986 --> 00:28:45.946 A:middle
Now, the thing about these
shared resources is the CPU has

00:28:46.076 --> 00:28:48.076 A:middle
completely unsynchronized
access to them.

00:28:48.486 --> 00:28:53.096 A:middle
It can modify the data as freely
as it wants through a pointer.

00:28:53.946 --> 00:28:58.166 A:middle
And in fact, it's quite easy
for the CPU to stomp all

00:28:58.166 --> 00:29:01.136 A:middle
over the data which
is in use by the GPU,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:28:58.166 --> 00:29:01.136 A:middle
over the data which
is in use by the GPU,

00:29:01.466 --> 00:29:03.276 A:middle
which tends to be
pretty catastrophic.

00:29:03.776 --> 00:29:04.886 A:middle
So we want to avoid that.

00:29:05.756 --> 00:29:07.246 A:middle
But how can we achieve this?

00:29:07.846 --> 00:29:12.306 A:middle
Well, the brute force approach
would be to have a single buffer

00:29:12.306 --> 00:29:16.936 A:middle
for the resource, where we
have, say, a buffer of constants

00:29:16.936 --> 00:29:21.276 A:middle
which are updated on the CPU
and consumed later by the GPU.

00:29:22.506 --> 00:29:26.136 A:middle
Now, if the CPU wants to
modify any of the data

00:29:26.166 --> 00:29:29.566 A:middle
in the constants
buffer, it has to wait

00:29:29.636 --> 00:29:31.446 A:middle
until the GPU is
finished with it.

00:29:31.446 --> 00:29:34.756 A:middle
And the only way it can
know that is if it waits

00:29:34.826 --> 00:29:38.416 A:middle
for the command buffer in which
the resource is referenced

00:29:39.116 --> 00:29:41.006 A:middle
to finish processing on the GPU.

00:29:41.076 --> 00:29:45.436 A:middle
And for that, in this case
we use Wait Until Completed.

00:29:46.096 --> 00:29:49.796 A:middle
So we wait around, rather
the CPU waits around,

00:29:49.826 --> 00:29:51.716 A:middle
until the GPU is
finished processing

00:29:52.176 --> 00:29:54.766 A:middle
and then it can go ahead
and modify the buffer,

00:29:54.766 --> 00:29:57.166 A:middle
which is consumed by the
GPU in the next frame.

00:29:58.186 --> 00:30:02.376 A:middle
Now, this is really bad because
not only is the CPU stored


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:58.186 --> 00:30:02.376 A:middle
Now, this is really bad because
not only is the CPU stored

00:30:02.376 --> 00:30:05.946 A:middle
but the GPU is stored as well
because the CPU hasn't had time

00:30:05.946 --> 00:30:07.436 A:middle
to queue up work
for the next frame.

00:30:08.086 --> 00:30:13.436 A:middle
This is what is happening
in the example app.

00:30:14.616 --> 00:30:20.326 A:middle
The CPU is waiting around for
the GPU to finish on each frame.

00:30:20.506 --> 00:30:24.046 A:middle
You are introducing a massive
store period, and, yes,

00:30:24.186 --> 00:30:27.186 A:middle
there is no parallelism
between the CPU and the GPU.

00:30:28.156 --> 00:30:30.836 A:middle
So we need a better
approach clearly,

00:30:31.736 --> 00:30:35.406 A:middle
and you might be tempted to just
create new buffers every frame

00:30:35.916 --> 00:30:36.706 A:middle
as you need them.

00:30:37.696 --> 00:30:40.476 A:middle
But as we learned in
the previous section,

00:30:40.476 --> 00:30:42.216 A:middle
that's not a particularly
good idea

00:30:42.246 --> 00:30:44.616 A:middle
because there is an
overhead associated

00:30:44.616 --> 00:30:46.066 A:middle
with creating each buffer.

00:30:46.836 --> 00:30:50.226 A:middle
And if you have many buffers,
large buffers, this will add up,

00:30:50.226 --> 00:30:52.146 A:middle
so you really don't
want to be doing this.

00:30:53.076 --> 00:30:57.686 A:middle
What you should do instead
is employ a buffer scheme.

00:30:58.246 --> 00:31:00.426 A:middle
Here we have a triple
buffering scheme,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:58.246 --> 00:31:00.426 A:middle
Here we have a triple
buffering scheme,

00:31:01.076 --> 00:31:05.256 A:middle
where we have three buffers,
which are updated on the CPU

00:31:05.256 --> 00:31:06.786 A:middle
and then consumed by the GPU.

00:31:07.436 --> 00:31:08.306 A:middle
Why three?

00:31:08.876 --> 00:31:12.026 A:middle
Typically we suggest
that you limit the number

00:31:12.026 --> 00:31:16.486 A:middle
of command buffers in flight
to three, and effectively,

00:31:16.486 --> 00:31:20.416 A:middle
you have one buffer
per command buffer.

00:31:21.386 --> 00:31:25.806 A:middle
And by employing a
semaphore to prevent the CPU

00:31:25.806 --> 00:31:29.056 A:middle
from getting too far ahead
of the GPU, we can ensure

00:31:29.056 --> 00:31:33.056 A:middle
that it's safe to update
the buffers on the CPU

00:31:33.636 --> 00:31:37.586 A:middle
when the GPU wraps
around, when it goes back

00:31:37.756 --> 00:31:39.056 A:middle
to reading the first buffer.

00:31:40.126 --> 00:31:43.556 A:middle
Rather than bore you with
a lot of sample code,

00:31:43.556 --> 00:31:46.996 A:middle
I will point you straight at a
great example we already have.

00:31:47.516 --> 00:31:49.856 A:middle
That is the Metal
Uniform Streaming example,

00:31:49.966 --> 00:31:52.236 A:middle
which shows you exactly
how to do this.

00:31:53.426 --> 00:31:56.016 A:middle
So I recommend you check it out
afterward if you are interested.

00:31:57.326 --> 00:31:59.736 A:middle
Getting back to our example app,

00:31:59.926 --> 00:32:03.766 A:middle
you may remember we had these
very performance-crippling


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:31:59.926 --> 00:32:03.766 A:middle
you may remember we had these
very performance-crippling

00:32:03.766 --> 00:32:06.066 A:middle
weights between each
frame on the CPU.

00:32:07.286 --> 00:32:12.626 A:middle
Now, after employing a buffering
scheme to update dynamic data,

00:32:13.516 --> 00:32:17.246 A:middle
we managed to greatly reduce
the gap between processing

00:32:17.246 --> 00:32:20.136 A:middle
on both the CPU and the GPU.

00:32:20.686 --> 00:32:23.096 A:middle
We still have some sort
of synchronization issue,

00:32:23.096 --> 00:32:25.246 A:middle
but we are going to look
into that very shortly.

00:32:26.536 --> 00:32:28.586 A:middle
So we are making good
progress already.

00:32:29.726 --> 00:32:32.316 A:middle
And in summary, you
want to buffer

00:32:32.316 --> 00:32:34.296 A:middle
up your dynamic shared resources

00:32:34.546 --> 00:32:37.286 A:middle
because it's the most
efficient way of updating these

00:32:37.286 --> 00:32:43.556 A:middle
between frames, and you enforce
safety via use of the buffers

00:32:43.556 --> 00:32:44.876 A:middle
and flights that I mentioned.

00:32:45.466 --> 00:32:50.326 A:middle
Now, I'm going to
talk about something

00:32:50.866 --> 00:32:53.896 A:middle
or rather the one thing you
don't actually want to do

00:32:53.896 --> 00:32:56.516 A:middle
up front, and that relates

00:32:56.516 --> 00:32:59.276 A:middle
to when you acquire your
app's drawable service.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:33:01.056 --> 00:33:04.626 A:middle
Now, the drawable surface is
your app's window on the world,

00:33:04.696 --> 00:33:08.446 A:middle
it's what your app renders
its visible content into,

00:33:08.766 --> 00:33:12.796 A:middle
which is either displayed
directly on the display

00:33:13.366 --> 00:33:15.806 A:middle
or it may be part of a
composition pipeline.

00:33:16.796 --> 00:33:20.866 A:middle
Now, you retrieve the
drawables from the Metal layer

00:33:20.866 --> 00:33:23.656 A:middle
of Core Animation, but there
is only a limited number

00:33:23.656 --> 00:33:26.046 A:middle
of these drawables because
they are actually quite big,

00:33:26.916 --> 00:33:30.366 A:middle
and we don't want to keep loads
of them around nor do we want

00:33:30.366 --> 00:33:33.186 A:middle
to be allocating them
whenever we need them.

00:33:33.996 --> 00:33:37.366 A:middle
So these drawables are
maintained very limited,

00:33:37.566 --> 00:33:40.666 A:middle
and predrawables
are relinquished

00:33:40.666 --> 00:33:43.626 A:middle
at display intervals once
they have been displayed

00:33:43.916 --> 00:33:44.516 A:middle
in the hardware.

00:33:45.666 --> 00:33:51.126 A:middle
And each stage of the display
pipeline may actually be holding

00:33:51.126 --> 00:33:54.906 A:middle
onto a drawable at any point
from your app, to a GPU,

00:33:54.906 --> 00:33:57.256 A:middle
to Core Animation if you
have any compositing,

00:33:57.786 --> 00:34:01.616 A:middle
to the actual display hardware.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:33:57.786 --> 00:34:01.616 A:middle
to the actual display hardware.

00:34:01.726 --> 00:34:04.946 A:middle
Now, your app grabs a
drawable surface typically

00:34:05.276 --> 00:34:07.126 A:middle
by calling the next
drawable method.

00:34:07.866 --> 00:34:11.565 A:middle
If you are using MetalKit,
this will be performed

00:34:11.646 --> 00:34:14.466 A:middle
when you call Current
Render Pass Descriptor.

00:34:16.085 --> 00:34:20.775 A:middle
Now, the method will only return
once a drawable is available,

00:34:21.505 --> 00:34:24.676 A:middle
and if there happens to be a
drawable available at the time,

00:34:24.726 --> 00:34:26.016 A:middle
it will return immediately.

00:34:26.166 --> 00:34:29.505 A:middle
Great, you can go on and
continue with the frame.

00:34:29.976 --> 00:34:32.216 A:middle
However, if there are
none available your app,

00:34:32.866 --> 00:34:35.356 A:middle
or rather the calling
for it, will be blocked

00:34:35.436 --> 00:34:39.946 A:middle
until at least the next display
interval waiting for a drawable.

00:34:39.946 --> 00:34:41.085 A:middle
This can be a long time.

00:34:41.235 --> 00:34:42.616 A:middle
It's 60 frames per second.

00:34:42.616 --> 00:34:44.616 A:middle
We are talking 16 milliseconds.

00:34:45.666 --> 00:34:48.326 A:middle
So that's very bad news.

00:34:48.596 --> 00:34:52.366 A:middle
So is this what our
example app was doing?

00:34:52.366 --> 00:34:56.966 A:middle
Is this the explanation for
these huge gaps in execution?

00:34:58.086 --> 00:34:59.486 A:middle
Well, let's see what Xcode says.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:35:00.556 --> 00:35:03.806 A:middle
So we go to the frame
navigator, and we take a look

00:35:04.056 --> 00:35:06.036 A:middle
at the frame navigator here.

00:35:06.086 --> 00:35:08.986 A:middle
And Xcode seems to
have a problem

00:35:08.986 --> 00:35:10.926 A:middle
with our shadow buffer encoder.

00:35:11.716 --> 00:35:13.646 A:middle
See a little warning there.

00:35:14.976 --> 00:35:16.386 A:middle
So if we take a closer look,

00:35:17.416 --> 00:35:20.266 A:middle
we see that indeed we are
actually calling the next

00:35:20.266 --> 00:35:22.606 A:middle
drawable method earlier
than we should do.

00:35:23.246 --> 00:35:25.366 A:middle
The next code offers
some very sage advice

00:35:25.366 --> 00:35:28.556 A:middle
that we should only call it when
we actually need the drawable.

00:35:29.676 --> 00:35:32.556 A:middle
So how does this fit in
with our example app?

00:35:34.176 --> 00:35:38.146 A:middle
Well, we have several passes
here in our example app,

00:35:38.146 --> 00:35:41.406 A:middle
and we were acquiring the
drawable right at the start

00:35:41.406 --> 00:35:44.276 A:middle
of each frame before
the shadow pass.

00:35:44.276 --> 00:35:48.196 A:middle
This is far too early, because
right up until the last pass,

00:35:48.196 --> 00:35:49.846 A:middle
we are drawing everything
off screen,

00:35:50.326 --> 00:35:54.266 A:middle
and we don't need a drawable
right up until we come

00:35:54.406 --> 00:35:56.126 A:middle
to render the UI pass.

00:35:56.676 --> 00:36:01.036 A:middle
So the best place to acquire the
next drawable is naturally right


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:35:56.676 --> 00:36:01.036 A:middle
So the best place to acquire the
next drawable is naturally right

00:36:01.036 --> 00:36:04.446 A:middle
before the UI pass.

00:36:04.656 --> 00:36:09.686 A:middle
So we went ahead and we made
the change, we moved our call

00:36:09.686 --> 00:36:13.456 A:middle
to next drawable
later, and let's see

00:36:13.456 --> 00:36:14.746 A:middle
if that solved our problem.

00:36:15.196 --> 00:36:17.906 A:middle
Well, as you can
already see, yes, it did!

00:36:18.456 --> 00:36:22.786 A:middle
We removed our second
synchronization point,

00:36:23.416 --> 00:36:26.276 A:middle
and now we don't have any
stalls between processing

00:36:26.276 --> 00:36:29.116 A:middle
on the frame processing
on the CPU.

00:36:29.596 --> 00:36:30.936 A:middle
That's a massive improvement.

00:36:31.466 --> 00:36:36.756 A:middle
So the advice is very simple:
only acquire the drawable

00:36:36.756 --> 00:36:38.136 A:middle
when you actually need it.

00:36:38.866 --> 00:36:41.836 A:middle
This is before the render pass
in which it's actually used.

00:36:42.826 --> 00:36:48.086 A:middle
This will ensure that
you hide any long latency

00:36:48.086 --> 00:36:51.866 A:middle
that would occur if there
weren't any drawables available.

00:36:52.016 --> 00:36:55.296 A:middle
So your app can continue
to do useful work,

00:36:55.296 --> 00:36:58.106 A:middle
and by the time it
actually needs a drawable,

00:36:58.236 --> 00:36:59.536 A:middle
one is likely to be available.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:37:01.996 --> 00:37:05.256 A:middle
So at this point we are
doing pretty well so far.

00:37:05.256 --> 00:37:07.716 A:middle
But there is still
room for improvement.

00:37:08.476 --> 00:37:11.076 A:middle
So why don't we look
at the efficiency

00:37:11.076 --> 00:37:15.456 A:middle
of the GPU side rather than
diving to a very low level, say,

00:37:15.456 --> 00:37:19.456 A:middle
trying to optimize our shaders
or change texture formats,

00:37:19.616 --> 00:37:20.846 A:middle
whatever, why don't we see

00:37:20.846 --> 00:37:22.796 A:middle
if there is any general
advice we can apply.

00:37:23.916 --> 00:37:25.176 A:middle
As it so happens, there is.

00:37:25.656 --> 00:37:28.776 A:middle
That relates to how we use
Render Command Encoders.

00:37:29.486 --> 00:37:35.816 A:middle
Now, a Render Command
Encoder is what is used

00:37:35.946 --> 00:37:40.306 A:middle
to generate Draw commands
for a single rendering pass.

00:37:40.866 --> 00:37:45.306 A:middle
And a single rendering pass
operates on a fixed set

00:37:45.416 --> 00:37:48.956 A:middle
of color attachments, and
depth and stencil attachments.

00:37:49.336 --> 00:37:52.616 A:middle
Once you begin the pass, you
cannot change these attachments.

00:37:53.066 --> 00:37:56.496 A:middle
However, you can change
the actions acting on them,

00:37:56.756 --> 00:38:01.206 A:middle
such as the depth stencil
state, color masking


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:37:56.756 --> 00:38:01.206 A:middle
such as the depth stencil
state, color masking

00:38:01.206 --> 00:38:02.896 A:middle
and blending, for instance.

00:38:02.896 --> 00:38:05.026 A:middle
And this is valuable
to remember.

00:38:06.966 --> 00:38:12.026 A:middle
Now, the way in which we use
our render encoders particularly

00:38:12.026 --> 00:38:17.776 A:middle
important on the iOS device
GPUs due to the interesting way

00:38:17.776 --> 00:38:20.206 A:middle
in which they are architected.

00:38:20.346 --> 00:38:22.486 A:middle
They are tile-based
deferred renderers.

00:38:23.286 --> 00:38:28.796 A:middle
So each Render Command Encoder
results in two GPU passes.

00:38:29.676 --> 00:38:34.546 A:middle
First you have the vertex
phase, which transforms all

00:38:34.546 --> 00:38:41.236 A:middle
of the geometry in your encoder,
and then performs clipping,

00:38:41.236 --> 00:38:47.826 A:middle
coloring, and then bins
all of the geometry

00:38:47.826 --> 00:38:49.386 A:middle
into screen space tiles.

00:38:50.456 --> 00:38:54.506 A:middle
This is followed by the fragment
phase, which processes all

00:38:54.506 --> 00:38:58.836 A:middle
of the objects tile
by tile to determine

00:38:58.836 --> 00:39:01.586 A:middle
which objects are visible,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:38:58.836 --> 00:39:01.586 A:middle
which objects are visible,

00:39:02.006 --> 00:39:05.766 A:middle
and then only the visible
pixels are actually processed.

00:39:07.026 --> 00:39:10.086 A:middle
And all of the fragment
processing occurs

00:39:10.086 --> 00:39:12.426 A:middle
in these fast on-chip
tile buffers.

00:39:13.756 --> 00:39:17.276 A:middle
Now, typically at the end
of a render you only need

00:39:17.276 --> 00:39:19.146 A:middle
to store out the color buffer.

00:39:19.476 --> 00:39:21.346 A:middle
You would just discard
the depth buffer.

00:39:21.906 --> 00:39:26.286 A:middle
And even sometimes you may have,
say, multiple color attachments,

00:39:26.326 --> 00:39:28.746 A:middle
but you only need to
store one of them.

00:39:28.746 --> 00:39:33.766 A:middle
By not storing the
tile data in each pass,

00:39:33.826 --> 00:39:35.666 A:middle
you are saving quite
a bit of bandwidth.

00:39:35.816 --> 00:39:38.076 A:middle
You are avoiding writing
out entire frame buffers.

00:39:38.076 --> 00:39:42.446 A:middle
This is important for
performance, as is not having

00:39:42.446 --> 00:39:44.646 A:middle
to load in data each tile.

00:39:47.406 --> 00:39:50.606 A:middle
So what can Xcode tell us?

00:39:50.706 --> 00:39:53.476 A:middle
Can it give us -- or rather,

00:39:55.826 --> 00:40:01.096 A:middle
I mentioned that each
encoder corresponds


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:39:55.826 --> 00:40:01.096 A:middle
I mentioned that each
encoder corresponds

00:40:01.226 --> 00:40:04.476 A:middle
to a vertex pass
and a fragment pass.

00:40:05.076 --> 00:40:08.486 A:middle
And this applies
even for MT encoders,

00:40:08.486 --> 00:40:09.816 A:middle
and this is quite important.

00:40:10.766 --> 00:40:13.656 A:middle
Here we have actually
two G-buffer encoders,

00:40:13.656 --> 00:40:16.626 A:middle
and the first one doesn't
seem to be drawing anything.

00:40:17.356 --> 00:40:19.256 A:middle
I guess that just slipped
in there by mistake,

00:40:19.986 --> 00:40:25.106 A:middle
but this actually has quite an
impact on performance if we look

00:40:25.106 --> 00:40:26.626 A:middle
at the system trace of the app.

00:40:27.966 --> 00:40:33.266 A:middle
Just that empty encoder consumed
2.8 milliseconds on the GPU,

00:40:33.996 --> 00:40:38.856 A:middle
and presumably it was
just writing a clear color

00:40:38.856 --> 00:40:42.886 A:middle
out to however many
attachments we had, three color

00:40:42.886 --> 00:40:47.026 A:middle
and two depth and stencil.

00:40:47.646 --> 00:40:50.606 A:middle
And our total GPU
processing time

00:40:50.606 --> 00:40:52.886 A:middle
for this particular
frame is 22 milliseconds.

00:40:53.486 --> 00:40:57.036 A:middle
Now, if we remove
the MT encoder,

00:40:57.036 --> 00:40:59.466 A:middle
which is done very easily
because it shouldn't be there

00:40:59.466 --> 00:41:05.386 A:middle
in the first place, we go down
to 19, so that's a very nice win


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:40:59.466 --> 00:41:05.386 A:middle
in the first place, we go down
to 19, so that's a very nice win

00:41:05.386 --> 00:41:06.816 A:middle
for doing very little at all.

00:41:07.176 --> 00:41:09.526 A:middle
So watch out for
these MT encoders.

00:41:09.526 --> 00:41:11.286 A:middle
If you are not going
to do any drawing

00:41:11.286 --> 00:41:14.236 A:middle
in a pass, don't start encoding.

00:41:14.926 --> 00:41:19.656 A:middle
So let's look a bit deeper now.

00:41:19.746 --> 00:41:22.786 A:middle
Let's have a look at the render
passes in our example app

00:41:22.916 --> 00:41:23.906 A:middle
and see what we have got.

00:41:25.496 --> 00:41:27.126 A:middle
So we have got a shadow pass,

00:41:27.456 --> 00:41:30.076 A:middle
which renders into
a depth buffer.

00:41:31.006 --> 00:41:32.696 A:middle
We have a G-buffer
pass, which renders

00:41:32.696 --> 00:41:36.516 A:middle
into three color attachments and
a depth and stencil attachment,

00:41:37.456 --> 00:41:40.186 A:middle
and then we have these
three lighting passes,

00:41:40.236 --> 00:41:45.536 A:middle
which use the render attachment
data from the G-buffer pass,

00:41:45.536 --> 00:41:48.086 A:middle
either sampling through the
texture units or loading

00:41:49.046 --> 00:41:53.346 A:middle
to the frame buffer content.

00:41:53.346 --> 00:41:55.976 A:middle
And when the lighting
passes use this data,

00:41:55.976 --> 00:41:59.856 A:middle
and they perform
lighting and outputs


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:42:00.146 --> 00:42:02.866 A:middle
to a single accumulation target

00:42:02.866 --> 00:42:04.146 A:middle
which is used several
times over.

00:42:04.866 --> 00:42:07.476 A:middle
And finally you have
a user interface pass

00:42:07.476 --> 00:42:10.536 A:middle
onto which user interface
elements are drawn

00:42:11.096 --> 00:42:12.496 A:middle
and presented to the screen.

00:42:13.956 --> 00:42:18.086 A:middle
So is this the most
efficient setup of encoders?

00:42:18.886 --> 00:42:22.956 A:middle
Once again we summon
Xcode's frame debugger to see

00:42:22.956 --> 00:42:23.916 A:middle
if it has anything to say.

00:42:23.916 --> 00:42:26.706 A:middle
And once again, yes it does.

00:42:26.886 --> 00:42:29.526 A:middle
It has taken issue with
our sunlight encoder.

00:42:30.456 --> 00:42:31.506 A:middle
So let's take a closer look.

00:42:31.506 --> 00:42:35.536 A:middle
We are inefficiently using
our command encoders.

00:42:36.856 --> 00:42:38.976 A:middle
And Xcode is kind
enough to tell us

00:42:38.976 --> 00:42:41.866 A:middle
which ones we could
actually combine.

00:42:43.576 --> 00:42:47.666 A:middle
So let's go ahead and
merge a couple of passes.

00:42:48.166 --> 00:42:51.436 A:middle
Rather than merge just two,
we can actually merge three,

00:42:51.436 --> 00:42:54.126 A:middle
which all operate on the
same color attachment.

00:42:54.916 --> 00:42:56.506 A:middle
So let's go ahead and do that.

00:42:56.906 --> 00:43:00.046 A:middle
So we have six passes
here, and now we are going


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:42:56.906 --> 00:43:00.046 A:middle
So we have six passes
here, and now we are going

00:43:00.046 --> 00:43:01.696 A:middle
to merge them down to four.

00:43:02.966 --> 00:43:06.956 A:middle
So what impact did that have
on performance, GPU side?

00:43:07.896 --> 00:43:11.426 A:middle
Let's go back to the
GPU, the system trace.

00:43:12.456 --> 00:43:16.716 A:middle
Here we can see we have
gone from 21 milliseconds,

00:43:16.916 --> 00:43:20.946 A:middle
six passes, down to 18 by
not having to write out all

00:43:21.006 --> 00:43:23.786 A:middle
of that load and store all
of that attachment data.

00:43:24.556 --> 00:43:25.846 A:middle
So that's quite a nice win.

00:43:27.256 --> 00:43:28.756 A:middle
But could we go any further?

00:43:28.756 --> 00:43:31.536 A:middle
Let's return to our app.

00:43:32.756 --> 00:43:39.746 A:middle
So we have four passes,
and is it actually possible

00:43:39.746 --> 00:43:44.736 A:middle
to combine both the G-buffer and
the lighing pass to avoid having

00:43:44.736 --> 00:43:49.056 A:middle
to store out five attachments
and keep everything on chip?

00:43:50.076 --> 00:43:52.676 A:middle
Well, it in fact is.

00:43:52.676 --> 00:43:56.576 A:middle
We can do that with clever
use of programmable blending.

00:43:57.636 --> 00:43:59.446 A:middle
So I'm not going to go
into too much detail there,

00:43:59.446 --> 00:44:04.446 A:middle
but what we did was we combined
these two encoders down to one.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:43:59.446 --> 00:44:04.446 A:middle
but what we did was we combined
these two encoders down to one.

00:44:04.696 --> 00:44:07.386 A:middle
So now we are left with
three render encoders

00:44:08.056 --> 00:44:10.236 A:middle
and we are having to
load and store far,

00:44:10.236 --> 00:44:13.946 A:middle
far less attachment data,
and that's a massive win

00:44:13.996 --> 00:44:16.596 A:middle
in terms of bandwidth.

00:44:16.676 --> 00:44:18.466 A:middle
So let's see what
impact that had.

00:44:20.006 --> 00:44:21.776 A:middle
Actually not a lot.

00:44:21.936 --> 00:44:23.416 A:middle
That was very unexpected.

00:44:23.416 --> 00:44:26.556 A:middle
We have only chopped
off about a millisecond.

00:44:26.936 --> 00:44:28.446 A:middle
That's not great.

00:44:28.446 --> 00:44:31.036 A:middle
I was hoping for more than that.

00:44:31.036 --> 00:44:33.756 A:middle
So once again, can
Xcode save us?

00:44:34.676 --> 00:44:37.176 A:middle
We turn to Xcode's
frame debugger.

00:44:38.256 --> 00:44:41.496 A:middle
And we take a closer look at
the load and store bandwidth

00:44:42.016 --> 00:44:43.826 A:middle
for the G-buffer encoder.

00:44:45.896 --> 00:44:48.266 A:middle
Now, it turns out that we
are actually still loading

00:44:48.266 --> 00:44:52.566 A:middle
and storing quite a lot
of data, and the reason

00:44:52.566 --> 00:44:53.706 A:middle
for that is quite simple.

00:44:54.126 --> 00:44:57.566 A:middle
It looks like here we have
mistakenly set our loads

00:44:58.026 --> 00:45:00.686 A:middle
and store actions for each
attachment incorrectly.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:44:58.026 --> 00:45:00.686 A:middle
and store actions for each
attachment incorrectly.

00:45:01.526 --> 00:45:05.586 A:middle
We only wanted to be storing
the first color attachment,

00:45:06.096 --> 00:45:08.976 A:middle
and we want to discard the
remaining color attachments

00:45:08.976 --> 00:45:11.756 A:middle
in addition to the depth
and stencil attachments,

00:45:12.556 --> 00:45:14.986 A:middle
and we certainly don't
want to be loading them in.

00:45:16.406 --> 00:45:21.276 A:middle
So if we make the very simple
change, we change our load

00:45:21.276 --> 00:45:24.116 A:middle
and store actions to
something more appropriate,

00:45:24.826 --> 00:45:28.026 A:middle
we have reduced our load
bandwidth down to zero

00:45:28.186 --> 00:45:31.706 A:middle
and we have massively
reduced the amounts

00:45:31.836 --> 00:45:33.746 A:middle
of attachment data
we're storing.

00:45:35.296 --> 00:45:38.246 A:middle
So now, what impact
did that have?

00:45:39.266 --> 00:45:41.836 A:middle
So before, with our
three passes,

00:45:41.836 --> 00:45:44.906 A:middle
we are taking 17
milliseconds on the GPU.

00:45:45.806 --> 00:45:48.656 A:middle
Now, we are down to 14.

00:45:48.656 --> 00:45:49.566 A:middle
That's more like it.

00:45:51.766 --> 00:45:55.496 A:middle
So to summarize, don't
waste your render encoders.

00:45:55.596 --> 00:45:58.166 A:middle
Try to do as much useful
work as possible in them,

00:45:59.056 --> 00:46:01.756 A:middle
and definitely do
not start encoding


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:45:59.056 --> 00:46:01.756 A:middle
and definitely do
not start encoding

00:46:01.756 --> 00:46:03.326 A:middle
if you are not going
to draw anything.

00:46:05.276 --> 00:46:10.496 A:middle
And if you can, and with the
help of Xcode, merge encoders

00:46:10.496 --> 00:46:12.596 A:middle
which are rendering to
the same attachments.

00:46:13.136 --> 00:46:16.266 A:middle
This will get you big wins.

00:46:17.116 --> 00:46:20.386 A:middle
Now, we are doing pretty
well on the GPU side now.

00:46:20.496 --> 00:46:24.166 A:middle
In fact, we are actually
within our frame budget.

00:46:25.496 --> 00:46:28.476 A:middle
But is there anything we
can do on the CPU side?

00:46:29.676 --> 00:46:33.226 A:middle
If you remember, I think we were
actually still slightly beyond

00:46:33.356 --> 00:46:34.396 A:middle
our frame budget.

00:46:35.876 --> 00:46:36.956 A:middle
What about multithreading?

00:46:37.386 --> 00:46:39.106 A:middle
How could multithreading
help us?

00:46:40.246 --> 00:46:42.926 A:middle
What does Metal allow us to
do in terms of multithreading?

00:46:44.496 --> 00:46:47.846 A:middle
Fortunately for us, Metal was
designed with multithreading

00:46:47.846 --> 00:46:55.546 A:middle
in mind and has a very efficient
threadsafe and scalable means

00:46:55.546 --> 00:46:57.366 A:middle
of multithreading
your rendering.

00:46:57.366 --> 00:47:01.756 A:middle
It allows you to encode multiple
command buffers simultaneously


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:46:57.366 --> 00:47:01.756 A:middle
It allows you to encode multiple
command buffers simultaneously

00:47:02.086 --> 00:47:06.766 A:middle
on different threads, and your
app has control over the order

00:47:06.766 --> 00:47:07.896 A:middle
in which these are executed.

00:47:09.386 --> 00:47:12.256 A:middle
Let's take a look at
a possible scenario

00:47:12.256 --> 00:47:14.036 A:middle
where we might attempt
some multithreading.

00:47:14.956 --> 00:47:17.346 A:middle
But before that, I
would like to stress

00:47:17.346 --> 00:47:20.436 A:middle
that before you even
go ahead and try

00:47:20.436 --> 00:47:21.806 A:middle
to multithread your rendering,

00:47:21.806 --> 00:47:25.276 A:middle
you should actively
pursue the best possible

00:47:25.276 --> 00:47:26.686 A:middle
single-threaded performance.

00:47:27.206 --> 00:47:30.096 A:middle
So make sure there is
nothing terribly inefficient

00:47:30.096 --> 00:47:34.106 A:middle
in there before you start
trying to multithread things.

00:47:34.286 --> 00:47:38.346 A:middle
Okay. So we have an example here
where we have two render passes,

00:47:39.336 --> 00:47:45.996 A:middle
and we are actually taking so
long to encode these two passes

00:47:45.996 --> 00:47:51.636 A:middle
on the CPU that we are actually
missing our frame deadline.

00:47:53.016 --> 00:47:54.746 A:middle
So how can we improve this?

00:47:55.386 --> 00:47:59.286 A:middle
Well, we can go ahead and
we can encode the two passes

00:47:59.286 --> 00:47:59.916 A:middle
in parallel.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:48:00.866 --> 00:48:06.176 A:middle
And not only have we managed to
reduce the CPU time per frame,

00:48:07.286 --> 00:48:11.046 A:middle
the side effect is that the
first render pass can be

00:48:11.046 --> 00:48:13.496 A:middle
submitted to the GPU quicker.

00:48:13.646 --> 00:48:19.716 A:middle
So how would this look in
terms of Metal objects?

00:48:20.926 --> 00:48:21.866 A:middle
How does it come together?

00:48:22.826 --> 00:48:25.626 A:middle
Where we start with our Metal
device in the command queue

00:48:25.626 --> 00:48:29.656 A:middle
as usual, and now for
this example we are going

00:48:29.656 --> 00:48:30.906 A:middle
to have three threads.

00:48:30.906 --> 00:48:36.226 A:middle
And for each thread, you
need a command buffer.

00:48:36.416 --> 00:48:41.756 A:middle
Now, for the two threads, each
has a Render Command Encoder

00:48:41.806 --> 00:48:44.296 A:middle
which is operating
on separate passes,

00:48:45.336 --> 00:48:50.426 A:middle
and on our third thread we
might have multiple encoders

00:48:51.296 --> 00:48:52.416 A:middle
executing serially.

00:48:53.046 --> 00:48:55.116 A:middle
So it goes to show
the approaches

00:48:55.116 --> 00:48:57.376 A:middle
to multithreading can
be quite flexible,

00:48:58.306 --> 00:49:00.706 A:middle
and once they have all
finished their encoding,


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:48:58.306 --> 00:49:00.706 A:middle
and once they have all
finished their encoding,

00:49:00.706 --> 00:49:03.406 A:middle
the command buffers are
submitted to the command queue.

00:49:04.976 --> 00:49:07.186 A:middle
So how would you set this up?

00:49:08.556 --> 00:49:09.446 A:middle
It's quite simple.

00:49:10.656 --> 00:49:15.856 A:middle
You create one command buffer
per thread and you go ahead

00:49:15.856 --> 00:49:18.926 A:middle
and initialize render
passes as usual,

00:49:19.586 --> 00:49:23.206 A:middle
and now the important
point here is the order

00:49:23.206 --> 00:49:26.936 A:middle
in which the command buffers
will be submitted to the GPU.

00:49:27.846 --> 00:49:29.936 A:middle
Chances are this is
important to you.

00:49:30.256 --> 00:49:33.866 A:middle
So you enforce it by
calling the Enqueue method

00:49:34.296 --> 00:49:39.086 A:middle
on the command buffers,
and that reserves a place

00:49:39.086 --> 00:49:43.026 A:middle
in the command queue so when
the buffers are eventually

00:49:43.026 --> 00:49:46.336 A:middle
committed, they will be
executed in the order

00:49:46.336 --> 00:49:47.216 A:middle
that they were enqueued.

00:49:47.216 --> 00:49:49.366 A:middle
This is an important
point to remember.

00:49:50.486 --> 00:49:54.966 A:middle
Because then we create the
render encoders for each thread,

00:49:55.766 --> 00:50:00.146 A:middle
and we go ahead and encode our
draws on the separate threads


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:49:55.766 --> 00:50:00.146 A:middle
and we go ahead and encode our
draws on the separate threads

00:50:00.146 --> 00:50:02.106 A:middle
and then commit the
command buffers.

00:50:02.746 --> 00:50:04.206 A:middle
It's really very simple to do.

00:50:06.846 --> 00:50:08.756 A:middle
Now, what about another scenario

00:50:08.846 --> 00:50:11.236 A:middle
which could potentially
benefit from multithreading?

00:50:13.086 --> 00:50:15.236 A:middle
So here again we
have two passes,

00:50:15.776 --> 00:50:18.006 A:middle
but one of them is significantly
longer than the other.

00:50:18.816 --> 00:50:20.346 A:middle
Could we split that up somehow?

00:50:21.086 --> 00:50:21.816 A:middle
Yes, we can.

00:50:22.506 --> 00:50:25.586 A:middle
Here, we will break it up
into two separate passes.

00:50:26.046 --> 00:50:27.246 A:middle
We have three threads here.

00:50:27.906 --> 00:50:29.646 A:middle
One is working on the
first render pass,

00:50:29.896 --> 00:50:33.206 A:middle
and we have two dedicated to
working on chunks of the second.

00:50:34.226 --> 00:50:37.626 A:middle
And, again, here by employing
multithreading we are

00:50:37.626 --> 00:50:41.286 A:middle
within our frame deadline,
and we have got a bit of time

00:50:41.286 --> 00:50:42.836 A:middle
to spare on the CPU as well

00:50:42.836 --> 00:50:45.326 A:middle
for doing whatever
else we fancy doing.

00:50:45.326 --> 00:50:47.636 A:middle
It need not necessarily
be more Metal work.

00:50:49.636 --> 00:50:52.946 A:middle
So how would we, or rather
what would this look like?

00:50:54.516 --> 00:50:58.366 A:middle
So once again, we have the
device and the command queue.

00:50:58.456 --> 00:51:02.306 A:middle
And for this example, we are
going to be using three threads.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:50:58.456 --> 00:51:02.306 A:middle
And for this example, we are
going to be using three threads.

00:51:03.866 --> 00:51:08.866 A:middle
But here we only want
one command buffer.

00:51:09.056 --> 00:51:13.096 A:middle
Next, we have the special form
of the Render Command Encoder,

00:51:13.346 --> 00:51:15.456 A:middle
the Parallel Render
Command Encoder.

00:51:16.176 --> 00:51:21.246 A:middle
Now, this allows you to split
work for a single encoder

00:51:21.826 --> 00:51:25.196 A:middle
over multiple threads, and this
is particularly important to use

00:51:25.196 --> 00:51:27.456 A:middle
on iOS because it ensures

00:51:27.566 --> 00:51:32.266 A:middle
that the threaded
workloads are later combined

00:51:32.266 --> 00:51:35.796 A:middle
into a single pass on the GPU.

00:51:35.796 --> 00:51:38.696 A:middle
So there is no loading and
storing between passes.

00:51:38.826 --> 00:51:41.406 A:middle
This is very important that
you use this if you are going

00:51:41.406 --> 00:51:43.986 A:middle
to split up a single pass
across multiple threads.

00:51:45.516 --> 00:51:47.806 A:middle
So from the Parallel
Render Command Encoder,

00:51:47.996 --> 00:51:52.026 A:middle
we create our three
subordinate command encoders,

00:51:53.206 --> 00:51:57.396 A:middle
and each will encode to
the command buffer now,

00:51:57.396 --> 00:52:00.346 A:middle
because we are multithreading
they may finish encoding


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:51:57.396 --> 00:52:00.346 A:middle
because we are multithreading
they may finish encoding

00:52:00.646 --> 00:52:03.266 A:middle
at indeterminate times,

00:52:03.266 --> 00:52:05.696 A:middle
not necessarily any
particular order.

00:52:06.866 --> 00:52:09.526 A:middle
Then the command buffer
submitted to the queue.

00:52:10.596 --> 00:52:12.656 A:middle
Now, it's entirely feasible

00:52:12.726 --> 00:52:16.276 A:middle
that you could even have
parallel Parallel Render

00:52:16.276 --> 00:52:17.216 A:middle
Command Encoders.

00:52:18.526 --> 00:52:22.796 A:middle
The multithreading possibilities
are not quite endless,

00:52:22.846 --> 00:52:23.726 A:middle
but very flexible.

00:52:24.456 --> 00:52:26.856 A:middle
Or you could have
like we saw earlier,

00:52:26.856 --> 00:52:28.366 A:middle
you could have a fourth thread

00:52:28.936 --> 00:52:31.996 A:middle
which is executing
encoder serially.

00:52:32.726 --> 00:52:37.826 A:middle
So how do we set this up?

00:52:38.336 --> 00:52:42.256 A:middle
Well, we begin by creating one
command buffer per Parallel

00:52:42.826 --> 00:52:43.556 A:middle
Render Command Encoder.

00:52:43.556 --> 00:52:46.016 A:middle
So no matter how many
threads you are using,

00:52:46.296 --> 00:52:47.696 A:middle
you only want one
command buffer.

00:52:48.296 --> 00:52:54.206 A:middle
We then proceed to initialize
the render pass as usual,

00:52:54.206 --> 00:52:58.516 A:middle
and then we create our
actual parallel encoder.

00:52:58.516 --> 00:53:01.026 A:middle
Now, here is the important bit.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:52:58.516 --> 00:53:01.026 A:middle
Now, here is the important bit.

00:53:02.516 --> 00:53:05.436 A:middle
When we create our
subordinate encoders,

00:53:06.036 --> 00:53:09.866 A:middle
the order in which they are
created determines the order

00:53:09.866 --> 00:53:12.736 A:middle
in which they will be
submitted to the GPU.

00:53:12.736 --> 00:53:15.526 A:middle
This is something to bear
in mind when you split

00:53:15.526 --> 00:53:18.446 A:middle
up your workload for encoding
over multiple threads.

00:53:20.436 --> 00:53:24.596 A:middle
Then we go ahead and we encode
our draws and separate threads,

00:53:25.206 --> 00:53:28.706 A:middle
and then finish encoding for
each subordinate encoder.

00:53:29.966 --> 00:53:32.296 A:middle
Now, the second important
point is all

00:53:32.296 --> 00:53:36.996 A:middle
of the subordinate encoders must
have finished encoding before we

00:53:36.996 --> 00:53:39.236 A:middle
end encoding on the
parallel encoder.

00:53:40.216 --> 00:53:41.926 A:middle
And how you implement
this is up to you.

00:53:42.916 --> 00:53:46.076 A:middle
Then finally, the command buffer
is committed to the queue.

00:53:48.306 --> 00:53:52.646 A:middle
So we went ahead and we
decided to multithread our app.

00:53:53.606 --> 00:53:54.616 A:middle
Look what turned up.

00:53:56.106 --> 00:54:00.656 A:middle
So previously, we had
serial encoding or passes.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:53:56.106 --> 00:54:00.656 A:middle
So previously, we had
serial encoding or passes.

00:54:01.856 --> 00:54:06.486 A:middle
This was taking 25
milliseconds of CPU time.

00:54:08.166 --> 00:54:16.176 A:middle
Now, we pursued an approach
where we encode the shadow pass

00:54:16.176 --> 00:54:20.656 A:middle
on one thread, and the G-buffer
pass and UI pass on another,

00:54:21.656 --> 00:54:24.266 A:middle
and now we are down
to 15 milliseconds.

00:54:25.286 --> 00:54:27.746 A:middle
That's quite a nifty
improvement,

00:54:27.906 --> 00:54:33.976 A:middle
and we have got a bit of time
left over on the CPU as well.

00:54:34.176 --> 00:54:36.826 A:middle
So as far as multithreading
goes,

00:54:36.886 --> 00:54:40.766 A:middle
if you find that you are still
CPU bound and you have done all

00:54:40.766 --> 00:54:42.546 A:middle
of the investigations you can,

00:54:42.726 --> 00:54:45.756 A:middle
and determining you haven't
got anything silly going

00:54:45.756 --> 00:54:48.556 A:middle
on in your app, and that
you could actually benefit

00:54:48.556 --> 00:54:51.896 A:middle
from multithreading, you
can encode render passes

00:54:51.896 --> 00:54:53.786 A:middle
simultaneously on
multiple threads.

00:54:54.776 --> 00:54:57.846 A:middle
But should you decide to
split up a single pass

00:54:58.286 --> 00:54:59.486 A:middle
across multiple threads,

00:54:59.966 --> 00:55:03.066 A:middle
you want to use the Parallel
Render Command Encoder to do so.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:54:59.966 --> 00:55:03.066 A:middle
you want to use the Parallel
Render Command Encoder to do so.

00:55:03.066 --> 00:55:09.426 A:middle
Now, what did we
learn in this session?

00:55:10.936 --> 00:55:13.386 A:middle
Well, we introduced the
Metal System Trace tool,

00:55:13.386 --> 00:55:14.296 A:middle
and it was great.

00:55:14.296 --> 00:55:17.826 A:middle
It offers new insight into
your app's Metal performance.

00:55:18.606 --> 00:55:21.406 A:middle
And you want to use this
in conjunction with Xcode

00:55:21.526 --> 00:55:23.366 A:middle
to profile early and often.

00:55:23.366 --> 00:55:27.516 A:middle
And as we have seen,
you should also try

00:55:27.516 --> 00:55:30.036 A:middle
to follow the best
practices set out,

00:55:30.616 --> 00:55:34.266 A:middle
so you want to create the
expensive state up front

00:55:34.296 --> 00:55:35.846 A:middle
and reuse it as often
as possible.

00:55:36.976 --> 00:55:39.956 A:middle
We want to buffer
dynamic resources

00:55:40.436 --> 00:55:44.156 A:middle
so we can efficiently
modify them between frames

00:55:44.156 --> 00:55:45.216 A:middle
without causing stalls.

00:55:46.746 --> 00:55:50.166 A:middle
We want to make sure we
are acquiring our drawable

00:55:50.166 --> 00:55:52.216 A:middle
at the correct point in time.

00:55:52.736 --> 00:55:54.626 A:middle
Usually at the last
possible moment.

00:55:56.086 --> 00:55:59.326 A:middle
We want to make sure we are
efficiently using our Render

00:55:59.326 --> 00:56:00.326 A:middle
Command Encoders.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:55:59.326 --> 00:56:00.326 A:middle
Command Encoders.

00:56:00.816 --> 00:56:03.216 A:middle
We don't have any
empty encoders,

00:56:03.216 --> 00:56:06.866 A:middle
and we have coalesced any
encoders which are writing

00:56:06.866 --> 00:56:08.546 A:middle
to the same attachment
down to one.

00:56:09.136 --> 00:56:14.196 A:middle
And then if we find we are
still CPU bound as we were

00:56:14.196 --> 00:56:18.606 A:middle
in this case, we might consider
the approaches Metal offers

00:56:18.606 --> 00:56:20.046 A:middle
for multithreading
our rendering.

00:56:22.046 --> 00:56:25.176 A:middle
So how did we do?

00:56:25.686 --> 00:56:27.876 A:middle
Well, now look at our app!

00:56:28.336 --> 00:56:30.776 A:middle
We don't have any runtime
shader compilation.

00:56:31.696 --> 00:56:36.456 A:middle
Furthermore, our GPU workload
is within the frame deadline.

00:56:36.666 --> 00:56:37.146 A:middle
It's great.

00:56:38.196 --> 00:56:40.266 A:middle
As is the CPU workload.

00:56:41.376 --> 00:56:45.356 A:middle
And there are no gaps between
processing of frames on the CPU.

00:56:46.016 --> 00:56:51.656 A:middle
And we even got quite fancy and
decided to do multithreading.

00:56:51.656 --> 00:56:56.366 A:middle
We have a lot of time left
over there to do other things.

00:56:56.556 --> 00:56:59.006 A:middle
And we managed to
meet our target,

00:56:59.006 --> 00:57:01.016 A:middle
which in this case was
60 frames per second.


WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:56:59.006 --> 00:57:01.016 A:middle
which in this case was
60 frames per second.

00:57:01.146 --> 00:57:03.766 A:middle
So well done us!

00:57:05.216 --> 00:57:08.566 A:middle
So now, the talk is
over, and if you would

00:57:08.566 --> 00:57:11.356 A:middle
like any more information
on anything mentioned

00:57:11.356 --> 00:57:14.526 A:middle
in this session, you can
visit our developer portal,

00:57:14.916 --> 00:57:18.006 A:middle
you can also sign up for
the developer forums,

00:57:18.896 --> 00:57:22.606 A:middle
and should you have any detailed
questions or general inquiries,

00:57:22.606 --> 00:57:26.156 A:middle
you can direct them to Allan
Schaffer, who is our Graphics

00:57:26.156 --> 00:57:27.896 A:middle
and Games Technologies
Evangelist.

00:57:29.476 --> 00:57:32.316 A:middle
So thank you very much
for attending this talk.

00:57:32.376 --> 00:57:34.676 A:middle
And we hope you found
it interesting,

00:57:34.846 --> 00:57:37.886 A:middle
and enjoy the rest of WWDC!

00:57:38.276 --> 00:57:38.876 A:middle
Thank you very much!

00:57:39.676 --> 00:57:52.520 A:middle
[ Applause ]

